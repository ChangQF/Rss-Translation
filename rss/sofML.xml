<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 22 Apr 2024 15:14:43 GMT</lastBuildDate>
    <item>
      <title>最大似然估计初始参数问题</title>
      <link>https://stackoverflow.com/questions/78366722/maximum-likelihood-estimation-initial-parameters-issue</link>
      <description><![CDATA[我的数据集由 x 和 y 变量组成，我想执行最大似然估计 (MLE) 来拟合 sigmoid 均值函数 μ(X;β)=β0​+1+e−(X−β2​) β1​​ 和数据的线性标准偏差函数 σ(X;α)=α0​+α1​⋅X。我使用最大似然函数 L(θ∣X,Y)=i=1ΣN​logf(Yi​∣Xi​;θ) 估计 beta 和 alpha 参数，以便观察数据中的均值和 sigma 趋势。
可能性 = -np.sum(np.log(norm.pdf(Y, mu, sigma)))
最后，每次遇到以下情况时，使用 result = minusminimum(likelihood, initial_params, args=(X,Y), method=&#39;L-BFGS-B&#39;,options={&#39;maxiter&#39;: 100}) 执行似然优化当传递不同的初始值时获得不同的均值和西格玛值的问题时，我发现我的模型对初始参数变得敏感。有什么方法可以解决这种情况，以便我可以获得自动适合我的模型的均值和西格玛的最佳值？
附：我也应用了不同的优化方法，但没有效果。
我通过其他技术实现它已经取得了所需的结果，但我想使用 MLE 来实现它。我该如何解决这个问题？
我尝试过不同的优化方法]]></description>
      <guid>https://stackoverflow.com/questions/78366722/maximum-likelihood-estimation-initial-parameters-issue</guid>
      <pubDate>Mon, 22 Apr 2024 13:47:56 GMT</pubDate>
    </item>
    <item>
      <title>用于回归问题的 PyTorch 模型，每个样本 4 个图像，图像之间有时间间隔</title>
      <link>https://stackoverflow.com/questions/78366460/pytorch-model-for-regression-problem-with-4-images-per-sample-with-time-gap-betw</link>
      <description><![CDATA[我正在使用一个数据集，其中每个样本对应于以已知延迟拍摄的 4 个图像，并且每组 4 个图像都有一个目标预测，该目标预测是一个数字（不是分类）。我目前已经制作了下面的模型，但它根本没有给出好的结果。有什么建议吗？
class SimpleModel(nn.Module)：
    def __init__(自身):
        超级(SimpleModel, self).__init__()
        
        self.conv1 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(8)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.dropout1 = nn.Dropout(p=0.25)
        
        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(16)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.dropout2 = nn.Dropout(p=0.25)
        
        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm2d(32)
        self.pool3 = nn.MaxPool2d(kernel_size=5, stride=2)
        self.dropout3 = nn.Dropout(p=0.25)
        
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(28800, 512)
        self.dropout4 = nn.Dropout(p=0.5)
        self.fc2 = nn.Linear(512, 1) # 单输出

    def 前向（自身，x）：
        x = torch.relu(self.bn1(self.conv1(x)))
        x = self.pool1(x)
        x = self.dropout1(x)
        
        x = torch.relu(self.bn2(self.conv2(x)))
        x = self.pool2(x)
        x = self.dropout2(x)
        
        x = torch.relu(self.bn3(self.conv3(x)))
        x = self.pool3(x)
        x = self.dropout3(x)
        
        x = self.展平(x)
        x = torch.relu(self.fc1(x))
        x = self.dropout4(x)
        
        x = self.fc2(x) # 输出层，无回归激活函数
        返回x

此外，目标预测值通常非常小，有时甚至大得多，例如从 1e-9 到 1e2 左右。我已将对数刻度应用于目标预测，以减少这种影响，以尝试改进学习，但不确定它有多大帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78366460/pytorch-model-for-regression-problem-with-4-images-per-sample-with-time-gap-betw</guid>
      <pubDate>Mon, 22 Apr 2024 13:04:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 绘制糖尿病视网膜病变检测图</title>
      <link>https://stackoverflow.com/questions/78365786/mapping-in-a-diabetic-retinopathy-detection-using-python</link>
      <description><![CDATA[我目前正在开发一个使用 Inception V3 预训练模型进行糖尿病视网膜病变分类的 Python 程序，然后将其传递到 SVM 和随机森林分类器。快速分解该项目：

对 5 种类型（0、1、2、3、4）的眼睛图像进行分类，其中 0 表示没有患病，4 表示严重。
在这个特定的程序中，我有意将 0,1 图像映射到值 10，将 2,3,4 映射到值 11，将其变成二元分类器。
然后构建模型，然后正确训练和执行。

为了提供有关我的代码工作的更多详细信息，我想显示图像的特定映射。
我建了两个表：
表 1：它有三列，第一列是从 xero 开始的所有图像的编号，第二列是与图像对应的唯一标识符，第三列是类的原始映射 0、1、2 ,3,4。
表 2：前两列相同，但第三列现在显示映射的 ID（10 或 11）
一些有帮助的图像是：
图片 1
图片_2 图片 3
图片 4
我尝试实现上述问题，但是 2,3,4 的映射没有出现，只有 0,1 的映射出现。请帮我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78365786/mapping-in-a-diabetic-retinopathy-detection-using-python</guid>
      <pubDate>Mon, 22 Apr 2024 11:05:03 GMT</pubDate>
    </item>
    <item>
      <title>预测值与目标值/实际值之间没有相关性</title>
      <link>https://stackoverflow.com/questions/78365619/no-correlation-between-predicted-values-and-target-value-real-values</link>
      <description><![CDATA[我目前正在开发一个机器学习项目。具体来说是回归任务。当我绘制预测值与实际值时，我发现变量之间没有相关性。我猜这意味着模型无法拟合数据（类似于分类模型预测最常见的类别）。


我尝试了很多方法，但没有一个能够使模型适合数据：

我尝试用对数函数转换目标值：

y_train = np.log(y_train)
y_test = np.log(y_test)



我对目标变量应用了平方根函数，但它不起作用：

y_train = (y_train)**0.5
y_测试 = (y_测试)**0.5



我什至尝试标准化目标函数，但也不起作用

def preprocess_data_standard_regression(数据):
    定标器=标准定标器()
    X = data[[data.columns 中的 col 的 col
              如果不是 col.startswith(&quot;POSTOP_&quot;)
              并且 col !=“in_患者_id”
              和 col !=“in_laterity”]]
    y = 数据[“POSTOP_MAN_vault_posto”]
    y = scaler.fit_transform(y.values.reshape(-1,1)).flatten()
    缩放器 = MinMaxScaler()
    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)
    X_train = 缩放器.fit_transform(X_train)
    X_test = 缩放器.transform(X_test)
    返回 X_train、X_test、y_train、y_test


我的数据集的形状是 545 行 vs 24 列。
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78365619/no-correlation-between-predicted-values-and-target-value-real-values</guid>
      <pubDate>Mon, 22 Apr 2024 10:41:06 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该始终在神经网络初始化部分中包含初始化层？</title>
      <link>https://stackoverflow.com/questions/78365535/should-i-always-include-initialization-layers-in-my-neural-network-initializatio</link>
      <description><![CDATA[我看到有人的代码包含使用Xavier这种方式（如下），该代码用于预测具有1400行和300个变量（80个，在one-hot-encoding之前）的房价数据。我查了一下它的描述，上面说防止梯度消失或爆炸，加速收敛。这似乎都是有益的，所以我应该始终在代码中包含 Xavier 初始化吗？或者我什么时候不应该包括 Xavier？ TIA
类 Net(torch.nn.Module):
    def __init__(自身):
        超级(网络,自我).__init__()
        self.hidden_​​layer1 = nn.Linear(331,1024)
        self.hidden_​​layer2 = nn.Linear(1024,1024)
        self.hidden_​​layer3 = nn.Linear(1024,1024)
        self.hidden_​​layer4 = nn.Linear(1024,1024)
        self.output_layer = nn.Linear(1024,1)
        self.dropout = nn.Dropout(p=0.2)
        nn.init.xavier_uniform_(self.hidden_​​layer1.weight)
        nn.init.xavier_uniform_(self.hidden_​​layer2.weight)
        nn.init.xavier_uniform_(self.hidden_​​layer3.weight)
        nn.init.xavier_uniform_(self.hidden_​​layer4.weight)
        nn.init.xavier_uniform_(self.output_layer.weight)

defforward(self,x)：
    输入 = x
    layer1_out = torch.nn.function.gelu(self.hidden_​​layer1(输入))
    Layer1_out = self.dropout(layer1_out)
    Layer2_out = torch.nn.function.gelu(self.hidden_​​layer2(layer1_out))
    Layer2_out = self.dropout(layer2_out)
    layer3_out = torch.nn.function.gelu(self.hidden_​​layer3(layer2_out))
    Layer3_out = self.dropout(layer3_out)
    Layer4_out = torch.nn.function.gelu(self.hidden_​​layer4(layer3_out))
    Layer4_out = self.dropout(layer4_out)
    输出 = torch.relu(self.output_layer(layer4_out))
    返回输出

我一直在尝试学习深度学习，但我一直不清楚在神经网络中包含初始化的重要性。]]></description>
      <guid>https://stackoverflow.com/questions/78365535/should-i-always-include-initialization-layers-in-my-neural-network-initializatio</guid>
      <pubDate>Mon, 22 Apr 2024 10:25:38 GMT</pubDate>
    </item>
    <item>
      <title>您好，请帮忙，我遇到了 djangorestframework 的错误问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78365482/hi-there-help-plz-im-facing-an-error-issue-with-djangorestframework</link>
      <description><![CDATA[我尝试使用 djangorestframework 创建 API，但遇到错误问题，有人可以帮助我调试吗？我的代码如下
serializers.py：
从rest_framework导入序列化器
从rest_framework.exceptions导入ValidationError

类 ImagePredictionSerializer(serializers.Serializer):
    图像 = 序列化器.ImageField()

    def validate_image(自身, 值):
        如果没有值：
            raise ValidationError(“图像字段为必填项”)
        返回值

错误：
/api/upload/ 处出现类型错误
“方法”对象不支持项目分配
请求方式：GET
请求网址：http://127.0.0.1:8000/api/upload/
Django 版本：4.2.3
异常类型：TypeError
异常值：
“方法”对象不支持项目分配
异常位置：C:\src\Django_tuto\fridgevision\env\Lib\site-packages\django\middleware\clickjacking.py，第 34 行，在 process_response 中
在 process.serializers.ImagePredictionSerializer 期间引发
Python 可执行文件：C:\src\Django_tuto\fridgevision\env\Scripts\python.exe
Python版本：3.11.8
Python路径：
[&#39;C:\\src\\Django_tuto\\fridgevision&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\python311.zip&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\DLLs&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311&#39;,
 &#39;C:\\src\\Django_tuto\\fridgevision\\env&#39;,
 &#39;C:\\src\\Django_tuto\\fridgevision\\env\\Lib\\site-packages&#39;]
服务器时间：2024年4月22日周一10:00:10 +0000

我希望获得模型输入图像的预测。这是一个简单的二值分类模型，可以预测图像是好还是坏。]]></description>
      <guid>https://stackoverflow.com/questions/78365482/hi-there-help-plz-im-facing-an-error-issue-with-djangorestframework</guid>
      <pubDate>Mon, 22 Apr 2024 10:15:50 GMT</pubDate>
    </item>
    <item>
      <title>测量 pytorch 模型的 FPS 的正确方法是什么？</title>
      <link>https://stackoverflow.com/questions/78365230/which-is-correct-way-to-measure-fps-of-pytorch-model</link>
      <description><![CDATA[当我使用此代码时，我通过 cuda 事件（8.7 FPS）和 pref_counter （8.8 FPS）获得几乎相同的 FPS 值
 model.to(设备)

    宽、高 = 640, 640
    dummy_input = torch.randn(200, 1, 3, w, h, dtype=torch.float).to(设备)

    步骤、重复次数 = 10, 100
        # 分配 40MB 来匹配 A100 上的 L2 缓存大小
    x = torch.empty(int(40 * (1024 ** 2)), dtype=torch.int8, device=&#39;cuda&#39;)

    deflush_cache():
        x.zero_()

    # 热身步骤
    对于范围内的 i（步数）：
        _ = model(dummy_input[i]) # 不记录时间

    start_events = [torch.cuda.Event(enable_timing=True) for _ in range(repetitions)]
    end_events = [torch.cuda.Event(enable_timing=True) for _ in range(repetitions)]

    for i in tqdm(范围(重复), desc=&#39;进度&#39;):
        刷新缓存（）
        torch.cuda._sleep(1_000_000)

        start_events[i].record()
        _ = 模型(dummy_input[i])
        end_events[i].record()

    torch.cuda.synchronize()
    times = [s.elapsed_time(e) for s, e in zip(start_events, end_events)]

    # 重置时钟速度()
    
    Mean_syn = np.sum(次) / 重复次数
    fps = 1000 / 均值_syn

    print(&quot;平均推理时间: {:.4f} ms&quot;.format(mean_syn))
    print(“平均 FPS {} x {}: {:.4f}”.format(w, h, fps))

    # 热身步骤
    对于范围内的 i（步数）：
        _ = model(dummy_input[i]) # 不记录时间

    时间 = 0
    for i in tqdm(范围(重复), desc=&#39;进度&#39;):
        s = time.perf_counter()
        _ = 模型(dummy_input[i])
        e = time.perf_counter()
        t += (e-s)

    每秒帧数 = 100/吨
    print(“平均 FPS {} x {}: {:.4f}”.format(w, h, fps))

但是如果我在 pref_counter 方法中添加 torch.cuda.empty_cache() ，那么 pref_counter 方法中的 FPS 将变为 34.8。
 for i in tqdm(range(repetitions), desc=&#39;Progress&#39;):
        torch.cuda.empty_cache()
        s = time.perf_counter()
        _ = 模型(dummy_input[i])
        e = time.perf_counter()
        t += (e-s)

    每秒帧数 = 100/吨
    print(“平均 FPS {} x {}: {:.4f}”.format(w, h, fps))

那么哪个是正确的以及为什么会发生这种情况。有人可以帮忙吗？
我也尝试将 torch.cuda.empty_cache() 包含在 cuda 事件中，但 FPS 在 cuda 事件方法中保持不变。]]></description>
      <guid>https://stackoverflow.com/questions/78365230/which-is-correct-way-to-measure-fps-of-pytorch-model</guid>
      <pubDate>Mon, 22 Apr 2024 09:28:52 GMT</pubDate>
    </item>
    <item>
      <title>无法导入 py 文件并出现以下错误消息：无法解析导入“load_images”(reportMissingImports)</title>
      <link>https://stackoverflow.com/questions/78364383/the-py-file-cannot-be-imported-and-the-following-error-message-appears-import</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78364383/the-py-file-cannot-be-imported-and-the-following-error-message-appears-import</guid>
      <pubDate>Mon, 22 Apr 2024 06:43:40 GMT</pubDate>
    </item>
    <item>
      <title>我对我创建的 PINNs 模型有疑问 [关闭]</title>
      <link>https://stackoverflow.com/questions/78363881/i-have-doubts-about-the-pinns-model-that-i-created</link>
      <description><![CDATA[我尝试为一维表面波高程创建 PINN，输入为 (x,t)。经过长时间的尝试和错误，我意识到我的模型仍然不适合。我对之前创建的代码产生了怀疑，但又找不到错误所在，因为训练过程一直运行得很顺利。
我的代码哪里出错了？
导入tensorflow为tf
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

# 转换为 TensorFlow 张量
x_train = tf.convert_to_tensor(x, dtype=tf.float32)
t_train = tf.convert_to_tensor(t, dtype=tf.float32)
eta_train = tf.convert_to_tensor(eta_X, dtype=tf.float32)

# 组合 x 和 t 作为训练输入
输入 = tf.concat([x_train, t_train], axis=1)

# 定义物理信息神经网络 (PINN) 模型
PINN 类（tf.keras.Model）：
    def __init__(自身):
        超级（PINN，自我）.__init__()
        self.dense1 = tf.keras.layers.Dense(1000，激活=&#39;tanh&#39;，input_dim=2)
        self.dense2 = tf.keras.layers.Dense(1000, 激活=&#39;tanh&#39;)
        self.dense3 = tf.keras.layers.Dense(1000, 激活=&#39;tanh&#39;)
        self.dense4 = tf.keras.layers.Dense(1000, 激活=&#39;tanh&#39;)
        self.dense5 = tf.keras.layers.Dense(1000, 激活=&#39;tanh&#39;)
        self.dense6 = tf.keras.layers.Dense(1000, 激活=&#39;tanh&#39;)
        self.output_layer = tf.keras.layers.Dense(1, 激活=无)
        
    def 调用（自身，输入）：
        x = 输入[:, 0:1]
        t = 输入[:, 1:2]
        concat_input = tf.concat([x,t], 轴=1)
        hidden_​​1 = self.dense1(concat_input)
        隐藏_2 = self.dense2(隐藏_1)
        隐藏_3 = self.dense3(隐藏_2)
        隐藏_4 = self.dense4(隐藏_3)
        隐藏_5 = self.dense5(隐藏_4)
        隐藏_6 = self.dense6(隐藏_5)
        输出 = self.output_layer(hidden_​​6)
        返回输出
    
def物理损失（模型，x，t）：
    使用 tf.GradientTape(persistent=True) 作为磁带：
        磁带.watch(x)
        磁带.watch(t)
        u_pred = 模型(tf.concat([x,t], axis=1))
        u_x = Tape.gradient(u_pred, x)
        u_t = Tape.gradient(u_pred, t)
        删除磁带
    
    克=9.81
    h = 1
    
    损失 = u_t + np.sqrt(g*h) * u_x
    
    返回 tf.reduce_mean(tf.square(loss))

# 创建并编译PINN模型
模型 = PINN()
优化器 = tf.keras.optimizers.Adam(learning_rate=0.0001)

# 训练循环
纪元 = 200000
对于范围内的纪元（纪元）：
    使用 tf.GradientTape() 作为磁带：
        物理损失值=物理损失（模型，x_train，t_train）
        data_loss_value = tf.reduce_mean(tf.square(模型(输入) - eta_train))
        总损失 = 物理损失值 + 数据损失值
        
    梯度 = Tape.gradient(total_loss, model.trainable_variables)
    optimizer.apply_gradients(zip(梯度, model.trainable_variables))
    
    如果纪元 % 1000 == 0:
        print(f&quot;纪元 {epoch}/{epochs}，总损失：{total_loss.numpy()}，物理损失：{physicals_loss_value.numpy()}，数据损失：{data_loss_value.numpy()}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/78363881/i-have-doubts-about-the-pinns-model-that-i-created</guid>
      <pubDate>Mon, 22 Apr 2024 03:47:04 GMT</pubDate>
    </item>
    <item>
      <title>我收到错误 - ValueError: 在使用模型 ss3 进行投票分类器时，估计器 SS3 应该是分类器</title>
      <link>https://stackoverflow.com/questions/78362782/i-am-getting-an-error-valueerror-the-estimator-ss3-should-be-a-classifier-whi</link>
      <description><![CDATA[我正在研究一个使用投票的集成模型，用于 ss3 模型、svm 模型和 RoBERTa 模型，但我遇到了很多错误。
我尝试包含拟合函数、预测函数，并尝试在 ss3 类的 init 中添加 _estimator_type = &#39;classifier&#39; 行，但随后出现错误，表明这是不必要的。请帮助我消除这个错误并指导我如何制作集成模型。
这是我面临最多问题的代码部分：
SS3 级：
def __init__(自身):
    _estimator_type = &#39;分类器&#39;
    # self.train_df = 无
    self.cf = 无
    self. precision = 无，
    自我回忆=无，
    self.f1_score = 无，
    self.accuracy = 无，
    self.local_values = 无

def get_params(self, deep=True):
    返回 {
        &#39;_estimator_type&#39;: self._estimator_type,
    }

这是错误：
回溯（最近一次调用最后一次）：
 第 236 行，在 _validate_estimators 中
    引发值错误（
ValueError：估计器 SS3 应该是一个分类器。

进程已完成，退出代码为 1
]]></description>
      <guid>https://stackoverflow.com/questions/78362782/i-am-getting-an-error-valueerror-the-estimator-ss3-should-be-a-classifier-whi</guid>
      <pubDate>Sun, 21 Apr 2024 18:48:18 GMT</pubDate>
    </item>
    <item>
      <title>KNN 类型错误和数据标准化</title>
      <link>https://stackoverflow.com/questions/78360476/knn-typeerror-and-data-normalization</link>
      <description><![CDATA[即使完成教程指示的所有操作，我也无法使预测正常工作。
从 sklearn.neighbors 导入 KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=3, metric=&#39;euclidean&#39;)
knn_model.fit(train_val_process, merge_labels.label)
y_pred_knn = knn.predict(test_data_process)

错误如下：
TypeError：KNeighborsClassifier.predict() 缺少 1 个必需的位置参数：
&#39;X&#39;

我应该将数据均值标准化为 1 std 0。这样好吗？
from sklearn.preprocessing import StandardScaler
定标器=标准定标器()
缩放器.fit(pd.concat([train_data, val_data]))
train_data_process = pd.DataFrame(scaler.transform(train_data), columns=train_data.columns)
val_data_process = pd.DataFrame(scaler.transform(val_data), columns=val_data.columns)
train_val_process = pd.concat([train_data, val_data])
test_data_process = pd.DataFrame(scaler.transform(test_data), columns=test_data.columns)
y_test = test_labels.label
]]></description>
      <guid>https://stackoverflow.com/questions/78360476/knn-typeerror-and-data-normalization</guid>
      <pubDate>Sun, 21 Apr 2024 05:13:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 Raspberry Pi 4 在 Python 中崩溃的多线程 [关闭]</title>
      <link>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</link>
      <description><![CDATA[我在尝试使用 Raspberry Pi 4B 完成大学项目时遇到问题。
该项目使用 Python 编写，由 5 个线程组成，其中 2 个线程运行机器学习预测，第 3 个线程按顺序运行一系列计算，以达到与机器学习模型预测的输出相同的输出（这样我可以对比输出是否是合理的值）。另外两个线程是：一个等待 10 秒并激活一个标志（开始处理所需的标志），另一个在终端上打印值（都是从 ML 模型和计算中预测的）。
我的问题是，当我尝试同时运行所有线程时，ML 模型运行正确，但我的计算线程不执行任何操作。相反，如果我不启动 ML 线程，计算线程就会正常工作。
我认为Raspberry没有足够的计算能力，因此计算线程崩溃了。
没有必要所有 3 个线程同时运行（我希望能够选择是否要查看终端上打印的 ML 预测或计算输出），因此我尝试禁用线程当我不使用它们时（使用 thread.join() ）并在我决定希望该线程再次开始运行时再次启动它们（thread.start() ）但它无法正常工作。
我还尝试过使用运行预测或计算函数所需的两个标志（ML_flag 和calculations_flag），但也不起作用。
关于我可以使用的其他技术的任何想法，以便 ML 预测和计算单独运行并且不会崩溃？
谢谢！
下图显示了命令htop：
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</guid>
      <pubDate>Fri, 19 Apr 2024 08:31:18 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“tensorflow.keras”的模块，库不匹配</title>
      <link>https://stackoverflow.com/questions/72409779/modulenotfounderror-no-module-named-tensorflow-keras-libraries-mismatching</link>
      <description><![CDATA[软件包1
packages2
这些是我在 anaconda 上的包。我在最后一张照片上收到此错误。我尝试了 stackoverflow 和 github 上的几乎所有内容。我尝试了各种方法来导入 keras 和 tensorflow 。我降级了tensorflow，keras，但我遇到了任何其他错误，例如numpy不兼容等。我将numpy降级为，但这次keras需要更高的版本。
从 keras.preprocessing.text 导入分词器
/从keras.preprocessing.sequence导入pad_sequences
这些是我尝试导入的行。
导入keras
回溯（最近一次调用最后一次）：

  在&lt;单元格行：1&gt;中输入[6]
    导入keras

   中的文件 ~\anaconda3\lib\site-packages\keras\__init__.py:3
    从 。导入实用程序

   中的文件 ~\anaconda3\lib\site-packages\keras\utils\__init__.py:26
    从 .vis_utils 导入 model_to_dot

   中的文件 ~\anaconda3\lib\site-packages\keras\utils\vis_utils.py:7
    从 ..models 导入模型

   中的文件 ~\anaconda3\lib\site-packages\keras\models.py:12
    从 .engine.training 导入模型

   中的文件 ~\anaconda3\lib\site-packages\keras\engine\__init__.py:7
    从 .network 导入 get_source_inputs

   中的文件 ~\anaconda3\lib\site-packages\keras\engine\network.py:15
    从 。进口储蓄

   中的文件 ~\anaconda3\lib\site-packages\keras\engine\ saving.py:21
    从 .. 导入优化器

   中的文件 ~\anaconda3\lib\site-packages\keras\optimizers\__init__.py:1
    从tensorflow.keras.optimizers导入*

ModuleNotFoundError：没有名为“tensorflow.keras”的模块
]]></description>
      <guid>https://stackoverflow.com/questions/72409779/modulenotfounderror-no-module-named-tensorflow-keras-libraries-mismatching</guid>
      <pubDate>Fri, 27 May 2022 18:37:11 GMT</pubDate>
    </item>
    <item>
      <title>将 make_column_transformer 与 OnehotEncoder 和 StandaScaler + 直通结合使用</title>
      <link>https://stackoverflow.com/questions/59605035/using-make-column-transformer-with-onehotencoder-and-standascaler-passthrough</link>
      <description><![CDATA[每当我同时使用 StandardScaler 和 OnehotEncoding 时，我都无法使用 remainder=&#39;passthrough&#39;。不管我怎么说，我都有一个问题。它要么是参数之前的关键字，要么是 fit_tranform 的问题......你能想到的。这是我正在做的事情：
trans_cols= make_column_transformer((OneHotEncoder(),[&#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;,
 &#39;默认&#39;,&#39;住房&#39;,&#39;贷款&#39;,&#39;联系人&#39;,&#39;月份&#39;,&#39;poutcome&#39;]),remainder=&#39;passthrough&#39;)

trans_cols.fit_transform(X)

这是我的专栏：
Index([&#39;年龄&#39;, &#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;, &#39;默认&#39;, &#39;余额&#39;, &#39;住房&#39;,
   &#39;贷款&#39;, &#39;联系&#39;, &#39;月份&#39;, &#39;持续时间&#39;, &#39;活动&#39;, &#39;pdays&#39;, &#39;上一个&#39;,
   &#39;撅嘴&#39;，&#39;y&#39;]，
  dtype=&#39;对象&#39;)

上面的代码有效，我只是在使用 remainder 键参数时无法组合 2 个估计器。这就是我尝试的原因：
trans_cols= make_column_transformer((OneHotEncoder(),[&#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;, &#39;默认&#39;,&#39;住房&#39;,&#39;贷款&#39;,
                                                  &#39;联系人&#39;,&#39;月份&#39;,&#39;poutcome&#39;]),remainder=&#39;passthrough&#39;,

(StandardScaler(),[&#39;年龄&#39;, &#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;, &#39;默认&#39;, &#39;余额&#39;,
                  &#39;住房&#39;,&#39;贷款&#39;, &#39;联系方式&#39;, &#39;月份&#39;, &#39;期限&#39;,
                  &#39;活动&#39;、&#39;pdays&#39;、&#39;上一个&#39;、&#39;poutcome&#39;]))

但是，在我删除 remainder 并保留 2 个元组之前，上述方法不起作用。这是可以理解的。然而，这样做它试图对我的一些数字进行编码，并且有一条消息告诉我它遇到了一些具有浮动的列。而且我的准确性严重下降。]]></description>
      <guid>https://stackoverflow.com/questions/59605035/using-make-column-transformer-with-onehotencoder-and-standascaler-passthrough</guid>
      <pubDate>Sun, 05 Jan 2020 23:14:28 GMT</pubDate>
    </item>
    <item>
      <title>当权重存在时，glmnet 如何标准化变量？</title>
      <link>https://stackoverflow.com/questions/41122803/how-does-glmnet-standardize-variables-when-weights-are-present</link>
      <description><![CDATA[glmnet 允许用户通过 weights 参数输入观察权重向量。 glmnet 还标准化（默认情况下）预测变量以具有零均值和单位方差。我的问题是：当提供 weights 时，glmnet 是否使用每列的加权平均值（和标准差）或未加权平均值（和标准差）来标准化预测变量？]]></description>
      <guid>https://stackoverflow.com/questions/41122803/how-does-glmnet-standardize-variables-when-weights-are-present</guid>
      <pubDate>Tue, 13 Dec 2016 13:50:42 GMT</pubDate>
    </item>
    </channel>
</rss>