<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 21 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Hyacinth6B：繁体中文大型语言模型</title>
      <link>https://arxiv.org/abs/2403.13334</link>
      <description><![CDATA[arXiv:2403.13334v1 公告类型：新
摘要：本研究的主要动机是解决通常与法学硕士相关的高硬件和计算需求。因此，我们的目标是在模型轻量性和性能之间找到平衡，力求在使用相对轻量级的模型时最大化性能。 Hyacinth6B 的开发就是考虑到这一目标，旨在充分利用法学硕士的核心功能，而不产生大量的资源成本，有效地突破较小模型的性能界限。训练方法涉及使用 LoRA 方法进行参数高效微调。]]></description>
      <guid>https://arxiv.org/abs/2403.13334</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>研究人脑语言处理的计算模型：一项调查</title>
      <link>https://arxiv.org/abs/2403.13368</link>
      <description><![CDATA[arXiv:2403.13368v1 公告类型：新
摘要：尽管当前的语言模型在实现和算法上与人类语言处理机制有所不同，但仍表现出显着的类人类或超越人类的语言能力。是否应该采用计算语言模型来研究大脑？如果是，何时以及如何？为了深入探讨这个主题，本文回顾了使用计算模型进行大脑研究的努力，强调了新兴趋势。为了确保公平比较，本文在同一数据集上使用一致的指标评估各种计算模型。我们的分析表明，没有任何一个模型在所有数据集上都优于其他模型，这强调了在涉及计算模型的研究中需要丰富的测试数据集和严格的实验控制才能得出可靠的结论。]]></description>
      <guid>https://arxiv.org/abs/2403.13368</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>Arcee 的 MergeKit：用于合并大型语言模型的工具包</title>
      <link>https://arxiv.org/abs/2403.13257</link>
      <description><![CDATA[arXiv:2403.13257v1 公告类型：新
摘要：开源语言模型领域的快速扩展提供了通过组合参数来合并这些模型检查点能力的机会。迁移学习（针对特定任务对预训练模型进行微调的过程）的进步导致了大量特定于任务的模型的开发，这些模型通常专门针对单个任务并且无法利用彼此的优势。模型合并有助于创建多任务模型，而无需额外的训练，为增强模型性能和多功能性提供了一条有希望的途径。通过保留原始模型的内在功能，模型合并解决了人工智能中的复杂挑战，包括灾难性遗忘和多任务学习的困难。为了支持这一不断扩大的研究领域，我们引入了 MergeKit，这是一个综合性的开源库，旨在促进模型合并策略的应用。 MergeKit 提供了一个可扩展的框架，可以在任何硬件上有效地合并模型，为研究人员和从业者提供实用性。迄今为止，开源社区已经合并了数千个模型，从而创建了一些世界上最强大的开源模型检查点，正如 Open LLM 排行榜所评估的那样。该库可通过 https://github.com/arcee-ai/MergeKit 访问。]]></description>
      <guid>https://arxiv.org/abs/2403.13257</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>AFLoRA：大型模型参数高效微调中低阶自适应的自适应冻结</title>
      <link>https://arxiv.org/abs/2403.13269</link>
      <description><![CDATA[arXiv:2403.13269v1 公告类型：新
摘要：我们提出了一种新颖的参数高效微调（PEFT）方法，称为低阶自适应自适应冻结（AFLoRA）。具体来说，对于每个预训练的冻结权重张量，我们添加可训练低秩矩阵的并行路径，即下投影和上投影矩阵，每个矩阵后跟一个特征变换向量。基于一种新颖的冻结分数，我们在微调过程中逐步冻结这些投影矩阵，以减少计算量并缓解过度拟合。我们的实验结果表明，根据 GLUE 基准评估，我们可以实现最先进的性能，平均提高高达 $0.85\%$，同时平均可训练参数减少高达 $9.5\times$。就运行时间而言，与类似的 PEFT 替代方案相比，AFLoRA 可以带来高达 1.86 美元\倍的改进。除了我们方法的实用性之外，我们还提供了有关不同模块的 LoRA 路径的可训练性要求以及不同投影矩阵的冻结时间表的见解。代码将被发布。]]></description>
      <guid>https://arxiv.org/abs/2403.13269</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>LeanReasoner：用精益促进复杂的逻辑推理</title>
      <link>https://arxiv.org/abs/2403.13312</link>
      <description><![CDATA[arXiv:2403.13312v1 公告类型：新
摘要：由于逻辑不一致和推理固有的困难，大型语言模型（LLM）经常难以处理复杂的逻辑推理。我们使用精益（Lean）这个定理证明框架来应对这些挑战。通过将逻辑推理问题形式化为精益中的定理，我们可以通过证明或反驳相应的定理来解决它们。该方法借助 Lean 的符号求解器降低了逻辑不一致的风险。它还通过使用 Lean 广泛的定理证明库来增强我们处理复杂推理任务的能力。我们的方法在 FOLIO 数据集上实现了最先进的性能，并在 ProofWriter 上实现了接近这一水平的性能。值得注意的是，这些结果是通过对每个数据集的不到 100 个域内样本进行微调来实现的。]]></description>
      <guid>https://arxiv.org/abs/2403.13312</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>使用师生大语言模型指导多约束分子生成</title>
      <link>https://arxiv.org/abs/2403.13244</link>
      <description><![CDATA[arXiv:2403.13244v1 公告类型：新
摘要：虽然已经提出了各种模型和计算工具用于分子的结构和性质分析，但生成符合所有所需结构和性质的分子仍然是一个挑战。在这里，我们介绍了一种多约束分子生成大语言模型 TSMMG，它类似于学生，融合了来自各种小模型和工具（即“老师”）的知识。为了训练 TSMMG，我们通过从这些“老师”那里提取分子知识来构建大量的文本-分子对，使其能够通过各种文本提示生成符合描述的新颖分子。我们的实验表明，TSMMG 在生成满足复杂的、自然语言描述的属性要求的分子方面表现出色，跨越两个、三个和四个约束任务，平均分子有效性超过 99%，成功率分别为 88.08%、65.27% 、 和 61.44%。该模型还通过零次测试展现了适应性，创建了满足尚未遇到的属性组合的分子。正如通过经验验证所证实的，它可以理解具有各种语言风格的文本输入，超出了概述提示的范围。此外，TSMMG的知识蒸馏功能有助于小模型的不断增强，而数据集构建的创新方法有效解决了数据稀缺和质量问题，这使TSMMG成为药物发现和材料科学领域的一个有前途的工具。代码可在 https://github.com/HHW-zhou/TSMMG 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.13244</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型的知识蒸馏促进开放域对话系统的色情文本检测</title>
      <link>https://arxiv.org/abs/2403.13250</link>
      <description><![CDATA[arXiv:2403.13250v1 公告类型：新
摘要：人机交互对话中出现的色情内容会给开放域对话系统中的用户带来严重的副作用。然而，人机交互对话中检测色情语言的研究是一个很少被研究的重要课题。为了朝这个方向前进，我们引入了 CensorChat，这是一个对话监控数据集，旨在检测对话会话是否包含色情内容。为此，我们在野外收集现实生活中的人机交互对话，并将其分解为单句话和单回合对话，最后一句话是由聊天机器人说出的。我们建议利用大型语言模型的知识蒸馏来注释数据集。具体来说，首先，原始数据集由四个开源大型语言模型进行注释，并以多数票决定标签。其次，我们使用 ChatGPT 更新第一步中的空标签。第三，为了确保验证和测试集的质量，我们利用 GPT-4 进行标签校准。如果当前标签与 GPT-4 生成的标签不匹配，我们会采用一种自我批评策略来验证其正确性。最后，为了促进色情文本的检测，我们使用伪标记数据集开发了一系列文本分类器。详细的数据分析表明，利用大型语言模型的知识蒸馏技术为开发色情文本检测器提供了一种实用且经济高效的方法。]]></description>
      <guid>https://arxiv.org/abs/2403.13250</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>使用解析语言结构对文档作者进行分类</title>
      <link>https://arxiv.org/abs/2403.13253</link>
      <description><![CDATA[arXiv:2403.13253v1 公告类型：新
摘要：多年来，人们一直对基于文本的统计属性（例如通过使用非上下文单词的出现率）来检测文本的作者产生了兴趣。在之前的工作中，这些技术已被用来确定所有 \emph{联邦党人文集} 的作者身份。在现代，此类方法可能有助于检测假冒作者或人工智能作者。统计自然语言解析器的进展引入了使用语法结构来检测作者身份的可能性。在本文中，我们探索了一种使用统计自然语言解析器提取的语法结构信息来检测作者身份的新可能性。本文提供了一个概念证明，在一组“证明文本”（《联邦党人文集》和《桑迪顿》）上测试基于语法结构的作者分类，这些文本在之前的作者身份检测研究中已作为测试用例。探索了从统计自然语言解析器中提取的几个特征：来自任何级别的一定深度的所有子树；一定深度的有根子树、词性以及解析树中按级别的词性。人们发现将特征投影到较低维度的空间中是有帮助的。对这些文档的统计实验表明，来自统计解析器的信息实际上可以帮助区分作者。]]></description>
      <guid>https://arxiv.org/abs/2403.13253</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>技术报告：BetterMixture 竞赛解决方案</title>
      <link>https://arxiv.org/abs/2403.13233</link>
      <description><![CDATA[arXiv:2403.13233v1 公告类型：新
摘要：在大规模模型蓬勃发展的时代，从浩瀚而复杂的数据海洋中选择和优化数据集，以在有限的计算资源的约束下增强大型语言模型的性能已变得至关重要。本文详细介绍了我们针对 BetterMixture 挑战的解决方案，该解决方案重点关注大型语言模型的数据混合微调。我们的方法获得了第三名，它结合了重复数据删除、低级和高级质量过滤以及多样性选择。我们解决方案的基础是 Ke-Data-Juicer，它是 Data-Juicer 的扩展，展示了其在处理和优化大型语言模型数据方面的强大功能。]]></description>
      <guid>https://arxiv.org/abs/2403.13233</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>SumTra：用于少样本跨语言摘要的可微管道</title>
      <link>https://arxiv.org/abs/2403.13240</link>
      <description><![CDATA[arXiv:2403.13240v1 公告类型：新
摘要：跨语言摘要（XLS）以不同于输入文档的语言（例如英语到西班牙语）生成摘要，使目标语言的使用者能够获得其内容的简洁视图。目前，完成此任务的主要方法是采用执行的、预训练的多语言语言模型 (LM)，并针对感兴趣的语言对对其进行微调以适用于 XLS。然而，微调样本的稀缺使得这种方法在某些情况下具有挑战性。因此，在本文中，我们建议重新审视总结和翻译管道，其中总结和翻译任务按顺序执行。这种方法允许重复使用许多公开可用的资源进行单语摘要和翻译，从而获得非常有竞争力的零样本性能。此外，所提出的管道是端到端完全可微的，使其能够在可用的情况下利用少样本微调。在两个当代且广泛采用的 XLS 数据集（CrossSum 和 WikiLingua）上进行的实验表明，所提出的方法具有卓越的零样本性能，并且与等效的多语言 LM 基线相比，其强大的少样本性能也表明所提出的方法能够只需 10% 的微调样本即可在许多语言中表现出色。]]></description>
      <guid>https://arxiv.org/abs/2403.13240</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>编码一次并行解码：高效 Transformer 解码</title>
      <link>https://arxiv.org/abs/2403.13112</link>
      <description><![CDATA[arXiv:2403.13112v1 公告类型：新
摘要：基于 Transformer 的 NLP 模型功能强大，但计算成本较高，限制了部署场景。微调编码器-解码器模型在专业领域很流行，并且可以胜过更大、更通用的仅解码器模型，例如 GPT-4。我们为编码器-解码器模型引入了一种新的配置，可以提高结构化输出和问答任务的效率，其中单个输入需要多个输出。我们的方法提示解码器 (PiD) 对输入进行一次编码并并行解码输出，通过避免重复输入编码来提高训练和推理效率，从而减少解码器的内存占用。我们实现了计算量的减少，其计算量大致随子任务的数量而变化，与用于对话状态跟踪、摘要和问答任务的最先进模型相比，速度提高了 4.6 倍，并且性能相当或更好。我们发布了训练/推理代码和检查点。]]></description>
      <guid>https://arxiv.org/abs/2403.13112</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>用于持续神经机器翻译的自生成重播存储器</title>
      <link>https://arxiv.org/abs/2403.13130</link>
      <description><![CDATA[arXiv:2403.13130v1 公告类型：新
摘要：现代神经机器翻译系统在多种不同语言中表现出强大的性能，并且正在不断改进。然而，他们持续学习的能力仍然受到灾难性遗忘问题的严重限制。在这项工作中，我们利用编码器-解码器 Transformer 的一个关键属性，即它们的生成能力，提出了一种持续学习神经机器翻译系统的新方法。我们展示了如何通过利用模型本身作为并行句子生成器填充的重放内存，有效地学习包含不同语言的经验流。我们凭经验证明，我们的方法可以抵消灾难性遗忘，而无需明确记忆训练数据。代码将在发布后公开。代码：https://github.com/m-resta/sg-rep]]></description>
      <guid>https://arxiv.org/abs/2403.13130</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>Wav2Gloss：从语音生成行间注释文本</title>
      <link>https://arxiv.org/abs/2403.13169</link>
      <description><![CDATA[arXiv:2403.13169v1 公告类型：新
摘要：世界上数以千计的语言正面临灭绝的危险——这对文化认同和人类语言多样性构成了巨大威胁。行间注释文本 (IGT) 是一种语言注释形式，可以支持这些语言社区的文档和资源创建。 IGT 通常由 (1) 转录、(2) 形态分割、(3) 注释和 (4) 到主要语言的自由翻译组成。我们提出 Wav2Gloss：一项从语音中自动提取这四个注释组件的任务，并为此引入第一个数据集 Fieldwork：一个包含所有这些注释的语音语料库，涵盖 37 种语言，具有标准格式和训练/开发/测试分割。我们比较了端到端和级联的 Wav2Gloss 方法，分析表明预先训练的解码器有助于翻译和注释，多任务和多语言方法表现不佳，并且端到端系统比级联系统表现更好，尽管纯文本系统具有优势。我们提供基准，为未来通过语音生成 IGT 的研究奠定基础。]]></description>
      <guid>https://arxiv.org/abs/2403.13169</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>通过即时调优使用大语言模型自动总结医患对话</title>
      <link>https://arxiv.org/abs/2403.13089</link>
      <description><![CDATA[arXiv:2403.13089v1 公告类型：新
摘要：自动文本摘要（ATS）是一项新兴技术，可帮助临床医生提供持续、协调的护理。本研究提出了一种使用生成大语言模型（LLM）总结医患对话的方法。我们开发了即时调整算法来指导生成法学硕士总结临床文本。我们检查了 GatorTronGPT 的提示调整策略、软提示的大小以及短学习能力，GatorTronGPT 是一种生成临床 LLM，使用 2770 亿个临床和通用英语单词以及多达 200 亿个参数开发。我们使用临床基准数据集 MTS-DIALOG，将 GatorTronGPT 与之前基于广泛使用的 T5 模型微调的解决方案进行了比较。实验结果表明，GatorTronGPT-20B模型在所有评估指标上均取得了最佳性能。所提出的解决方案具有较低的计算成本，因为 LLM 参数在提示调整期间不会更新。这项研究证明了通过及时调整，生成临床法学硕士对于临床 ATS 的效率。]]></description>
      <guid>https://arxiv.org/abs/2403.13089</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>面向法律文本多级摘要的无监督问答系统</title>
      <link>https://arxiv.org/abs/2403.13107</link>
      <description><![CDATA[arXiv:2403.13107v1 公告类型：新
摘要：本文总结了 SCaLAR 团队在 SemEval-2024 任务 5：民事诉讼中的法律论证推理方面的工作。为了解决由于所涉及的法律文本的复杂性而令人畏惧的二元分类任务，我们提出了一种简单而新颖的相似性和基于距离的无监督方法来生成标签。此外，我们探索使用集成特征（包括 CNN、GRU 和 LSTM）的 Legal-Bert 嵌入的多级融合。为了解决数据集中法律解释的冗长性，我们引入了基于 T5 的分段摘要，它成功地保留了关键信息，从而提高了模型的性能。我们的无监督系统在开发集上的宏观 F1 分数提高了 20 点，在测试集上提高了 10 点，考虑到其不复杂的架构，这是有希望的。]]></description>
      <guid>https://arxiv.org/abs/2403.13107</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    </channel>
</rss>