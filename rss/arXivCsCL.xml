<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Fri, 19 Jan 2024 03:15:32 GMT</lastBuildDate>
    <item>
      <title>解决命名实体中的常规多义现象。 （arXiv：2401.09758v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.09758</link>
      <description><![CDATA[词义消歧主要解决常用词的词汇歧义
基于预定义意义清单的单词。相反，专有名称是
通常被认为是指特定的现实世界所指对象。一旦参考
一旦决定，据称歧义就得到解决。然而，专有名称也
通过称谓表现出歧义，即它们的作用就像普通词一样
并且可以表示其所指对象的不同方面。我们建议解决
通过常规多义词来消除专有名称的歧义，我们
形式化为点对象。本文介绍了组合词义
用于消除中文常用词歧义的消歧（WSD）模型
Wordnet (CWN) 和专有名称作为点对象。该模型利用了
基于光泽度的模型架构的灵活性，它利用了
CWN 的注释和例句。我们证明该模型实现了
在普通名词和专有名词上都有竞争性的结果，即使是相对而言
稀疏感知数据集。除了作为一个高性能的 WSD 工具之外，该模型还进一步
方便词汇资源的未来开发。
]]></description>
      <guid>http://arxiv.org/abs/2401.09758</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:32 GMT</pubDate>
    </item>
    <item>
      <title>使用具有 InfoNCE 损失和语言切换方法的 Transformer 基础模型的课程推荐。 （arXiv：2401.09699v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.09699</link>
      <description><![CDATA[课程推荐范式致力于促进学习
在不断发展的教育技术领域内的平等
课程发展。在承认所造成的固有障碍时
现有的方法，例如内容冲突和语言干扰
翻译，这种范式旨在面对和克服这些挑战。
值得注意的是，它解决了语言带来的内容冲突和干扰
翻译，可能会阻碍创造一个包罗万象的障碍
个性化的学习体验。该范式的目标是培养
教育环境不仅包容多样性，而且定制
学习经验，以满足每个学习者的不同需求。克服
这些挑战，我们的方法建立在课程的显着贡献之上
发展和个性化学习，引入三项关键创新。这些
包括 Transformer 基础模型的集成以增强计算能力
效率，实施InfoNCE Loss以获得准确的内容主题
匹配，并采用语言切换策略来缓解
与翻译相关的歧义。这些创新共同旨在
共同应对固有的挑战，并为打造一个更加
为不同类型的学习者提供公平有效的学习之旅。
竞争性交叉验证分数强调了功效
Sentence-Transformers/LaBSE，达到 0.66314，展示了我们的方法论
内容对齐预测的不同语言细微差别的有效性。
索引词-课程推荐、InfoNCE Loss 的 Transformer 模型、
语言切换。
]]></description>
      <guid>http://arxiv.org/abs/2401.09699</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:31 GMT</pubDate>
    </item>
    <item>
      <title>预测病毒谣言和弱势用户以进行信息流行病监控。 （arXiv：2401.09724v1 [cs.SI]）</title>
      <link>http://arxiv.org/abs/2401.09724</link>
      <description><![CDATA[在信息流行时代，拥有有效的工具至关重要
监控可以迅速传播的猖獗谣言的传播，以及
识别可能更容易传播此类信息的弱势用户
误传。这种积极主动的方法可以及时采取预防措施
采取措施，减轻虚假信息对社会的负面影响。我们
提出一种新方法来预测病毒式谣言和易受攻击的用户
统一图神经网络模型。我们预训练基于网络的用户嵌入
并利用用户和帖子之间的交叉注意力机制，以及
社区增​​强的漏洞传播（CVP）方法，以提高用户和
传播图表示。此外，我们采用两个多任务
减轻任务之间负转移效应的培训策略
不同的设置，增强了我们方法的整体性能。我们也
构建两个具有信息病毒性真实注释的数据集
以及用户在谣言和非谣言事件中的漏洞，这些事件会自动
来自现有的谣言检测数据集。广泛的评估结果
我们的联合学习模型证实了它在所有方面都优于强基线
三个任务：谣言检测、病毒性预测和用户漏洞
得分。例如，与基于微博的最佳基线相比
数据集，我们的模型在准确度和 MacF1 上分别提高了 3.8% 和 3.0%
谣言检测，并将均方误差 (MSE) 降低 23.9\% 和 16.5\%
分别是病毒式传播预测和用户漏洞评分。我们的发现
表明我们的方法有效地捕捉了谣言之间的相关性
病毒式传播和用户脆弱性，利用这些信息来改进
预测性能并为信息流行病监测提供有价值的工具。
]]></description>
      <guid>http://arxiv.org/abs/2401.09724</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:31 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型横向鱼叉式网络钓鱼：大规模组织环境中的比较研究。 （arXiv：2401.09727v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2401.09727</link>
      <description><![CDATA[网络钓鱼电子邮件的严重威胁进一步加剧
法学硕士具有产生高度针对性、个性化和自动化的潜力
鱼叉式网络钓鱼攻击。关于LLM促进的两个关键问题
网络钓鱼需要进一步调查：1）横向网络钓鱼的现有研究
缺乏针对大规模攻击目标的 LLM 集成的具体检查
整个组织，以及 2) 当前的反网络钓鱼基础设施，尽管
其广泛的发展，缺乏阻止LLM产生的能力
攻击，可能影响员工和 IT 安全事件
管理。然而，此类调查研究的执行需要
真实环境，在正常业务运营期间发挥作用的环境
并反映了大型组织基础设施的复杂性。这
设置还必须提供促进多样化阵列所需的灵活性
实验条件，特别是网络钓鱼电子邮件的合并
由法学硕士精心制作。本研究是对大数据应用的开创性探索
用于创建有针对性的横向网络钓鱼电子邮件的语言模型（LLM），
目标是大型一级大学的运营和员工人数约为
11 个月内有 9,000 人。它还评估了以下人员的能力
电子邮件过滤基础设施来检测此类 LLM 生成的网络钓鱼尝试，
提供对其有效性的见解并确定潜在的领域
改进。根据我们的发现，我们提出基于机器学习的检测
此类电子邮件的技术可检测 LLM 生成的网络钓鱼电子邮件
现有基础设施错过了这一点，F1 分数为 98.96。
]]></description>
      <guid>http://arxiv.org/abs/2401.09727</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:31 GMT</pubDate>
    </item>
    <item>
      <title>用大型语言模型描述在线饮食失调社区。 （arXiv：2401.09647v1 [cs.SI]）</title>
      <link>http://arxiv.org/abs/2401.09647</link>
      <description><![CDATA[饮食失调症的增加，这是一种危险的心理健康状况，
死亡率和发病率，与理想化身体的扩散有关
社交媒体上的图像。然而，社交媒体和饮食之间的联系
疾病要复杂得多。我们认为社交媒体平台创造了
反馈循环，放大内容和社区的增长，促进
厌食症和贪食症等饮食失调。具体来说，社交媒体
平台使弱势群体可以轻松找到并联系
志同道合的其他人，而团体动态过程鼓励他们留下来
参与宣扬和美化与以下行为相关的有害行为的社区
饮食失调。我们通过经验来描述这种动态
网络和语言分析的结合。我们描述了一个新颖的框架
利用大型语言模型来分析在线话语
社区并调查他们对饮食失调相关话题的态度
识别潜在有害的内容。我们的工作强调需要更好
社交媒体节制以破坏有害的反馈循环并保护
弱势个体。
]]></description>
      <guid>http://arxiv.org/abs/2401.09647</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:30 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型辅助对患者阅读临床笔记的影响：混合方法研究。 （arXiv：2401.09637v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2401.09637</link>
      <description><![CDATA[患者从阅读临床记录中获益匪浅，
包括增强对健康的控制感并改善
了解他们的护理计划。然而，复杂的医学概念和术语
临床记录中的内容会妨碍患者的理解并可能导致焦虑。我们
开发了一种面向患者的工具，使临床记录更具可读性，
利用大型语言模型 (LLM) 来简化、提取信息，
并为笔记添加上下文。我们促使工程化的 GPT-4 来执行这些
基于乳腺癌幸存者捐赠的真实临床记录的增强任务
以及临床医生生成的合成注释，总共 12 个注释，3868 个
字。 2023 年 6 月，随机抽取了 200 名美国女性参与者
使用我们的方法分配了具有不同增强程度的三个临床记录
工具。参与者回答了有关每个笔记的问题，评估他们的
了解后续行动和自我报告的信心。我们发现
增强与行动的显着增加相关
理解得分（选择增强为 0.63 $\pm$ 0.04，相比之下为 0.54
$\pm$ 0.02（对照），p=0.002。深度访谈
还通过视频对自我识别的乳腺癌患者（N=7）进行了调查
会议。增强，尤其是定义，引发了积极的影响
七名参与者的回应，其中对依赖
法学硕士。临床医生评估了增强的错误，我们发现
存在误导性错误，真实捐赠票据中的错误比真实捐赠票据中更常见
综合笔记，说明仔细书写临床的重要性
笔记。增强提高了一些但不是全部的可读性指标。这部作品
展示了法学硕士在改善患者体验方面的潜力
临床记录可以减轻临床医生的负担。然而，有一个人在
循环对于纠正潜在的模型错误非常重要。
]]></description>
      <guid>http://arxiv.org/abs/2401.09637</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>ClimateGPT：迈向人工智能综合气候变化跨学科研究。 （arXiv：2401.09646v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.09646</link>
      <description><![CDATA[本文介绍了 ClimateGPT，一个特定于领域的大型模型系列
综合气候变化跨学科研究的语言模型。
我们在 300B 的面向科学的数据集上从头开始训练了两个 7B 模型
代币。对于第一个模型，包含 4.2B 特定于域的令牌
在预训练期间，第二个在训练后适应气候领域
预训练。此外，ClimateGPT-7B、13B 和 70B 不断
在 Llama~2 的 4.2B 令牌的特定领域数据集上进行预训练。每个
模型是在高质量和人工生成的指令上进行微调的
与气候密切合作创建的特定领域数据集
科学家们。为了减少幻觉的数量，我们优化了模型
检索增强并提出分层检索策略。到
提高我们的模型对非英语使用者的可及性，我们建议
利用级联机器翻译并证明这种方法可以
性能与本地多语言模型相当，同时更容易扩展
到大量的语言。此外，为了解决内在的
气候变化的跨学科方面，我们考虑不同的研究
观点。因此，该模型可以产生专注于以下方面的深入答案：
除了总体答案之外，还有不同的观点。我们建议一套
自动针对特定气候的基准来评估法学硕士。在这些基准上，
ClimateGPT-7B 的性能与大十倍的 Llama-2-70B Chat 模型相当
同时不会降低一般领域基准测试的结果。我们的人类评价
证实了我们在基准测试中看到的趋势。所有模型均经过训练并
使用可再生能源进行评估并公开发布。
]]></description>
      <guid>http://arxiv.org/abs/2401.09646</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>将大型语言模型与反事实 DPO 结合起来。 （arXiv：2401.09566v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.09566</link>
      <description><![CDATA[大型语言模型 (LLM) 的进步已证明是显着的
跨各种应用程序的功能。这些模型擅长
生成上下文连贯并涵盖的文本完成
广泛的主题。然而，他们需要大量的数据集
培训使预培训和指导期间的反应风格保持一致
调整阶段具有挑战性。因此，额外的对齐阶段是
通常采用，其中模型根据人类偏好进行进一步训练
数据以更好地使其输出与人类期望保持一致。虽然这个过程
本身并没有引入新功能，它确实强调了生成风格
模型固有的。本文探讨了反事实的运用
在直接偏好优化 (DPO) 框架内提示进行调整
模型的风格无需依赖人工干预。我们证明
这种方法有效地灌输了理想的行为，减少了不良行为
，并鼓励模型忽略不适当的指令。我们的
研究结果表明，DPO 的反事实提示资源匮乏
微调法学硕士以满足负责任和道德一致的要求的方法
人工智能系统。
]]></description>
      <guid>http://arxiv.org/abs/2401.09566</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:28 GMT</pubDate>
    </item>
    <item>
      <title>学习捷径：论 NLU 在语言模型中的误导性承诺。 （arXiv：2401.09615v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.09615</link>
      <description><![CDATA[大型语言模型 (LLM) 的出现使得显着的
自然语言处理领域的性能提升。然而，最近
研究发现法学硕士在执行任务时经常采取捷径，
造成性能增强的错觉，同时缺乏普遍性
他们的决策规则。这种现象给精确定位带来了挑战
评估法学硕士的自然语言理解。我们的论文提供了一个简洁的
对该领域的相关研究进行了调查，并提出了自己的观点
快捷学习在语言模型评估中的影响，
专门用于 NLU 任务。本文呼吁加大研究力度
加深我们对快捷学习的理解，为
开发更强大的语言模型，提高 NLU 的标准
现实场景中的评估。
]]></description>
      <guid>http://arxiv.org/abs/2401.09615</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:28 GMT</pubDate>
    </item>
    <item>
      <title>BERTologyNavigator：使用基于 BERT 的语义进行高级问答。 （arXiv：2401.09553v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.09553</link>
      <description><![CDATA[知识图谱与语言模型的开发与融合
在人工智能和自然语言处理中具有重要意义。在
在这项研究中，我们介绍了 BERTologyNavigator——一个两阶段系统，
结合关系提取技术和 BERT 嵌入来导航
DBLP 知识图谱 (KG) 中的关系。我们的方法侧重于
在第一阶段提取单跳关系和标记候选对。
接下来是使用 BERT 的 CLS 嵌入和额外的启发式方法
用于第二阶段的关系选择。我们的系统达到了 F1 分数
Scholarly QALD 的 DBLP QuAD Final 测试数据集为 0.2175，F1 分数为 0.98
在 QA 阶段使用 DBLP QuAD 测试数据集的子集。
]]></description>
      <guid>http://arxiv.org/abs/2401.09553</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:27 GMT</pubDate>
    </item>
    <item>
      <title>通过人工反馈提高分类性能：标记一些，我们标记其余的。 （arXiv：2401.09555v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.09555</link>
      <description><![CDATA[在人工智能领域，绝大多数数据都是
非结构化，获取大量标记数据来训练监督
机器学习模型提出了重大挑战。为了解决这个问题，我们
深入研究小样本和主动学习，目标是改进人工智能模型
以及对一些标记示例的人类反馈。本文重点讨论
了解连续反馈循环如何完善模型，从而
通过增量人力提高准确性、召回率和精确度
输入。通过采用大型语言模型 (LLM)，例如 GPT-3.5、BERT 和
SetFit，我们的目标是分析使用有限数量的标记的效果
显着提高模型准确性的示例。我们对这种方法进行基准测试
Financial Phrasebank、Banking、Craigslist、Trec、Amazon Reviews 数据集
证明只需几个带标签的例子，我们就能够超越
零样本大语言模型的准确性以提供增强的文本
分类性能。我们证明不需要手动
标记数百万行数据，我们只需要标记几行，模型就可以
有效地预测其余的。
]]></description>
      <guid>http://arxiv.org/abs/2401.09555</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:27 GMT</pubDate>
    </item>
    <item>
      <title>Voila-A：使视觉语言模型与用户的注视注意力保持一致。 （arXiv：2401.09454v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.09454</link>
      <description><![CDATA[近年来，视觉与语言理解的融合引领了
人工智能的重大进步，特别是通过
视觉语言模型 (VLM)。然而，现有的 VLM 面临以下挑战：
处理具有复杂场景和多个对象的现实世界应用程序，例如
以及将他们的注意力与人类不同的注意力模式保持一致
用户。在本文中，我们介绍了可以通过 AR 收集的注视信息
或 VR 设备，作为人类注意力的代理来指导 VLM 并提出新颖的方案
方法，Voila-A，用于凝视对齐以增强可解释性和
这些模型在实际应用中的有效性。首先，我们收集
数百分钟的注视数据证明我们可以模仿人类注视
使用本地化叙事的方式。然后我们设计一个自动数据
使用 GPT-4 生成 VOILA-COCO 数据集的注释管道。
此外，我们创新了 Voila Perceiver 模块来集成凝视
将信息输入 VLM，同时保留其预先训练的知识。我们评估
Voila-A 使用保留验证集和新收集的 VOILA-GAZE
测试集，其中包含通过视线跟踪捕获的现实生活场景
设备。我们的实验结果表明，Voila-A 显着
优于几个基线模型。通过使模型注意力与人类注意力保持一致
Voila-A 为更直观、以用户为中心的 VLM 铺平了道路
促进跨广泛应用的人机交互。
]]></description>
      <guid>http://arxiv.org/abs/2401.09454</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:26 GMT</pubDate>
    </item>
    <item>
      <title>LoMA：无损压缩内存注意力。 （arXiv：2401.09486v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.09486</link>
      <description><![CDATA[处理长文本的能力是最重要的能力之一
大型语言模型（LLM），但随着文本长度的增加，消耗
资源也急剧增加。目前，减少资源
通过压缩KV缓存来消耗是一种常见的做法。虽然有
现有的压缩方法有很多，但它们都有一个共同的缺点：
压缩不是无损的。也就是说，信息在传输过程中不可避免地会丢失。
压缩过程。如果压缩率高，丢失的概率
重要信息急剧增加。我们提出了一种新方法，无损
压缩内存注意力（LoMA），允许无损压缩
根据设定的压缩将信息放入特殊的记忆令牌KV对中
比率。我们的实验取得了显着的成果，表明
LoMA可以被有效地训练并且具有非常有效的表现。
]]></description>
      <guid>http://arxiv.org/abs/2401.09486</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:26 GMT</pubDate>
    </item>
    <item>
      <title>RoleCraft-GLM：在大型语言模型中推进个性化角色扮演。 （arXiv：2401.09432v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.09432</link>
      <description><![CDATA[这项研究提出了 RoleCraft-GLM，这是一个旨在增强
使用大型语言模型 (LLM) 进行个性化角色扮演。角色工艺-GLM
解决了会话中缺乏个性化交互的关键问题
人工智能，并提供具有细节和情感微妙特征的解决方案
的描绘。我们贡献了一个独特的对话数据集，该数据集从
传统的以名人为中心的角色到多样化的非名人角色，
从而增强语言建模交互的真实性和复杂性。
此外，我们的方法包括细致的角色发展，确保
对话既现实又引起情感共鸣。的有效性
RoleCraft-GLM 通过各种案例研究得到验证，突出了其
不同场景下的多功能性和技能。我们的框架擅长于
生成准确反映人物性格特征的对话
情绪，从而提高用户参与度。总之，RoleCraft-GLM 标志着
个性化人工智能交互的重大飞跃，并为更多内容铺平道路
通过启用更多功能，提供真实且身临其境的人工智能辅助角色扮演体验
细致入微且情感丰富的对话
]]></description>
      <guid>http://arxiv.org/abs/2401.09432</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:25 GMT</pubDate>
    </item>
    <item>
      <title>孟加拉语模因的可解释多模态情感分析。 （arXiv：2401.09446v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.09446</link>
      <description><![CDATA[模因已成为一种独特且有效的沟通形式
数字时代，吸引在线社区并跨越文化
障碍。尽管模因经常与幽默联系在一起，但它们有一个
传达各种情感的惊人能力，包括幸福，
讽刺、沮丧等等。理解和解释情绪
潜在的模因在信息时代变得至关重要。以前的
研究探索了基于文本、基于图像和多模式的方法，
导致 CAPSAN 和 PromptHate 等模型的开发用于检测
各种模因类别。然而，对低资源语言的研究，例如
孟加拉语表情包仍然稀缺，公开可用的内容有限
数据集。最近的贡献包括引入 MemoSen
数据集。然而，所达到的精度明显较低，并且数据集受到影响
来自分配不平衡。在这项研究中，我们采用了多模式方法
使用ResNet50和BanglishBERT并取得了令人满意的结果0.71
加权 F1 分数，与单峰方法进行比较，以及
使用可解释的人工智能解释模型的行为
（XAI）技术。
]]></description>
      <guid>http://arxiv.org/abs/2401.09446</guid>
      <pubDate>Fri, 19 Jan 2024 03:15:25 GMT</pubDate>
    </item>
    </channel>
</rss>