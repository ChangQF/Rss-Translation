<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 07 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过主动探究赋予语言模型更深入的理解</title>
      <link>https://arxiv.org/abs/2402.03719</link>
      <description><![CDATA[大型语言模型 (LLM) 的兴起彻底改变了我们通过自然语言与人工智能系统交互的方式。然而，法学硕士经常因为用户的意图不确定而误解用户的查询，从而导致回复的帮助不大。在自然的人际互动中，通过有针对性的提问来寻求澄清，以发现晦涩的信息。因此，在本文中，我们介绍了 LaMAI（主动探究语言模型），旨在赋予法学硕士同样水平的互动参与。 LaMAI 利用主动学习技术提出信息最丰富的问题​​，促进动态的双向对话。这种方法不仅缩小了背景差距，而且还完善了法学硕士的输出，使其更符合用户的期望。我们的实证研究涵盖了法学硕士对话背景有限的各种复杂数据集，证明了 LaMAI 的有效性。该方法将答案准确率从 31.9% 提高到 50.9%，优于其他领先的问答框架。此外，在涉及人类参与者的场景中，LaMAI 在超过 82% 的情况下始终能够生成优于或与基线方法相当的响应。 LaMAI 与各种法学硕士的成功集成进一步证明了 LaMAI 的适用性，凸显了其在交互式语言模型未来的潜力。]]></description>
      <guid>https://arxiv.org/abs/2402.03719</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:32 GMT</pubDate>
    </item>
    <item>
      <title>基于情感增强图的对话讽刺解释</title>
      <link>https://arxiv.org/abs/2402.03658</link>
      <description><![CDATA[对话中的讽刺解释（SED）是一项新的但具有挑战性的任务，旨在为涉及多种模式（即话语、视频和音频）的给定讽刺对话生成自然语言解释。尽管现有的基于生成预训练语言模型 BART 的研究取得了巨大成功，但它们忽视了对话语、视频和音频中存在的情感的利用，而这些情感是讽刺解释的重要线索。事实上，由于三个主要挑战，纳入情绪来提高 SED 性能并非易事：1）话语标记对情绪的不同影响； 2）视音频情感信号与BART嵌入空间之间的差距； 3）话语、话语情感和视频音频情感之间的各种关系。为了应对这些挑战，我们提出了一种新颖的基于情感增强图的多模态讽刺解释框架，名为 EDGE。特别是，我们首先提出了一个词典引导的话语情感推理模块，其中设计了启发式话语情感细化策略。然后，我们通过扩展多模态情感分析模型 JCA 来开发一个名为基于联合交叉注意的情感推理（JCA-SI）的模块，以导出每个视频音频剪辑的联合情感标签。此后，我们设计了一个上下文情感图来全面建模话语、话语情感和视频音频情感之间的语义关系，以促进讽刺解释的生成。对公开发布的数据集 WITS 进行的大量实验验证了我们的模型相对于前沿方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2402.03658</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:31 GMT</pubDate>
    </item>
    <item>
      <title>作为间接推理机的大型语言模型：自动推理的反证和矛盾</title>
      <link>https://arxiv.org/abs/2402.03667</link>
      <description><![CDATA[最近，人们越来越关注提高大型语言模型（LLM）执行复杂推理的能力。然而，以前的方法，例如思想链和自洽性，主要遵循直接推理（DR）框架，因此它们在解决许多现实世界的任务时会遇到困难，而这些任务很难通过直接推理来解决。因此，为了增强法学硕士的推理能力，本文提出了一种新颖的间接推理（IR）方法，利用反证和矛盾的逻辑来处理事实推理和数学证明等IR任务。具体来说，我们的方法包括两个步骤。首先，我们利用反证的逻辑等价来扩充数据和规则，以增强法学硕士的可理解性。其次，我们设计了一套提示模板来触发LLM进行基于反证法的IR，逻辑上与原始DR过程等效。我们的 IR 方法简单而有效，可以直接与现有的 DR 方法集成，以进一步提高法学硕士的推理能力。在流行的LLM（例如GPT-3.5-turbo和Gemini-pro）上的实验结果表明，与传统的DR方法相比，我们的IR方法将事实推理的整体准确性提高了27.33％，数学证明的整体准确性提高了31.43％。此外，结合 IR 和 DR 的方法显着优于单独使用 IR 或 DR 的方法，进一步证明了我们策略的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.03667</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:31 GMT</pubDate>
    </item>
    <item>
      <title>思维与机器：重新思考语言模型的蕴涵验证</title>
      <link>https://arxiv.org/abs/2402.03686</link>
      <description><![CDATA[人类在文本理解中做出大量推理来理解话语。本文旨在了解人类和最先进的大型语言模型（LLM）之间推理判断的共性和差异。利用全面策划的蕴含验证基准，我们评估人类和法学硕士在各种推理类别中的表现。我们的基准包括来自三个类别（NLI、上下文 QA 和基本原理）的数据集，其中包括多句子前提和不同的知识类型，从而评估复杂推理实例中的推理能力。值得注意的是，我们的研究结果揭示了法学硕士在跨扩展上下文的多跳推理方面的优势，而人类则擅长需要简单演绎推理的任务。利用这些见解，我们引入了经过微调的 Flan-T5 模型，该模型的性能优于 GPT-3.5，可与 GPT-4 相媲美，为蕴涵验证提供强大的开源解决方案。作为一个实际应用，我们展示了经过微调的模型在增强模型生成的解释的自我一致性方面的功效，从而使三个多项选择问答数据集的性能平均提高了 6%。]]></description>
      <guid>https://arxiv.org/abs/2402.03686</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:31 GMT</pubDate>
    </item>
    <item>
      <title>视觉语言模型鲁棒性的部分重新集中 Softmax 损失</title>
      <link>https://arxiv.org/abs/2402.03627</link>
      <description><![CDATA[随着大型语言模型在自然语言处理任务（NLP）中取得突破，多模态技术变得非常流行。然而，事实证明，多模态 NLP 很容易受到对抗性攻击，其中模型的输出可能会因输入的扰动而发生巨大变化。虽然计算机视觉和 NLP 模型中已经提出了几种防御技术，但模型的多模态鲁棒性尚未得到充分探索。在本文中，我们通过限制前 K 个 softmax 输出来研究通过修改预训练多模态模型的损失函数来提供的对抗鲁棒性。基于评估和评分，我们的实验表明，经过微调后，预训练模型的对抗鲁棒性可以显着提高，以对抗流行的攻击。还需要进一步研究，例如此类损失函数的输出多样性、泛化性以及鲁棒性与性能的权衡。我们的代码将在本文被接受后可用]]></description>
      <guid>https://arxiv.org/abs/2402.03627</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:30 GMT</pubDate>
    </item>
    <item>
      <title>专业代理——将大型语言模型进化为具有人类水平能力的自主专家</title>
      <link>https://arxiv.org/abs/2402.03628</link>
      <description><![CDATA[ChatGPT、PaLM 和 GPT-4 等大型语言模型 (LLM) 的出现促进了自然语言处理领域的显着进步，展示了类似人类的语言流利度和推理能力。本立场文件介绍了专业代理 (PAgents) 的概念，这是一个利用 LLM 功能来创建具有可控、专业、交互式和专业级能力的自主代理的应用程序框架。我们认为 PAgents 可以通过不断发展的专业知识重塑专业服务。我们提出的 PAgents 框架需要一个用于起源、进化和协同的三层架构：基础工具层、中间代理层和顶层协同层。本文旨在激发人们对法学硕士在现实世界中的应用前景的讨论。我们认为，PAgent 的日益复杂和集成可能会导致人工智能系统展现出对复杂领域的专业掌握，满足关键需求，并有可能实现通用人工智能。]]></description>
      <guid>https://arxiv.org/abs/2402.03628</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:30 GMT</pubDate>
    </item>
    <item>
      <title>Stanceosaurus 2.0：对俄罗斯和西班牙错误信息的立场进行分类</title>
      <link>https://arxiv.org/abs/2402.03642</link>
      <description><![CDATA[Stanceosaurus 语料库（Zheng et al., 2022）旨在提供从 Twitter 中提取的高质量、带注释的 5 向立场数据，适合分析跨文化和跨语言的错误信息。在 Stanceosaurus 2.0 迭代中，我们扩展了这个框架以涵盖俄语和西班牙语。由于与西方的紧张局势升级以及对乌克兰的暴力入侵，错误信息普遍存在，因此前者具有当前的意义。与此同时，后者代表了一个在主要社交媒体平台上很大程度上被忽视的巨大社区。通过在 41 个错误信息声明中纳入另外 3,874 条西班牙和俄罗斯推文，我们的目标是支持针对这些问题的研究。为了证明这些数据的价值，我们在多语言 BERT 上采用了零样本跨语言迁移，得到的结果与最初的 Stanceosaurus 研究相当，两种语言的宏观 F1 分数均为 43。这强调了立场分类作为识别多元文化错误信息的有效工具的可行性。]]></description>
      <guid>https://arxiv.org/abs/2402.03642</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:30 GMT</pubDate>
    </item>
    <item>
      <title>解决西班牙语转录歧义：用于标点符号恢复的混合声学词汇系统</title>
      <link>https://arxiv.org/abs/2402.03519</link>
      <description><![CDATA[标点符号恢复是自动语音识别 (ASR) 系统之后的关键步骤，可增强转录本的可读性并促进后续的 NLP 任务。然而，传统的基于词汇的方法不足以解决西班牙语中的标点符号恢复任务，因为在西班牙语中，不加标点的陈述语和疑问句之间经常存在歧义。在这项研究中，我们提出了一种用于西班牙语转录的新型混合声学-词汇标点符号恢复系统，该系统通过模块化过程整合声学和词汇信号。我们的实验结果表明，所提出的系统可以有效提高公共和内部西班牙语会话数据集上问号的 F1 分数和整体标点符号恢复。此外，与 LLM（大型语言模型）的基准比较表明了我们的方法在准确性、可靠性和延迟方面的优越性。此外，我们还证明了 ASR 模块的字错误率 (WER) 也受益于我们提出的系统。]]></description>
      <guid>https://arxiv.org/abs/2402.03519</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:29 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型从现实世界数据中确定避孕转换的原因</title>
      <link>https://arxiv.org/abs/2402.03597</link>
      <description><![CDATA[处方避孕药在支持妇女生殖健康方面发挥着关键作用。美国有近 5000 万女性使用避孕药具，了解推动避孕药具选择和更换的因素具有重要意义。然而，与药物转换相关的许多因素通常只能在非结构化的临床记录中捕获，并且很难提取。在这里，我们评估了最近开发的大型语言模型 GPT-4（通过符合 HIPAA 的 Microsoft Azure API）的零样本能力，以从 UCSF 信息共享临床记录数据集中确定避孕药具类别之间切换的原因。我们证明，GPT-4 可以准确地提取避孕药更换的原因，优于基于 BERT 的基线模型，避孕开始和停止提取的 microF1 分数分别为 0.849 和 0.881。对 GPT-4 提取的转换原因的人类评估显示出 91.4% 的准确度，且幻觉极少。通过提取的原因，我们确定患者偏好、不良事件和保险是改用无监督主题建模方法的关键原因。值得注意的是，我们还使用我们的方法表明，“体重增加/情绪变化”和“保险覆盖范围”被不成比例地视为特定人口群体中避孕药具转换的原因。我们的代码和补充数据可在 https://github.com/BMiao10/contraceptive-switching 上获取。]]></description>
      <guid>https://arxiv.org/abs/2402.03597</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:29 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型实现混合工作场所决策支持</title>
      <link>https://arxiv.org/abs/2402.03616</link>
      <description><![CDATA[大型语言模型 (LLM) 具有执行各种文本处理任务并为提议的操作或决策提供文本解释的潜力。在混合工作时代，法学硕士可以为正在设计混合工作计划的员工提供智能决策支持。特别是，他们可以为工人提供平衡众多决策因素的建议和解释，从而增强他们的工作经验。在本文中，我们利用法学硕士的推理技能，提出了混合工作环境中工作空间的决策支持模型。我们首先考察LLM提出合适工作空间建议的能力。我们发现它的推理超出了提示中的指导方针，法学硕士可以管理工作空间中可用资源之间的权衡。我们进行了广泛的用户研究，以了解员工选择工作空间的决策过程并评估系统的有效性。我们观察到，工人的决定可能会受到法学硕士的建议和解释的影响。我们研究的参与者发现该系统很方便，无论是否提供理由。我们的结果表明，员工可以从法学硕士授权的系统中受益，以选择混合工作场所的工作空间。]]></description>
      <guid>https://arxiv.org/abs/2402.03616</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:29 GMT</pubDate>
    </item>
    <item>
      <title>基于 BERT 的阿拉伯语同义词文本分类对抗示例</title>
      <link>https://arxiv.org/abs/2402.03477</link>
      <description><![CDATA[文本分类系统已被证明容易受到对抗性文本示例的影响，原始文本示例的修改版本通常不会被人眼注意到，但可以迫使文本分类模型改变其分类。通常，量化对抗性文本攻击影响的研究工作仅适用于用英语训练的模型。在本文中，我们介绍了阿拉伯语对抗性攻击的第一个单词级研究。具体来说，我们在黑盒设置中使用带有 BERT 模型的掩码语言建模 (MLM) 任务进行同义词（词级）攻击，以评估最先进的文本分类模型对对抗性攻击的鲁棒性阿拉伯语。为了使用基于同义词 BERT 的攻击来评估新生成的对抗性示例的语法和语义相似性，我们邀请了四位人类评估者来评估和比较生成的对抗性示例与其原始示例。我们还研究了这些新生成的阿拉伯语对抗性示例到各种模型的可迁移性，并研究了 BERT 模型上针对这些对抗性示例的防御机制的有效性。我们发现，经过微调的 BERT 模型比我们训练的其他深度神经网络 (DNN) 模型（例如 WordCNN 和 WordLSTM）更容易受到同义词攻击。我们还发现，经过微调的 BERT 模型更容易受到转移攻击。最后，我们发现，在应用对抗性训练作为初始防御机制后，经过微调的 BERT 模型成功地恢复了至少 2% 的准确率。]]></description>
      <guid>https://arxiv.org/abs/2402.03477</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:28 GMT</pubDate>
    </item>
    <item>
      <title>SWAG：讲故事与行动指导</title>
      <link>https://arxiv.org/abs/2402.03483</link>
      <description><![CDATA[自动长篇故事生成通常采用长上下文大语言模型 (LLM) 进行一次性创作，这可以生成有凝聚力但不一定引人入胜的内容。我们引入行动指导讲故事（SWAG），这是一种与法学硕士一起讲故事的新颖方法。我们的方法通过两个模型反馈循环将故事写作简化为搜索问题：一个LLM生成故事内容，另一个辅助LLM用于选择下一个最佳“行动”来引导故事的未来方向。我们的结果表明，当通过 GPT-4 和人工评估进行评估时，SWAG 可以大大优于以前的端到端故事生成技术，并且我们仅使用开源模型的 SWAG 管道超越了 GPT-3.5-Turbo。]]></description>
      <guid>https://arxiv.org/abs/2402.03483</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:28 GMT</pubDate>
    </item>
    <item>
      <title>评估不同领域的零样本摘要器的真实性</title>
      <link>https://arxiv.org/abs/2402.03509</link>
      <description><![CDATA[最近的工作表明，大型语言模型（LLM）能够生成零样本（即没有明确监督）的摘要，在人工评估下，这些摘要通常与手动撰写的参考摘要相当甚至更受欢迎。然而，这项先前的工作几乎完全集中于评估新闻文章摘要。零样本摘要器在其他（可能更专业的）领域表现如何？在这项工作中，我们评估了跨专业领域的零样本生成的摘要，包括生物医学文章和法律法案（以及供参考的标准新闻基准）。我们特别关注产出的真实性。我们从领域专家那里获取注释，以识别摘要中的不一致之处，并对这些错误进行系统分类。我们分析预训练语料库中给定领域的流行是否影响该领域文章生成摘要的提取性和忠实度。我们发布所有收集的注释，以促进更多研究，以衡量和实现除新闻文章之外的事实准确的摘要。该数据集可以从 https://github.com/sanjanaramprasad/zero_shot_faceval_domains 下载]]></description>
      <guid>https://arxiv.org/abs/2402.03509</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:28 GMT</pubDate>
    </item>
    <item>
      <title>语义交流与知识学习的相互作用</title>
      <link>https://arxiv.org/abs/2402.03339</link>
      <description><![CDATA[在快速发展的通信技术领域，强调知识理解和处理的语义通信（SemCom）已成为一个热门话题。通过整合人工智能技术，SemCom 促进了对通信内容的深刻理解、分析和传输。在本章中，我们阐明了 SemCom 中知识学习的方法，特别关注知识图谱 (KG) 的利用。具体来说，我们首先回顾将 SemCom 与知识学习相结合的现有努力。随后，我们引入了 KG 增强型 SemCom 系统，其中接收器经过仔细校准，以利用其静态知识库中的知识来改善解码性能。根据这个框架，我们进一步探索潜在的方法，使系统能够更有效地在不断发展的知识库中运行。此外，我们还研究了与大型语言模型 (LLM) 集成以进行数据增强的可能性，为 SemCom 的潜在实现方式提供了额外的视角。大量的数值结果表明，所提出的框架在 KG 增强解码的基础上产生了优越的性能，并体现了其在不同场景下的多功能性。]]></description>
      <guid>https://arxiv.org/abs/2402.03339</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:27 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行心理评估：一种注重隐私且具有成本效益的方法</title>
      <link>https://arxiv.org/abs/2402.03435</link>
      <description><![CDATA[本研究探索使用大型语言模型（LLM）来分析 Reddit 用户的文本评论，旨在实现两个主要目标：首先，查明支持自杀风险预定义心理评估的关键摘录；其次，总结材料以证实预设的自杀风险水平。这项工作仅限于使用可以在本地运行的“开源”法学硕士，从而增强数据隐私。此外，它优先考虑计算要求低的模型，使计算预算有限的个人和机构都可以使用它。实施的策略仅依赖于精心设计的提示和语法来指导法学硕士的文本完成。尽管它很简单，但评估指标显示出出色的结果，使其成为一种有价值的注重隐私且具有成本效益的方法。这项工作是计算语言学和临床心理学 (CLPsych) 2024 共享任务的一部分。]]></description>
      <guid>https://arxiv.org/abs/2402.03435</guid>
      <pubDate>Thu, 08 Feb 2024 00:56:27 GMT</pubDate>
    </item>
    </channel>
</rss>