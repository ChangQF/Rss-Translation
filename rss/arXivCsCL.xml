<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Fri, 22 Dec 2023 03:14:40 GMT</lastBuildDate>
    <item>
      <title>人机交互中基于属性的对象引用的组合零样本学习。 （arXiv：2312.13655v1 [cs.RO]）</title>
      <link>http://arxiv.org/abs/2312.13655</link>
      <description><![CDATA[过去几年，支持语言的机器人已被广泛研究
在各种现实世界中实现自然的人机交互和团队合作
应用程序。支持语言的机器人必须能够理解指称
使用一组表达式从视觉感知中识别特定对象
从自然语言中提取的引用属性。然而，视觉
当一个对象被引用时，对该对象的观察可能不可用，并且
在开放世界中，对象和属性的数量也可能是无限的。到
为了解决这些挑战，我们实现了基于属性的组合零样本
使用属性列表进行指代表达的学习方法
开放世界中的理解。我们在两个数据集上评估该方法
包括 MIT-States 和 Clothing 16K。初步实验
结果表明，我们实施的方法可以让机器人正确识别
人类命令所引用的对象。
]]></description>
      <guid>http://arxiv.org/abs/2312.13655</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:39 GMT</pubDate>
    </item>
    <item>
      <title>Text2Analysis：具有高级数据分析和不明确查询的表格问答基准。 （arXiv：2312.13671v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.13671</link>
      <description><![CDATA[表格数据分析在各个领域都至关重要，大型语言模型
在这一领域表现出希望。然而，目前的研究主要集中在
像 Text2SQL 和 TableQA 这样的基本任务，忽略了像
预测和图表生成。为了解决这一差距，我们开发了
Text2Analysis 基准测试，包含超出范围的高级分析任务
SQL兼容的操作，需要更深入的分析。我们也
开发五种创新且有效的注释方法，利用
大型语言模型提高数据质量和数量的能力。
此外，我们还包括类似于真实世界用户的不清楚查询
测试模型如何理解和应对这些挑战的问题。
最后，我们收集了 347 个表的 2249 个查询结果对。我们评价五
使用三种不同指标的最先进模型，结果表明
我们的基准提出了该领域的相当大的挑战
表格数据分析，为更高级的研究机会铺平道路。
]]></description>
      <guid>http://arxiv.org/abs/2312.13671</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:39 GMT</pubDate>
    </item>
    <item>
      <title>神经有限状态传感器的结构感知路径推理。 （arXiv：2312.13614v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.13614</link>
      <description><![CDATA[神经有限状态传感器 (NFST) 形成了一个富有表现力的家族
神经符号序列转导模型。 NFST 将每个字符串对建模为
由有限状态换能器中的潜在路径生成。像他们
是深度生成模型，NFST 的训练和推理都需要
近似此类潜在后验分布的推理网络
变量。在本文中，我们重点关注由此产生的挑战
解释给定的输入和输出字符串对的潜在对齐路径
（例如，在训练期间）。我们训练三个自回归近似模型
路径的摊销推理，然后可以用作提案
重要性抽样的分布。所有三个模型都执行前瞻。我们的
最复杂（且新颖）的模型利用 FST 结构来考虑
未来路径图；不幸的是，我们发现它输给了
更简单的方法——除了我们编造的用来混淆视听的人为任务
更简单的方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.13614</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>在 VQA 中使用多级对比学习实现更忠实的自然语言解释。 （arXiv：2312.13594v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.13594</link>
      <description><![CDATA[视觉问答中的自然语言解释（VQA-NLE）旨在
通过生成自然语言来解释模型的决策过程
句子来增加用户对黑匣子系统的信任。现有事后
方法在获得合理的
解释。然而，这种事后解释并不总是与
人类的逻辑推理，面临以下问题：1）演绎
不可满足性，生成的解释在逻辑上不会导致
回答; 2）事实不一致，模型伪造了其反事实
对答案的解释，不考虑图像中的事实；和 3)
语义扰动不敏感，模型无法识别语义
由微小的扰动引起的变化。这些问题降低了忠诚度
由模型生成的解释。针对上述问题，我们提出一个
小说自监督 \textbf{M}多层次 \textbf{C}对比
\textbf{L}基于自然语言的收入 \textbf{E}xplanation 模型（MCLE）
VQA 具有语义级、图像级和实例级事实和
反事实样本。 MCLE 提取判别特征并对齐
通过视觉问题和答案的解释来生成特征空间
更一致的解释。我们进行广泛的实验，消融
分析和案例研究来证明我们的方法在两个方面的有效性
VQA-NLE 基准。
]]></description>
      <guid>http://arxiv.org/abs/2312.13594</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>简洁地与我争论：走向句子级反驳生成。 （arXiv：2312.13608v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.13608</link>
      <description><![CDATA[反论点生成——计算领域的一个迷人领域
语言学——寻求提出相反观点的陈述。虽然大多数
研究已涉足段落级生成、句子级
反论点的产生以其独特的限制和
注重简洁的挑战。此外，性质的多样性
反驳对单独评估模型性能提出了挑战
基于基于 n-gram 的指标。在本文中，我们提出了 ArgTersely
句子级反驳生成的基准，借鉴于
来自 ChangeMyView 辩论论坛的手动注释数据集。我们还建议
Arg-LlaMA 用于生成高质量的反驳。为了更好的评价，
我们用人类偏好数据训练了一个基于 BERT 的评估器 Arg-Judge。我们
进行了涉及各种基线的比较实验，例如 LlaMA，
羊驼毛、GPT-3 等。结果显示了我们提出的竞争力
反论点生成任务中的框架和评估器。代码和数据是
可以在 https://github.com/amazingljy1206/ArgTersely 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.13608</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>真相就在那里：通过层选择性降级改进语言模型的推理。 （arXiv：2312.13558v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.13558</link>
      <description><![CDATA[基于 Transformer 的大型语言模型 (LLM) 已成为
现代机器学习。相应地，大量资源被分配
旨在进一步推进这项技术的研究，通常
导致模型尺寸不断增大，并接受越来越多的训练量
数据的。然而，这项工作展示了令人惊讶的结果：
通常可以通过选择性地显着提高法学硕士的表现
删除其权重矩阵的高阶分量。这个简单的
可以进行干预，我们称之为层选择等级降低（LASER）
在训练完成后的模型上，不需要额外的参数
或数据。我们展示了广泛的实验来证明这一点的普遍性
跨语言模型和数据集进行查找，并提供深入分析
提供有关激光何时有效以及其机制的见解
它运作。
]]></description>
      <guid>http://arxiv.org/abs/2312.13558</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行语音翻译：工业实践。 （arXiv：2312.13585v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.13585</link>
      <description><![CDATA[鉴于大型语言模型 (LLM) 在各种任务中取得的巨大成功，
在本文中，我们介绍了 LLM-ST，一种新颖且有效的语音翻译
基于预先训练的法学硕士构建的模型。通过整合大语言
具有语音编码器并采用多任务指令调整的模型（LLM），
LLM-ST 可以生成准确的带时间戳的转录和翻译，甚至
来自长音频输入。此外，我们的研究结果表明
实施思想链（CoT）提示可以在以下方面产生优势：
LLM-ST 的背景。通过英文和中文的严格实验
数据集，我们展示了 LLM-ST 的卓越性能，建立了一个新的
语音翻译领域的标杆。演示：
https://speechtranslation.github.io/llm-st/。
]]></description>
      <guid>http://arxiv.org/abs/2312.13585</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>开发互动旅游规划：大语言模式驱动的对话机器人系统。 （arXiv：2312.13545v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.13545</link>
      <description><![CDATA[近年来，大型语言模型 (LLM) 迅速激增，
已被用于各种任务，包括对话系统的研究。我们
旨在构建一个不仅利用灵活的对话方式的系统
法学硕士的能力，以及他们的先进规划能力，以减少
减轻人类对话者的说话负担并有效地计划旅行。此外，
我们提出了一种方法，将旅行社的复杂任务分为
多个子任务，将每个子任务作为一个单独的阶段进行管理以有效完成
任务。我们提出的系统通过实现以下目标证实了一定程度的成功
2023年对话机器人大赛预赛第四名。我们
报告通过竞赛发现的挑战。
]]></description>
      <guid>http://arxiv.org/abs/2312.13545</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>如何修剪您的语言模型：恢复“稀疏性可能会哭泣”基准的准确性。（arXiv：2312.13547v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.13547</link>
      <description><![CDATA[从 BERT 家族中修剪大型语言模型 (LLM) 已成为一种
标准压缩基准，并提出了几种修剪方法
为了这个任务。最近投入使用的“稀疏性可能会哭泣”（SMC）基准
质疑所有现有方法的有效性，展示更复杂的设置
许多已知的修剪方法似乎都失败了。我们重新审视这个问题
在下游数据集微调期间进行准确的 BERT 剪枝，并提出
一套成功修剪的一般准则，即使是在具有挑战性的 SMC 上
基准。首先，我们对剪枝模型进行成本与收益分析
组件，例如嵌入和分类头；第二，我们
提供一种简单而通用的方法来扩展训练、稀疏化和
相对于所需目标稀疏度的学习率计划；最后，我们
研究适当参数化对知识蒸馏的重要性
在法学硕士的背景下。我们简单的见解带来最先进的结果，
在经典的 BERT 剪枝基准和 SMC 基准上，
表明即使是经典的渐进剪枝（GMP）也能产生有竞争力的结果
结果，用正确的方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.13547</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>用于少镜头意图分类和槽填充的解耦表示和知识。 （arXiv：2312.13495v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.13495</link>
      <description><![CDATA[少镜头意图分类和槽位填充很重要但具有挑战性
由于缺乏精细标记的数据而导致的任务。因此，目前的工作
首先在具有充分标记数据的源域上训练模型，然后
将模型转移到目标域，其中只有很少标记的数据
可用的。然而，作为一个整体的经验转移通常会受到以下问题的影响：
源域和目标域之间存在差距。例如，
转移特定领域知识相关的经验很困难。到
为了解决这个问题，我们提出了一种新方法，可以显式地解耦
一般语义表示相关经验的迁移和
特定领域知识相关的经验。具体来说，对于
特定领域知识相关的经验，我们设计了两个模块来捕获
分别是意图-时隙关系和时隙-时隙关系。广泛的实验
在 Snips 和 FewJoint 数据集上的测试表明我们的方法达到了最先进的水平
表现。该方法将联合精度指标从 27.72% 提高到
1 次拍摄设置中为 42.20%，5 次拍摄设置中从 46.54% 升至 60.79%。
]]></description>
      <guid>http://arxiv.org/abs/2312.13495</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:34 GMT</pubDate>
    </item>
    <item>
      <title>门诊部的自动临床编码。 （arXiv：2312.13533v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.13533</link>
      <description><![CDATA[计算机化临床编码方法旨在实现自动化流程
为医疗记录分配一组代码。虽然有积极的研究
推动住院患者临床编码的最先进技术，
门诊环境——医生照顾非住院患者的地方——是
被忽视了。尽管这两种设置都可以形式化为多标签
分类任务，它们提出了独特且独特的挑战，这提出了
住院临床编码方法是否成功的问题
转化为门诊环境。本文首次探讨了
最先进的基于深度学习的临床编码方法的效果如何
在医院规模的门诊环境中。为此，我们收集了大量
门诊数据集包含超过 700 万条记录，记录了超过一半的记录
百万患者。我们采用四种最先进的临床编码方法来
这种设置并评估他们协助编码人员的潜力。我们找到证据
门诊环境中的临床编码可以从更多创新中受益
在流行的住院编码基准中。更深入的因素分析
促成成功——数据的数量和形式以及文件的选择
表示——揭示了容易解决的例子的存在，编码
它可以完全自动化且错误率低。
]]></description>
      <guid>http://arxiv.org/abs/2312.13533</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:34 GMT</pubDate>
    </item>
    <item>
      <title>VADIS——变量检测、互连和总结系统。 （arXiv：2312.13423v1 [cs.DL]）</title>
      <link>http://arxiv.org/abs/2312.13423</link>
      <description><![CDATA[VADIS 系统满足提供增强信息的需求
进入社会科学领域。这是通过允许用户实现的
在基础研究数据的背景下搜索和使用调查变量
以及相互关联的学术出版物。
]]></description>
      <guid>http://arxiv.org/abs/2312.13423</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>用于跨简单、复杂和多对象注释任务聚合注释的通用模型。 （arXiv：2312.13437v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.13437</link>
      <description><![CDATA[人工注释对于监督学习至关重要，但注释者通常
对于正确的标签存在分歧，尤其是随着注释任务的增加
复杂。提高标签质量的策略是询问多个注释者
标记相同的项目并聚合它们的标签。许多聚合模型都有
被提议用于分类或数值注释任务，但工作量要少得多
考虑了涉及开放式的更复杂的注释任务，
多变量或结构化响应。虽然各种定制型号都有
针对具体任务提出，我们的工作首先介绍
概括许多不同的复杂任务的聚合方法，
包括序列标记、翻译、句法分析、排序、边界
框和关键点。这种通用性是通过设计一个与任务无关的方法来实现的
方法对标签之间的距离而不是标签本身进行建模。

本文通过对三项新研究的调查扩展了我们之前的工作
问题。一、复杂注释属性如何影响聚合
准确性？其次，任务负责人应该如何在众多建模选择中导航
最大化聚合精度？最后，什么诊断可以证实这一点
对于给定的数据是否正确指定了聚合模型？要了解
各种因素如何影响准确性并为模型选择提供信息，我们进行
对真实、复杂的数据集进行模拟研究和实验。关于
测试，我们引入了聚合模型的单元测试，并提出了一套
此类测试可确保给定模型没有错误指定并展示
预期的行为。

除了调查上述这些研究问题之外，我们还讨论了
注释复杂性的基本概念，提出一种新的聚合模型
作为传统模型和我们自己的模型之间的桥梁，并贡献新的
性能优于复杂标签聚合的半监督学习方法
之前的工作。
]]></description>
      <guid>http://arxiv.org/abs/2312.13437</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>DSPy 断言：自精炼语言模型管道的计算约束。 （arXiv：2312.13382v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.13382</link>
      <description><![CDATA[将语言模型 (LM) 调用链接为可组合模块正在推动一种新的
强大的编程方式。然而，确保 LM 遵守重要的
制约因素仍然是一个关键挑战，通常通过启发式的“迅速”解决
工程”。我们引入了 LM 断言，这是一种新的编程结构
表达 LM 应满足的计算约束。我们整合我们的
构建到最新的 LM DSPy 编程模型中，并提出了新的
允许 DSPy 编译具有任意 LM 断言的程序的策略
变成更可靠、更准确的系统。在 DSPy 中，LM 断言
可以在编译时通过自动提示优化和/或在
推理时间，通过自动自我细化和回溯。我们报道两个
复杂问题回答 (QA) 的早期案例研究，其中 LM 程序
必须迭代地检索多跳信息并合成
带有引文的长篇答案。我们发现 LM 断言不仅提高了
遵守强加的规则和准则，同时也加强下游任务
性能，带来高达 35.7% 和 13.3% 的内在和外在收益，
分别。我们的 LM Assertions 参考实现已集成到
DSPy：https://github.com/stanfordnlp/dspy
]]></description>
      <guid>http://arxiv.org/abs/2312.13382</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:32 GMT</pubDate>
    </item>
    <item>
      <title>时间被编码在微调语言模型的权重中。 （arXiv：2312.13401v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.13401</link>
      <description><![CDATA[我们推出了时间向量，这是一个将语言模型定制为新语言的简单工具。
时间段。时间向量是通过微调数据的语言模型来创建的
从单个时间（例如，一年或一个月）开始，然后减去
原始的预训练模型。该向量指定权重方向
正如我们的实验所示，该空间可以提高文本的性能
时间段。专门针对相邻时间段的时间向量似乎是
在歧管中更靠近地放置。使用这个结构，我们插值
在时间向量之间引入在干预方面表现更好的新模型
以及未来的时间段，无需任何额外的培训。我们展示了
我们的研究结果在不同任务、领域、模型大小和
时间尺度。我们的结果表明时间被编码在权重空间中
微调模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.13401</guid>
      <pubDate>Fri, 22 Dec 2023 03:14:32 GMT</pubDate>
    </item>
    </channel>
</rss>