<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Mon, 25 Dec 2023 03:14:58 GMT</lastBuildDate>
    <item>
      <title>利用新颖的 GPT-4 API。 （arXiv：2312.14302v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.14302</link>
      <description><![CDATA[语言模型攻击通常采用两种极端威胁模型之一：
对模型权重的完全白盒访问，或仅限于文本的黑盒访问
生成API。然而，现实世界的 API 通常比文本更灵活
一代：这些 API 暴露了“灰盒”访问，导致新的威胁
向量。为了探索这一点，我们对在
GPT-4 API：微调、函数调用和知识检索。我们发现
对模型进行微调，只需 15 个有害示例或 100 个良性示例即可
删除 GPT-4 的核心保护措施，从而实现一系列有害输出。
此外，我们发现 GPT-4 助手很容易泄露函数调用
架构并可以执行任意函数调用。最后，我们发现
知识检索可以通过注入指令来劫持
检索文档。这些漏洞凸显了对
API 公开的功能可能会产生新的漏洞。
]]></description>
      <guid>http://arxiv.org/abs/2312.14302</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>参数高效调整允许法学硕士文本输入的可扩展个性化：缩写扩展的案例研究。 （arXiv：2312.14327v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14327</link>
      <description><![CDATA[缩写扩展是一种用于加速沟通的策略
限制输入量并使用语言模型来建议扩展。
在这里，我们研究基于个性化大型语言模型（LLM）的建议
之前的对话，以增强预测的相关性，特别是
当用户数据较小时（~1000 个样本）。具体来说，我们比较
微调、提示调整和检索增强了扩展文本的生成
关于缩写输入的建议。我们的案例研究采用了已部署的 8B 参数
对患有 ALS 的真实用户进行法学硕士研究，并对电影角色进行实验
个性化表明（1）在某些方面可能需要定制
场景和提示调整很好地概括了这些，（2）微调
然而，域内数据（只有 600 个样本）仍然显示出一些收益 (3)
检索增强的小样本选择也优于微调。 (4)
参数高效调整可实现高效且可扩展的个性化。
对于提示调整，我们还发现将学习到的“软提示”初始化为
用户相关概念标记比随机标记具有更高的准确性
初始化。
]]></description>
      <guid>http://arxiv.org/abs/2312.14327</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>根据开发者论坛帖子的意图对帖子进行特征描述和分类。 （arXiv：2312.14279v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2312.14279</link>
      <description><![CDATA[随着开发者社区的快速增长，帖子数量不断增加
在线技术论坛的快速增长给技术论坛带来了困难
用户过滤有用的帖子并查找重要信息。标签提供了
简洁的功能维度，方便用户定位自己感兴趣的帖子
搜索引擎根据查询索引最相关的帖子。
然而，大多数标签只关注技术角度（例如，程序
语言、平台、工具）。在大多数情况下，在线开发者中的论坛帖子
社区揭示了作者解决问题的意图、寻求建议、
共享信息等。对帖子意图的建模可以提供
当前标签分类的额外维度。通过参考以前的研究
并从行业角度学习，我们为
技术论坛帖子的意图。通过手动标记和分析
从在线论坛中提取的样本帖子数据集，我们了解相关性
帖子的构成（代码、错误消息）与其意图之间。
此外，受我们手动研究的启发，我们设计了一个预训练的
基于变压器的模型自动预测帖子意图。最好的
我们的意图预测框架的变体，实现了 Micro F1 分数
为 0.589，Top 1-3 准确率为 62.6% 至 87.8%，平均 AUC 为 0.787，
优于最先进的基线方法。我们的特征和
根据论坛帖子的意图自动分类可能会有所帮助
论坛维护者或第三方工具开发人员改进组织和
检索技术论坛上的帖子。我们已经发布了带注释的数据集
以及我们的补充材料包中的代码。
]]></description>
      <guid>http://arxiv.org/abs/2312.14279</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>在 NASA SciX 中试验大型语言模型和向量嵌入。 （arXiv：2312.14211v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14211</link>
      <description><![CDATA[开源大型语言模型支持 NASA SciX 等项目（即
NASA ADS）跳出框框思考并尝试其他方法
信息检索和数据增强，同时尊重数据版权
和用户的隐私。但是，当大型语言模型直接提示时
对于没有任何背景的问题，他们很容易产生幻觉。在美国宇航局
SciX 我们开发了一个实验，为我们的模型创建语义向量
大量摘要和全文内容，我们设计了一个提示
系统使用我们系统中的上下文块来提问。基于一个
非系统的人类评估，实验显示较低程度的
使用检索增强生成时产生幻觉和更好的反应。
需要进一步探索来设计新功能和数据增强
NASA SciX 的流程充分利用了这项技术，同时尊重高标准
项目所拥有的信任和质量水平。
]]></description>
      <guid>http://arxiv.org/abs/2312.14211</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>SimLM：语言模型可以推断物理系统的参数吗？ （arXiv：2312.14215v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14215</link>
      <description><![CDATA[大规模机器学习模型的最新发展
通用理解、翻译和语言生成是
推动各个领域的影响，包括医学、机器人技术和
科学发现。这种大型语言模型 (LLM) 的优势在于
来自他们接受训练的大型语料库。虽然这让他们充满了
功能广泛，但已发现它们不适合某些特定的
问题类型，例如高等数学。在本文中，我们强调
法学硕士无法推理物理任务。我们证明他们的
可以提高推断物理系统参数的能力，而无需
通过物理模拟的反馈来增强他们的背景，从而进行再培训。
]]></description>
      <guid>http://arxiv.org/abs/2312.14215</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>Deep de Finetti：从大型语言模型中恢复主题分布。 （arXiv：2312.14226v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14226</link>
      <description><![CDATA[大型语言模型 (LLM) 可以生成长而连贯的文本段落，
表明法学硕士虽然接受过下一个单词预测的训练，但必须代表
表征文档的潜在结构。之前的工作发现
LLM 的内部表示编码潜在结构的一方面，即
句法;在这里我们研究一个补充方面，即文档的主题
结构。我们提出这样的假设：法学硕士通过以下方式捕获主题结构：
将 LLM 优化与隐式贝叶斯推理联系起来。德菲内蒂
定理表明，可交换概率分布可以表示为
关于潜在生成分布的混合物。虽然文字是
在语法层面上不可互换，可互换性是合理的
主题结构的起始假设。因此我们假设预测
文本中的下一个标记将引导法学硕士恢复潜在主题分布。我们
使用潜在狄利克雷分配 (LDA) 检验该假设，
可交换概率主题模型作为目标，我们表明
由法学硕士形成的表示对用于生成的主题进行编码
合成数据和用于解释自然语料库数据的数据。
]]></description>
      <guid>http://arxiv.org/abs/2312.14226</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>对大型语言模型进行基准测试并防御间接提示注入攻击。 （arXiv：2312.14197v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14197</link>
      <description><![CDATA[大型语言模型 (LLM) 最近取得的显着进步导致
它们在各种应用中得到广泛采用。这些的一个关键特征
应用程序是法学硕士与外部内容的组合，其中用户
说明和第三方内容相结合，创建 LLM 提示
加工。然而，这些应用程序很容易受到间接提示的影响
注入攻击，其中恶意指令嵌入外部
内容损害了 LLM 的输出，导致其响应偏离用户
期望。尽管发现了这个安全问题，但没有全面的
可以对不同 LLM 的间接提示注入攻击进行分析
由于缺乏基准。此外，还没有采取有效的防御措施
建议的。

在这项工作中，我们引入了第一个基准 BIPIA 来衡量
各种法学硕士的稳健性和对间接即时注入的防御
攻击。我们的实验表明，能力更强的法学硕士表现出
更容易受到文本任务的间接提示注入攻击，从而导致
在更高的 ASR 中。我们假设间接即时注入攻击是
主要是由于法学硕士无法区分指令和指令
外部内容。基于这个猜想，我们提出了四种黑盒方法
一种基于即时学习和基于微调的白盒防御方法
通过对抗性训练使法学硕士能够区分指令
和外部内容并忽略外部内容中的说明。我们的
实验结果表明我们的黑盒防御方法可以有效
减少 ASR 但不能完全阻止间接提示注入攻击，
而我们的白盒防御方法可以将 ASR 降低到几乎为零，几乎不需要
对法学硕士在一般任务上的表现产生不利影响。我们希望我们的
基准和防御可以激发这一重要领域的未来工作。
]]></description>
      <guid>http://arxiv.org/abs/2312.14197</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>照亮黑匣子：对大型语言模型多方面性质的心理测量调查。 （arXiv：2312.14202v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14202</link>
      <description><![CDATA[这项研究探讨了 AI 个性或 AInality 的概念，表明
大型语言模型 (LLM) 表现出与人类性格相似的模式。
假设法学硕士与人类共享这些模式，我们研究使用
以人为本的心理测试，例如迈尔斯-布里格斯类型指标
(MBTI)、大五量表 (BFI) 和短黑三联征 (SD3) 来识别和
确认LLM性格类型。通过引入角色扮演提示，我们展示了
法学硕士的适应性，显示出他们在不同领域之间动态切换的能力
不同的性格类型。使用投射测试，例如华盛顿测试
大学句子完成测试（WUSCT），我们揭示LLM的隐藏方面
通过直接提问不容易接触到的个性。
投射测试可以深入探索法学硕士的认知过程和
思维模式并为我们提供了对 AInality 的多维视角。我们的机器
学习分析表明法学硕士表现出独特的 AInality 特征
表现出不同的人格类型，表现出响应的动态变化
外部指令。这项研究开创了投射测试的应用
法学硕士，揭示了他们多样化且适应性强的 AInality 特征。
]]></description>
      <guid>http://arxiv.org/abs/2312.14202</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>Shai：用于资产管理的大型语言模型。 (arXiv:2312.14203v1 [q-fin.PM])</title>
      <link>http://arxiv.org/abs/2312.14203</link>
      <description><![CDATA[本文具体介绍了“Shai”一个10B级别的大语言模型
专为资产管理行业设计，基于开源
基础模型。使用连续的预训练和微调
目标语料库，Shai 在相关任务中表现出增强的性能
它的领域，优于基线模型。我们的研究包括
制定创新的评估框架，其中整合了
专业资格考试、定制任务、开放式问题
回答和安全评估，全面评估Shai的情况
能力。此外，我们还讨论了以下挑战和影响：
利用 GPT-4 等大型语言模型进行资产性能评估
管理，建议将自动评估和人工评估相结合
判断。 Shai 的发展，展示了其潜力和多功能性
金融领域10B级大型语言模型，具有重大意义
性能和适度的计算要求，希望提供实用的
帮助业界同行开展类似工作的见解和方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.14203</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>医学术语分类中的大型语言模型以及响应和推理之间的意外偏差。 （arXiv：2312.14184v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14184</link>
      <description><![CDATA[这项研究评估了最先进的大型语言模型的能力
（法学硕士）包括 GPT-3.5、GPT-4、Falcon 和 LLaMA 2，用于识别患有以下疾病的患者
出院总结中的轻度认知障碍 (MCI) 并检查实例
模型的反应与他们的推理不一致。利用
MIMIC-IV v2.2 数据库，我们重点关注 65 岁及以上的队列，验证 MCI
根据 ICD 代码和专家评估进行诊断。数据已分区
模型按 7:2:1 的比例分为训练集、验证集和测试集
微调和评估，以及来自的额外转移性癌症数据集
MIMIC III 用于进一步评估推理一致性。 GPT-4展示
卓越的解释能力，特别是在应对复杂的问题时
提示，但显示出明显的响应推理不一致。相比之下，
Falcon 和 LLaMA 2 等开源模型实现了高精度，但缺乏
解释性推理，强调进一步研究的必要性
优化性能和可解释性。该研究强调
及时工程的意义和进一步探索的必要性
GPT-4 中观察到的意外推理-反应错位。结果
强调将法学硕士纳入医疗保健诊断的承诺，
取决于方法学的进步，以确保准确性和临床
人工智能生成的输出的一致性，从而提高了可信度
医疗决策法学硕士。
]]></description>
      <guid>http://arxiv.org/abs/2312.14184</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>Auto311：用于非紧急呼叫的信心引导自动化系统。 （arXiv：2312.14185v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14185</link>
      <description><![CDATA[紧急和非紧急响应系统是提供的基本服务
受到地方政府的重视，对于保护生命、环境和
财产。有效处理（非）紧急呼叫对于
公共安全和福祉。通过非紧急措施减轻负担
通过 911 紧急需要援助的呼叫者、居民将收到
快速有效的响应。与紧急事务部合作
纳什维尔通讯 (DEC)，我们分析了 11,796 个非紧急呼叫
录音并开发了 Auto311，第一个处理 311 的自动化系统
非紧急呼叫，其 (1) 有效且动态地预测正在进行的
非紧急事件类型，可在通话期间生成量身定制的案例报告；
(2) 逐项列出对话上下文中的基本信息以完成
生成的报告； (3) 战略性地构建系统调用者对话
具有优化的信心。我们使用真实世界的数据来评估系统的
有效性和可部署性。实验结果表明
系统有效预测事件类型，平均 F-1 分数为 92.54%。
此外，该系统成功地逐项列出了相关的关键信息。
完成报告的上下文，平均一致性得分为 0.93
与地面事实相比。此外，仿真表明
随着话语量的增加，系统有效地减少了对话次数
广泛并对正在进行的呼叫进行分类，平均准确度为 94.49%。
]]></description>
      <guid>http://arxiv.org/abs/2312.14185</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>WaveCoder：广泛且多功能的增强指令调整和精细数据生成。 （arXiv：2312.14187v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14187</link>
      <description><![CDATA[最近的工作表明，经过高质量的微调后
指令数据集，所得模型可以获得令人印象深刻的能力
解决广泛的任务。然而，现有的指令数据方法
生成经常产生重复数据并且对数据的可控性不够
质量。在本文中，我们通过以下方式扩展了指令调优的泛化
将指令数据分类为 4 个与代码相关的任务，并提出一个
基于 LLM 的生成器-鉴别器数据处理框架，可生成多样化的、
来自开源代码的高质量指令数据。因此，我们介绍
CodeOcean，一个数据集，包含 4 个通用领域的 20,000 个指令实例
与代码相关的任务，旨在增强
指令调优和提高fine-tuned的泛化能力
模型。随后，我们推出了 WaveCoder，一个经过微调的代码法学硕士
广泛且多功能的增强指令调整。这个型号是
专为增强代码语言模型的指令调整而设计
（法学硕士）。我们的实验表明 Wavecoder 模型优于其他模型
开源模型在不同领域的泛化能力方面
代码相关任务处于同一级别的微调规模。此外，波编码器
在之前的代码生成任务中表现出很高的效率。因此本文
为指令数据生成领域做出了重大贡献
和微调模型，提供新的见解和工具来增强
代码相关任务的性能。
]]></description>
      <guid>http://arxiv.org/abs/2312.14187</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>SEOpinion：电子商务网站的总结和探索意见。 （arXiv：2312.14171v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14171</link>
      <description><![CDATA[电子商务 (EC) 网站提供了大量有用的信息，
超越人类的认知处理能力。为了帮助客户在
购买产品时比较替代方案，之前的研究设计了意见
基于客户评论的摘要系统。他们忽略了模板&#39;
制造商提供的信息，尽管这些描述性信息
有很多产品方面或特征。因此，本文提出一种
被称为 SEOpinion（意见总结和探索）的方法论
其中提供了产品方面的摘要并指出了有关的意见
他们使用模板信息与客户评论的组合
分两个主要阶段。一、层次方面提取（HAE）阶段
从模板创建产品方面的层次结构。随后，
基于层次方面的意见总结 (HAOS) 阶段丰富了这一点
与客户意见的等级关系；向其他潜在买家展示。到
测试使用基于深度学习的 BERT 技术的可行性
方法，我们通过收集前五名的信息创建了一个语料库
笔记本电脑的 EC 网站。实验结果表明，循环神经网络
网络（RNN）取得了更好的结果（F1-measure 分别为 77.4% 和 82.6%）
对于第一阶段和第二阶段）比卷积神经网络（CNN）和
支持向量机（SVM）技术。
]]></description>
      <guid>http://arxiv.org/abs/2312.14171</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:53 GMT</pubDate>
    </item>
    <item>
      <title>异质儿童心理健康临床笔记的动态主题语言模型。 （arXiv：2312.14180v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14180</link>
      <description><![CDATA[心理健康疾病影响儿童的生活和福祉，
自 COVID-19 大流行以来，它受到越来越多的关注。分析精神科
带有主题模型的临床记录对于评估儿童的心理至关重要
随着时间的推移的状态。然而，很少有主题模型是针对纵向构建的
设置，并且他们无法保持一致的主题并捕获时间
每个文档的轨迹。为了应对这些挑战，我们开发了
具有时不变主题和个性化时间的纵向主题模型
对不断发展的文档元数据的依赖。我们的模型保留了
随着时间的推移发现的主题的语义意义并包含异质性
文件之间。特别是，当文档可以分类时，我们建议
一种无监督的主题学习方法，可以最大限度地提高跨领域的主题异质性
不同的文档组。我们还提出了一种有效的变分
适用于多级纵向设置的优化程序。在这个
案例研究中，我们将我们的方法应用于大型精神病学临床记录
南加州三级儿科医院，实现 38% 的增长
提取主题的整体连贯性。我们的真实数据分析揭示了
孩子们在国家关闭期间往往会表达更多的负面情绪
当学校重新开放时会更加积极。此外，它表明性和
性别少数（SGM）儿童对专业表现出更明显的反应
与非 SGM 相比，COVID-19 事件和对疫苗相关新闻的敏感度更高
孩子们。这项研究调查了儿童心理健康的进展
在大流行期间，为临床医生提供了宝贵的见解，以认识到
儿童心理健康方面的差异与性和性别有关
身份。
]]></description>
      <guid>http://arxiv.org/abs/2312.14180</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:53 GMT</pubDate>
    </item>
    <item>
      <title>关于事实问答中幻觉的早期检测。 （arXiv：2312.14183v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.14183</link>
      <description><![CDATA[虽然大型语言模型（LLM）在帮助
人类承担大量任务，例如搜索和总结、幻觉
仍然是获得用户信任的主要障碍。流畅性和连贯性
即使出现幻觉也很难检测到模型生成
模型是否产生幻觉。在这项工作中，我们探索是否
与模型生成相关的工件可以提供提示：
一代人就会产生幻觉。具体来说，我们在 1) 方面探讨法学硕士
通过基于集成梯度的令牌属性输入，2）通过
Softmax 概率，以及 3）通过自注意力的内部状态和
开放式幻觉迹象的全连接层激活
问答任务。我们的结果表明这些分布
幻觉一代和非幻觉一代的文物有所不同。
基于这种见解，我们训练使用这些工件的二元分类器
作为输入特征将模型生成分类为幻觉和
非幻觉。这些幻觉分类器的 AUROC 高达 0.80。
我们进一步表明，幻觉之前的令牌可以预测
随后出现幻觉。
]]></description>
      <guid>http://arxiv.org/abs/2312.14183</guid>
      <pubDate>Mon, 25 Dec 2023 03:14:53 GMT</pubDate>
    </item>
    </channel>
</rss>