<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Mon, 22 Jan 2024 03:15:44 GMT</lastBuildDate>
    <item>
      <title>具有基于注意力的偏差短语增强波束搜索的情境化自动语音识别。 （arXiv：2401.10449v1 [eess.AS]）</title>
      <link>http://arxiv.org/abs/2401.10449</link>
      <description><![CDATA[展示端到端（E2E）自动语音识别（ASR）方法
卓越的表现。然而，由于此类方法的性能
与训练数据中存在的上下文有内在联系，E2E-ASR
对于未见过的用户上下文（例如，技术
术语、个人姓名和播放列表）。因此，E2E-ASR 方法必须易于实现
由用户或开发人员具体化。本文提出了一种基于注意力的
可以使用可编辑短语列表进行定制的上下文偏差方法
（称为偏差列表）。所提出的方法可以通过以下方式进行有效训练
结合偏差短语索引损失和特殊标记来检测偏差
输入语音数据中的短语。此外，为了提高情境化
为了进一步提高推理过程中的性能，我们提出了偏置短语增强（BPB）
基于偏置短语索引概率的波束搜索算法。实验性的
结果表明，所提出的方法持续改进了单词
偏差列表中目标短语的错误率和字符错误率
在 Librispeech-960（英语）和我们内部（日语）数据集上，
分别。
]]></description>
      <guid>http://arxiv.org/abs/2401.10449</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:43 GMT</pubDate>
    </item>
    <item>
      <title>从 Grokking 的角度看语言模型的关键数据大小。 （arXiv：2401.10463v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.10463</link>
      <description><![CDATA[我们探索语言模型中的临界数据大小，这是标志着
从快速记忆到缓慢概括的根本转变。我们
将 grokking 配置下的相变形式化为数据
效率假设并识别数据不足、充足和过剩
语言模型训练动态中的制度。我们开发了一个grokking
配置以在简单的语言模型上稳定地重现 grokking
重新调整初始化和权重衰减。我们证明泛化发生了
仅当语言模型达到临界大小时。我们分析了 grokking
样本和模型方面，验证了所提出的数据效率假设。
我们的实验揭示了在临界点发生更平滑的相变
语言数据集的数据集大小。随着模型尺寸的增加，这个关键
点也变得更大，表明更大的模型需要更多的数据。我们的
结果加深了对语言模型训练的理解，提供了一种新颖的方法
数据在语言模型学习机制中的作用的观点。
]]></description>
      <guid>http://arxiv.org/abs/2401.10463</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:43 GMT</pubDate>
    </item>
    <item>
      <title>数据驱动的字素到音素表示，用于无词典的文本到语音的转换。 （arXiv：2401.10465v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.10465</link>
      <description><![CDATA[字素到音素 (G2P) 是任何现代、
高质量的文本转语音 (TTS) 系统。目前大多数G2P系统都依赖于
由专家精心制作的词典。这构成了两重
问题。首先，使用固定音素集生成词典，
通常是 ARPABET 或 IPA，这可能不是表示的最佳方式
所有语言的音素。其次，生产这样的产品所需的工时
专家词典非常高。在本文中，我们消除了这两个问题
通过利用自我监督学习的最新进展来获得数据驱动的
音素表示而不是固定表示。我们比较我们的
针对强大基线的无词典方法，利用精心设计的方法
词典。此外，我们表明我们的数据驱动的无词典方法执行
与传统的基于规则的或什至稍好一些
基于词典的神经 G2P 的平均意见得分 (MOS)，同时不使用
先前的语言词典或音素集，即没有语言专业知识。
]]></description>
      <guid>http://arxiv.org/abs/2401.10465</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:43 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是抗噪声语音识别的高效学习者。 （arXiv：2401.10446v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.10446</link>
      <description><![CDATA[大型语言模型 (LLM) 的最新进展促进了生成式
自动语音识别 (ASR) 的纠错 (GER)，它利用
LLM丰富的语言知识和强大的推理能力可以提高
识别结果。最新工作提出了 HyPoadise 的 GER 基准
用于学习从 ASR N 最佳假设到真实情况的映射的数据集
通过高效的LLM微调进行转录，显示出巨大的有效性，但
缺乏抗噪声 ASR 的特异性。在这项工作中，我们将基准扩展到
噪声条件并研究我们是否可以教法学硕士进行降噪
GER 就像稳健的 ASR 所做的那样}，其中一种解决方案是引入噪声
信息作为进入LLM的条件。然而，直接加入噪声
由于跨模态，音频编码器的嵌入可能会损害 LLM 调优
差距。为此，我们建议从中提取语言空间噪声嵌入
表示源语音噪声条件的 N-best 列表，可以
促进GER的去噪进程。此外，为了增强其
音频噪声的表示能力，我们设计了知识蒸馏（KD）
通过互信息估计来提取真实噪声的方法
音频嵌入中的信息到我们的语言嵌入。实验
各种最新的法学硕士证明我们的方法取得了新的突破
字错误率方面的纠正率提高高达 53.9%
有限的训练数据。分析表明我们的语言空间噪声嵌入
可以很好地表征源语音的噪声条件，其中
现成的法学硕士表现出强大的语言空间去噪能力。
]]></description>
      <guid>http://arxiv.org/abs/2401.10446</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:42 GMT</pubDate>
    </item>
    <item>
      <title>研究语音识别中语言建模的低秩适应的训练策略和模型鲁棒性。 （arXiv：2401.10447v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.10447</link>
      <description><![CDATA[使用低秩适应 (LoRA) 和冻结的预训练语言模型
(PLM) 作为一种主流、资源高效的方法已变得越来越流行
内存受限硬件的建模方法。在本研究中，我们首先
探索如何通过引入各种LoRA训练来增强模型性能
策略，实现相对字错误率降低 3.50\%
公共 Librispeech 数据集和 3.67\% 的内部数据集
消息域。进一步表征基于LoRA的稳定性
第二遍语音识别模型，我们检查输入的鲁棒性
扰动。这些扰动根源于同音词替换和
称为 N 最佳基于扰动的重新评分鲁棒性 (NPRR) 的新颖度量，两者
旨在衡量重新评分性能的相对退化
楷模。我们的实验结果表明，虽然 LoRA 的高级变体，
例如动态排名分配的 LoRA，会导致性能下降
$1$-最佳扰动，它们减轻了 $N$-最佳扰动的退化。
这一发现是与完全调整的模型和普通 LoRA 调整进行比较的
基线，建议使用时需要综合选择
基于 LoRA 的适应可节省计算成本并实现强大的语言建模。
]]></description>
      <guid>http://arxiv.org/abs/2401.10447</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:42 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型摘要器能否适应多样化的科学传播目标？ （arXiv：2401.10415v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.10415</link>
      <description><![CDATA[在这项工作中，我们研究了大型语言模型的可控性
（法学硕士）科学总结任务。我们确定关键的风格和内容
表征不同类型摘要（例如纸张）的覆盖因素
评论、摘要和简明摘要。通过控制风格特征，我们
发现未经微调的法学硕士在 MuP 评审生成中优于人类
任务，无论是在与参考摘要的相似性还是人类偏好方面。
此外，我们还表明，我们可以通过以下方式提高法学硕士的可控性：
基于关键字的无分类器指导 (CFG)，同时实现词汇重叠
与 arXiv 和 PubMed 上强大的微调基线相当。然而，我们的
结果还表明法学硕士无法始终如一地生成长摘要
超过8个句子。此外，这些模型的容量有限
生成高度抽象的外行摘要。尽管法学硕士表现出很强的
通用摘要能力，复杂的内容控制，无需昂贵的费用
对于特定领域的应用程序来说，微调仍然是一个悬而未决的问题。
]]></description>
      <guid>http://arxiv.org/abs/2401.10415</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:41 GMT</pubDate>
    </item>
    <item>
      <title>用跨语言专家语言模型打破多语言的魔咒。 （arXiv：2401.10440v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.10440</link>
      <description><![CDATA[尽管多语言模型在非英语 NLP 中很受欢迎
由于模型的语言间竞争，通常表现不佳单语模型
参数。我们提出跨语言专家语言模型（X-ELM），
通过在子集上独立训练语言模型来缓解这种竞争
的多语言语料库。此过程专门针对不同的 X-ELM
语言，同时保持作为多语言整体的有效性。我们的实验
表明，当给定相同的计算预算时，X-ELM 的性能优于联合训练的
跨所有考虑的语言的多语言模型，这些收益
转移到下游任务。 X-ELM 提供的额外优势超过
性能改进：可以迭代添加新专家，适应 X-ELM
掌握新语言而不会发生灾难性的遗忘。此外，培训是
异步，降低多语言训练的硬件要求
使多语言建模民主化。
]]></description>
      <guid>http://arxiv.org/abs/2401.10440</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:41 GMT</pubDate>
    </item>
    <item>
      <title>通过文化价值调查弥合对话主体的文化细微差别。 （arXiv：2401.10352v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.10352</link>
      <description><![CDATA[与对话代理互动的文化景观是一个引人注目的
但仍是相对未开发的领域。很明显，不同的社会文化
方面——从沟通方式和信仰到共享的隐喻和
知识——深刻地影响这些相互作用。为了更深入地研究这个
动态，我们引入了 cuDialog，首个对话基准
具有文化视角的一代人。我们还开发了能够
从对话交流中提取文化属性，目的是
提高对话代理的预测准确性和质量。到
有效地共同学习文化理解和多轮对话
预测，我们建议将文化维度与对话结合起来
编码特征。我们的实验结果强调，结合
文化价值调查促进与参考文献和文​​化标记的一致性，
展示其对个性化和对话的巨大影响
质量。为了促进对这个令人兴奋的领域的进一步探索，我们发布了
我们的基准可在 https://github.com/yongcaoplus/cuDialog 上公开访问。
]]></description>
      <guid>http://arxiv.org/abs/2401.10352</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:40 GMT</pubDate>
    </item>
    <item>
      <title>不一致的对话响应以及如何从中恢复。 （arXiv：2401.10353v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.10353</link>
      <description><![CDATA[聊天系统的一个关键问题是保持偏好一致，
观点、信念和事实本身，这已被证明是困难的
问题。在这项工作中，我们研究评估和支持话语的方法
聊天系统的一致性。首先开发一个数据集用于研究
不一致，对话反应、解释不一致
不一致和恢复话语是由注释者撰写的。这
涵盖了不一致的生命周期，即介绍、理解、
和分辨率。在此基础上，我们引入了一系列任务
对话一致性，特别关注其检测和解决。我们的
实验结果表明我们的数据集显着帮助
在识别和解决对话不一致方面取得的进展，以及
目前流行的大语言模型如ChatGPT，擅长解决
然而，不一致之处仍然难以检测。
]]></description>
      <guid>http://arxiv.org/abs/2401.10353</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:40 GMT</pubDate>
    </item>
    <item>
      <title>学习高质量和通用的短语表示。 （arXiv：2401.10407v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.10407</link>
      <description><![CDATA[短语表示在数据科学和自然科学中发挥着重要作用
语言处理，有利于实体对齐、记录等各种任务
链接、模糊连接和释义分类。目前的
最先进的方法涉及微调预训练的语言模型
使用对比学习的短语嵌入。然而，我们已经确定
需要改进的方面。首先，这些预先训练的模型往往是不必要的
复杂，需要在带有上下文句子的语料库上进行预训练。
其次，利用短语类型和形态给出短语表示
既更精确又更灵活。我们提出一个改进的框架
以与上下文无关的方式学习短语表示。框架
采用短语类型分类作为辅助任务，并结合
字符级信息更有效地转化为短语表示。
此外，我们设计了三种数据增强粒度来增加
训练样本的多样性。我们的实验涉及广泛的任务
表明我们的方法与相比产生了更好的短语嵌入
以前的方法，同时需要较小的模型尺寸。该代码可在
\faGithub~ \url{https://github.com/tigerchen52/PEARL} \end{摘要}
]]></description>
      <guid>http://arxiv.org/abs/2401.10407</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:40 GMT</pubDate>
    </item>
    <item>
      <title>DrugAssist：用于分子优化的大型语言模型。 (arXiv:2401.10334v1 [q-bio.QM])</title>
      <link>http://arxiv.org/abs/2401.10334</link>
      <description><![CDATA[最近，大型语言模型 (LLM) 在
广泛的任务吸引了越来越多的尝试
药物发现法学硕士。然而，分子优化是该领域的一项关键任务。
药物发现管道，目前是一个很少有人参与的领域
来自法学硕士。大多数现有方法仅专注于捕获底层
数据提供的化学结构模式，没有利用
的专家反馈。这些非交互式方法忽视了这样一个事实：
药物发现过程实际上是一个需要专家整合的过程
经验和迭代完善。为了弥补这一差距，我们建议
DrugAssist，一种交互式分子优化模型，执行
利用LLM强大的优势，通过人机对话进行优化
交互性和普遍性。 DrugAssist 在以下方面取得了领先成果
单一和多重属性优化，同时展示
在可迁移性和迭代优化方面具有巨大的潜力。此外，
我们公开发布了一个基于指令的大型数据集，称为
MolOpt-分子优化语言模型微调说明
任务。我们已将我们的代码和数据公开在
https://github.com/blazerye/DrugAssist，我们希望为此铺平道路
法学硕士在药物发现方面的应用的未来研究。
]]></description>
      <guid>http://arxiv.org/abs/2401.10334</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:39 GMT</pubDate>
    </item>
    <item>
      <title>基于噪声对比估计的低资源安全攻击模式识别匹配框架。 （arXiv：2401.10337v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.10337</link>
      <description><![CDATA[战术、技术和程序 (TTP) 代表复杂的攻击
网络安全领域的模式，以百科全书式的文本描述
知识库。识别网络安全写作中的 TTP，通常称为 TTP
测绘是一项重要且具有挑战性的任务。传统的学习方法
通常针对经典多类或多标签中的问题
分类设置。这种设置阻碍了模型的学习能力
由于大量的类（即 TTP），不可避免的偏斜
标签分布和标签空间的复杂层次结构。
我们用不同的学习范式来表述问题，其中作业
文本与 TTP 标签之间的直接语义相似性决定
两者，从而降低了单独竞争大型企业的复杂性
标签空间。为此，我们提出了一种神经匹配架构
有效的基于抽样的学习比较机制，促进学习
尽管资源有限，但匹配模型的过程。
]]></description>
      <guid>http://arxiv.org/abs/2401.10337</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:39 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络的知识图驱动推荐模型。 （arXiv：2401.10244v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.10244</link>
      <description><![CDATA[一种新的基于图神经网络的推荐模型，称为 KGLN，它
利用知识图谱 (KG) 信息，旨在增强
个性化推荐的准确性和有效性。这个模型开始
通过使用单层神经网络来合并单个节点特征
图形。然后，它通过以下方式调整相邻实体的聚合权重：
纳入影响因素。模型从单层发展到
通过迭代实现多层，使实体能够访问广泛的
多阶关联实体信息。最后一步涉及整合
实体和用户的特征来产生推荐分数。该模型的
通过比较其对各种聚合的影响来评估性能
方法及影响因素。在使用 MovieLen-1M 和 Book-Crossing 的测试中
数据集上，KGLN 显示 AUC（ROC 曲线下面积）提高了 0.3%
分别比既定基准方法（如
LibFM、DeepFM、Wide&amp;Deep 和 RippleNet。
]]></description>
      <guid>http://arxiv.org/abs/2401.10244</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:38 GMT</pubDate>
    </item>
    <item>
      <title>对大型语言模型中地理空间位置嵌入方法的系统回顾：空间人工智能系统的路径。 （arXiv：2401.10279v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.10279</link>
      <description><![CDATA[地理空间位置嵌入 (GLE) 有助于大型语言模型 (LLM)
同化和分析空间数据。 GLE 在地理空间人工领域的出现
对更深层次地理空间的需求催生了智能（GeoAI）
对我们复杂的当代空间的认识以及法学硕士在
提取生成人工智能中的深层含义。我们搜索了谷歌学术、科学
Direct，以及 arXiv 有关地理空间位置嵌入和 LLM 的论文以及
评论的文章侧重于通过法学硕士获得更深入的空间“了解”。我们
筛选了 304 篇标题、30 篇摘要和 18 篇全文论文，揭示了 4 个 GLE
主题 - 实体位置嵌入 (ELE)、文档位置嵌入 (DLE)、
序列位置嵌入（SLE）和令牌位置嵌入（TLE）。
综合是表格和叙述性的，包括之间的对话
“太空”和“法学硕士”。尽管 GLE 通过叠加来帮助空间理解
空间数据，他们强调需要在空间的复杂性方面取得进展
模式和广义推理。 GLE 表明需要空间
将空间认知嵌入到模型中的基础/语言模型 (SLM)
建筑学。 SLM 框架推进空间人工智能
系统（SPAIS），建立映射到的空间向量空间（SVS）
物理空间。由此产生的充满空间的语言模型是独一无二的。它
同时代表实际空间和人工智能空间，铺平道路
以 AI 原生地理存储、分析和多模态为基础
空间人工智能系统（SPAIS）。
]]></description>
      <guid>http://arxiv.org/abs/2401.10279</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:38 GMT</pubDate>
    </item>
    <item>
      <title>中文数据处理顶尖：英文代码模型。 （arXiv：2401.10286v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.10286</link>
      <description><![CDATA[虽然任务和训练语料库之间的一致性是一个基本的
在语言模型的应用、我们的一系列实验和
我们设计的指标揭示了基于代码的大型语言模型（LLM）
显着优于在与数据密切匹配的数据上训练的模型
非编码中文任务中的任务。此外，在任务中对
中国幻觉，模型表现出较少的语言特征
中文取得更好的成绩。我们的实验结果可以
在中文数据处理任务中很容易复制，例如准备数据
检索增强生成（RAG），只需将基本模型替换为
基于代码的模型。此外，我们的研究为以下问题提供了独特的视角：
关于哲学“中国室”思想实验的讨论。
]]></description>
      <guid>http://arxiv.org/abs/2401.10286</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:38 GMT</pubDate>
    </item>
    </channel>
</rss>