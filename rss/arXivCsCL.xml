<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Fri, 29 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>代码大型语言模型的代码比较调优</title>
      <link>https://arxiv.org/abs/2403.19121</link>
      <description><![CDATA[arXiv:2403.19121v1 公告类型：新
摘要：我们提出了代码比较调优（CCT），这是一种简单有效的代码大语言模型（代码 LLM）调优方法，可以更好地处理细微的代码错误。具体来说，我们在标记和序列级别将比较的概念集成到指令调整中，使模型能够识别代码中最轻微的偏差。为了将原始代码与包含手动添加代码错误的错误版本进行比较，我们使用令牌级别偏好损失来进行详细的令牌级别比较。此外，我们结合代码段来创建新的指令调优样本，用于序列级比较，增强模型的错误修复能力。 HumanEvalFix 基准测试的实验结果表明，在不同的代码 LLM 中，CCT 在 pass@1 分数中超过了指令调整高达 4 分，并且广泛的分析证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.19121</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>通过简化不重要层来压缩大型语言模型</title>
      <link>https://arxiv.org/abs/2403.19135</link>
      <description><![CDATA[arXiv:2403.19135v1 公告类型：新
摘要：大语言模型（LLM）已广泛应用于各种自然语言任务和领域，但其适用性受到模型参数数量过多的限制。因此，人们越来越重视具有高性能的紧凑型模型。在这项研究中，我们观察到 LLM 中的不同层对隐藏状态有不同程度的扰动，这使我们能够识别不太重要的层。基于这种现象，我们提出了LLM-Streamline，它由两部分组成：层剪枝，根据目标稀疏度删除模型中重要性最低的一组连续层；和层替换，我们训练一个轻量级模型来替换修剪后的层，从而减轻修剪引起的性能下降。在我们的实验中，我们利用多层感知器（MLP）和变换层等结构作为轻量级模型，并最终证明单个 MLP 可以有效地拟合剪枝层。综合实验表明，我们提出的方法 LLM-Streamline 优于以前最先进的 (SOTA) 模型修剪方法。]]></description>
      <guid>https://arxiv.org/abs/2403.19135</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>在没有提示的情况下从正确性中学习使 LLM 成为高效推理者</title>
      <link>https://arxiv.org/abs/2403.19094</link>
      <description><![CDATA[arXiv:2403.19094v1 公告类型：新
摘要：大型语言模型（LLM）在各种任务中表现出了出色的性能，但它们仍然表现出幻觉、不忠实推理和有毒内容等局限性。缓解这些问题的一种潜在方法是从人类或外部反馈（例如工具）中学习。在本文中，我们为法学硕士介绍了一种内在的自我正确推理框架，消除了对人类反馈、外部工具和手工提示的需要。所提出的框架基于从\textbf{Co}正确性（\textsc{LeCo}）学习的多步推理范式\textbf{Le}，无需从错误中学习即可提高推理性能。该范例优先考虑从正确的推理步骤中学习，以及基于生成逻辑来衡量每个推理步骤的置信度的独特方法。各种多步推理任务的实验结果证明了该框架在提高推理性能和减少令牌消耗方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.19094</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>FACTOID：幻觉检测的事实依据</title>
      <link>https://arxiv.org/abs/2403.19113</link>
      <description><![CDATA[arXiv:2403.19113v1 公告类型：新
摘要：大型语言模型（LLM）的广泛采用带来了许多好处。然而，幻觉是一个重大问题。作为回应，检索增强生成（RAG）已成为一种非常有前途的范式，通过以事实信息为基础来提高法学硕士的输出。 RAG 依靠文本蕴含 (TE) 或类似方法来检查法学硕士生成的文本与检索到的文档相比是否得到支持或矛盾。本文认为，传统的 TE 方法不足以发现法学硕士生成的内容中的幻觉。例如，考虑有关“美国对乌克兰战争的立场”的提示。人工智能生成的文本指出，……美国奥巴马总统表示美国不会在乌克兰驻军……”然而，战争期间的美国总统是乔·拜登，这与事实相矛盾。此外，当前的 TE 系统无法准确注释给定文本并识别出矛盾的确切部分。为了解决这个问题，我们引入了一种名为“事实蕴涵（FE）”的新型 TE，旨在检测法学硕士生成的内容中的事实不准确之处，同时突出显示与现实相矛盾的特定文本片段。我们提出了 FACTOID（幻觉检测的 FACTual enTAILment），这是 FE 的基准数据集。我们提出了一个 FE 多任务学习 (MTL) 框架，结合了最先进的 (SoTA) 长文本嵌入，例如 e5-mistral-7b-instruct，以及 GPT-3、SpanBERT 和 RoFormer。所提出的 FE MTL 架构实现了平均。与 SoTA TE 方法相比，FACTOID 基准的准确性提高了 40%。由于 FE 自动检测幻觉，我们评估了 15 个现代法学硕士，并使用我们提出的自动幻觉脆弱性指数 (HVI_auto) 对它们进行排名。该指数量化并提供了一个比较尺度，以根据法学硕士的幻觉对其进行评估和排名。]]></description>
      <guid>https://arxiv.org/abs/2403.19113</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>MFORT-QA：多跳少样本开放丰富表问答</title>
      <link>https://arxiv.org/abs/2403.19116</link>
      <description><![CDATA[arXiv:2403.19116v1 公告类型：新
摘要：在当今快节奏的行业中，专业人员每天面临着总结大量文档并从中提取重要信息的挑战。这些指标经常隐藏在表格和/或其嵌套超链接中。为了应对这一挑战，开发了表格问答（QA）方法来提取相关信息。然而，为问题提供表格和黄金单元坐标答案的传统表格 QA 训练任务可能并不总是确保提取准确的答案。大型语言模型 (LLM) 的最新进展为使用提示从表格数据中提取信息开辟了新的可能性。在本文中，我们介绍了多跳少样本开放式丰富表 QA (MFORT-QA) 方法，该方法由两个主要步骤组成。第一步涉及少样本学习 (FSL)，其中根据给定问题检索相关表格和超链接的关联上下文。然后，检索到的内容用于构建少量提示，作为 LLM（例如 ChatGPT）的输入。为了应对回答复杂问题的挑战，第二步利用思想链 (CoT) 提示，以多跳方式将复杂问题分解为一系列问题和推理思想的顺序链。检索增强生成 (RAG) 通过检索与所得推理想法和问题相关的相关表格和超链接上下文来增强此过程。然后，这些额外的上下文将用于补充第一步中使用的提示，从而使法学硕士得到更准确的答案。 OTT-QA 的经验结果表明，我们的抽象 QA 方法显着提高了提取表 QA 方法的准确性。]]></description>
      <guid>https://arxiv.org/abs/2403.19116</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>使用公共社交媒体数据评估健康相关文本分类任务的大型语言模型</title>
      <link>https://arxiv.org/abs/2403.19031</link>
      <description><![CDATA[arXiv:2403.19031v1 公告类型：新
摘要：大型语言模型（LLM）在 NLP 任务中取得了显着的成功。然而，很少有研究试图评估他们在基于社交媒体的健康相关自然语言处理任务上的表现，而这些任务传统上很难取得高分。我们对一种基于支持向量的有监督经典机器学习模型进行了基准测试机器 (SVM)、三个基于 RoBERTa、BERTweet 和 SocBERT 的有监督预训练语言模型 (PLM)，以及两个基于 LLM 的分类器（GPT3.5 和 GPT4），涵盖 6 个文本分类任务。我们开发了三种利用 LLM 进行文本分类的方法：使用 LLM 作为零样本分类器，使用 LLM 作为注释器来注释监督分类器的训练数据，以及利用 LLM 和少量样本来增强手动注释数据。我们的综合实验表明，与单独使用人工注释数据进行训练相比，使用 LLM (GPT-4) 和相对较小的人工注释数据进行数据增强来训练轻量级监督分类模型可以获得更好的结果。监督学习器在零样本设置中也优于 GPT-4 和 GPT-3.5。通过利用这种数据增强策略，我们可以利用法学硕士的力量来开发更小、更有效的特定领域 NLP 模型。在没有人工指导的情况下使用法学硕士注释数据来训练轻量级监督分类模型是一种无效的策略。然而，LLM 作为一种零样本分类器，在排除漏报并可能减少数据注释所需的人力方面表现出了希望。未来的研究必须探索最佳的训练数据大小和最佳的增强数据量。]]></description>
      <guid>https://arxiv.org/abs/2403.19031</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>原因：面向任务的对话系统中用户满意度估计的反事实评估</title>
      <link>https://arxiv.org/abs/2403.19056</link>
      <description><![CDATA[arXiv:2403.19056v1 公告类型：新
摘要：之前关于面向任务的对话（TOD）系统的用户满意度估计的一个重要的未探索的方面是对用户不满意识别的鲁棒性进行评估：当前 TOD 系统中用户满意度估计的基准高度偏向于对话用户对此感到满意。拥有一套更平衡的满意度标签对绩效的影响尚不清楚。然而，用更多不满意的对话样本来平衡数据需要进一步的数据收集和人工注释，这是昂贵且耗时的。在这项工作中，我们利用大型语言模型 (LLM) 并解锁其生成满意度感知反事实对话的能力，以增强测试集合的原始对话集。我们收集人工注释以确保生成样本的可靠性。我们根据最先进的微调模型评估了两个开源法学硕士作为我们的增强集合的用户满意度评估器。我们的实验表明，当用作小样本用户满意度估计器时，开源法学硕士对测试集合中不​​满意标签数量的增加表现出比经过微调的最先进模型更高的鲁棒性。我们的结果揭示了 TOD 系统中用户满意度评估的数据增强方法的需求。我们发布了由人工注释整理的一致的反事实对话，以促进对该主题的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2403.19056</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>“抱歉，再来一次吗？”提示——通过注入[PAUSE]的最佳释义来增强理解并减少幻觉</title>
      <link>https://arxiv.org/abs/2403.18976</link>
      <description><![CDATA[arXiv:2403.18976v1 公告类型：新
摘要：幻觉已成为当代大型语言模型（LLM）中最脆弱的方面。在本文中，我们介绍了“抱歉，再来一次”(SCA) 提示，旨在通过以下方式增强理解力，从而避免 LLM 幻觉：(i) 最佳释义和 (ii) 注入 [PAUSE] 标记以延迟 LLM 生成。首先，我们对语言上的细微差别进行了深入分析：21 名法学硕士的提示的形式性、可读性和具体性，并阐明这些细微差别如何导致幻觉的产生。可读性、形式性或具体性较低的提示给法学硕士带来了理解挑战，类似于人类所面临的挑战。在这种情况下，法学硕士倾向于根据其想象力（联想记忆）推测和生成内容，以填补这些信息空白。尽管这些推测有时可能与事实信息相符，但其准确性并不确定，常常会导致幻觉。最近的研究表明，法学硕士经常忽略扩展提示的中间部分，这种现象被称为迷失在中间。虽然特定的释义可能适合一个法学硕士，但相同的释义版本可能会引起另一个法学硕士的不同反应。因此，我们提出了一种最佳释义技术来识别给定提示的最容易理解的释义，并使用集成梯度（及其变体）进行评估，以保证法学硕士准确地处理所有单词。在阅读长句子时，人们经常会在不同的地方停顿，以更好地理解到目前为止所读到的含义。我们通过注入 [PAUSE] 标记对 LLM 进行了微调，允许 LLM 在阅读较长的提示时暂停。这带来了几个关键贡献：(i) 确定注入 [PAUSE] 的最佳位置，(ii) 确定要插入的 [PAUSE] 代币的数量，以及 (iii) 引入反向代理调整来微调 LLM [暂停]插入。]]></description>
      <guid>https://arxiv.org/abs/2403.18976</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>ReflectSumm：课程反思总结的基准</title>
      <link>https://arxiv.org/abs/2403.19012</link>
      <description><![CDATA[arXiv:2403.19012v1 公告类型：新
摘要：本文介绍了 ReflectSumm，这是一个专门为总结学生反思性写作而设计的新型总结数据集。 ReflectSumm 的目标是促进开发和评估新颖的摘要技术，这些技术针对现实场景而定制，训练数据很少，%实际任务对一般意见摘要领域和特别是教育领域具有潜在影响。该数据集包含各种汇总任务，并包含全面的元数据，能够探索各种研究问题并支持不同的应用。为了展示其实用性，我们使用多个最先进的基线进行了广泛的评估。研究结果为促进该领域的进一步研究提供了基准。]]></description>
      <guid>https://arxiv.org/abs/2403.19012</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>共形意图分类和澄清，实现快速准确的意图识别</title>
      <link>https://arxiv.org/abs/2403.18973</link>
      <description><![CDATA[arXiv:2403.18973v1 公告类型：新
摘要：我们提出了保形意图分类和澄清（CICC），这是一个面向任务的对话系统快速准确的意图分类的框架。该框架将任何意图分类器的启发式不确定性分数转变为澄清问题，保证在预定义的置信水平上包含真实意图。通过消除少量可能意图的歧义，可以快速准确地解决用户查询。此外，我们建议增强范围外检测的框架。在使用七个意图识别数据集的比较评估中，我们发现 CICC 会生成小的澄清问题，并且能够进行范围外检测。 CICC 可以帮助从业者和研究人员通过具体的澄清问题大幅改善对话代理的用户体验。]]></description>
      <guid>https://arxiv.org/abs/2403.18973</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>使用基于 BERT 的语言模型的带注释的医学影像报告和信息提取结果的新型语料库</title>
      <link>https://arxiv.org/abs/2403.18975</link>
      <description><![CDATA[arXiv:2403.18975v1 公告类型：新
摘要：医学成像对于许多健康状况的诊断、监测和治疗至关重要，包括肿瘤、神经、心血管和肌肉骨骼疾病等。放射科医生解释这些复杂的、非结构化的图像，并通过基本上非结构化的叙述性报告阐明他们的评估。这种非结构化的叙述必须转换为结构化的语义表示，以促进二次应用，例如回顾性​​分析或临床决策支持。在这里，我们介绍注释医学影像报告语料库 (CAMIR)，其中包括来自三种成像模式类型的 609 份注释放射学报告：计算机断层扫描、磁共振成像和正电子发射断层扫描-计算机断层扫描。报告使用基于事件的模式进行注释，捕获临床适应症、病变和医疗问题。每个事件由一个触发器和多个参数组成，大多数参数类型（包括解剖学）将跨度标准化为预定义的概念，以方便二次使用。 CAMIR 独特地结合了精细的事件结构和概念规范化。为了提取 CAMIR 事件，我们探索了两种基于 BERT（来自 Transformers 的双向编码器表示）的架构，包括联合提取所有事件信息的现有架构 (mSpERT) 和我们增强的多步骤方法 (PL-Marker++) CAMIR 模式。]]></description>
      <guid>https://arxiv.org/abs/2403.18975</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>使用生成变压器将自由文本放射学笔记重塑为结构化报告</title>
      <link>https://arxiv.org/abs/2403.18938</link>
      <description><![CDATA[arXiv:2403.18938v1 公告类型：新
摘要：背景：放射学报告通常以自由文本格式编写，使得临床信息难以提取和使用。最近，由于结构化报告 (SR) 所提供的优点，各个医学协会都推荐采用它，例如：标准化、完整性和信息检索。我们提出了一个从自由文本放射学报告中提取信息的管道，该管道与国家介入和医学放射学协会提出的参考 SR 注册表项相符，重点关注淋巴瘤患者的 CT 分期。方法：我们的工作旨在利用自然语言处理 (NLP) 和基于 Transformer 的模型的潜力来处理自动 SR 注册表填充问题。凭借 174 份放射学报告的可用性，我们研究了一种基于特定领域版本的 T5 (IT5) 的无规则生成问答方法。实施两种策略（批量截断和事后组合）以符合模型的上下文长度限制。性能从严格准确性、F1 和格式准确性方面进行评估，并与广泛使用的 GPT-3.5 大语言模型进行比较。使用 5 点李克特量表调查问卷来收集人类专家对医学注释和生成答案之间相似性的反馈。结果：微调和批量分割的结合使IT5取得了显着的效果；它的性能与 GPT-3.5 相当，尽管其尺寸在参数方面要小一千倍。基于人的评估分数显示出与 AI 性能指标 (F1) 的高度相关性（Spearman 相关系数&gt;0.88，p 值&lt;0.001），并证实了 LLM（即 GPT-3.5，参数 175B）在生成合理结果方面的卓越能力类似人类的陈述。]]></description>
      <guid>https://arxiv.org/abs/2403.18938</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型从概念到实现的综述</title>
      <link>https://arxiv.org/abs/2403.18969</link>
      <description><![CDATA[arXiv:2403.18969v1 公告类型：新
摘要：大型语言模型（LLM）的最新进展，特别是基于 Transformer 架构的模型，显着拓宽了自然语言处理（NLP）应用的范围，超越了它们最初在聊天机器人技术中的应用。本文研究了这些模型的多方面应用，重点是 GPT 系列。这项探索的重点是人工智能 (AI) 驱动工具对编码和解决问题等传统任务的革命性影响，同时也为不同行业的研发铺平了新的道路。从代码解释和图像字幕到促进交互式系统的构建和推进计算领域，Transformer 模型体现了深度学习、数据分析和神经网络设计的协同作用。这项调查深入探讨了 Transformer 模型的最新研究，强调了它们的多功能性以及它们在改变不同应用领域的潜力，从而让读者全面了解基于 Transformer 的法学硕士在实际应用中的当前和未来前景。]]></description>
      <guid>https://arxiv.org/abs/2403.18969</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>衡量大型语言模型中的政治偏见：说什么以及如何说</title>
      <link>https://arxiv.org/abs/2403.18932</link>
      <description><![CDATA[arXiv:2403.18932v1 公告类型：新
摘要：我们建议通过分析法学硕士生成的有关政治问题的内容的内容和风格来衡量法学硕士的政治偏见。现有的基准和措施侧重于性别和种族偏见。然而，法学硕士存在政治偏见，可能导致下游申请中的两极分化和其他危害。为了向用户提供透明度，我们主张应该对法学硕士产生的政治偏见采取细粒度且可解释的措施。我们提出的措施着眼于不同的政治问题，例如生殖权利和气候变化，以及这种偏见的内容（一代人的实质内容）和风格（词汇极性）。我们测量了十一个开源法学硕士的政治偏见，并表明我们提出的框架可以轻松扩展到其他主题并且是可解释的。]]></description>
      <guid>https://arxiv.org/abs/2403.18932</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>SemEval 任务 1：非洲和亚洲语言的语义文本相关性</title>
      <link>https://arxiv.org/abs/2403.18933</link>
      <description><![CDATA[arXiv:2403.18933v1 公告类型：新
摘要：我们提出了第一个关于语义文本相关性（STR）的共享任务。虽然早期的共享任务主要关注语义相似性，但我们反而研究了 14 种语言之间更广泛的语义相关性现象：南非荷兰语、阿尔及利亚阿拉伯语、阿姆哈拉语、英语、豪萨语、印地语、印度尼西亚语、基尼亚卢旺达语、马拉地语、摩洛哥阿拉伯语、现代标准阿拉伯语、旁遮普语、西班牙语和泰卢固语。这些语言起源于五个不同的语系，主要在非洲和亚洲使用，这些地区的 NLP 资源相对有限。数据集中的每个实例都是与分数相关联的句子对，该分数表示两个句子之间的语义文本相关程度。参与系统被要求按照 14 种语言的含义接近度（即语义相关程度）对句子对进行排名，分三个主要轨道：(a) 监督、(b) 无监督和 (c) 跨语言。该任务吸引了163名参与者。我们总共收到了来自 51 个不同团队的 70 份提交（涵盖所有任务）以及 38 篇系统描述论文。我们报告了三个不同轨道上性能最佳的系统以及最常见和最有效的方法。]]></description>
      <guid>https://arxiv.org/abs/2403.18933</guid>
      <pubDate>Fri, 29 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    </channel>
</rss>