<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 22 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用于数据注释的大型语言模型：调查</title>
      <link>https://arxiv.org/abs/2402.13446</link>
      <description><![CDATA[arXiv:2402.13446v1 公告类型：新
摘要：数据注释是用相关信息对原始数据进行标记或标记，对于提高机器学习模型的效率至关重要。然而，该过程是劳动密集型且昂贵的。以 GPT-4 为代表的高级大型语言模型 (LLM) 的出现为彻底改变和自动化复杂的数据注释过程提供了前所未有的机会。虽然现有的调查广泛涵盖了法学硕士架构、培训和一般应用，但本文特别关注它们在数据注释方面的具体用途。这项调查致力于三个核心方面：基于 LLM 的数据注释、评估 LLM 生成的注释以及使用 LLM 生成的注释进行学习。此外，本文还对采用法学硕士进行数据注释的方法进行了深入的分类，对结合法学硕士生成的注释的模型的学习策略进行了全面回顾，并详细讨论了与使用法学硕士进行数据注释相关的主要挑战和限制。作为一个关键指南，这项调查旨在指导研究人员和从业者探索最新法学硕士在数据注释方面的潜力，促进这一关键领域的未来进步。我们在 \url{https://github.com/Zhen-Tan-dmml/LLM4Annotation.git} 提供了全面的论文列表。]]></description>
      <guid>https://arxiv.org/abs/2402.13446</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>ED-Copilot：通过语言模型诊断协助减少急诊科等待时间</title>
      <link>https://arxiv.org/abs/2402.13448</link>
      <description><![CDATA[arXiv:2402.13448v1 公告类型：新
摘要：在急诊室（ED），患者在诊断前接受分诊和多项实验室检查。这个过程非常耗时，并且会导致急诊室拥挤，从而显着影响患者死亡率、医疗错误、员工倦怠等。这项工作提出了（时间）成本效益高的诊断援助，探索人工智能 (AI) 系统在协助急诊室方面的潜力临床医生能够做出省时、准确的诊断。利用公开的患者数据，我们与急诊科临床医生合作制定 MIMIC-ED-Assist，这是一个基准，用于衡量人工智能系统建议实验室测试的能力，以最大限度地减少急诊室等待时间，同时正确预测死亡等关键结果。我们开发了 ED-Copilot，它可以依次建议患者特定的实验室测试并做出诊断预测。 ED-Copilot 使用预先训练的生物医学语言模型对患者信息和强化学习进行编码，以最大限度地减少 ED 等待时间并最大限度地提高关键结果的预测准确性。在 MIMIC-ED-Assist 上，ED-Copilot 提高了基线的预测准确性，同时将平均等待时间从 4 小时减少到 2 小时。消融研究证明了模型规模和生物医学语言模型使用的重要性。进一步的分析揭示了个性化实验室测试建议对于诊断重症患者的必要性，以及 ED-Copilot 在为 ED 临床医生提供信息丰富的实验室测试建议方面的潜力。我们的代码可在 https://github.com/cxcscmu/ED-Copilot 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.13448</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>CAMELoT：迈向具有免训练巩固联想记忆的大型语言模型</title>
      <link>https://arxiv.org/abs/2402.13449</link>
      <description><![CDATA[arXiv:2402.13449v1 公告类型：新
摘要：由于内存和运行时成本较高，大型语言模型（LLM）难以处理长输入序列。记忆增强模型已成为解决这一问题的有希望的解决方案，但当前的方法受到有限的记忆容量的阻碍，并且需要昂贵的重新训练才能与新的法学硕士集成。在这项工作中，我们引入了一个关联记忆模块，它可以耦合到任何预训练（冻结）的基于注意力的 LLM，无需重新训练，使其能够处理任意长的输入序列。与以前的方法不同，我们的关联记忆模块将各个标记的表示合并到非参数分布模型中，通过适当平衡传入数据的新颖性和新近性来动态管理。通过从这种整合的联想记忆中检索信息，与在标准基准上评估的其他基线相比，基础法学硕士可以在长上下文建模中显着降低困惑度（在 Arxiv 上高达 29.7%）。这种架构，我们称之为 CAMELoT（统一关联记忆增强型长变换器），即使在 128 个标记的微小上下文窗口中也能展现出卓越的性能，并且还可以通过更大的演示集来改进上下文学习。]]></description>
      <guid>https://arxiv.org/abs/2402.13449</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>解释研究论文之间的关系</title>
      <link>https://arxiv.org/abs/2402.13426</link>
      <description><![CDATA[arXiv:2402.13426v1 公告类型：新
摘要：由于研究发表的速度很快，即使使用日常提要工具，跟上所有最新的相关论文也是非常耗时的。需要自动生成、简短、定制的论文集文献综述，以帮助研究人员决定阅读哪些内容。虽然过去十年中的几部著作都解决了解释一篇研究论文的任务，但通常是在另一篇论文引用它的背景下，多篇论文之间的关系却被忽视了；先前的工作侧重于单独生成单个引文句子，而没有解决在连贯的故事中连接多篇论文所需的说明性句子和过渡句。在这项工作中，我们探索了一种基于特征的 LLM 提示方法来生成更丰富的引文文本，以及一次生成多个引文以捕获研究论文之间的复杂关系。我们进行了专家评估，以调查我们提出的特征对生成段落质量的影响，并发现人类偏好和综合写作风格之间存在很强的相关性，这表明人类更喜欢高级的、抽象的引用，以及它们之间的过渡句子提供一个整体的故事。]]></description>
      <guid>https://arxiv.org/abs/2402.13426</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>DrBenchmark：法国生物医学领域大型语言理解评估基准</title>
      <link>https://arxiv.org/abs/2402.13432</link>
      <description><![CDATA[arXiv:2402.13432v1 公告类型：新
摘要：生物医学领域引发了人们对自然语言处理（NLP）领域的浓厚兴趣，预训练语言模型（PLM）在该领域取得了实质性进展。然而，由于不同模型的评估协议存在差异，比较这些模型已被证明具有挑战性。一个公平的解决方案是将不同的下游任务聚合到一个基准中，以便从不同的角度评估 PLM 的内在质量。尽管仍仅限于少数语言，但这一举措已在生物医学领域开展，特别是英语和中文。这种限制阻碍了对最新法国生物医学模型的评估，因为它们要么使用非标准化协议对最少数量的任务进行评估，要么使用一般下游任务进行评估。为了弥补这一研究差距并考虑到法语的独特敏感性，我们推出了第一个公开的法语生物医学语言理解基准，称为 DrBenchmark。它包含 20 种多样化的任务，包括命名实体识别、词性标注、问答、语义文本相似度和分类。我们根据一般数据和生物医学特定数据评估 8 个最先进的预训练掩蔽语言模型 (MLM)，以及英语特定的 MLM，以评估其跨语言能力。我们的实验表明，没有一个模型能够胜任所有任务，而通才模型有时仍然具有竞争力。]]></description>
      <guid>https://arxiv.org/abs/2402.13432</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>用于评估（语音）选区解析的结构化树对齐</title>
      <link>https://arxiv.org/abs/2402.13433</link>
      <description><![CDATA[arXiv:2402.13433v1 公告类型：新
摘要：我们提出了结构化平均交并比（STRUCT-IOU），这是一种由评估语音解析器问题引发的选区解析树之间的相似性度量。 STRUCT-IOU 可以在选区解析树（在自动识别的口头单词边界上）与真实解析（在书面单词上）之间进行比较。为了计算度量，我们通过强制对齐将真实解析树投影到语音域，在某些结构化约束下将投影的真实成分与预测成分对齐，并计算所有对齐成分对的平均 IOU 分数。 STRUCT-IOU 考虑了单词边界，克服了预测单词和真实值可能不具有完美的一一对应关系的挑战。扩展到文本选区解析的评估，我们证明 STRUCT-IOU 对语法上合理的解析表现出比 PARSEVAL 更高的容忍度（Black 等人，1991）。]]></description>
      <guid>https://arxiv.org/abs/2402.13433</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>医疗保健副驾驶：激发普通法学硕士进行医疗咨询的力量</title>
      <link>https://arxiv.org/abs/2402.13408</link>
      <description><![CDATA[arXiv:2402.13408v1 公告类型：新
摘要：copilot 框架旨在为特定的复杂任务增强和定制大型语言模型（LLM），而不需要进行微调，正受到社区越来越多的关注。在本文中，我们介绍了一个专为医疗咨询而设计的医疗副驾驶的构建。拟议的医疗保健副驾驶由三个主要部分组成：1）对话部分，负责有效和安全的患者互动； 2）Memory组件，存储当前对话数据和历史患者信息； 3) 处理组件，总结整个对话并生成报告。为了评估拟议的医疗保健副驾驶，我们使用 ChatGPT 实施自动评估方案，扮演两个角色：作为与副驾驶对话的虚拟患者，以及作为评估对话质量的评估者。大量结果表明，拟议的医疗保健副驾驶显着增强了普通法学硕士在医疗咨询方面的询问能力、对话流畅性、反应准确性和安全性方面的能力。此外，我们还进行消融研究，以突出医疗保健副驾驶中每个单独模块的贡献。代码将在 GitHub 上公开发布。]]></description>
      <guid>https://arxiv.org/abs/2402.13408</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>结构引导提示：通过探索文本的图形结构指导大型语言模型进行多步推理</title>
      <link>https://arxiv.org/abs/2402.13415</link>
      <description><![CDATA[arXiv:2402.13415v1 公告类型：新
摘要：虽然大型语言模型（LLM）擅长解决简单的推理任务，但由于一系列因素而面临更复杂的多步骤推理时，它们经常遇到困难。首先，自然语言通常包含实体之间的复杂关系，这使得在较长跨度内保持清晰的推理链具有挑战性。其次，丰富的语言多样性意味着相同的实体和关系可以使用不同的术语和结构来表达，从而使识别和建立多条信息之间的联系的任务变得复杂。图提供了一种有效的解决方案来表示富含关系信息的数据并捕获实体之间的长期依赖关系。为了利用图的潜力，我们的论文引入了结构引导提示，这是一种创新的三阶段任务无关提示框架，旨在提高法学硕士在零样本设置中的多步推理能力。该框架通过法学硕士明确地将非结构化文本转换为图表，并指示他们使用特定于任务的策略来导航该图表以制定响应。通过有效地组织信息和指导导航，它使法学硕士能够提供更准确和上下文感知的响应。我们的实验表明，该框架显着增强了法学硕士的推理能力，使他们能够在更广泛的自然语言场景中表现出色。]]></description>
      <guid>https://arxiv.org/abs/2402.13415</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>EvoGrad：与人类对手一起动态应对 Winograd 模式挑战</title>
      <link>https://arxiv.org/abs/2402.13372</link>
      <description><![CDATA[arXiv:2402.13372v1 公告类型：新
摘要：虽然大型语言模型 (LLM) 在 Winograd 模式挑战 (WSC) 中表现出色，这是一项通过代词消歧来测试常识推理的共指解析任务，但它们在处理具有细微更改或改写特征的实例时遇到了困难。为了解决这个问题，我们引入了 EvoGrad，这是一个开源平台，它利用人机交互方法来创建针对此类改变的 WSC 实例量身定制的动态数据集。利用 ChatGPT 的功能，我们将任务实例从 182 个扩展到 3,691 个，为多样化的常识推理数据集树立了新的基准。此外，我们引入了错误深度度量，评估动态任务中的模型稳定性。我们的结果强调了 EvoGrad 带来的挑战：即使是表现最好的 LLM GPT-3.5，也能达到 65.0% 的准确率，平均误差深度为 7.2，这与人类在没有扰动误差的情况下 92. 8% 的准确率形成鲜明对比。这凸显了持续存在的模型局限性以及动态数据集在发现这些局限性方面的价值。]]></description>
      <guid>https://arxiv.org/abs/2402.13372</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>用于面向任务的对话系统的可靠的基于 LLM 的用户模拟器</title>
      <link>https://arxiv.org/abs/2402.13374</link>
      <description><![CDATA[arXiv:2402.13374v1 公告类型：新
摘要：在对话系统领域，用户模拟技术已经成为游戏规则改变者，重新定义了面向任务的对话（TOD）系统的评估和增强。这些方法对于复制真实的用户交互、实现合成数据增强、错误检测和稳健评估等应用至关重要。然而，现有的方法通常依赖于严格的基于规则的方法或注释数据。本文介绍了 DAUS，一种领域感知用户模拟器。利用大型语言模型，我们根据面向任务的对话的真实示例对 DAUS 进行微调。两个相关基准的结果显示了用户目标实现方面的显着改进。值得注意的是，我们观察到微调增强了模拟器与用户目标的一致性，有效地减轻了幻觉——这是模拟器响应不一致的主要根源。]]></description>
      <guid>https://arxiv.org/abs/2402.13374</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>用于实体集扩展和分类扩展的统一分类引导指令调优框架</title>
      <link>https://arxiv.org/abs/2402.13405</link>
      <description><![CDATA[arXiv:2402.13405v1 公告类型：新
摘要：实体集扩展、分类法扩展和种子引导分类法构建是三个代表性任务，可用于自动用新实体填充现有分类法。然而，以前的方法通常使用异构技术分别解决这些任务，缺乏统一的视角。为了解决这个问题，在本文中，我们从分类结构的角度确定了这些任务所需的共同关键技能——寻找“兄弟姐妹”和寻找“父母”——并提出了一个统一的分类引导的指令调整框架，以共同解决三项任务。具体来说，通过利用现有的分类法作为实体关系的丰富来源，我们利用指令调整来微调大型语言模型以生成父实体和兄弟实体。对多个基准数据集的大量实验证明了 TaxoInstruct 的有效性，它在所有三个任务中都优于特定于任务的基线。]]></description>
      <guid>https://arxiv.org/abs/2402.13405</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>PIRB：波兰密集和混合文本检索方法的综合基准</title>
      <link>https://arxiv.org/abs/2402.13350</link>
      <description><![CDATA[arXiv:2402.13350v1 公告类型：新
摘要：我们提出了波兰语信息检索基准（PIRB），这是一个包含 41 项波兰语文本信息检索任务的综合评估框架。该基准包含现有数据集以及 10 个之前未发布的新数据集，涵盖医学、法律、商业、物理和语言学等不同主题。我们对 20 多种密集和稀疏检索模型进行了广泛的评估，包括我们训练的基线模型以及其他可用的波兰语和多语言方法。最后，我们介绍了一个训练高效特定语言检索器的三步过程，包括知识蒸馏、监督微调和使用轻量级重新评分模型构建稀疏-密集混合检索器。为了验证我们的方法，我们训练新的波兰语文本编码器，并将其结果与之前评估的方法进行比较。我们的密集模型优于迄今为止最好的解决方案，并且混合方法的使用进一步提高了其性能。]]></description>
      <guid>https://arxiv.org/abs/2402.13350</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>改进信息提取结构化语言模型输出的简单而有效的方法</title>
      <link>https://arxiv.org/abs/2402.13364</link>
      <description><![CDATA[arXiv:2402.13364v1 公告类型：新
摘要：大型语言模型（LLM）在根据指令生成非结构化自然语言方面表现出了令人印象深刻的能力。然而，当负责生成符合特定结构化格式的文本时，它们的性能可能不一致，这在命名实体识别 (NER) 或关系提取 (RE) 等应用中至关重要。为了解决这个问题，本文介绍了一种有效的方法 G&amp;O，来增强其结构化文本生成能力。它将生成过程分为两步：最初，法学硕士以自然语言生成答案作为中间响应。随后，法学硕士被要求使用中间响应作为上下文，将输出组织成所需的结构。 G&amp;O 有效地将内容生成与结构化过程分开，减少了同时完成两个正交任务的压力。在零样本 NER 和 RE 上进行测试，结果表明，以最少的额外努力即可显着提高 LLM 性能。这种简单且适应性强的提示技术还可以与其他策略（例如自我一致性）相结合，以进一步提升法学硕士在各种结构化文本生成任务中的能力。]]></description>
      <guid>https://arxiv.org/abs/2402.13364</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>通过语义词汇资源增强现代监督词义消歧模型</title>
      <link>https://arxiv.org/abs/2402.13302</link>
      <description><![CDATA[arXiv:2402.13302v1 公告类型：新
摘要：词义消歧（WSD）的监督模型目前在最流行的基准测试中取得了最先进的结果。尽管最近引入了词嵌入和循环神经网络来设计强大的上下文相关功能，但使用语义词汇资源（SLR）改进 WSD 模型的兴趣主要局限于基于知识的方法。在本文中，我们利用两种流行的 SLR：WordNet 和 WordNet Domains 增强了“现代”监督 WSD 模型。我们提出了一种将语义特征引入分类器的有效方法，并考虑使用 SLR 结构来增强训练数据。我们研究不同类型语义特征的影响，研究它们与通过词嵌入或循环神经网络混合编码的本地上下文的交互，并将所提出的模型扩展为 WSD 的新型多层架构。最近的统一评估框架（Raganato et al., 2017）中的详细实验比较表明，所提出的方法导致监督模型与最先进的技术相媲美。]]></description>
      <guid>https://arxiv.org/abs/2402.13302</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>通过简单的检测器聚合增强神经机器翻译中的幻觉检测</title>
      <link>https://arxiv.org/abs/2402.13331</link>
      <description><![CDATA[arXiv:2402.13331v1 公告类型：新
摘要：在机器翻译系统的实际部署中，幻觉翻译会带来重大威胁和安全问题。先前的研究工作已经发现，探测器表现出互补的性能，不同的探测器擅长探测不同类型的幻觉。在本文中，我们建议通过组合单个检测器并引入一种聚合多个检测器的简单方法来解决单个检测器的局限性。我们的结果证明了聚合检测器的有效性，为迈向更加可靠的机器翻译系统迈出了有希望的一步。]]></description>
      <guid>https://arxiv.org/abs/2402.13331</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:31 GMT</pubDate>
    </item>
    </channel>
</rss>