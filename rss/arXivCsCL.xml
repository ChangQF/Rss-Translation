<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Tue, 15 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>相似深度的层在LLM架构上产生类似的激活</title>
      <link>https://arxiv.org/abs/2504.08775</link>
      <description><![CDATA[ARXIV：2504.08775V1公告类型：新 
摘要：独立训练的LLM使用的潜在空间彼此之间有何关系？我们研究了24个开放量LLM的不同层的激活引起的最近的邻居关系，发现它们1）倾向于在模型中的一层倾向于不同，而2）在不同模型的相应层之间大约共享。权利要求2显示，这些最近的邻居关系不是任意的，因为它们在模型中共享，但是权利要求1表明它们也不是“显而易见的”，因为没有普遍共享的一组最近的邻居关系。总之，这些表明LLM会产生激活几何形状的进程，但是整个进展在很大程度上是在模型之间共享的，并伸展和挤压以适合不同的体系结构。]]></description>
      <guid>https://arxiv.org/abs/2504.08775</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Semcafe：命名实体通过实体级别分析评估Web源可靠性时有所不同</title>
      <link>https://arxiv.org/abs/2504.08776</link>
      <description><![CDATA[ARXIV：2504.08776V1公告类型：新 
摘要：随着从传统媒体转变为数字媒体，在线景观现在不仅托管了可靠的新闻文章，而且还提供大量不可靠的内容。数字媒体通过显着影响公众舆论并推进政治议程的速度更快。虽然报纸读者可能熟悉他们喜欢的媒体政治倾向或信誉，但确定不可靠的新闻文章更具挑战性。许多在线资源的信誉通常是不透明的，AI产生的内容很容易以最低的成本传播。不可靠的新闻文章，特别是那些在2022年俄罗斯入侵乌克兰之后的文章，密切模仿了可信资料的主题和写作风格，这使得它们难以区分。为了解决这个问题，我们介绍了Semcafe，该系统旨在通过将实体相关性纳入其评估中来检测新闻可靠性。 Semcafe采用标准的自然语言处理技术，例如除外板和令牌化，以及使用Yago知识库的实体级别的语义分析。通过为每本新闻文章创建语义指纹，Semcafe可以评估2022年2022年俄罗斯入侵乌克兰的46,020条可靠和3,407篇不可靠文章的信誉。我们的方法将宏F1得分提高了12％。示例数据和代码可在GitHub上找到]]></description>
      <guid>https://arxiv.org/abs/2504.08776</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从代币到晶格：语言模型中的新兴晶格结构</title>
      <link>https://arxiv.org/abs/2504.08778</link>
      <description><![CDATA[ARXIV：2504.08778V1公告类型：新 
摘要：经过验证的蒙版语言模型（MLMS）表现出了理解和编码概念知识的令人印象深刻的能力，揭示了概念之间的晶格结构。这引发了一个关键的问题：该概念化如何从传销预处理中出现？在本文中，我们从形式概念分析（FCA）的角度探讨了这个问题，这是一个数学框架，它从对象属性关系的观察结果中得出了概念晶格。我们表明，MLM的目标隐含地学习了一个描述对象，属性及其依赖性的\ Emph {正式上下文}，从而可以通过FCA重建概念晶格。我们提出了一个新颖的框架，用于从预算的MLM中构建概念晶格的结构，并研究MLMS在晶格结构学习中的电感偏见的起源。我们的框架与以前的工作不同，因为它不依赖于人类定义的概念，而允许发现超越人类定义的“潜在”概念。我们创建了三个用于评估的数据集，经验结果验证了我们的假设。]]></description>
      <guid>https://arxiv.org/abs/2504.08778</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI主建筑管理（CM）可以吗？基准在CM认证考试中基准的最先进的语言模型</title>
      <link>https://arxiv.org/abs/2504.08779</link>
      <description><![CDATA[ARXIV：2504.08779V1公告类型：新 
摘要：建筑管理（CM）项目的复杂性日益增长，再加上严格的监管要求和劳动力短缺等挑战，需要专门的分析工具来简化项目工作流程并提高绩效。尽管大型语言模型（LLMS）在一般推理任务中表现出了出色的表现，但它们在应对CM特定挑战（例如精确的定量分析和监管解释）方面的有效性仍然不足。为了弥合这一差距，这项研究介绍了CMEXAMSET，这是一个全面的基准测试数据集，其中包括689个真实的多项选择问题，这些问题源自四项全国认可的CM认证考试。我们的零射门评估评估了总体准确性，主题领域（例如施工安全性），推理复杂性（单步和多步）以及问题格式（仅本文，图形参考和桌面引用）。结果表明，GPT-4O和Claude 3.7超过典型的人通过阈值（70％），平均精度分别为82％和83％。此外，这两个模型在单步任务上的表现都更好，精度为85.7％（GPT-4O）和86.7％（Claude 3.7）。多步任务更具挑战性，将绩效降低到76.5％和77.6％。此外，两个LLM都对图形引用的问题均显示出显着局限性，精度下降到约40％。我们的错误模式分析进一步表明，概念上的误解是最常见的（44.4％和47.9％），强调了对增强域特异性推理模型的需求。这些发现强调了LLM作为CM中有价值的补充分析工具的潜力，同时强调了对特定领域的改进的需求，并在复杂的决策中持续了人类的监督。]]></description>
      <guid>https://arxiv.org/abs/2504.08779</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过协作过滤对大语言模型的有效评估</title>
      <link>https://arxiv.org/abs/2504.08781</link>
      <description><![CDATA[ARXIV：2504.08781V1公告类型：新 
摘要：随着大语言模型（LLM）的发展，已经提出了许多基准测量和比较不同LLM的功能。但是，由于大量的测试实例及其缓慢的推理速度，评估LLM的昂贵。在本文中，我们旨在探讨如何根据其从基准中采样的少数实例进行评估结果，在给定基准上有效估计模型的真实性能。受推荐系统（RS）中协作过滤（CF）的启发，我们将LLM视为用户，并将测试实例视为项目，并提出了两阶段的方法。在第一阶段，我们将实例选择视为向用户推荐产品，以选择可以轻松区分模型性能的实例。在第二阶段，我们将性能预测视为RS中的评级预测问题，以预测目标LLM在未选择实例上的行为。在多个LLM和数据集上进行的实验表明，我们的方法可以准确估算目标模型的性能，同时在很大程度上减少其推理开销。]]></description>
      <guid>https://arxiv.org/abs/2504.08781</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用跨语性数据增强来提高低资源巴基斯坦语言的NER性能</title>
      <link>https://arxiv.org/abs/2504.08792</link>
      <description><![CDATA[ARXIV：2504.08792V1公告类型：新 
摘要：命名实体识别（NER）是自然语言处理（NLP）的基本任务（NLP），已显示出高资源语言的重大进步。但是，由于缺乏注释的数据集和预训练的语言模型（PLM）的有限表示，因此对低资源语言的研究仍在研究且具有挑战性。为了应对这些挑战，我们提出了一种数据增强技术，该技术在四种低资源巴基斯坦语言上产生了具有文化合理的句子和实验；乌尔都语，沙木，信德和帕什托。通过微调多语言掩盖的大语言模型（LLM），我们的方法表现出Shahmukhi和Pashto的NER性能的显着改善。我们进一步探讨了生成LLM的NER和数据增强功能。]]></description>
      <guid>https://arxiv.org/abs/2504.08792</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索梯度引导的蒙版语言模型以检测文本对抗攻击</title>
      <link>https://arxiv.org/abs/2504.08798</link>
      <description><![CDATA[ARXIV：2504.08798V1公告类型：新 
摘要：文本对抗示例对自然语言处理系统的可靠性构成了严重威胁。最近的研究表明，对抗性例子往往会偏离正常文本的基本流形，而预先训练的蒙版语言模型可以近似正常数据的歧管。这些发现激发了探索蒙版语言模型，以检测文本对抗性攻击。我们首先介绍了基于语言模型的检测（MLMD），利用掩盖语言建模（MLM）目标的掩盖和操作来诱导正常文本和对抗文本之间的多种变化差异。尽管MLMD达到了竞争性检测性能，但其详尽的一对一掩蔽策略仍引入了重要的计算开销。我们的后验分析表明，输入中的大量非关键词对于检测而言并不重要，而是消耗资源。在此基础上，我们介绍了梯度引导的MLMD（GradMLMD），该MLMD（GradMLMD）利用梯度信息在检测过程中识别和跳过非关键词，从而在不损害检测性能的情况下大大降低了资源消耗。]]></description>
      <guid>https://arxiv.org/abs/2504.08798</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索基于LLM的时间序列模型中文本的有效性和解释性</title>
      <link>https://arxiv.org/abs/2504.08808</link>
      <description><![CDATA[ARXIV：2504.08808V1公告类型：新 
摘要：大型语言模型（LLM）已应用于时间序列预测任务，利用预训练的语言模型作为骨干，并将文本数据合并到据称增强了LLMS在时间序列上的全面功能。但是，这些文本对解释真的有帮助吗？这项研究旨在研究此类文本合并的实际功效和解释性。通过一系列关于文本提示和文本原型的经验实验，我们的发现表明，存在两种方式之间的错位，并且文本信息在许多情况下并不能显着改善时间序列的预测性能。此外，可视化分析表明，现有框架学到的文本表示，当应用于时间序列数据时缺乏足够的解释性。我们进一步提出了一个名为语义匹配索引（SMI）的新型度量，以更好地评估我们事后解释性调查期间时间序列和文本之间的匹配度。我们的分析揭示了当前时间序列LLM中文本的不对对准和有限的解释性，我们希望这项研究能够提高人们对时间序列文本的解释性的认识。该代码可在https://github.com/zachysun/ts-lang-exp上获得。]]></description>
      <guid>https://arxiv.org/abs/2504.08808</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Caredio：通过代表性和独特性指导数据优化的LLM文化对准</title>
      <link>https://arxiv.org/abs/2504.08820</link>
      <description><![CDATA[ARXIV：2504.08820V1公告类型：新 
摘要：随着大型语言模型（LLM）更深入地融入各个地区的人类生活，将它们与多元文化保持一致，对于改善用户体验和减轻文化冲突至关重要。现有的方法主要是通过大量精心策划的特定文化特定的语料库进行微调来发展文化统一的LLM。然而，受文化理论的启发，我们确定了这些数据集面临的两个主要挑战：（1）代表性：这些语料库未能完全捕获目标文化的核心特征，从而导致计算浪费； （2）独特性：他们努力将给定文化的独特细微差别与其他相关模式的共同模式区分开来，阻碍了精确的文化建模。为了应对这些挑战，我们介绍了一种新型的文化数据构建框架Caredio。具体而言，Caredio利用强大的LLM自动生成文化对话数据，在该数据中，查询和响应都可以通过最大化代表性和独特性来进一步优化。使用Caredio，我们构建了一个小而有效的数据集，涵盖了五种文化，并将其与最近的几个文化语料库进行了比较。广泛的实验表明，我们的方法会产生更有效的数据，并实现了只有100个培训样本的文化对准，从而提高了性能和效率。]]></description>
      <guid>https://arxiv.org/abs/2504.08820</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SD $^2 $：自dielded稀疏起草者</title>
      <link>https://arxiv.org/abs/2504.08838</link>
      <description><![CDATA[ARXIV：2504.08838V1公告类型：新 
摘要：投机解码是减少大语言模型（LLMS）潜伏期的强大技术，提供了容忍故障的框架，该框架能够使用高度压缩的草稿模型。在这项工作中，我们引入了自缩稀疏的稀疏起草人（SD $^2 $），这是一种新型方法，它利用自DATA蒸馏和细颗粒的重量稀疏性，以产生高效且良好的草稿模型。 SD $^2 $系统地增强了令牌的接受率，同时显着降低了多重蓄能操作（MAC），即使在通用辅助生成（UAG）设置中，草稿和目标模型来自不同的模型系列。在Llama-3.1-70B目标模型上，SD $^2 $提供了$ \ times $ 1.59的平均接收长度（MAL），与层 - 预截止的草稿型号相比，MAL与密集的型号相比，MAL降低了8.36％。我们的结果突出了稀疏感知微调和压缩策略的潜力，以提高LLM推理效率，同时保持与目标模型的一致性。]]></description>
      <guid>https://arxiv.org/abs/2504.08838</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过对话的预测沟通出轨</title>
      <link>https://arxiv.org/abs/2504.08905</link>
      <description><![CDATA[ARXIV：2504.08905V1公告类型：新 
摘要：预测沟通脱轨在现实世界中可能很有用，例如在线内容审核，冲突解决和业务谈判。但是，尽管语言模型在确定对话中存在的令人反感的演讲方面取得了成功，但他们仍在努力预测未来的沟通出轨。与以前的工作仅根据过去的对话历史来预测对话结果的先前工作相反，我们的方法采样了以后的多个对话轨迹，该对话轨迹是根据现有的对话历史记录的，使用微调的LLM进行了示例。它根据这些轨迹的共识来预测沟通结果。我们还试验了利用社会语言属性，这些属性反映了转向级的对话动态，作为引起未来对话时的指导。我们未来的对话轨迹的方法超过了英语交流出轨预测基准的最新结果，并且在消融研究中表现出显着的准确性提高。]]></description>
      <guid>https://arxiv.org/abs/2504.08905</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过LLM为开放式编程练习生成计划反馈</title>
      <link>https://arxiv.org/abs/2504.08958</link>
      <description><![CDATA[ARXIV：2504.08958V1公告类型：新 
摘要：要完成开放式的编程练习，学生需要计划高级解决方案并使用适当的语法实施它。但是，这些问题通常是根据测试案例提交的最终提交的正确性而自动化的，并且学生无法获得其计划过程的反馈。大型语言模型（LLM）可能能够通过检测到语法错误提交的总体代码结构来生成此反馈。为此，我们提出了一种检测使用LLMS的学生计划中存在哪些高级目标和模式（即编程计划）的方法。我们表明，完整的GPT-4O模型和小型变体（GPT-4O-MINI）都可以以显着的精度检测这些计划，超过了受传统代码分析方法启发的基线。我们进一步表明，较小，成本效益的变体（GPT-4O-MINI）在微调后与最先进的（GPT-4O）取得了相当的结果，从而对实时分级产生了有希望的含义。这些较小的型号可以将其纳入自动化器中，以进行开放式代码编写练习，以便为学生的隐式计划技能提供反馈，即使他们的程序在句法上不正确。此外，LLM可能在为学生开始以一组高级解决方案步骤开始并迭代计算输出（例如数学和物理问题）的其他领域的问题可能有用。]]></description>
      <guid>https://arxiv.org/abs/2504.08958</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对话性话语注释的全自动管道：树木方案生成和标签大型语言模型</title>
      <link>https://arxiv.org/abs/2504.08961</link>
      <description><![CDATA[ARXIV：2504.08961V1公告类型：新 
摘要：大语言模型（LLMS）的最新进展已显示出对对话的话语注释自动化的希望。虽然手动设计树注释方案可显着提高人类和模型的注释质量，但它们的创造仍然耗时，需要专业知识。我们提出了一种全自动管道，该管道使用LLMS构建此类方案并执行注释。我们评估了语音功能（SFS）和DAMSL（SWBD-DAMSL）分类法的方法。我们的实验比较了各种设计选择，我们表明频率引导的决策树与高级LLM配对以注释，可以胜过以前手动设计的树，甚至匹配或超过人体注释，同时大大减少注释所需的时间。我们发布所有代码和结果方案以及注释，以促进对话语注释的未来研究。]]></description>
      <guid>https://arxiv.org/abs/2504.08961</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从打孔线到预测：评估LLM表现时识别幽默的指标</title>
      <link>https://arxiv.org/abs/2504.09049</link>
      <description><![CDATA[ARXIV：2504.09049V1公告类型：新 
摘要：喜剧是我们生活时代的深刻反映，是人类互动的主食。鉴于大型语言模型（LLM）的广泛采用，幽默和AI的交集并没有笑。人类计算机互动的自然性的进步与AI系统能力理解幽默的能力的改善相关。在这项研究中，我们评估了模型准确地识别出幽默引号的能力。站立喜剧独特的喜剧叙事使其成为提高喜剧理解的整体自然性的理想数据集。我们提出了一种新型的幽默检测指标，旨在评估各种提示之间的LLM，以提取幽默的打孔线。该指标具有模块化结构，该结构提供了三种不同的评分方法 - 模糊字符串匹配，句子嵌入和子空间相似性 - 可提供对模型性能的总体评估。将模型的结果与同一任务中的人类评估者的结果进行了比较。我们的指标表明，无论迅速的工程，领先的模型，Chatgpt，Claude和Deepseek，幽默检测最多都达到51％。值得注意的是，这种表现超过了成绩41％的人的表现。对人类评估者和LLM的分析揭示了一致性的可变性，强调了幽默固有的主观性以及从实时绩效转录本中提取幽默报价所涉及的复杂性。可在https://github.com/swaggirl9000/humor上获得代码。]]></description>
      <guid>https://arxiv.org/abs/2504.09049</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索叙事文本的计划指导的摘要：小语言模型的情况</title>
      <link>https://arxiv.org/abs/2504.09071</link>
      <description><![CDATA[ARXIV：2504.09071V1公告类型：新 
摘要：计划指导的摘要尝试通过将生成的摘要接地到源文本中，以减少小语言模型（SLM）的幻觉，通常是通过针对细粒细节（例如日期或命名实体）来减少源文字的摘要。在这项工作中，我们研究了SLM中基于计划的方法是否改善了长期文档，叙事任务的摘要。叙事文本的长度和复杂性通常意味着它们很难忠实地总结。我们分析针对细粒细节的现有计划引导的解决方案，并提出我们自己的高级，基于叙事的计划制定。我们的结果表明，在不计划即将质量或忠诚的情况下，这两种方法都在基线上都无法显着改善。人类评估表明，尽管计划指导的方法通常符合其计划，但与摘要相比，计划同样有可能包含幻觉。结果，计划指导的摘要与没有计划的模型一样不忠。我们的作品是计划指导的总结方法的警示故事，尤其是对于诸如叙事文本之类的长期复杂领域。]]></description>
      <guid>https://arxiv.org/abs/2504.09071</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>