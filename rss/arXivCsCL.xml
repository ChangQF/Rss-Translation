<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Wed, 06 Dec 2023 03:14:47 GMT</lastBuildDate>
    <item>
      <title>重新审视主题引导语言模型。 （arXiv：2312.02331v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.02331</link>
      <description><![CDATA[自然语言处理领域最近的一项工作旨在结合
语言模型和主题模型。这些主题引导的语言模型增强了
具有主题模型的神经语言模型、无监督学习方法
可以发现文档级的单词使用模式。本文比较了
这些方法在标准化环境中的有效性。我们学习四
主题引导的语言模型和两个基线，评估保留的
每个模型在四个语料库上的预测性能。令人惊讶的是，我们发现
这些方法都没有优于标准 LSTM 语言模型基线，
大多数人都无法学习好的主题。此外，我们训练神经探针
显示基线的隐藏状态已经编码的语言模型
主题信息。我们公开了本研究使用的所有代码。
]]></description>
      <guid>http://arxiv.org/abs/2312.02331</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>用于将新闻标题映射到知识图中的事件类的评估框架。 （arXiv：2312.02334v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.02334</link>
      <description><![CDATA[以丰富的知识将持续的新闻头条映射到与事件相关的类
基础可以是基于知识的事件分析的重要组成部分
预测解决方案。在本文中，我们提出了一种创建
映射到维基数据中事件类别的新闻标题基准数据集，以及
用于评估执行映射的方法的资源。我们使用
用于研究此任务的两类无监督方法的数据集：1)
经典实体链接方法的改编，以及 2）处理
问题作为零样本文本分类问题。对于第一种方法，我们
评估现成的实体链接系统。对于第二种方法，我们
探索 a) 预训练的自然语言推理 (NLI) 模型，以及 b)
预先训练的大型生成语言模型。我们展示我们的结果
评价、经验教训和未来工作方向。数据集和
评估脚本已公开。
]]></description>
      <guid>http://arxiv.org/abs/2312.02334</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>测量文本中的分布变化：基于语言模型的嵌入的优势。 （arXiv：2312.02337v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.02337</link>
      <description><![CDATA[在生产中监控机器学习模型的一个重要部分是
测量输入和输出数据漂移。在本文中，我们提出了一个系统
测量自然语言数据的分布变化并突出显示和
研究使用大型语言模型 (LLM) 的潜在优势
这个问题。法学硕士的最新进展及其在以下领域的成功采用
不同的领域表明它们在捕获语义方面的有效性
解决各种自然语言处理问题的关系。这
法学硕士的力量很大程度上来自于生成的编码（嵌入）
相应神经网络的隐藏层。首先我们提出一个
基于聚类的算法，用于测量文本数据的分布变化
利用这种嵌入。然后我们研究我们方法的有效性
当应用于由法学硕士和经典嵌入生成的文本嵌入时
算法。我们的实验表明，基于 LLM 的通用嵌入
与其他嵌入方法相比，它对数据漂移具有较高的敏感性。
我们建议将漂移灵敏度作为一个重要的评估指标，以在以下情况下考虑：
比较语言模型。最后，我们提出见解和经验教训
将我们的框架部署为 Fiddler ML 监控平台的一部分
为期18个月。
]]></description>
      <guid>http://arxiv.org/abs/2312.02337</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>微调用于临床文档解析的预训练提取 QA 模型。 （arXiv：2312.02314v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.02314</link>
      <description><![CDATA[电子健康记录 (EHR) 包含大量高维信息
可以准确代表患者病史的多模态数据。
不幸的是，大多数数据要么是非结构化的，要么是半结构化的，
使其不适合实时和回顾性分析。一个遥控器
心力衰竭 (HF) 患者的患者监测 (RPM) 计划需要具备
获取 EF（射血分数）或 LVEF（左心室射血分数）等临床标志物
心室射血分数）以确定资格和
该计划的适当性。本文解释了一个可以解析的系统
超声心动图报告并验证 EF 值。该系统有助于识别
符合资格的心力衰竭患者可以参加此类计划。在心脏
该系统是一个预先训练的提取 QA 变压器模型，经过微调
关于自定义标记的数据。用于准备部署此类模型的方法
通过在公共临床数据集上运行实验来说明，例如
MIMIC-IV-注。该管道可用于概括类似的解决方案
资源匮乏环境中的问题。我们发现系统保存了1500多个
通过大规模自动化任务，为我们的临床医生节省了超过 12 个月的时间。
]]></description>
      <guid>http://arxiv.org/abs/2312.02314</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>GNN2R：弱监督原理——提供知识图问答。 （arXiv：2312.02317v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.02317</link>
      <description><![CDATA[当前针对知识进行多跳问答 (QA) 的方法
图（KG）仅提供最终结论性答案，而不提供解释，例如
作为普通用户难以查看和查看的一组 KG 实体
理解。这个问题严重限制了基于KG的QA的应用
现实世界的场景。然而，由于两个原因，解决这个问题并不简单
挑战：首先，多跳问题推理链的标注，
可以作为解释生成的监督，通常是
不足。其次，显式KG时很难保持高效率
需要检索三元组来生成解释。在本文中，我们
提出一种新颖的基于图神经网络的两步推理模型（GNN2R）
解决这个问题。 GNN2R 可以提供最终答案和推理子图
作为最终答案背后有效的基本原理，只有弱监督
可通过问题-最终答案对获得。我们广泛评估了
GNN2R 在实验中进行了详细分析。结果表明，在
生成解释的有效性、效率和质量，
GNN2R 优于适用于此的现有最先进方法
任务。我们的代码和预训练模型可在
https://github.com/ruijie-wang-uzh/GNN2R。
]]></description>
      <guid>http://arxiv.org/abs/2312.02317</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>微调语言模型以生成特定于上下文的 SQL 查询。 （arXiv：2312.02251v1 [cs.DB]）</title>
      <link>http://arxiv.org/abs/2312.02251</link>
      <description><![CDATA[从自然语言生成 SQL 查询的能力具有重要意义
对非专业人士访问数据的影响。本文介绍了
一种微调开源大语言模型（LLM）的新方法
将零售业中的自然语言转换为 SQL 查询的任务
领域。我们引入专门生成 SQL 查询的模型，并进行训练
针对 Snowflake SQL 和 GoogleSQL 方言定制的合成数据集。我们的
方法涉及使用 GPT-4 生成特定于上下文的数据集，然后
微调三个开源 LLM（Starcoder Plus、Code-Llama 和 Mistral）
采用 LoRa 技术来优化资源限制。这
微调模型在零样本设置中表现出卓越的性能
与基线 GPT-4 相比，Code-Llama 达到了最高的准确率
比率，Snowflake SQL 为 81.58%，GoogleSQL 为 82.66%。这些结果
强调法学硕士在特定领域任务上的微调的有效性
提出一个有希望的方向，以增强关系的可访问性
通过自然语言接口的数据库。
]]></description>
      <guid>http://arxiv.org/abs/2312.02251</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:44 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士加速医学信息提取注释。 （arXiv：2312.02296v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.02296</link>
      <description><![CDATA[电子健康记录中临床记录的非结构化性质
经常隐藏与患者相关的重要信息，这使得识别患者变得困难
访问或解释。为了发现这个隐藏的信息，专门的自然
需要语言处理 (NLP) 模型。然而，训练这些模型
需要大量标记数据，这个过程既
仅仅依靠人类专家进行注释既耗时又昂贵。
在本文中，我们提出了一种结合大型语言模型的方法
（法学硕士）利用人类专业知识创建一种有效的生成地面的方法
医学文本注释的真值标签。通过结合使用法学硕士
人类注释者，我们显着减少了人类注释负担，使
快速创建标记数据集。我们严格评估我们的方法
医疗信息提取任务，证明我们的方法不仅
大大减少了人为干预，同时保持了较高的准确性。
结果凸显了使用法学硕士提高利用率的潜力
非结构化临床数据，允许快速部署定制的 NLP
医疗保健解决方案。
]]></description>
      <guid>http://arxiv.org/abs/2312.02296</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:44 GMT</pubDate>
    </item>
    <item>
      <title>VaQuitA：增强法学硕士辅助视频理解的一致性。 （arXiv：2312.02310v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02310</link>
      <description><![CDATA[基于语言模型的视频理解的最新进展
在大语言引入的推动下，以惊人的速度进步
模型（法学硕士）。然而，先前的研究重点主要集中在
设计一个将视频特征映射到令牌的投影层，一种方法
这既初级又低效。在我们的研究中，我们引入了一个
尖端框架 VaQuitA，旨在优化视频之间的协同作用
和文字信息。在数据层面，而不是采样帧
我们统一实施以 CLIP-score 排名为指导的抽样方法，该方法
使框架的选择与给定的问题更加一致。在
功能级别，我们将可训练的视频感知器与
Visual-Query Transformer（缩写为 VQ-Former），它支持
输入问题和视频特征之间的相互作用。我们还发现
将一个简单的提示“请批评”纳入 LLM 输入中
可以大幅提升视频理解能力。我们的
实验结果表明 VaQuitA 始终树立了新的基准
适用于零镜头视频问答任务，擅长制作
与用户进行高质量、多轮视频对话。
]]></description>
      <guid>http://arxiv.org/abs/2312.02310</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:44 GMT</pubDate>
    </item>
    <item>
      <title>改进多模态情感分析：基于角裕度的监督对比学习以增强融合表示。 （arXiv：2312.02227v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02227</link>
      <description><![CDATA[模型的有效性很大程度上取决于融合的质量
多模态情感分析中多种模态的表示。
此外，每种模态都是从原始输入中提取并与
休息来构建多模态表示。虽然之前的方法有
提出了多模态表示并取得了可喜的结果，大多数
他们专注于形成正负对，忽略了
同一班级内的情绪分数。此外，他们未能捕捉到
融合向量中单峰表示的重要性。为了解决这些
为了克服这些限制，我们引入了一个名为 Supervised Angular-based 的框架
多模态情感分析的对比学习。该框架旨在
增强多模式表示的区分度和普遍性
并克服融合向量模态中的偏差。我们的实验结果，
以及两个广泛使用的数据集的可视化，展示了
我们的方法的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2312.02227</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:43 GMT</pubDate>
    </item>
    <item>
      <title>递归可视化编程。 （arXiv：2312.02249v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02249</link>
      <description><![CDATA[可视化编程 (VP) 已成为 Visual 的强大框架
问答 (VQA)。通过为每个项目生成并执行定制代码
问题，这些方法展示了令人印象深刻的构图和推理
能力，特别是在少样本和零样本场景中。然而，现有的
VP 方法在单个函数中生成所有代码，从而生成如下代码
在准确性和可解释性方面都不是最佳的。受人类启发
编码实践中，我们提出递归可视化编程（RVP），它
简化生成的例程，提供更有效的问题解决，并且可以
管理更复杂的数据结构。 RVP 的灵感来自于人类编码实践
并使用迭代递归代码生成方法处理 VQA 任务，
允许将复杂的问题分解为更小的部分。值得注意的是，RVP
能够进行动态类型分配，即随着系统递归地
生成一段新的代码，它自主地确定合适的
返回类型并制作必要的代码来生成该输出。我们展示
RVP 的功效是通过对 VSR、COVR、
GQA 和 NextQA，强调了采用类人递归和
通过编码解决 VQA 任务的模块化编程技术。
]]></description>
      <guid>http://arxiv.org/abs/2312.02249</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:43 GMT</pubDate>
    </item>
    <item>
      <title>如何在政府聊天机器人中有效使用生成式人工智能。 （arXiv：2312.02181v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.02181</link>
      <description><![CDATA[随着人工智能的快速发展和突破
机器学习和自然语言处理，智能
问答机器人在政务领域得到广泛应用。这
论文对广东省政府进行了横向比较
聊天机器人ChatGPT和文心Ernie这两个大型语言模型，来分析
现有政府聊天机器人和 AIGC 技术的优点和缺点。
研究发现政府聊天机器人与大型聊天机器人之间存在显着差异
语言模型。中国政务聊天机器人仍处于探索阶段
并有差距要接近才能实现“智能”。探索未来
政府聊天机器人的发展方向更加深入，本研究提出了有针对性的
帮助生成式人工智能在政府中有效应用的优化路径
聊天机器人对话。
]]></description>
      <guid>http://arxiv.org/abs/2312.02181</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:42 GMT</pubDate>
    </item>
    <item>
      <title>视频摘要：走向实体感知字幕。 （arXiv：2312.02188v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02188</link>
      <description><![CDATA[现有流行的视频字幕基准和模型处理通用问题
标题中不含特定的人、地点或组织命名实体。在
相比之下，新闻视频呈现出一个具有挑战性的背景，其中字幕需要
此类命名实体进行有意义的总结。因此，我们提出任务
将新闻视频直接总结为实体感知的字幕。我们还发布了一个
大型数据集 VIEWS（视频新闻）来支持该任务的研究。
此外，我们提出了一种增强视频视觉信息的方法
从外部世界知识中检索上下文以生成实体感知
字幕。我们通过三个视频展示了我们方法的有效性
字幕模型。我们还表明我们的方法可以推广到现有新闻
图像标题数据集。凭借所有广泛的实验和见解，我们
相信我们为未来研究这一具有挑战性的问题奠定了坚实的基础
任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.02188</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:42 GMT</pubDate>
    </item>
    <item>
      <title>长篇问答的公理偏好模型。 （arXiv：2312.02206v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.02206</link>
      <description><![CDATA[像 GPT-4 这样的大型语言模型（LLM）的卓越能力部分
源于训练后过程，例如人类强化学习
反馈（RLHF）涉及奖励模型中编码的人类偏好。然而，
这些奖励模型 (RM) 通常缺乏对原因或在什么情况下的直接了解
原则，偏好注释。在这项研究中，我们确定
指导 RM 更好地符合人类偏好的原则，然后
开发一个公理框架来生成丰富多样的偏好信号
来支持他们。我们使用这些公理信号来训练评分模型
长篇问题的答案。我们的方法产生一个偏好模型，仅
大约 2.2 亿个参数与人工注释的黄金偏好标签一致
比 GPT-4 更常见。这项工作的贡献包括：
独立的偏好模型，可以对人类和法学硕士生成的答案进行评分
相同的规模；开发用于生成训练数据的公理框架
根据某些原则量身定制的配对；并表明少量
公理化信号可以帮助小型模型在偏好评分方面优于 GPT-4。
我们在 Huggingface 上发布了我们的模型：
https://huggingface.co/corbyrosset/axiomatic_preference_model
]]></description>
      <guid>http://arxiv.org/abs/2312.02206</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:42 GMT</pubDate>
    </item>
    <item>
      <title>魔术背后的 MERLIM：大型图像语言模型的多模态评估基准。 （arXiv：2312.02219v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02219</link>
      <description><![CDATA[大视觉和语言模型在全面
监督和零样本视觉任务。这些大型预训练架构
作为当前所谓的大指令调整的基线
视觉和语言模型 (IT-LVLM)。 IT-LVLM 是通用多模式
其反应由自然语言指令调节的助手
任意视觉数据。尽管具有这种多功能性，但 IT-LVLM 的有效性
基本的计算机视觉问题仍不清楚，主要是由于
缺乏标准化的评价基准。本文介绍了一个
名为 MERLIM 的多模式评估基准，是一个可扩展的评估测试平台
IT-LVLM 在基本计算机视觉任务上的性能。梅林
包含超过 279K 个图像问题对，并且重点关注检测
IT-LVLM 中的跨模式“幻觉”事件，其中语言输出
指的是缺乏图像有效基础的视觉概念。我们的
结果表明，最先进的 IT-LVML 在识别方面仍然有限
细粒度的视觉概念、物体幻觉在任务中很常见，
并且他们的结果因输入查询中的微小变化而产生强烈偏差，
即使查询具有完全相同的语义。我们的研究结果还表明
这些模型的视觉基础很弱，但它们仍然可以做出足够的
根据法学硕士中包含的全局视觉模式或文本偏差进行的猜测
成分。
]]></description>
      <guid>http://arxiv.org/abs/2312.02219</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:42 GMT</pubDate>
    </item>
    <item>
      <title>通过潜变量推理训练思维链。 （arXiv：2312.02179v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02179</link>
      <description><![CDATA[大型语言模型 (LLM) 可以更准确、更可解释地解决问题
当被指示使用a逐步计算出答案时
“思想链”（CoT）提示。人们还可以提高法学硕士在以下方面的表现：
通过监督微调来完成特定任务，即通过对某些任务使用梯度上升
可调参数以最大化正确答案的平均对数似然
来自标记的训练集。天真地将 CoT 与监督调优结合起来
不仅需要监督正确答案，还需要监督细节
得出这些答案的理由；这些理由的代价是昂贵的
手工制作。相反，我们提出了一个微调策略，试图
最大化生成正确答案的 \emph{marginal} 对数似然
使用 CoT 提示，对所有可能的理由进行近似平均。这
核心挑战是从后验的基础上进行采样
正确答案;我们使用简单的马尔可夫链蒙特卡罗来解决它
（MCMC）期望最大化（EM）算法的灵感来自于自学
推理机 (STaR)、记忆唤醒睡眠、马尔可夫分数攀爬和持久性
对比分歧。该算法还允许一种新颖的控制变量
将梯度估计的方差驱动为零的技术
模型得到改善。将我们的技术应用于 GSM8K 和 BIG-Bench 中的任务
很难，我们发现这种 MCMC-EM 微调技术通常可以提高
模型在保留示例上的准确性高于 STaR 或使用 或 进行提示调整
没有 CoT。
]]></description>
      <guid>http://arxiv.org/abs/2312.02179</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:41 GMT</pubDate>
    </item>
    </channel>
</rss>