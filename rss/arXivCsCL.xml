<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Thu, 27 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>解开类型学，数据和模型体系结构对跨语义POS标签的排名转移语言的影响</title>
      <link>https://arxiv.org/abs/2503.19979</link>
      <description><![CDATA[ARXIV：2503.19979V1公告类型：新 
摘要：跨语性转移学习是克服数据稀缺的宝贵工具，但是选择合适的转移语言仍然是一个挑战。语言类型学，培训数据和模型架构在转移语言选择中的确切作用尚不完全了解。我们采用了一种整体方法，研究了数据集特异性和细粒度的类型特征如何影响词性标记的转移语言选择，考虑到形态句法特征的两个不同来源。尽管以前的工作在双语双语的背景下检查了这些动态，但我们将分析扩展到更现代的转移学习管道：使用预读的多语言模型的零射击预测。我们训练一系列传输语言排名系统，并检查不同的功能输入如何影响跨体系结构的排名绩效。单词重叠，类型的比率和家谱距离作为所有体系结构中的最高特征。我们的发现表明，类型学和数据集依赖性功能的结合可以达到最佳排名，并且可以单独使用任何一个功能组获得良好的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.19979</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>低资源的机器翻译，用于开关的哈萨克 - 俄罗斯语言对</title>
      <link>https://arxiv.org/abs/2503.20007</link>
      <description><![CDATA[ARXIV：2503.20007V1公告类型：新 
摘要：低资源语言对的机器翻译是一项具有挑战性的任务。一旦扬声器使用代码切换，此任务可能会变得非常困难。我们提出了一种方法，用于建立一个机器翻译模型，用于没有标记的数据，用于加沙俄罗斯语言对。我们的方法基于生成合成数据。此外，我们介绍了第一个对哈萨克 - 俄罗斯平行语料库的交换和评估结果，其中包括达到16.48 BLEU的模型几乎达到了现有的商业系统并通过人类评估来击败它。]]></description>
      <guid>https://arxiv.org/abs/2503.20007</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型的一致性和可取性不佳：大学录取论文的证据</title>
      <link>https://arxiv.org/abs/2503.20062</link>
      <description><![CDATA[ARXIV：2503.20062V1公告类型：新 
摘要：人们越来越多地使用配备大语言模型（LLM）的技术来编写正式交流的文本，这在技术与社会的交集中提出了两个重要的问题：LLMS的写作像（模型对齐）；并且可以提示LLMS更改他们写的人（模型可管）。我们通过比较30,000名申请人写的论文与两种类型的LLM生成的论文之间的词汇和句子变化来调查在选择性大学的本科录取的高风险背景下进行调查的这些问题：仅在人类申请人使用的论文问题中提示。另一个包含有关每个申请人的其他人口统计信息。我们一致地发现，无论特定的模型和分析方法如何，两种类型的LLM生成的论文在语言上都与人为著名的论文不同。此外，促使特定的社会人口统计学身份在将模型与该身份群体中人类写作中观察到的语言模式保持一致时非常无效。这符合性，种族，第一代状态和地理位置的关键维度。在人口统计学的促进和未提及的合成文本中，彼此的综合文本也比人类文本更相似，这意味着提示并不能减轻均质化。当前LLMS中模型对齐和可施用性的这些问题引起了人们对在高风险环境中使用LLM的使用的担忧。]]></description>
      <guid>https://arxiv.org/abs/2503.20062</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过近似可能性匹配的跨tokeni液蒸馏</title>
      <link>https://arxiv.org/abs/2503.20083</link>
      <description><![CDATA[ARXIV：2503.20083V2公告类型：新 
摘要：蒸馏已在将知识从大语言模型（LLM）教师转移到学生LLM方面取得了显着成功。但是，当前的蒸馏方法主要需要教师和学生之间的同样令牌，这将其适用性限制在一小部分教师对对中。在这项工作中，我们开发了一种交叉蒸馏方法来解决这种关键的缺陷。我们的方法是第一个可以在没有下一步的预测损失的情况下实现交叉蒸馏的主要目标，而是纯粹是最大化学生预测与教师的预测（称为纯蒸馏）的相似性，同时对老师和学生的象征功能和词汇的大不了不多。从经验上讲，我们的方法可实现两种用例测试的实质性提高的性能。首先，我们表明，将令牌剂转移视为自distiltation，可以使跨令牌跨越有效地转移。在可比的培训预算下，我们将（子词级）骆驼和Gemma模型转移到字节级令牌化中，比先前的方法更有效地转移到类似的子词令牌。将不同的基本模型转移到同一令牌机构还可以使它们结合起来（例如，通过平均其预测概率）来提高性能。其次，我们使用跨局体蒸馏方法将大型数学专题的LLM它所扩展为较小的模型，从而实现竞争性数学问题解决问题。总体而言，我们的结果朝着更好的适应性和增强不同LLM之间的相互作用而实现的大步进展。]]></description>
      <guid>https://arxiv.org/abs/2503.20083</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成语言学，大语言模型和科学成功的社会本质</title>
      <link>https://arxiv.org/abs/2503.20088</link>
      <description><![CDATA[ARXIV：2503.20088V1公告类型：新 
摘要：Chesi（即将出版的）目标论文描绘了危机中的生成语言学，这是Piantadosi（2023）的宣告，即“现代语言模型驳斥了乔姆斯基的语言方法”。为了生存，Chesi警告说，Generatixist必须遵守更高的正式和经验严格标准。这种反应表明，切西和Piantadosi所描述的危机实际上与严峻无关，而是反映出有限的社会野心的反映。 Chesi将生成语言学的命运与其智力优点联系在一起，但是语言模型研究的当前成功本质上是社会性质的。因此，为了蓬勃发展，富长必须做的比Chesi呼吁严峻的人要做的还要多。他们还必须通过给外界的未来成功来扩大野心。]]></description>
      <guid>https://arxiv.org/abs/2503.20088</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>更大但不是更好的：小型神经语言模型在检测思想障碍方面的表现优于大型语言模型</title>
      <link>https://arxiv.org/abs/2503.20103</link>
      <description><![CDATA[ARXIV：2503.20103V1公告类型：新 
摘要：混乱的思维是精神分裂症谱系疾病的关键诊断指标。最近，已经证明了对杂乱无章的思维严重程度的临床估计，与衡量语音转录本对大语模型（LLMS）进行预测的难度相关。但是，LLMS的部署挑战 - 包括隐私问题，计算和财务成本以及缺乏培训数据的透明度 - 限制了其临床公用事业。我们研究了使用基于滑动窗口的同一的困惑测量值证明有效的较大模型，我们研究了较小的神经语言模型是否可以作为检测正式思想障碍的有效替代方案。令人惊讶的是，我们的结果表明，较小的模型对与形式思想障碍相关的语言差异比较大的同行更敏感。检测能力的下降超出了一定的模型大小和上下文长度，挑战了基于LLM的应用程序``更大&#39;&#39;的共同假设。我们的发现跨越了有精神病症状的人的音频日记和临床访谈语音样本，这表明可以在临床和自然主义环境中部署有效，具有成本效益和隐私的筛查工具的有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2503.20103</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>“还有其他吗？</title>
      <link>https://arxiv.org/abs/2503.20104</link>
      <description><![CDATA[ARXIV：2503.20104V1公告类型：新 
摘要：阿尔茨海默氏病（AD）痴呆是一种进行性神经退行性疾病，对患者的认知能力产生负面影响。先前的研究表明，自然语言样本的变化对于早期筛查AD痴呆症可能是有用的。但是，语言缺陷的性质通常要求测试管理人员在自发语言评估中使用各种语音启发技术，以从痴呆症患者中获得足够的命题话语。这可能导致``观察者的效应&#39;&#39;对尚未完全研究的下游分析。我们的研究旨在量化测试管理员对痴呆症评估中语言特征的影响，并通过两个英文语料库``cookie Theft&#39;&#39;图片描述在不同位置收集的数据集和测试管理员显示不同级别的管理员参与。我们的结果表明，测试管理员的参与程度显着影响患者语音中观察到的语言特征。这些结果表明，下游分类任务中许多重要的语言特征可能部分归因于测试管理实践的差异，而不仅仅是参与者的认知状况。测试管理员行为的变化可能导致语言数据的系统偏见，可能会混淆研究成果和临床评估。我们的研究表明，在制定负责任的临床语音分析框架的开发中，需要更标准化的测试管理方案。]]></description>
      <guid>https://arxiv.org/abs/2503.20104</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过微调传输有效开发模型开发</title>
      <link>https://arxiv.org/abs/2503.20110</link>
      <description><![CDATA[ARXIV：2503.20110V1公告类型：新 
摘要：现代LLM与有效的更新努力，因为每个新审计的模型版本都需要重复昂贵的对齐过程。这项挑战也适用于域或特定于语言的模型，在这些模型中，对于每个新的基本模型发布，必须重新调整专用数据的微调。在本文中，我们探讨了模型版本之间的微调更新的传输。具体而言，我们从一个源模型版本中得出了DIFF向量，该版本代表了与微调的重量变化，并将其应用于不同目标版本的基本模型。通过对各种开放重量模型版本的经验评估，我们表明传递差异向量可以显着改善目标基本模型，通常可以实现与其微调对应物相当的性能。例如，重复使用Llama 3.0 8b的微调更新导致GPQA的绝对准确性提高了10.7％，而基本的Llama 3.1 8B没有额外的培训，超过了Llama 3.1 8B指令。在多语言模型开发环境中，我们表明，与Llama 3.1 8b指导相比，这种方法可以显着提高目标和不重新培训的目标，而无需重新培训，分别在MALAGASY和TURKISH的全球MMLU中实现了4.7％和15.5％的绩效。我们的对照实验表明，当源模型和目标模型在参数空间中线性连接时，微调传输最有效。此外，我们证明了微调转移提供了更强大，更有效的开发点，以进行进一步的微调。最后，我们提出了一种迭代回收，然后提出了连续模型开发方法，从而提高了效率和有效性。我们的发现表明，微调转移是一项可行的策略，可以在保持模型绩效的同时降低培训成本。]]></description>
      <guid>https://arxiv.org/abs/2503.20110</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Protobert-Lora：用于免疫疗法研究鉴定的参数效率原型鉴定</title>
      <link>https://arxiv.org/abs/2503.20179</link>
      <description><![CDATA[ARXIV：2503.20179V1公告类型：新 
摘要：在基因组表达（GEO）（GEO）（GEO）等基因组储存库中鉴定免疫检查点抑制剂（ICI）研究对于癌症研究至关重要，但由于语义歧义，极端的类不平衡和低资源环境中标记的数据有限，因此仍然具有挑战性。我们提出了Protobert-Lora，这是一种混合框架，将PubMedbert与原型网络和低级别适应性（Lora）相结合，以进行有效的微调。该模型通过情节原型训练强化类分离的嵌入，同时保留生物医学领域知识。我们的数据集被分为：训练（20个正，20负），原型集（10个正，10负），验证（20个正，200负）和测试（71个正，765负）。在测试数据集上进行了评估，Protobert-Lora的F1得分为0.624（精度：0.481，召回：0.887），表现优于基于规则的系统，机器学习基线和列出的PubMedbert。在44,287项未标记的研究中申请将手动审查工作减少了82％。消融研究证实，将原型与洛拉相结合，比独立的洛拉提高了29％的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.20179</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用隐性情感：在LLMS的心理特质评估中提高可靠性和有效性</title>
      <link>https://arxiv.org/abs/2503.20182</link>
      <description><![CDATA[ARXIV：2503.20182V1公告类型：新 
摘要：大语言模型（LLM）的最新进展导致它们不断扩大到人类生活中。通过从单纯的工具到类似人类的助手的过渡，了解他们的心理方面，例如情感倾向和个性，对确保其可信度至关重要。但是，通常基于人类心理评估（例如BFI）对LLM的心理评估面临重大局限性。这些方法的结果通常缺乏可靠性，在预测现实世界中LLM行为时的有效性有限。在这项工作中，我们介绍了一种专门为LLM设计的新型评估工具，称为核心情感清单（CSI）。 CSI是一种双语工具，涵盖了英语和中文，它隐含地评估了模型的情感趋势，在三个维度上提供了LLM的深刻心理肖像：乐观，悲观和中立。通过广泛的实验，我们证明：1）CSI有效地捕获了细微的情感模式，从而揭示了跨语言和环境的LLM的显着差异； 2）与当前的方法相比，CSI显着提高了可靠性，从而产生了更一致的结果； 3）CSI得分与LLM现实世界产出的情感之间的相关性超过0.85，这表明其在预测LLM行为方面的有效性很强。我们通过以下方式将CSI公开提供：https：//github.com/deppentententsign/csi。]]></description>
      <guid>https://arxiv.org/abs/2503.20182</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GAPO：通过生成对抗性策略优化学习优惠提示</title>
      <link>https://arxiv.org/abs/2503.20194</link>
      <description><![CDATA[ARXIV：2503.20194V1公告类型：新 
摘要：大语言模型的最新进展强调了通过预定义的约束对模型输出进行精确控制的关键需求。尽管现有的方法试图通过直接指令 - 响应综合或优先响应优化来实现这一目标，但它们通常在约束理解和适应方面挣扎。当处理细粒度的约束时，这种限制变得尤为明显，从而导致幻觉或脆弱性能。我们介绍了生成的对抗性政策优化（GAPO），这是一个新颖的框架，将基于GAN的训练动力学与仅编码器奖励模型相结合，以逐步学习并适应日益复杂的约束。 GAPO利用对抗性培训来自动生成各种难度的训练样本，同时利用仅编码器架构来更好地捕获及时响应关系。广泛的实验表明，GAPO在多个基准测试中的出色性能，尤其是在需要细粒约束处理的情况下，在这种情况下，它极大地胜过了PPO，DPO和KTO等现有方法。我们的结果表明，Gapo的优先提示学习的独特方法为控制LLM输出提供了更强大，更有效的解决方案。代码在https://github.com/mikegu721/gapo中是可用的。]]></description>
      <guid>https://arxiv.org/abs/2503.20194</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>萨尔士：通过意图链的语义对齐可靠的手势产生</title>
      <link>https://arxiv.org/abs/2503.20202</link>
      <description><![CDATA[ARXIV：2503.20202V1公告类型：新 
摘要：共同语音的手势产生通过语音同步的手势合成增强了人类计算机的相互作用现实主义。但是，产生语义意义的手势仍然是一个具有挑战性的问题。 We propose SARGes, a novel framework that leverages large language models (LLMs) to parse speech content and generate reliable semantic gesture labels, which subsequently guide the synthesis of meaningful co-speech gestures.First, we constructed a comprehensive co-speech gesture ethogram and developed an LLM-based intent chain reasoning mechanism that systematically parses and decomposes gesture semantics into structured inference steps following ethogram标准，有效指导LLMS生成上下文感知的手势标签。随后，我们构建了一个意图链的文本到手机标签数据集，并训练了轻巧的手势标签生成模型，然后指导了可信和语义上一致的共同语音语音手势的产生。实验结果表明，Sarges具有有效的单通行推理（0.4秒），可实现高度语义对齐的手势标记（精度为50.2％）。提出的方法为语义手势合成提供了可解释的意图推理途径。]]></description>
      <guid>https://arxiv.org/abs/2503.20202</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>海豚：东方语言的大规模自动语音识别模型</title>
      <link>https://arxiv.org/abs/2503.20212</link>
      <description><![CDATA[ARXIV：2503.20212V1公告类型：新 
摘要：本报告介绍了Dolphin，这是一种大规模的多语言自动语音识别（ASR）模型，该模型扩展了耳语体系结构，以支持更广泛的语言。我们的方法集成了内部专有和开源数据集，以完善和优化海豚的性能。该模型是专门设计的，目的是针对整个东亚，南亚，东南亚和中东的40种东方语言的明显识别准确性，同时还支持22种中国方言。实验评估表明，海豚在各种语言上的最新开源模型明显胜过当前的最新开源模型。为了促进可重复性和社区驱动的创新，我们正在公开制作训练有素的模型和推理源代码。]]></description>
      <guid>https://arxiv.org/abs/2503.20212</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>QWEN2.5-OMNI技术报告</title>
      <link>https://arxiv.org/abs/2503.20215</link>
      <description><![CDATA[ARXIV：2503.20215V1公告类型：新 
摘要：在本报告中，我们提出了Qwen2.5-OMNI，这是一种端到端的多模型模型，旨在感知各种方式，包括文本，图像，音频和视频，同时以流方式生成文本和自然语音响应。为了启用多模式信息输入的流，音频和视觉编码器都采用了块处理方法。为了将视频输入的时间戳与音频同步，我们以交织方式依次组织音频和视频，并提出了一种新颖的位置嵌入方法，称为TMrope（时间平行的多模式绳）。为了同时生成文本和语音，同时避免了两种模式之间的干扰，我们建议\ textbf {thinker-talker}架构。在此框架中，思想家充当一个由文本生成的大型语言模型，而Talker是一种双轨自动回归模型，直接利用思想家的隐藏表示形式来产生音频令牌作为输出。思想家和谈话者模型都被设计为以端到端的方式进行培训和推断。为了以流方式解码音频令牌，我们引入了一个滑动窗口dit，该窗口限制了接受场，旨在减少初始包装延迟。 QWEN2.5-OMNI与类似尺寸的QWEN2.5-VL相当，并且胜过Qwen2-Audio。此外，Qwen2.5-omni在诸如Omni Bench之类的多模式基准上实现了最先进的性能。值得注意的是，以下Qwen2.5-omni在端到端语音说明中的性能与文本输入的能力相当，如MMLU和GSM8K等基准所证明。至于语音产生，QWEN2.5-OMNI的流式说话者在鲁棒和自然性方面优于大多数现有的流媒体和非流式替代方案。]]></description>
      <guid>https://arxiv.org/abs/2503.20215</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自然语言处理的进步：探索基于变压器的架构以了解文本理解</title>
      <link>https://arxiv.org/abs/2503.20227</link>
      <description><![CDATA[ARXIV：2503.20227V1公告类型：新 
摘要：自然语言处理（NLP）在基于变压器的架构的出现中见证了变革性的飞跃，这些架构显着增强了机器理解和生成类似人类的文本的能力。本文探讨了诸如BERT和GPT等变压器模型的进步，重点是与复发性神经网络（RNN）（RNN）相比，其在文本理解任务中的出色表现。通过通过视觉表示分析统计属性 - 包括文本长度分布的概率密度函数和特征空间分类 - 研究突出了模型在处理长期依赖性，适应条件偏移方面的熟练程度，即使在重叠的类别中，模型都可以适应有条件的偏移以及提取分类的特征。该论文借鉴了最近2024年的研究，包括增强多跳跃知识图形推理和上下文感知的聊天互动，概述了一种涉及数据准备，模型选择，预处理，微调和评估的方法论。结果表明，诸如胶水和小队之类的基准上的最先进的表现，F1得分超过90％，尽管诸如高计算成本之类的挑战仍然存在。这项工作强调了变压器在现代NLP中的关键作用，并提出了未来的方向，包括效率优化和多模式集成，以进一步推进基于语言的AI系统。]]></description>
      <guid>https://arxiv.org/abs/2503.20227</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>