<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Thu, 04 Jan 2024 03:15:09 GMT</lastBuildDate>
    <item>
      <title>为品牌生成社交媒体就绪标题。 （arXiv：2401.01637v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01637</link>
      <description><![CDATA[社交媒体广告是品牌营销的关键，旨在吸引
具有吸引人的标题、图片或徽标的消费者。虽然之前
研究重点是为一般图像生成标题，结合
将品牌个性融入社交媒体标题中仍有待探索。品牌
性格被证明会影响消费者的行为和社会
互动因此被证明是营销策略的一个关键方面。
当前的开源多模式法学硕士并不直接适合这项任务。
因此，我们提出了一个管道解决方案来帮助品牌创造有吸引力的
与形象和品牌个性相一致的社交媒体标题。
我们的架构基于两部分：第一部分包含图像
字幕模型，接收品牌想要在线发布的图像，并
给出简单的英文标题； b 第二部分接受生成的标题
与目标品牌个性一起输出引人注目的
符合个性的社交媒体标题。除了品牌个性之外，我们
系统还使用户可以灵活地提供主题标签、Instagram 句柄、
URL 以及他们希望标题包含的命名实体，从而使标题
与社交媒体句柄在语义上更相关。对比评价
针对各种基线证明了我们方法的有效性，
定性和定量。
]]></description>
      <guid>http://arxiv.org/abs/2401.01637</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>围手术期风险预测和预测的大型语言模型功能。 （arXiv：2401.01620v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.01620</link>
      <description><![CDATA[我们研究通用领域大语言模型（例如 GPT-4）是否
Turbo 可以进行风险分层并预测术后结果
使用程序描述和患者临床记录进行测量
来自电子健康记录。我们检查预测性能
8个不同的任务：ASA身体状况分类预测、医院
入院、ICU 入院、计划外入院、医院死亡率、PACU 第一阶段
持续时间、住院时间和 ICU 持续时间。少镜头和思路
提示可以提高某些任务的预测性能。我们实现
ASA 身体状况分类 F1 分数为 0.50，ICU 分数为 0.81
入院死亡率为 0.86。持续时间预测的性能
所有即时策略的任务普遍较差。当前这一代
大语言模型可以帮助临床医生应对围手术期风险
对分类任务进行分层并产生高质量的自然
语言摘要和解释。
]]></description>
      <guid>http://arxiv.org/abs/2401.01620</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可以像人类一样有创造力吗？ （arXiv：2401.01623v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.01623</link>
      <description><![CDATA[创造力是社会进步和创新的基石，但是
其评估仍然是一项复杂且往往是主观的工作。随着上涨
先进的生成人工智能模型能够完成曾经为人类保留的任务
创造力，对人工智能创造力潜力的研究变得势在必行
负责任的开发和应用。本文解决了复杂性
通过引入一个新概念来定义和评估创造力
相对创造力。我们不是试图普遍地定义创造力，而是
将焦点转向人工智能能否与人类的创造力相匹配
假设的人类。这个观点从图灵测试中汲取灵感，
对其进行扩展以解决固有的挑战和主观性
评估创造力。这种方法论的转变有利于统计
对人工智能创造力的量化评估，我们称之为统计
创造力。这种方法可以直接比较人工智能的创意
与特定人类群体的能力。在此基础上，我们
讨论统计创造力在当代的应用
提示条件自回归模型。除了定义和分析
作为创造力的衡量标准，我们引入了可行的培训指南，
有效弥合创造力理论量化之间的差距
以及实用模型训练。通过这些多方面的贡献，
论文建立了一个有凝聚力、不断发展和变革的组织
用于评估和培养人工智能模型统计创造力的框架。
]]></description>
      <guid>http://arxiv.org/abs/2401.01623</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>MedSumm：总结代码混合印地语-英语临床查询的多模式方法。 （arXiv：2401.01596v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.01596</link>
      <description><![CDATA[在医疗保健领域，总结患者提出的医疗问题是
对于改善医患互动和医疗决策至关重要。
尽管医疗数据的复杂性和数量不断增加，但目前的数据主体
该领域的研究主要集中在基于文本的方法，
忽视视觉线索的整合。以及之前在该领域的工作
医学问题摘要仅限于英语。这
工作介绍了多模态医学问题总结的任务
在资源匮乏的环境中进行代码混合输入。为了解决这个差距，我们引入
多模态医学代码混合问题总结 MMCQS 数据集，其中
将印地语-英语混合代码医学查询与视觉辅助工具结合起来。这
整合丰富了患者医疗状况的表现，
提供更全面的视角。我们还提出了一个名为
MedSumm 利用 LLM 和 VLM 的力量来完成此任务。通过利用
我们的 MMCQS 数据集，我们展示了整合视觉信息的价值
从图像中改进医学详细摘要的创建。这
多模式策略不仅可以改善医疗保健决策，还可以
促进对患者询问的更深入理解，为未来铺平道路
探索个性化和响应式医疗服务。我们的数据集、代码和
预训练的模型将公开。
]]></description>
      <guid>http://arxiv.org/abs/2401.01596</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>PLLaMa：植物科学的开源大型语言模型。 （arXiv：2401.01600v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01600</link>
      <description><![CDATA[大型语言模型 (LLM) 在以下方面表现出了卓越的能力
理解各个领域的自然语言并与之互动。
然而，它们的有效性仅限于要求高的专业领域。
准确性，例如植物科学，由于缺乏这些领域的具体专业知识
字段。本文介绍了 PLLaMa，一种开源语言模型，
由LLaMa-2演变而来。它通过综合数据库得到增强，包括
超过 150 万篇植物科学学术文章。这一发展
显着丰富了 PLLaMa 丰富的植物知识和熟练程度
和农业科学。我们的初步测试，涉及特定数据集
与植物和农业相关，表明 PLLaMa 显着提高了其
了解植物科学相关主题。此外，我们还组建了
国际专业小组，包括植物科学家、农业科学家
工程师和植物育种家。该团队在验证
PLLaMa 对各种学术询问的答复的准确性，确保其
有效且可靠的现场应用。支持进一步的研究
和开发，我们制作了模型的检查点和源代码
科学界可以访问。这些资源可用于
下载地址：\url{https://github.com/Xianjun-Yang/PLLaMa}。
]]></description>
      <guid>http://arxiv.org/abs/2401.01600</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>如果接地的话，GPT-4V(ision) 是一个多面手网络代理。 （arXiv：2401.01614v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.01614</link>
      <description><![CDATA[大型多模态模型（LMM）的最新发展，特别是
GPT-4V(ision)和Gemini，一直在快速拓展能力边界
超越图像字幕和视觉等传统任务的多模态模型
问题回答。在这项工作中，我们探索了 GPT-4V 等 LMM 的潜力
作为一个多面手网络代理，可以遵循自然语言指令
在任何给定网站上完成任务。我们推荐 SEEACT，一个通用网络代理
利用 LMM 的力量进行综合视觉理解和表演
在网上。我们对最近的 MIND2WEB 基准进行评估。此外
对缓存网站进行标准离线评估，我们启用新的在线评估
通过开发允许实时运行网络代理的工具来进行评估设置
网站。我们证明 GPT-4V 为网络代理带来了巨大的潜力 - 它
如果我们手动的话，可以成功完成实时网站上 50% 的任务
将其文本计划落实到网站上的行动中。这实质上
优于 GPT-4 等纯文本法学硕士或更小的模型（FLAN-T5 和 BLIP-2）
专门针对网络代理进行了微调。然而，接地仍然是一个
重大挑战。现有的 LMM 基础策略，例如标记集提示
事实证明对于网络代理来说并不有效，而我们最好的接地策略是
本文中的开发利用了 HTML 文本和视觉效果。然而，还有
与甲骨文落地仍有很大差距，留有进一步发展的空间
改进。
]]></description>
      <guid>http://arxiv.org/abs/2401.01614</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>GOAT-Bench：通过基于 Meme 的社交滥用对大型多模式模型的安全见解。 （arXiv：2401.01523v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01523</link>
      <description><![CDATA[社交媒体的指数级增长深刻地改变了人们的生活方式
信息的创造、传播和吸收，超越了任何先例
数字时代。遗憾的是，这次爆炸也引发了重大事件。
网络滥用模因的现象有所增加。评估模因的负面影响
由于其通常微妙和隐含的含义，因此特别具有挑战性，
这些不是通过明显的文字和图像直接传达的。鉴于
大型多模态模型 (LMM) 已成为人们关注的焦点
由于它们在处理各种多式联运任务方面具有卓越的能力。在
为了应对这一发展，我们的论文旨在彻底检查能力
各种 LMM（例如 GPT-4V）的数据来辨别和响应的细微差别
社会虐待表现在模因中。我们介绍综合模因
基准测试 GOAT-Bench，包含超过 6K 个不同的模因封装主题
例如隐含的仇恨言论、性别歧视和网络欺凌等。
GOAT-Bench，我们深入研究 LMM 准确评估仇恨的能力，
厌女症、攻击性、讽刺和有害内容。我们广泛的
一系列 LMM 的实验表明，当前模型仍然表现出
安全意识不足，对各种形式的安全事故不敏感
隐性虐待。我们认为这种短缺是一个关键障碍
以实现安全的人工智能。山羊凳和
随附的资源可在 https://goatlmm.github.io/ 上公开访问，
为这一重要领域正在进行的研究做出贡献。
]]></description>
      <guid>http://arxiv.org/abs/2401.01523</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>神经自动语音识别中的幻觉：识别错误和幻觉模型。 （arXiv：2401.01572v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01572</link>
      <description><![CDATA[幻觉是深度神经网络产生的一种输出错误。
虽然这已经在自然语言处理中进行了研究，但尚未得到证实。
之前研究过自动语音识别。在这里，我们定义
ASR 中的幻觉是由模型生成的转录
在语义上与源话语无关，但仍然流畅且连贯。
幻觉与可能的自然语言输出的相似性
模型会产生欺骗的危险并影响系统的可信度。
我们表明，常用的指标（例如单词错误率）不能
区分幻觉和非幻觉模型。讲话
为此，我们提出了一种基于扰动的方法来评估敏感性
自动语音识别（ASR）模型在测试时产生幻觉，
不需要访问训练数据集。我们证明这
方法有助于区分幻觉和非幻觉模型
具有相似的基线错误率。我们进一步探索
ASR 错误类型与数据集噪声类型之间的关系
确定哪些类型的噪音最有可能产生幻觉输出。
我们设计了一个框架，通过分析幻觉来识别幻觉
与基本事实的语义联系及其流畅性。最后，我们
发现如何通过随机噪声注入来诱发幻觉
发声。
]]></description>
      <guid>http://arxiv.org/abs/2401.01572</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>基于图对比学习的两阶段多模态情感识别模型。 （arXiv：2401.01495v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01495</link>
      <description><![CDATA[在人机交互方面，越来越多
正确理解对话中用户的情绪状态很重要，
因此，多模态情感识别（MER）任务开始受到更多关注
注意力。然而，现有的情感分类方法通常执行
仅分类一次。单个句子可能会被错误分类
一轮分类。以前的工作通常忽略相似之处和
融合过程中不同形态特征之间的差异。到
针对上述问题，我们提出了一种两阶段情感识别模型
基于图对比学习（TS-GCL）。首先，我们对原始数据进行编码
具有不同预处理方式的数据集。二、一张图对比
针对这三种模态数据引入了学习（GCL）策略以及其他策略
结构来学习模式内部和之间的相似性和差异。
最后，我们使用 MLP 两次来实现最终的情感分类。这
阶段性分类方法可以帮助模型更好地关注不同的
情绪信息水平，从而提高绩效
模型。大量实验表明TS-GCL在以下方面具有优越的性能
IEMOCAP 和 MELD 数据集与以前的方法进行比较。
]]></description>
      <guid>http://arxiv.org/abs/2401.01495</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>利用神经换能器通过语义标记预测进行两阶段文本转语音。 （arXiv：2401.01498v1 [eess.AS]）</title>
      <link>http://arxiv.org/abs/2401.01498</link>
      <description><![CDATA[我们提出了一种新颖的文本转语音（TTS）框架，以神经网络为中心
传感器。我们的方法将整个 TTS 管道划分为语义级别
序列到序列 (seq2seq) 建模和细粒度声学建模
阶段，利用从 wav2vec2.0 嵌入获得的离散语义标记。
为了实现稳健且高效的对齐建模，我们采用神经传感器
用于语义标记预测的命名标记转换器，受益于其
硬单调对齐约束。随后，非自回归 (NAR)
语音生成器有效地从这些语义标记合成波形。
此外，参考语音控制时间动态和声学
各个阶段的条件。这种解耦的框架减少了训练
TTS 的复杂性，同时允许每个阶段专注于语义和声学
造型。我们在零样本自适应 TTS 上的实验结果表明
我们的模型在语音质量和说话人方面超越了基线
相似性，无论是客观上还是主观上。我们也深入研究一下推论
我们方法的速度和韵律控制能力，突出了
TTS 框架中神经传感器的潜力。
]]></description>
      <guid>http://arxiv.org/abs/2401.01498</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>初看 Stack Overflow 答案中的信息突出显示。 （arXiv：2401.01472v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01472</link>
      <description><![CDATA[背景：掌握 Stack Overflow (SO) 的知识仍然具有挑战性。
为了使帖子对用户来说生动，SO 允许用户使用以下方式编写和编辑帖子
Markdown 或 HTML，以便用户可以利用各种格式样式（例如，
粗体、斜体和代码）以突出显示重要信息。尽管如此，
对重点信息的研究有限。目标：我们
开展了首次大规模的信息探索性研究
在我们最近的研究中，SO 答案中强调了这一点。为了扩展我们之前的研究，我们
开发自动推荐突出显示内容的方法
使用最初设计的神经网络架构格式化样式
命名实体识别任务。方法：在本文中，我们研究了 31,169,429
堆栈溢出的答案。对于训练推荐模型，我们选择CNN
以及每种格式类型的 BERT 模型（即粗体、斜体、代码和
标题）使用我们从 SO 收集的信息突出显示数据集
答案。结果：我们基于 CNN 架构的模型达到了精度
范围从 0.71 到 0.82。自动编码内容的训练模型
突出显示实现了 0.73 的召回率和 0.71 的 F1 分数，表现优于
其他格式样式的训练模型。 BERT 模型甚至更低
召回率和 F1 分数与 CNN 模型相比。我们对失败案例的分析
表明大多数失败案例都缺少标识
（即模型错过了应该突出显示的内容）由于
这些模型倾向于学习经常突出显示的单词，同时努力学习
学习不太常见的单词。结论：我们的研究结果表明这是可能的
开发推荐模型来突出显示答案的信息
Stack Overflow 上的不同格式样式。
]]></description>
      <guid>http://arxiv.org/abs/2401.01472</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:04 GMT</pubDate>
    </item>
    <item>
      <title>自然语言处理和多模式股票价格预测。 （arXiv：2401.01487v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.01487</link>
      <description><![CDATA[在财务决策领域，预测股票价格是
关键的。人工智能技术，例如长短期记忆
网络 (LSTM)、支持向量机 (SVM) 和自然语言
处理（NLP）模型通常用于预测所述价格。这
论文利用库存百分比变化作为训练数据，与
传统使用原始货币价值，重点是公开分析
发布新闻文章。百分比变化的选择旨在提供模型
与价格波动和总体价格的重要性有关的背景
变化对给定股票的影响。该研究采用了专门的 BERT 自然
预测股票价格趋势的语言处理模型，具有特定的
强调各种数据模式。结果展示了
这种策略通过小型自然语言处理模型来准确地
预测整体股票趋势，并突出某些数据的有效性
特征和特定部门的数据。
]]></description>
      <guid>http://arxiv.org/abs/2401.01487</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:04 GMT</pubDate>
    </item>
    <item>
      <title>发散还是不发散：机器翻译与人工翻译的形态句法视角。 （arXiv：2401.01419v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01419</link>
      <description><![CDATA[我们对机器进行大规模细粒度对比分析
翻译（MT）与人工翻译（HT）的对比
形态句法分歧。跨越三种语言对和两种类型
分歧定义为来源和目标之间的结构差异
目标，MT 始终比 HT 更保守，形态句法更少
多样性、更加趋同的模式以及更加一对一的排列。通过
通过对不同解码算法的分析，我们将这种差异归因于
使用波束搜索使 MT 偏向于更收敛的模式。这种偏见
当收敛模式出现在 50% 左右的时间时，放大最为明显
训练数据。最后，我们表明对于大多数形态句法
差异，它们在 HT 中的存在与 MT 性能下降相关，
对机器翻译系统提出了更大的挑战。
]]></description>
      <guid>http://arxiv.org/abs/2401.01419</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>使用检索增强生成对电子健康记录进行基于问答的总结。 （arXiv：2401.01469v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01469</link>
      <description><![CDATA[电子健康记录 (EHR) 的汇总可以大大减少
患者和医务人员的“屏幕时间”。最近几年
EHR 的总结已经采用了机器学习管道，使用状态
艺术神经模型。然而，这些模型产生的效果还不够
结果归因于难以获得足够的注释
训练数据。此外，要求考虑整个内容
总结中的 EHR 导致绩效不佳，因为
现代大语言模型（LLM）中的注意力机制增加了二次
输入大小的复杂性。我们在这里提出一种方法
通过结合语义搜索、增强检索来减轻这些缺点
使用最新的法学硕士进行生成（RAG）和问答。在我们的方法中
总结是对特定问题的答案的提取
主题专家 (SME) 认为重要。我们的做法相当
高效的;需要最少的培训或不需要培训；不遭受
法学硕士的“幻觉”问题；它确保了多样性，因为摘要
不会有重复的内容，而是针对具体问题提供多样化的答案。
]]></description>
      <guid>http://arxiv.org/abs/2401.01469</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>量化唐纳德·特朗普在总统演讲中的独特性。 （arXiv：2401.01405v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01405</link>
      <description><![CDATA[唐纳德·特朗普的说话方式与其他总统不同吗？如果是这样，在什么情况下
方法？这些差异是否仅限于任何单一的沟通媒介？到
为了调查这些问题，本文引入了一种新颖的独特性度量
基于大型语言模型，开发了一个新的分裂语音词典，以及
提出了一个比较政治对手词汇特征的框架。
将这些工具应用于各种总统演讲语料库，我们发现
大量证据表明特朗普的讲话模式与所有人不同
近代历史上主要政党的总统候选人。一些值得注意的
调查结果包括特朗普使用了特别分裂和敌对的人
针对他的政治对手的语言和他的重复模式
为了强调。此外，特朗普比他的总统更加独特。
共和党同胞们，他们的独特价值观与共和党人比较接近
民主党人。这些差异存在于各种测量中
战略，出现在竞选活动和正式总统选举中
地址，并且似乎不是长期时间趋势的产物。
]]></description>
      <guid>http://arxiv.org/abs/2401.01405</guid>
      <pubDate>Thu, 04 Jan 2024 03:15:02 GMT</pubDate>
    </item>
    </channel>
</rss>