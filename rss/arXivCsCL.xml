<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Wed, 10 Jan 2024 06:18:37 GMT</lastBuildDate>
    <item>
      <title>通过对比学习提高基于知识的对话的稳健性。 （arXiv：2401.04361v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04361</link>
      <description><![CDATA[基于知识的对话 (KGD) 学习生成信息丰富的响应
基于给定的对话上下文和外部知识（\emph{e.g.}，
知识图谱；千克）。最近，大型语言模型（LLM）的出现
预训练技术为知识基础带来了巨大成功
对话。然而，在实际应用中构建KGD系统时，存在以下问题：
现实世界中不可避免要面对的各种噪音。例如，
对话上下文可能涉及干扰，例如拼写错误和
缩写。此外，KG 通常会遇到不完整的问题，而且
可能包含错误和过时的事实。这种现实世界的噪音构成了
对 KGD 系统的鲁棒性提出了挑战并阻碍了其在
真实世界。在本文中，我们提出了一种基于实体的对比学习
提高 KGD 鲁棒性的框架。具体来说，我们利用
KGD 样本中的实体信息来创建其正面和负面
涉及语义不相关和语义相关扰动的样本，
分别。对比学习框架确保 KGD 模型具有感知能力
这两种类型的扰动，从而产生信息丰富的响应
实际应用中潜在的噪声输入。实验结果
三个基准数据集表明我们的方法达到了新的最先进水平
自动评估分数方面的表现，验证其
有效性和潜力。此外，我们表明我们的方法可以
在噪声和噪声方面都比比较模型产生更好的响应
少拍设置。
]]></description>
      <guid>http://arxiv.org/abs/2401.04361</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>患者报告经历的概率情绪和情绪建模。 （arXiv：2401.04367v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04367</link>
      <description><![CDATA[这项研究引入了一种新的方法来模拟患者的情绪
在线患者体验叙述。我们采用了元数据网络主题
建立模型来分析护理意见中患者报告的经历，揭示
与患者与护理人员互动和临床相关的关键情感主题
结果。我们开发了一个概率性的、特定于上下文的情感推荐器
能够预测多标签情感和二元情感的系统
使用朴素贝叶斯分类器，使用上下文有意义的主题作为
预测因子。我们在该模型下预测情绪的优越表现
使用信息检索评估与基线模型的比较
指标 nDCG 和 Q-measure，我们的预测情绪达到了 F1 分数
为 0.921，明显优于标准情感词典。这个方法
提供一种透明、经济高效的方式来了解患者的反馈，
加强传统收集方法并告知个性化患者
关心。我们的发现可以通过 R 包和交互式仪表板访问，
为医疗保健研究人员和从业人员提供有价值的工具。
]]></description>
      <guid>http://arxiv.org/abs/2401.04367</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>通过零阶优化对大型语言模型进行私人微调。 （arXiv：2401.04343v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.04343</link>
      <description><![CDATA[在私有数据集上微调大型预训练模型可能会面临以下风险：
侵犯隐私。差异隐私是减轻隐私影响的框架
通过强制算法稳定性来承担风险。 DP-SGD 支持训练模型
以保护隐私的方式保护私人数据，但提出了新的障碍
形式的性能损失和重大的工程挑战。我们介绍
DP-ZO，一种微调大型语言模型的新方法，保留了
通过私有化零阶优化来保护训练数据的隐私。关键
对我们方法设计的深入了解是梯度的方向
SPSA，我们使用的零阶算法，总是随机的并且是唯一的
依赖于私有数据的信息是步长，即标量。
因此，我们只需要将标量步长私有化即可，即
内存效率高。 DP-ZO，可以用拉普拉斯或拉普拉斯实例化
高斯噪声，提供了跨不同隐私和效用的强大权衡
在保守的隐私预算下的任务和模型大小。值得一提的是
结果是 DP-ZO 仅表现出 $1.86\%$ 性能下降，原因是
在 1000 个训练样本上微调 OPT-66B 时，隐私性为 $(1,10^{-5})$-DP
来自小队。
]]></description>
      <guid>http://arxiv.org/abs/2401.04343</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>LAMPAT：使用对抗性训练进行多语言释义的低阶适应。 （arXiv：2401.04348v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04348</link>
      <description><![CDATA[释义是用不同的方式传达相同含义的文本
单词或句子结构。它可以用作自动数据增强
用于许多自然语言处理任务的工具，特别是在处理
资源匮乏的语言，数据短缺是一个严重的问题。到
在多语言环境中生成释义，之前的研究已经利用
来自机器翻译领域的知识，即形成释义
通过同一种语言的零样本机器翻译。尽管不错
人类评估的表现，这些方法仍然需要并行
翻译数据集，从而使其不适用于不支持的语言
有平行语料库。为了缓解这个问题，我们提出了第一个
无监督多语言释义模型，LAMPAT ($\textbf{L}$ow-rank
$\textbf{A}$适应$\textbf{M}$多语言$\textbf{P}$使用
$\textbf{A}$dversarial $\textbf{T}$raining)，单语数据集是
足以生成类似人类且多样化的句子。在整个
实验中，我们发现我们的方法不仅适用于英语，而且
也可以概括出未见过的语言。数据和代码可在
https://github.com/phkhanhtrinh23/LAMPAT。
]]></description>
      <guid>http://arxiv.org/abs/2401.04348</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>MARG：科学论文的多代理评审生成。 （arXiv：2401.04259v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04259</link>
      <description><![CDATA[我们研究法学硕士为科学论文提供反馈的能力，以及
开发 MARG，一种使用多个 LLM 实例的反馈生成方法，
进行内部讨论。通过在代理之间分发纸质文本，MARG
可以使用超出输入长度限制的论文全文
基础法学硕士，并通过专业代理并纳入量身定制的子任务
不同的评论类型（实验、清晰度、影响）它提高了
反馈的有用性和特异性。在用户研究中，基线方法
使用 GPT-4 被评为产生通用或非常通用的评论超过
一半的时间，每篇论文只有 1.7 条评论被评为总体良好
最好的基线。我们的系统大大提高了 GPT-4 的能力
生成具体且有用的反馈，减少一般性评论的发生率
从 60% 到 29%，每篇论文产生 3.7 条好评（2.2 倍）
改进）。
]]></description>
      <guid>http://arxiv.org/abs/2401.04259</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>视觉重新构想：人工智能驱动的 WiFi 室内成像突破。 （arXiv：2401.04317v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.04317</link>
      <description><![CDATA[室内成像是机器人和物联网的一项关键任务。无线上网
作为一种无所不在的信号，它是执行被动攻击的有希望的候选者
成像并将最新信息同步到所有连接的设备。
这是第一个将 WiFi 室内成像视为
多模态图像生成任务，将测得的 WiFi 功率转换为
高分辨率室内图像。我们提出的 WiFi-GEN 网络已初具规模
重建精度是基于物理模型的重建精度的 275%
反演方法。此外，Frechet 起始距离分数已
大幅减少82%。检查模型的有效性
任务，发布第一个包含 80,000 对 WiFi 的大规模数据集
信号和成像目标。我们的模型吸收了基于模型的挑战
方法包括非线性、不适定性和不确定性
我们的生成人工智能网络的大量参数。网络也设计了
以最适合测量的 WiFi 信号和所需的成像输出。为了
再现性，我们将在接受后发布数据和代码。
]]></description>
      <guid>http://arxiv.org/abs/2401.04317</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>更好地了解您的需求：通过类比推理增强法学硕士对营销人员需求进行结构化理解。 （arXiv：2401.04319v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04319</link>
      <description><![CDATA[在本文中，我们探索了一种用户定位的新方法，其中非专家
营销人员可以仅根据自然需求选择目标用户
语言形式。这个问题的关键是如何将自然语言转化为
实用的结构化逻辑语言，即结构化理解
营销人员的要求。考虑到令人印象深刻的自然语言处理
大语言模型（LLM）的能力，我们尝试利用LLM来解决这个问题
问题。过去的研究表明，法学硕士的推理能力可以
通过思想链（CoT）提示有效增强。但现有的
方法仍然存在一些局限性：（1）以前的方法要么使用简单的
“让我们一步一步思考”咒语或在演示中提供固定示例
不考虑提示和问题之间的兼容性，使得法学硕士
在某些复杂的推理任务（例如结构化语言）中效果不佳
转型。 (2)以前的方法往往是闭源实现的
型号或过大的型号，不适合工业应用
实际场景。基于这些，我们提出了 ARALLM（即 Analogical
推理增强大型语言模型）由两个模块组成：
基于类比​​推理的提示和推理增强多任务模型
蒸馏。
]]></description>
      <guid>http://arxiv.org/abs/2401.04319</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中判断空间关系的扭曲：自然语言地理数据的黎明？。 （arXiv：2401.04218v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04218</link>
      <description><![CDATA[我们提出了评估大型语言模型能力的基准
（法学硕士）辨别地理位置和
将其应用于三个著名的法学硕士：GPT-3.5、GPT-4 和 Llama-2。这个基准
特别评估法学硕士是否表现出类似的分层空间偏差
对于人类来说，对各个位置的空间关系的判断
受到较大群体的感知关系的影响，其中包含
他们。为了调查这一点，我们针对众所周知的问题制定了 14 个问题
美国城市。设计了七个问题来挑战法学硕士
可能受到更大地理区域方向影响的情景
单位，例如州或国家，而其余七个目标
不太容易受到这种等级分类的影响的地点。之间
经过测试的模型，GPT-4 表现出优越的性能，准确率达到 55.3%，
其次是 GPT-3.5（占 47.3%）和 Llama-2（占 44.7%）。模型显示
具有可疑层次偏差的任务的准确性显着降低。为了
例如，GPT-4 在这些任务上的准确率下降至 32.9%，而在这些任务上的准确率则为 85.7%
其他的。尽管存在这些不准确之处，模型还是确定了最近的基数
在大多数情况下，方向，建议联想学习，体现类人
误解。我们讨论基于文本的数据表示的潜力
地理关系直接提高空间推理能力
法学硕士。
]]></description>
      <guid>http://arxiv.org/abs/2401.04218</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>通过可检索的语音文本嵌入进行高精度语音搜索查询纠正。 （arXiv：2401.04235v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04235</link>
      <description><![CDATA[自动语音识别 (ASR) 系统可能会遇到以下问题：
各种原因，例如嘈杂的音频、缺乏足够的训练数据等。

之前的工作表明，可以通过检索重写来提高召回率
来自可能的、与上下文相关的替代方案的大型数据库中的候选者
使用最近邻搜索对假设文本进行嵌入
ASR 假设文本要更正和候选更正。

但是，如果以下情况，基于 ASR 假设的检索可能会产生较差的精度：
文本假设在语音上与抄本事实相差太大。在
在本文中，我们通过查询来消除假设音频不匹配问题
直接使用从语音音频导出的嵌入来校正数据库；
语音音频和候选校正的嵌入是由
多模态语音文本嵌入网络经过训练以放置嵌入
话语的音频及其相应文本记录的嵌入
紧靠在一起。

使用最近邻找到合适的校正候选后
搜索，我们用之前的语音文本嵌入距离对候选者进行评分
将候选者添加到原始 n-best 列表中。

我们发现，以下语句的相对单词错误率 (WER) 降低了 6%：
成绩单出现在候选集中，不会增加一般的 WER
话语。
]]></description>
      <guid>http://arxiv.org/abs/2401.04235</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>生物信息学中的大型语言模型：应用和观点。 （arXiv：2401.04155v1 [q-bio.QM]）</title>
      <link>http://arxiv.org/abs/2401.04155</link>
      <description><![CDATA[大型语言模型（LLM）是一类人工智能模型
基于深度学习，在各种任务中都有出色的表现，
尤其是在自然语言处理（NLP）领域。大型语言模型
通常由具有大量参数的人工神经网络组成，
使用自我监督或对大量未标记输入进行训练
半监督学习。然而，它们解决生物信息学问题的潜力
问题甚至可能超出他们对人类语言建模的熟练程度。在这个
回顾一下，我们将总结所使用的重要大型语言模型
专注于自然语言处理，例如BERT和GPT，并重点探索
大语言模型在不同组学层面的应用
生物信息学，主要包括大语言模型在生物信息学中的应用
基因组学、转录组学、蛋白质组学、药物发现和单细胞分析。
最后，这篇综述总结了大语言的潜力和前景
解决生物信息问题的模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.04155</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>unnyNet-W：野外视频中有趣时刻的多模态学习。 （arXiv：2401.04210v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.04210</link>
      <description><![CDATA[自动理解有趣的时刻（即让人兴奋的时刻）
笑）当观看喜剧具有挑战性时，因为它们涉及各种功能，
例如肢体语言、对话和文化。在本文中，我们建议
unnynet-w，一个依赖交叉和自注意力的视觉、音频模型
和文本数据来预测视频中的有趣时刻。与大多数依赖的方法不同
基于字幕形式的真实数据，在这项工作中我们利用
视频自然出现的模式：(a) 视频帧，因为它们包含
视觉信息对于场景理解不可或缺，(b) 音频
包含与有趣时刻相关的更高级别的线索，例如语调，
音高和停顿以及 (c) 通过语音转文本自动提取文本
模型，因为它在由大语言处理时可以提供丰富的信息
模型。为了获取训练标签，我们提出了一种无监督方法
发现并标记有趣的音频时刻。我们提供了五个数据集的实验：
情景喜剧《TBBT》、《MHD》、《MUStARD》、《老友记》和 TED 演讲《UR-Funny》。广泛的
实验和分析表明，FunnyNet-W 成功地利用了视觉、
听觉和文字提示来识别有趣的时刻，而我们的研究结果表明
unnyNet-W 能够预测野外的有趣时刻。 unnyNet-W 设置了
最先进的有趣时刻检测，所有内容均具有多模式提示
使用和不使用地面真实信息的数据集。
]]></description>
      <guid>http://arxiv.org/abs/2401.04210</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>Z 世代在 Discord 上区分人工智能生成的文本和人类创作的文本的能力。 （arXiv：2401.04120v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2401.04120</link>
      <description><![CDATA[生成人工智能 (AI) 聊天机器人越来越受欢迎
ChatGPT 等正在对社交媒体产生变革性影响。作为
人工智能生成的内容越来越流行，人们对此表示担忧
在线隐私和错误信息。在社交媒体平台中，Discord
实现人工智能集成——打造其主要的“Z 世代”用户群
特别是接触人工智能生成的内容。我们调查了 Z 世代老年人
个人（n = 335）来评估他们区分不同类别的能力
Discord 上人工智能生成和人类创作的文本。调查采用了
ChatGPT 的一次性提示，伪装成在网络上收到的短信
Discord.com 平台。我们探讨人口因素对
能力，以及参与者对 Discord 和人工的熟悉程度
情报技术。我们发现 Z 世代个人无法
辨别人工智能和人类创作的文本（p = 0.011），并且那些具有
自我报告对 Discord 的熟悉程度较低，表明能力有所提高
与那些自我报告的经验相比，识别人类创作的内容
与 AI (p &lt;&lt; 0.0001)。我们的结果表明存在微妙的关系
人工智能技术与 Z 世代流行的沟通方式之间，
为人机交互、数字化等领域提供宝贵的见解
沟通和人工智能素养。
]]></description>
      <guid>http://arxiv.org/abs/2401.04120</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>Chain of LoRA：通过残差学习对语言模型进行高效微调。 （arXiv：2401.04151v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.04151</link>
      <description><![CDATA[微调是定制预训练大型模型的主要方法
特定任务的语言模型。随着模型的规模和多样性
任务扩展，参数高效的微调方法至关重要
重要性。最广泛使用的方法系列之一是低秩方法
适应（LoRA）及其变体。 LoRA 将权重更新编码为乘积
两个低秩矩阵。尽管有其优点，LoRA 仍存在不足
针对某些任务的泛化误差进行全参数微调。

我们介绍Chain of LoRA (COLA)，一个迭代优化框架
受到 Frank-Wolfe 算法的启发，弥合 LoRA 和完整算法之间的差距
参数微调，不会产生额外的计算成本或
内存开销。 COLA 采用残差学习程序，将
将 LoRA 模块学习到预先训练的语言模型参数中，并
重新启动对新生 LoRA 模块的优化。我们提供理论
收敛保证以及实证结果来验证
我们算法的有效性。跨各种型号（OPT 和 llama-2）和
七项基准测试任务，我们证明 COLA 可以持续超越
LoRA 无需额外的计算或内存成本。
]]></description>
      <guid>http://arxiv.org/abs/2401.04151</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>用于多说话者语音识别的跨说话者编码网络。 （arXiv：2401.04152v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2401.04152</link>
      <description><![CDATA[端到端多说话者语音识别作为一种
直接转录多个重叠语音的有效方法
扬声器。当前的方法通常采用 1) 单输入
带有分支编码器的多输出 (SIMO) 模型，或 2) 单输入
基于基于注意力的编码器-解码器的单输出（SISO）模型
具有串行化输出训练（SOT）的架构。在这项工作中，我们提出了一个
跨说话者编码 (CSE) 网络可解决 SIMO 模型的局限性
通过聚合跨说话者表示。此外，CSE模型是
与SOT集成，发挥SIMO和SISO的优点，同时
减轻他们的缺点。据我们所知，这项工作代表
早期尝试将 SIMO 和 SISO 集成以实现多说话者语音识别。
在二人 LibrispeechMix 数据集上的实验表明，CES 模型
与 SIMO 基线相比，字错误率 (WER) 降低了 8%。 CSE-SOT 模型
与
SOT 模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.04152</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>处理人与机器人对话中的麻烦和失败 (WTF 2023) & CUI 设计准备好了吗？ （arXiv：2401.04108v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2401.04108</link>
      <description><![CDATA[两个同一地点的研讨会“处理麻烦和问题”的研讨会记录
与人类和机器人对话的失败”（WTF 2023）和“CUI 设计是这样的吗？”
准备好了吗？”，这两篇文章都是 ACM 会话会议的一部分
用户界面 2023。

WTF 23 旨在将人机交互领域的研究人员聚集在一起，
对话系统、人机交互和对话分析。
尽管取得了所有进展，但机器人语音接口在实际应用中仍然很脆弱。
此类接口的方式繁多且失败的经历已是家常便饭
在机器人专家中。然而，技术文献是积极倾斜的
为他们的良好表现。研讨会旨在为大家提供一个平台
讨论人机交互中的沟通问题和失败
非机器人语音接口中的相关故障。目标包括一丝不苟
调查沟通失败，开始对沟通失败进行分类
此类故障，并就可能的缓解措施进行初步讨论
策略。研讨会网站：https://sites.google.com/view/wtf2023/overview

CUI 设计准备好了吗？随着 CUI 在学术界变得越来越普遍
研究和商业市场，设计可用变得更加重要
和可采用的 CUI。虽然关于方法的研究一直在不断增长
设计用于商业用途的 CUI，但很少有关于该问题的讨论
开发设计资源以帮助实践的整体社区实践
崔设计。因此，本次研讨会的目的是让 CUI 社区
共同讨论开发工具和资源的当前实践
对于实际的 CUI 设计，采用（或不采用）这些工具以及
资源，以及如何在培训和教育中利用这些资源
进入该领域的新 CUI 设计师。研讨会网站：
https://speech-interaction.org/cui2023_design_workshop/index.html
]]></description>
      <guid>http://arxiv.org/abs/2401.04108</guid>
      <pubDate>Wed, 10 Jan 2024 06:18:31 GMT</pubDate>
    </item>
    </channel>
</rss>