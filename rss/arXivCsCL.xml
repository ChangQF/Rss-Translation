<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 15 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>信息提取：发展中国家超本地金融数据领域的应用</title>
      <link>https://arxiv.org/abs/2403.09077</link>
      <description><![CDATA[arXiv:2403.09077v1 公告类型：新
摘要：尽管发展研究和经济分析需要有关发展中国家公司活动的财务数据，但此类数据并不存在。在这个项目中，我们开发并评估了两种基于自然语言处理（NLP）的技术来解决这个问题。首先，我们策划一个特定于发展中国家金融文本数据领域的自定义数据集，并探索多种信息提取方法。然后，我们使用基于 Transformer 的 T5 模型探索文本到文本的方法，目标是同时进行 NER 和关系提取。我们发现该模型能够学习与实体及其关系相对应的自定义文本结构输出数据，从而从我们最好的 T5 模型中获得 92.44\% 的准确度、68.25\% 的精确度和 54.20\% 的召回率关于联合任务。其次，我们探索了一种顺序 NER 和关系提取的方法。对于 NER，我们使用 SpaCy 运行预训练和微调的模型，并使用 SpaCy 的依赖解析器输出和一些启发式方法开发自定义关系提取模型来确定实体关系 \cite{spacy}。在这个顺序任务中，我们获得了 84.72% 的准确度、6.06% 的精确度和 5.57% 的召回率。]]></description>
      <guid>https://arxiv.org/abs/2403.09077</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>有意义的学习：通过通用事实指导推进大型语言模型中的抽象推理</title>
      <link>https://arxiv.org/abs/2403.09085</link>
      <description><![CDATA[arXiv:2403.09085v1 公告类型：新
摘要：大型语言模型（LLM）在各种推理场景中都表现出了令人印象深刻的性能和强大的可解释性，标志着在模仿类人智能方面迈出了一大步。尽管如此，当处理由一般事实支持的简单问题时，法学硕士通常无法提供一致和精确的答案，这表明抽象推理能力的缺陷。这引发了关于法学硕士到底是真正的推理还是仅仅是记忆的激烈争论。有鉴于此，我们设计了一项初步研究来量化和深入研究现有法学硕士的抽象推理能力。我们的研究结果表明，他们的一般推理和抽象推理表现之间存在巨大差异。为了缓解这个问题，我们定制了一个抽象推理数据集（AbsR）和一个有意义的学习范式，以教导法学硕士如何利用通用事实进行推理。结果表明，我们的方法不仅提高了法学硕士的一般推理能力，而且还使他们的抽象推理能力取得了长足的进步，超越了简单的记忆或模仿，达到了对一般事实的更细致的理解和应用。]]></description>
      <guid>https://arxiv.org/abs/2403.09085</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>MCFEND：中国假新闻检测的多源基准数据集</title>
      <link>https://arxiv.org/abs/2403.09092</link>
      <description><![CDATA[arXiv:2403.09092v1 公告类型：新
摘要：各种网络来源的假新闻盛行对公众产生了重大影响。现有的中国假新闻检测数据集仅限于仅来自微博的新闻。然而，来自多个来源的假新闻在各个方面表现出多样性，包括其内容和社会背景。纯粹针对单一新闻源训练的方法很难适用于现实场景。我们的试点实验表明，当测试数据更改为多源新闻时，从大型中国假新闻检测数据集 Weibo-21 中学习的最先进方法的 F1 分数从 0.943 显着下降到 0.470数据，未能识别超过三分之一的多源假新闻。为了解决这一限制，我们构建了第一个用于中国假新闻检测的多源基准数据集，称为 MCFEND，它由我们从社交平台、消息应用程序和传统在线新闻媒体等不同来源收集的新闻组成。值得注意的是，此类新闻已经过全球 14 家权威事实核查机构的事实核查。此外，各种现有的中国假新闻检测方法在我们提出的数据集上以跨源、多源和未见源的方式进行了彻底的评估。 MCFEND 作为基准数据集，旨在推进现实场景中的中国假新闻检测方法。]]></description>
      <guid>https://arxiv.org/abs/2403.09092</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>LAMP：地图上的语言模型</title>
      <link>https://arxiv.org/abs/2403.09059</link>
      <description><![CDATA[arXiv:2403.09059v1 公告类型：新
摘要：大型语言模型 (LLM) 有望在我们的生活中发挥越来越重要的作用，为各种任务提供帮助。在地理空间领域，法学硕士已经证明了回答一般问题的能力，例如识别一个国家的首都；然而，当涉及到回答有关特定地点（例如杂货店或餐馆）的细粒度问题时，它们的效用受到了阻碍，这些地点构成了人们日常生活的重要方面。这主要是因为我们城市的地方还没有系统地输入到LLM中，以便理解和记忆。这项研究引入了一种新颖的框架，用于根据特定城市的数据微调预训练模型，使其能够提供准确的建议，同时最大限度地减少幻觉。我们共享我们的模型 LAMP 以及用于训练它的数据。我们进行实验来分析其正确检索空间对象的能力，并将其与著名的开源和闭源语言模型（例如 GPT-4）进行比较。最后，我们通过有关日计划的案例研究探索其新兴功能。]]></description>
      <guid>https://arxiv.org/abs/2403.09059</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:13 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是并行的多语言学习者</title>
      <link>https://arxiv.org/abs/2403.09073</link>
      <description><![CDATA[arXiv:2403.09073v1 公告类型：新
摘要：在这项研究中，我们揭示了多语言大语言模型（LLM）的上下文学习（ICL）能力：通过将输入翻译为多种语言，我们为 LLM 提供多语言并行输入（PiM），这显着增强了他们的理解能力。为了测试这种能力，我们设计了广泛的实验，涵盖 8 个典型数据集、7 种语言和 8 个最先进的多语言法学硕士。实验结果表明：（1）融入更多的语言有助于PiM进一步超越传统的ICL； (2) 即使与低于基线性能的翻译相结合也会有所帮助。此外，通过检查法学硕士中激活的神经元，我们发现了一个违反直觉但有趣的现象。人们普遍认为 PiM 会比单语言输入激活更多的神经元来利用从不同语言中学到的知识，但 PiM 实际上会抑制神经元并促进更精确的神经元激活，尤其是在添加更多语言时。这种现象与神经科学关于突触修剪的见解相一致，即删除较少使用的神经连接，加强剩余部分，然后增强大脑智力。]]></description>
      <guid>https://arxiv.org/abs/2403.09073</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:13 GMT</pubDate>
    </item>
    <item>
      <title>半参数令牌序列共同监督</title>
      <link>https://arxiv.org/abs/2403.09024</link>
      <description><![CDATA[arXiv:2403.09024v1 公告类型：新
摘要：在这项工作中，我们介绍了一种半参数令牌序列协同监督训练方法。它通过同时利用传统的下一个标记预测损失（在参数标记嵌入空间上计算）和下一个序列预测损失（在非参数序列嵌入空间上计算）的监督来训练语言模型。非参数序列嵌入空间由单独的语言模型构建，该模型的任务是将输入文本压缩为单个代表性嵌入。我们的实验表明，通过两个监督训练的模型始终优于通过每个监督独立训练的模型。分析表明，这种共同监督鼓励整个模型具有更广泛的泛化能力。特别是，在预训练步骤中建立的参数标记空间的鲁棒性往往会有效增强非参数序列嵌入空间（由另一种语言模型建立的新空间）的稳定性。]]></description>
      <guid>https://arxiv.org/abs/2403.09024</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>ChartInstruct：图表理解和推理的指令调整</title>
      <link>https://arxiv.org/abs/2403.09028</link>
      <description><![CDATA[arXiv:2403.09028v1 公告类型：新
摘要：图表提供数据的可视化表示，广泛用于分析信息、解决查询以及向他人传达见解。最近出现了各种与图表相关的下游任务，例如问答和总结。解决这些任务的常见策略是微调最初在视觉任务语言上训练的各种模型。然而，此类特定于任务的模型无法解决广泛的与图表相关的任务，从而限制了它们的实际适用性。为了克服这些挑战，我们引入了 ChartInstruct：一种新颖的图表特定视觉语言指令跟踪数据集，包含由 71K 图表生成的 191K 指令。然后，我们提出了两种不同的系统，用于对此类数据集进行指令调整：（1）将用于图表理解的视觉编码器与法学硕士连接起来的端到端模型； (2) 管道模型，采用两步方法提取图表数据表并将其输入到法学硕士中。在四个下游任务的实验中，我们首先展示了我们模型的有效性——实现了一组新的最先进的结果。进一步的评估表明，我们的指令调整方法支持广泛的现实世界图表理解和推理场景，从而将我们的模型的范围和适用性扩展到新类型的任务。]]></description>
      <guid>https://arxiv.org/abs/2403.09028</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>衣衫褴褛：走向检索增强生成系统的知情设计</title>
      <link>https://arxiv.org/abs/2403.09040</link>
      <description><![CDATA[arXiv:2403.09040v1 公告类型：新
摘要：检索增强生成（RAG）通过为基于文档的问答（DBQA）等任务提供额外的上下文，极大地有益于语言模型（LM）。尽管具有潜力，但 RAG 的功能高度依赖于其配置，这就提出了一个问题：最佳的 RAG 配置是什么？为了回答这个问题，我们引入了 RAGGED 框架来分析和优化 RAG 系统。在一组代表性的 DBQA 任务中，我们研究了两种经典的稀疏和密集检索器，以及编码器-解码器和仅解码器架构中的四种表现最佳的 LM。通过 RAGGED，我们发现不同的模型适合不同的 RAG 设置。虽然编码器-解码器模型随着更多文档的增加而单调改进，但我们发现仅解码器模型只能有效地使用 &lt; 5 个文档，尽管通常具有更长的上下文窗口。 RAGGED 提供了对 LM 上下文使用习惯的进一步见解，我们发现编码器-解码器模型更多地依赖于上下文，因此对检索质量更加敏感，而仅解码器模型往往依赖于训练期间记忆的知识。]]></description>
      <guid>https://arxiv.org/abs/2403.09040</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>自动生成医疗记录的持续预训练法学硕士方法</title>
      <link>https://arxiv.org/abs/2403.09057</link>
      <description><![CDATA[arXiv:2403.09057v1 公告类型：新
摘要：法学硕士正在彻底改变 NLP 任务。然而，最强大的 LLM（如 GPT-4）对于大多数特定领域的场景来说成本太高。我们推出第一个持续训练的基于 13B Llama2 的法学硕士，专为医学对话而设计，并通过自动划线进行测量。我们的结果表明，我们的模型在 PubMedQA 中的表现优于 GPT-4，准确率达到 76.6%，并且在将医学对话总结为 SOAP 笔记方面的表现与其相匹配。值得注意的是，我们的模型在捕获更多正确医学概念方面超过了 GPT-4，并在更高的正确性和完整性方面优于人类抄写员。]]></description>
      <guid>https://arxiv.org/abs/2403.09057</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>AutoGuide：自动生成和选择大型语言模型代理的状态感知指南</title>
      <link>https://arxiv.org/abs/2403.08978</link>
      <description><![CDATA[arXiv:2403.08978v1 公告类型：新
摘要：大型语言模型（LLM）的主要限制是它们对世界的理解有限。这给基于法学硕士的代理带来了巨大的困难，特别是在预训练的法学硕士缺乏足够知识的领域。在本文中，我们介绍了一种名为 AutoGuide 的新颖框架，该框架通过利用离线体验中的隐性知识来弥补预训练法学硕士的知识差距。具体来说，AutoGuide 通过提取一组状态感知指南来有效地提取嵌入离线数据中的知识。重要的是，每个状态感知指南都以简洁的自然语言表达，并遵循条件结构，清楚地描述了它适用的状态。因此，由此产生的指南能够以一种有原则的方式来提供与代理当前决策过程相关的有用知识。我们表明，我们的方法在连续决策基准中大幅优于基于 LLM 的竞争基线。]]></description>
      <guid>https://arxiv.org/abs/2403.08978</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>精神：在正交参数空间中纠正语言模型</title>
      <link>https://arxiv.org/abs/2403.08994</link>
      <description><![CDATA[arXiv:2403.08994v1 公告类型：新
摘要：语言模型（LM）极大地推动了自然语言处理的研究。然而，LM 也对产生偏见或有毒内容以及训练数据集中私人信息的潜在泄露表示担忧。在这项工作中，我们提出了一种新的有效方法 Ethos，它可以纠正 LM，以减轻输出中的毒性和偏差，并避免隐私泄露。 Ethos 建立在任务算术的基础上。然而，与当前的任务算术算法不同，Ethos 在重建任务向量时区分一般有益和不需要的知识。具体来说，Ethos 首先使用奇异值分解从预训练模型中获取一组主成分。然后，通过将任务向量投影到主成分上，Ethos 识别出编码一般或不需要的知识的主成分。 Ethos 仅使用具有不需要的知识的任务向量来执行否定，从而最大限度地减少对一般模型效用的附带损害。我们展示了我们的方法在三个不同任务上的有效性：去偏见、解毒和记忆忘却。评估表明，与当前的任务算术方法相比，Ethos 在消除不需要的知识和保持整体模型性能方面更有效。]]></description>
      <guid>https://arxiv.org/abs/2403.08994</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>AraTrust：阿拉伯语法学硕士的可信度评估</title>
      <link>https://arxiv.org/abs/2403.09017</link>
      <description><![CDATA[arXiv:2403.09017v1 公告类型：新
摘要：人工智能（AI）系统的快速进步和广泛接受凸显了理解与人工智能相关的功能和潜在风险的迫切要求。鉴于阿拉伯语的语言复杂性、文化丰富性以及人工智能研究中代表性不足的地位，迫切需要关注阿拉伯语相关任务的大型语言模型 (LLM) 性能和安全性。尽管在发展方面取得了一些进展，但缺乏全面的可信度评估基准，这对准确评估和提高阿拉伯语提示的法学硕士的安全性提出了重大挑战。在本文中，我们介绍 AraTrust 1，这是第一个针对阿拉伯语法学硕士的综合可信度基准。 AraTrust 包含 516 个人工撰写的多项选择题，涉及与真实性、道德、安全、身体健康、心理健康、不公平、非法活动、隐私和攻击性语言相关的多个维度。通过引入 AraTrust，我们的目标是促进合作，为阿拉伯语用户创建更安全、更值得信赖的法学硕士。我们根据我们的基准评估了一组法学硕士，以评估其可信度。 GPT-4 在阿拉伯语方面被证明是最值得信赖的。]]></description>
      <guid>https://arxiv.org/abs/2403.09017</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>从“嗯”到“是”：人类对话中信息流的产生、预测和调节</title>
      <link>https://arxiv.org/abs/2403.08890</link>
      <description><![CDATA[arXiv:2403.08890v1 公告类型：新
摘要：谈话需要注意力。演讲者必须记住单词，听众必须理解它们，双方必须一起协商信息流，所有这些都在不到一秒的时间内完成。我们使用大型语言模型来研究它在大型英语对话数据集 CANDOR 语料库中的工作原理。我们对非结构化对话的信息密度进行了新的估计，约为 13 位/秒，并发现与检索和呈现该信息的认知负荷相关的显着影响。我们还揭示了反向渠道——听众提供的简短的“是”、“嗯嗯”和“嗯嗯”——在调节新奇事物的产生方面的作用：反向渠道的引导与信息率下降有关，而下游语音则反弹至以前的费率。我们的研究结果为我们如何应对认知资源波动的需求以及我们如何与他人合作协商这些需求的长期理论提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.08890</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>检测有争议主题的检索增强生成中的幻觉和覆盖错误</title>
      <link>https://arxiv.org/abs/2403.08904</link>
      <description><![CDATA[arXiv:2403.08904v1 公告类型：新
摘要：我们基于维基百科的中立观点（NPOV）原则，探索了一种处理基于 LLM 的聊天机器人中有争议主题的策略：承认不存在单一真实答案并提出多种观点。我们将其描述为检索增强生成，其中从知识库中检索观点，而法学硕士的任务是从给定的观点生成流畅且忠实的响应。作为起点，我们使用确定性检索系统，然后重点关注这种文本生成方法中出现的常见 LLM 失败模式，即幻觉和覆盖错误。我们提出并评估了三种基于（1）单词重叠、（2）显着性和（3）基于 LLM 的分类器来检测此类错误的方法。我们的结果表明，基于 LLM 的分类器，即使仅针对合成错误进行训练，也能实现较高的错误检测性能，在明确错误情况下，幻觉的 ROC AUC 分数为 95.3%，覆盖错误检测的 ROC AUC 分数为 90.5%。我们表明，当没有可用的训练数据时，我们的其他方法在幻觉（84.0％）和覆盖错误（85.2％）检测方面仍然产生良好的结果。]]></description>
      <guid>https://arxiv.org/abs/2403.08904</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>LMStyle Benchmark：评估聊天机器人的文本样式迁移</title>
      <link>https://arxiv.org/abs/2403.08943</link>
      <description><![CDATA[arXiv:2403.08943v1 公告类型：新
摘要：自从 ChatGPT 取得突破以来，大语言模型（LLM）引起了研究界的广泛关注。随着法学硕士的发展，对话模型的文本风格迁移问题已经成为自然的延伸，聊天机器人可能拥有自己的风格甚至性格。然而，尚未为这一新设置建立标准评估指标。本文旨在通过提出 LMStyle Benchmark 来解决这个问题，这是一种适用于聊天式文本风格迁移（C-TST）的新颖评估框架，可以以自动化和可扩展的方式衡量法学硕士的风格迁移质量。除了传统的风格强度指标之外，LMStyle Benchmark 还考虑了指标的一个新颖方面，即适当性，这是一种高级指标，无需参考样本的帮助即可考虑连贯性、流畅性和其他隐含因素。我们的实验表明，LMStyle Benchmark引入的新评估方法在适当性方面与人类判断具有更高的相关性。基于 LMStyle Benchmark，我们为流行的法学硕士（包括 LLaMA、Alpaca 和 Vicuna）提供了一份全面的评估结果列表，反映了它们的风格特征，例如形式和情感强度以及它们的适当性。]]></description>
      <guid>https://arxiv.org/abs/2403.08943</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:10 GMT</pubDate>
    </item>
    </channel>
</rss>