<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 08 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>HaluEval-Wild：评估野外语言模型的幻觉</title>
      <link>https://arxiv.org/abs/2403.04307</link>
      <description><![CDATA[arXiv:2403.04307v1 公告类型：新
摘要：幻觉对关键领域的大型语言模型（LLM）的可靠性提出了重大挑战。最近设计用于评估传统 NLP 任务（例如知识密集型问答 (QA) 和总结）中的 LLM 幻觉的基准不足以捕捉动态、现实环境中用户与 LLM 交互的复杂性。为了解决这一差距，我们推出了 HaluEval-Wild，这是第一个专门为评估野外 LLM 幻觉而设计的基准。我们从现有的现实世界用户与法学硕士交互数据集（包括 ShareGPT）中精心收集具有挑战性（由 Alpaca 进行对抗性过滤）的用户查询，以评估各种法学硕士的幻觉率。在分析收集到的查询后，我们将它们分为五种不同的类型，这使得能够对法学硕士表现出的幻觉类型进行细粒度分析，并利用强大的 GPT-4 模型和检索增强生成 (RAG) 综合参考答案。我们的基准提供了一种新颖的方法，可以增强我们对反映现实世界交互场景中法学硕士可靠性的理解和改进。]]></description>
      <guid>https://arxiv.org/abs/2403.04307</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>DEEP-ICL：语言模型情境学习的定义丰富的专家</title>
      <link>https://arxiv.org/abs/2403.04233</link>
      <description><![CDATA[arXiv:2403.04233v1 公告类型：新
摘要：长期以来，人们一直认为大型语言模型（LLM）中的参数数量巨大，可以驱动上下文学习（ICL）能力，通过利用特定于任务的演示来实现显着的性能改进。为了挑战这一假设，我们引入了 DEEP-ICL，这是一种用于 ICL 的新颖任务定义丰富的专家集成方法。 DEEP-ICL 从给定的演示中显式提取任务定义，并通过学习特定于任务的示例生成响应。我们认为 ICL 的改进并不直接依赖于模型大小，而本质上源于对任务定义和任务引导学习的理解。受此启发，DEEP-ICL 结合了两个具有不同角色的 3B 模型（一个用于总结任务定义，另一个用于学习任务演示），并实现了与 LLaMA2-13B 相当的性能。此外，我们的框架通过克服预训练序列长度限制并支持无限演示，优于传统 ICL。我们认为，DEEP-ICL 为实现高效的小样本学习提供了一种新颖的替代方案，超越了传统的 ICL。]]></description>
      <guid>https://arxiv.org/abs/2403.04233</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>UltraWiki：具有负种子实体的超细粒度实体集扩展</title>
      <link>https://arxiv.org/abs/2403.04247</link>
      <description><![CDATA[arXiv:2403.04247v1 公告类型：新
摘要：实体集扩展（ESE）旨在识别与给定种子实体集属于同一语义类的新实体。传统方法主要依靠正种子实体来表示目标语义类，这对超细粒度语义类的表示提出了挑战。超细粒度语义类是在具有更具体属性约束的细粒度语义类的基础上定义的。仅用正面种子实体来描述它会导致两个问题：（i）超细粒度语义类别之间的歧义。 (ii) 无法定义“不需要的”语义。由于这些固有的缺点，以前的方法很难解决超细粒度的 ESE（Ultra-ESE）。为了解决这个问题，我们首先在输入中引入负种子实体，它们与正种子实体属于相同的细粒度语义类，但在某些属性上有所不同。负面种子实体通过正面和负面属性之间的对比来消除语义歧义。同时，它提供了一种直接的方式来表达“不想要的”。为了评估 Ultra-ESE 中的模型性能，我们构建了 UltraWiki，这是第一个为 Ultra-ESE 定制的大型数据集。 UltraWiki 包含 236 个超细粒度语义类，其中每个查询都用 3-5 个正负种子实体表示。提出了基于检索的框架 RetExpan 和基于生成的框架 GenExpan 来综合评估 Ultra-ESE 中两种不同范式的大型语言模型的有效性。此外，我们设计了三种策略来增强模型对超细粒度实体语义的理解：对比学习、检索增强和思维链推理。大量的实验证实了我们提出的策略的有效性，也表明 Ultra-ESE 仍有很大的改进空间。]]></description>
      <guid>https://arxiv.org/abs/2403.04247</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>Proxy-RLHF：使用代理解耦大型语言模型中的生成和对齐</title>
      <link>https://arxiv.org/abs/2403.04283</link>
      <description><![CDATA[arXiv:2403.04283v1 公告类型：新
摘要：人类反馈强化学习（RLHF）是确保大型语言模型（LLM）符合人类价值观的流行方法。然而，现有的 RLHF 方法需要较高的计算成本，一个主要原因是 RLHF 将生成和比对任务同时分配给 LLM。在本文中，我们介绍了 Proxy-RLHF，它将 LLM 的生成和对齐过程解耦，以更低的计算成本实现与人类价值观的对齐。我们从专为对齐过程设计的新型马尔可夫决策过程 (MDP) 开始，并采用强化学习 (RL) 来训练简化的代理模型，该模型可监督 LLM 的代币生成，而无需更改 LLM 本身。实验表明，我们的方法仅用其他方法 1% 的训练参数就达到了相当的对齐水平。]]></description>
      <guid>https://arxiv.org/abs/2403.04283</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>通过语义相似性提取人物角色以生成情感支持对话</title>
      <link>https://arxiv.org/abs/2403.04212</link>
      <description><![CDATA[arXiv:2403.04212v1 公告类型：新
摘要：通过对话系统提供情感支持在当今世界变得越来越重要，因为它可以在许多对话场景中支持心理健康和社交互动。之前的研究表明，使用角色可以有效地产生同理心和支持性反应。他们经常依赖预先提供的角色，而不是在对话中推断它们。然而，在对话开始之前并不总是能够获得用户角色。为了应对这一挑战，我们提出了 PESS（通过语义相似性进行角色提取），这是一种新颖的框架，可以从对话中自动推断出信息丰富且一致的角色。我们根据语义相似度分数设计完整性损失和一致性损失。完整性损失鼓励模型生成缺失的角色信息，一致性损失指导模型区分一致和不一致的角色。我们的实验结果表明，PESS 推断出的高质量角色信息可有效产生情感支持反应。]]></description>
      <guid>https://arxiv.org/abs/2403.04212</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>基于Glass-box特征的大语言模型自评估</title>
      <link>https://arxiv.org/abs/2403.04222</link>
      <description><![CDATA[arXiv:2403.04222v1 公告类型：新
摘要：开源大型语言模型（LLM）的激增凸显了对评估方法的迫切需求。现有的工作主要依靠外部评估者，侧重于培训和激励策略。然而，一个关键的方面——模型感知玻璃盒功能——却被忽视了。在本研究中，我们探索了玻璃盒特征在自我评估场景下的效用，即应用法学硕士来评估自己的输出。我们研究了各种玻璃盒特征组，发现 softmax 分布可以作为质量评估的可靠指标。此外，我们提出了两种策略来通过结合参考文献中的特征来增强评估。公共基准的实验结果验证了利用玻璃盒特征进行法学硕士自我评估的可行性。]]></description>
      <guid>https://arxiv.org/abs/2403.04222</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>协调者：法学硕士与协调的解耦</title>
      <link>https://arxiv.org/abs/2403.04224</link>
      <description><![CDATA[arXiv:2403.04224v1 公告类型：新
摘要：大型语言模型（LLM）需要符合人类的期望，以确保其在大多数应用中的安全性和实用性。对齐是具有挑战性的、成本高昂的，并且需要针对每个法学硕士和对齐标准重复进行。我们建议通过训练对齐器模型来解耦法学硕士和对齐，该模型可用于根据需要对齐任何给定标准的法学硕士，从而减少对齐对性能的潜在负面影响。我们训练对准器模型的方法仅依赖于（提示的）LLM 生成的合成数据，并且可以轻松调整以适应各种对准标准。我们通过训练“道德”矫正器来说明我们的方法，并根据经验验证其功效。]]></description>
      <guid>https://arxiv.org/abs/2403.04224</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>语音到语音机器翻译中压力转移的尝试</title>
      <link>https://arxiv.org/abs/2403.04178</link>
      <description><![CDATA[arXiv:2403.04178v1 公告类型：新
摘要：印度教育部门的语言多样性构成了重大挑战，阻碍了包容性。尽管通过在线教育内容实现了知识民主化，但英语作为互联网通用语言的主导地位限制了可访问性，这凸显了翻译成印度语言的迫切需要。尽管现有语音到语音机器翻译 (SSMT) 技术，但这些系统中缺乏语调，导致翻译单调，导致受众失去兴趣并脱离内容。为了解决这个问题，我们的论文引入了一个带有印度英语重音注释的数据集，以及能够将重音合并到合成语音中的文本转语音 (TTS) 架构。该数据集用于训练重音检测模型，然后在 SSMT 系统中使用该模型来检测源语音中的重音并将其转换为目标语言语音。 TTS 架构基于 FastPitch，可以根据给定的重读词修改方差。我们提出了一种印度英语到印地语 SSMT 系统，该系统可以转移压力，旨在提高教育内容的整体质量和参与度。]]></description>
      <guid>https://arxiv.org/abs/2403.04178</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>度量感知的 LLM 推理</title>
      <link>https://arxiv.org/abs/2403.04182</link>
      <description><![CDATA[arXiv:2403.04182v1 公告类型：新
摘要：大型语言模型 (LLM) 在一系列 NLP 任务上表现出了强劲的结果。通常，输出是通过从 LLM 的基础分布中进行自回归采样获得的。我们表明，这种推理策略对于一系列任务和相关的评估指标来说可能不是最优的。作为补救措施，我们提出了度量感知 LLM 推理：一种在推理时针对自定义度量进行优化的决策理论方法。我们报告了学术基准和公开模型的基线改进。]]></description>
      <guid>https://arxiv.org/abs/2403.04182</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是上下文中的分子学习者</title>
      <link>https://arxiv.org/abs/2403.04197</link>
      <description><![CDATA[arXiv:2403.04197v1 公告类型：新
摘要：大型语言模型（LLM）在生化任务中表现出了卓越的性能，特别是分子标题翻译任务，其目的是弥合分子和自然语言文本之间的差距。然而，以前使法学硕士适应分子标题翻译任务的方法需要额外的特定领域的预训练阶段，分子和文本空间之间的对齐较弱，或者对法学硕士的规模提出了严格的要求。为了解决这些挑战，我们提出了上下文分子适应（ICMA），作为一种新范式，允许法学硕士通过上下文分子调整从上下文示例中学习分子文本对齐。具体来说，ICMA 包含以下三个阶段：跨模态检索、检索后重新排序和上下文分子调谐。最初，跨模式检索利用 BM25 标题检索和分子图检索来检索信息丰富的上下文示例。此外，我们还提出使用序列反转和随机游走进行检索后重新排序，以进一步提高检索结果的质量。最后，上下文分子调整通过检索到的示例解锁了法学硕士的上下文分子学习能力，并针对分子标题翻译任务调整了法学硕士的参数。实验结果表明，ICMT 可以使法学硕士能够实现最先进的或可比的性能，而无需额外的训练语料库和复杂的结构，这表明法学硕士本质上是上下文中的分子学习者。]]></description>
      <guid>https://arxiv.org/abs/2403.04197</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>不要责怪数据，责怪模型：从主观注释学习时理解噪音和偏差</title>
      <link>https://arxiv.org/abs/2403.04085</link>
      <description><![CDATA[arXiv:2403.04085v1 公告类型：新
摘要：研究人员提高了人们对聚合标签危害的认识，特别是在主观任务中，这些任务自然包含人类注释者之间的分歧。在这项工作中，我们表明仅提供聚合标签的模型对高度不一致的数据实例表现出较低的置信度。虽然之前的研究认为此类实例被错误标记，但我们认为高度不一致的文本实例难以学习的原因是传统的聚合模型在从主观任务中提取有用信号方面表现不佳。受最近证明从原始注释中学习的有效性的研究的启发，我们研究了使用多重地面实况（Multi-GT）方法进行分类。我们的实验表明，高度分歧实例的置信度有所提高。]]></description>
      <guid>https://arxiv.org/abs/2403.04085</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>DA-Net：用于多源跨语言迁移学习的解缠结自适应网络</title>
      <link>https://arxiv.org/abs/2403.04158</link>
      <description><![CDATA[arXiv:2403.04158v1 公告类型：新
摘要：多源跨语言迁移学习处理语言转换下任务知识从多种标记源语言到未标记目标语言的迁移。现有方法通常侧重于对遵循共享编码器的不同源的特定于语言的分类器产生的预测进行加权。但是，所有源语言共享相同的编码器，并由所有这些语言更新。提取的表示不可避免地包含不同源语言的信息，这可能会干扰特定于语言的分类器的学习。此外，由于语言差距，使用源标签训练的特定语言分类器无法对目标语言做出准确的预测。这两个事实都会损害模型的性能。为了应对这些挑战，我们提出了一种解缠结自适应网络（DA-Net）。首先，我们设计了一种反馈引导的协作解开方法，旨在净化分类器的输入表示，从而减轻来自多个来源的相互干扰。其次，我们提出了一种类感知并行适应方法，该方法可以对齐每个源-目标语言对的类级别分布，从而缩小语言对的语言差距。涉及 38 种语言的三种不同任务的实验结果验证了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.04158</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以进行分析推理吗？</title>
      <link>https://arxiv.org/abs/2403.04031</link>
      <description><![CDATA[arXiv:2403.04031v1 公告类型：新
摘要：本文探讨了体育领域前沿的分析推理大语言模型。我们的分析推理体现了让大型语言模型计算 NBA 和 NFL 比赛中每支球队在一个季度内得分的任务。我们的主要发现有两个方面。首先，我们发现在我们使用的所有模型中，GPT-4 的有效性最为突出，其次是 Claude-2.1，GPT-3.5、Gemini-Pro 和 Llama-2-70b 落后。具体来说，我们比较了三种不同的提示技术和分而治之的方法，我们发现后者是最有效的。我们的分而治之的方法将逐个比赛数据分解为更小、更易于管理的部分，单独解决每个部分，然后将它们聚合在一起。除了分而治之的方法之外，我们还探索了思想链（CoT）策略，该策略显着改善了某些模型的结果，特别是 GPT-4 和 Claude-2.1，其准确率显着提高。然而，CoT 策略对 GPT-3.5 和 Gemini-Pro 等其他模型的性能影响可以忽略不计甚至有害。其次，令我们惊讶的是，我们观察到大多数模型（包括 GPT-4）都难以准确计算 NBA 季度的总得分，尽管在计算 NFL 季度得分方面表现出色。这促使我们通过大量实验进一步研究影响分析推理任务复杂性的因素，通过这些实验我们得出结论：任务复杂性取决于上下文的长度、信息密度和相关信息的存在。我们的研究为分析推理任务的复杂性和开发未来大型语言模型的潜在方向提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.04031</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>通过高质量伪标签选择进行半监督对话抽象总结</title>
      <link>https://arxiv.org/abs/2403.04073</link>
      <description><![CDATA[arXiv:2403.04073v1 公告类型：新
摘要：半监督对话摘要（SSDS）利用模型生成的摘要来减少对人类标记数据的依赖并提高摘要模型的性能。在解决标签噪声的同时，之前的半监督学习工作主要集中在自然语言理解任务上，假设每个样本都有一个独特的标签。然而，这些方法并不直接适用于 SSDS，因为它是一项生成任务，每个对话都可以用不同的方式进行总结。在这项工作中，我们提出了一种新颖的评分方法 SiCF，它封装了摘要模型质量的三个主要维度：语义不变性（表示模型置信度）、覆盖率（事实召回）和忠实性（事实精度）。使用 SiCF 分数，我们选择具有高质量生成摘要的未标记对话来训练摘要模型。对三个公共数据集的综合实验证明了 SiCF 分数在对话摘要任务的不确定性估计和半监督学习中的有效性。我们的代码可在 \url{https://github.com/amazon-science/summarization-sicf-score} 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.04073</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>形式理解中的变压器和语言模型：扫描文档分析的全面回顾</title>
      <link>https://arxiv.org/abs/2403.04080</link>
      <description><![CDATA[arXiv:2403.04080v1 公告类型：新
摘要：本文对扫描文档背景下的形式理解主题的研究工作进行了全面的调查。我们深入研究了该领域的最新进展和突破，强调了语言模型和转换器在解决这一具有挑战性的任务中的重要性。我们的研究方法涉及对过去十年流行文献和趋势理解形式的深入分析，使我们能够对该领域的演变提供有价值的见解。我们专注于尖端模型，展示 Transformer 如何推动该领域向前发展，彻底改变形式理解技术。我们的探索包括对最先进的语言模型的广泛检查，旨在有效解决噪声扫描文档的复杂性。此外，我们还概述了最新和最相关的数据集，这些数据集可作为评估所选模型性能的基本基准。通过比较和对比这些模型的功能，我们的目标是为研究人员和实践者提供有用的指导，帮助他们为特定的形式理解任务选择最合适的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2403.04080</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:42 GMT</pubDate>
    </item>
    </channel>
</rss>