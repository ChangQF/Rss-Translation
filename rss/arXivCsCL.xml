<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Wed, 20 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过大型语言模型构建特色 AI 代理</title>
      <link>https://arxiv.org/abs/2403.12368</link>
      <description><![CDATA[arXiv:2403.12368v1 公告类型：新
摘要：大型语言模型（LLM）的进步导致聊天机器人系统的性能显着增强。许多研究人员致力于开发为聊天机器人带来特性。虽然已经有使用法学硕士开发角色驱动的聊天机器人的商业产品，但值得注意的是，该领域的学术研究仍然相对匮乏。我们的研究重点是通过模拟不同环境下的现实生活中的个体来调查法学硕士在构建特征人工智能代理方面的表现。目前的调查主要集中在具有简单配置文件的角色上。针对这一研究空白，我们为特征人工智能代理任务创建了一个基准，包括数据集、技术和评估指标。为此基准构建了一个名为“Character100”的数据集，其中包含维基百科上访问量最大的人员，用于进行角色扮演的语言模型。利用构建的数据集，我们对各种环境下的法学硕士进行了全面评估。此外，我们还设计了一套用于定量绩效评估的自动指标。实验结果强调了进一步提高法学硕士构建特征人工智能体能力的潜在方向。该基准可在 https://github.com/nuaa-nlp/Character100 上获取。]]></description>
      <guid>https://arxiv.org/abs/2403.12368</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>RankPrompt：逐步比较使语言模型成为更好的推理机</title>
      <link>https://arxiv.org/abs/2403.12373</link>
      <description><![CDATA[arXiv:2403.12373v1 公告类型：新
摘要：大型语言模型（LLM）在各种推理任务中取得了令人印象深刻的性能。然而，即使是像 ChatGPT 这样最先进的法学硕士，在推理过程中也容易出现逻辑错误。现有的解决方案，包括部署特定于任务的验证器或对多个推理路径进行投票，要么需要大量的人工注释，要么在响应不一致的情况下失败。为了应对这些挑战，我们引入了 RankPrompt，这是一种新的提示方法，使法学硕士能够对他们的回答进行自我排名，而无需额外的资源。 RankPrompt 将排名问题分解为不同响应之间的一系列比较，利用法学硕士的固有功能生成比较链作为上下文范例。我们在 11 个算术和常识推理任务中进行的实验表明，RankPrompt 显着增强了 ChatGPT 和 GPT-4 的推理性能，提升幅度高达 13%。 RankPrompt 还擅长基于 LLM 的开放式生成自动评估，在 AlpacaEval 集中 74% 的时间与人类偏好保持一致。此外，RankPrompt 展示了针对响应顺序和一致性变化的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2403.12373</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型从临床记录中提取有关药物使用障碍严重程度的信息：零样本学习方法</title>
      <link>https://arxiv.org/abs/2403.12297</link>
      <description><![CDATA[arXiv:2403.12297v1 公告类型：新
摘要：药物使用障碍（SUD）因其对健康和社会的有害影响而引起人们的主要关注。 SUD 的识别和治疗取决于多种因素，例如严重程度、共同决定因素（例如戒断症状）和健康的社会决定因素。美国保险公司使用的现有诊断编码系统，例如国际疾病分类 (ICD-10)，缺乏某些诊断的粒度，但临床医生会添加这种粒度（如《精神疾病诊断和统计手册》分类或 DSM 中所见） -5) 作为临床笔记中的补充非结构化文本。传统的自然语言处理（NLP）方法在准确解析如此多样化的临床语言方面面临局限性。大型语言模型 (LLM) 有望通过适应不同的语言模式来克服这些挑战。本研究调查了法学硕士在从临床记录中提取各种 SUD 诊断的严重程度相关信息的应用。我们提出了一种采用法学硕士零样本学习的工作流程，并带有精心设计的提示和后处理技术。通过对开源法学硕士 Flan-T5 的实验，我们证明了其与基于规则的方法相比具有更高的召回率。我们重点关注 11 类 SUD 诊断，展示了法学硕士在提取严重程度信息方面的有效性，有助于改进 SUD 患者的风险评估和治疗计划。]]></description>
      <guid>https://arxiv.org/abs/2403.12297</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>OpenEval：在能力、一致性和安全性方面对中国法学硕士进行基准测试</title>
      <link>https://arxiv.org/abs/2403.12316</link>
      <description><![CDATA[arXiv:2403.12316v1 公告类型：新
摘要：中文大语言模型（LLM）的快速发展给LLM的高效评估带来了巨大挑战。虽然目前的举措引入了新的基准或评估平台来评估中国法学硕士，但其中许多主要关注能力，通常忽视潜在的一致性和安全问题。为了弥补这一差距，我们引入了 OpenEval，这是一个评估测试平台，可以在能力、一致性和安全性方面对中国法学硕士进行基准测试。在能力评估方面，我们包含了12个基准数据集，从NLP任务、学科知识、常识推理和数学推理4个子维度评估中国法学硕士。对于一致性评估，OpenEval 包含 7 个数据集，用于检查中国法学硕士输出中的偏见、冒犯性和非法性。为了评估高级法学硕士的安全性，特别是预期风险（例如，权力追求、自我意识），我们包括 6 个数据集。除了这些基准之外，我们还实施了分阶段的公开评估和基准更新策略，以确保OpenEval符合中国LLM的发展甚至能够提供前沿的基准数据集来指导中国LLM的发展。在我们的第一次公开评估中，我们测试了一系列中国法学硕士，参数范围从 7B 到 72B，包括开源模型和专有模型。评估结果表明，虽然中国的法学硕士在某些任务中表现出了令人印象深刻的表现，但更多的注意力应该集中在更广泛的方面，例如常识推理、一致性和安全性。]]></description>
      <guid>https://arxiv.org/abs/2403.12316</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>零样本多任务幻觉检测</title>
      <link>https://arxiv.org/abs/2403.12244</link>
      <description><![CDATA[arXiv:2403.12244v1 公告类型：新
摘要：在最近的研究中，大型语言模型的广泛使用强调了稳健的评估方法对于评估文本生成质量和与特定任务的相关性的重要性。这揭示了一个被称为幻觉的普遍问题，这是模型中的一种紧急情况，其中生成的文本缺乏对源的忠实度并偏离评估标准。在这项研究中，我们正式定义了幻觉，并提出了一个在零样本设置中定量检测幻觉的框架，利用我们的定义和模型输出需要任务和样本特定输入的假设。在检测幻觉时，我们的解决方案在模型感知设置中实现了 0.78 的准确度，在与模型无关的设置中实现了 0.61 的准确度。值得注意的是，我们的解决方案保持了计算效率，比其他 SOTA 方法需要更少的计算资源，符合轻量级和压缩模型的趋势。]]></description>
      <guid>https://arxiv.org/abs/2403.12244</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>FinLlama：算法交易应用程序的金融情绪分类</title>
      <link>https://arxiv.org/abs/2403.12285</link>
      <description><![CDATA[arXiv:2403.12285v1 公告类型：新
摘要：在线财经新闻有多种来源，影响着市场走势和交易者的决策。这凸显了除了拥有​​适当的算法交易技术之外还需要准确的情绪分析，以做出更明智的交易决策。基于标准词典的情绪方法已经证明了它们在帮助财务决策方面的力量。然而，众所周知，它们会遇到与上下文敏感性和词序相关的问题。大型语言模型 (LLM) 也可以在这种情况下使用，但它们不是特定于金融的，并且往往需要大量的计算资源。为了促进金融特定的 LLM 框架，我们引入了一种基于 Llama 2 7B 基础模型的新颖方法，以便从其生成性和全面的语言操作中受益。这是通过在一小部分有监督的金融情绪分析数据上对 Llama2 7B 模型进行微调来实现的，以共同处理金融词汇和上下文的复杂性，并进一步为其配备基于神经网络的决策机制。这种生成器分类器方案被称为 FinLlama，经过训练不仅可以对情绪效价进行分类，还可以量化其强度，从而为交易者提供对金融新闻文章的细致入微的洞察。作为补充，通过 LoRA 实现参数高效微调可优化可训练参数，从而在不牺牲准确性的情况下最大限度地减少计算和内存需求。模拟结果表明，拟议的 FinLlama 能够为增强投资组合管理决策和增加市场回报提供框架。这些结果支撑了 FinLlama 构建高回报投资组合的能力，即使在动荡时期和不可预测的市场事件中，该投资组合也表现出增强的弹性。]]></description>
      <guid>https://arxiv.org/abs/2403.12285</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>DALL-E 2 中组成句法和语义的比较研究</title>
      <link>https://arxiv.org/abs/2403.12294</link>
      <description><![CDATA[arXiv:2403.12294v1 公告类型：新
摘要：在这项研究中，我们比较了 DALL-E 2 在视觉上代表幼儿理解测试中语言提示含义的效果。代表语法知识基本组成部分的句子是从对数百名 2-7 岁英语儿童进行的评估测试中选出的，我们为这些儿童收集了原始的项目级数据。 DALL-E 2 收到这些提示五次，为每个项目生成 20 个卡通片，供 9 名成年评委评分。结果显示，即使在最小的年龄（2 岁），DALL-E 2 生成的图像也无法与儿童的语义准确性相匹配。 DALL-E 2未能以可逆的形式分配适当的角色；尽管对比提示比孩子们收到的要容易，但它还是失败了；它经常将形容词分配给错误的名词；它忽略了被动语态中的隐含主体。这项工作指出 DALL-E 2 明显缺乏组合句子表示。]]></description>
      <guid>https://arxiv.org/abs/2403.12294</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>评估命名实体识别：巴西企业盈利电话转录的单语言和多语言 Transformer 模型的比较分析</title>
      <link>https://arxiv.org/abs/2403.12212</link>
      <description><![CDATA[arXiv:2403.12212v1 公告类型：新
摘要：命名实体识别（NER）是一种从文本文档中提取信息的自然语言处理技术。然而，现有的 NER 研究大部分都集中在英语文档上，导致针对葡萄牙语金融领域量身定制的数据集的可用性存在缺口。这项研究解决了金融领域对 NER 的需求，重点关注从巴西银行的财报电话会议记录中提取的葡萄牙语文本。通过整理包含 384 个转录的综合数据集并利用弱监督技术进行注释，我们评估了在葡萄牙语（BERTimbau 和 PTT5）上训练的单语言模型和多语言模型（mBERT 和 mT5）的性能。值得注意的是，我们引入了一种新颖的方法，将标记分类任务重新构建为文本生成问题，从而能够对 T5 模型进行微调和评估。在对模型进行微调之后，我们使用性能和错误指标对测试数据集进行评估。我们的研究结果表明，基于 BERT 的模型始终优于基于 T5 的模型。此外，虽然多语言模型表现出可比的宏观 F1 分数，但 BERTimbau 表现出优于 PTT5 的性能。对 PTT5 和 mT5 生成的句子进行手动分析，发现原始句子和生成的句子之间的相似度范围为 0.89 到 1.0。然而，由于两种模型都存在差异，例如货币和百分比值的改变，因此出现了严重错误，这凸显了金融领域准确性和一致性的重要性。尽管存在这些挑战，PTT5 和 mT5 通过我们提出的方法分别实现了 98.52% 和 98.85% 的令人印象深刻的宏观 F1 分数。此外，我们的研究揭示了模型之间推理的内存和时间消耗的显着差异。]]></description>
      <guid>https://arxiv.org/abs/2403.12212</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>基于参考的指标在问题生成中证明了自己的错误</title>
      <link>https://arxiv.org/abs/2403.12242</link>
      <description><![CDATA[arXiv:2403.12242v1 公告类型：新
摘要：基于参考的指标（例如 BLEU 和 BERTScore）被广泛用于评估问题生成（QG）。在本研究中，在 SQuAD 和 HotpotQA 等 QG 基准上，我们发现使用人工编写的参考文献并不能保证基于参考指标的有效性。大多数 QG 基准只有一个参考；我们复制了注释过程并收集了另一个参考。一个好的指标应该能够对经过人工验证的问题进行评分，不会比生成的问题差。然而，我们新收集的参考文献的基于参考指标的结果反驳了这些指标本身。我们利用大型语言模型提出了一种由多维标准组成的无参考指标，例如自然性、可回答性和复杂性。这些标准不限于单个参考问题的句法或语义，并且度量不需要不同的参考集。实验表明，我们的指标可以准确地区分高质量问题和有缺陷的问题，并实现与人类判断最先进的一致性。]]></description>
      <guid>https://arxiv.org/abs/2403.12242</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>EasyJailbreak：越狱大型语言模型的统一框架</title>
      <link>https://arxiv.org/abs/2403.12171</link>
      <description><![CDATA[arXiv:2403.12171v1 公告类型：新
摘要：越狱攻击对于识别和减轻大型语言模型（LLM）的安全漏洞至关重要。它们旨在绕过安全措施并引发禁止的输出。然而，由于各种越狱方法之间存在显着差异，社区没有可用的标准实施框架，这限制了全面的安全评估。本文介绍了 EasyJailbreak，这是一个统一的框架，可简化针对 LLM 的越狱攻击的构建和评估。它使用四个组件构建越狱攻击：选择器、变异器、约束器和评估器。这种模块化框架使研究人员能够轻松地通过新颖和现有组件的组合来构造攻击。到目前为止，EasyJailbreak 支持 11 种不同的越狱方法，并有助于广泛的法学硕士的安全验证。我们对 10 个不同的法学硕士进行的验证揭示了一个重大漏洞，在各种越狱攻击下，平均违规概率为 60%。值得注意的是，即使是 GPT-3.5-Turbo 和 GPT-4 等高级模型，平均攻击​​成功率 (ASR) 也分别为 57% 和 33%。我们为研究人员发布了丰富的资源，包括网络平台、PyPI 发布包、截屏视频和实验输出。]]></description>
      <guid>https://arxiv.org/abs/2403.12171</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>TnT-LLM：使用大型语言模型进行大规模文本挖掘</title>
      <link>https://arxiv.org/abs/2403.12173</link>
      <description><![CDATA[arXiv:2403.12173v1 公告类型：新
摘要：将非结构化文本转换为由有用的类别标签组织的结构化且有意义的形式，是下游分析和应用的文本挖掘的基本步骤。然而，大多数用于生成标签分类和构建基于文本的标签分类器的现有方法仍然严重依赖于领域专业知识和手动管理，使得该过程既昂贵又耗时。当标签空间未指定并且大规模数据注释不可用时，这尤其具有挑战性。在本文中，我们通过大型语言模型（LLM）解决这些挑战，其基于提示的界面有助于大规模伪标签的归纳和使用。我们提出了 TnT-LLM，这是一个两阶段框架，它利用 LLM 来自动化端到端标签生成和分配的过程，对于任何给定的用例，只需最少的人力。在第一阶段，我们引入了一种零样本、多阶段推理方法，使法学硕士能够迭代地生成和完善标签分类法。在第二阶段，LLM 被用作生成训练样本的数据标记器，以便可以可靠地构建、部署和大规模服务轻量级监督分类器。我们将 TnT-LLM 应用于 Bing Copilot（以前称为 Bing Chat）（一种基于聊天的开放域搜索引擎）的用户意图和对话域分析。使用人工和自动评估指标进行的大量实验表明，与最先进的基线相比，TnT-LLM 可以生成更准确、更相关的标签分类法，并在大规模分类的准确性和效率之间实现良好的平衡。我们还分享了关于在实际应用中使用法学硕士进行大规模文本挖掘的挑战和机遇的实践经验和见解。]]></description>
      <guid>https://arxiv.org/abs/2403.12173</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>TMU 参加 TREC 临床试验轨道 2023</title>
      <link>https://arxiv.org/abs/2403.12088</link>
      <description><![CDATA[arXiv:2403.12088v1 公告类型：新
摘要：本文描述了多伦多城市大学参与 2023 年 TREC 临床试验轨道的情况。作为任务的一部分，我们在实验中利用先进的自然语言处理技术和神经语言模型来检索最相关的临床试验。我们阐述了作为 V-TorontoMU 团队一部分的运行提交的总体方法、实验设置和实施结果。]]></description>
      <guid>https://arxiv.org/abs/2403.12088</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>Syn-QA2：使用综合 QA 数据集评估长尾问题中的错误假设</title>
      <link>https://arxiv.org/abs/2403.12145</link>
      <description><![CDATA[arXiv:2403.12145v1 公告类型：新
摘要：对信息搜索问题中错误假设（或错误前提）的敏感性对于稳健的问答（QA）系统至关重要。最近的工作表明，自然发生的问题中的错误假设对当前模型提出了挑战，在生成 QA 和简单检测任务上的性能都很低（Kim 等人，2023）。然而，现有工作的重点是自然发生的问题，导致在可能问题分布的长尾上分析模型行为方面存在差距。为此，我们引入了 Syn-(QA)$^2$，这是一组两个综合生成的 QA 数据集：一个是使用来自 Wikidata 的扰动关系生成的，另一个是通过扰动 HotpotQA 生成的（Yang 等人，2018）。我们评估一系列大型语言模型的结果有三个方面：(1) QA 中的错误假设具有挑战性，这与之前工作的结果相呼应，(2) 即使与生成 QA 本身的难度相比，二进制检测任务也具有挑战性，可能由于问题的语言结构，（3）与自然发生的问题相比，长尾问题的检测任务更具挑战性，这凸显了我们的合成数据集和生成方法的实用性。]]></description>
      <guid>https://arxiv.org/abs/2403.12145</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>评估生成搜索引擎在对抗性事实问题上的鲁棒性</title>
      <link>https://arxiv.org/abs/2403.12077</link>
      <description><![CDATA[arXiv:2403.12077v1 公告类型：新
摘要：生成搜索引擎有潜力改变人们在线搜索信息的方式，但现有大语言模型（LLM）支持的生成搜索引擎生成的响应可能并不总是准确的。尽管如此，检索增强生成加剧了安全问题，因为对手可能通过巧妙地操纵索赔中最脆弱的部分来成功逃避整个系统。为此，我们建议评估生成搜索引擎在现实和高风险环境中的鲁棒性，其中对手只有黑盒系统访问权限并试图欺骗模型返回错误的响应。通过对各种生成搜索引擎（例如 Bing Chat、PerplexityAI 和 YouChat）跨不同查询的全面人工评估，我们证明了对抗性事实问题在诱导错误响应方面的有效性。此外，与没有检索的法学硕士相比，检索增强生成对事实错误的敏感性更高。这些发现凸显了这些系统的潜在安全风险，并强调在部署前进行严格评估的必要性。]]></description>
      <guid>https://arxiv.org/abs/2403.12077</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:13 GMT</pubDate>
    </item>
    <item>
      <title>幸存的男孩：将哈利·波特从法学硕士中除名比报道的更难</title>
      <link>https://arxiv.org/abs/2403.12082</link>
      <description><![CDATA[arXiv:2403.12082v1 公告类型：新
摘要：最近的工作 arXiv.2310.02238 声称“我们有效地消除了模型生成或回忆哈利波特相关内容的能力。”这种说法被证明过于宽泛。一个不到十次试验的小实验导致了重复和具体的结果提到哈利·波特，包括“啊，我明白了！ “麻瓜”是特里·普拉切特在《哈利·波特》系列丛书中使用的一个术语……”]]></description>
      <guid>https://arxiv.org/abs/2403.12082</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:13 GMT</pubDate>
    </item>
    </channel>
</rss>