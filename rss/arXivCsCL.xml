<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 12 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>InternLM-Math：开放数学大型语言模型以实现可验证的推理</title>
      <link>https://arxiv.org/abs/2402.06332</link>
      <description><![CDATA[大语言模型的数学能力可以代表其抽象推理能力。在本文中，我们介绍并开源了我们的数学推理法学硕士 InternLM-Math，它是从 InternLM2 继续进行预训练的。我们以统一的 seq2seq 格式统一思想链推理、奖励建模、形式推理、数据增强和代码解释器，并监督我们的模型成为多功能数学推理器、验证器、证明器和增强器。这些能力可用于开发下一个数学法学硕士或自我迭代。 InternLM-Math 在各种非正式和正式基准测试（包括 GSM8K、MATH、匈牙利数学考试、MathBench）中，在上下文学习、监督微调和代码辅助推理的设置下获得了开源的最先进性能-ZH 和 MiniF2F。我们的预训练模型在 MiniF2F 测试集上无需微调即可达到 30.3。我们进一步探讨了如何使用 LEAN 来解决数学问题，并研究其在多任务学习设置下的性能，这表明使用 LEAN 作为数学解决和证明的统一平台的可能性。我们的模型、代码和数据发布在 \url{https://github.com/InternLM/InternLM-Math}。]]></description>
      <guid>https://arxiv.org/abs/2402.06332</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>RareBench：法学硕士可以担任罕见病专家吗？</title>
      <link>https://arxiv.org/abs/2402.06341</link>
      <description><![CDATA[通用大型语言模型 (LLM)，例如 GPT-4，在包括医疗诊断在内的各个领域都显示出了巨大的前景。罕见病影响着全球约3亿人，其临床诊断率往往不理想，主要是由于缺乏经验丰富的医生以及区分许多罕见病的复杂性。在这种背景下，最近的新闻，如“在 17 名医生失败后，ChatGPT 正确诊断了一名 4 岁儿童的罕见病”，强调了法学硕士在临床诊断罕见病方面的潜力，但尚未得到充分探索。为了弥补这一研究差距，我们推出了 RareBench，这是一个开创性的基准，旨在系统地评估法学硕士在罕见疾病领域 4 个关键维度上的能力。同时，我们还编制了关于罕见病患者的最大的开源数据集，为该领域的未来研究建立了基准。为了促进罕见疾病的鉴别诊断，我们开发了一种动态的小样本提示方法，利用从多个知识库合成的全面的罕见疾病知识图谱，显着提高了法学硕士的诊断性能。此外，我们还对 GPT-4 的诊断能力与专科医生的诊断能力进行了详尽的比较研究。我们的实验结果强调了将法学硕士纳入罕见疾病临床诊断过程的巨大潜力。这为该领域未来的进步铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2402.06341</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>指令调优的统一因果观</title>
      <link>https://arxiv.org/abs/2402.06220</link>
      <description><![CDATA[对混合任务的指令调整提高了自然语言处理 (NLP) 中的零样本能力。然而，现有的方法通常学习表现出指令格式样本和目标标签之间相关性的特征，而不是因果关系。在统计学中被称为“虚假相关性”，这种相关性可能在新任务中发生巨大变化，从而使学习到的特征的效果产生误导。为此，我们开发了元结构因果模型（meta-SCM），将不同的 NLP 任务集成到数据的单一因果结构下。具体来说，元 SCM 引入了多个表示源上下文属性的潜在因素，其中只有一些因素会因果影响特定任务的目标标签。关键思想是学习任务所需的因果因素，并仅使用这些因素对给定任务进行预测。从理论上讲，我们证明可以在不混合其他信息的情况下识别因果因素。在可识别性的指导下，我们提出了一种结构指令调整（SIT）方法来学习任务所需的因果表示，该表示可以模仿每个任务的因果因素。我们的方法的实用性通过对一系列未见过的数据集和任务的零样本能力的改进得到了验证。]]></description>
      <guid>https://arxiv.org/abs/2402.06220</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>ResumeFlow：法学硕士推动的个性化简历生成和完善流程</title>
      <link>https://arxiv.org/abs/2402.06221</link>
      <description><![CDATA[对于许多求职者来说，特别是对于职业生涯早期的求职者来说，制作理想的、针对具体工作的简历是一项具有挑战性的任务。虽然强烈建议申请人根据其申请的特定职位定制简历，但根据职位描述和特定职位要求手动定制简历通常 (1) 极其耗时，(2) 容易出现人为错误。此外，在申请多个职位时大规模执行此类定制步骤可能会导致编辑后的简历质量下降。为了解决这个问题，在这篇演示论文中，我们提出了 ResumeFlow：一种大型语言模型 (LLM) 辅助工具，使最终用户能够简单地提供详细的简历和所需的职位发布，并获得专门针对该特定职位量身定制的个性化简历几秒钟内即可发布招聘信息。我们提出的管道利用了最先进的 LLM 的语言理解和信息提取功能，例如 OpenAI 的 GPT-4 和 Google 的 Gemini，以便 (1) 从职位描述中提取详细信息，(2) 提取特定于角色的信息从用户提供的简历中获取详细信息，然后 (3) 使用这些信息为用户完善并生成特定于角色的简历。我们易于使用的工具以完全现成的方式利用用户选择的 LLM，因此无需进行微调。我们通过视频演示展示了我们工具的有效性，并提出了新颖的特定于任务的评估指标来控制对齐和幻觉。我们的工具可在 https://job-aligned-resume.streamlit.app 上获取。]]></description>
      <guid>https://arxiv.org/abs/2402.06221</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>论驱逐策略对键值约束生成语言模型推理的有效性</title>
      <link>https://arxiv.org/abs/2402.06262</link>
      <description><![CDATA[尽管最近与大型语言模型（LLM）相关的成功，但由于其过多的内存和计算需求，在资源有限的环境中部署它们的成本非常高昂。除了模型参数之外，键值缓存也存储在 GPU 内存中，随着批量大小和序列长度线性增长。作为一种补救措施，最近的工作提出了各种驱逐策略，以在给定的预算下维持键值缓存的开销。本文从 \textit{重要性得分计算} 和 \textit{驱逐范围构建} 方面着手探讨现有驱逐政策的有效性。我们发现了先前策略在这两个方面的不足，并引入了 RoCo，一种基于时间注意力分数和鲁棒性度量的 \underline{r}\underline{o}bust \underline{c}ache \underline{o}mission 策略。涵盖预填充和自回归解码阶段的广泛实验验证了 RoCo 的优越性。最后，我们发布了 EasyKV，这是一个多功能软件包，专用于用户友好的键值约束生成推理。代码可在 \url{https://github.com/DRSY/EasyKV} 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.06262</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>使用规范示例进行模型编辑</title>
      <link>https://arxiv.org/abs/2402.06155</link>
      <description><![CDATA[我们引入了带有规范示例的模型编辑，在这种设置中（1）根据所需行为提供单个学习示例，（2）仅在分布外执行评估，以及（3）严格限制与初始模型的偏差。一个典型的例子是良好行为的简单实例，例如，毛里求斯的首都是路易港）或不良行为，例如，研究人员的一个方面是冷酷的）。评估集包含每种行为的更复杂的示例（例如要求毛里求斯首都的段落）。我们创建三个数据集并修改另外三个数据集，以使用规范示例进行模型编辑，涵盖知识密集型改进、社会偏见缓解、和句法边缘情况。在 Pythia 语言模型的实验中，我们发现 LoRA 的性能优于完全微调和 MEMIT。然后我们转向 Backpack 语言模型架构，因为它旨在实现有针对性的改进。 Backpack 定义了大量意义向量（每个单词不同用途的分解），对它们进行加权和求和以形成模型的输出逻辑。我们提出了意义微调，它为每个典型示例选择并微调一些（$\approx$10）意义向量，并发现它优于其他微调方法，例如，提高了 4.8% 而不是 0.3%。最后，我们通过推理时间集成改进了 GPT-J-6B，仅对小 35 倍的 Backpack 进行感知微调，在一种设置中优于编辑 GPT-J 本身（4.1% vs 1.0%）。]]></description>
      <guid>https://arxiv.org/abs/2402.06155</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型：调查</title>
      <link>https://arxiv.org/abs/2402.06196</link>
      <description><![CDATA[自2022年11月ChatGPT发布以来，大型语言模型（LLM）因其在广泛的自然语言任务上的强劲表现而受到广泛关注。LLM的通用语言理解和生成能力是通过训练获得的正如缩放定律所预测的那样，在大量文本数据上有数十亿个模型参数 \cite{kaplan2020scaling,hoffmann2022training}。法学硕士的研究领域虽然最近，但正在以许多不同的方式迅速发展。在本文中，我们回顾了一些最著名的法学硕士，包括三个流行的法学硕士系列（GPT、LLaMA、PaLM），并讨论了它们的特点、贡献和局限性。我们还概述了为构建和增强法学硕士而开发的技术。然后，我们调查为 LLM 培训、微调和评估准备的流行数据集，审查广泛使用的 LLM 评估指标，并比较几个流行的 LLM 在一组代表性基准上的表现。最后，我们通过讨论开放的挑战和未来的研究方向来总结本文。]]></description>
      <guid>https://arxiv.org/abs/2402.06196</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能评估悖论：它能解决什么，它可能无法评估什么</title>
      <link>https://arxiv.org/abs/2402.06204</link>
      <description><![CDATA[本文探讨了这样一个假设：擅长生成任务的大型语言模型（LLM）同样擅长评估器。我们使用 TriviaQA (Joshi et al., 2017) 数据集评估了三个法学硕士和一个开源语言模型在问答 (QA) 和评估任务中的表现。结果表明存在显着差异，与生成任务相比，法学硕士在评估任务中表现出较低的表现。有趣的是，我们发现了不忠实评估的例子，其中模型准确地评估了他们缺乏能力的领域的答案，这强调了有必要检查法学硕士作为评估者的忠诚度和可信度。这项研究有助于理解“生成人工智能悖论”（West et al., 2023），强调需要探索生成卓越性和评估熟练程度之间的相关性，以及审查模型评估中的忠实度方面的必要性。]]></description>
      <guid>https://arxiv.org/abs/2402.06204</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>用解析器驱动的修辞控制方法完成语言模型句子</title>
      <link>https://arxiv.org/abs/2402.06125</link>
      <description><![CDATA[受控文本生成 (CTG) 旨在指导大语言模型 (LLM) 输出以生成符合所需标准的文本。当前的研究提出了一种新颖的 CTG 算法，该算法通过解析器驱动的解码方案强制遵守 LLM 句子完成上下文中的特定修辞关系，无需模型微调。该方法通过自动评估和人工评估进行了验证。该代码可在 GitHub 上访问。]]></description>
      <guid>https://arxiv.org/abs/2402.06125</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>学会高效：在大型语言模型中构建结构化稀疏性</title>
      <link>https://arxiv.org/abs/2402.06126</link>
      <description><![CDATA[大型语言模型 (LLM) 凭借其十亿级参数取得了显着的成功，但它们会产生很高的推理开销。 LLM 中激活稀疏性的出现提供了一种自然的方法，通过仅涉及部分参数进行推理来降低这种成本。现有方法仅专注于利用这种自然形成的激活稀疏性，而忽视了进一步放大这种固有稀疏性的潜力。在本文中，我们假设 LLM 可以通过实现更结构化的激活稀疏性来学习高效。为了实现这一目标，我们引入了一种新颖的算法，Learn-To-be-Efficient (LTE)，旨在训练具有效率意识的 LLM 学习激活更少的神经元并在稀疏性和性能之间实现更好的权衡。此外，与主要关注基于ReLU的模型的SOTA MoEfication方法不同，LTE还可以应用于具有软激活函数的GPT和LLaMA等LLM。我们在四个模型和 11 个数据集上评估 LTE。实验表明，LTE 在稀疏性和任务性能之间实现了更好的权衡。例如，带有 LLaMA 的 LTE 将语言生成任务的 FLOP 速度提高了 1.83 倍至 2.59 倍，优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2402.06126</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>LightCAM：基于上下文感知屏蔽的 D-Tdnn 的快速、轻松实现，用于说话人验证</title>
      <link>https://arxiv.org/abs/2402.06073</link>
      <description><![CDATA[传统的时延神经网络（TDNN）以高计算复杂度和较慢的推理速度为代价实现了最先进的性能，这使得它们难以在工业环境中实现。具有上下文感知屏蔽 (CAM) 模块的密集连接时延神经网络 (D-TDNN) 已被证明是一种有效的结构，可以在保持系统性能的同时降低复杂性。在本文中，我们提出了一种快速且轻量级的模型LightCAM，该模型进一步采用深度可分离卷积模块（DSM）并使用多尺度特征聚合（MFA）进行不同级别的特征融合。在VoxCeleb数据集上进行了大量的实验，对比结果表明，VoxCeleb1-O的EER为0.83，MinDCF为0.0891，优于其他主流说话人验证方法。此外，复杂性分析进一步表明所提出的架构具有更低的计算成本和更快的推理速度。]]></description>
      <guid>https://arxiv.org/abs/2402.06073</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>重新思考监督微调的数据选择</title>
      <link>https://arxiv.org/abs/2402.06094</link>
      <description><![CDATA[尽管监督微调（SFT）已成为使大型语言模型与人类保持一致的基本技术，但它被认为是肤浅的，风格学习才是其本质。与此同时，最近的工作表明了 SFT 数据选择的重要性，表明对原始数据集的高质量和多样化子集进行微调可以带来卓越的下游性能。在这项工作中，我们重新思考 SFT 数据选择背后的直觉。考虑到 SFT 很肤浅，我们建议 SFT 的基本演示应侧重于反映类人交互，而不是数据质量或多样性。然而，直接评估示威在多大程度上反映了人类风格并不容易。在这个方向上的初步尝试中，我们发现选择具有长响应的实例对于 SFT 来说比利用完整数据集或基于质量和多样性选择的实例更加有效。我们假设这种简单的启发式方法隐含地模仿了人类对话的一个关键方面：详细的回答通常更有帮助。]]></description>
      <guid>https://arxiv.org/abs/2402.06094</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>探索大型语言模型中的群和对称原理</title>
      <link>https://arxiv.org/abs/2402.06120</link>
      <description><![CDATA[大型语言模型 (LLM) 在广泛的应用程序中展示了令人印象深刻的性能；然而，评估他们的推理能力仍然是一个重大挑战。在本文中，我们介绍了一个基于群原理和对称原理的框架，这些原理在物理和数学等领域发挥了至关重要的作用，并提供了另一种评估其能力的方法。虽然提出的框架是通用的，但为了展示使用这些属性的好处，我们专注于算术推理并研究这些模型在四个组属性上的性能：闭包、恒等、逆和关联性。我们的研究结果表明，在这项工作中研究的法学硕士很难在不同的测试制度中保留群体属性。在封闭测试中，我们观察到特定输出的偏差以及在特定序列长度后其性能从 100% 突然下降到 0%。它们在身份测试中也表现不佳，身份测试代表在上下文中添加不相关的信息，并且在进行逆向测试时表现出敏感性，逆向测试检查模型相对于否定的稳健性。此外，我们还证明，将问题分解为更小的步骤有助于法学硕士进行我们进行的关联性测试。为了支持这些测试，我们开发了一个即将发布的综合数据集。]]></description>
      <guid>https://arxiv.org/abs/2402.06120</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>探索 GPT-4V 中的视觉文化意识：全面的探索</title>
      <link>https://arxiv.org/abs/2402.06015</link>
      <description><![CDATA[近年来，预训练的大型视觉语言模型因其卓越的性能而引起了人们的极大兴趣。尽管从不同角度评估这些模型付出了相当大的努力，但最先进的 GPT-4V 模型中视觉文化意识的程度仍未得到探索。为了解决这一差距，我们使用 MaRVL 基准数据集广泛探讨了 GPT-4V，旨在研究其在视觉理解方面的能力和局限性，重点关注文化方面。具体来说，我们引入了三个视觉相关任务，即字幕分类、成对字幕和文化标签选择，以系统地深入研究细粒度的视觉文化评估。实验结果表明，GPT-4V 在识别文化概念方面表现出色，但在泰米尔语和斯瓦希里语等低资源语言中表现仍然较弱。值得注意的是，通过人类评估，GPT-4V 被证明在图像字幕任务中比原始 MaRVL 人类注释更具文化相关性，这为未来视觉文化基准构建提供了一个有前景的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2402.06015</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:13 GMT</pubDate>
    </item>
    <item>
      <title>及时响应自动中性翻译的需求</title>
      <link>https://arxiv.org/abs/2402.06041</link>
      <description><![CDATA[避免偏见和不适当的二元假设的性别中立翻译（GNT）是创建更具包容性的翻译技术的关键挑战。然而，机器翻译 (MT) 中这项任务的进展因缺乏专用并行数据而受到阻碍，而专用并行数据是调整 MT 系统以满足中性约束所必需的。对于这种情况，大型语言模型提供了迄今为止不可预见的可能性，因为它们具有在提供显式指令时在各种（子）任务中具有通用性的独特优势。在本文中，我们通过将 MT 与流行的 GPT-4 模型进行比较，探索自动化 GNT 的潜力。通过广泛的手动分析，我们的研究凭经验揭示了当前 MT 系统在生成 GNT 方面的固有局限性，并为促进中立性相关的潜力和挑战提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2402.06041</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:13 GMT</pubDate>
    </item>
    </channel>
</rss>