<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Fri, 29 Dec 2023 06:18:33 GMT</lastBuildDate>
    <item>
      <title>提出的文本概念多样性的新度量。 （arXiv：2312.16548v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16548</link>
      <description><![CDATA[一个单词可能包含一个或多个隐藏的概念。而“兽”字
在我们的脑海中唤起许多形象并概括了许多概念（鸟、狗、
猫、鳄鱼等），“鹦鹉”这个词会唤起一个单一的图像（一个彩色的
具有短而钩状喙并具有模仿声音能力的鸟）。在口语或
在书面文本中，我们使用一些一般意义上的单词和一些详细的单词
指向特定对象。到目前为止，文本的概念多样性价值
无法使用标准且精确的技术来确定。这项研究
通过提供
用于评估和比较概念的标准化方法和通用指标
不同文本和领域的多样性。它还为该领域做出了贡献
语言的语义研究。如果我们给出多样性得分的例子
两句话，“他发现了一个未知的实体。”具有较高的概念性
多样性得分（16.6801），以及“内质网形成一系列
真核细胞细胞质内的扁平囊。”这句话的语气很低。
概念多样性得分为 3.9068。
]]></description>
      <guid>http://arxiv.org/abs/2312.16548</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士对上下文中的多数标签偏见的鲁棒性如何？ （arXiv：2312.16549v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.16549</link>
      <description><![CDATA[在情境学习 (ICL) 设置中，各种形式的标签偏差可以
显现。其中一种表现是多数标签偏差，当
上下文样本中标记示例的分布偏向
一个或多个特定的类使得大型语言模型（LLM）更容易
预测这些标签。这种差异可能由多种因素引起，
包括后勤限制、数据收集方法的固有偏差，
对不同数据源等的访问受到限制，这在
现实世界的行业设置。在这项工作中，我们研究了上下文中的稳健性
法学硕士学习到由于多数标签偏差而发生的转变
文本分类任务的范围。先前的工作表明，在上下文中
与法学硕士一起学习很容易受到这种偏见的影响。在我们的研究中，我们进入一个层次
更深入地表明不同模型的鲁棒性边界差异很大
和任务，某些法学硕士对于多数标签偏差具有高度鲁棒性（~90%）。
此外，我们的研究结果还强调了模型大小和
丰富的教学提示有助于模型的稳健性。我们
将我们的研究限制为仅公开可用的开源模型，以确保
透明度和可重复性。
]]></description>
      <guid>http://arxiv.org/abs/2312.16549</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>了解新闻创作意图：框架、数据集和方法。 （arXiv：2312.16490v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16490</link>
      <description><![CDATA[随着媒体经济的颠覆性变化和传播
另类新闻媒体的新闻意图已逐渐偏离
服务于公共利益的道德标准。新闻意图是指
创作新闻文章背后的目的或意图。虽然
新闻意图研究的重要性已得到广泛认可，
缺乏系统的新闻意图理解框架阻碍了进一步
新闻意图及其下游应用的探索。为了弥补这一差距，
我们提出 News INTent (NINT) 框架，这是第一个组件感知的形式主义
基于哲学研究理解新闻创作意图，
心理学和认知科学。在这个框架内，我们定义新闻意图
识别任务并提供带有细粒度标签的基准数据集
以及有效的基准方法。实验证明 NINT 是
对意图识别任务和下游任务都有好处
要求对新闻有深刻的理解。这项工作标志着一个基础性的一步
更系统地探索新闻创作意图。
]]></description>
      <guid>http://arxiv.org/abs/2312.16490</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>S2M：将单轮数据集转换为多轮数据集以进行对话式问答。 （arXiv：2312.16511v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16511</link>
      <description><![CDATA[为对话式问答 (CQA) 提供数据增强可以
有效提升模型性能。然而，改善幅度较小
由于单轮和单轮之间的分布差距，CQA 中的单轮数据集
多轮数据集。另一方面，虽然大量的单轮数据集
可用，但我们尚未有效利用它们。为了解决这个问题，我们
提出一种将单轮数据集转换为多轮数据集的新方法。
所提出的方法由三部分组成，即QA对生成器、QA
一对重组器和一个问题重写器。给定一个由上下文组成的样本
和单轮 QA 对，生成器获得候选 QA 对和
基于上下文的知识图谱。重组器利用知识
图表以获得连续的 QA 对，重写器重写来自
会话视角获得多轮数据集S2M。我们的实验
表明我们的方法可以为 CQA 合成有效的培训资源。
值得注意的是，S2M 在提交时在 QuAC 排行榜上排名第一
（2022 年 8 月 24 日）。
]]></description>
      <guid>http://arxiv.org/abs/2312.16511</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>用于广义类别发现的转移和对齐网络。 （arXiv：2312.16467v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16467</link>
      <description><![CDATA[广义类别发现是一项至关重要的现实任务。尽管
改进了已知类别的性能，当前方法在以下方面表现不佳
小说类别。我们将表现不佳归因于两个原因：
标记和未标记数据之间的知识转移以及噪声表示
学习未标记的数据。为了缓解这两个问题，我们提出了一个
迁移和对齐网络（TAN），包含两种知识迁移
校准有偏见的知识和两个特征对齐的机制
学习判别特征的机制。具体来说，我们建模不同的
具有原型的类别，并将标记数据中的原型传输到
纠正模型对已知类别的偏差。一方面，我们拉取实例
未标记数据中的已知类别更接近这些原型，以形成更多
紧凑的聚类并避免已知类别和新类别之间的边界重叠。
另一方面，我们使用这些原型来校准噪声原型
根据类别相似性从未标记的数据中估计，这允许
更准确地估计新类别的原型，可用作
以后有可靠的学习目标。知识转移后，我们进一步提出
两种特征对齐机制来获取实例级别和类别级别
通过将实例特征与增强的数据对齐来从未标记的数据中获得知识
功能和校准原型，可以提高模型性能
已知的和新颖的类别都具有较少的噪音。三个基准的实验
数据集显示我们的模型优于 SOTA 方法，尤其是在新颖的方面
类别。提供理论分析以深入了解
我们的一般模型。我们的代码和数据可在
https://github.com/Lackel/TAN。
]]></description>
      <guid>http://arxiv.org/abs/2312.16467</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>源代码是一个图，而不是一个序列：代码克隆检测的跨语言视角。 （arXiv：2312.16488v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16488</link>
      <description><![CDATA[源代码克隆检测的任务是查找具有以下特征的代码片段：
相同或相似的功能，但语法或结构可能不同。这
任务对于软件维护、重用和质量保证很重要（Roy
等人。 2009）。然而，代码克隆检测具有挑战性，因为源代码可以
以不同的语言、领域和风格编写。在本文中，我们认为
源代码本质上是一个图，而不是一个序列，并且基于图
方法比基于序列的方法更适合代码克隆检测。
我们比较了两种最先进模型的性能：CodeBERT（Feng 等人）
等人。 2020），一个基于序列的模型，以及 CodeGraph（Yu et al. 2023），一个
基于图的模型，基于两个基准数据集：BCB (Svajlenko et al. 2014) 和
PoolC（PoolC 无日期）。我们证明 CodeGraph 在这两个方面都优于 CodeBERT
数据集，尤其是跨语言代码克隆。尽我们最大的努力
知识，这是第一个展示基于图的优越性的工作
跨语言代码克隆检测的方法优于基于序列的方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.16488</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士测谎仪：通过中间数据分析揭示法学硕士的事实辨别力。 （arXiv：2312.16374v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16374</link>
      <description><![CDATA[大型语言模型（LLM）已经彻底改变了各个领域
丰富的知识和创造能力。然而，一个关键问题是
法学硕士倾向于产生与实际情况不同的成果。
这种现象在敏感应用中尤其令人担忧，例如
医疗咨询和法律建议，其中准确性至关重要。在这个
论文中，我们介绍了 LLM Factorscope，一种新颖的基于 Siamese 网络的模型
利用法学硕士的内部状态进行事实检测。我们的
调查揭示了法学硕士的内部状态的明显模式
生成事实内容与非事实内容。我们展示了LLM
factscope 在各种架构中的有效性，达到 96% 以上
事实检测的准确性。我们的工作为利用法学硕士的知识开辟了新途径
用于事实检测的内部状态并鼓励进一步探索
法学硕士的内部运作提高了可靠性和透明度。
]]></description>
      <guid>http://arxiv.org/abs/2312.16374</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>使用法学硕士自动获取以内容为中心的认知代理的知识。 （arXiv：2312.16378v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16378</link>
      <description><![CDATA[论文描述了一个使用大语言模型（LLM）技术的系统
支持智能代理自动学习新条目
语义词典。该过程由现有的非玩具词典引导
以及一个自然语言生成器，可以将形式化的、基于本体论的
将意义表示为自然语言句子。学习方法
涉及一系列法学硕士请求并包括自动质量控制
步。迄今为止，这种学习方法已被应用于学习多词
其含义与及物动词相同的表达方式
特工的词典。该实验展示了混合学习的好处
将基于知识的方法和资源与两者相结合的架构
传统数据分析和法学硕士。
]]></description>
      <guid>http://arxiv.org/abs/2312.16378</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>表示多语言自动语言生成中的多阶段原型概念：从语料库到词嵌入到自动词典。 （arXiv：2312.16311v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16311</link>
      <description><![CDATA[名词价多语言词典 Portlex 被认为是
用于创建自动语言生成器 Xera 和
本文介绍了 Combinatoria 的开发和使用。两个都
原型用于自动生成名义短语及其
单参数和双参数价槽，除其他外，可用作
字典示例或作为未来自主的集成组件
电子学习工具。作为新型自动配价词典的样本
包括用户交互，我们考虑我们所知道的语言生成器
今天。在开发的具体方法过程中
语言生成器，名词槽的句法语义描述
从组合和范式的角度来看，它是主要焦点。
除了代表性、语法正确性等因素之外，
语义连贯性、频率和候选词汇的多样性，以及
语义类和参数结构，它们是两者的固定组成部分
资源，多边原型的概念脱颖而出。合并后的
该原型概念以及词嵌入的应用
具有自动自然语言处理领域的技术和
一代（NLP和NLG）为未来发展开辟了新途径
自动生成多语言配价词典。万物
考虑到，本文从以下角度描述了语言生成器：
从他们的发展以及用户的角度来看。重点在于
原型概念在资源开发中的作用。
]]></description>
      <guid>http://arxiv.org/abs/2312.16311</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>任务污染：语言模型可能不再是少样本。 （arXiv：2312.16337v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16337</link>
      <description><![CDATA[大型语言模型 (LLM) 在各种领域提供令人印象深刻的性能
零样本和少样本任务。然而，他们在零镜头和少镜头方面的成功
设置可能会受到任务污染的影响，这是一个潜在的限制
没有经过彻底检查。本文研究了零样本和
法学硕士的小样本表现随着时间的推移而发生了变化。利用
GPT-3系列模型和其他几个最近开源的LLM，以及控制
对于数据集难度，我们发现在 LLM 之前发布的数据集上
训练数据创建日期，法学硕士的表现出奇地好于数据集
后释放。这强烈表明，对于许多法学硕士来说，存在任务
对之前发布的数据集的零样本和少样本评估的污染
到法学硕士的培训数据创建日期。此外，我们还利用培训
数据检查、任务示例提取和成员推理攻击，
这揭示了任务污染的进一步证据。重要的是，我们发现
对于不存在任务污染可能性的分类任务，法学硕士很少
与简单多数相比，在统计上显示出显着的改进
零次和几次射击设置中的基线。
]]></description>
      <guid>http://arxiv.org/abs/2312.16337</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>可观察的传播：一种发现 Transformer 中特征向量的数据高效方法。 （arXiv：2312.16291v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.16291</link>
      <description><![CDATA[当前 NLP 机械可解释性研究的一个关键目标是找到
变压器的线性特征（也称为“特征向量”）：方向
对应于给定模型使用的概念的激活空间
它的计算。目前寻找线性特征的最先进方法
需要大量标记数据——获取起来很费力，而且
使用起来计算成本昂贵。在这部作品中，我们介绍了一部小说
方法，称为“可观察传播”（简称：ObsProp），用于寻找线性
Transformer 语言模型在计算给定任务时使用的功能——使用
几乎没有数据。我们的范式以可观察量、线性的概念为中心
与给定任务相对应的功能。然后我们引入一个数学
特征向量分析的理论：我们提供理论动机
为什么 LayerNorm 非线性不影响特征的方向
载体；我们还引入了特征向量之间的相似性度量，称为
耦合系数，估计一个特征的程度
输出与另一个输出相关。我们使用 ObsProp 来执行广泛的
对多项任务进行定性调查，包括性别职业
偏见、政党预测和编程语言检测。我们的
结果表明 ObsProp 超越了传统的寻找方法
低数据状态下的特征向量，并且 ObsProp 可以用来更好地
了解大型语言模型中造成偏差的机制。代码
实验可以在 github.com/jacobdunefsky/ObservablePropagation 找到。
]]></description>
      <guid>http://arxiv.org/abs/2312.16291</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>组合语义对多语言数字工具开发的贡献。（arXiv:2312.16309v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16309</link>
      <description><![CDATA[本文描述了组合语义学领域如何做出贡献
设计三个用于自动生成参数的原型
西班牙语、法语和德语中名词性短语的模式（Xera、Combinatoria
和 CombiContext）。这也表明了了解论点的重要性
生产情境中的句法语义界面
外语。在对设计、类型学和设计进行了描述性部分之后
资源的信息级别，下面有解释
组合意义的中心角色（角色和本体特征）。这
研究涉及选择中应用的不同语义过滤器，
词汇的组织和扩展，是这些的关键部分
生成语法正确且语义可接受的单一和
双参数名词性短语。
]]></description>
      <guid>http://arxiv.org/abs/2312.16309</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>研究维度语音情感分析中的显着表示和标签方差。 （arXiv：2312.16180v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2312.16180</link>
      <description><![CDATA[源自 BERT（双向编码器）等模型的表示
来自 Transformers）和 HuBERT（隐藏单元 BERT）的代表提供了帮助
在维度语音情感方面实现最先进的性能
认出。尽管它们的维度很大，尽管这些
表征不是为情感识别任务量身定制的，它们是
经常用于训练具有高记忆力和高记忆力的大型语音情感模型
计算成本。在这项工作中，我们证明存在低维
这些预先训练的表示空间中的子空间提供了
降低下游模型复杂性而不牺牲性能
情绪估计。此外，我们以以下形式对标签不确定性进行建模
评分者意见差异，并证明此类信息可以改善
模型的泛化能力和鲁棒性。最后，我们比较一下
情绪模型对声学退化的鲁棒性和观察到的
降维表示能够保留
性能类似于全维表示，没有显着的
维度情感表现的回归。
]]></description>
      <guid>http://arxiv.org/abs/2312.16180</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>聊天机器人并不是您所需要的一切：信息丰富，提示更现实的响应。 （arXiv：2312.16233v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16233</link>
      <description><![CDATA[最近的大型语言模型（LLM）在以下方面表现出了非凡的能力：
在对话环境中模仿虚构人物或真实的人类。
然而，这些反应的真实性和一致性还可以进一步增强
通过提供被模仿的代理的更丰富的信息。在本文中，我们
提出一种新颖的方法来产生更现实和一致的反应
来自法学硕士，利用五种感官、属性、情绪状态、关系
与对话者和回忆。通过综合这些因素，我们的目标是
提高法学硕士在以下方面产生自然和现实反应的能力
对话式交流。通过我们的研究，我们希望为
发展法学硕士，展示模仿能力的提高
虚构人物。我们发布了一个新的基准数据集和我们所有的代码，
提示以及我们的 Github 上的示例结果：
https://github.com/srafsasm/InfoRichBot
]]></description>
      <guid>http://arxiv.org/abs/2312.16233</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>不仅仅是相关性：大型语言模型是否能够学习空间的因果表示？。 （arXiv：2312.16257v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.16257</link>
      <description><![CDATA[最近的工作发现学习的表示之间有很高的互信息
大语言模型（LLM）及其输入的地理空间属性，
暗示着一种新兴的空间内部模型。然而，无论这种内部
空间模型对法学硕士的行为有任何因果影响没有得到回答
这项工作导致了对这些发现的批评，认为这些发现仅仅是统计相关性。
我们的研究重点是揭示空间表征的因果关系
法学硕士。特别是，我们发现了潜在的空间表征
DeBERTa，GPT-Neo 使用代表性相似性分析和线性和
非线性探测。我们的随意干预实验表明，空间
表示影响模型在下一个单词预测方面的性能
依赖地理空间信息的下游任务。我们的实验
建议法学硕士学习并使用空间内部模型来解决
地理空间相关任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.16257</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:27 GMT</pubDate>
    </item>
    </channel>
</rss>