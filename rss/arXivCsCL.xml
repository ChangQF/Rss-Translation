<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Tue, 12 Dec 2023 06:18:19 GMT</lastBuildDate>
    <item>
      <title>Aligner：在对齐大型语言模型时，一个全局代币相当于数百万个参数。 （arXiv：2312.05503v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05503</link>
      <description><![CDATA[我们介绍 Aligner，一种新颖的参数高效微调 (PEFT) 方法
用于对齐数十亿参数大小的大型语言模型（LLM）。
Aligner 采用独特的设计，构建了一套全球共享的
修改每一层注意力的可调令牌。值得注意的是，与此
方法，即使使用一个令牌仅占 5,000 个参数，
Aligner 的性能仍可与最先进的 LLM 适配相媲美
像 LoRA 这样的方法需要数百万个参数。这个容量是
在指令遵循和价值调整任务中得到证实。除了
参数效率多个数量级的提高，
Aligner 提供的关于法学硕士内部机制的见解也很有价值。
我们的方法的架构特征和功效，以及我们的
实验表明法学硕士将其内部对“形式”的处理分开
和“知识”以某种正交的方式。这一发现有望
激发对法学硕士机制理解和价值调整的新研究。
]]></description>
      <guid>http://arxiv.org/abs/2312.05503</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以充当博弈论中的理性参与者吗？系统分析。 （arXiv：2312.05488v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.05488</link>
      <description><![CDATA[博弈论作为一种分析工具，经常被用来分析人类
社会科学研究中的行为。随着之间的高度对齐
大型语言模型 (LLM) 和人类的行为，一项有前景的研究
方向是利用法学硕士来代替人类进行游戏实验，
促进社会科学研究。然而，尽管有大量的经验
法学硕士与博弈论相结合的研究，能力
博弈论法学硕士的界限仍不清楚。在这项研究中，我们努力
在博弈论的背景下系统地分析法学硕士。具体来说，
理性作为博弈论的基本原理，是衡量博弈论的标准
用于评估玩家的行为——建立明确的愿望，完善信念
关于不确定性，并采取最佳行动。据此，我们选择三
经典游戏（独裁者游戏、剪刀石头布、环网游戏）
分析一下LLM在这三个方面能做到什么程度的合理性。这
实验结果表明，即使是目前最先进的法学硕士
（GPT-4）在博弈论中与人类相比表现出巨大的差异。为了
例如，法学硕士很难根据不常见的偏好来建立愿望，无法
从许多简单的模式中提炼信念，并且可能会忽略或修改精炼的信念
采取行动时的信念。因此，我们认为将LLM引入
社会科学领域的游戏实验应以
更加谨慎。
]]></description>
      <guid>http://arxiv.org/abs/2312.05488</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 Captum 解释生成语言模型。 （arXiv：2312.05491v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05491</link>
      <description><![CDATA[Captum 是 PyTorch 中用于模型可解释性的综合库，
提供可解释性文献中的一系列方法来增强
用户对 PyTorch 模型的理解。在本文中，我们介绍了新的
Captum 中专门用于分析行为的功能
生成语言模型。我们提供了可用的概述
其理解潜力的功能和示例应用
生成语言模型中学习到的关联。
]]></description>
      <guid>http://arxiv.org/abs/2312.05491</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>历史很重要：大型语言模型中的时态知识编辑。 （arXiv：2312.05497v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05497</link>
      <description><![CDATA[修改或更新大数据中存储的知识是当务之急。
语言模型有两个不同的来源：
需要修正的模型和由于外部原因而过时的知识
现实世界中的变化应该更新。模型中的普遍努力
编辑将这两种不同类别的编辑混为一谈，这些编辑源于不同的
原因并直接将模型中的原始知识修改为新的知识
知识。然而，我们认为保留模型的原始知识
仍然具有相关性。具体来说，如果模型的知识由于以下原因而变得过时：
不断发展的世俗动态，它应该保留对历史的记忆
知识，同时整合新发现的知识。在这项工作中，我们介绍
时间知识编辑（TKE）任务并建立基准AToKe
（TempOral Knowledge Editing评估）评估当前模型编辑
方法。我们发现，虽然现有的模型编辑方法在以下方面很有效
让模型记住新知识，编辑后的模型会灾难性地忘记
历史知识。为了解决这个差距，我们提出了一个简单而通用的方法
称为具有时间目标的多重编辑（METO）的框架，用于增强
现有的编辑模型，既编辑历史知识又编辑新知识
同时优化模型对每个事实发生时间的预测。
我们的评估表明，虽然 AToKe 仍然很困难，但 METO 坚持认为
学习新知识的有效性，同时大幅提高
提高编辑模型在利用历史知识方面的性能。
]]></description>
      <guid>http://arxiv.org/abs/2312.05497</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>团队协作对话的细粒度分析。 （arXiv：2312.05471v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05471</link>
      <description><![CDATA[人类协作聊天对话的自然语言分析是一种
具有许多独特挑战的未充分研究领域：大量对话行为
标签、未指定的和动态的任务、交错的主题和远程
上下文依赖。虽然之前的工作研究了团队的广泛指标
使用LSA等方法进行对话和相关表演，已经有
很少花精力生成团队动态的细粒度描述，并且
对话中的个人表现。我们描述了初步工作
在软件开发领域开发可解释的分析工具
使用从我们组织中挖掘的 Slack 聊天记录，包括小说的生成，
分层标签方案；描述性指标的设计基于
对话行为发生的频率；和使用的初步结果
Transformer + CRF 架构融入远程上下文。
]]></description>
      <guid>http://arxiv.org/abs/2312.05471</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 BERT 进行团队合作维度分类。 （arXiv：2312.05483v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05483</link>
      <description><![CDATA[团队合作是学生的一项必要能力，但往往没有得到充分利用
评估。为了对学生团队合作提供形成性评估，
开发了自动化自然语言处理方法来识别
学生在线团队聊天的团队合作维度。该领域的发展
自然语言处理和人工智能带来了
先进的深度迁移学习方法，即双向编码器
Transformers (BERT) 模型的表示可以更深入
对文本上下文的理解。虽然传统机器学习
之前的工作中使用了算法来自动分类
我们的研究结果表明，聊天消息可以分为不同的团队合作维度
基于预训练语言模型 BERT 的分类器提供了改进的
分类性能以及通用性的巨大潜力
不同团队聊天环境和团队成员人口统计的语言使用。
该模型将有助于增强学习分析工具
团队合作评估和反馈。
]]></description>
      <guid>http://arxiv.org/abs/2312.05483</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>增强与来源相关的分布变化下基础模型表示的鲁棒性。 （arXiv：2312.05435v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05435</link>
      <description><![CDATA[基础模型是当前业界和业界关注的焦点
学术界。虽然他们在各种任务中展示了自己的能力，
需要进行深入研究以确定其对分布的稳健性
当用作监督机器学习的基础时发生转变。这尤其是
在临床数据背景下很重要，但有相关的特殊限制
数据可访问性、缺乏预培训材料以及可用性有限
高质量的注释。在这项工作中，我们检查模型的稳定性
基于分布转移下基础模型的表示。我们
重点关注来源混淆，这是一种出现的分布转移形式
在多机构数据集的背景下，当存在差异时
特定于源的语言使用和类分布。使用抽样策略
综合地引起不同程度的分布变化，我们评估
基础模型的表示在多大程度上导致
预测本质上对出处的混淆具有鲁棒性。
此外，我们还检查了简单混杂的有效性
调整方法的灵感来自于Pearl的后门调整概念。
结果表明，虽然基础模型确实显示出一些开箱即用的功能，
对来源混杂相关的分布变化的鲁棒性，这可以
通过调整，得到明显改善。这些发现表明需要
使用以下表示有意调整预测模型
特定源分布差异背景下的基础模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.05435</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>最先进的文本到 SQL 模型的领域适应：经验教训和发现的挑战。 （arXiv：2312.05448v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05448</link>
      <description><![CDATA[文本到 SQL 任务最近有许多高级开发，其中
根据以下指标衡量，Picard 模型是性能最好的模型之一
Spider 数据集竞赛。然而，将文本到 SQL 系统带入现实
通过领域适应来实现用例仍然是一个艰巨的挑战。我们分析如何
基础 T5 语言模型和 Picard 在查询结构上表现良好
与Spider数据集不同，我们对Spider上的基础模型进行了微调
数据和独立数据库（DB）。避免访问数据库内容
在推理过程中，我们还提出了一种替代方法来消除歧义
使用基于规则的方法输入问题中的值，该方法依赖于
输入问题的语义概念的中间表示。在
我们的结果展示了 T5 和 Picard 在什么情况下可以提供良好的性能，
我们分享经验教训，并讨论当前的领域适应挑战。
]]></description>
      <guid>http://arxiv.org/abs/2312.05448</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>社交媒体中的文本毒性：理解 Facebook 评论中表达的孟加拉有毒语言。 （arXiv：2312.05467v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05467</link>
      <description><![CDATA[社交媒体是数字文献的存储库，包括用户生成的
内容。社交媒体的用户通过不同的方式表达自己的观点
文本、表情符号、模因等媒介，以及其他视觉和文本媒介
媒介。这些媒体元素的大部分可能被视为有害
其他人有很多词，包括网络欺凌和有毒
语言 。本研究论文的目的是分析一个精心策划和
名为 ToxLex_bn 的有毒语言增值数据集。这是一个详尽的
可以用作分类材料来检测社交毒性的词汇表
媒体。孟加拉社区使用的有毒语言/文字
网络欺凌、仇恨言论和道德警务成为社会的主要趋势
孟加拉国和西孟加拉邦的媒体文化。毒性变得如此之大
受害者必须发帖反击或发布解释视频
仇恨者。大多数案件都针对女性名人及其关系、着装、
生活方式受到控制，评论框中充斥着有毒的言论。不仅
名人攻击，但印度教穆斯林之间也存在仇恨，
印度-孟加拉国，1971年的两个对手，这些对于虚拟比赛来说很常见
评论区有冲突。甚至很多时候脸书评论都会引起起诉和
孟加拉国的法律问题，因此需要更多研究。在这项研究中，一个
用户输入的孟加拉有毒语言数据集已被分析
孟加拉语文字和语言。为此，大约有 1968 个独特的二元词或短语：
对来自 2207590 条评论的词汇表进行了分析。这是
假设该分析将加强对孟加拉有毒物质的检测
社交媒体中使用的语言，从而治愈这种虚拟疾病。
]]></description>
      <guid>http://arxiv.org/abs/2312.05467</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>通过科学推理实现受控的表到文本生成。 （arXiv：2312.05402v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05402</link>
      <description><![CDATA[大量的科学实验结果和复杂的技术
报表通常以表格形式呈现，构成了巨大的障碍
个人获取首选信息。科学领域
遵循用户偏好的推理和内容生成
独特的挑战。在这项工作中，我们提出了一个生成流利的新任务
与用户对科学表格的偏好相匹配的逻辑描述
数据，旨在自动化科学文档分析。为了促进研究
在这个方向上，我们构建了一个新的具有挑战性的数据集 CTRLSciTab，其中包括
从科学文献中提取的表格描述对，其中
突出显示的单元格和相应的特定领域知识库。我们
评估流行的预训练语言模型以建立基线和
提出了一种优于竞争方法的新颖架构。结果
表明大型模型很难生成与以下内容相符的准确内容
用户偏好。作为此类工作中的第一个，我们的工作应该进一步激励
科学领域的研究。
]]></description>
      <guid>http://arxiv.org/abs/2312.05402</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>实验研究：评估用于文本转语音合成的 WavLM 和 BEST-RQ 组合框架。 （arXiv：2312.05415v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2312.05415</link>
      <description><![CDATA[我们提出了一种特别适合文本转语音的新模型架构
（TTS）模型。我们结合了 WavLM，一种预训练的自我监督学习（SSL）
语音模型和 BEST-RQ 矢量量化框架。我们评估
与任务无关的 WavLM 与优越的性能相结合的程度
简单化的 BEST-RQ 框架适用于更广泛的下游
任务，产生良好的结果。在 LibriSpeech 数据集上进行的实验
SUPERB 基准测试断言所提出的模型表现明显不佳。
我们推测这种表现的根本原因与
特征化原始音频波形和频谱图之间的区别
量化器。我们讨论这种方法的局限性，以更好地指导未来
TTS 的进步。
]]></description>
      <guid>http://arxiv.org/abs/2312.05415</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>表面之下：通过从大型语言模型中提取的多模态推理揭示有害模因。 （arXiv：2312.05434v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05434</link>
      <description><![CDATA[社交媒体时代充斥着迷因。理解和检测
有害模因构成了重大挑战，因为它们的隐含含义是
没有通过表面文字和图像明确传达。然而，
现有的有害模因检测方法只能识别表面现象
以端到端分类方式显示危害指示信号，但忽略
对模因文本和图像的深入认知。在本文中，我们尝试
基于对相互作用的高级推理来检测有害模因
模因中的多模态信息。受到大语言成功的启发
关于复杂推理的模型（法学硕士），我们首先进行溯因推理
法学硕士。然后我们提出了一个新颖的生成框架来学习合理的想法
来自法学硕士的更好的多模态融合和轻量级微调，
包括两个训练阶段：1）从
法学硕士； 2）微调生成框架以推断危害性。广泛的
在三个模因数据集上进行的实验表明，我们提出的
该方法比最先进的方法实现了卓越的性能
有害模因检测任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.05434</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>歌词：通过语义感知的视觉对象促进细粒度的语言视觉对齐和理解。 （arXiv：2312.05278v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.05278</link>
      <description><![CDATA[大视觉语言模型 (LVLM) 展示了令人印象深刻的零样本
各种视觉语言对话场景的能力。但是，那
缺乏细粒度的视觉对象检测会阻碍模型
理解图像的细节，导致不可挽回的视觉
幻觉和事实错误。在本文中，我们提出了小说《Lyrics》
引导的多模式预训练和指令微调范例
细粒度跨模式协作的视觉语言对齐。建筑
Lyrics在BLIP-2的基础上注入了提取的局部视觉特征
来自视觉细化器，包括图像标记、对象检测和
将语义分割模块放入查询转换器中，同时在文本上
侧面，语言输入配备了从
视觉细化器。我们进一步引入了一个两阶段的培训计划，其中
预训练阶段通过明确和全面的方式弥合模式差距
视觉语言对齐目标。在指令微调阶段，我们
引入语义感知的视觉特征提取，这是一种重要的方法
使模型能够从具体的视觉对象中提取信息特征。
我们的方法在 13 个跨不同领域的保留数据集上取得了出色的性能
视觉语言任务，并展示了有前途的多模式理解和
真实对话场景的细致描绘能力。
]]></description>
      <guid>http://arxiv.org/abs/2312.05278</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:14 GMT</pubDate>
    </item>
    <item>
      <title>GlitchBench：大型多模态模型可以检测视频游戏故障吗？ （arXiv：2312.05291v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.05291</link>
      <description><![CDATA[大型多模态模型 (LMM) 是从大型语言模型 (LLM) 发展而来的
集成多种输入方式，例如视觉输入。这种整合
增强法学硕士完成需要视觉理解的任务的能力
推理。然而，他们增强能力的程度和局限性是
尚未完全理解，尤其是在涉及现实世界的任务时。讲话
这个间隙，我们引入了 GlitchBench，一个源自视频游戏的新颖基准
质量保证任务，测试和评估推理能力
LMM。我们的基准测试是根据各种异常和故障场景制定的
来自电子游戏，旨在挑战视觉和语言推理
LMM 检测和解释异常事件的能力。我们
评估多个最先进的 LMM，我们表明 GlitchBench 呈现
这些模型面临新的挑战。代码和数据可在以下位置获取：
https://glitchbench.github.io/
]]></description>
      <guid>http://arxiv.org/abs/2312.05291</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:14 GMT</pubDate>
    </item>
    <item>
      <title>神经元修补：代码生成和法学硕士的神经元级模型编辑。 （arXiv：2312.05356v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2312.05356</link>
      <description><![CDATA[大型语言模型在软件工程中被成功采用，
特别是在代码生成方面。用新知识更新这些模型非常重要
昂贵，并且通常需要充分实现其价值。在本文中，
我们提出了一种新颖有效的模型编辑方法 \textsc{MENT}，
在编码任务中修补法学硕士。基于生成式LLM的机制，
\textsc{MENT} 允许在下一个标记预测中进行模型编辑，并进一步
支持常见的编码任务。 \textsc{MENT} 是有效的、高效的，并且
可靠的。它可以通过修补 1 或 2 个神经元来纠正神经模型。作为
关于生成模型的神经元级模型编辑的开创性工作，我们将其形式化
编辑过程并介绍所涉及的概念。除此之外，我们还
引入新的措施来评估其泛化能力，并建立一个
进一步学习的基准。我们的方法在三个编码任务上进行评估，
包括 API-seq 推荐、行级代码生成，以及
伪代码到代码的交易。它的性能优于最先进的技术
有效性和效率措施的显着优势。此外，
我们演示了 \textsc{MENT} 在软件中 LLM 推理中的用法
工程。通过使用 \textsc{MENT} 编辑 LLM 知识，可以直接或
思想链中间接依赖的行为相应地发生变化，
自动地。
]]></description>
      <guid>http://arxiv.org/abs/2312.05356</guid>
      <pubDate>Tue, 12 Dec 2023 06:18:14 GMT</pubDate>
    </item>
    </channel>
</rss>