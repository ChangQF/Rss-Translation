<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Wed, 20 Dec 2023 03:12:12 GMT</lastBuildDate>
    <item>
      <title>KGLens：一种参数化知识图解决方案，用于评估法学硕士知道什么和不知道什么。 （arXiv：2312.11539v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.11539</link>
      <description><![CDATA[目前评估大型语言模型 (LLM) 的方法
现有的知识图谱（KG）大多忽略了知识图谱的结构
任意选择要评估图表的哪一部分。在本文中，
我们引入 KGLens，一种通过生成自然语言来评估 LLM 的方法
以结构感知方式从 KG 提出问题，以便我们能够表征其特征
更全面的表现。 KGLens 使用参数化 KG，其中
每条边都通过 beta 分布进行增强，指导如何对边进行采样
来自 KG 进行 QA 测试。随着评估的进行，不同的边缘
参数化的 KG 被适当地采样和评估，收敛到一个更
法学硕士在 KG 整体表现的全球概况。在我们的
实验中，我们构建了三个特定领域的知识图谱来进行知识评估，
包括超过 19,000 个边、700 个关系和 21,000 个实体。结果
证明 KGLens 不仅可以评估整体表现，还可以
提供法学硕士的主题、时间和关系分析。这展示了
KGLens 的适应性和可定制性，强调其聚焦能力
根据特定标准进行评估。
]]></description>
      <guid>http://arxiv.org/abs/2312.11539</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:12 GMT</pubDate>
    </item>
    <item>
      <title>CLIPSyntel：CLIP 和 LLM 协同用于医疗保健中的多模式问题总结。 （arXiv：2312.11541v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.11541</link>
      <description><![CDATA[现代医疗时代，快速产生医疗问题
摘要对于知情和及时的患者护理至关重要。尽管
医疗数据的复杂性和数量不断增加，现有研究重点关注
只注重文字概括，忽视视觉的整合
信息。认识到组合文本查询的未开发潜力
通过医疗状况的视觉表示，我们引入了多模式
医学问题总结 (MMQS) 数据集。这个数据集，一个主要的
对我们的工作做出贡献，将医学查询与视觉辅助工具结合起来，促进
对患者需求有更丰富、更细致的了解。我们还提出了一个
框架，利用对比语言图像预训练（CLIP）的力量
和大型语言模型（LLM），由四个模块组成，这些模块识别
医学疾病，生成相关背景，过滤医学概念，以及
制作视觉感知摘要。我们的综合框架利用力量
CLIP（多模式基础模型）和各种通用法学硕士，
包括四个主要模块：医疗疾病识别模块、
相关上下文生成模块、上下文过滤模块
提炼相关医学概念和知识，最终形成一个
通用法学硕士，用于生成视觉感知的医学问题摘要。
利用我们的 MMQS 数据集，我们展示了图像的视觉线索如何增强
医学上细致入微的总结的产生。这种多式联运方法不
不仅增强了医疗保健的决策过程，而且还培养了更多
细致入微地了解患者询问，为未来奠定基础
个性化和响应式医疗保健研究
]]></description>
      <guid>http://arxiv.org/abs/2312.11541</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:12 GMT</pubDate>
    </item>
    <item>
      <title>ToViLaG：你的视觉语言生成模型也是一个邪恶者。 （arXiv：2312.11523v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11523</link>
      <description><![CDATA[警告：本文包含显示攻击性内容的模型输出。最近的
大规模视觉语言生成模型（VLGM）已经实现
多模式图像/文本生成的前所未有的改进。然而，这些
模型还可能生成有毒内容，例如攻击性文本和色情内容
图像，引发重大道德风险。尽管对有毒物质进行了详尽的研究
由于语言模型的退化，这个问题在很大程度上仍未得到探索
视觉语言生成的背景。这项工作深入研究了这种倾向
用于各种 VLGM 的毒性产生和对毒性数据的敏感性。
为此，我们构建了 ToViLaG，一个包含 32K 数据的数据集
共毒/单毒文本图像对和 1K 无害但令人回味的文本
往往会刺激毒性。此外，我们提出了 WInToRe，一种新型毒性
为视觉语言生成量身定制的度量，理论上反映了
考虑输入和输出的毒性的不同方面。就这样一个
在此基础上，我们对多种 VLGM 的毒性进行了基准测试，
发现有些模型做的坏事比预期更多，而有些则更多
易受感染，强调了 VLGM 解毒的必要性。
因此，我们开发了一种创新的基于瓶颈的解毒方法。我们的
方法可以降低毒性，同时保持可比的发电质量，
为这一领域的研究提供了一个有前景的初步解决方案。
]]></description>
      <guid>http://arxiv.org/abs/2312.11523</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:11 GMT</pubDate>
    </item>
    <item>
      <title>评估 GPT4-V 的结构化推理任务。 （arXiv：2312.11524v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11524</link>
      <description><![CDATA[多模态有望解锁大型语言模型的进一步用途。
最近，最先进的语言模型 GPT-4 通过视觉得到了增强
能力。我们对 GPT-4V 和其他五个产品进行了及时评估
结构化推理任务的基线，例如数学推理、视觉推理
数据分析和代码生成。我们展示了视觉思维链
将思想链扩展到多模式法学硕士，产生了显着的成果
对香草模型的改进。我们还进行了分类分析
这些模型表现良好和表现不佳的场景，强调
与连贯多模态推理相关的挑战。
]]></description>
      <guid>http://arxiv.org/abs/2312.11524</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:11 GMT</pubDate>
    </item>
    <item>
      <title>Topic-VQ-VAE：利用潜在密码本进行灵活的主题引导文档生成。 （arXiv：2312.11532v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11532</link>
      <description><![CDATA[本文介绍了一种利用潜在主题建模的新方法
来自矢量量化变分自动编码器~（VQ-VAE）的码本，离散
封装预训练嵌入的丰富信息，例如
预训练的语言模型。从小说的潜伏解读
密码本和嵌入作为概念词袋，我们提出了一种新的
称为 Topic-VQ-VAE~(TVQ-VAE) 的生成主题模型，它反向生成
与各自的潜在码本相关的原始文件。 TVQ-VAE
可以可视化具有各种生成分布的主题，包括
传统的 BoW 分布和自回归图像生成。我们的
文档分析和图像生成的实验结果表明
TVQ-VAE 有效地捕捉了主题上下文，揭示了潜在的内容
数据集的结构并支持灵活形式的文档生成。
提议的 TVQ-VAE 的正式实施可在
https://github.com/clovaai/TVQ-VAE。
]]></description>
      <guid>http://arxiv.org/abs/2312.11532</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:11 GMT</pubDate>
    </item>
    <item>
      <title>解锁肌肉骨骼疾病风险因素：基于 NLP 的分类和基于模式的排名。 （arXiv：2312.11517v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11517</link>
      <description><![CDATA[这项研究深入探讨了肌肉骨骼疾病的复杂情况
(MSD) 风险因素，采用自然语言处理的新颖融合
（NLP）技术和基于模式的排名方法。主要目标是
促进对 MSD 风险因素及其分类的理解
它们的相对严重性，有助于更有针对性的预防和管理
干预措施。该研究利用八种不同的模型，整合了预先训练的模型
变压器、余弦相似度和各种距离度量来对风险进行分类
个人、生物力学、工作场所、心理和
组织类。主要发现表明，带有余弦的 BERT 模型
相似度达到 28\% 的总体准确率，而句子转换器，
与欧几里德距离、布雷-柯蒂斯距离和闵可夫斯基距离相结合，得到
完美准确度分数为 100\%。在分类工作的同时，
该研究采用基于模式的调查数据排名方法来辨别
MSD 风险因素的严重程度等级。有趣的是，排名一致
与以前的文献完全一致，重申了一致性和
该方法的可靠性。 “工作姿势”成为最严重的风险
因素，强调正确姿势在预防 MSD 中的关键作用。这
调查参与者的集体看法强调了
“工作不安全感”、“努力回报失衡”和“员工素质不佳”等因素
设施”在促进 MSD 风险方面具有优势。排名的趋同提供了
为旨在减少 MSD 患病率的组织提供可行的见解。
该研究的结论是对有针对性的干预措施的影响，
改善工作场所条件的建议以及未来的途径
研究。
]]></description>
      <guid>http://arxiv.org/abs/2312.11517</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:10 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型时代的用户建模：当前研究和未来方向。 （arXiv：2312.11518v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11518</link>
      <description><![CDATA[用户建模（UM）旨在发现模式或学习表征
有关特定用户特征的用户数据，例如个人资料，
偏好、个性。用户模型支持个性化和
许多在线应用程序中的可疑性检测，例如推荐，
教育、医疗保健。两种常见的用户数据类型是文本和图形，如
数据通常包含大量用户生成的内容（UGC）和
在线互动。文本和图挖掘的研究正在发展
迅速发展，在过去二十年中贡献了许多著名的解决方案。最近，
大型语言模型（LLM）在生成、
理解，甚至推理文本数据。用户的做法
模特已经获得了法学硕士学位，并很快变得出色。本文
总结了关于法学硕士如何以及为何成为出色的建模工具的现有研究
并了解 UGC。然后回顾一下大语言的几类
将 LLM 与文本集成的用户建模 (LLM-UM) 方法的模型
和基于图的方法以不同的方式。然后介绍具体的LLM-UM
适用于各种 UM 应用的技术。最后给出剩余的
密苏里大学法学硕士研究的挑战和未来方向。我们维持
阅读列表：https://github.com/TamSiuhin/LLM-UM-Reading
]]></description>
      <guid>http://arxiv.org/abs/2312.11518</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:10 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是复杂的表解析器。 （arXiv：2312.11521v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11521</link>
      <description><![CDATA[随着生成式预训练 Transformer 3.5 (GPT-3.5) 的展示
自然语言处理方面卓越的推理和理解能力
（NLP），大多数问答（QA）研究主要集中在
基于 GPT 的一般 QA 任务，忽略了以下问题带来的具体挑战
复杂的表质量检查。在本文中，我们建议合并 GPT-3.5 来解决
这些挑战，其中复杂的表被重建为元组和
对话采用了特定的提示设计。具体来说，我们编码
每个单元格的层次结构、位置信息和内容
元组。通过使用解释性描述来增强提示模板
每个元组的含义以及任务的逻辑推理过程，我们
有效提升GPT-3.5的层次结构感知能力
更好地解析复杂的表格。大量的实验和结果
复杂表 QA 数据集，即开放域数据集 HiTAB 和航空数据集
领域数据集 AIT-QA 显示我们的方法明显优于以前的方法
在这两个数据集上工作，从而获得最先进的 (SOTA) 性能。
]]></description>
      <guid>http://arxiv.org/abs/2312.11521</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:10 GMT</pubDate>
    </item>
    <item>
      <title>建立基于强化学习的系统来调整药物以最大程度地减少言语不流畅。 （arXiv：2312.11509v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11509</link>
      <description><![CDATA[我们提出了一个基于强化学习的系统，该系统会自动
为假设的患者开出可能有助于患者的药物
他们与心理健康相关的言语不流利，并调整药物和
根据患者的数据确定剂量。我们演示了组件
系统的组成部分：在大范围内检测和评估言语不流畅的模块
我们构建的数据集，以及自动强化学习算法
找到良好的药物组合。为了支持这两个模块，我们收集
关于精神科药物治疗言语不流畅的效果的数据
文献，并建立一个合理的患者模拟系统。我们展示
强化学习系统在某些情况下能够
遵循良好的药物治疗方案。我们收集并标记人员数据集
可能存在言语不流利的情况，并使用该数据集演示我们的方法。
我们的工作是一个概念验证：我们表明这个想法是有希望的
使用自动数据收集来解决不流畅问题。
]]></description>
      <guid>http://arxiv.org/abs/2312.11509</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:09 GMT</pubDate>
    </item>
    <item>
      <title>ComplexityNet：通过学习任务复杂性来提高 LLM 推理效率。 （arXiv：2312.11511v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11511</link>
      <description><![CDATA[我们提出了 ComplexityNet，这是一种简化的语言模型，旨在评估
任务复杂性。该模型通过以下方式预测准确输出的可能性
各种语言模型，每种模型都有不同的功能。我们最初的
ComplexityNet的应用涉及最基础的Python问题（MBPP）
数据集。我们率先创建了第一组标签来定义任务
复杂。 ComplexityNet 在确定任务方面达到了 79% 的显着准确率
复杂度，比原来的 34% 准确率有了显着提升，
非微调模型。此外，ComplexityNet 有效地减少了
与使用最高复杂度相比，计算资源使用量减少了 90%
模型，同时保持 86.7% 的高代码生成准确率。这项研究
演示了微调较小的模型以根据任务对任务进行分类
复杂性可以导致准确性和准确性之间更平衡的权衡
使用大型语言模型的效率。我们的研究结果表明
优化LLM申请的有希望的方向，特别是在
资源受限的环境。
]]></description>
      <guid>http://arxiv.org/abs/2312.11511</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:09 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士概览：有限内存下的高效大型语言模型推理。 （arXiv：2312.11514v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11514</link>
      <description><![CDATA[大型语言模型 (LLM) 是现代自然语言的核心
处理，在各种任务中提供卓越的性能。然而，他们的
密集的计算和内存需求带来了挑战，特别是
适用于 DRAM 容量有限的设备。本文解决了以下挑战
通过存储超过可用 DRAM 容量的高效运行的 LLM
闪存上的模型参数，但按需将它们传送到 DRAM。我们的
方法涉及构建一个与
闪存行为，指导我们在两个关键领域进行优化：
从闪存传输的数据量和读取的数据量更大、更多
连续的块。在这个基于闪存的框架内，我们引入了
两个主要技术。首先，“窗口”战略性地减少数据
通过重用先前激活的神经元进行转移，第二，“行-列”
捆绑”，针对闪存的顺序数据访问优势量身定制，
增加从闪存读取的数据块的大小。这些方法
共同支持运行高达可用 DRAM 大小两倍的模型，
与简单加载相比，推理速度提高了 4-5 倍和 20-25 倍
分别采用CPU和GPU的方法。我们整合稀疏意识，
上下文自适应加载和面向硬件的设计为
在内存有限的设备上进行 LLM 的有效推理。
]]></description>
      <guid>http://arxiv.org/abs/2312.11514</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:09 GMT</pubDate>
    </item>
    <item>
      <title>基于语音和文本的情感识别器。 （arXiv：2312.11503v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11503</link>
      <description><![CDATA[情感计算是一个专注于开发系统的研究领域
以及能够理解、解释和响应人类情感的技术。
语音情感识别（SER）尤其受到广泛关注
来自最近的研究人员。然而，在很多情况下，公开
用于训练和评估的可用数据集稀缺且不平衡
跨越情感标签。在这项工作中，我们专注于建立一个平衡的
通过将这些数据集组合为来自这些公开可用数据集的语料库
以及采用各种语音数据增强技术。此外，我们
尝试了不同的语音情感识别架构。我们的
最佳系统，多模态语音和基于文本的模型，提供了性能
与 UA（未称重精度）+ WA（称重精度）相比，为 157.57
基线算法性能为 119.66
]]></description>
      <guid>http://arxiv.org/abs/2312.11503</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:08 GMT</pubDate>
    </item>
    <item>
      <title>多种语言模型在识别社交媒体上的攻击性语言方面的表现。 （arXiv：2312.11504v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11504</link>
      <description><![CDATA[文本分类是自然语言领域的一个重要课题
加工。已初步应用于信息检索、数字化
库、自动摘要、文本过滤、词语义判别
以及许多其他领域。本研究的目的是利用各种
测试识别攻击性帖子并评估其攻击性帖子的能力的算法
绩效对比多种评估方法。这样做的动机
该项目是通过自动化来减少这些语言对人类审查员的伤害
筛选违规帖子。该领域是一个新领域，尽管有很多
近两年的兴趣，一直没有关注的对象
罪行。通过这个项目的实验，应该对未来有所启发
识别方法和识别内容的研究。
]]></description>
      <guid>http://arxiv.org/abs/2312.11504</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:08 GMT</pubDate>
    </item>
    <item>
      <title>多样性和质量胜过数量：迈向多功能教学策划。 （arXiv：2312.11508v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11508</link>
      <description><![CDATA[指令微调，涉及使用预训练的法学硕士的细化
数据集伴随着自然指令，是一种强大的方法。然而，
其有效性受到冗余和缺陷的阻碍
LLM 生成的指令数据集。在本文中，我们介绍了一种高度
用于选择多样化和高质量的有效和多功能范例
来自微调数据集的指令跟踪数据。我们首先采用
数据集增强和扩展，使数据集更加多样化和
高质量的数据，然后我们应用多样性压缩和质量压缩
按顺序整理所需的数据集。我们的实验结果展示
即使高质量的教学数据数量有限，法学硕士
在两种自然语言中始终保持稳健的性能
理解任务和代码生成任务。值得注意的是，它们的表现优于模型
在某些情况下，在更大的指令数据集上进行训练。
]]></description>
      <guid>http://arxiv.org/abs/2312.11508</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:08 GMT</pubDate>
    </item>
    <item>
      <title>拉布拉多：探索实验室数据掩码语言建模的局限性。 （arXiv：2312.11502v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11502</link>
      <description><![CDATA[在这项工作中，我们介绍了 Labrador，一种预训练的 Transformer 模型，用于
实验室数据。 Labrador 和 BERT 在 1 亿的语料库上进行预训练
来自电子健康记录 (EHR) 的实验室测试结果并根据各种评估进行评估
下游结果预测任务。两种模型都展示了对
预训练任务，但在下游都没有始终优于 XGBoost
受监督的任务。我们的消融研究表明，迁移学习表明
BERT 的有效性有限，而 Labrador 取得了有限的成功。我们
探究迁移学习失败的原因并提出
无法描述每个患者的数据生成过程
除其他因素外，仅充分利用实验室即可。我们鼓励未来的工作
专注于多个 EHR 数据类别的联合建模，并包括
评估中基于树的基线。
]]></description>
      <guid>http://arxiv.org/abs/2312.11502</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:07 GMT</pubDate>
    </item>
    </channel>
</rss>