<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Fri, 26 Jan 2024 03:15:08 GMT</lastBuildDate>
    <item>
      <title>LocMoE：用于大型语言模型训练的低开销 MoE。 （arXiv：2401.13920v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.13920</link>
      <description><![CDATA[专家混合 (MoE) 模型是一种广泛分布的、
大语言模型（LLM）的集成学习方法备受青睐
由于它能够有效地稀疏和扩展模型。但是，那
MoE 的性能受到负载不平衡和 All-To-All 的高延迟的限制
通信，以及由于大而相对冗余的计算
专家能力。负载不平衡可能是由于现有路由策略造成的
始终倾向于选择某些专家。频繁的节点间
All-To-All 程序中的通信也显着延长了
训练时间。为了缓解上述性能问题，我们提出了一种新颖的
通过转换部分负载平衡和局部性相结合的路由策略
节点间通信与节点内通信。值得注意的是，我们阐明
专家能力有一个最低阈值，通过以下方式计算
专家和专家的选通权重之间的最大角度偏差
分配的令牌。我们将这些修改移植到基于 PanGu-Sigma 模型上
多级路由的MindSpore框架并进行实验
上升集群。实验结果表明，所提出的 LocMoE
与经典相比，每个 epoch 的训练时间减少了 12.68% 至 22.24%
路由器，例如哈希路由器和交换路由器，不影响模型
准确性。
]]></description>
      <guid>http://arxiv.org/abs/2401.13920</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>适用于大型语言模型的自适应文本水印。 （arXiv：2401.13927v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13927</link>
      <description><![CDATA[大型语言模型 (LLM) 的进步导致了越来越多的
对滥用人工智能生成的文本和水印的担忧
LLM 生成的文本已成为一种潜在的解决方案。然而，它是
生成高质量的水印文本同时保持强大的水印文本具有挑战性
安全性、鲁棒性以及无需事先检测水印的能力
了解提示或模型。本文提出了一种自适应水印
解决这个问题的策略。提高文本质量并保持
鲁棒性，我们自适应地将水印添加到高令牌分布中
使用辅助模型测量熵并保留低熵标记
分布未受影响。为了安全起见并进一步减少
水印对文本质量的影响，而不是使用固定的绿色/红色列表
从随机密钥生成，该密钥可能容易被解密和
伪造时，我们根据
使用精心设计的语义对先前生成的文本进行语义嵌入
映射模型。我们涉及各种法学硕士的实验表明，我们的
方法实现了与现有水印相当的鲁棒性性能
方法。此外，我们的方法生成的文本具有复杂性
与 \emph{un-watermarked} LLM 相当，同时保持安全性
即使受到各种攻击。
]]></description>
      <guid>http://arxiv.org/abs/2401.13927</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>Leeroo Orchestrator：通过模型集成提升法学硕士的绩效。 （arXiv：2401.13979v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13979</link>
      <description><![CDATA[在本文中，我们提出了一种利用集体知识的架构
多名经过培训的法学硕士组成的团队创造了新的最先进技术。这的核心是
框架是一个基于法学硕士的编排器，擅长选择正确的
底层 LLM 专家可实现最佳任务执行。受到自我游戏的启发
强化学习，我们创建了一个查询生成、编排的循环，
和评估来为协调器生成训练数据。我们的评价
专注于 MMLU 基准，采用 7B、13B 和 34B 模型
Hugging Face 上可用的参数。结果表明新的
最先进的开源模型：我们的 Leeroo 编排器实现了
性能与 Mixtral 模型相当，同时仅花费三分之二
它的成本。此外，增加允许成本会超出 Mixtral 的准确度
在相同成本水平下，成本降低5%以上，准确率达到75.9%。更远
将 GPT4 集成到底层模型中时观察到增强功能
水池。 Leeroor 编排器几乎可以与 GPT4 的性能相媲美，性能是 GPT4 的一半
成本甚至超过了 GPT4 的结果，成本降低了 25%。这些发现
说明我们的架构在创造最先进和
通过优化多个法学硕士之间的协同作用，实现具有成本效益的法学硕士
卓越的绩效成果。
]]></description>
      <guid>http://arxiv.org/abs/2401.13979</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>不再分心：减少数据伪影的自适应上采样算法。 （arXiv：2401.13907v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13907</link>
      <description><![CDATA[研究人员最近发现，有时语言模型会取得很高的成绩
基准数据集上的准确性，但即使使用它们也不能很好地概括
对原始数据集的改动很小。有时这是由于数据
工件，模型正在学习标记和之间的虚假相关性
标签，而不是语义和逻辑。在这项工作中，我们分析了 SNLI 数据
并将这种虚假的相关性可视化。我们提出了一种自适应上采样
纠正数据伪影的算法，简单有效，并且
不需要人工编辑或注释。我们做了一个实验，应用
修复 SNLI 数据中数据伪影的算法以及训练的模型
校正数据的表现明显优于使用原始数据训练的模型
SNLI 数据，整体以及我们更正的子集。
]]></description>
      <guid>http://arxiv.org/abs/2401.13907</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>WebVoyager：使用大型多模式模型构建端到端 Web 代理。 （arXiv：2401.13919v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13919</link>
      <description><![CDATA[大型语言模型（LLM）的进步引领了一个以
现实世界中自主应用程序的发展，推动了
创建先进的基于网络的代理的创新。现有网络代理
通常仅处理一种输入模态，并且仅以简化的形式进行评估
Web 模拟器或静态 Web 快照，极大地限制了它们的适用性
现实世界的场景。为了弥补这一差距，我们引入了 WebVoyager，
创新的大型多式联运模型 (LMM) 支持的网络代理，可以完成
通过与现实世界的网站交互来实现端到端的用户指令。而且，
我们为网络代理提出了一个新的评估协议来应对挑战
开放式网络代理任务的自动评估，利用强大的
GPT-4V 的多模态理解能力。我们创造了一个新的基准
从 15 个广泛使用的网站收集现实世界的任务来评估我们的代理。
我们表明 WebVoyager 实现了 55.7% 的任务成功率，显着
超越 GPT-4（所有工具）和 WebVoyager 的性能
（纯文本）设置，强调了 WebVoyager 的卓越功能
实际应用。我们发现我们提出的自动评估
与人类判断达到 85.3% 的一致性，为进一步的研究铺平了道路
在现实环境中开发网络代理。
]]></description>
      <guid>http://arxiv.org/abs/2401.13919</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>揭露和量化医疗报告生成中大型语言模型的种族偏见。 （arXiv：2401.13867v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13867</link>
      <description><![CDATA[像 GPT-3.5-turbo 和 GPT-4 这样的大型语言模型有望实现
医疗保健专业人员，但他们可能会无意中继承偏见
他们的培训可能会影响他们在医疗应用中的效用。
尽管过去很少尝试，但这些偏见的确切影响和程度
仍然不确定。通过定性和定量分析，我们发现
这些模型往往会预测更高的成本和更长的住院时间
白人人口在充满挑战的医疗场景中表现出乐观的态度
具有更高的存活率。这些偏见反映了现实世界
医疗保健差异在患者背景的产生中显而易见，
特定疾病与特定种族的关联以及种族差异
治疗建议等。我们的研究结果强调了迫切需要
未来的研究旨在解决和减轻语言模型中的偏差，特别是
在关键的医疗保健应用中，以确保公平和准确的结果
所有患者。
]]></description>
      <guid>http://arxiv.org/abs/2401.13867</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>乳腺癌病理分类中大语言模型和监督建模的零样本推理的比较研究。 （arXiv：2401.13887v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13887</link>
      <description><![CDATA[尽管监督机器学习在信息提取方面很流行
根据临床记录，创建大型注释数据集需要大量
领域专业知识并且非常耗时。同时，大型语言模型（LLM）
已表现出有前途的迁移学习能力。在这项研究中，我们
探讨最近的法学硕士是否可以减少对大规模数据的需求
注释。我们整理了 769 例乳腺癌的手动标记数据集
病理报告，标有 13 个类别，用于比较零样本
GPT-4模型和GPT-3.5模型的分类能力
三种模型架构的监督分类性能：随机
森林分类器，带注意力的长短期记忆网络（LSTM-Att），
和 UCSF-BERT 模型。在所有 13 项任务中，GPT-4 模型执行了
明显优于或与最佳监督模型 LSTM-Att 一样好
模型（平均宏观 F1 得分为 0.83 vs. 0.75）。对于高度不平衡的任务
标签之间的差异更为突出。 GPT-4 的常见来源
错误包括来自多个样本的推论和复杂的任务设计。在
无法轻松收集大型带注释数据集的复杂任务，法学硕士
可以减轻大规模数据标注的负担。但是，如果使用法学硕士
是禁止的，使用带有大量注释的更简单的监督模型
数据集可以提供可比较的结果。法学硕士展示了以下潜力：
通过减少对 NLP 临床研究的需求来加速执行
整理大型带注释的数据集。这可能会导致增加
在观察性临床中使用基于 NLP 的变量和结果
学习。
]]></description>
      <guid>http://arxiv.org/abs/2401.13887</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>用于探索文学历史假设的动态嵌入式主题模型和变化点检测。 （arXiv：2401.13905v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13905</link>
      <description><![CDATA[我们提出了动态嵌入式主题模型和
变化点检测探索词汇语义的历时变化
古典和早期基督教拉丁语中的情态。我们演示了几种方法
用于查找和表征输出中的模式，并将它们与
比较文学和古典学的传统学术。这个简单的
语义变化无监督模型的方法可以应用于任何
合适的语料库，我们总结出未来的方向和改进目标
让噪音较大、策划较少的材料达到该阈值。
]]></description>
      <guid>http://arxiv.org/abs/2401.13905</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPT-4 的上下文学习自动找出云事件的根源。 （arXiv：2401.13810v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13810</link>
      <description><![CDATA[根本原因分析 (RCA) 在事件诊断中发挥着关键作用
云服务流程，要求待命工程师确定主要
问题并采取纠正措施，以防止今后再次发生。
改进事件 RCA 流程对于最大限度地减少服务停机时间至关重要，
客户影响和手工劳动。人工智能的最新进展
引入了最先进的大型语言模型 (LLM)，例如 GPT-4，
已被证明可以有效解决各种 AIOps 问题，包括代码
创作事件管理。尽管如此，GPT-4 模型的巨大尺寸
由于以下原因，尝试根据用户数据对其进行微调时会遇到挑战
巨大的GPU资源需求和连续模型的必要性
随着新数据的出现进行微调。为了解决高昂的成本
微调LLM，我们提出了一种自动根的上下文学习方法
导致，从而消除了微调的需要。我们进行广泛的研究
超过10万个生产事件，比较几种大型语言模型
使用多个指标。结果表明我们的情境学习
方法优于之前微调的大型语言模型，例如
GPT-3 在所有指标上平均提高了 24.8\%，令人印象深刻的是 49.7\%
零样本模型的改进。此外，人类评估涉及
实际事件所有者证明了其相对于微调模型的优越性，
正确性提高了 43.5%，准确性提高了 8.7%
可读性。令人印象深刻的结果证明了利用
用于 RCA 任务的普通 GPT 模型，从而避免了高计算量和
与微调模型相关的维护成本。
]]></description>
      <guid>http://arxiv.org/abs/2401.13810</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:04 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中模型与人类置信度之间的校准差距。 （arXiv：2401.13835v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.13835</link>
      <description><![CDATA[为了让大型语言模型 (LLM) 受到人类的信任，它们需要
良好的校准意味着他们可以准确地评估和沟通
他们的预测正确的可能性有多大。最近的工作重点是
内部法学硕士信心评估的质量，但问题仍然是
法学硕士如何向人类用户传达这种内部模型的信心。
本文探讨了法学硕士外部人类信心之间的差异
响应和模型的内部置信度。通过实验
涉及多项选择题，我们系统地检查人类用户的
辨别LLM输出可靠性的能力。我们的研究主要集中在两个关键
领域：(1) 评估用户对真实 LLM 信心的看法以及 (2)
研究量身定制的解释对这种看法的影响。这
研究强调，法学硕士的默认解释通常会导致用户
高估了模型的置信度及其准确性。通过修改
为了更准确地反映LLM的内部信心，我们的解释
观察用户感知的重大转变，使其与
模型的实际置信水平。此次解释方式的调整
展示了增强用户信任度和评估 LLM 准确性的潜力
输出。研究结果强调了透明沟通的重要性
法学硕士的置信水平，特别是在高风险应用中
了解人工智能生成信息的可靠性至关重要。
]]></description>
      <guid>http://arxiv.org/abs/2401.13835</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:04 GMT</pubDate>
    </item>
    <item>
      <title>TPD：通过原理发现和指导增强学生语言模型推理。 （arXiv：2401.13849v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13849</link>
      <description><![CDATA[大型语言模型（LLM）最近展示了非凡的推理能力
能力。然而，较大的模型通常在以下方面优于较小的模型
推理任务，提出了有效转移这些任务的挑战
更大型号的功能。现有的方法严重依赖于广泛的
微调数据或与优秀的法学硕士老师持续互动
推理。我们引入一个基于原则的师生框架，称为
“通过原理发现进行教学”（TPD）可以解决这些限制。
受人类学习机制的启发，TPD 模仿了
教师和学生使用基于原则的方法。老师LLM
根据问题生成指导和纠正原则
学生LLM的错误。这些原则指导指令的细化和
从验证集中选择指导性示例。这使得
学生模型从老师的指导和自己的错误中学习。
一旦学生模型开始进行推理，TPD 就不需要进一步的
来自法学硕士老师或人类的干预。通过大量的实验
在八个推理任务中，我们证明了 TPD 的有效性。比较的
与标准的思维链提示相比，TPD 显着提高了学生的学习能力
模型的性能，平均提高了 $6.2\%$。
]]></description>
      <guid>http://arxiv.org/abs/2401.13849</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:04 GMT</pubDate>
    </item>
    <item>
      <title>情绪检测和面向任务的对话建模的统一方法。 （arXiv：2401.13789v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13789</link>
      <description><![CDATA[在当前基于文本的面向任务的对话（TOD）系统中，用户情绪
检测（ED）经常被忽视，或者通常被视为一个单独的和
独立任务，需要额外培训。相比之下，我们的工作
证明无缝统一 ED 和 TOD 建模可以带来相互的好处
好处，因此是一个值得考虑的替代方案。我们的方法包括
通过扩展信念状态来增强 SimpleToD（一种端到端的 TOD 系统）
跟踪包括 ED，依赖于单一语言模型。我们评估我们的
在 EmoWOZ 基准（MultiWOZ 的一个版本）上使用 GPT-2 和 Llama-2 的方法
带有情感的注释。我们的结果显示绩效普遍提高
用于 ED 和任务结果。我们的研究结果还表明，用户情绪可以提供
对系统响应有用的上下文调节，并且可以用来
进一步完善同理心方面的反应。
]]></description>
      <guid>http://arxiv.org/abs/2401.13789</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>研究大型语言模型用于代码克隆检测的功效。 （arXiv：2401.13802v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2401.13802</link>
      <description><![CDATA[大型语言模型 (LLM) 在各个方面都取得了显着的成功
自然语言处理和软件工程任务，例如代码
一代。法学硕士主要用于基于提示的零/少样本
指导模型完成任务的范式。 %\textbf{目标：}
基于 GPT 的模型是针对代码等任务研究的流行模型之一
评论生成或测试生成。这些任务是“生成”任务。
然而，关于法学硕士在“非生成性”方面的使用的研究有限
任务，例如使用基于提示的范式进行分类。在这个
初步探索性研究，我们调查了法学硕士的适用性
代码克隆检测（CCD），一种非生成性任务。 %\textbf{方法:} 通过
构建源自 CodeNet 的单语言和跨语言 CCD 数据集，我们
首先使用ChatGPT调查了两个不同的提示来检测
\textcolor{black}{Type-4} 代码克隆在 Java-Java 和 Java-Ruby 对中
零射击设置。我们 \textcolor{black}{then} 进行了分析
了解 ChatGPT 在 CCD 中的优点和缺点。 %\textbf{结果:}
ChatGPT 超越了跨语言 CCD 的基线
\textcolor{black}{获得 F1 分数 0.877 } 并达到可比的水平
单语 CCD 的完全微调模型的性能，
\textcolor{黑色}{F1 分数为 0.878}。另外，
\textcolor{black}{prompt 并且}问题的难度级别有一个
对 ChatGPT 性能的影响。 \textcolor{黑色}{最后，}我们提供
基于我们初步分析的见解和未来方向
]]></description>
      <guid>http://arxiv.org/abs/2401.13802</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>使用多模态基础模型实现稳健的多模态学习。 （arXiv：2401.13697v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13697</link>
      <description><![CDATA[现有的多模态情感分析任务高度依赖于
假设训练集和测试集是完整的多模态数据，而
这个假设可能很难成立：多模态数据通常是
在现实场景中不完整。因此，稳健的多模态模型
具有随机缺失模式的场景是高度首选的。最近，
基于 CLIP 的多模态基础模型已经展示了令人印象深刻的
通过学习对齐的跨模态来执行众多多模态任务
图像和文本对的语义，但多模态基础模型是
也无法直接解决涉及模态缺失的场景。到
为了缓解这个问题，我们提出了一个简单有效的框架，即TRML，
使用多模态基础模型实现稳健的多模态学习。 TRML
使用生成的虚拟模态来替换缺失的模态，并对齐
生成的模态和缺失的模态之间的语义空间。具体来说，
我们设计了一个缺失的模态推理模块来生成虚拟模态
并替换缺失的模式。我们还设计了语义匹配学习
用于对齐生成的语义空间和缺失的模态的模块。在下面
提示完整的模态，我们的模型捕获了缺失的语义
通过利用对齐的跨模态语义空间来调整模态。实验
证明我们的方法在三种多模态情感上的优越性
分析基准数据集、CMU-MOSI、CMU-MOSEI 和 MELD。
]]></description>
      <guid>http://arxiv.org/abs/2401.13697</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>推文到引文：揭示社交媒体影响者对人工智能研究可见性的影响。 （arXiv：2401.13782v1 [cs.DL]）</title>
      <link>http://arxiv.org/abs/2401.13782</link>
      <description><![CDATA[随着人工智能和机器学习会议接受的论文数量达到
数千人，目前尚不清楚研究人员如何访问和阅读研究成果
出版物。在本文中，我们研究了社交媒体的作用
提高机器学习研究知名度的影响者，
特别是他们分享的论文的引用次数。我们整理了一份
包含 8,000 多篇论文的综合数据集，涵盖 2018 年 12 月以来的推文
到 2023 年 10 月，同时根据出版年份进行 1:1 匹配对照，
地点和抽象主题。我们的分析表明，
这些影响者认可的论文被引用的次数，以及引用次数的中位数
比对照组高2-3倍。此外，该研究
深入研究突出的地理、性别和制度多样性
作者。这些发现突显了社交媒体的影响力不断扩大
学术交流并强调不断发展的生态系统的重要性
在当今的数字学术环境中。
]]></description>
      <guid>http://arxiv.org/abs/2401.13782</guid>
      <pubDate>Fri, 26 Jan 2024 03:15:02 GMT</pubDate>
    </item>
    </channel>
</rss>