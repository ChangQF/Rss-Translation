<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Mon, 04 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用于词汇语义变化检测的语义距离度量学习方法</title>
      <link>https://arxiv.org/abs/2403.00226</link>
      <description><![CDATA[arXiv:2403.00226v1 公告类型：新
摘要：检测单词的时间语义变化是各种必须做出时间敏感预测的 NLP 应用程序的一项重要任务。词汇语义变化检测 (SCD) 任务考虑预测给定目标单词 $w$ 是否在两个不同文本语料库 $C_1$ 和 $C_2$ 之间改变其含义的问题。为此，我们提出了一种使用现有 Word-in-Context (WiC) 数据集的监督两阶段 SCD 方法。在第一阶段，对于目标单词 $w$，我们学习两个感知编码器，它们表示从语料库中选择的给定句子中 $w$ 的含义。接下来，在第二阶段，我们学习一个感知距离度量，该度量比较目标单词在 $C_1$ 和 $C_2$ 中所有出现的位置的语义表示。 SCD 多个基准数据集上的实验结果表明，我们提出的方法始终优于所有先前提出的多种语言的 SCD 方法，为 SCD 建立了新颖的最先进技术。有趣的是，我们的研究结果表明，存在一些专门的维度，它们携带与感知感知嵌入空间中单词的语义变化相关的信息。源代码可在 https://github.com/a1da4/svp-sdml 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.00226</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:34 GMT</pubDate>
    </item>
    <item>
      <title>使用 FlanT5-XXL 对零镜头姿态检测进行基准测试：从训练数据、提示和解码策略中洞察其接近 SoTA 的性能</title>
      <link>https://arxiv.org/abs/2403.00236</link>
      <description><![CDATA[arXiv:2403.00236v1 公告类型：新
摘要：我们研究了基于 LLM 的零样本姿态检测在推文上的性能。使用 FlanT5-XXL（一种指令调整的开源 LLM）以及 SemEval 2016 任务 6A、6B 和 P-Stance 数据集，我们研究了不同提示和解码策略下的性能及其变化，以及该模型。我们证明零样本方法可以匹配或超越最先进的基准，包括微调模型。我们对其性能提供了各种见解，包括对指令和提示的敏感性、解码策略、提示的复杂性以及提示中存在的否定和反对。最后，我们确保法学硕士没有接受过测试数据集的训练，并确定了积极偏差，这可能部分解释了解码策略之间的性能差异]]></description>
      <guid>https://arxiv.org/abs/2403.00236</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:34 GMT</pubDate>
    </item>
    <item>
      <title>使用数据增强和偏好优化改进苏格拉底式问题的生成</title>
      <link>https://arxiv.org/abs/2403.00199</link>
      <description><![CDATA[arXiv:2403.00199v1 公告类型：新
摘要：苏格拉底方法是引导学生独立解决问题而不直接揭示问题的解决方案的一种方法。尽管这种方法已被证明可以显着提高学生的学习成果，但对于教师来说仍然是一项复杂的劳动密集型任务。大型语言模型（LLM）可以通过自动为学生生成苏格拉底式问题来增强人类的努力。然而，涉及提示这些法学硕士的现有方法有时会产生无效的输出，例如，直接揭示问题的解决方案或提供不相关或不成熟的问题的输出。为了缓解这个问题，受到人工智能反馈强化学习（RLAIF）的启发，我们首先提出了一种数据增强方法，用在特定方式下无效的问题来丰富现有的苏格拉底提问数据集。接下来，我们提出了一种使用直接偏好优化（DPO）来优化开源 LLM 的方法，例如 LLama 2，以优先选择真实问题而不是生成的无效问题。我们在用于学生代码调试的苏格拉底问题数据集上进行的实验表明，经过 DPO 优化的 7B LLama 2 模型可以有效避免生成无效问题，因此优于现有最先进的提示方法。]]></description>
      <guid>https://arxiv.org/abs/2403.00199</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:33 GMT</pubDate>
    </item>
    <item>
      <title>在自定义数据集和 mBART 上使用微调的 XLSR Wav2Vec2 进行视频转录和翻译</title>
      <link>https://arxiv.org/abs/2403.00212</link>
      <description><![CDATA[arXiv:2403.00212v1 公告类型：新
摘要：这项研究解决了用最少的数据训练个性化语音 ASR 模型的挑战。我们仅利用 YouTube 视频中 14 分钟的自定义音频，采用基于检索的语音转换 (RVC) 来创建自定义 Common Voice 16.0 语料库。随后，在此数据集上微调跨语言自监督表示 (XLSR) Wav2Vec2 模型。开发的基于网络的 GUI 可以有效地转录和翻译输入的印地语视频。通过集成 XLSR Wav2Vec2 和 mBART，该系统将翻译文本与视频时间轴对齐，为多语言视频内容转录和个性化语音翻译提供易于访问的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2403.00212</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:33 GMT</pubDate>
    </item>
    <item>
      <title>“Flex Tape 无法解决这个问题”：编辑语言模型中的偏见和错误信息</title>
      <link>https://arxiv.org/abs/2403.00180</link>
      <description><![CDATA[arXiv:2403.00180v1 公告类型：新
摘要：模型编辑已成为更新语言模型中存储的知识的一种经济有效的策略。然而，模型编辑在应用编辑后可能会产生意想不到的后果：与编辑无关的信息也可能被更改，并且模型的其他一般行为可能被错误地更改。在这项工作中，我们研究了模型编辑方法如何意外地放大编辑后的模型偏差。我们引入了一个新颖的基准数据集 Seesaw-CF，用于测量模型编辑与偏差相关的危害，并首次深入研究不同的权重编辑方法如何影响模型偏差。具体来说，我们关注种族、地理起源和性别等人口统计属性的偏见，以及编辑语言模型生成的长文本的质量缺陷。我们发现，经过编辑的模型在不同程度上表现出更多的偏见行为，因为它们对亚洲、非洲和南美受试者的属性变得不那么有信心。此外，经过编辑的模型在文本生成中放大了性别歧视和仇外心理，同时保持了看似连贯和逻辑性。最后，编辑有关出生地、国籍或性别的事实会对模型对工作领域等不相关特征的了解产生特别负面的影响。]]></description>
      <guid>https://arxiv.org/abs/2403.00180</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:32 GMT</pubDate>
    </item>
    <item>
      <title>AXOLOTL：通过大型语言模型输出的辅助自我消除偏差实现公平</title>
      <link>https://arxiv.org/abs/2403.00198</link>
      <description><![CDATA[arXiv:2403.00198v1 公告类型：新
摘要：预训练的大型语言模型（LLM）具有显着先进的自然语言处理能力，但容易受到训练数据中存在的偏差的影响，从而导致各种应用中出现不公平的结果。虽然已经提出了许多策略来减轻偏差，但它们通常需要大量的计算资源，并且可能会损害模型性能。在这项工作中，我们介绍了 AXOLOTL，这是一种新颖的后处理框架，它可以跨任务和模型运行，利用公共 API 与 LLM 交互，而无需直接访问内部参数。通过类似于零样本学习的三步过程，AXOLOTL 识别偏差、提出解决方案并指导模型对其输出进行自我消除偏差。这种方法最大限度地减少了计算成本并保留了模型性能，使 AXOLOTL 成为一种很有前景的 LLM 输出去偏工具，具有广泛的适用性和易用性。]]></description>
      <guid>https://arxiv.org/abs/2403.00198</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:32 GMT</pubDate>
    </item>
    <item>
      <title>EBBS：用于零样本机器翻译的双层波束搜索集成</title>
      <link>https://arxiv.org/abs/2403.00144</link>
      <description><![CDATA[arXiv:2403.00144v1 公告类型：新
摘要：当我们训练具有一定翻译方向的多语言模型时，就会出现零样本翻译的能力；然后模型可以直接向看不见的方向平移。或者，零次翻译可以通过第三种语言（例如英语）来完成。在我们的工作中，我们观察到直接翻译和枢轴翻译都有噪音，并且性能不太令人满意。我们提出了 EBBS，一种采用新颖的双层波束搜索算法的集成方法，其中每个集成组件在较低级别逐步探索自己的预测，但它们通过较高级别的“软投票”机制进行同步。两个流行的多语言翻译数据集的结果表明，EBBS 始终优于直接翻译和枢转翻译以及现有的集成技术。此外，我们可以将集成的知识提炼回多语言模型，以提高推理效率；深刻的是，我们基于 EBBS 的蒸馏不会牺牲甚至提高翻译质量。]]></description>
      <guid>https://arxiv.org/abs/2403.00144</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:31 GMT</pubDate>
    </item>
    <item>
      <title>TELEClass：分类法丰富和法学硕士增强的层次文本分类，只需最少的监督</title>
      <link>https://arxiv.org/abs/2403.00165</link>
      <description><![CDATA[arXiv:2403.00165v1 公告类型：新
摘要：分层文本分类旨在将每个文档分类为标签分类中的一组类。大多数早期的工作都集中在完全或半监督的方法上，这些方法需要大量的人工注释数据，而获取这些数据既昂贵又耗时。为了减轻人类的努力，在本文中，我们以最少的监督进行分层文本分类：使用每个节点的唯一类名作为唯一的监督。最近，大型语言模型（LLM）通过零样本提示在各种任务上显示出有竞争力的性能，但该方法在分层设置中表现不佳，因为在提示中包含大型且结构化的标签空间是无效的。另一方面，以前的弱监督分层文本分类方法仅利用原始分类骨架，而忽略了文本语料库中隐藏的可作为附加类指示特征的丰富信息。为了应对上述挑战，我们提出了 TELEClass、分类法丰富和 LLM 增强型弱监督分层文本分类，它 (1) 使用从语料库中挖掘的类指示性主题术语自动丰富标签分类法，以促进分类器训练；(2)利用法学硕士进行数据注释和为分层标签空间量身定制的创建。实验表明，TELEClass 在两个公共数据集上可以优于之前的弱监督分层文本分类方法和基于 LLM 的零样本提示方法。]]></description>
      <guid>https://arxiv.org/abs/2403.00165</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:31 GMT</pubDate>
    </item>
    <item>
      <title>提示 ChatGPT 进行翻译：翻译摘要和角色提示的比较分析</title>
      <link>https://arxiv.org/abs/2403.00127</link>
      <description><![CDATA[arXiv:2403.00127v1 公告类型：新
摘要：法学硕士的即时工程已显示出提高翻译质量的潜力。然而，将翻译概念融入提示设计的潜力在很大程度上仍未得到充分开发。在此背景下，本文讨论了将翻译摘要概念工具以及译者和作者角色融入到 ChatGPT 翻译任务提示设计中的有效性。研究结果表明，尽管某些元素对于促进翻译任务中的人与人之间的交流具有建设性，但它们对于提高 ChatGPT 翻译质量的有效性有限。这凸显了对翻译理论家和实践者如何开发当前一套植根于人与人交流范式的概念工具进行更多探索性研究的需要，以用于在涉及人机交互的新兴工作流程中的翻译目的。]]></description>
      <guid>https://arxiv.org/abs/2403.00127</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:30 GMT</pubDate>
    </item>
    <item>
      <title>EROS：实体驱动的受控政策文件摘要</title>
      <link>https://arxiv.org/abs/2403.00141</link>
      <description><![CDATA[arXiv:2403.00141v1 公告类型：新
摘要：隐私政策文件在教育个人了解组织收集、使用和保护用户个人数据方面发挥着至关重要的作用。然而，它们因其冗长、复杂和令人费解的语言而臭名昭著，尤其是涉及隐私相关实体的语言。因此，它们对试图理解组织的数据使用策略的用户构成了重大挑战。在本文中，我们建议通过使用受控抽象摘要来增强政策文件的可解释性和可读性——我们强制生成的摘要包括关键的隐私相关实体（例如数据和媒介）和组织的基本原理（例如目标和理由） ）收集这些实体。为了实现这一目标，我们开发了 PD-Sum，这是一个带有标记的隐私相关实体标签的政策文档摘要数据集。我们提出的模型 EROS 通过基于跨度的实体提取模型来识别关键实体，并利用它们通过近端策略优化（PPO）来控制摘要的信息内容。比较显示在各种基线上都有令人鼓舞的改进。此外，我们还提供定性和人体评估来确定 EROS 的功效。]]></description>
      <guid>https://arxiv.org/abs/2403.00141</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:30 GMT</pubDate>
    </item>
    <item>
      <title>基于集成的无监督不连续选区树平均解析</title>
      <link>https://arxiv.org/abs/2403.00143</link>
      <description><![CDATA[arXiv:2403.00143v1 公告类型：新
摘要：我们解决了无监督的不连续选区解析问题，我们观察到先前模型的性能存在很大差异。我们建议通过对预测树进行平均来构建现有不连续解析器的不同运行的集合，以稳定和提高性能。首先，我们为不同二元性和连续性设置下的树平均提供全面的计算复杂性分析（就 P 和 NP 完全而言）。然后，我们开发了一种高效精确的算法来处理该任务，该算法在我们实验中的所有样本上运行在合理的时间内。三个数据集的结果表明我们的方法在所有指标上都优于所有基线；我们还对我们的方法进行了深入分析。]]></description>
      <guid>https://arxiv.org/abs/2403.00143</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:30 GMT</pubDate>
    </item>
    <item>
      <title>PROC2PDDL：来自文本的开放域规划表示</title>
      <link>https://arxiv.org/abs/2403.00092</link>
      <description><![CDATA[arXiv:2403.00092v1 公告类型：新
摘要：基于文本的环境中的规划仍然是人工智能系统的主要挑战。最近的方法使用语言模型来预测规划域定义（例如 PDDL），但仅在闭域模拟环境中进行评估。为了解决这个问题，我们提出了 Proc2PDDL，这是第一个包含开放域程序文本与专家注释的 PDDL 表示配对的数据集。使用该数据集，我们评估了定义行动的先决条件和效果的最先进模型。我们表明 Proc2PDDL 具有很高的挑战性，GPT-3.5 的成功率接近 0%，GPT-4 的成功率约为 35%。我们的分析显示了语法和语义错误，表明语言模型在生成特定领域的程序和事件推理方面都存在缺陷。我们希望这个分析和数据集有助于未来在整合最好的 LM 和正式规划方面取得进展。]]></description>
      <guid>https://arxiv.org/abs/2403.00092</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:29 GMT</pubDate>
    </item>
    <item>
      <title>FAC$^2$E：通过分离语言和认知更好地理解大型语言模型能力</title>
      <link>https://arxiv.org/abs/2403.00126</link>
      <description><![CDATA[arXiv:2403.00126v1 公告类型：新
摘要：大型语言模型（LLM）主要通过各种文本理解和生成任务的整体表现来评估。然而，这种范式未能全面区分细粒度的语言和认知技能，导致法学硕士的能力缺乏充分的解释。在本文中，我们提出了 FAC$^2$E，这是一个用于细粒度和基于认知的法学硕士能力评估的框架。具体来说，我们将语言相关能力和认知相关能力分离，以多维度、可解释的方式制定法学硕士的评估。此外，通过提取LLM的中间推理，我们进一步将应用特定能力的过程分解为三个子步骤：回忆相关知识、利用知识和解决问题。最后，FAC$^2$E 评估每个细粒度能力的每个子步骤，为 LLM 提供两个方面的诊断。利用 FAC$^2$E，我们发现了模型之间知识利用的常见缺陷，并提出了一种简单的知识增强方法来缓解这个问题。我们的结果不仅展示了有希望的性能增强，而且还突出了未来法学硕士进步的方向。]]></description>
      <guid>https://arxiv.org/abs/2403.00126</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:29 GMT</pubDate>
    </item>
    <item>
      <title>Query-OPT：会议摘要中通过多查询指令优化大型语言模型的推理</title>
      <link>https://arxiv.org/abs/2403.00067</link>
      <description><![CDATA[arXiv:2403.00067v1 公告类型：新
摘要：这项工作重点关注基于查询的会议摘要任务，其中响应特定查询生成上下文摘要（会议记录）。当使用大型语言模型 (LLM) 执行此任务时，每个新查询都需要对 LLM 推理端点/API 进行新调用，即使上下文保持不变也是如此。然而，重复调用 LLM 推理端点将显着增加在生产中使用它们的成本，使得 LLM 对于许多实际用例来说不切实际。为了解决这个问题，在本文中，我们研究了是否可以在会议摘要中成功使用在单个提示中组合对相同输入上下文的查询以最大程度地减少重复调用。在这方面，我们通过比较各种流行的 LLM 的性能进行了大量的实验：GPT-4、PaLM-2、LLaMA-2、Mistral 和 FLAN-T5 在单查询和多查询设置中的性能。我们观察到，虽然大多数 LLM 倾向于响应多查询指令，但几乎所有 LLM（GPT-4 除外）即使经过微调，也无法正确生成所需输出格式的响应。我们的结论是，虽然多查询提示可以通过减少对会议摘要任务的推理端点/API 的调用来优化推理成本，但这种以预期格式可靠生成响应的能力仅限于某些法学硕士。]]></description>
      <guid>https://arxiv.org/abs/2403.00067</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:28 GMT</pubDate>
    </item>
    <item>
      <title>Resonance RoPE：提高大型语言模型的上下文长度泛化</title>
      <link>https://arxiv.org/abs/2403.00071</link>
      <description><![CDATA[arXiv:2403.00071v1 公告类型：新
摘要：本文解决了配备旋转位置嵌入（RoPE）的大型语言模型（LLM）中的训练-短-测试-长（TSTL）场景的挑战，其中在较短序列上预训练的模型面临着超出范围的困难。较长序列中的分布（OOD）标记位置。我们引入了 Resonance RoPE，这是一种新颖的方法，旨在通过细化 OOD 位置的 RoPE 特征插值来缩小 TSTL 场景中的泛化差距，从而显着提高模型性能，而无需额外的在线计算成本。此外，我们还推出了 PosGen，这是一种专门为 TSTL 场景中的细粒度行为分析而设计的新综合基准，旨在将长上下文中不断增加的令牌生成难度与识别新令牌位置的挑战隔离开来。我们对合成任务的实验表明，应用 Resonance RoPE 后，Transformers 可以更好、更稳健地识别 OOD 位置。我们广泛的法学硕士实验还表明，将 Resonance RoPE 应用于当前最先进的 RoPE 缩放方法 YaRN 后，在上游语言建模任务和各种下游长文本应用程序上都具有卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.00071</guid>
      <pubDate>Mon, 04 Mar 2024 07:03:28 GMT</pubDate>
    </item>
    </channel>
</rss>