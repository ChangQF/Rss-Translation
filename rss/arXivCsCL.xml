<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Tue, 19 Dec 2023 06:17:56 GMT</lastBuildDate>
    <item>
      <title>半真半假：部分虚假的音频检测数据集。 （arXiv：2104.03617v2 [cs.SD] 已更新）</title>
      <link>http://arxiv.org/abs/2104.03617</link>
      <description><![CDATA[各种有前景的数据集旨在阻碍
虚假音频检测，例如 ASVspoof 数据库。然而之前的数据集
忽略黑客隐藏一些小假片段的攻击情况
在真实的语音音频中。这构成了严重的威胁，因为很难
将小假片段与整个语音内容区分开来。所以，
本文开发了这样一个用于半真音频检测（HAD）的数据集。
HAD 数据集中的部分伪造音频仅涉及更改其中的几个单词
一句话。单词的音频是用最新的生成的
最先进的语音合成技术。我们不仅可以辨别假货
uttrances，还可以使用此数据集本地化语音中的操纵区域。
该数据集提供了一些基准测试结果。结果表明
部分虚假音频比完全虚假音频更具挑战性
虚假音频检测。 HAD 数据集是公开的：
https://zenodo.org/records/10377492。
]]></description>
      <guid>http://arxiv.org/abs/2104.03617</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>学生是吵闹老师的固有降噪器。 （arXiv：2312.10185v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.10185</link>
      <description><![CDATA[知识蒸馏（KD）已被广泛应用于知识转移
从大型语言模型 (LLM) 到低数据领域的专用模型
通过伪标签学习。然而，老师生成的伪标签
模型通常有噪声，可能会影响 KD 性能。这项研究深入探讨了
与吵闹的老师一起进行 KD，并发现学生模型已经可以
生成比用于训练的教师标签更准确的预测
在 KD 期间，表明其固有的去噪嘈杂教师标签的能力。
受这一发现的启发，我们提出 Peer-Advised KD 来改进普通 KD
来自吵闹的老师。实验表明 Peer-Advised KD 可以优于 LLM
50 个人类标记的数据，提高了约 5%，甚至比
使用 750 个人工标记数据进行标准监督微调。
]]></description>
      <guid>http://arxiv.org/abs/2312.10185</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型对临床句子中的移动功能信息进行低资源分类。 （arXiv：2312.10202v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.10202</link>
      <description><![CDATA[目标：功能越来越被认为是一个重要指标
全人健康。这项研究评估了公开可用的能力
大型语言模型 (LLM) 可准确识别功能的存在
来自临床记录的信息。我们探索各种策略来改善
在此任务上的表现。材料和方法：我们收集平衡的二进制文件
来自 Mobility NER 数据集的 1000 个句子的分类数据集，其中
是根据 n2c2 临床记录整理的。为了评估，我们构建了零样本
和少数镜头提示询问法学硕士给定的句子是否包含
移动功能信息。两种抽样技术，随机抽样和
基于 k 最近邻 (kNN) 的采样，用于选择少数样本
例子。此外，我们应用了参数高效的基于提示的微调
法学硕士的方法并评估他们在各种培训下的表现
设置。结果：Flan-T5-xxl 在零样本方面均优于所有其他模型
和少镜头设置，单次拍摄的 F1 分数为 0.865
kNN 采样选择的示范示例。基于提示的微调
实验中，该基础模型也表现出了优越的性能
跨越所有低资源环境，特别是取得令人印象深刻的 F1 分数
使用完整训练数据集的结果为 0.922。较小的型号，Flan-T5-xl，
只需要 2.3M 额外参数进行微调即可达到可比较的效果
性能与完全微调的 Gatortron 基础模型相比，均超过 0.9
F1成绩。结论：开源指令调整的法学硕士表现令人印象深刻
移动功能分类任务中的情境学习能力。
这些模型的性能可以通过继续进一步提高
对特定于任务的数据集进行微调。
]]></description>
      <guid>http://arxiv.org/abs/2312.10202</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>VK-G2T：视觉和上下文知识增强的 Gloss2Text。 （arXiv：2312.10210v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.10210</link>
      <description><![CDATA[现有的手语翻译方法遵循两阶段流程：首先
将手语视频转换为注释序列（即 Sign2Gloss）以及
然后将生成的注释序列翻译成口语句子
（即 Gloss2Text）。虽然之前的研究主要集中在提高
Sign2Gloss 阶段的性能，我们强调的优化
Gloss2Text 阶段。然而，由于两个不同的因素，这项任务并不简单
Gloss2Text 的特点：(1) 隔离光泽输入和 (2) 低容量光泽
词汇。为了解决这些问题，我们提出了愿景和背景知识
增强的 Gloss2Text 模型，名为 VK-G2T，它利用了
手语视频来学习目标句子的属性
利用上下文知识促进注释的自适应翻译
字。在中国基准上进行的大量实验验证了
我们模型的优越性。
]]></description>
      <guid>http://arxiv.org/abs/2312.10210</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>LVLM 理解图表吗？分析和纠正图表标题中的事实错误。 （arXiv：2312.10160v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.10160</link>
      <description><![CDATA[大型视觉语言模型 (LVLM) 的最新进展导致
在生成视觉自然语言描述方面取得重大进展
内容，从而增强各种应用程序。这些强大的问题之一
模型的缺点是它们有时会产生与事实不一致的文本
通过视觉输入。虽然已经做出了一些努力来减轻这种情况
自然图像字幕的不一致，生成的真实性
结构化文档图像（例如图表）的标题尚未得到认可
大量审查，对关键领域的信息可靠性构成潜在威胁
应用程序。这项工作通过引入
生成的图表标题中事实错误的综合类型。 A
大规模的人工注释工作提供了对错误模式的洞察
以及由各种图表字幕模型制作的字幕中的频率，
最终形成了一个新颖的数据集“CHOCOLATE”的基础。我们的分析
表明即使是最先进的模型，包括 GPT-4V，也经常产生
标题与事实不准确。为了应对这一挑战，我们
建立图表标题事实错误纠正的新任务并引入
CHARTVE，一种视觉蕴涵模型，其性能优于专有和
评估事实一致性的开源 LVLM。此外，我们建议
C2TFEC，一个可解释的两阶段框架，擅长纠正事实
错误。这项工作开创了事实错误纠正的新领域
图表标题，提出了一种新颖的评估机制，并展示了
确保生成的图表标题真实性的有效方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.10160</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>无监督词性标注及其对语言习得的影响的回顾。 （arXiv：2312.10169v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.10169</link>
      <description><![CDATA[人类句法知识的一项能力是确定哪个
单词可以出现在相似的结构中（即按单词的顺序对单词进行分组）
句法类别）。这些分组使人类能够组合结构
以便传达复杂的含义。一个基本问题是如何
孩子们获得这种基于句法知识的能力。在探索这个
过程中，我们将回顾各种目标相似的工程方法
孩子的——在没有事先语法知识的情况下，正确识别
文本样本中单词的词性 (POS)。在审查这些
无监督标记工作，我们将讨论支持的共同主题
模型的进展及其与语言习得的相关性。为了
例如，我们讨论每个模型如何判断成功（评估指标），
限制 POS 学习的“附加信息”（例如正字法）
信息），以及用于确定 POS 的上下文（仅前一个单词、单词
目标之前和之后等）。确定的主题为
未来对支撑认知过程的研究
获取句法类别并提供当前的有用布局
最先进的无监督 POS 标记模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.10169</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>用于几乎任何语言的自动事实检查的管道和数据集生成。 （arXiv：2312.10171v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.10171</link>
      <description><![CDATA[本文介绍了一个利用自动化事实检查的管道
公开可用的语言模型和数据。目标是评估
使用来自真实证据语料库的证据的文本主张的准确性。
该管道由两个主要模块组成——证据检索和
索赔真实性评估。我们的主要关注点是易于部署
自动化领域中尚未探索的各种语言
事实核查。与大多数类似的管道不同，它需要证据
句子，我们的管道在段落级别处理数据，简化了
总体架构和数据要求。鉴于注释成本高昂
特定于语言的事实检查训练数据，我们的解决方案建立在
我们采用并使用了索赔生成问答 (QACG) 方法
生成管道所有模型的数据。我们的战略使
通过仅两种固定语言的机器翻译引入新语言
中等大小的数据集。随后，可以得到任意数量的训练样本
基于目标语言的证据语料库生成。我们提供开放的
访问捷克语、英语、波兰语和斯洛伐克语的所有数据和微调模型
管道，以及我们的代码库，可用于重现
结果。我们全面评估所有四种语言的管道，
包括人工注释和每个样本的难度评估
逐点 V 信息。所提出的实验基于完整的维基百科
快照以提高再现性。为了便于实施和用户
交互，我们开发了 FactSearch 应用程序，其特点是提出的
管道及其性能的初步反馈。
]]></description>
      <guid>http://arxiv.org/abs/2312.10171</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>LLM 知识库级别提示的回顾。 （arXiv：2312.10101v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2312.10101</link>
      <description><![CDATA[随着编码挑战变得更加复杂，大型领域的最新进展
语言模型（LLM）取得了显着的成功，例如取得了
HumanEval 基准测试的解决率为 94.6%。同时，还有一个
增加对存储库级内联代码完成工具的商业推动，
例如 GitHub Copilot 和 Tab Nine，旨在提高开发人员的工作效率。
本文深入研究了从个体编码问题到
存储库规模的解决方案，对当前的情况进行了彻底的审查
关于有效的 LLM 提示在存储库中生成代码的文献
等级。我们研究了适用于黑盒法学硕士的方法，以便它们
将有用并适用于商业用例及其适用性
在存储库规模解释代码。我们并置存储库级别
使用 RepoCoder 的提示生成技术，一种迭代检索和
生成方法，以强调每种方法固有的权衡，并
为其在尖端编码中的应用建立最佳实践
基准。提示的迭代细化与结果之间的相互作用
高级检索系统的开发构成了我们讨论的核心，
提供显着提高代码生成方面的 LLM 性能的途径
任务。这项研究的见解不仅指导这些方法的应用
还为未来的研究制定了路线，将这些技术整合到
更广泛的软件工程环境。
]]></description>
      <guid>http://arxiv.org/abs/2312.10101</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>ICD-LM：通过语言建模配置视觉语言上下文演示。 （arXiv：2312.10104v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.10104</link>
      <description><![CDATA[本文研究了如何配置强大的上下文演示（ICD）
用于解决视觉语言问题的大型视觉语言模型 (LVLM) 的序列
通过情境学习（ICL）完成任务。观察配置后
ICD 序列是造句的镜像过程，即，就像
句子可以通过语言模型逐字组成，ICD 序列可以
也可以一一配置。因此，我们引入了 ICD 语言模型
(ICD-LM) 专门设计用于生成有效的 ICD 序列。这
涉及为各种查询创建手工制作的 ICD 序列数据集
样本并用它来训练 ICD-LM。我们的方法不同于
NLP 中单独选择和订购 ICD 的传统方法能够
同时学习如何选择和订购 ICD，增强治疗效果
序列。此外，在数据构建过程中，我们使用了用于ICL的LVLM
实施来验证每个 ICD 序列的强度，从而产生
模型特定的数据集和由该数据集训练的 ICD-LM 也是
特定于型号。我们通过视觉实验验证我们的方法
问答和图像标题，确认使用
ICD 配置的语言模型。我们全面的消融研究
进一步探讨各种数据集构建和ICD-LM的影响
结果的发展设置。代码给出在
https://github.com/ForJadeForest/ICD-LM。
]]></description>
      <guid>http://arxiv.org/abs/2312.10104</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>文本简化系统保留意义吗？通过阅读理解进行人类评估。 （arXiv：2312.10126v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.10126</link>
      <description><![CDATA[自动文本简化（TS）旨在自动化重写过程
文本，使人们更容易阅读。 TS 有用的先决条件
是它应该传达与意思相一致的信息
原文。然而，当前的 TS 评估协议评估系统输出
为了简单和保留意义而不考虑文档上下文
输出句子出现的位置以及人们如何理解它们。在这个
工作中，我们引入了一个人类评估框架来评估是否简化
使用阅读理解问题来保留文本的含义。有了这个
框架中，我们对文本进行了彻底的人类评估
九个自动系统。利用预训练知识的监督系统
在阅读理解（RC）任务中取得最高分
自动控制 TS 系统。然而，即使是表现最好的监督者
系统难以回答至少 14% 的问题，将其标记为
基于简化的内容“无法回答”。我们进一步研究如何
现有的TS评估指标和自动问答系统
近似我们获得的人类判断。
]]></description>
      <guid>http://arxiv.org/abs/2312.10126</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>数据视角下的早期 ChatGPT 用户画像。 （arXiv：2312.10078v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2312.10078</link>
      <description><![CDATA[自推出以来，ChatGPT 作为一款多功能工具已取得了显着的成功
对话式人工智能平台，吸引了全球数百万用户并获得
学术界、工业界和一般社区的广泛认可。
本文旨在描绘早期 GPT 用户的肖像并了解他们如何
进化了。具体问题包括他们感兴趣的主题和他们的
潜在的职业；以及随着时间的推移这种情况如何变化。我们进行了详细的
通过多轮对话分析现实世界的 ChatGPT 数据集
用户和 ChatGPT。通过多管齐下的方法，我们量化对话
通过检查匝数来动态分析，然后衡量情绪以了解
用户情绪变化，最后采用潜在狄利克雷分配（LDA）
辨别对话中的总体主题。通过理解转变
在用户人口统计和兴趣方面，我们的目标是揭示不断变化的性质
人机交互并预测用户参与的未来趋势
语言模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.10078</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>三思而后行：语言模型中检索任务的通用紧急分解。 （arXiv：2312.10091v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.10091</link>
      <description><![CDATA[在解决具有挑战性的问题时，语言模型 (LM) 能够识别
来自冗长而复杂的上下文的相关信息。研究 LM 如何解决
在不同情况下的检索任务中，我们引入了 ORION，一个集合
结构化检索任务跨越六个领域，从文本理解到
编码。 ORION 中的每个任务都可以通过请求抽象地表示（例如
问题）从上下文中检索属性（例如角色名称）
（例如一个故事）。我们对 18 种开源语言模型进行因果分析
大小范围从 1.25 亿到 700 亿个参数。我们发现 LM
内部以模块化方式分解检索任务：中间层
最后一个令牌位置处理请求，而后面的层检索正确的
来自上下文的实体。在因果地执行这种分解之后，模型
仍然能够解决原来的任务，保留原来的70%
在 106 个研究的模型-任务对中，有 98 个的正确标记概率。我们连接
我们通过执行以下操作来进行宏观分解和微观描述
Pythia-2.8b 上问答任务的细粒度案例研究。建筑
根据我们的高层次理解，我们展示了概念验证应用程序
对LM进行可扩展的内部监督，以减少即时注入，同时
仅需要对单个输入进行人工监督。我们的解决方案改进了
准确率大幅提高（Pythia-12b 上从 15.5% 提高到 97.5%）。这部作品呈现
跨不同任务的通用紧急模块化处理的证据
领域和模型，是应用可解释性的开创性努力
可扩展的LM内部监督。
]]></description>
      <guid>http://arxiv.org/abs/2312.10091</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>基于算术的数字词分解——算术条件给出拆包策略。 （arXiv：2312.10097v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.10097</link>
      <description><![CDATA[在本文中，我们提出了一种新颖的数字分解器，旨在
恢复赫福德的包装策略。包装策略是一个关于如何
数字词是由较小的数字词通过递归形成的。这
分解器不仅仅检查十进制数字，它也适用于数字
形成在基座20或任何其他基座或什至不同基座的组合上。
我们使用的所有假设均经赫福德包装策略证明是合理的。这
分解器读取数字。当它找到子数字时，它会检查
算术条件来决定是否解包子数字。这
目标是解开那些可以明智地用类似的数字代替的数字
数字。例如，“270206”应该是
解压“二十七”和“两百零六”，因为它们可能分别是
明智地用 1 到 999 之间的任何数字替换。我们最常用的条件是：如果
S是数字N的可替换子数，则2*value(S)＜1。值（N）。我们
已经在 254 种不同的自然数系上测试了分解器
语言。我们还开发了基于强化学习的算法
分解者。两种算法的代码和结果均在 GitHub 上开源。
]]></description>
      <guid>http://arxiv.org/abs/2312.10097</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>基于知识图和循环注意力网络的方面级情感分析。 （arXiv：2312.10048v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.10048</link>
      <description><![CDATA[在本文中，我们提出了一种通过以下方式增强情感分析的新方法：
解决特定上下文词义的挑战。它结合了
双向长短期记忆网络（Bi-LSTM）的优点
知识图谱的同义词数据。这种协同作用利用了动态注意力
开发知识驱动状态向量的机制。用于分类
与特定方面相关的情绪，该方法构建了一个记忆库
整合位置数据。然后使用多层分析该数据
门控循环单元 (GRU)，用于查明与以下内容相关的情绪特征
具体方面术语。对三个广泛使用的数据集的测试表明
该方法在情感分类方面具有优越的性能。
]]></description>
      <guid>http://arxiv.org/abs/2312.10048</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>评估法学硕士的道德价值多元化。 （arXiv：2312.10075v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.10075</link>
      <description><![CDATA[目前人工智能领域缺乏定量评估和评估的方法
潜在地改变大语言输出中固有的道德价值观
模型（法学硕士）。然而，几十年来社会科学研究已经发展并
改进了广泛接受的道德价值观调查，例如世界价值观调查
（WVS），从不同地区的直接问题中得出价值判断。
我们将这些问题转化为价值陈述，并使用 NLP 进行计算
受欢迎的法学硕士与不同人群的道德价值观的契合程度如何
和文化。虽然 WVS 被认为是对价值观的明确评估，但我们
缺乏评估媒体中隐含的道德和文化价值观的方法，例如
在社交媒体、政治言论、叙事中遇到，并由
法学硕士等人工智能系统越来越多地出现在我们的日常生活中。和我们一样
我们可能会问，消费在线内容并利用法学硕士的成果，哪个道德
价值观正在被隐含地提升或削弱，或者——就法学硕士而言——
如果他们打算代表一种文化身份，他们会这样做吗
始终如一？在本文中，我们利用识别价值共振（RVR）NLP
模型来识别与给定段落产生共鸣和冲突的 WVS 值
输出文本。我们将 RVR 应用于法学硕士生成的文本来表征
隐含的道德价值观，使我们能够量化道德/文化距离
法学硕士和使用 WVS 调查的各种人口统计数据之间的关系。在
与其他工作一致，我们发现法学硕士表现出一些以西方为中心的价值
偏见；他们高估了非西方国家人民的保守程度，
它们在代表非西方国家的性别方面不太准确，并且
将老年人描绘为具有更传统的价值观。我们的成果
强调价值错位和年龄组以及对社会科学的需求
解决法学硕士价值多元化的明智技术解决方案。
]]></description>
      <guid>http://arxiv.org/abs/2312.10075</guid>
      <pubDate>Tue, 19 Dec 2023 06:17:51 GMT</pubDate>
    </item>
    </channel>
</rss>