<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 12 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>KG-Rank：利用知识图和排序技术增强医学 QA 的大型语言模型</title>
      <link>https://arxiv.org/abs/2403.05881</link>
      <description><![CDATA[arXiv:2403.05881v1 公告类型：新
摘要：大型语言模型（LLM）在生成能力方面显着推进了医疗保健创新。然而，由于可能偏离医学事实和固有偏见，它们在实际临床环境中的应用具有挑战性。在这项工作中，我们开发了一个增强的 LLM 框架 KG-Rank，它利用具有排名和重新排名技术的医学知识图 (KG)，旨在提高医学领域的自由文本问答 (QA)。具体来说，收到问题后，我们首先从医学知识库中检索三元组以收集事实信息。随后，我们创新地应用排序方法来细化这些三元组的排序，旨在产生更精确的答案。据我们所知，KG-Rank 是排序模型与 KG 相结合在医学 QA 中的第一个应用，专门用于生成长答案。对四个选定的医学 QA 数据集的评估表明，KG-Rank 在 ROUGE-L 分数上实现了超过 18% 的改进。此外，我们将 KG-Rank 扩展到开放域，实现了 ROUGE-L 14% 的改进，显示了 KG-Rank 的有效性和潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.05881</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>MP2D：利用知识图的自动主题转移对话生成框架</title>
      <link>https://arxiv.org/abs/2403.05814</link>
      <description><![CDATA[arXiv:2403.05814v1 公告类型：新
摘要：尽管主题对话系统取得了进步，但有效管理对话中的主题转移仍然是一个持续的挑战，这在很大程度上归因于训练数据集的可用性有限。为了解决这个问题，我们提出了 Multi-Passage to Dialogue (MP2D)，这是一种数据生成框架，可以自动创建具有自然主题转换的对话问答数据集。通过利用知识图中实体之间的关系，MP2D 映射对话中的主题流，有效地反映了人类对话的动态。它检索与主题相对应的相关段落，并通过段落到对话的方法将其转换为对话。通过定量和定性实验，我们证明了 MP2D 在生成具有自然主题转移的对话方面的功效。此外，本研究引入了主题转移对话的新颖基准 TS-WikiDialog。利用该数据集，我们证明即使是大型语言模型 (LLM) 也很难有效地处理对话中的主题转换，并且我们展示了在 MP2D 生成的数据集上训练的模型在不同主题转换对话任务中的性能改进。]]></description>
      <guid>https://arxiv.org/abs/2403.05814</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>反转该数字！解码算术学习中的顺序问题</title>
      <link>https://arxiv.org/abs/2403.05845</link>
      <description><![CDATA[arXiv:2403.05845v1 公告类型：新
摘要：预训练的最新进展表明，现代大型语言模型（LLM）具有有效学习算术运算的能力。然而，尽管承认数字顺序在算术计算中的重要性，但当前的方法主要依赖于顺序的、逐步的方法来教授法学硕士算术，从而得出这样的结论：获得更好的性能需要细粒度的逐步进行。与这种传统路径不同，我们的工作引入了一种新颖的策略，该策略不仅通过优先考虑最低有效数字的输出来重新评估数字顺序，而且还采用了逐步方法来大幅降低复杂性。我们已经在一系列综合实验中开发并应用了这种方法。与之前最先进的 (SOTA) 方法相比，我们的研究结果表明，准确性整体提高，同时只需要训练期间通常使用的令牌的三分之一。为了促进复制和进一步研究，我们已在 \url{https://anonymous.4open.science/r/RAIT-9FB7/} 上公开提供我们的代码和数据集。]]></description>
      <guid>https://arxiv.org/abs/2403.05845</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>ClinicalMamba：纵向临床记录的生成临床语言模型</title>
      <link>https://arxiv.org/abs/2403.05795</link>
      <description><![CDATA[arXiv:2403.05795v1 公告类型：新
摘要：自然语言处理（NLP）系统在医疗保健领域的进步取决于语言模型解释临床记录中包含的复杂信息的能力。此过程通常需要整合患者病史中不同时间点的信息。然而，大多数早期的临床语言模型都是经过预训练的，上下文长度仅限于大约一份临床文档。在这项研究中，我们引入了 ClinicalMamba，这是 Mamba 语言模型的专门版本，它在大量纵向临床笔记的语料库上进行了预训练，以满足医学领域独特的语言特征和信息处理需求。与 Mamba 和 Clinical Llama 相比，ClinicalMamba 拥有 1.3 亿和 28 亿个参数，在跨扩展文本长度的临床语言建模方面表现出卓越的性能。通过少量学习，ClinicalMamba 在速度和准确性方面达到了显着的基准，在纵向临床记录信息提取任务中优于现有的临床语言模型和 GPT-4 等通用领域大型模型。]]></description>
      <guid>https://arxiv.org/abs/2403.05795</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>UniSparse：通用稀疏格式定制的中间语言</title>
      <link>https://arxiv.org/abs/2403.05802</link>
      <description><![CDATA[arXiv:2403.05802v1 公告类型：新
摘要：硬件专业化的持续趋势导致在处理稀疏工作负载（通常受内存限制）时越来越多地使用自定义数据格式。这些格式通过利用稀疏模式或目标感知数据结构和布局来增强内存访问延迟和带宽利用率，从而促进优化的软件/硬件实现。然而，现有的稀疏张量编程模型和编译器很少或根本不支持高效地定制稀疏格式。此外，由于这些框架使用有限的每维度属性集来表示格式，因此它们缺乏适应自定义稀疏数据结构和布局的大量新变体的灵活性。为了克服这个缺陷，我们提出了 UniSparse，一种中间语言，它为表示和定制稀疏格式提供了统一的抽象。与现有的基于属性的框架不同，UniSparse 将稀疏张量的逻辑表示（即数据结构）与其低级内存布局解耦，从而实现两者的定制。因此，可以用一小组定义良好的查询、突变和布局基元来简洁地表达一组丰富的格式自定义。我们还开发了一个利用 MLIR 基础设施的编译器，它支持格式的自适应定制，以及格式转换和异构架构计算操作的自动代码生成。我们通过在多个不同硬件目标（包括 Intel CPU、NVIDIA GPU、AMD Xilinx FPGA 和模拟内存处理 (PIM)）上以专用格式运行常用稀疏线性代数运算的实验来证明我们方法的有效性。 ） 设备。]]></description>
      <guid>https://arxiv.org/abs/2403.05802</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>语言模型的算法进展</title>
      <link>https://arxiv.org/abs/2403.05812</link>
      <description><![CDATA[arXiv:2403.05812v1 公告类型：新
摘要：我们研究了自深度学习出现以来预训练语言模型算法的改进速度。使用 Wikitext 和 Penn Treebank 2012 年至 2023 年期间超过 200 个语言模型评估的数据集，我们发现达到设定性能阈值所需的计算量大约每 8 个月减少一半，95% 的置信区间约为 5 至 14 个月，比摩尔定律的硬件增益快得多。我们估计增强的缩放定律，这使我们能够量化算法进展并确定缩放模型与训练算法创新的相对贡献。尽管算法进步很快，变压器等新架构不断发展，但我们的分析表明，计算量的增加对这段时间内整体性能的提高做出了更大的贡献。尽管受到嘈杂的基准数据的限制，我们的分析量化了语言建模的快速进展，揭示了计算和算法的相对贡献。]]></description>
      <guid>https://arxiv.org/abs/2403.05812</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>细粒度损失截断的好处：摘要中事实性的案例研究</title>
      <link>https://arxiv.org/abs/2403.05788</link>
      <description><![CDATA[arXiv:2403.05788v1 公告类型：新
摘要：文本摘要和简化是人工智能最广泛使用的应用之一。然而，为此类任务开发的模型通常容易产生幻觉，这可能是由于对未对齐数据的训练造成的。解决此问题的一种有效方法是损失截断 (LT)（Kang 和 Hashimoto，2020），这是一种修改标准对数损失以在训练期间自适应删除噪声示例的方法。然而，我们发现仅 LT 在各种数据集上就产生了大量的幻觉实体。我们研究事实和非事实示例之间潜在损失的行为，以理解和完善 LT 的性能。我们证明，当噪声目标具有较高 NLL 损失的基本假设不满足时，LT 的性能受到限制，并发现实体之间的字级 NLL 为区分事实提供了更好的信号。然后，我们利用这一点提出细粒度的 NLL 损失和细粒度的数据清理策略，并观察某些数据集在减少幻觉方面的改进。我们的工作可在 https://https://github.com/yale-nlp/fine-grained-lt 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.05788</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>ItD：大型语言模型可以通过演绎自学归纳</title>
      <link>https://arxiv.org/abs/2403.05789</link>
      <description><![CDATA[arXiv:2403.05789v1 公告类型：新
摘要：尽管大型语言模型（LLM）在广泛的自然语言处理任务中表现出了令人印象深刻的性能，但研究人员发现它们的归纳能力仍然有限。最近的工作主要采用“后处理”范式来提高法学硕士在归纳方面的性能（例如，假设搜索和细化方法），但它们的性能仍然受到法学硕士固有的归纳能力的限制。在本文中，我们提出了一个新颖的框架，即通过演绎归纳（ItD），使法学硕士能够通过演绎自学归纳。 ItD 框架由两个主要组件组成：用于生成归纳数据的演绎数据生成模块和用于优化 LLM 微调和解码的朴素贝叶斯归纳模块。我们的实证结果展示了 ItD 在​​两个归纳基准上的有效性，与之前最先进的技术相比，分别实现了 36% 和 10% 的相对性能提升。我们的消融研究验证了 ItD 两个关键模块的有效性。我们还验证了 ItD 在​​不同法学硕士和扣除者中的有效性。本文的数据和代码可以在https://anonymous.4open.science/r/ItD-E844找到。]]></description>
      <guid>https://arxiv.org/abs/2403.05789</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>解码 AI 笔：检测 AI 生成文本的技术和挑战</title>
      <link>https://arxiv.org/abs/2403.05750</link>
      <description><![CDATA[arXiv:2403.05750v1 公告类型：新
摘要：大型语言模型（LLM）展示了生成类人文本的令人印象深刻的能力，彻底改变了自然语言生成（NLG）领域。然而，它们的广泛使用带来了挑战，需要深思熟虑的检查、道德审查和负责任的做法。在这项研究中，我们深入研究这些挑战，探索缓解这些挑战的现有策略，特别强调将人工智能生成的文本确定为最终解决方案。此外，我们从理论角度评估了检测的可行性，并提出了新的研究方向来解决该领域当前的局限性。]]></description>
      <guid>https://arxiv.org/abs/2403.05750</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>FLAP：法学硕士中具有约束解码的流程粘附规划</title>
      <link>https://arxiv.org/abs/2403.05766</link>
      <description><![CDATA[arXiv:2403.05766v1 公告类型：新
摘要：规划是面向任务的对话（TOD）中代理的一项关键任务。人工代理通常通过遵循预定义的工作流程、将工作流程步骤分解为可操作的项目以及通过按顺序执行 API 来执行操作来解决用户问题；所有这些都需要推理和计划。随着 LLM 的最新进展，越来越多的人尝试使用 LLM 进行任务规划和 API 使用。然而，LLM 无法保证计划对预定义工作流程和 API 依赖关系的忠实性，因为他们偏向于预训练数据。此外，在现实生活中，工作流程是自定义的并且容易发生变化，因此，需要快速使代理适应变化。在本文中，我们研究了 TOD 中的忠实规划，通过遵循预定义的流程并保留 API 依赖关系来解决用户意图。我们提出了一种基于前瞻启发式的约束解码算法，以实现忠实的规划。我们的算法减轻了使用特定领域数据微调 LLM 的需要，优于其他基于解码和提示的基线，并且将我们的算法应用于较小的 LLM (7B)，我们实现了与较大的 LLM (30B-40B) 相当的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.05766</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>DADIT：意大利 Twitter 用户人口统计分类数据集及预测方法比较</title>
      <link>https://arxiv.org/abs/2403.05700</link>
      <description><![CDATA[arXiv:2403.05700v1 公告类型：新
摘要：社会科学家越来越多地使用人口统计分层的社交媒体数据来研究公众的态度、信仰和行为。为了促进此类分析，我们构建、验证并公开发布了具有代表性的 DADIT 数据集，其中包含 2 万名意大利 Twitter 用户的 3000 万条推文，以及他们的个人简介和个人资料图片。我们通过性别、年龄和位置的高质量标签来丰富用户数据。 DADIT 使我们能够训练和比较各种最先进模型的性能，以预测社交媒体用户的性别和年龄。特别是，我们调查推文是否包含对任务有价值的信息，因为像 M3 这样的流行分类器不会利用它们。我们最好的基于 XLM 的分类器比常用的竞争对手 M3 提高了 53% F1。特别是对于年龄预测，分类器受益于将推文作为特征。我们还在德国测试集上证实了这些发现。]]></description>
      <guid>https://arxiv.org/abs/2403.05700</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>用于生成简短医院课程摘要的领域适应大语言模型的基准</title>
      <link>https://arxiv.org/abs/2403.05720</link>
      <description><![CDATA[arXiv:2403.05720v1 公告类型：新
摘要：简短的医院课程（BHC）摘要是通过总结临床记录生成的常见临床文档。虽然大型语言模型 (LLM) 在自动化现实世界任务方面展现了卓越的能力，但它们在 BHC 合成等医疗保健应用中的能力尚未得到展示。为了使法学硕士能够适应 BHC 合成，我们引入了一种新颖的基准，其中包含从 MIMIC-IV 笔记中提取的预处理数据集、封装的临床笔记和简短的医院课程 (BHC) 对。我们评估了两个通用法学硕士和三个医疗保健适应法学硕士的表现，以根据临床记录改进 BHC 合成。使用临床记录作为生成 BHC 的输入，我们将基于提示（使用上下文学习）和基于微调的适应策略应用于三个开源 LLM（Clinical-T5-Large、Llama2-13B、FLAN-UL2）和两个专有的法学硕士（GPT-3.5、GPT-4）。我们使用传统的自然语言相似性指标定量评估这些法学硕士在不同上下文长度输入上的表现。我们进一步进行了一项定性研究，其中五位不同的临床医生对 30 个样本的临床医生编写的 BHC 和两个法学硕士生成的 BHC 进行盲目比较，涵盖全面性、简洁性、事实正确性和流畅性等指标。总的来说，我们提出了一个新的基准和预处理数据集，用于根据临床记录在 BHC 合成中使用法学硕士。我们使用定量指标和定性临床读者研究来观察上下文中专有和微调的开源法学硕士的高质量总结性能。我们建议我们的工作作为基准，以激励未来的工作适应和评估法学硕士在 BHC 合成中的表现。]]></description>
      <guid>https://arxiv.org/abs/2403.05720</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>PipeRAG：通过算法-系统协同设计快速检索增强生成</title>
      <link>https://arxiv.org/abs/2403.05676</link>
      <description><![CDATA[arXiv:2403.05676v1 公告类型：新
摘要：检索增强生成（RAG）可以通过合并外部标记数据库来提高大型语言模型（LLM）的生成质量。然而，从大型数据库的检索可能占整个生成时间的很大一部分，特别是当定期执行检索以使检索到的内容与生成的最新状态对齐时。在本文中，我们介绍了 PipeRAG，这是一种新颖的算法系统协同设计方法，可减少生成延迟并提高生成质量。 PipeRAG 集成了 (1) 管道并行性，以实现并发检索和生成过程；(2) 灵活的检索间隔，以最大限度地提高管道并行性的效率；以及 (3) 性能模型，可根据生成状态和底层自动平衡检索质量和延迟硬件。我们的评估表明，通过结合上述三种方法，PipeRAG 在端到端生成延迟方面实现了高达 2.6$\times$ 的加速，同时提高了生成质量。这些有希望的结果展示了与底层系统共同设计算法的有效性，为未来 RAG 系统中采用 PipeRAG 铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2403.05676</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>SeeGULL 多语言：地理文化刻板印象数据集</title>
      <link>https://arxiv.org/abs/2403.05696</link>
      <description><![CDATA[arXiv:2403.05696v1 公告类型：新
摘要：虽然生成式多语言模型正在迅速部署，但其安全性和公平性评估很大程度上仅限于以英语收集的资源。对于针对固有社会文化现象（例如陈规定型观念）的评估来说，这一点尤其成问题，因为在这种情况下，建立反映各个语言社区中普遍存在的陈规定型观念的多语言资源非常重要。然而，以不同语言和地区大规模收集这些资源构成了重大挑战，因为它需要广泛的社会文化知识，而且成本也可能高得令人望而却步。为了克服这一关键差距，我们采用了最近推出的方法，将法学硕士世代的规模与文化背景的可靠性验证结合起来，并构建了 SeeGULL Multilingual，这是一个全球规模的社会刻板印象多语言数据集，包含超过 25K 刻板印象，涵盖 20 种语言，跨 23 个区域的人工注释，并展示了其在识别模型评估差距方面的实用性。内容警告：本文中分享的刻板印象可能会令人反感。]]></description>
      <guid>https://arxiv.org/abs/2403.05696</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 ChatGPT 生成硬否定超出范围的数据以进行意图分类</title>
      <link>https://arxiv.org/abs/2403.05640</link>
      <description><![CDATA[arXiv:2403.05640v1 公告类型：新
摘要：意图分类器必须能够区分用户的话语何时不属于任何支持的意图，以避免产生不正确和不相关的系统响应。尽管已经研究了意图分类器的范围外（OOS）检测，但之前的工作尚未研究针对硬负范围外话语（即与范围内数据共享共同特征的输入）分类器性能的变化，但实际上超出了范围）。我们提出了一种使用 ChatGPT 生成硬负 OOS 数据的自动化技术。我们使用我们的技术构建了五个新的硬负 OOS 数据集，并根据三个基准意图分类器对每个数据集进行了评估。我们表明，与一般的 OOS 话语相比，分类器更难以正确识别硬否定 OOS 话语。最后，我们表明，在检测硬负 OOS 数据和一般 OOS 数据时，结合硬负 OOS 数据进行训练可以提高模型的鲁棒性。我们的技术、数据集和评估解决了该领域的一个重要空白，提供了一种简单且廉价的方法来收集硬阴性 OOS 数据并提高意图分类器的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2403.05640</guid>
      <pubDate>Tue, 12 Mar 2024 06:17:19 GMT</pubDate>
    </item>
    </channel>
</rss>