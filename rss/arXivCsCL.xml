<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Mon, 04 Dec 2023 03:14:59 GMT</lastBuildDate>
    <item>
      <title>PsyAttention：用于人格检测的心理注意模型。 （arXiv：2312.00293v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00293</link>
      <description><![CDATA[人格检测工作往往将心理因素纳入其中
来自不同人格模型的特征，例如 BigFive 和 MBTI。有
超过900个心理特征，每一个都对性格有帮助
检测。然而，当组合使用时，不同的应用
这些特征之间的计算标准可能会导致相互干扰
使用不同系统计算的特征，从而引入噪声和
降低性能。本文采用了不同的心理模型
提出了用于人格检测的PsyAttention，可以有效地编码
心理特征，使其数量减少85%。在实验中关于
BigFive 和 MBTI 模型，PysAttention 的平均准确率达到 65.66%
86.30% 分别优于最先进的方法，表明
它可以有效地编码心理特征。
]]></description>
      <guid>http://arxiv.org/abs/2312.00293</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>Agent-OM：利用大型语言模型进行本体匹配。 （arXiv：2312.00326v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.00326</link>
      <description><![CDATA[本体匹配 (OM) 可实现不同类型之间的语义互操作性
本体并通过调整相关的来解决其概念异质性
实体。 OM系统目前有两种流行的设计范式：
传统的基于知识的专家系统和较新的基于机器学习的专家系统
预测系统。虽然大型语言模型 (LLM) 和基于 LLM 的代理
已成为数据工程领域的革命性成果并被创造性地应用
在各个领域，它们的 OM 潜力仍未得到充分开发。这项研究
为 OM 系统引入了一种新颖的、基于代理的、基于 LLM 的设计范例。和
深思熟虑利用法学硕士的几个具体挑战
OM，我们提出了一个通用框架，即Agent-OM，由两个Siamese组成
用于检索和匹配的代理，具有一组简单的基于提示的 OM 工具。
我们的框架是在概念验证系统中实现的。三人评价
本体一致性评估计划 (OAEI) 跟踪最先进的 OM
系统表明我们的系统可以达到非常接近最佳的结果
简单 OM 任务的长期性能并显着提高
复杂和少量 OM 任务的性能。
]]></description>
      <guid>http://arxiv.org/abs/2312.00326</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>通过闭环解开进行文本属性控制。 （arXiv：2312.00277v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00277</link>
      <description><![CDATA[更改文本的属性而不更改内容通常需要
首先将文本分解为不相关的属性和内容
交涉。之后，在推理阶段，一个的表示
属性被调整为不同的值，期望相应的
文本的属性也可以相应地改变。通常的方式是
解缠结是对潜在空间添加一些约束
编码器-解码器架构，包括基于对抗性的约束和
基于互信息的约束。然而，之前的半监督
属性改变的过程通常不足以保证成功
属性改变和内容保存。在本文中，我们提出了一部小说
在增强内容的同时实现对属性的稳健控制的方法
保存。在这种方法中，我们使用半监督对比学习
鼓励在潜在空间中解开属性的方法。
与之前的作品不同，我们重新解开重构的句子
并将重新解纠缠的潜在空间与原始潜在空间进行比较，
这形成了闭环解缠结过程。这也有助于内容
保存。此外，对比学习法还可以
取代最大限度地减少相互信息和对抗性训练的作用
解缠结过程，减少了计算成本。我们
对三个文本数据集进行了实验，包括 Yelp 服务评论
数据集、亚马逊产品评论数据集和 GoEmotions 数据集。这
实验结果表明了我们模型的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2312.00277</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>脓毒症：我能识破你的谎言——欺骗检测的新范式。 （arXiv：2312.00292v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00292</link>
      <description><![CDATA[欺骗是故意扭曲信息的行为。它是一个
细致入微的社会实践与人类社会进化深深交织在一起，
具有多方面的特点。本研究探讨的问题是
通过心理学的视角进行欺骗，采用的框架
将欺骗分为三种形式：不作为的谎言、行为的谎言、
和影响力的谎言。这项研究的主要重点是
仅调查遗漏的谎言。我们提出了一种新颖的欺骗框架
利用 NLP 技术进行检测。我们整理了一个包含 876,784 个带注释的数据集
通过合并流行的大规模假新闻数据集并抓取样本
来自印度知名印度时报《印度时报》推特账号的新闻头条
新闻媒体之家。每个样本都被标记了四层，即： (i)
遗漏的类型（推测、偏见、歪曲、听起来真实以及
意见），（ii）谎言的颜色（黑色、白色等），以及（iii）意图
此类谎言（影响等） (iv) 谎言主题（政治、教育、
宗教等）。我们提出了一种新颖的多任务学习管道，它利用
微调语言模型的无数据合并以解决欺骗问题
前面提到的检测任务。我们提出的模型取得了 F1 分数
0.87，展示了包括类型在内的所有层的强大性能，
欺骗性内容的颜色、意图和主题方面。最后，我们的研究
探讨遗漏谎言与宣传技巧之间的关系。
为了实现这一目标，我们进行了深入分析，揭示了令人信服的
发现。例如，我们的分析揭示了之间的显着相关性
丰富的语言和观点，揭示了它们之间的相互联系。到
鼓励该领域的进一步研究，我们将制作模型并
数据集可通过 MIT 许可证获得，使其有利于开源
研究。
]]></description>
      <guid>http://arxiv.org/abs/2312.00292</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>相关性引导的神经机器翻译。 （arXiv：2312.00214v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00214</link>
      <description><![CDATA[随着 Transformer 架构的出现，神经机器翻译
（NMT）结果最近显示出很大的进步。然而，结果是
资源匮乏的条件在双语和多语方面仍然落后
设置，由于可用的单语和/或并行的数量有限
数据;因此，需要一种有效、并且能够解决数据稀缺问题的方法。
可以解释的方式，是杰出的。我们提出基于可解释性的培训
NMT 方法，应用于无监督和监督模型训练，
翻译不同资源的三种语言：法语、古吉拉特语、哈萨克语、
与英语之间。我们的结果表明我们的方法很有前途，特别是
在资源匮乏的条件下训练时，表现优于简单训练
基线；尽管改进幅度很小，但它为进一步的改进奠定了基础
探索该方法和参数，并将其扩展到其他领域
语言。
]]></description>
      <guid>http://arxiv.org/abs/2312.00214</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>具有双对比域适应的多模态视频主题分割。 （arXiv：2312.00220v1 [cs.MM]）</title>
      <link>http://arxiv.org/abs/2312.00220</link>
      <description><![CDATA[视频主题分割揭示了粗粒度语义结构
底层视频，对于其他视频理解任务至关重要。给定
最近多式联运激增，仅依赖单一方式
可以说是不够的。另一方面，类似任务的先前解决方案
比如视频场景/镜头分割迎合视觉清晰的短视频
会发生变化，但对于有细微变化的长视频（例如直播）来说会犹豫不决。在
在本文中，我们介绍了一种多模式视频主题分割器，它利用了
视频转录和帧，由跨模式注意机制支持。
此外，我们提出了一个遵循以下原则的双重对比学习框架：
无监督领域适应范式，增强了我们模型的适应性
更长、语义更复杂的视频。短视频和长视频的实验
语料库表明我们提出的解决方案显着超越
基线方法在准确性和可转移性方面，在内部
以及跨域设置。
]]></description>
      <guid>http://arxiv.org/abs/2312.00220</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>标记我的话：分析和评估语言模型水印。 （arXiv：2312.00273v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00273</link>
      <description><![CDATA[大型语言模型的能力近年来显着增长
多年来，人们也担心它们的滥用。在此背景下，能力
区分机器生成的文本和人类创作的内容变得
重要的。先前的工作提出了多种水印文本方案，其中
将受益于系统的评估框架。本作品以文字为主
水印技术 - 与图像水印相反 - 并提出了一种
为他们在不同任务下的综合基准以及实际
攻击。我们关注三个主要指标：质量、规模（例如数量）
检测水印所需的令牌）和防篡改。当前的
水印技术足以部署：Kirchenbauer 等人。能
水印 Llama2-7B-聊天，在 100 以内没有明显的质量损失
代币，并且对简单攻击具有良好的抗篡改能力，无论
温度。我们认为水印的不可区分性太强了
要求：稍微修改 logit 分布的方案优于其方案
无法区分的对应物，发电质量没有明显损失。
我们公开发布我们的基准。
]]></description>
      <guid>http://arxiv.org/abs/2312.00273</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>适用于资源匮乏设备的端到端非自回归图像到语音系统的压缩。 （arXiv：2312.00174v1 [eess.AS]）</title>
      <link>http://arxiv.org/abs/2312.00174</link>
      <description><![CDATA[有视力障碍的人很难访问支持触摸屏的设备
个人计算设备，例如移动电话和笔记本电脑。图像到语音
（ITS）系统可以帮助他们缓解这个问题，但是他们庞大的模型
尺寸使其极难部署在资源匮乏的嵌入式设备上。
在本文中，我们的目标是通过开发一种高效的方法来克服这一挑战
用于从微小片段生成音频的端到端神经架构
在资源匮乏的设备上显示内容。我们提出了一个愿景
基于 Transformer 的图像编码器并利用知识蒸馏
将模型参数从 610 万个压缩到 246 万个。人类和
自动评估结果表明，我们的方法导致的结果非常小
性能下降，并且可以将推理时间加快 22%。
]]></description>
      <guid>http://arxiv.org/abs/2312.00174</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>通过核化率失真最大化实现稳健的概念擦除。 （arXiv：2312.00194v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00194</link>
      <description><![CDATA[分布式表示提供了一个向量空间来捕获有意义的内容
数据实例之间的关系。这些的分布式性质
然而，表征将多个属性或概念纠缠在一起
数据实例（例如，文本的主题或情感、文本的特征
作者（年龄、性别等）等）。最近的工作提出了任务概念
擦除，其目标不是使概念可预测，而是
从分布式表示中删除一个属性，同时保留其他属性
尽可能多地从原始表示空间获取信息。在这个
论文中，我们提出了一个新的基于距离度量学习的目标，即
内核化率失真最大化器 (KRaM)，用于执行概念擦除。
KRaM 拟合表示变换以匹配指定距离
使用修改后的测量（由要擦除的标记概念定义）
率失真函数。具体来说，KRaM 的目标函数旨在使
具有相似概念标签的实例在学习表示中不相似
空间，同时保留其他信息。我们发现优化 KRaM
有效地消除了各种类型的概念：绝对的、连续的和
来自不同领域的数据表示的向量值变量。我们
还提供了 KRaM 物镜的几个特性的理论分析。
为了评估学习表示的质量，我们提出了一种对齐方式
分数来评估它们与原始表示空间的相似性。
此外，我们还进行实验来展示 KRaM 在各种方面的功效
设置，从删除词嵌入中的二元性别变量到
GPT-3 表示中的向量值变量。
]]></description>
      <guid>http://arxiv.org/abs/2312.00194</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>一个视频胜过一万字：使用不同的字幕进行训练和基准测试，以实现更好的长视频检索。 （arXiv：2312.00115v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00115</link>
      <description><![CDATA[现有的长视频检索系统是在
段落到视频检索机制，其中每个长视频都由一个
单个长段落。这忽略了可能有效的丰富性和多样性
视频的描述，可以详细描述每个时刻，
或单个短语摘要，或介于两者之间的任何内容。为了提供更多
通过对长视频检索系统的能力进行全面评估，我们
提出一个利用最先进的大型语言模型的管道
仔细为长视频生成一组多样化的合成字幕。我们
通过严格的人工检查来验证该管道的保真度。然后我们
在这些合成的基础上对一组代表性视频语言模型进行基准测试
使用一些长视频数据集的字幕，表明他们与
转换后的数据，尤其是最短的标题。我们还提出了一个
轻量级微调方法，我们使用对比损失来学习
基于不同层次信息的分层嵌入损失
各种字幕。我们的方法提高了下游的性能
段落到视频检索任务（ActivityNet 上 +1.1% R@1），以及
我们使用合成数据计算的各种长视频检索指标
（+3.6% R@1 对于 ActivityNet 的简短描述）。用于数据访问和其他
详情请参阅我们的项目网站：
https://mgwillia.github.io/10k-words。
]]></description>
      <guid>http://arxiv.org/abs/2312.00115</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>导航新闻叙述：媒体偏见分析数据集。 （arXiv：2312.00168v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00168</link>
      <description><![CDATA[各种媒体平台上带有偏见的新闻叙述激增
已成为一个突出的挑战，影响关键话题的公众舆论
例如政治、健康和气候变化。本文介绍了
“导航新闻叙事：媒体偏见分析数据集”，综合性的
数据集来满足对检测和分析媒体偏见工具的迫切需求。
该数据集包含广泛的偏见，使其成为独特且
媒体研究和人工智能领域的宝贵财富。这
数据集可在
https://figshare.com/articles/dataset/news-media-bias_data_json/24422122
]]></description>
      <guid>http://arxiv.org/abs/2312.00168</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>通过后门注入对大型语言模型进行隐秘且持久的不一致。 （arXiv：2312.00027v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00027</link>
      <description><![CDATA[大型语言模型 (LLM) 的最新发展已经体现出来
重大进步。为了促进防范恶意
开发，一系列研究集中于使法学硕士与人类保持一致
偏好并禁止他们生成不适当的内容。
不幸的是，这种对齐方式通常很脆弱：用最小的量进行微调
大量的有害数据很容易使目标法学硕士脱节。当被
有效，这种基于微调的不对齐方法也有自己的
局限性：（1）非隐身性，经过微调、安全审核或
红队可以轻松暴露未对齐模型的潜在弱点，
从而阻止它们的释放/使用。 (2)非持久性、不结盟的LLM
可以通过重新对准轻松修复，即再次微调
对齐的数据点。在这项工作中，我们表明可以进行
通过后门对大型语言模型进行隐秘且持久的不对齐
注射。我们还对两者之间的关系提供了新颖的理解
后门持久性和激活模式，并进一步提供
潜在触发器设计指南。通过大量的实验，我们
证明我们提出的秘密和持久的不结盟可以
保持坚强毅力的同时顺利通过安全评估
反对重新调整防守。
]]></description>
      <guid>http://arxiv.org/abs/2312.00027</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>Bergeron：通过基于良心的联盟框架对抗对抗性攻击。 （arXiv：2312.00029v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00029</link>
      <description><![CDATA[现代大型语言模型 (LLM) 仍然可以生成可能无法生成的响应
与人类的期望或价值观保持一致。虽然许多基于权重的对齐
已经提出了一些方法，其中许多方法仍然使模型容易受到影响
单独使用时进行攻击。为了帮助缓解这个问题，我们引入
Bergeron，一个旨在提高法学硕士的稳健性的框架
对抗性攻击。 Bergeron 采用两层架构。在这里，一个
二级法学硕士充当了保护初级法学硕士的模拟良心。
我们通过监控和纠正潜在有害文本来做到这一点
主要 LLM 的提示输入和生成的输出。经验
评估表明 Bergeron 可以提高
几个受欢迎的法学硕士，无需昂贵的微调。它有助于开源和
黑盒法学硕士通过补充和加强其现有的一致性
训练。
]]></description>
      <guid>http://arxiv.org/abs/2312.00029</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>HiFi 调谐器：针对扩散模型的高保真主体驱动微调。 （arXiv：2312.00079v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00079</link>
      <description><![CDATA[本文探讨了高保真个性化图像的进展
通过利用预先训练的文本到图像扩散生成
楷模。虽然以前的方法在生成
基于文本描述和一些输入图像的多功能场景、挑战
坚持保持生成图像中的主题保真度。在
在这项工作中，我们引入了一种名为 HiFi Tuner 的创新算法来增强
个性化图像生成过程中对象的外观保留。我们的
所提出的方法采用参数有效的微调框架，包括
去噪过程和关键反演过程。主要增强功能包括
利用掩模引导，一种新颖的参数正则化技术，
并结合逐步的主题表征来提升
样本保真度。此外，我们提出了参考引导生成
利用参考图像的关键反转来减轻
不需要的主题变化和伪影。我们进一步将我们的方法扩展到
新颖的图像编辑任务：通过文本替换图像中的主题
操纵。在 DreamBooth 数据集上进行的实验评估
使用稳定扩散模型展示了有希望的结果。仅微调
文本嵌入将 CLIP-T 分数提高了 3.6 分，并改进了 DINO
比 Textual Inversion 得分高 9.6 分。当微调所有参数时，
HiFi Tuner 将 CLIP-T 分数提高 1.2 分，将 DINO 分数提高 1.2 分
超越 DreamBooth，建立了新的技术水平。
]]></description>
      <guid>http://arxiv.org/abs/2312.00079</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>修辞平行检测简介：一项包含数据集、指标和基线的新任务。 （arXiv：2312.00100v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00100</link>
      <description><![CDATA[修辞，无论是口语还是书面语，不仅涉及内容，还涉及风格。
一种常见的文体工具是 $\textit{parallelism}$：并置
具有相同语言序列的短语（$\textit{例如}$，
语音、句法、语义）特征。尽管无处不在
并行性，自然语言处理领域很少研究
它，错过了更好地理解结构本质、含义的机会，
以及人类传达的意图。为了解决这个问题，我们引入了任务
$\textit{修辞平行检测}$.我们构建一个正式的定义
其中；我们为其提供了一个新的拉丁语数据集和一个改编的中文数据集；
我们建立了一系列指标来评估绩效；最后，我们
创建基线系统和新颖的序列标记方案来捕获它。在
根据我们最严格的指标，我们的得分为 $F_{1}$ 分别为 $0.40$ 和 $0.43$
分别是拉丁文和中文数据集。
]]></description>
      <guid>http://arxiv.org/abs/2312.00100</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:54 GMT</pubDate>
    </item>
    </channel>
</rss>