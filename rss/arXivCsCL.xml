<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Thu, 07 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>CLongEval：评估长上下文大语言模型的中国基准</title>
      <link>https://arxiv.org/abs/2403.03514</link>
      <description><![CDATA[arXiv:2403.03514v1 公告类型：新
摘要：开发具有强大的长上下文能力的大型语言模型（LLM）一直是最近的研究热点，导致精通中文的长上下文 LLM 的出现。然而，由于缺乏基准，这些模型的评估仍然不发达。为了弥补这一差距，我们推出了 CLongEval，这是一个用于评估长背景法学硕士的综合中国基准。 CLongEval具有三个关键特征：（1）足够的数据量，包括7个不同的任务和7,267个示例； (2)适用性广泛，可适应上下文窗口大小从1K到100K的模型； （3）质量高，除了自动构建的标签外，还有超过2000个手动注释的问答对。通过 CLongEval，我们对 6 名开源长语境法学硕士和 2 名兼具长语境能力和中文熟练程度的领先商业同行进行了全面评估。我们还根据实证结果提供深入分析，试图阐明在长上下文环境中带来挑战的关键能力。数据集、评估脚本和模型输出将被发布。]]></description>
      <guid>https://arxiv.org/abs/2403.03514</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>用于生成开放域对话的知识即插即用测试床</title>
      <link>https://arxiv.org/abs/2403.03496</link>
      <description><![CDATA[arXiv:2403.03496v1 公告类型：新
摘要：基于知识的开放领域对话生成旨在构建使用挖掘的支持知识与人类对话的聊天系统。许多类型和来源的知识先前已被证明可用作支持知识。即使在大型语言模型时代，基于从其他最新来源检索的知识的响应生成仍然是一种实际上很重要的方法。虽然之前使用单源知识的工作表明知识选择和响应生成的性能之间存在明显的正相关性，但目前还没有用于评估支持知识检索的多源数据集。此外，先前的工作假设测试时可用的知识源与训练期间相同。这种不切实际的假设不必要地阻碍了模型，因为在模型训练后可以使用新的知识源。在本文中，我们提出了一个名为多源维基百科向导（Ms.WoW）的高质量基准，用于评估多源对话知识选择和响应生成。与现有数据集不同，它包含干净的支持知识，基于话语级别并划分为多个知识源。我们进一步提出了一个新的挑战，即对话知识即插即用，其目的是测试已经训练好的对话模型，以零样本的方式使用来自以前未见过的来源的新支持知识。]]></description>
      <guid>https://arxiv.org/abs/2403.03496</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>在人类-人工智能协作混合文本中检测人工智能生成的文本</title>
      <link>https://arxiv.org/abs/2403.03506</link>
      <description><![CDATA[arXiv:2403.03506v1 公告类型：新
摘要：本研究探讨了人类与人工智能协作混合文本中句子级人工智能生成文本检测的挑战。现有的人工智能生成的混合文本文本检测研究通常依赖于合成数据集。这些通常涉及边界数量有限的混合文本。我们认为，检测混合文本中人工智能生成的内容的研究应该涵盖在现实环境中生成的不同类型的混合文本，以更好地为现实世界的应用程序提供信息。因此，我们的研究利用了 CoAuthor 数据集，其中包括通过人类作家和智能写作系统在多轮交互中协作生成的多样化、真实的混合文本。我们采用基于分段的两步流程：（i）检测给定混合文本中的片段，其中每个片段包含作者身份一致的句子，以及（ii）对每个已识别片段的作者身份进行分类。我们的实证研究结果强调（1）在混合文本中检测人工智能生成的句子总体上是一项具有挑战性的任务，因为（1.1）人类作家根据个人喜好选择甚至编辑人工智能生成的句子增加了识别片段作者的难度； (1.2) 混合文本中相邻句子之间作者身份的频繁变化给片段检测器识别作者一致的片段带来了困难； (1.3) 混合文本中文本片段的长度较短，为可靠的作者身份确定提供了有限的文体线索； (2) 在开始检测过程之前，评估混合文本中片段的平均长度是有益的。该评估有助于决定是否（2.1）对具有较长片段的混合文本采用基于文本分段的策略，或（2.2）对具有较短片段的混合文本采用直接逐句分类策略。]]></description>
      <guid>https://arxiv.org/abs/2403.03506</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>VLSP 2023 -- LTER：法律文本蕴涵识别挑战总结</title>
      <link>https://arxiv.org/abs/2403.03435</link>
      <description><![CDATA[arXiv:2403.03435v1 公告类型：新
摘要：在人工智能特别是语言处理快速发展的新时代，法律领域对人工智能的需求日益迫切。在英语、日语和汉语等其他语言的研究已经成熟的背景下，我们引入了法律领域越南语的第一个基础研究：通过越南语言和语音处理研讨会进行法律文本蕴涵识别。在分析参与者的结果时，我们讨论了法律领域中某些至关重要的语言方面，这些方面构成了需要解决的挑战。]]></description>
      <guid>https://arxiv.org/abs/2403.03435</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>魔法标记：使用法学硕士维护文档外部标记</title>
      <link>https://arxiv.org/abs/2403.03481</link>
      <description><![CDATA[arXiv:2403.03481v1 公告类型：新
摘要：文本文档（包括程序）通常具有人类可读的语义结构。从历史上看，对这些语义的编程访问需要显式的文档内标记。特别是在文本具有执行语义的系统中，这意味着它是一个很难正确支持的选择加入功能。如今，语言模型提供了一种新方法：可以使用模型对语义的类人理解将元数据绑定到更改文本中的实体，而对文档结构没有要求。该方法扩展了文档注释的应用范围，文档注释是程序编写、调试、维护和演示中的基本操作。我们贡献了一个系统，该系统采用智能代理来重新标记修改后的程序，使丰富的注释能够随着代码的发展自动跟随代码。我们还提供了正式的问题定义、经验综合基准套件和基准生成器。我们的系统在基准测试中的准确率达到 90%，并且可以以每个标签 5 秒的速度并行替换文档标签。虽然仍有很大的改进空间，但我们发现性能足够可靠，足以证明进一步探索应用程序是合理的。]]></description>
      <guid>https://arxiv.org/abs/2403.03481</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>否定阴性：通过分布分布优化在没有人类阳性样本的情况下进行比对</title>
      <link>https://arxiv.org/abs/2403.03419</link>
      <description><![CDATA[arXiv:2403.03419v1 公告类型：新
摘要：大型语言模型（LLM）彻底改变了人工智能的作用，但也带来了传播不道德内容的潜在风险。对齐技术已被引入以引导法学硕士迎合人类的偏好，并受到越来越多的关注。尽管在这个方向上取得了显着的突破，但现有的方法严重依赖于高质量的正负训练对，受到噪声标签以及首选和不首选响应数据之间边缘差异的影响。鉴于最近的法学硕士在产生有用反应方面的熟练程度，这项工作转向了一个新的研究重点：仅使用人工注释的负样本来实现对齐，保留有用性，同时减少危害性。为此，我们提出分布不偏好优化（D$^2$O），它最大化生成的响应和不偏好的响应之间的差异，以有效避开有害信息。我们从理论上证明，D$^2$O 相当于学习一个分布而不是实例级偏好模型，反映了人类对负面反应分布的不偏好。此外，D$^2$O 集成了隐式杰弗里散度正则化来平衡参考策略的利用和探索，并在训练过程中收敛到非负策略。大量的实验表明，我们的方法实现了可比的生成质量，并超越了最新的基线，产生了危害更小、信息更丰富的响应，具有更好的训练稳定性和更快的收敛速度。]]></description>
      <guid>https://arxiv.org/abs/2403.03419</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>LoRA 的混合：大型语言模型的高效多任务调优</title>
      <link>https://arxiv.org/abs/2403.03432</link>
      <description><![CDATA[arXiv:2403.03432v1 公告类型：新
摘要：指令调优有潜力激发或增强大型语言模型（LLM）的特定功能。然而，实现数据的正确平衡对于防止灾难性遗忘和任务之间的干扰至关重要。为了解决这些限制并增强训练灵活性，我们提出了 Mixture-of-LoRAs (MoA) 架构，这是一种新颖且参数高效的调整方法，专为 LLM 的多任务学习而设计。在本文中，我们首先使用相应的监督语料库数据单独训练多个特定领域的 LoRA 模块。这些 LoRA 模块可以与专家混合 (MoE) 中遵守的专家设计原则保持一致。随后，我们使用显式路由策略组合多个 LoRA，并引入域标签来促进多任务学习，这有助于防止任务之间的干扰，并最终提高每个任务的性能。此外，每个 LoRA 模型都可以迭代地适应新领域，从而实现快速的特定领域适应。在不同任务上的实验证明了其优越而稳健的性能，这可以进一步促进特定领域法学硕士的广泛应用。]]></description>
      <guid>https://arxiv.org/abs/2403.03432</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>学习最大化互信息以进行思想链蒸馏</title>
      <link>https://arxiv.org/abs/2403.03348</link>
      <description><![CDATA[arXiv:2403.03348v1 公告类型：新
摘要：知识蒸馏是将知识从大型复杂模型转移到较小模型的技术，标志着高效人工智能部署的关键一步。逐步蒸馏 (DSS) 是一种利用思想链 (CoT) 蒸馏的新颖方法，通过为较小的模型赋予较大模型的卓越推理能力，展现出良好的前景。在 DSS 中，蒸馏模型获得了通过多任务学习框架同时生成原理和预测标签的能力。然而，DSS忽略了两个训练任务之间的内在关系，导致CoT知识与标签预测任务的无效整合。为此，我们从信息瓶颈的角度研究了两个任务的相互关系，并将其表述为最大化两个任务的表示特征的互信息。我们提出了一种使用基于学习的方法来解决此优化问题的变分方法。我们在四个数据集上的实验结果表明，我们的方法优于最先进的 DSS。我们的研究结果为未来语言模型蒸馏的研究以及涉及 CoT 的应用提供了富有洞察力的指导。代码和模型将很快发布。]]></description>
      <guid>https://arxiv.org/abs/2403.03348</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>日英句子翻译练习自动评分数据集</title>
      <link>https://arxiv.org/abs/2403.03396</link>
      <description><![CDATA[arXiv:2403.03396v1 公告类型：新
摘要：本文提出了句子翻译练习（STE）的自动评估任务，该任务已在第二语言学习的早期阶段使用。我们将任务正式化为根据教育工作者预先指定的每个评分标准对学生的反应进行评分。然后，我们创建了一个日语和英语之间的 STE 数据集，其中包括 21 个问题，以及总共 3, 498 个学生的回答（平均 167 个）。答案是从学生和人群工作人员那里收集的。使用该数据集，我们展示了基线的性能，包括经过微调的 BERT 和 GPT 模型以及少量上下文学习。实验结果表明，经过微调的 BERT 基线模型能够对 F1 中大约 90% 的正确答案进行分类，但对错误答案的分类率只有不到 80%。此外，采用少样本学习的 GPT 模型显示的结果比微调的 BERT 更差，这表明我们新提出的任务提出了一个具有挑战性的问题，即使对于最先进的大型语言模型也是如此。]]></description>
      <guid>https://arxiv.org/abs/2403.03396</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>多样化：通过视频评论立场分析解读互联网对美国军方的看法，一种新颖的立场分类基准数据集</title>
      <link>https://arxiv.org/abs/2403.03334</link>
      <description><![CDATA[arXiv:2403.03334v1 公告类型：新
摘要：社交媒体文本的立场检测是下游任务的关键组成部分，涉及识别对疫苗接种和争论等争议话题持反对意见的用户群体。特别是，立场表明了对实体的看法。本文介绍了 DIVERSE，这是一个包含超过 173,000 条 YouTube 视频评论的数据集，注释了他们对美国军方视频的立场。该立场是通过人工引导、机器辅助的标记方法来注释的，该方法利用句子中的微弱语气信号作为支持指标，而不是使用人类手动注释。这些微弱信号包括仇恨言论和讽刺的存在、特定关键字的存在、文本的情绪以及来自两个大型语言模型的立场推断。然后，在用最终立场标签对每条评论进行注释之前，使用数据编程模型来整合弱信号。平均每个视频有 200 条评论，评论的立场稍微倾向于“反对”美国陆军和频道上发布的视频。]]></description>
      <guid>https://arxiv.org/abs/2403.03334</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>用于挖掘在线健康话语中新兴观点的大型语言模型的范围</title>
      <link>https://arxiv.org/abs/2403.03336</link>
      <description><![CDATA[arXiv:2403.03336v1 公告类型：新
摘要：在本文中，我们开发了一个由法学硕士支持的框架，用于在线健康社区中新兴观点挖掘的策划和评估。我们将新兴观点挖掘表述为源自 Reddit 的（标题、评论）对之间的成对立场检测问题，其中帖子标题包含针对未预定义主题的新兴健康相关主张。声明由用户明确或隐含地表达。我们详细介绍了（i）一种声明识别方法——识别帖子标题是否包含声明的任务，以及（ii）使用法学硕士进行立场检测的意见挖掘驱动的评估框架。
  我们通过发布一个新颖的测试数据集“Long COVID-Stance”或“LC-stance”来促进我们的探索，该数据集可用于评估法学硕士在在线健康社区中的声明识别和立场检测任务上的能力。 Long Covid 是一种新兴的后新冠疾病，其治疗指南不确定且复杂，因此使其成为我们任务的合适用例。 LC-Stance 包含来自 Reddit 社区的长篇新冠治疗相关讨论。我们的评估表明，GPT-4 在零样本姿态检测方面明显优于先前的工作。然后，我们执行彻底的 LLM 模型诊断，确定声明类型（即隐式声明与显式声明）和评论长度作为模型错误来源的作用。]]></description>
      <guid>https://arxiv.org/abs/2403.03336</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>Book2Dial：从教科书中生成师生互动，以经济高效地开发教育聊天机器人</title>
      <link>https://arxiv.org/abs/2403.03307</link>
      <description><![CDATA[arXiv:2403.03307v1 公告类型：新
摘要：教育聊天机器人是一种很有前景的辅助学生学习的工具。然而，在教育领域开发有效的聊天机器人一直具有挑战性，因为该领域很少有高质量的数据。在本文中，我们提出了一个基于一组教科书生成综合师生互动的框架。我们的方法捕捉了学习互动的一个方面，即具有部分知识的好奇学生向老师互动地询问有关教科书材料的问题。我们强调了此类对话应满足的各种质量标准，并比较了依赖于提示或微调大型语言模型的几种方法。我们使用合成对话来训练教育聊天机器人，并展示在不同教育领域进一步微调的好处。然而，人类评估表明，我们最好的数据合成方法仍然存在幻觉，并且倾向于重申之前对话中的信息。我们的研究结果为未来合成对话数据的努力提供了见解，以在大小和质量之间取得平衡。我们将开源我们的数据和代码。]]></description>
      <guid>https://arxiv.org/abs/2403.03307</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士遗忘的护栏基线</title>
      <link>https://arxiv.org/abs/2403.03329</link>
      <description><![CDATA[arXiv:2403.03329v1 公告类型：新
摘要：最近的工作表明，微调是从大型语言模型中“忘却”概念的一种有前途的方法。然而，微调可能会很昂贵，因为它需要生成一组示例并运行微调迭代来更新模型。在这项工作中，我们证明了简单的基于护栏的方法（例如提示和过滤）可以实现与微调相当的忘却结果。我们建议研究人员在评估计算密集型微调方法的性能时研究这些轻量级基线。虽然我们并不认为提示或过滤等方法是解决遗忘问题的通用解决方案，但我们的工作表明需要评估指标来更好地区分护栏与微调的力量，并强调护栏本身可能会出现的情况有利于遗忘，例如在仅 API 访问可用时生成用于微调或遗忘的示例。]]></description>
      <guid>https://arxiv.org/abs/2403.03329</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>Mad Libs 就是您所需要的：增强跨域文档级事件参数数据</title>
      <link>https://arxiv.org/abs/2403.03304</link>
      <description><![CDATA[arXiv:2403.03304v1 公告类型：新
摘要：文档级事件参数提取（DocEAE）是一个极其困难的信息提取问题，在资源匮乏的跨域设置中具有很大的局限性。为了解决这个问题，我们引入了 Mad Lib Aug (MLA)，一种新颖的生成式 DocEAE 数据增强框架。我们的方法利用了 Mad Libs 的直觉，Mad Libs 是一种被明确屏蔽的文档，用作流行游戏的一部分，可以由法学硕士生成和解决，为 DocEAE 生成数据。使用 MLA，我们的总体 F1 分数平均提高了 2.6 分。此外，与所有实验中的无增强基线相比，这种方法在零次和少次事件角色中实现了 3.9 和 5.2 点的平均增加。
  为了更好地促进跨域 DocEAE 的分析，我们还引入了一个新的度量，角色深度 F1 (RDF1)，它使用统计深度来识别目标域中的角色，这些角色相对于源域中观察到的角色是语义异常值。我们的实验表明，与非增强数据集相比，MLA 增强可以将 RDF1 性能平均提高 5.85 个点。]]></description>
      <guid>https://arxiv.org/abs/2403.03304</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>两全其美：一种灵活且可推广的关系分类神经符号方法</title>
      <link>https://arxiv.org/abs/2403.03305</link>
      <description><![CDATA[arXiv:2403.03305v1 公告类型：新
摘要：本文介绍了一种用于关系分类（RC）的新型神经符号架构，它将基于规则的方法与当代深度学习技术相结合。这种方法利用了两种范式的优点：基于规则的系统的适应性和神经网络的泛化能力。我们的架构由两个组件组成：用于透明分类的基于声明性规则的模型和通过语义文本匹配增强规则泛化性的神经组件。值得注意的是，我们的语义匹配器以无监督的与领域无关的方式进行训练，仅使用合成数据。此外，这些组件是松散耦合的，允许修改规则而无需重新训练语义匹配器。在我们的评估中，我们重点关注两个少样本关系分类数据集：Few-Shot TACRED 和 NYT29 的少样本版本。我们表明，尽管没有看到任何人工注释的训练数据，但我们提出的方法在四分之三的设置中优于以前最先进的模型。此外，我们表明我们的方法仍然是模块化和柔韧的，即可以局部修改相应的规则以改进整体模型。对 TACRED 关系 \texttt{org:parents} 规则的人为干预使该关系的性能相对提高了 26%，而不会对其他关系产生负面影响，也无需重新训练语义匹配组件。]]></description>
      <guid>https://arxiv.org/abs/2403.03305</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:29 GMT</pubDate>
    </item>
    </channel>
</rss>