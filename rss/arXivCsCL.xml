<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Wed, 03 Jan 2024 03:15:05 GMT</lastBuildDate>
    <item>
      <title>大型语言模型的零样本位置去偏。 （arXiv：2401.01218v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01218</link>
      <description><![CDATA[微调已被证明是改善性能的有效方法
大型语言模型（LLM）的领域性能。然而，LLM 可能适合
数据集偏差和预测捷径，导致不良生成
表现。实验结果表明法学硕士很容易表现出位置
偏见，即利用位于开头或结尾的信息，或
输入中的特定位置提示。现有的缓解工作
位置偏差需要外部偏差知识或带注释的无偏差样本，
这在现实中是不切实际的。在这项工作中，我们提出了零射击位置
去偏差（ZOE）框架，以减轻法学硕士的职位偏差。 ZOE杠杆
来自预先训练的法学硕士的无监督反应用于去偏，因此没有任何
外部知识或数据集。提高无人监督的质量
响应，我们提出了一个主从对齐（MSA）模块来修剪这些
回应。对八个数据集和五个任务的实验表明，ZOE
在减轻四种类型的职位方面始终优于现有方法
偏见。此外，ZOE 通过仅牺牲一点性能来实现这一点
有偏差样本，简单有效。
]]></description>
      <guid>http://arxiv.org/abs/2401.01218</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:04 GMT</pubDate>
    </item>
    <item>
      <title>VideoDrafter：使用法学硕士生成内容一致的多场景视频。 （arXiv：2401.01256v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01256</link>
      <description><![CDATA[扩散模型的最新创新和突破
显着扩展了生成高质量视频的可能性
给定的提示。大多数现有作品都处理单场景场景
单一背景中仅发生一个视频事件。扩展生成
然而，多场景视频并不是微不足道的，需要很好地
管理之间的逻辑，同时保持一致的视觉外观
跨视频场景的关键内容。在本文中，我们提出了一部小说
内容一致的多场景视频框架，即VideoDrafter
一代。从技术上讲，VideoDrafter 利用大型语言模型 (LLM)
将输入提示转换为全面的多场景脚本，受益匪浅
来自LLM学到的逻辑知识。每个场景的脚本包括
描述事件的提示、前景/背景实体以及
相机运动。 VideoDrafter 识别整个过程中的常见实体
脚本并要求法学硕士详细说明每个实体。生成的实体描述是
然后输入文本到图像模型，为每个文本生成参考图像
实体。最后，VideoDrafter通过生成每个场景来输出多场景视频
场景视频通过扩散过程获取参考图像，
考虑到事件的描述性提示和摄像机的移动。扩散
模型将参考图像作为条件和对齐
加强多场景视频的内容一致性。广泛的实验
证明 VideoDrafter 在以下方面优于 SOTA 视频生成模型
视觉质量、内容一致性和用户偏好。
]]></description>
      <guid>http://arxiv.org/abs/2401.01256</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:04 GMT</pubDate>
    </item>
    <item>
      <title>自然语言处理和大型语言模型的公平性认证。 （arXiv：2401.01262v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01262</link>
      <description><![CDATA[自然语言处理 (NLP) 在我们的日常生活中发挥着重要作用，
特别是由于大型语言模型（LLM）的巨大进步。
然而，NLP 有许多公平性关键的用例，例如，作为专家系统
招聘或作为教育领域的法学硕士导师。由于NLP是基于人类
语言中，潜在有害的偏见可能会扩散到 NLP 系统中并产生
不公平的结果、歧视少数群体或产生法律问题。
因此，为 NLP 方法开发公平性认证非常重要。
我们遵循定性研究方法来进行公平认证
自然语言处理。特别是，我们回顾了大量有关算法的文献
公平性，我们对广泛的专家进行了半结构化访谈
来自该领域的一系列专家。我们系统地设计了六大公平
NLP的标准，可以进一步细化为18个子类别。我们的
标准为操作和测试流程提供了基础
从审核员和被审核者的角度证明公平性
组织。
]]></description>
      <guid>http://arxiv.org/abs/2401.01262</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:04 GMT</pubDate>
    </item>
    <item>
      <title>将结构化数据统一为图形，以进行数据到文本的预训练。 （arXiv：2401.01183v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01183</link>
      <description><![CDATA[数据到文本（D2T）生成旨在将结构化数据转换为自然数据
语言文本。事实证明，数据到文本的预训练对于增强
D2T 生成并产生令人印象深刻的性能。然而，之前的
预训练方法要么将结构化数据过度简化为序列
不考虑输入结构或量身定制的培训目标
对于特定的数据结构（例如表或知识图）。在本文中，
我们统一不同类型的结构化数据（即表、键值数据、
知识图谱）转换为图格式并将不同的数据转换为文本
生成任务如图形到文本生成。为有效利用
输入图的结构信息，我们提出了一种结构增强的
通过设计结构增强的 D2T 生成预训练方法
变压器。具体来说，我们为 Transformer 设计一个位置矩阵，
对输入图中连接节点的相对位置信息进行编码。
此外，我们提出了一个新的注意力矩阵来合并图结构
通过采用可用的显式连接将其转换为原始 Transformer
结构考虑在内。对六个基准数据集的广泛实验表明
我们模型的有效性。我们的源代码位于
https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t。
]]></description>
      <guid>http://arxiv.org/abs/2401.01183</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>错误信息检测中的不确定性解决。 （arXiv：2401.01197v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01197</link>
      <description><![CDATA[错误信息会带来各种风险，例如破坏公众信任和
歪曲事实的言论。像 GPT-4 这样的大型语言模型 (LLM) 已经
在减少错误信息方面表现出有效的效果，特别是在处理
提供了足够上下文的陈述。然而，他们很难评估
准确地表达模棱两可或上下文不足的陈述。这项工作介绍了一个
解决此类陈述中的不确定性的新方法。我们提出一个框架
对缺失信息进行分类并发布说谎者的类别标签-新
数据集，适用于缺失信息的跨域内容。
然后，我们利用这个框架来生成有效的用户查询以查找缺失的信息
语境。与基线相比，我们的方法提高了生成速度
用户可回答的问题有38个百分点和分类
宏观F1性能提升超过10个百分点。因此，这种方法可以
为未来的错误信息缓解渠道提供有价值的组成部分。
]]></description>
      <guid>http://arxiv.org/abs/2401.01197</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>Quokka：用于材料科学的开源大型语言模型聊天机器人。 （arXiv：2401.01089v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01089</link>
      <description><![CDATA[本文介绍了专门用于材料的聊天机器人的开发
科学，利用 Llama-2 语言模型，并继续进行预训练
S2ORC 材料科学领域的广泛研究文章
数据集。该方法涉及一个以上的初始预训练阶段
百万个特定领域的论文，然后是一个指令调整过程
完善聊天机器人的功能。聊天机器人旨在协助
研究人员、教育工作者和学生通过提供即时的、情境感知的
对材料科学领域询问的答复。我们做四个
训练有素的检查点（7B、13B，有或没有聊天功能）可免费使用
研究社区 https://github.com/Xianjun-Yang/Quokka。
]]></description>
      <guid>http://arxiv.org/abs/2401.01089</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>揭示越南产品评论中的比较情绪：顺序分类框架。 （arXiv：2401.01108v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01108</link>
      <description><![CDATA[比较意见挖掘是情感分析的一个专门领域，
旨在识别和提取相对表达的情绪。讲话
对于这项任务，我们提出了一种方法，该方法包括解决三个连续的问题
子任务：（i）识别比较句，即一个句子是否有
比较意义，（ii）提取比较元素，即什么是
比较主语、客体、方面、谓语，以及 (iii) 分类
比较类型有助于更深入地理解用户情绪
在越南产品评论中。我们的方法在越南排名第五
语言和语音处理 (VLSP) 2023 年比较观点挑战赛
来自越南产品评论的采矿 (ComOM)。
]]></description>
      <guid>http://arxiv.org/abs/2401.01108</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>通过选择性推理从法律决策中发现重要主题。 （arXiv：2401.01068v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01068</link>
      <description><![CDATA[我们提出并评估一个自动化管道，以发现重要的
通过传递与主题综合的特征来提取法律决策文本中的主题
通过惩罚回归和选择后显着性检验建立模型。这
方法识别与结果显着相关的案例主题，
可以手动解释主题词分布以获得见解
关于重要主题以及可用于识别的案例主题权重
每个主题的代表性案例。我们在新数据集上演示该方法
域名争议和欧洲人权法院的规范数据集
侵犯权利案件。基于潜在语义分析的主题模型
当评估语言模型嵌入时。我们表明，由
管道符合这两个领域的法律原则，并且可用于
其他相关的法律分析任务。
]]></description>
      <guid>http://arxiv.org/abs/2401.01068</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:01 GMT</pubDate>
    </item>
    <item>
      <title>DialCLIP：使 CLIP 成为多模式对话检索器。 （arXiv：2401.01076v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01076</link>
      <description><![CDATA[最近，预训练视觉语言模型取得了重大进展
大大增强了多模态对话系统的能力。这些型号
通过对下游任务进行微调，展示了显着的改进。
然而，现有的预训练模型主要关注于有效
捕捉视觉和语言模式之间的一致性，通常忽略
对话上下文的复杂性。在本文中，我们提出了一个
用于多模式对话框的名为 DialCLIP 的参数高效提示调整方法
恢复。具体来说，我们的方法引入了多模式上下文提示
生成器来学习上下文特征，这些特征随后被提炼成
预先训练的视觉语言模型 CLIP 中的提示。除此之外，我们
引入域提示以减轻下游对话框中的磁盘重复占用
数据。为了方便各类检索，我们还设计了多个专家
学习从 CLIP 输出到多模态表示空间的映射，
每个专家负责一种特定的检索类型。广泛的
实验表明 DialCLIP 在两个方面实现了最先进的性能
通过调整广泛认可的基准数据集（即 PhotoChat 和 MMDialog）
仅占总参数的0.04%。这些结果凸显了功效和
我们提出的方法的效率，强调了其推进
多模态对话检索领域。
]]></description>
      <guid>http://arxiv.org/abs/2401.01076</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:01 GMT</pubDate>
    </item>
    <item>
      <title>越南诗歌的生成与跨语言诗对诗翻译的前景。 （arXiv：2401.01078v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01078</link>
      <description><![CDATA[诗歌生成在自然领域一直是一项具有挑战性的任务
语言处理，因为它需要模型理解语言的细微差别
语言、情感和风格。在本文中，我们建议使用大语言
根据自然语言提示生成越南诗的模型，从而
通过增强的内容控制促进直观的过程。我们最
有效的模型，GPT-3 Babbage 变体，实现了自定义评估
得分 0.8，专为越南语“luc bat”流派量身定制
诗歌。此外，我们还探讨了将诗歌转述为正常的想法
文本提示并在“luc bat”类型中获得相对较高的分数 0.718。
这个实验展现了跨语言诗对诗的潜力
以译诗为输入的翻译，同时保持
完全控制生成的内容。
]]></description>
      <guid>http://arxiv.org/abs/2401.01078</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:01 GMT</pubDate>
    </item>
    <item>
      <title>Cheetah：517 种非洲语言的自然语言生成。 （arXiv：2401.01053v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01053</link>
      <description><![CDATA[资源匮乏的非洲语言给自然语言带来了独特的挑战
处理（NLP）任务，包括自然语言生成（NLG）。在这个
论文中，我们开发了 Cheetah，一种大规模多语言 NLG 语言模型
非洲语言。 Cheetah支持517种非洲语言和语言
品种，使我们能够解决 NLG 资源的稀缺问题并提供
促进语言多样性的解决方案。我们证明了以下方法的有效性
猎豹经过七代下游综合评估
任务。在七项任务中的五项中，Cheetah 明显优于其他任务
模型，展示了其在生成相干和
多种非洲语言的适合上下文的文本。我们
另外进行详细的人类评估以更深入地研究
猎豹的语言能力。猎豹的推出
语言多样性带来深远的好处。通过利用预训练模型
并使它们适应特定的语言，我们的方法有助于
为非洲社区开发实用的 NLG 应用程序。调查结果
这项研究的一部分有助于推进资源匮乏环境中的 NLP 研究，
迅速提高非洲语言的可及性和包容性
不断扩大的数字景观。我们将公开发布我们的研究模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.01053</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>超越英语的 LLaMA：语言能力迁移的实证研究。 （arXiv：2401.01055v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01055</link>
      <description><![CDATA[近年来，在大范围内取得了重大进展
语言模型 (LLM)，以 ChatGPT 为例，展示了非凡的性能
熟练地完成一系列复杂的任务。然而，许多主流的法学硕士
（例如 LLaMA）是在英语主导的语料库上进行预训练的，这限制了它们的
其他非英语语言的表现。在本文中，我们重点讨论如何
有效地传递语言生成和跟随的能力
非英语语言的说明。为了回答这个问题，我们进行了
基于LLaMA的广泛实证研究，累计超过1440个GPU
小时。我们分析了词汇扩展等关键因素的影响，
进一步的预训练和转移指令调整。准确评估
为了模型的知识水平，我们采用了四种广泛使用的标准化测试
基准测试：C-Eval、MMLU、AGI-Eval 和 GAOKAO-Bench。此外，一个
对模型的响应质量进行综合评价，
考虑准确性、流畅性、信息性、逻辑性等方面
连贯性和无害性，基于 LLM-Eval，这是一个基准，包括
17 个不同类别的教学任务。我们的评估结果
证明与最先进的传输模型具有可比的性能
可以用不到 1% 的预训练数据来实现，无论是在
知识协调和响应质量。此外，实验
十三种低资源语言的结果也表现出类似的结果
趋势。我们预计实验揭示的结论将有助于
培养非英语法学硕士的社区。
]]></description>
      <guid>http://arxiv.org/abs/2401.01055</guid>
      <pubDate>Wed, 03 Jan 2024 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>DocLLM：用于多模式文档理解的布局感知生成语言模型。 （arXiv：2401.00908v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00908</link>
      <description><![CDATA[企业文件，例如表格、发票、收据、报告、合同、
和其他类似的记录，通常在交集处携带丰富的语义
文本和空间模式。它们的复杂性提供的视觉线索
布局对于有效理解这些文档起着至关重要的作用。在
在本文中，我们提出了 DocLLM，这是对传统大型数据库的轻量级扩展
用于对视觉文档进行推理的语言模型（LLM），考虑到
文本语义和空间布局。我们的模型与现有模型不同
多模态法学硕士通过避免昂贵的图像编码器并专注于
边界框信息合并空间布局结构。
具体来说，文本和空间模态之间的交叉对齐是
通过将经典变形金刚中的注意力机制分解为
解纠缠矩阵的集合。此外，我们设计了一个预训练目标
学习填充文本片段。这种方法使我们能够解决
视觉中经常遇到的不规则布局和异构内容
文件。使用大规模指令对预训练模型进行微调
数据集，涵盖四个核心文档智能任务。我们证明
我们的解决方案在所有任务的 16 个数据集中的 14 个上优于 SotA LLM，
并能很好地推广到 5 个以前未见过的数据集中的 4 个。
]]></description>
      <guid>http://arxiv.org/abs/2401.00908</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>Auffusion：利用扩散和大型语言模型的力量来生成文本到音频。 （arXiv：2401.01044v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2401.01044</link>
      <description><![CDATA[扩散模型和大型语言模型 (LLM) 的最新进展
极大地推动了AIGC领域的发展。文本转音频 (TTA)，一种新兴的技术
AIGC 应用程序旨在根据自然语言提示生成音频，
引起越来越多的关注。然而，现有的 TTA 研究常常遇到困难
具有生成质量和文本音频对齐，特别是对于复杂的
文本输入。从最先进的文本到图像 (T2I) 中汲取灵感
扩散模型，我们引入 Auffusion，一个采用 T2I 模型的 TTA 系统
通过有效利用其固有的生成能力，将框架转化为TTA任务
优势和精确的跨模式对齐。我们的客观和主观
评估表明 Auffusion 超越了之前的 TTA 方法
有限的数据和计算资源。此外，之前的 T2I 研究
认识到编码器选择对跨模式对齐的重大影响，
例如细粒度的细节和对象绑定，而类似的评估是
之前的TTA作品中缺乏。通过全面的消融研究和
创新的交叉注意力图可视化，我们提供富有洞察力的
TTA 中文本-音频对齐的评估。我们的研究结果揭示了 Auffusion
生成与文本精确匹配的音频的卓越能力
描述，在几个相关任务中进一步证明，例如
音频风格转换、修复和其他操作。我们的实施
演示可在 https://auffusion.github.io 获取。
]]></description>
      <guid>http://arxiv.org/abs/2401.01044</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>LaFFi：利用混合自然语言反馈来微调语言模型。 （arXiv：2401.00907v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.00907</link>
      <description><![CDATA[微调大型语言模型（LLM）使经过训练的模型适应特定的
下游任务，显着提高特定任务的性能。监督
微调（SFT）是一种常见的方法，法学硕士接受培训以产生
想要的答案。然而，接受过 SFT 培训的法学硕士有时会犯一些简单的错误
并导致对推理任务（例如回答问题）产生幻觉。
如果没有外部反馈，SFT 很难学习到良好的映射
问题和所需答案之间的关系，尤其是在数据集较小的情况下。
本文介绍了 SFT 的替代方案，称为自然语言反馈
用于微调法学硕士 (LaFFi)。 LaFFi 让法学硕士直接预测他们的反馈
将从注释者处收到。我们发现需要这样的反思可以
显着提高领域内问答任务的准确性，
为自然语言的应用提供了一个有前景的方向
SFT LLM 领域的反馈。额外的消融研究表明
带注释的数据集中的部分人工注释数据会影响
微调性能。
]]></description>
      <guid>http://arxiv.org/abs/2401.00907</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:58 GMT</pubDate>
    </item>
    </channel>
</rss>