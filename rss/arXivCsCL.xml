<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 21 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>上下文很重要吗？ contextualjudgebench在上下文设置中评估基于LLM的法官</title>
      <link>https://arxiv.org/abs/2503.15620</link>
      <description><![CDATA[ARXIV：2503.15620V1公告类型：新 
摘要：大型语言模型（LLM）-AS-Gudge范式已被用来满足对AI系统开发和部署后监控过程中对模型输出的廉价，可靠和快速评估的需求。虽然法官模型（LLMS FINETUNED专门用于评估和批评模型输出）已被吹捧为通用评估者，但通常仅在非上下文场景（例如以下说明）上进行评估。鉴于检索效果生成（RAG）和摘要用例的越来越多的流行率越来越多，因此省略了上下文设置（将外部信息用作生成输出的上下文的情况）令人惊讶。上下文评估具有独特的挑战，因为评估通常取决于从业人员的优先级，导致有条件的评估标准（例如，比较基于事实的响应，然后考虑完整性，如果它们同样是事实）。为了解决差距，我们提出了ContextualJudgeBench，这是法官的基准，在八个拆分中具有2,000个具有挑战性的响应对，受到现实世界情境评估方案的启发。我们通过多管齐下的数据构建管道来构建基准，该数据构建管道利用现有的人类注释和基于模型的扰动。我们对11个法官模型和9个通用模型进行的全面研究表明，上下文信息及其评估标准对甚至最先进的模型都带来了重大挑战。例如，Openai的O1是表现最佳的模型，几乎无法达到55％的一致精度。]]></description>
      <guid>https://arxiv.org/abs/2503.15620</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大语言模型增强胰腺癌分期：检索发电的作用</title>
      <link>https://arxiv.org/abs/2503.15664</link>
      <description><![CDATA[ARXIV：2503.15664V1公告类型：新 
摘要：目的：检索功能增强的生成（RAG）是一种通过从可靠的外部知识（REK）中检索相关信息来增强大语言模型（LLM）功能和可靠性的技术。 RAG对放射学引起了兴趣，我们以前报道了Notebooklm（带有RAG（RAG-LLM））的Notebooklm的实用性，用于肺癌分期。但是，由于比较器llm与笔记本电脑的内部模型有所不同，因此尚不清楚其优势是源于抹布还是固有的模型差异。为了更好地隔离RAG的影响并评估其在不同癌症中的效用，我们在胰腺癌分期实验中比较了笔记本LLM与其内部LLM Gemini 2.0 Flash。
  材料和方法：日本胰腺癌分期指南的摘要被用作REK。我们将三个组（rek+/rag+（Notebooklm）与REK），REK+/rag-（带REK的Gemini 2.0闪光灯）和Rek-/rag-（无REK的Gemini 2.0闪光灯） - 基于CT发现。分期标准包括TNM分类，局部入侵因子和切除性分类。在REK+/rag+中，根据检索到的REK摘录的充分性来量化检索精度。
  结果：REK+/RAG+达到了70％的分期精度，表现优于REK+/RAG-（38％）和REK-/RAG-（35％）。对于TNM分类，REK+/RAG+达到80％的精度，超过REK+/rag-（55％）和Rek-/rag-（50％）。此外，REK+/rag+明确提出的REK摘录，获得了92％的检索精度。
  结论：在胰腺癌分期实验中，Notebooklm（rag-llm）优于其内部LLM Gemini 2.0 Flash，这表明RAG可以提高LLM的分期精度。此外，其检索和介绍REK摘录的能力为医师提供了透明度，强调了其适用于临床诊断和分类。]]></description>
      <guid>https://arxiv.org/abs/2503.15664</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我有资格吗？自然语言推断临床试验患者招募：患者的观点</title>
      <link>https://arxiv.org/abs/2503.15718</link>
      <description><![CDATA[ARXIV：2503.15718V1公告类型：新 
摘要：招募患者参加临床试验可能具有挑战性且耗时。通常，参与临床试验是由医疗保健专业人员发起的，并向患者提出了建议。通过在线招聘直接向患者促进临床试验可能有助于更有效地与他们联系。在这项研究中，我们解决了患者正在启动自己的招聘过程并希望确定他们是否有资格参加给定临床试验的情况，并使用自己的语言来描述其医学概况。为了研究这是否在患者试验匹配过程中造成困难，我们设计了一个新的数据集和任务，自然语言招募（NLI4PR），其中必须将患者语言概况与临床试验相匹配。我们通过调整TREC 2022临床试验轨道数据集来创建它，该临床试验数据集可提供患者的医疗概况，并使用患者语言手动重新塑造它们。我们还使用相关的临床试验报告，其中患者符合条件或排除在内。我们在我们的任务上提示了几种开源大语模型，并使用患者语言实现了F1分数的56.5至71.8，而使用医学语言的同一任务为64.7至73.1。当使用患者语言时，我们只观察到最佳模型的性能损失很小，这表明可以将患者作为起点以帮助招募患者进行临床试验。语料库和代码库都可以在我们的GitHub和HuggingFace存储库中免费获得。]]></description>
      <guid>https://arxiv.org/abs/2503.15718</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Kogner：关于生物医学命名实体识别的知识图蒸馏的新型框架</title>
      <link>https://arxiv.org/abs/2503.15737</link>
      <description><![CDATA[ARXIV：2503.15737V1公告类型：新 
摘要：命名实体识别（NER）是自然语言处理（NLP）的基本任务，在信息提取，问题答案和基于知识的系统中起着至关重要的作用。传统的基于深度学习的NER模型通常会在特定领域的概括中遇到困难，并且遇到了数据稀疏问题。在这项工作中，我们引入了针对命名实体识别（Kogner）提炼的知识图，这是一种新颖的方法，将知识图（kg）蒸馏集成到NER模型中以增强实体识别性能。我们的框架利用了从KG的结构化知识表示形式来丰富上下文嵌入，从而改善了实体分类并减少实体检测的歧义。 Kogner采用了两个步骤的过程：（1）知识蒸馏，将外部知识源蒸馏成与NER模型无缝集成的轻量级表示，（2）实体感知的增强功能，将其集成到与知识图的上下文嵌入的嵌入式相结合，从而将知识图直接与GNN富含，从而将模型的能力直接融合到模型的能力中，从而可以理解和代表实体关系。基准数据集的实验结果表明，Kogner实现了最先进的性能，优于固定的NER模型和LLM的表现可观。这些发现表明，利用知识图作为辅助信息可以显着提高NER准确性，使Kogner成为知识吸引NLP的未来研究的有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2503.15737</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一个尺寸是否适合全部？：测量多文件摘要域转移中的故障</title>
      <link>https://arxiv.org/abs/2503.15768</link>
      <description><![CDATA[ARXIV：2503.15768V1公告类型：新 
摘要：摘要性多文件摘要（MDS）是自动汇总多个文档中信息的任务，从新闻文章到与多个扬声器的对话。当前MDS模型的培训方法可以分为四种方法：端到端，具有特殊的预训练（“直接”），块 - 夏令式，提取到夏季化以及使用GPT风格的模型进行推断。在这项工作中，我们评估了跨培训方法，域和维度（参考相似性，质量和事实）的MDS模型，以分析在一个域中训练的模型以及为什么在零射击域转移设置中的另一个（新闻，科学和对话）的文档。我们将域转移“失败”定义为事实的减少，较高的目标偏差以及总结质量的总体下降。除了探索MDS模型的域传输外，我们还研究了使用流行的摘要指标的潜在问题。]]></description>
      <guid>https://arxiv.org/abs/2503.15768</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语法和游戏玩法的RL用于游戏描述与LLM的生成</title>
      <link>https://arxiv.org/abs/2503.15783</link>
      <description><![CDATA[ARXIV：2503.15783V1公告类型：新 
摘要：游戏说明生成（GDG）是生成用自然语言文本编写的游戏描述（GDL）的游戏描述的任务。先前的研究已经探索了利用大语模型（LLMS）的上下文理解能力的生成方法；但是，准确地重现游戏描述的游戏功能仍然是一个挑战。在本文中，我们提出了基于GDG（RLGDG）的LLM的加强学习微调。我们的培训方法同时通过引入语法奖励和概念奖励来提高语法正确性和对游戏概念的忠诚。此外，我们采用了两阶段的培训策略，在监督微调（SFT）之后，应用强化学习（RL）。实验结果表明，我们所提出的方法仅使用SFT显着胜过基线方法。]]></description>
      <guid>https://arxiv.org/abs/2503.15783</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>f \'ux \`i：用于评估古代中国文本理解和世代语言模型的基准</title>
      <link>https://arxiv.org/abs/2503.15837</link>
      <description><![CDATA[ARXIV：2503.15837V1公告类型：新 
摘要：古代中国文本处理对大型语言模型（LLM）提出了独特的挑战，因为其独特的语言特征，复杂的结构限制和丰富的文化背景。尽管现有的基准主要集中于通过多项选择问题评估理解，但在评估模型在古典中文中的生成能力方面仍然存在一个关键的差距。我们介绍了f \&#39;ux \`i，这是一个全面的基准，可评估21个不同任务的理解和发电能力。我们的基准通过三个关键贡献来区分：（1）对理解和发电任务的平衡覆盖范围，包括诗歌组成和对联的完成，（2）专门为中国文本生成设计的专业评估指标，将基于规则的验证结合在一起，将基于规则的验证与精细的LLM评估者以及（3）的系统构成效果相结合。通过对最先进的LLM的广泛评估，我们揭示了理解和发电任务之间的显着绩效差距，模型在理解中取得了令人鼓舞的结果，但在一代任务中却大大挣扎，尤其是那些需要深厚的文化知识和遵守经典格式的任务。我们的发现突出了中国古代文本处理中当前的局限性，并为未来的模型开发提供了见解。基准，评估工具包和基线结果可公开使用，以促进该领域的研究。]]></description>
      <guid>https://arxiv.org/abs/2503.15837</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型中的不确定性量化和置信度校准：调查</title>
      <link>https://arxiv.org/abs/2503.15850</link>
      <description><![CDATA[ARXIV：2503.15850V1公告类型：新 
摘要：大型语言模型（LLM）在文本，推理和决策中表现出色，使其能够在医疗保健，法律和运输等高风险领域中采用。但是，它们的可靠性是一个主要问题，因为它们通常会产生合理但不正确的响应。不确定性定量（UQ）通过估计对产出的信心，降低风险和选择性预测来增强可信度。但是，由于计算限制和解码不一致，传统的UQ方法与LLMS难度。此外，LLMS引入了独特的不确定性来源，例如输入歧义，推理路径差异和解码随机性，这些源超出了经典的质地和认知不确定性。为了解决这个问题，我们引入了一种新的分类法，该分类法基于计算效率和不确定性维度（输入，推理，参数和预测不确定性）对UQ方法进行分类。我们评估现有技术，评估其现实世界的适用性并确定开放的挑战，强调对可扩展，可解释和强大的UQ方法提高LLM可靠性的需求。]]></description>
      <guid>https://arxiv.org/abs/2503.15850</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>打字摊位：非事实问题的类型多相关分解回答</title>
      <link>https://arxiv.org/abs/2503.15879</link>
      <description><![CDATA[ARXIV：2503.15879V1公告类型：新 
摘要：由于其开放性的性质，不同的意图以及对多相关推理的需求，非事实的问题避开（NFQA）构成了重大挑战，这使传统的factoid QA方法（包括检索成绩（RAG））不足。与Factoid问题不同，非事实问题（NFQ）缺乏确切的答案，需要从各种推理维度的多个来源的综合信息。为了解决这些局限性，我们引入了键入rag，这是NFQA的RAG范式内的一种类型感知的多相关分解框架。键入rag将NFQ分类为不同类型的类型，例如辩论，经验和比较 - 并将基于方面的分解应用于完善检索和发电策略。通过将多种敏感的NFQ分解为单一的子征值并汇总结果，键入rag会产生更有信息和上下文相关的响应。为了评估键入rag，我们介绍了Wiki-NFQA，这是一种涵盖不同NFQ类型的基准数据集。实验结果表明，键入rag的表现优于基准，从而突出了类型感知分解对于在NFQA中有效检索和产生的重要性。我们的代码和数据集可在\ href {https://github.com/teamnlp/typed-rag} {https://github.com/teamnlp/typed-rag}中获得。]]></description>
      <guid>https://arxiv.org/abs/2503.15879</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>参数与上下文：语言模型中知识依赖的细粒度控制</title>
      <link>https://arxiv.org/abs/2503.15888</link>
      <description><![CDATA[ARXIV：2503.15888V1公告类型：新 
摘要：通过整合外部知识，检索型发电（RAG）减轻大语言模型（LLMS）的幻觉。但是，参数知识和检索到上下文之间的冲突构成了挑战，尤其是当检索到的信息不可靠或模型的内部知识已过时时。在这种情况下，LLM努力确定是否更多地依靠其自己的参数或冲突的背景。为了解决这个问题，我们提出了** ck-plug **，这是一种用于控制LLMS依赖参数和上下文知识的插件方法。我们介绍了一种新颖的知识一致性指标，信心增益，该指标通过测量插入后令牌概率分布的熵变化来检测知识冲突。然后，通过单个调谐参数调整具有负置信度增益的令牌的概率分布，CK插槽可以对知识偏好进行细粒度的控制。实验表明，CK-Plug能够显着调节反事实抹布情景中知识依赖的能力，同时保持发电的流利性和知识准确性。例如，在Llama3-8b上，与基线42.1％相比，可以在广泛范围内调整抹布响应的记忆回忆（MR）。此外，CK-Plug基于模型对内部和外部知识的信心支持自适应控制，从而在各种一般的抹布任务中实现了一致的性能提高。我们的代码可在：$ \ href {https://github.com/byronbbl/ck-plug} {\ text {this https url}} $中。]]></description>
      <guid>https://arxiv.org/abs/2503.15888</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从结构化的提示到开放叙述：通过开放式讲故事来衡量LLMS中的性别偏见</title>
      <link>https://arxiv.org/abs/2503.15904</link>
      <description><![CDATA[ARXIV：2503.15904V1公告类型：新 
摘要：大型语言模型（LLM）彻底改变了自然语言处理，但担心他们反映或扩大其培训数据中存在的社会偏见的趋势。这项研究介绍了一个新颖的评估框架，以发现LLMS中的性别偏见，重点是他们的职业叙事。与以前依靠结构化场景或精心制作的提示的方法不同，我们的方法利用了自由形式的讲故事来揭示模型中嵌入的偏见。系统的分析表明，在六个广泛使用的LLM中，女性角色对女性角色的代表性过高。此外，我们的发现表明，LLM生成的职业性别排名与人类的刻板印象相比，比实际的劳动统计更加紧密地与人类的刻板印象保持一致。这些见解强调了需要平衡缓解策略以确保公平性的必要性，同时避免了新的刻板印象的增强。]]></description>
      <guid>https://arxiv.org/abs/2503.15904</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向自动持续学习：一个自适应框架连续教学调整</title>
      <link>https://arxiv.org/abs/2503.15924</link>
      <description><![CDATA[ARXIV：2503.15924V1公告类型：新 
摘要：持续的指导调整使大型语言模型（LLM）能够逐步学习，同时保留过去的知识，而现有方法主要关注如何保留旧知识，而不是选择要学习的新知识。在特定领域的环境中，维持数据质量和管理系统约束仍然是主要挑战。为了解决这些问题，我们提出了一个自动化的连续指令调谐框架，该框架动态过滤了传入的数据，该数据可以识别和减少连续更新中的冗余数据。我们的方法利用一个小的代理模型来有效地基于困惑，并更新代理以确保过滤标准与已部署模型的不断发展的状态保持一致。与现有的静态数据选择方法相比，我们的框架可以有效地处理逐步获取的数据和变化分布。此外，它通过启用无缝模型更新，支持版本回滚并合并自动检查点评估来解决实际部署挑战。我们在现实的医疗情况下评估了系统。它将计算成本降低了66.7％，并提高了模型性能，并实现了自动更新，从而证明了其自动连续教学调整的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.15924</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从混乱到顺序：大语言模型中细粒度推理的原子推理框架</title>
      <link>https://arxiv.org/abs/2503.15944</link>
      <description><![CDATA[ARXIV：2503.15944V1公告类型：新 
摘要：大型语言模型（LLM）的最新进展显示出了显着的进步，但其逻辑``缓慢思考&#39;&#39;推理的能力仍然是一个重要的研究领域。当前的推理缩放范式受到了两个基本约束：零散的思想流动损害了逻辑相干性，以及随着搜索空间维度升级的强烈计算复杂性。为了克服这些局限性，我们提出\ textbf {atomic推理器}（\ textbf {ar}），这是一种认知推理策略，可以通过系统的原子级操作实现细粒度的推理。 AR采用认知路由机制将推理过程分解为原子认知单元，以动态构建推理表示并编排推理途径。这种系统的方法可以逐步实现结构化认知，从而确保了逻辑连贯性，同时显着降低了认知载荷，从而有效地模拟了在人类深思熟虑过程中观察到的认知模式。广泛的实验结果表明，没有详尽解决方案搜索的计算负担，尤其是在语言逻辑难题中脱颖而出，AR的卓越推理能力。这些发现证明了AR在增强LLM的稳健，悠久逻辑推理和审议能力方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.15944</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自适应小组政策优化：进行稳定的培训和令牌有效的推理</title>
      <link>https://arxiv.org/abs/2503.15952</link>
      <description><![CDATA[ARXIV：2503.15952V1公告类型：新 
摘要：自从DeepSeek-R1普及以来，小组相对政策优化（GRPO）已成为推理LLMS培训的核心部分。但是，我们发现一些影响RL稳定性和推理效率的缺陷。因此，我们提出了自适应组策略优化（AGPO），其中包含两个简单但有效的修改：一种修订的优势估计方法，以减轻零变量的情况；基于长度的奖励，激励模型以避免过度思考。该实验证明了我们的方法实现了更稳定的训练，并且在推理步骤中具有较少的令牌，可以进行更稳定或卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.15952</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索性研究认知扭曲与情感评估之间的关系</title>
      <link>https://arxiv.org/abs/2503.15979</link>
      <description><![CDATA[ARXIV：2503.15979V1公告类型：新 
摘要：近年来，从计算和心理学的角度研究认知扭曲和情感评估的兴趣越来越大。尽管情绪重新评估和认知反映与情绪调节技术之间的相似之处相似，但这些概念在很大程度上被孤立地研究了。这项研究探讨了认知扭曲与情绪评估维度之间的关系，研究了它们的潜在联系和与未来跨学科研究的相关性。以这个借口，我们进行了一项探索性计算研究，旨在研究认知失真与情绪评估之间的关系。我们表明，认知扭曲和评估维度之间具有统计学意义的关系的模式在不同的扭曲类别之间有所不同，从而产生了单个失真类别的不同评估概况。此外，我们分析了认知重组对评估维度的影响，体现了认知重组的情绪调节方面。]]></description>
      <guid>https://arxiv.org/abs/2503.15979</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>