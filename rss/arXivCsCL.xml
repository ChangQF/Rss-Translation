<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Tue, 02 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于理由的意见总结</title>
      <link>https://arxiv.org/abs/2404.00217</link>
      <description><![CDATA[arXiv:2404.00217v1 公告类型：新
摘要：意见摘要旨在生成简洁的摘要，呈现大量评论的流行观点。然而，这些摘要可能过于笼统并且缺乏支持细节。为了解决这些问题，我们提出了一种新的综述范式，即基于理由的意见总结。基于理由的意见摘要输出代表性意见以及一个或多个相应的理由。为了提取良好的基本原理，我们定义了四个理想的属性：相关性、特异性、流行性和多样性，并提出了一种基于吉布斯抽样的方法来提取基本原理。总的来说，我们提出了 RATION，一个无监督的提取系统，它有两个组件：意见提取器（用于提取代表性意见）和理由提取器（用于提取相应的理由）。我们进行自动和人工评估，以表明 RATION 提取的基本原理具有所提出的属性，并且其摘要比传统摘要更有用。我们工作的实施可以在 https://github.com/leehaoyuan/RATION 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.00217</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:07 GMT</pubDate>
    </item>
    <item>
      <title>通过监督微调将新知识注入大型语言模型</title>
      <link>https://arxiv.org/abs/2404.00213</link>
      <description><![CDATA[arXiv:2404.00213v1 公告类型：新
摘要：近年来，大型语言模型（LLM）在生成类人文本方面表现出了卓越的性能，被证明是跨各种应用程序的宝贵资产。然而，调整这些模型以纳入新的、领域外的知识仍然是一个挑战，特别是对于模型知识截止日期之后发生的事实和事件。本文研究了监督微调（SFT）作为法学硕士知识注入方法的有效性，特别关注最近的体育赛事领域。我们比较不同的数据集生成策略（基于标记和基于事实的缩放），以创建帮助模型学习新信息的训练数据。我们在 GPT-4 上的实验表明，虽然基于令牌的扩展可以提高问答准确性，但它可能无法提供新知识的统一覆盖。另一方面，基于事实的扩展提供了一种更系统的方法来确保均匀覆盖所有事实。我们提出了一种新颖的数据集生成过程，可以通过 SFT 更有效地获取知识，我们的结果表明，与域外知识相关的问答任务的性能得到了显着提高。这项研究有助于理解法学硕士的领域适应，并强调了 SFT 在增强特定知识领域法学硕士回答的真实性方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.00213</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:06 GMT</pubDate>
    </item>
    <item>
      <title>事实解码对法学硕士来说是免费午餐吗？知识编辑基准评估</title>
      <link>https://arxiv.org/abs/2404.00216</link>
      <description><![CDATA[arXiv:2404.00216v1 公告类型：新
摘要：大型语言模型（LLM）的快速发展使它们能够以更类似于人类的方式传达事实知识。通过修改具有事实解码功能的法学硕士，人们做出了广泛的努力来减少事实幻觉。然而，它们也带来了阻碍知识更新的风险，因为它们使模型对已知事实过于自信。在这项工作中，我们首先重新审视当前的事实解码方法，并验证它们在提高事实准确性方面的有效性。随后，我们在知识编辑基准上对几种强事实性解码方法进行了进一步评估。与原始解码相比，所有这些解码方法都显着降低了 llama2 模型的性能，最大降幅达到惊人的 81.3%。这进一步表明，当前现有的解码方法仍然无法完美解决事实幻觉，因为它们忽视了保留知识编辑灵活性的重要性。因此，我们的工作表明，对事实对齐的研究应同时关注知识编辑的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.00216</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:06 GMT</pubDate>
    </item>
    <item>
      <title>EventGround：基于以事件为中心的知识图谱进行叙事推理</title>
      <link>https://arxiv.org/abs/2404.00209</link>
      <description><![CDATA[arXiv:2404.00209v1 公告类型：新
摘要： 叙事推理依赖于对故事背景中可能发生的事件的理解，这需要丰富的背景世界知识。为了帮助机器利用这些知识，现有的解决方案可以分为两类。有些人专注于通过预训练具有偶发性感知目标的语言模型 (LM) 来隐式建模偶发性知识。然而，这种方法破坏了知识结构并且缺乏可解释性。其他人明确地将有关偶发事件的世界知识收集到结构化的以偶发事件为中心的知识图（KG）中。然而，现有的利用这些知识源获取自由文本的研究是有限的。在这项工作中，我们提出了一个名为 EventGround 的初步综合框架，旨在解决将自由文本扎根于以事件为中心的知识图谱以进行情境化叙事推理的问题。我们在这个方向上确定了两个关键问题：事件表示和稀疏性问题。我们提供简单而有效的解析和部分信息提取方法来解决这些问题。实验结果表明，当与基于图神经网络（GNN）或大语言模型（LLM）的图推理模型相结合时，我们的方法始终优于基线模型。我们的框架结合了扎实的知识，在提供可解释的证据的同时实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.00209</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:05 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的多条件排名</title>
      <link>https://arxiv.org/abs/2404.00211</link>
      <description><![CDATA[arXiv:2404.00211v1 公告类型：新
摘要：利用大型语言模型（LLM）对一组项目进行排名已成为推荐和检索系统中的常见方法。通常，这些系统专注于根据给定查询以单调顺序对大量文档进行排序。然而，现实世界的场景通常会带来不同的挑战：对相对较小的一组项目进行排名，但要根据各种不同且偶尔发生冲突的条件。在本文中，我们通过引入 MCRank 来定义和探索多条件排名的任务，MCRank 是一个为评估各种项目类型和条件的多条件排名而定制的基准。我们使用 MCRank 对法学硕士的分析表明，随着项目和条件的数量和复杂性的增加，其表现会显着下降。为了克服这个限制，我们提出了一种新颖的分解推理方法，包括对条件进行提取和排序，然后对项目进行迭代排名（EXSIR）。我们的大量实验表明，这种分解推理方法显着提高了法学硕士的表现，比现有法学硕士的性能提高了 12%。我们还对各种条件类别的法学硕士表现进行了详细分析，并检查了分解步骤的有效性。此外，我们将我们的方法与现有的方法（例如思想链和编码器类型排序模型）进行比较，证明了我们的方法的优越性和 MCR 任务的复杂性。我们发布了我们的数据集和代码。]]></description>
      <guid>https://arxiv.org/abs/2404.00211</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:05 GMT</pubDate>
    </item>
    <item>
      <title>GPTA：与法学硕士协同下游神经网络增强的生成提示调整助手</title>
      <link>https://arxiv.org/abs/2404.00189</link>
      <description><![CDATA[arXiv:2404.00189v1 公告类型：新
摘要：本研究介绍了大型语言模型辅助训练框架 GPTA，该框架通过前缀提示增强下游任务模型的训练。通过最大限度地减少 LLM 的数据暴露，该框架解决了在下游任务模型训练中应用 LLM 的安全和法律挑战。 GPTA 采用新的协同训练方法，通过参数梯度优化下游模型，并通过新颖的“对话梯度”优化法学硕士。该框架不仅在六个 NLP 基准数据集上展示了模型性能的显着改进，而且还有效减少了低资源场景下的过度拟合。详细的分析进一步验证了我们的先驱框架为在法学硕士支持下的下游任务模型训练提供了一种经济高效且适应性强的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.00189</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:04 GMT</pubDate>
    </item>
    <item>
      <title>语言模型中的概念和无偏推理</title>
      <link>https://arxiv.org/abs/2404.00205</link>
      <description><![CDATA[arXiv:2404.00205v1 公告类型：新
摘要：概念推理，即从抽象和高层次角度进行推理的能力，是人类认知泛化的关键。然而，对大型语言模型执行概念推理的能力的研究有限。在这项工作中，我们弥合了这一差距，并提出了一种新颖的概念化框架，该框架迫使模型对抽象问题进行概念推理，并在可验证的符号空间中生成解决方案。使用这个框架作为分析工具，我们发现现有的大型语言模型在概念推理方面存在不足，与直接推理方法相比，在各种基准测试中下降了 9% 到 28%。然后我们讨论模型如何改进，因为高级抽象推理是公正和可概括决策的关键。我们提出了两种技术来添加可信的归纳信号，即通过生成具有相似底层推理路径的熟悉问题并要求模型执行自我改进。实验表明，我们提出的技术将模型的概念推理性能提高了 8% 到 11%，实现了更少依赖归纳偏差的更稳健的推理系统。]]></description>
      <guid>https://arxiv.org/abs/2404.00205</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:04 GMT</pubDate>
    </item>
    <item>
      <title>人类语言模型协作的因果推理</title>
      <link>https://arxiv.org/abs/2404.00207</link>
      <description><![CDATA[arXiv:2404.00207v1 公告类型：新
摘要：在本文中，我们研究了人类和语言模型 (LM) 之间的协作动态，其中交互通常涉及 LM 提出文本片段以及人类编辑或响应这些建议。在这种情况下，人类与语言模型的有效互动需要从人类与语言模型的历史交互中辨别出有效的基于文本的交互策略，例如编辑和响应风格。这一目标本质上是因果关系，由反事实的“假设”问题驱动：如果人类采用不同的文本编辑/细化策略，协作的结果将如何变化？回答这个因果推理问题的一个关键挑战是制定适当的因果估计值：传统的平均治疗效果（ATE）估计值由于其高维度而不适用于基于文本的治疗。为了解决这个问题，我们引入了一种新的因果估计量——增量文体效应（ISE）——它描述了将文本无限地转向特定风格（例如增加正式性）的平均影响。我们建立了ISE非参数辨识的条件。在此基础上，我们开发了 CausalCollab，一种旨在估计动态人类与LM 协作中各种交互策略的 ISE 的算法。我们对三种不同的人类与 LM 协作场景的实证调查表明，CausalCollab 有效减少了混杂因素，并显着改进了对一组竞争基线的反事实估计。]]></description>
      <guid>https://arxiv.org/abs/2404.00207</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:04 GMT</pubDate>
    </item>
    <item>
      <title>Word Ladders：用于语义数据收集的移动应用程序</title>
      <link>https://arxiv.org/abs/2404.00184</link>
      <description><![CDATA[arXiv:2404.00184v1 公告类型：新
摘要：Word Ladders 是一款适用于 Android 和 iOS 的免费移动应用程序，开发用于收集语言数据，特别是抽象项目 (ERC-2021-STG-101039777) 中通过分类包含的语义关系相互关联的单词列表。我们在此概述 Word Ladders，解释其游戏逻辑、动机和预期结果以及在 nlp 任务以及认知科学开放问题调查中的应用]]></description>
      <guid>https://arxiv.org/abs/2404.00184</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:03 GMT</pubDate>
    </item>
    <item>
      <title>DataAgent：评估大型语言模型回答零样本自然语言查询的能力</title>
      <link>https://arxiv.org/abs/2404.00188</link>
      <description><![CDATA[arXiv:2404.00188v1 公告类型：新
摘要：分析数据集和提取有意义信息的传统过程通常既耗时又费力。之前的工作已将手动、重复编码和数据收集确定为阻碍数据科学家开展更细致的工作和高水平项目的主要障碍。为了解决这个问题，我们将 OpenAI 的 GPT-3.5 评估为“语言数据科学家”（LDS），它可以从给定的数据集中推断出关键发现，包括相关性和基本信息。该模型在一组不同的基准数据集上进行了测试，以评估其跨多个标准的性能，包括涉及 NumPy、Pandas、Scikit-Learn 和 TensorFlow 等库的基于数据科学代码生成的任务，并且在正确回答问题方面取得了广泛成功。给定与基准数据集相关的数据科学查询。 LDS 使用各种新颖的提示工程技术来有效回答给定问题，包括思想链强化和 SayCan 提示工程。我们的研究结果表明，利用大型语言模型进行低级、零样本数据分析具有巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.00188</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:03 GMT</pubDate>
    </item>
    <item>
      <title>个体文本语料库预测开放性、兴趣、知识和教育水平</title>
      <link>https://arxiv.org/abs/2404.00165</link>
      <description><![CDATA[arXiv:2404.00165v1 公告类型：新
摘要：在这里，我们研究是否可以从个人谷歌搜索历史中预测体验开放性的个性维度。通过网络抓取，从 214 名参与者中生成了个人文本语料库 (IC)，平均包含 500 万个单词标记。我们训练了 word2vec 模型，并使用每个 IC 的相似性来标记单词，这些单词源自个性的词汇方法。这些 IC-标签-单词相似性被用作神经模型中的预测特征。为了进行训练和验证，我们依赖 179 名参与者，并提供了 35 名参与者的测试样本。进行了具有不同数量的预测特征、隐藏单元和增强因子的网格搜索。作为模型选择标准，我们在验证样本中使用 R2，并受到训练和验证之间绝对 R2 差异的惩罚。所选的神经模型解释了测试样本中 35% 的开放性方差，而具有相同架构的集成模型通常对智力兴趣、人文知识和教育水平提供稍微更稳定的预测。最后，学习曲线分析表明，需要大约 500 名培训参与者才能进行普遍预测。我们讨论 IC 作为基于调查的心理诊断的补充或替代。]]></description>
      <guid>https://arxiv.org/abs/2404.00165</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:02 GMT</pubDate>
    </item>
    <item>
      <title>LSCD 基准：历时词义任务的测试平台</title>
      <link>https://arxiv.org/abs/2404.00176</link>
      <description><![CDATA[arXiv:2404.00176v1 公告类型：新
摘要：词汇语义变化检测（LSCD）是一项复杂的引理级任务，通常基于两个随后应用的用法级任务进行操作：首先，为用法对导出上下文中的单词（WiC）标签。然后，这些标签以图表的形式表示，在图表中应用词义归纳 (WSI) 来导出义簇。最后，LSCD 标签是通过比较一段时间内的意义簇而得出的。这种模块化反映在大多数 LSCD 数据集和模型中。它还导致建模选项和任务定义存在很大的异质性，而各种数据集版本、预处理选项和评估指标又加剧了这种异质性。这种异质性使得在可比条件下评估模型、选择最佳模型组合或重现结果变得困难。因此，我们提供了一个标准化 LSCD 评估的基准存储库。通过透明的实施，结果可以轻松重现，并且通过标准化，可以自由组合不同的组件。该存储库通过允许对 WiC、WSI 和 LSCD 进行模型评估来反映任务的模块化。这允许仔细评估日益复杂的模型组件，提供模型优化的新方法。]]></description>
      <guid>https://arxiv.org/abs/2404.00176</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:02 GMT</pubDate>
    </item>
    <item>
      <title>你从哪来？让我猜猜！索拉尼库尔德语语音的子方言识别</title>
      <link>https://arxiv.org/abs/2404.00124</link>
      <description><![CDATA[arXiv:2404.00124v1 公告类型：新
摘要：由于需要公开数据集或可靠的资源（例如社交媒体或数据收集网站），对索拉尼库尔德子方言进行分类提出了挑战。为了解决这个问题，我们对各个城市和村庄进行了实地考察，与不同年龄层、性别、学术背景和职业的母语人士建立了联系。我们在参与涵盖生活方式、背景历史、爱好、兴趣、假期和人生教训等不同主题的对话时记录了他们的声音。研究的目标地区是伊拉克库尔德斯坦地区。结果，我们积累了 107 次采访的 29 小时 16 分 40 秒的录音，构成了包含 6 个子方言的不平衡数据集。随后，我们采用了三种深度学习模型：ANN、CNN 和 RNN-LSTM。我们探索了各种配置，包括不同的轨道持续时间、数据集分割和不平衡数据集处理技术（例如过采样和欠采样）。进行了两百二十五（225）次实验，并对结果进行了评估。结果表明，RNN-LSTM 的准确率达到 96%，优于其他方法。 CNN 的准确率达到 93%，ANN 的准确率达到 75%。当应用于平衡数据集时，主要是当我们遵循过采样方法时，所有三个模型都表现出了改进的性能。未来的研究可以探索更多的未来研究方向，包括其他库尔德方言。]]></description>
      <guid>https://arxiv.org/abs/2404.00124</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:01 GMT</pubDate>
    </item>
    <item>
      <title>对阴谋叙事进行大规模分类：误报和错误连接</title>
      <link>https://arxiv.org/abs/2404.00141</link>
      <description><![CDATA[arXiv:2404.00141v1 公告类型：新
摘要：网络讨论经常涉及阴谋论，这可能会导致人们对阴谋论的信仰泛滥。然而，并非所有围绕阴谋论的讨论都在宣扬阴谋论，因为有些讨论的目的是揭穿阴谋论。现有的研究依赖于简单的代理或专注于一组有限的信号来识别阴谋论，这限制了我们对不同主题和在线社区的阴谋讨论的理解。这项工作根据作者对阴谋信仰的观点建立了一个对与阴谋论相关的讨论进行分类的总体方案，可以通过代理人、行动或目标等叙事元素明确表达，也可以通过引用已知理论隐式表达。例如化学尾迹或新世界秩序。我们利用人类标记的真实数据来训练基于 BERT 的模型，用于对在线 CT 进行分类，然后将其与用于检测在线阴谋内容的生成式预训练 Transformer 机 (GPT) 进行比较。尽管 GPT 在表达能力和语境理解方面具有众所周知的优势，但我们的研究揭示了其逻辑推理的重大缺陷，同时也证明了我们的分类器的类似优势。我们使用来自最活跃的阴谋相关 Reddit 论坛的帖子进行了首次大规模分类研究，发现只有三分之一的帖子被归类为正面帖子。这项研究揭示了大型语言模型在需要细致入微的上下文理解的任务中的潜在应用。]]></description>
      <guid>https://arxiv.org/abs/2404.00141</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:01 GMT</pubDate>
    </item>
    <item>
      <title>生物医学 NER 法学硕士的即时定义增强</title>
      <link>https://arxiv.org/abs/2404.00152</link>
      <description><![CDATA[arXiv:2404.00152v1 公告类型：新
摘要：尽管法学硕士具有一般能力，但他们在生物医学 NER 任务上仍然举步维艰，由于专业术语的存在和训练数据的缺乏，这些任务很困难。在这项工作中，我们着手通过一种新的知识增强方法，在有限的数据设置中提高生物医学 NER 的法学硕士表现，该方法结合了动态相关概念的定义。在此过程中，为了提供知识增强的试验台，我们对提示策略进行了全面的探索。我们的实验表明，定义增强对于开源和封闭式法学硕士都很有用。例如，它使我们所有（六个）测试数据集的 GPT-4 性能 (F1) 相对提高了 15%（平均）。我们进行了广泛的消融和分析，以证明我们的性能改进源于添加相关的定义知识。我们发现，仔细的提示策略也可以提高 LLM 的性能，使它们能够在少量设置中超越微调的语言模型。为了促进这个方向的未来研究，我们在 https://github.com/allenai/beacon 发布了我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2404.00152</guid>
      <pubDate>Tue, 02 Apr 2024 21:12:01 GMT</pubDate>
    </item>
    </channel>
</rss>