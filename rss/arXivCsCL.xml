<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Mon, 15 Jan 2024 03:15:47 GMT</lastBuildDate>
    <item>
      <title>一种从印度语 MT 任务的流行数据集中消除误译的方法。 （arXiv：2401.06398v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06398</link>
      <description><![CDATA[利用计算机将内容从一种语言转换为另一种语言
系统被称为机器翻译（MT）。各种技术已经出现
确保有效的翻译保留上下文和词汇
源语言的解释。端到端神经机器翻译
（NMT）是一种流行的技术，现在广泛应用于现实世界的机器翻译中
系统。大量并行数据集（一种语言的句子
机器翻译系统需要翻译（以及另一个翻译）。这些数据集
对于机器翻译系统学习语言结构和模式至关重要
在训练阶段使用两种语言。 Samanantar 就是这样一个数据集，
印度语言 (IL) 最大的可公开访问的并行数据集。自从
该语料库是从各种来源收集的，其中包含许多不正确的内容
翻译。因此，使用该数据集构建的机器翻译系统无法执行
他们通常的潜力。在本文中，我们提出了一种算法来删除
训练语料库中的误译并评估其性能
效率。两种印度语言 (IL)，即印地语 (HIN) 和奥迪亚语 (ODI)
选择用于实验。为这两个 IL 构建了基线 NMT 系统，
还研究了不同数据集大小的影响。的质量
实验中的翻译是使用标准指标进行评估的，例如
蓝色、流星和肋骨。从结果中可以看出，去除
数据集的错误翻译可以提高翻译质量。它
还注意到，尽管 ILs-English 和 English-ILs
系统使用相同的语料库进行训练，ILs-English 的工作效率更高
涵盖所有评估指标。
]]></description>
      <guid>http://arxiv.org/abs/2401.06398</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:47 GMT</pubDate>
    </item>
    <item>
      <title>通过具有大型语言模型的 QA 链将视觉问答从合成问题推广到人类编写的问题。 （arXiv：2401.06400v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06400</link>
      <description><![CDATA[视觉问答（VQA）是一项给定图像和
询问一系列有关图像的问题。建立高效的VQA
算法，需要大量的QA数据，这是非常昂贵的。
基于模板生成综合 QA 对是一种实用的方法来获得
数据。然而，在这些数据上训练的 VQA 模型在复杂的、
人工编写的问题。为了解决这个问题，我们提出了一种新方法，称为
{\it 人工编写问题的 QA 链} (CoQAH)。 CoQAH 利用
大型语言模型和 VQA 模型之间的 QA 交互序列
对合成数据进行训练以推理并得出逻辑答案
人工编写的问题。我们测试了 CoQAH 对两种类型的有效性
人工编写的 3D 渲染和胸部 X 射线图像的 VQA 数据集，并发现
它在两种类型的数据上都达到了最先进的准确性。尤其，
CoQAH 的性能优于一般视觉语言模型、VQA 模型和医学模型
无需微调的基础模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.06400</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:47 GMT</pubDate>
    </item>
    <item>
      <title>我应该说什么？ -- 与人工智能和自然语言界面交互。 （arXiv：2401.06382v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2401.06382</link>
      <description><![CDATA[随着人工智能 (AI) 技术变得越来越普遍，
探索人类如何与人工智能互动变得越来越重要。
人机交互（HAI）子领域是从人机交互中兴起的
交互（HCI）领域，旨在检验这个概念。多互动
模式已在没有充分理解变化的情况下实施
所需的认知以及使用这些的认知科学含义
旨在本质上更加人性化的替代界面。先前的研究
表明心理理论表征对于成功和成功至关重要
毫不费力的沟通，然而当涉及到时却很少被理解
与人工智能交互时如何建立心理理论表征。
]]></description>
      <guid>http://arxiv.org/abs/2401.06382</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:46 GMT</pubDate>
    </item>
    <item>
      <title>用于方面情感四重预测的自适应数据增强。 （arXiv：2401.06394v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06394</link>
      <description><![CDATA[方面情感四元预测（ASQP）旨在预测四元情感
给定句子的元素，这是该领域的一项关键任务
基于方面的情感分析。但数据不平衡问题尚未解决
在ASQP任务中受到足够的重视。在本文中，我们将问题分为
分为两重、四元模式不平衡和方面类别不平衡，以及
提出自适应数据增强（ADA）框架来解决不平衡问题
问题。具体来说，具有条件函数的数据增强过程
自适应增强尾部四边形模式和方面类别，减轻
ASQP 中的数据不平衡。继之前的研究之后，我们还进一步探索
通过引入提取完整四边形的生成框架
类别先验知识和语法引导的解码目标。实验性的
结果表明，ASQP 任务中不平衡的数据增强可以
提高性能，并且所提出的 ADA 方法优于朴素数据
过采样。
]]></description>
      <guid>http://arxiv.org/abs/2401.06394</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:46 GMT</pubDate>
    </item>
    <item>
      <title>从半事实中学习：用于广义关系发现的去偏见和语义感知框架。 （arXiv：2401.06327v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06327</link>
      <description><![CDATA[我们引入了一项新颖的任务，称为广义关系发现（GRD），用于
开放世界关系提取。 GRD 旨在识别中未标记的实例
现有的预定义关系或通过分配发现新的关系
实例到集群以及为这些实例提供特定含义
集群。 GRD的关键挑战是如何缓解严重模型
由标记的预定义关系引起的偏差，以学习有效的关系
表示以及如何确定新关系的具体语义
在对未标记实例进行分类或聚类期间。然后我们提出一部小说
SFGRD 框架，该任务通过学习来解决上述问题
半事实分两个阶段。第一阶段是半事实生成
由三视图去偏关系表示模块实现，其中我们
以每个原句为主视图，设计两个偏向视图
为这句话生成半事实示例。第二阶段是
双空间三视图协作关系执行的半事实思维
学习模块，我们设计一个聚类语义空间和一个类别索引
分别学习关系语义和关系标签索引的空间。
此外，我们还设计了对齐和选择策略来整合两个
空间并为未标记数据建立一个自我监督的学习循环
跨三种观点进行半事实思考。广泛的实验结果
表明 SFGRD 在准确性方面超越了最先进的模型
2.36\% $\sim$5.78\% 和余弦相似度 32.19\%$\sim$ 84.45\% 关系
分别是标签索引和关系语义质量。尽我们最大的努力
知识，我们是第一个利用半事实的功效
关系提取。
]]></description>
      <guid>http://arxiv.org/abs/2401.06327</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:45 GMT</pubDate>
    </item>
    <item>
      <title>约翰尼如何说服法学硕士越狱：重新思考通过人性化法学硕士来说服挑战人工智能安全。 （arXiv：2401.06373v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06373</link>
      <description><![CDATA[大多数传统人工智能安全研究都将人工智能模型视为机器和
以安全专家开发的以算法为中心的攻击为中心。一样大
语言模型（LLM）变得越来越普遍和有能力，非专家
用户还可以在日常交互中施加风险。本文介绍了一个
越狱法学硕士作为类人沟通者的新视角，以探索这一点
忽视了日常语言交互和人工智能安全之间的交叉点。
具体来说，我们研究如何说服法学硕士越狱。首先，我们
提出了一种源自数十年社会科学研究的说服分类法。
然后，我们应用分类法自动生成可解释的有说服力的内容
对抗性提示（PAP）越狱法学硕士。结果表明，说服力
显着提高所有风险类别的越狱性能：
PAP 在 Llama 2-7b 上持续实现超过 $92\%$ 的攻击成功率
Chat、GPT-3.5 和 GPT-4 正在进行 10 美元的试验，超越了最近以算法为中心的
攻击。在防御方面，我们探索针对 PAP 的各种机制，并且，
发现现有防御措施存在重大差距，并主张采取更根本的措施
高度互动的法学硕士的缓解措施
]]></description>
      <guid>http://arxiv.org/abs/2401.06373</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:45 GMT</pubDate>
    </item>
    <item>
      <title>用于系统评论筛选自动化的零样本生成大型语言模型。 （arXiv：2401.06320v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.06320</link>
      <description><![CDATA[系统评价对于循证医学至关重要，因为它们
全面分析已发表的针对特定问题的研究成果。
进行此类审查通常需要大量资源和时间，尤其是在
筛选阶段，评估出版物摘要是否纳入
在评论中。本研究调查了使用零样本大样本的有效性
用于自动筛选的语言模型〜（LLM）。我们评估有效性
八个不同的法学硕士并研究了一种使用
预定义的召回阈值来确定出版物是否应该被
纳入系统评价。我们综合评价五项
标准测试集表明指令微调起着重要作用
在筛选中的作用，校准使法学硕士对于实现
有针对性的召回，并将两者与零样本模型集合相结合
与最先进的方法相比，可以节省大量筛选时间。
]]></description>
      <guid>http://arxiv.org/abs/2401.06320</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:44 GMT</pubDate>
    </item>
    <item>
      <title>TTS 前端文本处理的多任务学习。 （arXiv：2401.06321v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06321</link>
      <description><![CDATA[我们提出了一种多任务学习（MTL）模型，用于联合执行三个任务
文本转语音 (TTS) 前端通常解决的任务：文本
标准化 (TN)、词性 (POS) 标记和同形异义词消歧
（高清）。我们的框架采用树状结构，其主干可以学习
共享表示，然后是单独的特定任务负责人。我们进一步
结合预先训练的语言模型来利用其内置的词汇和
上下文知识，并研究如何最好地使用其嵌入，以便最大程度地
有效地使我们的多任务模型受益。通过任务明智的消融，我们展示了
我们在所有三项任务上训练的完整模型达到了最强的整体水平
与在单个或子组合上训练的模型相比的性能
任务，证实了我们的 MTL 框架的优势。最后，我们介绍一个
新的高清数据集包含不同上下文中均衡数量的句子
各种同形异义词及其发音。我们证明
将此数据集纳入训练可显着提高 HD 性能
而不是仅使用常用但不平衡的预先存在的数据集。
]]></description>
      <guid>http://arxiv.org/abs/2401.06321</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:44 GMT</pubDate>
    </item>
    <item>
      <title>LLM情境学习中基于不信任的示范选择。 （arXiv：2401.06301v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06301</link>
      <description><![CDATA[使用大型语言模型 (LLM) 进行的情境学习擅长适应
快速完成各种任务。然而，它的成功取决于精心选择
示威活动，这在实践中仍然是一个障碍。目前的方法
这个问题要么依赖于难以获得的外部监督，要么需要
与LLM的频繁互动，导致成本高昂。我们提出一个新的
称为上下文反射（ICR）的方法可以克服这些挑战。 ICR
战略性地选择示威活动，以减少与实际情况之间的差异
LLM 的输出和实际的输入输出映射。具体来说，ICR 启动
通过一组随机的初始演示，然后迭代地完善它。在
每一步，它都会分析候选示例池并识别其中的示例
最有可能挑战法学硕士当前的理解，以新的衡量标准
衡量标准称为错误信心。然后选择这些最令人困惑的例子
替换当前集中信息较少的演示。我们的
对包含 13 个子任务的 5 个不同数据集进行综合评估
显示了ICR的功效。与现有方法相比，ICR 实现了
平均性能提升 4%，同时展现出卓越的跨任务能力
泛化能力。
]]></description>
      <guid>http://arxiv.org/abs/2401.06301</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:43 GMT</pubDate>
    </item>
    <item>
      <title>超越表面：文本到图像生成中视觉刻板印象的全球范围分析。 （arXiv：2401.06310v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.06310</link>
      <description><![CDATA[最近的研究强调了刻板印象的问题
文本到图像 (T2I) 模型生成中不同身份群体的人。
然而，这些现有的方法有几个关键的局限性，包括
在评估中明显缺乏对全球身份群体的覆盖，以及
他们相关的刻板印象的范围。此外，他们往往缺乏
固有视觉刻板印象之间的关键区别，例如
“体重不足”或“宽边帽”，以及文化依赖性的刻板印象，例如
“有吸引力”或“恐怖分子”。在这项工作中，我们通过以下方法解决了这些限制
多方面的方法，利用现有的文本资源来奠定我们的基础
评估 T2I 模型生成的图像中的地理文化刻板印象。
我们利用现有的刻板印象基准来识别和评估视觉
全球范围内的刻板印象，涵盖 135 个国籍的身份群体。
我们证明刻板印象属性出现的可能性是原来的三倍
与其他属性相比，这些身份的图像。我们进一步
调查生成图像的描述有多么令人反感
对于不同的民族。最后，通过详细的案例研究，我们揭示了
所有身份群体的“默认”表示如何具有刻板印象
外貌。此外，对于南半球来说，具有不同属性的图像
即使在明确提示的情况下，它们在视觉上也相似。内容警告：
有些例子可能包含令人反感的刻板印象。
]]></description>
      <guid>http://arxiv.org/abs/2401.06310</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:43 GMT</pubDate>
    </item>
    <item>
      <title>学习无监督语义文档表示以进行基于方面的细粒度情感分析。 （arXiv：2401.06210v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.06210</link>
      <description><![CDATA[文档表示是许多机器上 NLP 任务的核心
理解。以无监督方式学习的一般表示
保留通用性，可用于各种应用。在实践中，
情感分析（SA）一直是一项具有挑战性的任务，被认为是
与语义深度相关，通常用于评估一般表示。
现有的无监督文档表示学习方法可以是
分为两个系列：顺序系列，明确采用
考虑单词的顺序和非顺序的单词，这不
明确地这样做。然而，他们俩都有自己的弱点。在
在本文中，我们提出了一个模型来克服两者遇到的困难
方法族。实验表明我们的模型优于
流行的 SA 数据集上最先进的方法和基于方面的细粒度
SA大幅领先。
]]></description>
      <guid>http://arxiv.org/abs/2401.06210</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:42 GMT</pubDate>
    </item>
    <item>
      <title>LEGOBench：科学模型的排行榜生成基准。 （arXiv：2401.06233v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06233</link>
      <description><![CDATA[论文提交量不断增加，让人难以留下来
了解最新的最先进的研究。为了应对这一挑战，
我们引入了 LEGOBench，这是一个评估生成系统的基准
排行榜。 LEGOBench 根据 22 年预印本提交数据整理而成
arXiv 和 PapersWithCode 中超过 11,000 个机器学习排行榜
门户网站。我们评估四种传统的基于图的排名的性能
变体和三个最近提出的大型语言模型。我们的初步
结果显示自动排行榜生成方面存在显着的性能差距。
该代码可在 https://github.com/lingo-iitgn/LEGOBench 上找到，
数据集托管于
https://osf.io/9v2py/?view_only=6f91b0b510df498ba01595f8f278f94c 。
]]></description>
      <guid>http://arxiv.org/abs/2401.06233</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:42 GMT</pubDate>
    </item>
    <item>
      <title>CrisisKAN：用于危机事件分类的知识注入和可解释的多模态注意网络。 （arXiv：2401.06194v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.06194</link>
      <description><![CDATA[社交媒体的普遍使用已成为实时信息的新兴来源
用于识别各种事件的信息（如图像、文本或两者）。尽管
基于图像和文本的事件分类的快速增长
最先进的（SOTA）模型发现弥合语义差距具有挑战性
由于编码不一致，图像和文本模态的特征之间存在差异。
此外，模型的黑盒性质无法解释模型的结果
在灾害、流行病等高风险情况下建立信任。
此外，对社交媒体帖子施加的字数限制可能会
引入对特定事件的偏见。为了解决这些问题，我们提出
CrisisKAN，一种新颖的注入知识且可解释的多模态注意力
将图像和文本与外部知识结合起来的网络
从维基百科对危机事件进行分类。丰富具体情境
为了理解文本信息，我们使用整合维基百科知识
提出的维基提取算法。除此之外，引导交叉注意力
模块的实现是为了填补视觉和视觉集成中的语义空白
文本数据。为了确保可靠性，我们采用特定于模型的
称为梯度加权类激活映射 (Grad-CAM) 的方法
为所提出的模型的预测提供了强有力的解释。这
对 CrisisMMD 数据集进行的综合实验产生了深入的结果
跨各种危机特定任务和环境的分析。因此，
CrisisKAN 优于现有的 SOTA 方法，并提供了一种新颖的观点
可解释的多模式事件分类领域。
]]></description>
      <guid>http://arxiv.org/abs/2401.06194</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:41 GMT</pubDate>
    </item>
    <item>
      <title>EASYTOOL：通过简洁的工具说明增强基于 LLM 的代理。 （arXiv：2401.06201v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06201</link>
      <description><![CDATA[为了解决复杂的现实世界任务，人们对
大型语言模型（LLM）应用中的工具利用。发展
基于LLM的代理，通常需要LLM了解很多工具功能
来自不同的工具文档。但这些文件可能多种多样，
冗余或不完整，这极大地影响了法学硕士的能力
使用工具。为了解决这个问题，我们引入了EASYTOOL，一个转换框架
将多样化且冗长的工具文档转化为统一而简洁的工具
更轻松地使用工具的说明。 EasyTool 从中纯化重要信息
不同来源的广泛工具文档，并阐述了统一的
接口（即工具指令）提供标准化的工具描述和
基于 LLM 的代理的功能。多个方面进行了广泛的实验
不同的任务表明EasyTool可以显着减少token
消耗并提高现实世界中工具利用的性能
场景。我们的代码将在
\url{https://github.com/microsoft/JARVIS/} 将来。
]]></description>
      <guid>http://arxiv.org/abs/2401.06201</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:41 GMT</pubDate>
    </item>
    <item>
      <title>使用 Bark、mBART 和经过微调的 XLSR Wav2Vec2 进行端到端印地语到英语语音转换。 （arXiv：2401.06183v1 [eess.AS]）</title>
      <link>http://arxiv.org/abs/2401.06183</link>
      <description><![CDATA[言语长期以来一直是有效沟通和联系的障碍，
在我们这个日益互联的世界中，这一直是一个挑战。这
研究论文介绍了解决这一持续障碍的变革性解决方案
专为印地语到英语定制的端到端语音转换框架
翻译，最终合成英语音频。通过整合
用于自动语音的 XLSR Wav2Vec2 等尖端技术
识别 (ASR)、用于神经机器翻译 (NMT) 的 mBART 以及
文本到语音（TTS）合成组件，该框架提供了一个统一的、
无缝的跨语言沟通方法。我们深入研究错综复杂的
每个组成部分的详细信息，阐明其各自的贡献和
探索能够实现从印地语到口语的流畅过渡的协同作用
合成的英语音频。
]]></description>
      <guid>http://arxiv.org/abs/2401.06183</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:40 GMT</pubDate>
    </item>
    </channel>
</rss>