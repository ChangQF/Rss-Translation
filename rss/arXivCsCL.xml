<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Thu, 21 Dec 2023 06:18:22 GMT</lastBuildDate>
    <item>
      <title>微调大型语言模型以实现自适应机器翻译。 （arXiv：2312.12740v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12740</link>
      <description><![CDATA[本文介绍了 Mistral 7B（通用型）的微调结果
大语言模型 (LLM)，用于自适应机器翻译 (MT)。这
微调过程涉及利用零样本和单样本的组合
医学领域内的翻译提示。主要目标是
增强Mistral 7B的实时自适应MT能力，使其能够适应
在推理时翻译到所需的域。结果，
特别是对于西班牙语到英语的机器翻译，展示微调的功效
模型，展示了零样本和单样本的质量改进
翻译场景，超越了 Mistral 7B 的基准性能。尤其，
经过微调的 Mistral 在零射击方面优于 ChatGPT“gpt-3.5-turbo”
翻译，同时实现可比的一次性翻译质量。而且，
经过微调的 Mistral 的零射击平移与 NLLB 3.3B 相匹配
性能，一次性翻译质量超过NLLB 3.3B。
这些发现强调了微调高效法学硕士的重要性，例如
Mistral 7B 产生的高质量零样本翻译可与
面向任务的模型，例如 NLLB 3.3B。此外，获得的自适应增益
一次性翻译可与商业法学硕士相媲美，例如
聊天GPT。我们的实验表明，使用相对较小的数据集
20,000 个片段，融合了零次和一次提示，
微调显着增强了 Mistral 的情境学习能力，
特别是对于实时自适应机器翻译。
]]></description>
      <guid>http://arxiv.org/abs/2312.12740</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>BloomVQA：评估分层多模态理解。 （arXiv：2312.12716v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.12716</link>
      <description><![CDATA[我们提出了一个新颖的 VQA 数据集，基于为以下目的而设计的图画故事
教育幼儿，旨在促进综合评估和
理解任务中视觉语言模型的表征。不像
当前的 VQA 数据集通常侧重于基于事实的记忆和简单的
在没有原则科学基础的推理任务中，我们收集数据
包含反映不同理解水平和基础的任务
认知过程，如布鲁姆分类法（一个经典框架）中所阐述的
广泛应用于教育研究。所提出的 BloomVQA 数据集可以是
映射到基于分层图的视觉故事表示，从而使
自动数据增强和表征模型一致性的新颖措施
跨越基础分类法。我们展示分级评估和
基于我们提出的一致性指标的可靠性分析
最先进的视觉语言模型。我们的结果表明，虽然
当前的模型在低级理解任务上取得了最大的收益，它们
通常无法完成需要更高级理解的高级任务
和认知技能，相比之下，VQA 准确度下降了 38.0%
最低和最高级别的任务。此外，当前模型显示出一致性
在各种情况下，模式与人类的理解不一致，表明
模型行为的涌现结构。
]]></description>
      <guid>http://arxiv.org/abs/2312.12716</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>学习和忘记大型语言模型中的不安全示例。 （arXiv：2312.12736v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12736</link>
      <description><![CDATA[随着向公众发布的大型语言模型 (LLM) 数量的增长，
迫切需要了解与相关的安全影响
这些模型从第三方自定义微调数据中学习。我们探索
LLM 的行为针对包含不安全内容的嘈杂自定义数据进行了微调，
由包含偏见、毒性和危害性的数据集表示，发现
虽然一致的法学硕士可以很容易地学习这些不安全的内容，但他们也倾向于
当随后进行微调时，比其他示例更容易忘记它
关于更安全的内容。从遗忘的差异中汲取灵感，我们
引入“ForgetFilter”算法，该算法根据如何过滤不安全数据
模型的遗忘信号是针对该数据的。我们证明了
ForgetFilter算法确保定制微调的安全性，无需
与顺序安全微调不同，会损害下游任务性能。
ForgetFilter 的性能优于重放和道德等替代策略
自我纠正以遏制法学硕士在学习期间吸收不安全内容的能力
自定义微调，例如比不采取任何安全措施低 75%，比不采取任何安全措施低 62%
毒性评分低于使用自我校正。
]]></description>
      <guid>http://arxiv.org/abs/2312.12736</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>将以英语为中心的法学硕士转变为多语言者：需要多少多语言能力？ （arXiv：2312.12683v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12683</link>
      <description><![CDATA[当今绝大多数大型语言模型都是以英语为中心的，
主要接受过英文文本的预训练。然而，为了遇见
用户期望，模型需要能够在多种情况下做出适当的响应
一旦部署在下游应用程序中的语言。由于接触有限
在预训练期间使用其他语言，跨语言迁移对于
在非英语环境中取得不错的表现。在这项工作中，我们
研究在微调过程中需要多少多语言能力
在一系列任务和目标中引发强大的跨语言概括
语言。我们发现，与仅英语微调相比，多语言
仅需三种语言的指令调优即可显着提高
模型在生成任务上的跨语言迁移能力，假设
输入/输出语言协议，虽然对于高度
结构化任务。我们的代码和数据可在
https://github.com/ZurichNLP/multilingual-instruction-tuning。
]]></description>
      <guid>http://arxiv.org/abs/2312.12683</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>响应增强的半监督对话查询生成。 （arXiv：2312.12713v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12713</link>
      <description><![CDATA[利用来自互联网的大量且不断更新的知识已经
被认为是对话系统的重要能力。因此，对话
提出了查询生成任务，用于从对话中生成搜索查询
历史记录，将提交给搜索引擎以检索相关
互联网上的网站。对此，此前的努力
收集带有注释查询的对话并训练查询生成器
（QP）通过标准监督学习。然而，这些研究仍然面临着
数据稀缺和领域适应的挑战。为了解决这些问题，在
在本文中，我们提出了一个半监督学习框架——SemiDQG，
通过未标记的对话提高模型性能。基于
观察到搜索查询通常与对话主题相关
响应，我们训练一个响应增强查询生成器（RA）来提供丰富且
QP 的有效训练信号。我们首先应用基于相似性的查询
选择策略来选择高质量的 RA 生成的伪查询，其中
用于构建训练 QP 和 RA 的伪实例。那么，我们采用
REINFORCE算法进一步增强QP，RA提供的奖励为
细粒度的训练信号。实验结果和深入分析
三个基准测试显示了我们的框架在跨域和
资源匮乏的场景。特别是SemiDQG显着超越ChatGPT
和竞争基线。我们的代码位于
\url{https://github.com/DeepLearnXMU/SemiDQG}。
]]></description>
      <guid>http://arxiv.org/abs/2312.12713</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>模仿生命：生物启发设计的搜索引擎。 （arXiv：2312.12681v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12681</link>
      <description><![CDATA[生物启发设计 (BID) 或仿生学是一种解决问题的方法
应用自然类比来解决工程挑战的方法论。
例如，Speedo工程师根据鲨鱼皮设计了泳衣。寻找
针对现实世界问题的相关生物解决方案具有重要意义
挑战，既由于有限的生物学知识工程师和
设计人员通常拥有有限的 BID 资源。现有出价
数据集是手工整理的，而且规模很小，扩大规模需要昂贵的人力
注释。

在本文中，我们介绍了 BARcode（生物类比检索器），一种搜索
用于大规模自动从网络中挖掘生物灵感的引擎。使用
自然语言理解和数据编程、条形码的进展
确定工程挑战的潜在灵感。我们的实验
证明条形码可以检索有价值的灵感
工程师和设计师解决现实世界的问题，并恢复著名
历史 BID 示例。我们发布数据和代码；我们将条形码视为一个步骤
致力于解决历史上阻碍实际行动的挑战
BID在工程创新中的应用
]]></description>
      <guid>http://arxiv.org/abs/2312.12681</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>Mini-GPT：通过上下文修剪的高效大型语言模型。 （arXiv：2312.12682v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12682</link>
      <description><![CDATA[在人工智能研究中，大型语言模型（LLM）的优化仍然是一个
重大挑战，对于推进该领域的实际应用至关重要
和可持续性。以韩松教授的基础工作为基础
麻省理工学院实验室，本文介绍了一种通过以下方式开发 Mini-GPT 的新方法：
上下文修剪。我们的方法论战略性地修剪了计算
传统法学硕士的架构，如 Phi-1.5，侧重于保留核心
功能，同时大大减小模型尺寸。我们采用该技术
跨越多样化和复杂的数据集，包括美国法律、医学问答、Skyrim
对话、英台翻译、经济学文章。结果
强调上下文修剪的效率和有效性，而不仅仅是
作为一个理论概念，但作为开发特定领域的实用工具，
资源高效的法学硕士。上下文剪枝是一种很有前途的构建方法
特定领域的法学硕士，这项研究是未来的基石
通过更多的硬件计算、精细的微调和量化进行开发。
]]></description>
      <guid>http://arxiv.org/abs/2312.12682</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>MotionScript：富有表现力的 3D 人体动作的自然语言描述。 （arXiv：2312.12634v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.12634</link>
      <description><![CDATA[本文提出了 MotionScript，一种运动到文本的转换算法
人体动作的自然语言表示。 MotionScript 旨在
比以前更详细、更准确地描述动作
自然语言方法。许多运动数据集描述相对客观
以及表达方式几乎没有变化的简单动作（例如
坐着、行走、运球）。但对于包含
课堂上动作的多样性（例如悲伤、跳舞）或动作
标准动作捕捉数据集范围之外（例如风格行走、
手语），更具体和细致的自然语言描述是
需要。我们提出的 MotionScript 描述与现有的自然描述不同
语言表示，因为它提供了自然的直接描述
语言而不是简单的动作标签或高级人类字幕。至
据我们所知，这是将 3D 运动转化为
无需训练数据的自然语言描述。我们的实验
表明当 MotionScript 表示用于文本到运动神经网络时
任务、肢体动作更准确地重构、大语言
模型可用于生成看不见的复杂运动。
]]></description>
      <guid>http://arxiv.org/abs/2312.12634</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 可以在上下文中学习顺序函数类吗？ （arXiv：2312.12655v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.12655</link>
      <description><![CDATA[情境学习 (ICL) 彻底改变了 Transformer 的功能
NLP 中的模型。在我们的项目中，我们扩展了对机制的理解
通过探索 Transformer 是否可以从顺序学习中来支持 ICL，
非文本函数类数据分布。我们推出一种新颖的滑动
窗口顺序函数类并使用带有 GPT-2 的玩具大小的变压器
架构来进行我们的实验。我们的分析表明，这些
在非文本序列函数上训练时，模型确实可以利用 ICL
类。此外，我们使用随机 y 标签序列进行的实验
强调变压器保留了一些 ICL 功能，即使标签
关联被混淆了。我们提供证据证明变压器可以推理
并理解函数类中编码的顺序性，如所反映的
通过有效学习我们提出的任务。我们的结果还表明
性能随着标签随机性的增加而恶化，但并非如此
在人们可能期望的范围内，这意味着所学知识的潜在稳健性
针对标签噪声的顺序性。未来的研究可能想要研究如何
之前对变压器的解释，例如感应头和任务
在这些玩具示例中，向量与 ICL 中的顺序相关。我们的
调查为进一步研究变压器如何工作奠定了基础
处理和感知顺序数据。
]]></description>
      <guid>http://arxiv.org/abs/2312.12655</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>译后编辑真的比人工翻译快吗？ （arXiv：2312.12660v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12660</link>
      <description><![CDATA[时间效率对于本地化行业至关重要，这要求
更快的周转时间。然而，翻译速度很大程度上
研究不足，并且对于语言服务如何提供缺乏明确性
提供商 (LSP) 可以评估其译后编辑 (PE) 和
人工翻译 (HT) 服务。这项研究是第一个大规模
HT 和 PE 神经网络翻译和修订速度的研究
机器翻译，基于来自 LSP 的真实数据。它使用一个
用于调查 9000 万字数据的探索性数据分析方法
由 879 名语言学家跨 11 个语言对翻译，历时 2.5 年。这
这项研究的结果表明 (a) PE 通常但并不总是更快
比HT； (b) 平均速度值可能会产生误导； (c) 翻译速度为
高度可变； (d) 编辑距离不能用作
后期编辑生产力，因为它与速度没有很强的相关性。
]]></description>
      <guid>http://arxiv.org/abs/2312.12660</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>无监督神经机器翻译的实证研究：分析 NMT 输出、模型的行为和句子的贡献。 （arXiv：2312.12588v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12588</link>
      <description><![CDATA[无监督神经机器翻译 (UNMT) 专注于改进 NMT
假设没有人工翻译的并行数据的结果，但是
迄今为止，在强调其与相比之下的优势方面还没有做多少工作
监督方法并在翻译以外的方面分析其输出
准确性。我们专注于三种非常不同的语言：法语、古吉拉特语和
哈萨克语，并训练双语 NMT 模型，往返于英语，具有各种
在资源丰富和资源匮乏的情况下，监督水平可以衡量
NMT 输出并比较生成的序列的词序和语义
源句和参考句的相似性。我们还使用分层相关性
传播以评估源句子和目标句子对
结果，将先前工作的发现扩展到 UNMT 范式。
]]></description>
      <guid>http://arxiv.org/abs/2312.12588</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>利用领域知识指令集为 Odia 语言构建 Llama2 微调的法学硕士。 （arXiv：2312.12624v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12624</link>
      <description><![CDATA[由于以下原因，建立英语以外语言的法学硕士的需求量很大
多语言法学硕士的可用性和表现，例如了解
当地背景。这个问题对于资源匮乏的语言来说是至关重要的，因为
需要指令集。在印度这样的多语言国家，
需要支持印度语言的法学硕士提供生成式人工智能和基于法学硕士的
为其公民提供技术和服务。

本文介绍了我们的方法 i) 生成大型 Odia 指令
集，包括适合LLM微调的领域知识数据，以及ii)
构建专为增强 Odia 性能而定制的 Llama2 微调模型
领域。拟议的工作将帮助研究人员建立指令集并
法学硕士，特别是印度语言。我们将发布模型并
为公众研究和非商业目的而制定的指令集。
]]></description>
      <guid>http://arxiv.org/abs/2312.12624</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>实现更好的表格数据序列化以进行少样本分类。 （arXiv：2312.12464v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.12464</link>
      <description><![CDATA[我们提出了一项关于大型语言模型 (LLM) 集成的研究
表格数据分类，强调高效的框架。建立在
TabLLM (arXiv:2210.10723) 中所做的现有工作，我们介绍了三个新颖的
序列化技术，包括杰出的 LaTeX 序列化方法。
该方法显着提高了法学硕士的处理性能
特定领域的数据集，我们的方法因其内存效率而脱颖而出
充分利用复杂数据结构的能力。通过广泛
实验，包括各种序列化方法，例如特征
组合和重要性，我们展示了我们工作在准确性方面的优势
和效率高于传统模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.12464</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>用户为智能家居设备提供反馈的方法。 （arXiv：2312.12466v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2312.12466</link>
      <description><![CDATA[智能家居技术已经引起了人们的极大兴趣
人们的生活近来变得更加简单和轻松。
最近的技术带来了许多精明而精致的
促进巧妙生活创新的框架。在本文中，我们将
调查用户提供方法的行为意图
智能家居设备的反馈。我们将进行一项在线调查
通过简单随机抽样抽取三到五名学生进行研究
用户对智能家居设备及其使用情况提供反馈的座右铭
期望。我们观察到大多数用户都愿意分享他们的
积极反馈智能家居设备，提高智能家居的服务和质量
产品能够满足用户的需求，让他们的生活更轻松。
]]></description>
      <guid>http://arxiv.org/abs/2312.12466</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>当参数高效的调优遇到通用视觉语言模型时。 （arXiv：2312.12458v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12458</link>
      <description><![CDATA[指令调优已显示出广阔的开发潜力
通过使用大规模预训练模型和
推动不断发展的研究整合多模式信息以实现创意
应用程序。然而，现有的工作仍然面临两个主要限制：
全模型的训练成本和对计算资源的严重依赖
微调以及指令中缺乏语义信息，这
阻碍多模式对齐。针对这些挑战，本文提出
一种利用参数高效调整来实现通用目的的新方法
视觉语言模型，即PETAL。 PETAL 彻底改变了培训过程
通过独特的模式仅需要总参数的 0.5%
近似技术，显着降低了训练成本
对计算资源的依赖。此外，PETAL 增强了语义
通过两种创新方式提高指令深度：1）通过引入自适应
专家混合教学 (MOE)，以及 2) 通过强化基于分数的
参数有效调整和互信息之间的联系。我们的
五个多式联运下游基准的广泛实验表明
PETAL 不仅在大多数情况下都优于当前最先进的方法
而且在有效性上也超越了完全微调模型。此外，我们的
方法在少样本设置中表现出显着的优势，
全面的可视化分析。我们的源代码位于：
https://github。 com/melonking32/PETAL.
]]></description>
      <guid>http://arxiv.org/abs/2312.12458</guid>
      <pubDate>Thu, 21 Dec 2023 06:18:15 GMT</pubDate>
    </item>
    </channel>
</rss>