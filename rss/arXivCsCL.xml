<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 15 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>实现更好的人机协调：评估法学硕士支持的应用程序中的任务效用</title>
      <link>https://arxiv.org/abs/2402.09015</link>
      <description><![CDATA[arXiv:2402.09015v1 公告类型：新
摘要：大型语言模型（LLM）领域的快速发展导致了促进多个代理之间协作以协助人类完成日常任务的应用程序激增。然而，在评估 LLM 支持的应用程序是否真正增强用户体验和任务执行效率方面仍然存在重大差距。这凸显了对验证法学硕士应用程序实用性的方法的迫切需求，特别是通过确保应用程序的功能和最终用户需求之间的一致性。我们介绍 AgentEval 提供了数学问题的实现，这是一个新颖的框架，旨在通过自动提出一组针对任何给定应用程序的独特目的而定制的标准来简化实用程序验证过程。这样可以进行全面评估，根据建议的标准量化应用程序的效用。我们对量词工作的稳健性进行了全面分析。]]></description>
      <guid>https://arxiv.org/abs/2402.09015</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>SLEB：通过冗余验证和消除变压器块来简化法学硕士</title>
      <link>https://arxiv.org/abs/2402.09025</link>
      <description><![CDATA[arXiv:2402.09025v1 公告类型：新
摘要：大语言模型（LLM）已被证明在各种自然语言处理任务中非常有效。然而，它们的大量参数给实际部署带来了重大挑战。修剪是一种旨在减少 LLM 的规模和复杂性的技术，通过从网络中删除冗余组件来提供潜在的解决方案。尽管有修剪的希望，但现有方法通常难以实现大幅的端到端 LLM 推理加速。在本文中，我们介绍了 SLEB，这是一种旨在通过消除冗余变压器块来简化 LLM 的新颖方法。我们选择 Transformer 块作为剪枝的基本单元，因为 LLM 表现出块级冗余，相邻块的输出之间具有高度相似性。这一选择使我们能够有效提升LLM的处理速度。我们的实验结果表明，SLEB 成功地加速了 LLM 推理，而不会影响这些模型的语言能力，使其成为优化 LLM 效率的有前途的技术。代码位于：https://github.com/leapingjagg-dev/SLEB]]></description>
      <guid>https://arxiv.org/abs/2402.09025</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>用于鲁棒结构预测的结构化语言生成模型</title>
      <link>https://arxiv.org/abs/2402.08971</link>
      <description><![CDATA[arXiv:2402.08971v1 公告类型：新
摘要：我们提出了结构化语言生成模型（SLGM），它结合了新的损失函数和推理方法，以更好地泛化结构化输出。先前关于结构预测（例如 NER、RE）的研究利用了显式数据集信息，这可以提高性能，但可能对现实情况下的稳健泛化提出挑战。相反，我们的模型间接提供有关数据的通用格式信息。有了格式信息，我们可以通过损失校准和格式化解码将序列到序列问题简化为分类问题。我们的实验结果表明，SLGM 在没有数据集信息的情况下成功保持了性能，并且格式错误少得多。我们还展示了我们的模型可以像单个数据集上的适配器一样工作，无需额外的训练。]]></description>
      <guid>https://arxiv.org/abs/2402.08971</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>通过基于指令的提示进行多查询聚焦灾难总结</title>
      <link>https://arxiv.org/abs/2402.09008</link>
      <description><![CDATA[arXiv:2402.09008v1 公告类型：新
摘要：群体性突发事件的自动总结在灾害管理中发挥着至关重要的作用。 CrisisFACTS 第二版旨在基于多流事实调查推进灾难总结，重点关注 Twitter、Reddit、Facebook 和 Webnews 等网络资源。在这里，参与者被要求开发一个系统，可以从几个与灾难相关的事件中提取关键事实，最终作为总结。本文描述了我们解决这一具有挑战性的任务的方法。我们遵循之前的工作，并建议结合使用检索、重新排序和极其简单的指令跟踪摘要。两阶段检索管道依赖于 BM25 和 MonoT5，而摘要模块基于开源大型语言模型 (LLM) LLaMA-13b。作为总结，我们探索了一种问答（QA）驱动的提示方法，并找到了对于提取查询相关事实有用的证据。自动指标和人工评估显示出强劲的结果，但也凸显了开源系统和专有系统之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2402.09008</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>具有自我激励功能的大型语言模型的基于树的硬注意力</title>
      <link>https://arxiv.org/abs/2402.08874</link>
      <description><![CDATA[arXiv:2402.08874v1 公告类型：新
摘要：虽然大型语言模型（LLM）擅长理解和生成纯文本，但它们并不是专门为处理分层文本结构而定制的。从自然语言响应中提取任务所需的属性通常需要额外的处理步骤。事实上，有选择地理解大规模文本的层次结构对于理解其实质至关重要。通过提示将法学硕士与特定任务的分类或回归值更紧密地结合起来仍然具有挑战性。为此，我们提出了一种称为大型语言模型自我激励的基于树的硬注意力（TEAROOM）的新颖框架。 TEAROOM 结合了基于树的硬注意力机制，供法学硕士处理分层结构的文本输入。通过利用提示，它使冻结的法学硕士能够有选择地关注与根相关的相关叶子，生成它们关系的定制符号表示。此外，TEAROOM 还包括另一个配备可训练适配器和线性层的法学硕士的自我激励策略。选定的象征性结果与任务的预测价值一起​​集成到另一个提示中。我们迭代地将输出值反馈到提示中，使可训练的法学硕士能够逐步接近黄金真理。 TEAROOM 在三个基准数据集的实验评估中优于现有的最先进方法，显示了其在估计特定任务属性方面的有效性。通过全面的实验和分析，我们验证了TEAROOM通过多重推论逐步接近底层黄金真理的能力。]]></description>
      <guid>https://arxiv.org/abs/2402.08874</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>MaxMin-RLHF：实现大型语言模型与不同人类偏好的公平对齐</title>
      <link>https://arxiv.org/abs/2402.08925</link>
      <description><![CDATA[arXiv:2402.08925v1 公告类型：新
摘要：人类反馈强化学习（RLHF）通过采用从偏好数据派生的单一奖励模型，使语言模型与人类偏好保持一致。然而，这种方法忽视了从多个用户收集的数据中固有的人类偏好的丰富多样性。在这项工作中，我们首先得出了与单一奖励 RLHF 对齐的不可能结果，从而强调了它在代表不同人类偏好方面的不足。为了为问题提供公平的解决方案，我们通过期望最大化算法学习偏好分布的混合，并受社会选择理论中平等原则的启发，提出政策学习的 MaxMin 对齐目标，以更好地代表不同的人类偏好。我们阐明了我们提出的方法与分布鲁棒优化和通用强化学习的联系，从而强调了我们提出的解决方案的通用性和鲁棒性。我们提出了小规模（GPT-2）和大规模语言模型（使用 Tulu2-7B）的综合实验结果，并展示了所提出的方法在人类偏好存在多样性的情况下的有效性。我们的算法比传统 RLHF 算法的胜率平均提高了 16% 以上，并且在不影响多数群体表现的情况下，将少数群体的胜率（准确性）提高了 33% 以上，展示了我们的算法的稳健性和公平性。方法。我们指出，我们在这项工作中的发现不仅限于语言模型，而且还扩展到一般的强化学习。]]></description>
      <guid>https://arxiv.org/abs/2402.08925</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>学习为具体人工智能代理生成上下文敏感的反向微笑并应用于心理健康对话</title>
      <link>https://arxiv.org/abs/2402.08837</link>
      <description><![CDATA[arXiv:2402.08837v1 公告类型：新
摘要：解决有效筛查、诊断和治疗的精神卫生资源严重短缺问题仍然是一个重大挑战。这种稀缺凸显了对创新解决方案的需求，特别是在提高治疗支持的可及性和有效性方面。具有先进交互能力的实体代理成为传统护理方法的一种有前途且具有成本效益的补充。这些代理的有效性的关键在于它们模拟非语言行为的能力，例如反向渠道，这对于在治疗环境中建立融洽和理解至关重要，但仍尚未得到充分探索。为了提高实体代理建立融洽关系的能力，我们在有关心理健康、疾病和人际关系等话题的亲密面对面对话的视频中注释了秘密微笑。我们假设说话者和听者的行为都会影响秘密微笑的持续时间和强度。利用语音韵律和语言的线索以及说话者和听众的人口统计数据，我们发现它们包含了隐藏微笑强度的重要预测因素。根据我们的发现，我们将隐身代理中的反向微笑产生作为生成问题引入。我们基于注意力的生成模型表明，听众信息比以说话者为中心的基线生成方法提供了性能改进。使用微笑强度的显着预测因子进行的条件生成在生成质量的经验测量方面提供了统计上显着的改进。我们通过将生成的微笑转移到具体代理进行的用户研究表明，具有反向微笑的代理被认为更像人类，并且对于非个人对话而言，与没有反向微笑的代理相比，是一个有吸引力的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2402.08837</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>具有强大 ASR 能力的 LLM 极其简单的方法</title>
      <link>https://arxiv.org/abs/2402.08846</link>
      <description><![CDATA[arXiv:2402.08846v1 公告类型：新
摘要：在本文中，我们专注于利用语音基础编码器和大型语言模型（LLM）解决语音处理领域最重要的任务之一，即自动语音识别（ASR）。最近的工作具有复杂的设计，例如压缩语音编码器的输出时间、解决投影仪的模态对齐问题以及利用 LLM 的参数高效微调。我们发现，精致的设计是不必要的，而现成的语音编码器、LLM 和唯一可训练的线性投影仪的简单得令人尴尬的组合足以胜任 ASR 任务。更具体地说，我们对 LLM 和语音编码器的各种组合进行基准测试和探索，从而得到基于 LLM 的最佳 ASR 系统，我们称之为 SLAM-ASR。所提出的 SLAM-ASR 提供​​了一个干净的设置和很少的特定于任务的设计，其中仅训练线性投影仪。据我们所知，SLAM-ASR 在基于 LLM 的 ASR 模型中在 Librispeech 基准上实现了最佳性能，甚至优于最新的基于海量配对数据训练的基于 LLM 的音频通用模型。最后，我们探讨了基于LLM的ASR在模态对齐过程中的能力涌现。我们希望我们的研究能够促进以跨模态能力扩展法学硕士的研究，并为基于法学硕士的 ASR 社区带来光明。]]></description>
      <guid>https://arxiv.org/abs/2402.08846</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>基于音节的DNN-HMM粤语语音转文本系统</title>
      <link>https://arxiv.org/abs/2402.08788</link>
      <description><![CDATA[arXiv:2402.08788v1 公告类型：新
摘要：本文报告了我们使用基于音节的声学模型构建粤语语音到文本（STT）系统的工作。这是构建 STT 系统的努力的一部分，该系统旨在帮助那些在写作技能方面存在认知缺陷但可以通过言语表达自己的想法的诵读困难学生。对于粤语语音识别，声学模型的基本单位可以是传统的声母-韵母（IF）音节，也可以是起始-核心-尾音（ONC）音节，其中韵母进一步分为核心和尾音以反映音节内的情况粤语的变体。通过使用 Kaldi 工具包，我们的系统在 GPU 的帮助下使用随机梯度下降优化模型进行训练，用于混合深度神经网络和隐马尔可夫模型 (DNN-HMM)，有或没有基于 I 向量的说话人自适应训练技术。在所有情况下都使用具有说话者自适应训练 (GMM-SAT) 的相同高斯混合模型到 DNN 的输入特征。实验表明，基于ONC的音节声学建模与基于I向量的DNN-HMM实现了最佳性能，词错误率（WER）为9.66％，实时因子（RTF）为1.38812。]]></description>
      <guid>https://arxiv.org/abs/2402.08788</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>eCeLLM：从大规模、高质量的指令数据中泛化电子商务的大型语言模型</title>
      <link>https://arxiv.org/abs/2402.08831</link>
      <description><![CDATA[arXiv:2402.08831v1 公告类型：新
摘要：随着人们在开发有效的电子商务模型方面付出了巨大的努力，传统的电子商务模型在通用电子商务建模方面取得的成功有限，并且在新用户和新产品方面的表现不尽如人意，这是典型的域外泛化挑战。同时，大型语言模型（LLM）在许多领域的通才建模和域外泛化性方面表现出了出色的性能。为了充分释放它们对电子商务的力量，在本文中，我们构建了第一个开源、大规模、高质量的电子商务基准指令数据集ECInstruct。利用 ECInstruct，我们通过指令调整通用 LLM 开发了 eCeLLM，这是一系列电子商务 LLM。我们全面的实验和评估表明，eCeLLM 模型的性能大大优于基线模型，包括最先进的 GPT-4 和领域内评估中最先进的特定任务模型。此外，eCeLLM 对域外设置（包括未见过的产品和未见过的指令）表现出出色的泛化性，凸显了其作为通用电子商务模型的优越性。 ECInstruct 数据集和 eCeLLM 模型在为电子商务提供多功能且有效的法学硕士方面都显示出巨大的潜力。 ECInstruct 和 eCeLLM 模型可通过 https://ninglab.github.io/eCeLLM 公开访问。]]></description>
      <guid>https://arxiv.org/abs/2402.08831</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>用于检测非人化语言的数据集</title>
      <link>https://arxiv.org/abs/2402.08764</link>
      <description><![CDATA[arXiv:2402.08764v1 公告类型：新
摘要：非人化是一种心理过程，导致一群人被排斥和虐待。在本文中，我们提出了两个非人化文本数据集，一个大型的自动收集的语料库和一个较小的手动注释的数据集。这两个数据集都包含政治话语和电影字幕对话的组合。我们的方法为我们提供了广泛且多样化的非人化数据可供使用，从而能够对非人化模式进行进一步的探索性分析和自动分类。这两个数据集都将公开发布。]]></description>
      <guid>https://arxiv.org/abs/2402.08764</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>InstructGraph：通过以图为中心的指令调整和偏好调整来提升大型语言模型</title>
      <link>https://arxiv.org/abs/2402.08785</link>
      <description><![CDATA[arXiv:2402.08785v1 公告类型：新
摘要：当前的大型语言模型（LLM）是否可以通过参数更新更好地解决图推理和生成任务？在本文中，我们提出了 InstructGraph，这是一个框架，通过指令调整和偏好对齐赋予法学硕士以图形推理和生成的能力。具体来说，我们首先提出一种结构化格式语言器，将所有图数据统一为通用的类似代码的格式，它可以简单地表示图，而无需任何外部特定于图的编码器。此外，还引入了图形指令调整阶段来指导法学硕士解决图形推理和生成任务。最后，我们识别图任务中潜在的幻觉问题，并对负面实例进行采样以进行偏好对齐，其目标是增强模型输出的可靠性。跨多个以图为中心的任务的大量实验表明，InstructGraph 可以实现最佳性能，并且分别优于 GPT-4 和 LLaMA2 13\% 和 38\% 以上。]]></description>
      <guid>https://arxiv.org/abs/2402.08785</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>学习如何提问：循环一致性细化多模式基础模型中的提示</title>
      <link>https://arxiv.org/abs/2402.08756</link>
      <description><![CDATA[arXiv:2402.08756v1 公告类型：新
摘要：当法学硕士执行零样本推理时，他们通常使用带有任务规范的提示，并生成完成。然而，目前还没有工作来探索相反的可能性——从完成到任务规范。在本文中，我们采用两个方向来完全在上下文中执行循环监督学习。我们的目标是创建一个前向映射 f : X -&gt; Y （例如图像 -&gt; 生成的标题），再加上一个后向映射 g : Y -&gt; X （例如标题 -&gt; 生成的图像）​​来构建循环一致性“损失” “（作为提示的更新）强制执行 g(f(X)) ~= X。该技术称为 CyclePrompt，使用循环一致性作为自由监督信号来迭代地制作提示。重要的是，CyclePrompt 增强了模型性能，无需昂贵的微调，无需训练数据，也无需复杂的外部环境（例如编译器、API）。我们在两个领域演示了 CyclePrompt：代码生成和图像字幕。我们在 HumanEval 编码基准上的结果使我们在不依赖额外训练数据或外部环境使用的模型中排名第一，总体排名第三。与 GPT4 基线相比，我们将准确率从 80.5% 提高到 87.2%。在视觉语言空间中，我们生成的详细图像字幕在针对自然 (VQAv2) 和图解 (FigureQA) 视觉问答基准测试时优于基线零样本 GPT4V 字幕。据我们所知，这是首次使用自我监督学习进行提示。]]></description>
      <guid>https://arxiv.org/abs/2402.08756</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>JAMDEC：在小语言模型上使用约束解码进行无监督作者身份混淆</title>
      <link>https://arxiv.org/abs/2402.08761</link>
      <description><![CDATA[arXiv:2402.08761v1 公告类型：新
摘要：在线内容的持久性与增强的作者身份识别技术相结合，需要更强大的计算方法来在需要时保护在线作者的身份和隐私，例如科学论文的盲审、匿名在线评论或心理健康领域的匿名互动。论坛。在本文中，我们提出了一种无监督的推理时间方法来进行作者身份混淆，以解决作者身份混淆的独特挑战：缺乏不同作者身份和领域的监督数据，以及除了简单的释义之外还需要进行足够水平的修改来混淆作者身份，同时保留原始内容和流畅性。
  我们引入了 JAMDEC，这是一种用户控制的推理时间算法，用于作者身份混淆，原则上可以应用于任何文本和作者身份。我们的方法建立在 GPT2-XL 等小型语言模型的基础上，以帮助避免将原始内容泄露给专有的 LLM 的 API，同时还通过算法增强来缩小小型和大型语言模型之间的性能差距。我们的方法背后的关键思想是通过约束解码来提高较小语言模型的创造力，同时还允许用户指定的控制和灵活性。实验结果表明，我们基于 GPT2-XL 的方法优于之前基于相对较小模型的最先进方法，同时与 GPT3.5 175B（大两个数量级的专有模型）相比具有竞争力。]]></description>
      <guid>https://arxiv.org/abs/2402.08761</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>多步骤任务中的提示优化 (PROMST)：集成人类反馈和偏好调整</title>
      <link>https://arxiv.org/abs/2402.08702</link>
      <description><![CDATA[arXiv:2402.08702v1 公告类型：新
摘要：提示优化旨在为给定任务找到大型语言模型（LLM）的最佳提示。法学硕士已成功用于帮助寻找和改进单步任务的提示候选人。然而，代理人的实际任务是多步骤的，并带来了新的挑战：（1）提示内容可能更加广泛和复杂，使得法学硕士更难以分析错误，（2）单个步骤的影响很难评估，（3）不同的人对任务执行可能有不同的偏好。虽然人类努力优化提示，但他们擅长提供有关 LLM 输出的反馈；因此，我们引入了一种新的法学硕士驱动的离散提示优化框架，该框架结合了人工设计的有关潜在错误的反馈规则，以自动提供直接的改进建议。我们的框架被程式化为遗传算法，其中法学硕士根据父提示及其相关反馈生成新的候选提示；我们使用学习的启发式函数来预测即时表现，以有效地从这些候选者中进行抽样。这种方法在八个代表性多步骤任务中显着优于人工设计的提示和其他几种提示优化方法（与 GPT-3.5 和 GPT-4 上的当前最佳方法相比，平均分别提高了 27.7% 和 28.2%）。我们进一步表明，可以修改任务的评分函数以更好地符合个人偏好。我们相信我们的工作可以作为 LLM 驱动的多步骤任务自动提示优化的基准。数据集和代码可在 https://github.com/yongchao98/PROMST 获取。项目页面位于 https://yongchao98.github.io/MIT-REALM-PROMST。]]></description>
      <guid>https://arxiv.org/abs/2402.08702</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:34 GMT</pubDate>
    </item>
    </channel>
</rss>