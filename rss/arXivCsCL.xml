<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Wed, 13 Dec 2023 03:15:21 GMT</lastBuildDate>
    <item>
      <title>DYAD：线性神经网络层的描述性但令人厌恶的密度有效近似。 （arXiv：2312.06881v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.06881</link>
      <description><![CDATA[我们设计、实施并评估 DYAD，这是一个可以充当
线性层的更快、更节省内存的近似替换，
（Pytorch 中的 nn.Linear()）。这些层出现在常见的子组件中，例如
在 Transformers 的 ff 模块中。 DYAD 基于定制的近稀疏矩阵
近似于矩阵相乘的密集“权重”矩阵 W 的结构
此类层的典型实现中的输入，也称为 DENSE。我们的
另一种近稀疏矩阵结构可分解为 2 个矩阵之和
可置换为块稀疏对应物。这些可以表示为 3D
张量，它们一致允许更快地执行矩阵乘法
与 DENSE 相比的小批量输入矩阵 X (O(rows(W ) x cols(W )) --&gt;
O( 行(W ) x 列(W ) 块数))。作为我们实验的关键，我们
预训练 2 种尺寸的 OPT 拱门和 1 种尺寸的 DYAD 和 DENSE 变体
Pythia 架构，包括 BabyLM 基准的不同代币规模。
我们发现 DYAD 在零样本（例如，
BLIMP)、少样本 (OPENLM) 和微调 (GLUE) 基准，同时 &gt;=7-15%
即使在 125m 规模下，在 GPU 上训练的速度也更快，除了在
增加比例和模型宽度。
]]></description>
      <guid>http://arxiv.org/abs/2312.06881</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:21 GMT</pubDate>
    </item>
    <item>
      <title>在数学：渐进式纠正提示中获得 A。 （arXiv：2312.06867v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.06867</link>
      <description><![CDATA[思想链（CoT）提示方法启用了大型语言模型
（法学硕士）生成推理路径并解决数学应用题（MWP）。
然而，它们对路径中的错误很敏感，因为任何错误都可能导致
在一个错误的答案中。我们提出了一种名为渐进式的新方法
纠正提示 (PRP) 可提高八个 MWP 数据集的平均准确度
从 77.3 到 90.5。给定 CoT 的初始答案，PRP 迭代
验证然后纠正过程，逐步识别不正确的答案和
纠正推理路径。凭借最有可能的正确答案，法学硕士
预测问题中的屏蔽数值；如果预测没有
匹配掩码值，答案可能是不正确的。那么LLM是
提示重新生成推理路径暗示一组不正确的
答案以防止自己重复以前的错误。 PRP 达到了
与 CoT 方法相比具有最佳性能。我们的实现是
公开发布于 https://wzy6642.github.io/prp.github.io/。
]]></description>
      <guid>http://arxiv.org/abs/2312.06867</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:20 GMT</pubDate>
    </item>
    <item>
      <title>Dozerformer：用于多元时间序列预测的序列自适应稀疏变压器。 （arXiv：2312.06874v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.06874</link>
      <description><![CDATA[变形金刚在多元时间上取得了非凡的表现
系列（MTS）预测，因为它们能够捕捉长期
依赖关系。然而，规范注意力机制有两个关键
局限性：（1）其二次时间复杂度限制了序列长度，并且
(2)它从整个历史序列中生成未来值。讲话
为此，我们提出了一种由三个稀疏组成的Dozer Attention机制
组件： (1) 本地，每个查询专门关注一个中的键
相邻时间步长的局部窗口。 (2) Stride，使每个查询能够
按预定的时间间隔注意按键。 (3) Vary，允许有选择地查询
关注历史序列子集中的键。值得注意的是，尺寸
该子集随着预测范围的扩展而动态扩展。那三个
组件旨在捕获 MTS 数据的基本属性，包括
局部性、季节性和全局时间依赖性。此外，我们
提出 Dozerformer 框架，结合了 Dozer Attention 机制
用于 MTS 预测任务。我们评估了提议的 Dozerformer 框架
使用最近在九个基准数据集上最先进的方法并确认
其优越的性能。代码将在稿件发布后发布
公认。
]]></description>
      <guid>http://arxiv.org/abs/2312.06874</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:20 GMT</pubDate>
    </item>
    <item>
      <title>医疗时间序列和注释的多模式预训练。 （arXiv：2312.06855v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.06855</link>
      <description><![CDATA[在重症监护病房 (ICU) 内，有大量患者数据，包括
临床测量和临床记录很容易获得。这个数据是一个
了解患者健康状况和为医疗提供信息的宝贵资源
决策，但它也包含许多分析挑战。深度学习
模型在提取有意义的模式方面表现出了希望，但它们需要
大量的标记数据，是重症监护中的一个挑战。为了解决这个问题，我们
提出了一种采用自我监督预训练的新颖方法，重点关注
临床测量和注释的对齐。我们的方法结合了对比
以及预训练期间的屏蔽标记预测任务。半监督
MIMIC-III 数据集上的实验证明了我们的有效性
自监督预训练。在下游任务中，包括医院内
死亡率预测和表型分析，我们的预训练模型表现优于其他模型
仅标记一小部分数据的设置中的基线，强调
其增强 ICU 数据分析的能力。值得注意的是，我们的方法擅长
可用标签很少的情况，如
院内死亡率的 AUC-ROC 为 0.17，表型分析的 AUC-PR 为 0.17
当只有 1% 的标签可访问时为 0.1。这项工作推进了自我监督
在医疗保健领域学习，从丰富的经验中优化临床见解
但 ICU 数据具有挑战性。
]]></description>
      <guid>http://arxiv.org/abs/2312.06855</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:19 GMT</pubDate>
    </item>
    <item>
      <title>理清对攻击性的看法：文化和道德的关联。 （arXiv：2312.06861v1 [cs.CY]）</title>
      <link>http://arxiv.org/abs/2312.06861</link>
      <description><![CDATA[对冒犯性的看法本质上是主观的，由生活所塑造
感知者的经验和社会文化价值观。近年来已见
大力开发基于人工智能的工具来检测攻击性语言
大规模，作为调节社交媒体平台并确保安全的手段
ChatGPT 和 Bard 等对话式 AI 技术的应用。然而，现有的
方法将此任务视为一项基于数据的技术努力
被全球人群注释为冒犯性，而没有受到任何关注
人群工作者的出处或他们的看法所反映的价值观。我们
认为文化和心理因素在
攻击性的认知处理，在这方面考虑至关重要
语境。我们将确定攻击性的任务重新定义为本质上
道德判断问题——决定道德错误与道德错误的界限
隐含的社会文化规范中的正确语言。通过一个
基于来自 21 个国家的 4309 名参与者的大规模跨文化研究
跨越 8 个文化区域，我们展示了实质性的跨文化
对攻击性的看法存在差异。更重要的是，我们发现
个人道德价值观在形成这些差异方面发挥着至关重要的作用：
对关怀和纯洁的担忧是驱动的重要中介因素
跨文化差异。这些见解对于我们至关重要
为多元化世界构建人工智能模型，他们所拥护的价值观应该
旨在尊重和解释不同地理文化背景下的道德价值观。
]]></description>
      <guid>http://arxiv.org/abs/2312.06861</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:19 GMT</pubDate>
    </item>
    <item>
      <title>通过法学硕士和情境学习从用户反馈中提取自洽的因果见解。 （arXiv：2312.06820v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.06820</link>
      <description><![CDATA[Microsoft Windows 反馈中心旨在接收客户对某个问题的反馈
主题广泛，包括电源和电池等关键主题。
反馈是掌握用户体验最有效的途径之一
Windows 及其生态系统。然而，收到的反馈数量之大
通过反馈中心使得诊断实际原因变得非常困难
报告的问题。为了更好地理解和分类问题，我们利用 Double
机器学习 (DML) 将用户的反馈与遥测信号相关联。一
我们在 DML 管道中面临的主要挑战之一是域的必要性
模型设计的知识（例如因果图），有时不是
可获得或难以获得。在这项工作中，我们利用推理
大型语言模型 (LLM) 中生成先验模型的能力
这在一定程度上弥补了领域知识的缺乏，并且可以
用作测量反馈信息量的启发式方法。我们的法学硕士为基础
方法能够提取先前已知的问题，发现新的错误，并且
识别导致错误的事件序列，同时最大限度地减少域外事件
输出。
]]></description>
      <guid>http://arxiv.org/abs/2312.06820</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:18 GMT</pubDate>
    </item>
    <item>
      <title>非语言行为和社交凝视在课堂人机交互交流中的利用。 （arXiv：2312.06825v1 [cs.RO]）</title>
      <link>http://arxiv.org/abs/2312.06825</link>
      <description><![CDATA[本摘要探讨了课堂人机交互 (HRI) 场景
强调机器人中受人类启发的社交凝视模型的适应
认知架构促进更无缝的社交互动。第一的，
我们详细介绍了我们在研究中探索的 HRI 场景，然后是
我们研究中使用的社交凝视模型的描述。我们强调
在课堂 HRI 中利用这种注意力模型的优势
场景。我们还详细说明了我们即将进行的研究的预期目标，包括
这种社会凝视模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.06825</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:18 GMT</pubDate>
    </item>
    <item>
      <title>EgoPlan-Bench：使用多模式大语言模型对以自我为中心的具体规划进行基准测试。 （arXiv：2312.06722v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.06722</link>
      <description><![CDATA[多模态大型语言模型 (MLLM)，建立在强大的大型语言模型之上
具有出色推理和泛化能力的语言模型 (LLM)
能力，为具体任务规划开辟了新途径。 MLLM 表现出色
他们整合不同环境输入的能力，例如实时
任务进度、视觉观察和开放式语言指令，
对于可执行的任务规划至关重要。在这项工作中，我们介绍了一个
人类注释基准，EgoPlan-Bench，进行定量研究
MLLM 作为现实场景中具体任务规划器的潜力。我们的
基准测试的特点是源自真实世界视频的真实任务，
涉及与数百个不同的交互的不同的动作集
物体以及来自不同环境的复杂视觉观察。我们评估
各种开源 MLLM，揭示这些模型尚未进化
转化为具体的规划通才（甚至 GPT-4V）。我们进一步构造一个
来自人与物体交互视频的指令调整数据集 EgoPlan-IT，
促进复杂现实世界中高级任务规划的学习
情况。实验结果表明模型调优
EgoPlan-IT 不仅显着提高了我们基准测试的性能，而且
在模拟中也有效地充当体现规划者。
]]></description>
      <guid>http://arxiv.org/abs/2312.06722</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>Honeybee：多模式法学硕士的局部增强投影仪。 （arXiv：2312.06742v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.06742</link>
      <description><![CDATA[在多模态大语言模型 (MLLM) 中，视觉投影仪扮演着
在将预先训练的视觉编码器与法学硕士联系起来方面发挥着至关重要的作用，使
深刻的视觉理解，同时利用法学硕士的强大能力。
尽管视觉投影仪很重要，但其相对较少
探索过。在本研究中，我们首先确定投影仪的两个基本属性：
(i) 管理视觉标记数量的灵活性，这对于 MLLM 至关重要
整体效率，以及（ii）从视觉上保护当地环境
特征，对于空间理解至关重要。根据这些发现，我们建议
新颖的投影仪设计，既灵活又增强局部性，
有效地满足了这两个理想的特性。此外，我们还提出
综合策略，有效利用多方面的
指令数据集。通过大量的实验，我们检验了
个性化设计选择。最后，我们提出的 MLLM，Honeybee，非常出色
在各种基准测试中都优于以前最先进的方法，
包括 MME、MMBench、SEED-Bench 和 LLaVA-Bench，取得了显着的成绩
更高的效率。代码和型号可在以下网址获取
https://github.com/kakaobrain/honeybee。
]]></description>
      <guid>http://arxiv.org/abs/2312.06742</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>构建值得信赖的 NeuroSymbolic AI 系统：一致性、可靠性、可解释性和安全性。 （arXiv：2312.06798v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.06798</link>
      <description><![CDATA[可解释性和安全性产生信任。这些都需要一个模型来展示
一致性和可靠性。为了实现这些目标，需要使用和
使用与相关的统计和符号人工智能方法分析数据和知识
人工智能应用程序——两者都行不通。因此，我们争论并寻求
证明 NeuroSymbolic AI 方法更适合使 AI
值得信赖的人工智能系统。我们提出了 CREST 框架，展示了一致性、
可靠性、用户级可解释性和安全性建立在 NeuroSymbolic 之上
使用数据和知识来支持关键需求的方法
健康和福祉等应用。本文主要关注大
语言模型 (LLM) 作为 CREST 框架内选定的人工智能系统。法学硕士
因其多功能性而受到研究人员的广泛关注
处理各种自然语言处理 (NLP) 场景。为了
例如，ChatGPT 和 Google 的 MedPaLM 已成为极具前景的工具
提供一般信息和健康相关查询的平台，
分别。然而，尽管如此，这些模型仍然是黑匣子
结合人类反馈和指令引导的调整。例如，
尽管设置了安全护栏，ChatGPT 仍可能产生不安全的响应。
CREST 提出了一种利用程序和基于图形的可行方法
NeuroSymbolic 框架内的知识揭示了挑战
与法学硕士相关。
]]></description>
      <guid>http://arxiv.org/abs/2312.06798</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>具有基于法学硕士的流程自动化的智能虚拟助理。 （arXiv：2312.06677v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.06677</link>
      <description><![CDATA[虽然 Siri、Alexa 和 Google Assistant 等智能虚拟助手
尽管它们在现代生活中已经无处不在，但它们仍然面临着局限性
能够遵循多步骤指令并完成复杂的目标
用自然语言表达。然而，最近在重大突破
语言模型（LLM）显示出克服现有障碍的希望
增强自然语言处理和推理能力。尽管
应用法学硕士来创建更先进的虚拟助理仍然面临着希望
确保稳健的性能和处理可变性等挑战
真实世界的用户命令。本文提出了一种新颖的基于法学硕士的虚拟
手机内自动执行多步操作的助手
基于高级用户请求的应用程序。该系统代表了一个进步
通过提供解析指令的端到端解决方案来提供助手，
推理目标并执行行动。基于法学硕士的流程自动化
(LLMPA) 具有用于分解指令、生成描述的模块，
检测界面元素、预测下一步操作和错误检查。
实验证明该系统能够完成复杂的移动操作任务
基于自然语言指令的支付宝。这显示了有多大
语言模型可以使自动化助理完成现实世界的任务。
主要贡献是针对应用程序优化的新颖的 LLMPA 架构
流程自动化、将法学硕士应用于移动应用程序的方法，以及
在现实环境中完成多步骤任务的演示。
值得注意的是，这项工作代表了首次实际部署和广泛
在广泛使用的基于大型语言模型的虚拟助手的评估
拥有数百个庞大用户群的移动应用程序
百万。
]]></description>
      <guid>http://arxiv.org/abs/2312.06677</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>通过对比激活加法控制 Llama 2。 （arXiv：2312.06681v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.06681</link>
      <description><![CDATA[我们介绍对比激活加法 (CAA)，这是一种创新方法
通过在前向传播过程中修改激活来控制语言模型。
CAA 通过平均残差差来计算“转向向量”
正例和负例对之间的流激活
特定行为，例如事实反应与幻觉反应。期间
推断，这些转向向量被添加到之后的所有标记位置
用户提示带有正或负系数，允许精确
控制目标行为的程度。我们评估 CAA
使用多项选择行为问题在 Llama 2 Chat 上的有效性
数据集和开放式生成任务。我们证明 CAA 显着
改变模型行为，优于微调等传统方法
少量提示，并最大限度地减少功能。此外，通过采用
各种激活空间解释方法，我们获得更深入的了解
CAA 的机制。 CAA 既能准确引导模型输出，又能提供启发
关于如何在大型语言模型 (LLM) 中表示高级概念。
]]></description>
      <guid>http://arxiv.org/abs/2312.06681</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>从 Google 应用评论中了解大学生的意见。 （arXiv：2312.06705v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.06705</link>
      <description><![CDATA[Google 应用市场捕获了各个角落用户的思想流派
在多语言舞台上通过评级和文字评论了解全球。这
无法手动提取评论中的潜在信息，因为其
指数增长。因此，通过机器学习和深度学习进行情感分析
使用 NLP 的学习算法明确地揭示并解释了
情绪。本研究对应用程序评论进行情感分类
并通过以下方式识别大学生对应用市场的行为
探索性分析。我们使用 TP、TF、
和 TF IDF 文本表示方案并评估其在 Bagging 上的性能，
一种集成学习方法。我们在深度上使用了词嵌入、Glove
学习范式。我们的模型接受了 Google 应用评论的训练并进行了测试
学生的应用程序评论（SAR）。这些算法的各种组合是
使用 F 分数和准确性进行相互比较，并进行推论
以图形方式突出显示。 SVM 和其他分类器一起取得了丰硕的成果
双字母组和 TF IDF 方案的准确率（93.41%）、F 分数（89%）。套袋增强
LR 和 NB 的性能分别为 87.88% 和 86.69%，F 得分为
分别为86%和78%。总体而言，Glove 嵌入上的 LSTM 记录最高
准确率（95.2%）和F分数（88%）。
]]></description>
      <guid>http://arxiv.org/abs/2312.06705</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>在台湾闽南语语料库上评估自监督语音模型。 （arXiv：2312.06668v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.06668</link>
      <description><![CDATA[由于语言转变，台湾闽南语的使用率和地位正在下降
台湾的普通话。这就是为什么它是一种低资源语言的部分原因
当今的 NLP 和语音研究。确保语音达到最先进的水平
加工不落后台湾闽南语，我们贡献1.5小时
台湾闽南语数据集到 ML-SUPERB 的隐藏集。评估 ML-SUPERB
我们的数据集上的一套自我监督学习（SSL）语音表示，
我们发现模型大小并不能始终决定性能。实际上，
某些较小的模型优于较大的模型。此外，语言学
预训练数据和目标语言之间的一致性至关重要
角色。
]]></description>
      <guid>http://arxiv.org/abs/2312.06668</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:15 GMT</pubDate>
    </item>
    <item>
      <title>Llama Guard：基于法学硕士的人类与人工智能对话的输入输出保护。 （arXiv：2312.06674v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.06674</link>
      <description><![CDATA[我们推出 Llama Guard，一种基于法学硕士的输入输出保护模型
面向人机对话用例。我们的模型包含安全风险
分类法，对发现的一组特定安全风险进行分类的宝贵工具
在 LLM 提示中（即提示分类）。这个分类法也是
有助于对法学硕士对这些提示的反应进行分类，
我们将这个过程称为响应分类。为了两者提示的目的
和响应分类，我们精心收集了一个高数据集
质量。 Llama Guard，一个 Llama2-7b 模型，在我们的指令上进行了调整
收集的数据集虽然数量较少，但在以下方面表现出强大的性能
现有的基准，例如 OpenAI 审核评估数据集和
ToxicChat，其性能匹配或超过当前可用的
内容审核工具。 Llama Guard 充当语言模型，携带
进行多类分类并生成二元决策分数。
此外，Llama Guard 的指令微调允许
任务的定制和输出格式的调整。此功能
增强模型的功能，例如启用分类法的调整
类别以与特定用例保持一致，并促进零样本或
在输入端使用不同的分类法进行少量提示。我们正在制作骆驼
防护模型权重可用，我们鼓励研究人员进一步开发
并对其进行调整以满足社区对人工智能安全不断变化的需求。
]]></description>
      <guid>http://arxiv.org/abs/2312.06674</guid>
      <pubDate>Wed, 13 Dec 2023 03:15:15 GMT</pubDate>
    </item>
    </channel>
</rss>