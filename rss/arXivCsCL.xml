<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Tue, 06 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>语言引导的世界模型：基于模型的人工智能控制方法</title>
      <link>https://arxiv.org/abs/2402.01695</link>
      <description><![CDATA[将概率世界模型安装到人工代理中，为人类与这些代理进行通信和控制提供了有效的渠道。除了更新代理策略之外，人类还可以修改他们的内部世界模型以影响他们的决策。然而，挑战在于，目前现有的世界模型很难让人类适应，因为它们缺乏自然的沟通界面。为了解决这个缺点，我们开发了语言引导世界模型（LWM），它可以通过读取语言描述来捕获环境动态。这些模型提高了代理的沟通效率，允许人类通过简洁的语言反馈同时改变其在多个任务中的行为。它们还使代理能够从最初为指导人类而编写的文本中进行自学习。为了促进 LWM 的开发，我们基于 MESSENGER 游戏设计了一个具有挑战性的基准（Hanjie et al., 2021），要求对新的语言描述和环境动态进行组合泛化。我们的实验表明，当前最先进的 Transformer 架构在此基准测试中表现不佳，这促使我们设计更强大的架构。为了展示我们提出的 LWM 的实用性，我们模拟了一个场景，其中这些模型通过使其能够在执行之前生成计划并与人类讨论来增强代理的可解释性和安全性。通过有效地将语言反馈纳入计划，这些模型将真实环境中的代理性能提高了三倍，而无需收集该环境中的任何交互体验。]]></description>
      <guid>https://arxiv.org/abs/2402.01695</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:41 GMT</pubDate>
    </item>
    <item>
      <title>生成大型语言模型与同龄患者在解释非专业患者实验室测试结果方面的答案质量：评估研究</title>
      <link>https://arxiv.org/abs/2402.01693</link>
      <description><![CDATA[实验室结果常常令人困惑且难以理解。 ChatGPT 等大型语言模型 (LLM) 为患者解答问题开辟了一条充满希望的途径。我们的目标是评估使用法学硕士对患者提出的实验室测试相关问题生成相关、准确、有用且无害的答复的可行性，并确定可以通过增强方法缓解的潜在问题。我们首先从 Yahoo! 收集了与实验室测试结果相关的问答数据。为本研究提供答案并选择 53 个 QA 对。使用 LangChain 框架和 ChatGPT 门户网站，我们生成了来自四位法学硕士（包括 GPT-4、Meta LLaMA 2、MedAlpaca 和 ORCA_mini）的 53 个问题的答案。我们首先使用基于标准 QA 相似性的评估指标（包括 ROUGE、BLEU、METEOR、BERTScore）评估他们答案的相似性。我们还利用基于 LLM 的评估器来判断目标模型在相关性、正确性、有用性和安全性方面是否比基线模型具有更高的质量。最后，我们与医学专家对同一四个方面的七个选定问题的所有回答进行了手动评估。胜率和医学专家评估的结果均表明，GPT-4 的回答在所有四个方面（相关性、正确性、有用性和安全性）都比所有其他 LLM 回答和人类回答取得了更好的分数。然而，法学硕士的回答有时也会受到缺乏医学背景的解释、不正确的陈述和缺乏参考资料的影响。我们发现，与其他三位法学硕士和问答网站的人工回答相比，GPT-4 的回答更加准确、有帮助、相关且安全。然而，在某些情况下，GPT-4 反应不准确且不个性化。我们确定了多种提高法学硕士回复质量的方法。]]></description>
      <guid>https://arxiv.org/abs/2402.01693</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:40 GMT</pubDate>
    </item>
    <item>
      <title>ARGS：作为奖励引导搜索的对齐</title>
      <link>https://arxiv.org/abs/2402.01694</link>
      <description><![CDATA[让大型语言模型与人类目标保持一致至关重要，但包括 RLHF 在内的常见方法都受到不稳定且资源密集型训练的困扰。为了应对这一挑战，我们引入了 ARGS（Alignment as Reward-Guided Search），这是一种新颖的框架，它将对齐集成到解码过程中，从而消除了昂贵的 RL 训练的需要。通过使用奖励信号调整模型的概率预测，ARGS 生成具有语义多样性的文本，同时符合人类偏好，为对齐语言模型提供了一种有前途且灵活的解决方案。值得注意的是，与不同对齐任务和各种模型维度的基线相比，ARGS 表现出平均奖励的持续增强。例如，在相同的基于贪婪的解码策略下，我们的方法相对于基线将平均奖励提高了 19.56%，并在 GPT-4 评估中确保了 64.33% 的偏好或平局分数。我们相信，我们的框架强调解码时间对齐，为未来更具响应性的语言模型铺平了道路。代码可在以下位置公开获取：\url{https://github.com/deeplearning-wisc/args}。]]></description>
      <guid>https://arxiv.org/abs/2402.01694</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:40 GMT</pubDate>
    </item>
    <item>
      <title>SMUTF：使用生成标签和混合功能进行模式匹配</title>
      <link>https://arxiv.org/abs/2402.01685</link>
      <description><![CDATA[我们引入了 SMUTF，这是一种用于大规模表格数据模式匹配（SM）的独特方法，它假设监督学习不会影响开放域任务的性能，从而实现有效的跨域匹配。该系统独特地结合了基于规则的特征工程、预训练语言模型和生成式大语言模型。在受人道主义交换语言启发的创新改编中，我们为每个数据列部署“生成标签”，从而增强了 SM 的有效性。 SMUTF 表现出广泛的多功能性，可与任何预先存在的预训练嵌入、分类方法和生成模型无缝协作。
  认识到缺乏广泛的公开可用的 SM 数据集，我们根据公共人道主义数据创建并开源了 HDXSM 数据集。我们相信这是目前可用的最详尽的 SM 数据集。在各种公共数据集和新颖的 HDXSM 数据集的评估中，SMUTF 表现出了卓越的性能，在准确性和效率方面超越了现有的最先进模型，并将 F1 分数提高了 11.84%，ROC 的 AUC 提高了 5.08 %。]]></description>
      <guid>https://arxiv.org/abs/2402.01685</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:39 GMT</pubDate>
    </item>
    <item>
      <title>使用信息丢失进行基于语言的轻度认知障碍检测</title>
      <link>https://arxiv.org/abs/2402.01690</link>
      <description><![CDATA[本文提出了一种使用自然语言处理（NLP）技术的深度学习方法，以区分老年人的轻度认知障碍（MCI）和正常认知（NC）状况。我们提出了一个框架，用于分析 I-CONECT 研究项目中收集的视频采访生成的文字记录，这是一项旨在通过视频聊天改善认知功能的随机对照试验。我们提出的 NLP 框架由两个基于 Transformer 的模块组成，即句子嵌入（SE）和句子交叉注意（SCA）。首先，SE 模块捕获每个句子中单词之间的上下文关系。随后，SCA 模块从句子序列中提取时间特征。然后，多层感知器 (MLP) 使用此功能将受试者分类为 MCI 或 NC。为了构建一个鲁棒的模型，我们提出了一种新颖的损失函数，称为 InfoLoss，它通过观察每个句子序列来考虑熵的减少，以最终提高分类准确性。我们使用 I-CONECT 数据集进行的综合模型评估结果表明，我们的框架可以区分 MCI 和 NC，平均曲线下面积为 84.75%。]]></description>
      <guid>https://arxiv.org/abs/2402.01690</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:39 GMT</pubDate>
    </item>
    <item>
      <title>通过自监督表示混合和嵌入初始化，最大限度地提高跨语言 TTS 适应的数据效率</title>
      <link>https://arxiv.org/abs/2402.01692</link>
      <description><![CDATA[本文提出了一种用于文本到语音系统中语言适应的有效迁移学习框架，重点是使用最少的标记和未标记数据来实现语言适应。虽然许多工作专注于减少标记数据的使用，但很少有人考虑最大限度地减少未标记数据的使用。通过在预训练阶段利用自监督特征，在微调期间用这些特征替换伪标签的噪声部分，并结合嵌入初始化技巧，与传统方法相比，我们的方法利用了更多来自未标记数据的信息。实验结果表明，我们的框架能够仅用 4 条标记数据和 15 分钟的未标记数据来合成看不见的语言的可理解语音。即使可以访问更多数据，我们的方法仍继续超越传统技术。这些发现凸显了我们的数据高效语言适应框架的潜力。]]></description>
      <guid>https://arxiv.org/abs/2402.01692</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:39 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的多代理：进展和挑战的调查</title>
      <link>https://arxiv.org/abs/2402.01680</link>
      <description><![CDATA[大型语言模型 (LLM) 在广泛的任务中取得了显着的成功。由于法学硕士令人印象深刻的规划和推理能力，他们已被用作自主代理来自动完成许多任务。最近，在使用一个LLM作为单一规划或决策代理的发展基础上，基于LLM的多代理系统在复杂问题解决和世界模拟方面取得了长足的进步。为了向社区提供对这个动态领域的概述，我们提出了这项调查，以深入讨论基于法学硕士的多智能体系统的基本方面以及挑战。我们的目标是让读者获得对以下问题的深入见解：基于 LLM 的多智能体模拟哪些领域和环境？这些代理的概况如何以及他们如何沟通？哪些机制有助于代理人能力的增长？对于那些有兴趣深入研究这一领域的人，我们还总结了常用的数据集或基准，以便他们方便地访问。为了让研究人员了解最新研究，我们维护了一个开源 GitHub 存储库，专门概述基于 LLM 的多智能体系统的研究。]]></description>
      <guid>https://arxiv.org/abs/2402.01680</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:38 GMT</pubDate>
    </item>
    <item>
      <title>表情符号解码：利用 ChatGPT 增强对社交媒体通信的理解</title>
      <link>https://arxiv.org/abs/2402.01681</link>
      <description><![CDATA[表情符号封装了超越单词或短语的语义，在社交网络通信中已经变得普遍。这激发了学术界对探索它们的属性和功能的兴趣。然而，表情符号相关的研究和应用面临两个主要挑战。首先，研究人员通常依靠众包来注释表情符号，以了解它们的情感、使用意图和语义。其次，用户的主观解读往往会导致对表情符号的误解，造成沟通障碍。大型语言模型 (LLM) 在各种注释任务中取得了巨大成功，ChatGPT 展示了跨多个领域的专业知识。在我们的研究中，我们评估了 ChatGPT 在处理先前注释的任务和下游任务方面的有效性。我们的目标是验证以下假设：ChatGPT 可以作为表情符号研究中人类注释器的可行替代方案，并且其解释表情符号含义的能力可以提高在线通信的清晰度和透明度。我们的研究结果表明 ChatGPT 对表情符号有广泛的了解。它擅长阐明表情符号在各种应用场景中的含义，并展示了在一系列任务中替代人类注释者的潜力。]]></description>
      <guid>https://arxiv.org/abs/2402.01681</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:38 GMT</pubDate>
    </item>
    <item>
      <title>使用 CGC-LORA 算法在法学硕士中实现 1+N 多任务微调模式的框架</title>
      <link>https://arxiv.org/abs/2402.01684</link>
      <description><![CDATA[随着自然语言处理（NLP）领域大语言模型（LLM）的高效发展，人们付出了大量的努力来有效地微调常见的预训练LLM，以完成一个或多个特定领域的各种任务。在实践中，有两种流行的方法可以实现适应：（i）多个独立模型：使用每个任务的相应训练样本对预训练的 LLM 进行多次独立微调。 (ii) 综合模型：使用所有任务的样本来统一微调预试验的法学硕士。为了同时解决高计算成本和跷跷板问题，我们提出了一个统一的框架，使用新颖的定制门控制（CGC）低秩适应（LoRA）算法在LLM中实现1+N多任务微调模式。我们的工作旨在利用 MTL（即 CGC）和 PEFT（即 LoRA）方案。对于给定的任务集群，我们设计了一个创新层，其中包含两种类型的专家作为额外的可训练参数，以使 LoRA 与 MTL 兼容。为了全面评估所提出的框架，我们在两个公共数据集上进行了精心设计的实验。实验结果表明，带有 CGC-LoRA 模块的统一框架在两个数据集上获得了比所有基准更高的评估分数。]]></description>
      <guid>https://arxiv.org/abs/2402.01684</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:38 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型嵌入追踪思想的谱系</title>
      <link>https://arxiv.org/abs/2402.01661</link>
      <description><![CDATA[在本文中，我提出了一种新颖的方法来检测大型语料库中的智力影响力。利用大型语言模型在编码语义和结构意义方面的独特功能，同时保持对释义的鲁棒性，我们可以以计算有效的方式搜索实质上相似的想法和智力影响的暗示。这种方法使我们能够操作不同级别的置信度：我们可以允许直接引用、释义或推测相似性，同时对每个阈值的限制保持开放。我应用了一种结合了通用文本嵌入的集成方法，一种最先进的句子嵌入方法，经过优化以捕获语义内容，以及一种抽象含义表示图表示，旨在捕获论证风格和隐喻使用中的结构相似性。我应用这种方法对 19 世纪大约 400,000 本非小说类书籍和学术出版物的语料库中的句子进行向量化，以获取达尔文出版物中出现的思想和论点的实例。这起到了初步评估和概念验证的作用；该方法不仅限于检测达尔文思想，还能够在广泛的语料库和上下文中大规模地检测相似性。]]></description>
      <guid>https://arxiv.org/abs/2402.01661</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:37 GMT</pubDate>
    </item>
    <item>
      <title>语言模型与人类对关键语法结构的判断保持一致</title>
      <link>https://arxiv.org/abs/2402.01676</link>
      <description><![CDATA[大型语言模型 (LLM) 是否可以进行类似人类的语言概括？登特拉等人。 （2023；“DGL”）提示几位法学硕士（“下面的句子在英语中语法上正确吗？”）引出了 80 个英语句子的语法判断，得出的结论是法学硕士表现出“是反应偏差”和“无法区分语法”来自不合语法的句子”。我们使用成熟的实践重新评估法学硕士的表现，发现 DGL 的数据实际上为法学硕士捕捉人类行为的能力提供了证据。模型不仅总体上实现了高精度，而且还捕获了人类语言判断的细粒度变化。]]></description>
      <guid>https://arxiv.org/abs/2402.01676</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:37 GMT</pubDate>
    </item>
    <item>
      <title>StickerConv：从头开始生成多模式同理心响应</title>
      <link>https://arxiv.org/abs/2402.01679</link>
      <description><![CDATA[贴纸虽然被广泛认为可以增强在线互动中的同理心沟通，但在当前的同理心对话研究中仍未得到充分探索。在本文中，我们介绍了 Agent for StickerConv (Agent4SC)，它使用协作代理交互来通过贴纸的使用来真实地模拟人类行为，从而增强多模式同理心沟通。在此基础上，我们开发了一个多模态同理心对话数据集 StickerConv，其中包括 12.9K 个对话会话、5.8K 个独特贴纸和 2K 个不同的对话场景，专门设计用于增强多模态环境中同理心反应的生成。为了利用该数据集的丰富性，我们提出了 PErceive 和生成贴纸（PEGS），这是一种多模式同理心响应生成模型，并辅以一套基于 LLM 的全面的同理心评估指标。我们的实验证明了 PEGS 在生成上下文相关且情感共鸣的多模式共情反应方面的有效性，有助于发展更细致、更有吸引力的共情对话系统。我们的项目页面位于 https://neu-datamining.github.io/StickerConv 。]]></description>
      <guid>https://arxiv.org/abs/2402.01679</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:37 GMT</pubDate>
    </item>
    <item>
      <title>通用句法结构：各种自然语言的句法建模</title>
      <link>https://arxiv.org/abs/2402.01641</link>
      <description><![CDATA[我们的目标是解释人脑如何连接单词以形成句子。引入了一种对句法表示进行建模的新方法，有可能表明所有自然语言都存在通用句法结构。由于 DNA 双螺旋结构的发现揭示了遗传学的内部运作原理，我们希望引入对语言如何在人脑中发挥作用的基本理解。它可能是大脑编码和解码知识的方式。它还带来了对语言学、心理学和认知科学理论的一些见解。在研究了通用句法结构背后的逻辑和建模技术的方法论之后，我们尝试分析展示英语和韩语等不同自然语言的语言过程中的普遍性的语料库。最后，我们讨论关键期假说、普遍语法和其他一些关于语言的断言，以增进我们对人类大脑的理解。]]></description>
      <guid>https://arxiv.org/abs/2402.01641</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:36 GMT</pubDate>
    </item>
    <item>
      <title>机器生成文本的检测：文献调查</title>
      <link>https://arxiv.org/abs/2402.01642</link>
      <description><![CDATA[由于语言模型可以快速、轻松地生成虚假文本，因此公共领域中此类内容供过于求。复杂程度和写作风格已经达到了几乎不可能区分人类创作和机器生成的内容的程度。因此，由语言模型而不是人类作者生成的作品获得了媒体的广泛关注并引发了争议。人们也开始担心高级语言模型对社会可能产生的影响，需要对这些过程有更全面的了解。自然语言生成（NLG）和生成式预训练变压器（GPT）模型已经彻底改变了各个领域：其范围不仅渗透到整个新闻业和客户服务领域，还延伸到了学术界。为了减轻使用这些模型可能产生的危险影响，必须实施预防措施，例如为人类代理提供利用自动化系统和可能的逆向工程语言模型区分人工生成和人类编写的文本的能力。此外，为了确保采取平衡和负责任的方法，充分掌握这些突破的社会技术影响至关重要。本文献综述旨在汇编和综合上述工作的成就和发展，同时也确定未来的前景。它还概述了机器生成的文本趋势，并探讨了更大的社会影响。最终，这项调查旨在通过探索语言模型的功能及其可能的含义之间的相互作用，为解决与机器生成文本的使用和检测相关的问题做出贡献。]]></description>
      <guid>https://arxiv.org/abs/2402.01642</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:36 GMT</pubDate>
    </item>
    <item>
      <title>L-TUNING：LLM 中提示和前缀的同步标签调整</title>
      <link>https://arxiv.org/abs/2402.01643</link>
      <description><![CDATA[针对特定任务有效地微调大型语言模型 (LLM) 在自然语言处理中提出了相当大的挑战。传统方法（例如提示或前缀调整）通常依赖于任意标记进行训练，导致训练时间延长以及跨各种类标签的通用标记使用。为了解决这些问题，本文引入了 L-Tuning，这是一种专为自然语言推理（NLI）框架内的分类任务而设计的高效微调方法。与传统方法不同，L-Tuning 侧重于通过预先训练的 LLM 处理的标签标记进行微调，从而利用其预先存在的语义知识。该技术不仅提高了微调的准确性和效率，而且还有助于为每个类别生成不同的标签嵌入，从而增强模型的训练细微差别。我们的实验结果表明，与传统方法相比，L-Tuning 的训练效率和分类准确性有了显着提高，这标志着在复杂语言任务的 LLM 微调方面取得了有希望的进步。 \\ 代码位于：\textcolor{red}{\href{https://github.com/Kowsher/L-Tuning}{\texttt{https://github.com/Kowsher/L-Tuning}}} 。]]></description>
      <guid>https://arxiv.org/abs/2402.01643</guid>
      <pubDate>Tue, 06 Feb 2024 15:13:36 GMT</pubDate>
    </item>
    </channel>
</rss>