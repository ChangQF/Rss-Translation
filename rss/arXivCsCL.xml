<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Wed, 06 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过代码从法学硕士那里获得更好的多语言结构化推理</title>
      <link>https://arxiv.org/abs/2403.02567</link>
      <description><![CDATA[arXiv:2403.02567v1 公告类型：新
摘要：大语言模型（LLM）的开发在推理方面取得了进展，尽管研究仅限于英语或简单的推理任务。因此，我们引入了一个多语言结构化推理和解释数据集，称为 xSTREET，涵盖六种语言的四项任务。 xSTREET 暴露了英语和非英语推理任务之间法学硕士基础表现的差距。然后，我们提出了两种方法来弥补这一差距，基于这样的见解：受过代码训练的法学硕士是更好的推理者。首先，在训练时，我们使用机器翻译通过多语言注释来扩充代码数据集，同时保持程序代码不变。其次，在推理时，我们通过采用包含分步代码原语的提示结构来弥合训练和推理之间的差距，以得出新事实并找到解决方案。我们的方法在 xSTREET 上显示出改进的多语言性能，尤其是在科学常识推理子任务上。此外，模型在非推理任务上没有表现出回归，从而表明我们的技术保持了通用能力。]]></description>
      <guid>https://arxiv.org/abs/2403.02567</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>平衡增强、无害和一般能力：通过直接 RLHF 增强会话式法学硕士</title>
      <link>https://arxiv.org/abs/2403.02513</link>
      <description><![CDATA[arXiv:2403.02513v1 公告类型：新
摘要：在会话大型语言模型 (LLM) 的最新进展中，出现了一个令人担忧的趋势，表明许多新的基础 LLM 在监督微调 (SFT) 后经历了基础能力的知识减少。这个过程通常会导致诸如遗忘或基础模型能力下降等问题。此外，经过微调的模型很难与用户偏好保持一致，在特别提示时会无意中增加有毒输出的产生。为了克服这些挑战，我们采用了一种创新方法，完全绕过 SFT，直接实施来自人类反馈的无害强化学习 (RLHF)。我们的方法不仅保留了基本模型的一般功能，而且还显着增强了其对话能力，同时显着减少了有毒输出的产生。我们的方法对于需要细致入微的理解和生成响应的领域具有重大影响，例如客户服务。我们将此方法应用于最流行的基础模型 Mistral，从而创建了 Mistral-Plus。我们对 11 个一般任务的验证表明，Mistral-Plus 的性能优于类似大小的开源基础模型及其相应的指令版本。重要的是，Mistral-Plus 的对话能力得到了显着提高，这表明在安全性和用户偏好一致性方面比传统 SFT 模型有了实质性的进步。]]></description>
      <guid>https://arxiv.org/abs/2403.02513</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>DACO：通过代码生成实现应用程序驱动的全面数据分析</title>
      <link>https://arxiv.org/abs/2403.02528</link>
      <description><![CDATA[arXiv:2403.02528v1 公告类型：新
摘要：数据分析是生成深入研究和结论性见解以全面回答给定用户对表格数据的查询的关键分析过程。在这项工作中，我们的目标是提出新的资源和基准，以激发未来对这一至关重要但具有挑战性且尚未探索的任务的研究。然而，收集专家整理的数据分析注释可能会非常昂贵。我们建议利用法学硕士的代码生成功能和多轮提示技术自动生成高质量的答案注释。我们构建了 DACO 数据集，其中包含 (1) 从现实场景收集的 440 个数据库（表格数据），(2) 约 2k 个查询-答案对，可以作为模型训练的弱监督，以及 (3) 一个集中但具有人工精细注释的高质量测试集作为我们的主要评估基准。我们在 DACO 数据集上训练了 6B 监督微调（SFT）模型，发现 SFT 模型学习了合理的数据分析能力。为了进一步使模型与人类偏好保持一致，我们使用强化学习来鼓励生成人类认为有帮助的分析，并设计一组密集奖励将稀疏的人类偏好奖励传播到中间代码生成步骤。我们的 DACO-RL 算法经过人类注释者的评估，在 57.72% 的情况下产生比 SFT 模型更有用的答案，验证了我们提出的算法的有效性。数据和代码发布于https://github.com/shirley-wu/daco]]></description>
      <guid>https://arxiv.org/abs/2403.02528</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>更新生成建模研究的临床人工智能 (MI-CLAIM) 最低信息清单</title>
      <link>https://arxiv.org/abs/2403.02558</link>
      <description><![CDATA[arXiv:2403.02558v1 公告类型：新
摘要：生成模型的最新进展，包括大语言模型（LLM）、视觉语言模型（VLM）和扩散模型，加速了医学中自然语言和图像处理领域的发展，并标志着生物医学模型如何进行重大范式转变。得到开发和部署。虽然这些模型高度适应新任务，但扩展和评估它们的使用提出了先前框架中未解决的新挑战。特别是，这些模型在几乎不需要专门训练数据（“零”或“少样本”方法）的情况下产生有用输出的能力，以及其输出的开放性，需要开发更新的模型使用和评估这些模型的指南。为了应对美国第 141103 号行政命令和几个新兴国家临床人工智能评估网络确定的临床人工智能工具开发标准和最佳实践方面的差距，我们开始通过建立在“有关临床人工智能的最低信息”的基础上，正式制定其中一些指南。情报建模”（MI-CLAIM）清单。 MI-CLAIM 清单最初于 2020 年制定，提供了一组六个步骤，并提供了鼓励透明、可重复的医学人工智能 (AI) 研究所需的最低限度信息的指南。在这里，我们建议对原始清单进行修改，突出显示生成模型与传统临床研究人工智能模型相比在训练、评估、可解释性和可重复性方面的差异。此更新的清单还旨在澄清队列选择报告，并添加与道德标准保持一致的其他项目。]]></description>
      <guid>https://arxiv.org/abs/2403.02558</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>试错法：LLM 智能体基于探索的轨迹优化</title>
      <link>https://arxiv.org/abs/2403.02502</link>
      <description><![CDATA[arXiv:2403.02502v1 公告类型：新
摘要：大型语言模型（LLM）已成为各种自治代理系统中不可或缺的组成部分。在这项研究中，我们提出了一种基于探索的轨迹优化方法，称为 ETO。这种学习方法旨在提高开放式LLM代理的性能。与之前专门训练成功的专家轨迹的研究相反，我们的方法允许智能体从探索失败中学习。这可以通过迭代优化框架提高性能。在探索阶段，智能体在完成给定任务的同时与环境进行交互，收集故障轨迹以创建对比轨迹对。在随后的训练阶段，代理利用这些轨迹偏好对，使用 DPO 等对比学习方法来更新其策略。这种探索和训练的迭代循环促进了智能体的持续改进。我们对三个复杂任务的实验表明，ETO 始终大幅超越基线性能。此外，在缺乏专家轨迹的情况下对任务解决效率和潜力的检查强调了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.02502</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>自然语言处理预训练-微调范式教程</title>
      <link>https://arxiv.org/abs/2403.02504</link>
      <description><![CDATA[arXiv:2403.02504v1 公告类型：新
摘要：预训练微调范式代表了自然语言处理（NLP）中的一种变革性方法。该范例通过使用大型预训练语言模型而脱颖而出，即使在训练数据有限的情况下，也能在微调任务方面表现出显着的效率。这种效率对于社会科学研究尤其有益，因为社会科学研究中带注释的样本数量通常非常有限。我们的教程全面介绍了预训练微调范例。我们首先深入研究预训练和微调的基本概念，然后使用实际应用进行实际练习。我们演示了该范例在各种任务中的应用，包括多类分类和回归。本教程强调其功效和用户友好性，旨在鼓励更广泛地采用这种范例。为此，我们提供了对所有代码和数据集的开放访问。该教程对于心理学定量研究人员特别有价值，为他们提供了这种创新方法的富有洞察力的指南。]]></description>
      <guid>https://arxiv.org/abs/2403.02504</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>SPUQ：大型语言模型的基于扰动的不确定性量化</title>
      <link>https://arxiv.org/abs/2403.02509</link>
      <description><![CDATA[arXiv:2403.02509v1 公告类型：新
摘要：近年来，大型语言模型（LLM）变得越来越普遍，提供了卓越的文本生成能力。然而，一个紧迫的挑战是他们倾向于做出自信的错误预测，这凸显了法学硕士对不确定性量化（UQ）的迫切需求。虽然以前的工作主要集中在解决任意不确定性，但对包括认知在内的所有不确定性的探索仍然不够。受这一差距的启发，我们引入了一种新颖的 UQ 方法，即 UQ 扰动采样（SPUQ），旨在解决任意和认知不确定性。该方法需要为 LLM 输入生成一组扰动，对每个扰动的输出进行采样，并结合一个聚合模块来概括文本生成任务的采样不确定性方法。通过对各种数据集进行广泛的实验，我们研究了不同的扰动和聚合技术。我们的研究结果表明模型不确定性校准有了显着改善，预期校准误差 (ECE) 平均减少了 50%。我们的研究结果表明，我们提出的昆士兰大学方法为提高法学硕士的可靠性和可信度提供了有希望的步骤。]]></description>
      <guid>https://arxiv.org/abs/2403.02509</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>文学小说的情感动态</title>
      <link>https://arxiv.org/abs/2403.02474</link>
      <description><![CDATA[arXiv:2403.02474v1 公告类型：新
摘要：故事在叙述中展现出丰富的情感，并在读者中唤起情感。故事中各个角色的情感历程是其吸引力的核心。然而，对小说情感的计算分析很少检查小说中不同角色情感轨迹的变化，而是将整部小说视为代表单个故事线。在这部作品中，我们通过人物对话来区分叙述的情感弧和各个人物。我们使用话语情感动力学框架分析英语文学小说数据集中各个人物的情感弧。我们的研究结果表明，小说的叙述和对话在很大程度上表达了不同的情感，而故事情感弧的共性或差异可以通过与各个角色相关的情感弧线更准确地捕捉到。]]></description>
      <guid>https://arxiv.org/abs/2403.02474</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>选择你自己的冒险：提高单词知识和理解能力的交互式电子书</title>
      <link>https://arxiv.org/abs/2403.02496</link>
      <description><![CDATA[arXiv:2403.02496v1 公告类型：新
摘要：本可行性研究的目的是探讨阅读数字互动电子书对三五年级学生支持阅读理解的基本技能的潜在影响。学生阅读两本教授单词学习和理解监控策略的电子书，以帮助学习困难的词汇和有关飓风的有针对性的科学概念。我们调查了特定的理解策略（包括单词学习和支持一般阅读理解、总结和问题生成的策略）是否能够有效地在电子书中构建词汇知识和理解技能。学生被分配阅读每本电子书的三个版本之一，每个版本实施一种策略。这些书采用了“选择你的冒险”的形式，嵌入了理解问题，为学生提供了关于他们回答的即时反馈。进行配对样本 t 检验，以检查学习两本电子书中教授的目标词汇和科学概念前后的差异。对于这两本电子书，学生们在单词学习和目标飓风概念方面都取得了显着的进步。此外，分层线性模型（HLM）显示，没有一种策略比另一种策略与更大的收益更相关。书中嵌入问题的表现也与两本电子书更好的后测结果相关。这项工作讨论了电子书的实施和未来开发的重要考虑因素，可以提高学生的参与度并提高阅读理解能力。]]></description>
      <guid>https://arxiv.org/abs/2403.02496</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>架构如何影响预训练语言模型的基本能力？基于 FFN-Wider 变压器模型的案例研究</title>
      <link>https://arxiv.org/abs/2403.02436</link>
      <description><![CDATA[arXiv:2403.02436v1 公告类型：新
摘要：预训练语言模型已被证明具有强大的基础能力，不仅在分布内语言建模方面表现出色，而且在分布外语言建模、迁移学习和少样本学习方面也表现出强大的能力。与关注规模对基础能力影响的现有工作不同，我们的工作研究了架构对基础能力的影响。具体来说，我们关心的是：架构如何影响预训练语言模型的基本能力？在这项工作中，我们试图解释并扭转由 FFN-Wider Transformers 架构引起的基础能力下降，寻求提供一些见解。通过分析，我们发现Multi-Head Attention（一种组合函数）对预训练语言模型的贡献率是影响基础能力的关键因素。 FFN-Wider Transformers降低了该组合功能的贡献比例，导致基础能力下降。我们通过实验证实了这一点，并提出了组合增强架构（CEA）来解决此类模型基础能力下降的问题。值得注意的是，我们将我们的解释和CEA扩展到了Mixture of Experts (MoE)架构Transformers，这也在一定程度上缓解了其基础能力的下降，证明我们的工作可以为架构分析、架构改进和架构设计提供有用的指导。]]></description>
      <guid>https://arxiv.org/abs/2403.02436</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>观点是我自己的，也是你的：使用共同点对心理理论进行基准测试</title>
      <link>https://arxiv.org/abs/2403.02451</link>
      <description><![CDATA[arXiv:2403.02451v1 公告类型：新
摘要：评估语言模型（LM）的心理理论（ToM）能力最近受到了广泛关注。然而，许多现有的基准依赖于合成数据，这可能导致实验结果与人类行为不一致。我们引入了第一个基于自然发生的口语对话的 ToM 数据集 Common-ToM，并表明 LM 很难展示 ToM。然后我们证明，集成简单、明确的信念表示可以提高 Common-ToM 上的 LM 性能。]]></description>
      <guid>https://arxiv.org/abs/2403.02451</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>OffLanDat：通过即时工程由大型语言模型生成的基于社区的隐性攻击性语言数据集</title>
      <link>https://arxiv.org/abs/2403.02472</link>
      <description><![CDATA[arXiv:2403.02472v1 公告类型：新
摘要：社交媒体上攻击性语言的广泛存在对社会福祉造成了不利影响。因此，高度优先解决这个问题变得非常重要。攻击性语言有显式和隐式两种形式，后者更难以检测。目前该领域的研究遇到了一些挑战。首先，现有数据集主要依赖于包含显式攻击性关键字的文本集合，这使得捕获缺乏这些关键字的隐式攻击性内容变得具有挑战性。其次，通常的方法往往只关注文本分析，而忽略了社区信息可以提供的有价值的见解。在这篇研究论文中，我们介绍了一个新颖的数据集 OffLanDat，这是一个由 ChatGPT 生成的基于社区的隐式攻击性语言数据集，其中包含 38 个不同目标群体的数据。尽管由于道德限制，使用 ChatGPT 生成攻击性文本存在局限性，但我们提出了一种基于提示的方法，可以有效生成隐式攻击性语言。为了确保数据质量，我们由人工评估我们的数据。此外，我们采用基于提示的零射击方法和 ChatGPT，并比较人工注释和 ChatGPT 注释之间的检测结果。我们利用现有的最先进的模型来看看它们在检测此类语言方面有多有效。我们将向其他研究人员公开我们的代码和数据集。]]></description>
      <guid>https://arxiv.org/abs/2403.02472</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>AdaptNMT：一个开源的、与语言无关的神经机器翻译开发环境</title>
      <link>https://arxiv.org/abs/2403.02367</link>
      <description><![CDATA[arXiv:2403.02367v1 公告类型：新
摘要：adaptNMT 简化了 RNN 和 Transformer 神经翻译模型的开发和部署所涉及的所有流程。作为一个开源应用程序，它是为机器翻译领域的技术和非技术用户而设计的。该应用程序基于广泛采用的 OpenNMT 生态系统而构建，对于该领域的新进入者特别有用，因为开发环境的设置以及训练、验证和测试分割的创建都得到了极大的简化。应用程序中嵌入的图形说明了模型训练的进度，SentencePiece 用于创建子词分割模型。通过直观的用户界面促进了超参数定制，并且已经实现了单击模型开发方法。由 AdaptNMT 开发的模型可以使用一系列指标进行评估，并在应用程序中部署为翻译服务。为了支持 NLP 领域的环保研究，绿色报告还标记了模型开发过程中产生的功耗和 kgCO$_{2}$ 排放量。该应用程序是免费提供的。]]></description>
      <guid>https://arxiv.org/abs/2403.02367</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>AdaptMLLM：通过集成的 LLM 游乐场在低资源语言上微调多语言语言模型</title>
      <link>https://arxiv.org/abs/2403.02370</link>
      <description><![CDATA[arXiv:2403.02370v1 公告类型：新
摘要：多语言语言模型（MLLM）和大型语言模型的出现催生了自然语言处理许多领域的创新。尽管这项技术具有令人兴奋的潜力，但它对为资源匮乏的语言开发高质量机器翻译 (MT) 输出的影响仍然相对未被充分探索。此外，专门用于微调 MLLM 和管理低资源语言的完整 MT 工作流程的开源应用程序仍然不可用。我们的目标是通过开发适应MLLM来解决这些不平衡问题，它简化了机器翻译MLLM微调所涉及的所有流程。这个开源应用程序是为从事机器翻译的开发人员、翻译人员和用户量身定制的。直观的界面可以轻松自定义超参数，并且该应用程序提供了一系列用于模型评估的指标以及直接在应用程序中将模型部署为翻译服务的功能。作为多语言工具，我们使用 AdaptMLLM 来微调两种低资源语言对的模型：英语到爱尔兰语 (EN$\leftrightarrow$GA) 和英语到马拉地语 (EN$\leftrightarrow$MR)。与 LoResMT2021 共享任务的基线相比，adaptMLLM 系统表现出显着的改进。在 EN$\rightarrow$GA 方向上，观察到 5.2 BLEU 点的改进，在 GA$\rightarrow$EN 方向上记录了 40.5 BLEU 点的增加。 EN$\leftrightarrow$MR 对的翻译性能也显着改善，尤其是在 MR$\rightarrow$EN 方向，增加了 21.3 BLEU 点。最后，使用多维质量指标和标量质量指标误差分类法对 EN$\rightarrow$GA 对上的 MLLM 输出进行细粒度的人工评估。该应用程序和模型可免费获得。]]></description>
      <guid>https://arxiv.org/abs/2403.02370</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>英语的人类评价——基于爱尔兰 Transformer 的 NMT</title>
      <link>https://arxiv.org/abs/2403.02366</link>
      <description><![CDATA[arXiv:2403.02366v1 公告类型：新
摘要：在这项研究中，针对资源匮乏的英语-爱尔兰语对，对超参数设置如何影响基于 Transformer 的神经机器翻译 (NMT) 的质量进行了人工评估。使用字节对编码 (BPE) 和一元组方法的 SentencePiece 模型进行了评估。模型架构的变化包括修改层数、评估注意力的最佳头部数量以及测试各种正则化技术。具有 16k BPE 子字模型的 Transformer 优化模型记录了最大的性能改进。与基线循环神经网络 (RNN) 模型相比，Transformer 优化模型的 BLEU 分数提高了 7.8 分。当与谷歌翻译进行基准测试时，我们的翻译引擎表现出了显着的改进。此外，还进行了定量细粒度手动评估，比较了机器翻译系统的性能。使用多维质量度量 (MQM) 错误分类法，探索了对基于 RNN 的系统和基于 Transformer 的系统生成的错误类型的人工评估。我们的研究结果表明，与基于 RNN 的模型相比，性能最佳的 Transformer 系统显着降低了准确性和流畅性误差。]]></description>
      <guid>https://arxiv.org/abs/2403.02366</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:30 GMT</pubDate>
    </item>
    </channel>
</rss>