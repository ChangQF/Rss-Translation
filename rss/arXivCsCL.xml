<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Mon, 01 Jan 2024 03:15:23 GMT</lastBuildDate>
    <item>
      <title>维度变化对词嵌入偏差的影响。 （arXiv：2312.17292v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17292</link>
      <description><![CDATA[词嵌入方法 (WEM) 广泛用于表示文本
数据。这些嵌入的维度因不同的任务而异
实施。维数变化对测量精度的影响
下游任务是一个经过充分探索的问题。然而，维数如何
变化对词嵌入偏差的影响需要调查。使用
英语维基百科语料库，我们研究了两个静态（Word2Vec 和
fastText）和两个上下文相关（ElMo 和 BERT）WEM。我们有两个
观察。首先，词的偏向性存在显着差异
嵌入随维度变化。其次，没有统一性
维度变化如何影响词嵌入的偏差。这些
选择词维数时应考虑的因素
嵌入。
]]></description>
      <guid>http://arxiv.org/abs/2312.17292</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:23 GMT</pubDate>
    </item>
    <item>
      <title>用于流式自动语音识别的状态 FastConformer 具有基于缓存的推理。 （arXiv：2312.17279v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17279</link>
      <description><![CDATA[在本文中，我们提出了一种高效且准确的流式语音
基于FastConformer架构的识别模型。我们调整了
FastConformer 架构通过以下方式实现流应用程序： (1) 约束
编码器中的前瞻和过去上下文，以及（2）引入
激活缓存机制，使非自回归编码器能够
在推理过程中进行自回归操作。所提出的模型是经过深思熟虑的
设计的方式是为了消除火车和火车之间的精度差异
推理时间对于许多流模型来说很常见。此外，我们的
所提出的编码器适用于各种解码器配置，包括
连接主义时间分类 (CTC) 和 RNN-Transducer (RNNT) 解码器。
此外，我们引入了混合 CTC/RNNT 架构，该架构利用
与 CTC 和 RNNT 解码器共享编码器，以提高准确性并节省成本
计算。我们在 LibriSpeech 数据集和
多领域大规模数据集并证明它可以取得更好的效果
与传统方法相比，具有更低的延迟和推理时间的准确性
缓冲流模型基线。我们还展示了训练模型
多个延迟可以比单个延迟模型获得更好的准确性，同时
它使我们能够用单一模型支持多种延迟。我们的
实验还表明，混合架构不仅可以加速
CTC解码器的收敛同时也提高了流媒体的准确性
模型与单个解码器模型的比较。
]]></description>
      <guid>http://arxiv.org/abs/2312.17279</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:22 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的大型语言模型的 AI 内容自我检测。 （arXiv：2312.17289v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17289</link>
      <description><![CDATA[$$基于大数据的生成人工智能（AI）工具的使用
用于文本生成的语言模型，包括 ChatGPT、Bard 和 Claude
许多令人兴奋的应用程序具有惊人的生产力潜力
收益。使用人工智能工具时的一个问题是作者归属。这是
在学术环境中尤其重要，因为学术环境中不恰当地使用
生成式人工智能工具可能会通过创建
大量自动生成的衍生作品。现有的抄袭行为
检测系统可以追踪提交文本的来源，但目前还不能
配备了准确检测人工智能生成文本的方法。这张纸
引入直接起源检测的思想并评估是否生成
人工智能系统可以识别其输出并将其与人类编写的内容区分开来
文本。我们争论为什么基于电流互感器的模型能够自我检测
他们自己生成的文本并使用零样本进行小型实证研究
学习调查是否是这种情况。结果显示不同
人工智能系统识别其生成的文本的能力。谷歌的吟游诗人
模型表现出最大的自检测能力，准确度为
94\%，其次是 OpenAI 的 ChatGPT，为 83\%。另一方面，人类的
克劳德模型似乎无法自我检测。
]]></description>
      <guid>http://arxiv.org/abs/2312.17289</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:22 GMT</pubDate>
    </item>
    <item>
      <title>通过知识图重构进行对话式问答。 （arXiv：2312.17269v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17269</link>
      <description><![CDATA[基于知识图 (KG) 的对话式问答 (convQA)
涉及回答有关信息的多轮自然语言问题
包含在 KG 中。最先进的 ConvQA 方法经常遇到困难
不明确的问答对。这些输入对于人类来说很容易
理解给定的对话历史，但机器很难解释，
这会降低 ConvQA 性能。为了解决这个问题，我们提出一个
基于强化学习 (RL) 的模型 CornNet，它利用问题
由大型语言模型 (LLM) 生成的重新表述以改进 ConvQA
表现。 CornNet采用师生架构，其中教师
模型使用人类书写重构来学习问题表示，并且
学生模型通过生成的重新公式来模仿教师模型的输出
由法学硕士。然后，RL 模型使用学习到的问题表示来
在 KG 中找到正确答案。大量的实验结果表明
CornNet 的性能优于最先进的 convQA 模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.17269</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:21 GMT</pubDate>
    </item>
    <item>
      <title>PanGu-$\pi$：通过非线性补偿增强语言模型架构。 （arXiv：2312.17276v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17276</link>
      <description><![CDATA[大型语言模型（LLM）的最新趋势是增加
模型大小（又名参数数量）和数据集以实现更好的效果
生成能力，这一点已被大量工作所证明，例如
著名的GPT和Llama。然而，大型模型通常涉及大量计算
成本，实际应用无法承受这么高的价格。但是，那
为法学硕士构建强大的模型架构的方法很少
讨论过。我们首先分析最先进的语言模型架构
并观察特征崩溃问题。基于理论分析，我们
提出非线性对于语言模型也非常重要，这
通常在视觉任务的卷积神经网络中进行研究。这
然后通过微小的计算引入系列通知激活函数
可以忽略，并且进一步使用增强快捷方式来增强
模型非线性。然后我们证明所提出的方法是
通过仔细观察，对于增强模型非线性非常有效
设计消融；因此，我们提出了一种新的高效模型架构
建立现代的，即盘古-$\pi$。然后使用进行实验
与 PanGu-$\pi$ 进行比较的相同数据集和训练策略
最先进的法学硕士。结果表明PanGu-$\pi$-7B可以实现
性能与基准测试相当，推理率约为 10%
加速，PanGu-$\pi$-1B 可以在以下方面实现最先进的性能
的准确性和效率。此外，我们还部署了 PanGu-$\pi$-7B
金融和法律的高价值领域，开发了名为云山的法学硕士
实际应用。结果表明云山可以超越其他模型
在基准上具有相似的尺度。
]]></description>
      <guid>http://arxiv.org/abs/2312.17276</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:21 GMT</pubDate>
    </item>
    <item>
      <title>用于进行高级文本分析信息系统研究的大型语言模型。 （arXiv：2312.17278v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17278</link>
      <description><![CDATA[数字内容的指数级增长产生了大量文本
数据集，需要先进的分析方法。大型语言模型
（法学硕士）已成为能够处理和提取见解的工具
大量非结构化文本数据集。然而，如何利用法学硕士
基于文本的信息系统（IS）研究目前尚不清楚。协助IS
研究了解如何实施法学硕士，我们提出了一个文本
信息系统研究分析 (TAISR) 框架。我们提出的
框架提供了基于 IS 和 LLM 文献的详细建议
关于如何进行有意义的基于文本的信息系统研究。我们做了三个案例
使用我们的 TAISR 框架进行商业智能研究，以展示其
跨多个 IS 研究背景的应用。我们还概述了潜力
采用法学硕士进行 IS 的挑战和限制。通过提供系统的
方法及其实用性的证据，我们的 TAISR 框架有助于未来
IS 研究流寻求将强大的法学硕士纳入文本分析。
]]></description>
      <guid>http://arxiv.org/abs/2312.17278</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:21 GMT</pubDate>
    </item>
    <item>
      <title>ESGReveal：一种基于 LLM 的方法，用于从 ESG 报告中提取结构化数据。 （arXiv：2312.17264v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17264</link>
      <description><![CDATA[ESGReveal 是一种创新方法，旨在高效提取和
分析企业的环境、社会和治理 (ESG) 数据
报告，满足可靠的 ESG 信息检索的迫切需求。
该方法利用通过检索增强的大型语言模型 (LLM)
增强生成（RAG）技术。 ESGReveal 系统包括 ESG
用于定向查询的元数据模块，用于组装的预处理模块
数据库和用于数据提取的 LLM 代理。其功效被评价
使用香港交易所上市公司各行业 166 家公司的 ESG 报告
2022年港交所，确保行业和市场全面
大写表示。利用 ESGReveal 发现了重要的
使用 GPT-4 深入了解 ESG 报告，显示准确度为 76.9%
数据提取和披露分析 83.7%，比
基线模型。这凸显了该框架提炼 ESG 数据的能力
分析精度。此外，它还揭示了对强化 ESG 的需求
环境和社会数据披露比例为69.5%
和 57.2% 分别表明追求更高的企业透明度。
虽然 ESGReveal 的当前迭代不处理图片信息，
为了未来增强的功能，该研究呼吁继续
研究进一步开发和比较各种分析能力
法学硕士。综上所述，ESGReveal 在 ESG 数据处理方面向前迈出了一大步，
为利益相关者提供复杂的工具来更好地评估和推进
企业可持续发展的努力。其演变有望促进
公司报告的透明度并与更广泛的可持续发展保持一致
发展目标。
]]></description>
      <guid>http://arxiv.org/abs/2312.17264</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:20 GMT</pubDate>
    </item>
    <item>
      <title>通过多视图解耦学习改进基于低资源提示的关系表示。 （arXiv：2312.17267v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17267</link>
      <description><![CDATA[最近，使用预训练语言模型 (PLM) 进行即时调优已成为可能
证明了关系提取（RE）能力的显着增强
任务。然而，在资源匮乏的情况下，可用的训练数据是
稀缺的，以前基于提示的方法对于基于提示的方法可能仍然表现不佳
由于对关系的肤浅理解而导致的表征学习。到
为此，我们强调学习高质量关系的重要性
RE 的低资源场景中的代表性，并提出了一种新颖的
基于提示的关系表示方法，称为MVRE
(\underline{M}ulti-\underline{V}iew \underline{R}elation
\underline{E}xtraction），更好地利用 PLM 的能力来改善
RE 在低资源提示调整范式中的性能。具体来说，
MVRE 将每种关系解耦为不同的视角来涵盖
多视图关系表示，用于最大化期间的可能性
关系推理。此外，我们还设计了 Global-Local 损失和
动态初始化方法可更好地对齐多视图
代表关系的虚拟词，包含关系的语义
优化学习过程和初始化期间的标签。广泛的
在三个基准数据集上的实验表明我们的方法可以实现
在资源匮乏的环境中实现最先进的技术。
]]></description>
      <guid>http://arxiv.org/abs/2312.17267</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:20 GMT</pubDate>
    </item>
    <item>
      <title>大学讲座录音中教学活动的多模态分类。 （arXiv：2312.17262v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17262</link>
      <description><![CDATA[人们对在线高等教育的理解方式发生了巨大变化
全球疫情形势。教学是远程进行的，
教师将讲座录音作为教材的一部分。
这种新的在线教学环境极大地影响了大学
类。丰富虚拟课堂的在线教学技术
过去两年里资金充足，但支持方面却没有出现同样的情况
在线学习期间的学生。 {为了克服这一限制，我们的目标是
努力使学生能够轻松访问课程内容
教师解释理论概念、解决问题的录音
练习，或对课程组织问题的评论。为此，我们
提出一种多模态分类算法来识别
在课程的任何时间通过使用
基于变压器的语言模型，利用音频文件中的特征
来自自动讲座转录。实验结果将表明
一些学术活动通过音频更容易识别
需要借助文本转录的信号来识别其他信号。
总而言之，我们的贡献旨在认可一个学术活动
老师在上课时。
]]></description>
      <guid>http://arxiv.org/abs/2312.17262</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:19 GMT</pubDate>
    </item>
    <item>
      <title>TACIT：用于跨域文本分类的与目标无关的特征解缠框架。 （arXiv：2312.17263v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17263</link>
      <description><![CDATA[跨域文本分类旨在从标签丰富的模型中迁移模型
将源域标记为较差的目标域，使其具有广泛的范围
实际应用。许多方法通过以下方式促进跨领域泛化
捕获域不变特征。然而，这些方法依赖于未标记的
目标域提供的样本，导致模型无效
当目标域不可知时。此外，模型很容易
受到源域中快捷方式学习的干扰，这也阻碍了
领域泛化能力的提高。为了解决上述问题
问题，本文提出了TACIT，一种与目标域无关的特征
解耦框架，自适应地解耦鲁棒性和非鲁棒性
变分自动编码器的功能。此外，为了鼓励
将不鲁棒的特征与鲁棒的特征分离，我们设计了一个特征
蒸馏任务，迫使不稳健的特征近似输出
老师。教师模型是用一些简单的样本进行训练的，这些样本很容易
携带潜在的未知捷径。实验结果验证了我们的
框架取得了与最先进的基线相当的结果，同时
仅利用源域数据。
]]></description>
      <guid>http://arxiv.org/abs/2312.17263</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:19 GMT</pubDate>
    </item>
    <item>
      <title>具有长期条件记忆的不断发展的大型语言模型助手。 （arXiv：2312.17257v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17257</link>
      <description><![CDATA[随着大型语言模型的快速发展，AI助手如
ChatGPT已广泛进入人们的工作和生活。在本文中，我们提出
一个不断发展的大型语言模型助手，利用口头长期
记忆。它的重点是保存历史中的知识和经验
用户与AI助手之间的对话，可应用于未来
对话以产生更好的反应。模型生成一组记录
每个完成的对话并将它们存储在内存中。在以后的使用中，给出
新的用户输入，模型使用它来检索其相关的记忆以改进
响应的质量。为了找到最好的记忆形式，我们探索
构建记忆的不同方式并提出新的记忆
称为条件记忆的机制来解决以前方法中的问题。
我们还研究了一代中记忆的检索和使用
过程。该助手使用 GPT-4 作为主干，我们从三个方面对其进行评估
构建了专注于人工智能所需的不同能力的测试数据集
具有长期记忆能力的助手。
]]></description>
      <guid>http://arxiv.org/abs/2312.17257</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:18 GMT</pubDate>
    </item>
    <item>
      <title>增强大型语言模型代理的工作记忆。 （arXiv：2312.17259v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17259</link>
      <description><![CDATA[大型语言模型 (LLM) 取得了令人印象深刻的语言学成就
能力。然而，一个关键的限制仍然存在，即它们缺乏类似人类的能力。
记忆能力。 LLM 表现出跨顺序的内存保留受限
相互作用，阻碍复杂的推理。本文探讨了潜力
应用认知心理学的工作记忆框架，提高法学硕士
建筑学。分析了传统LLM存储器设计的局限性，
包括他们对不同对话情节的隔离以及缺乏持久的
记忆链接。为了解决这个问题，提出了一种创新模型，其中包含
集中式工作记忆中心和情景缓冲区访问以保留记忆
跨剧集。该架构旨在提供更大的连续性
在复杂的任务和协作过程中进行细致入微的上下文推理
场景。虽然前景广阔，但仍需要进一步研究来优化
情景记忆编码、存储、优先级、检索和安全。
总体而言，本文为发展LLM代理人提供了战略蓝图
具有更复杂、类人的记忆能力，突出记忆力
机制作为通用人工智能的重要前沿。
]]></description>
      <guid>http://arxiv.org/abs/2312.17259</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:18 GMT</pubDate>
    </item>
    <item>
      <title>基于深度学习的情感分类：比较调查。 （arXiv：2312.17253v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17253</link>
      <description><![CDATA[最近，深度学习（DL）方法已被应用于解决
情感分类（SC）问题，这是评论挖掘的核心任务
或情绪分析 (SA)。这些方法的性能受到影响
由不同的因素。本文讨论了这些因素并对它们进行了分类
分为三类：基于数据准备的因素、特征表示
基于因素和基于分类技术的因素。该纸是一个
基于文献的综合调查，比较了更多
超过 100 个基于 DL 的 SC 方法，使用 21 个公共评论数据集
三个特定应用领域（产品、电影和
餐厅）。这21个数据集具有不同的特征
（平衡/不平衡、大小等）为我们的研究提供全球视野。这
比较解释了所提出的因素如何定量地影响
所研究的基于深度学习的 SC 方法的性能。
]]></description>
      <guid>http://arxiv.org/abs/2312.17253</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>基于模型的指标的忠实模型评估。 （arXiv：2312.17254v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17254</link>
      <description><![CDATA[统计显着性测试用于自然语言处理 (NLP)
确定研究或实验的结果是否可能是正确的
偶然或者他们是否反映了真正的关系。意义重大的关键一步
测试是对置信区间的估计，它是样本的函数
方差。评估时样本方差计算很简单
反对基本事实。然而，在许多情况下，度量模型通常用于
评估。例如，为了比较两个大型语言模型的毒性，
毒性分级器用于评价。现有作品通常不会
考虑由于度量模型误差导致的方差变化，这可能导致
错误的结论。在这项工作中，我们建立了数学基础
基于模型的指标的显着性测试。通过对公众的实验
基准数据集和生产系统，我们表明考虑指标
计算基于模型的指标的样本方差的模型错误会改变
在某些实验中得出的结论。
]]></description>
      <guid>http://arxiv.org/abs/2312.17254</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>从字节到偏见：调查大型语言模型的文化自我感知。 （arXiv：2312.17256v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.17256</link>
      <description><![CDATA[大型语言模型 (LLM) 能够处理听起来自然的问题
与人类对话，展示了前所未有的能力
信息检索和自动决策支持。他们扰乱了
人与技术的互动以及企业的运营方式。然而，
众所周知，基于生成人工智能（GenAI）的技术
海量数据集带来的幻觉、误导和显示偏差
他们接受过培训。现有研究表明，人类可能
无意识地内化了这些偏见，即使在它们停止之后，这些偏见仍然会持续存在
使用程序。本研究通过以下方式探讨了法学硕士的文化自我认知：
向 ChatGPT (OpenAI) 和 Bard (Google) 提出以下价值问题：
全球项目。研究结果表明，他们的文化自我认知
与英语国家的价值观最接近
具有持续经济竞争力的国家。认识到
法学硕士的文化偏见以及了解他们的工作方式对所有人都至关重要
社会成员，因为人们不想要人工的黑匣子
智力使人类永久存在偏见，反过来，人类可能会无意中
创建和训练更具偏见的算法。
]]></description>
      <guid>http://arxiv.org/abs/2312.17256</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:17 GMT</pubDate>
    </item>
    </channel>
</rss>