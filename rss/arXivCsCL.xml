<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Thu, 14 Dec 2023 03:14:49 GMT</lastBuildDate>
    <item>
      <title>FULL-W2V：在 GPU 加速系统上充分利用 W2V 的数据重用。 （arXiv：2312.07743v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.07743</link>
      <description><![CDATA[Word2Vec 仍然是该领域极具影响力的创新之一
自然语言处理（NLP），代表潜在的语法和
具有低维密集向量的人类文本中的句法信息。
由于算法本身的原因，Word2Vec 的计算成本较高
顺序性、密集的内存访问以及大量的词汇表
代表。虽然之前的研究已经调查了技术来探索
并行性并提高内存系统性能，他们努力有效地
在强大的 GPU 上获得吞吐量。

我们认为内存数据访问和延迟是之前的主要瓶颈
在 GPU 上工作，这会阻止高度优化的内核获得
架构的峰值性能。我们提出了一种新颖的算法 FULL-W2V，
最大限度地利用W2V算法中数据重用的机会，
利用 GPU 架构和资源来减少对低内存级别的访问
并改善时间局部性。 FULL-W2V 能够减少对 GPU 的访问
与之前相比，全局记忆显着提高，例如超过 89%
最先进的 GPU 实现，带来显着的性能
跨越连续几代硬件的改进。我们的原型
当从 Nvidia Pascal P100 移植到
Volta V100 卡，比 V100 卡上最先进的技术高出 5.72 倍
具有相同的嵌入质量。深入分析表明，减少
通过寄存器和共享内存缓存进行内存访问
高吞吐量共享内存的减少导致显着改善
算术强度。 FULL-W2V 可能使 NLP 中的许多应用受益
和其他领域。
]]></description>
      <guid>http://arxiv.org/abs/2312.07743</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>大型人类语言模型：需求和挑战。 （arXiv：2312.07751v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07751</link>
      <description><![CDATA[随着以人为中心的 NLP 研究的进展，人们越来越认识到
将人类和社会因素纳入 NLP 模型的重要性。在
与此同时，我们的 NLP 系统已经严重依赖 LLM，其中大多数
不为作者建模。打造真正能够理解的NLP系统
人类语言，我们必须更好地将人类背景融入法学硕士。这带来
突出了一系列设计考虑因素和挑战
要捕捉的人的方面、如何表示它们以及什么建模策略
去探求。为了解决这些问题，我们主张三种立场：
使用心理学和语言学概念的大型人类语言模型 (LHLM)
行为科学：首先，LM 培训应包括人类背景。
其次，LHLM 应该认识到人们不仅仅是他们的群体。第三，
LHLM 应该能够解释动态和时间依赖性
人类背景。我们参考相关进展并提出开放挑战
需要解决的问题以及实现这些问题的可能解决方案
目标。
]]></description>
      <guid>http://arxiv.org/abs/2312.07751</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>LLM能找到绿色圆圈吗？用于组合概括的调查和人工引导工具操作。 （arXiv：2312.07763v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07763</link>
      <description><![CDATA[自然语言中复杂短语的含义是由它们的
单独的组件。组合概括的任务评估
模型理解新的组件组合的能力。之前的学习
训练的较小的、特定于任务的模型，其泛化能力较差。
虽然大型语言模型 (LLM) 表现出令人印象深刻的泛化能力
通过情境学习（ICL）来完成许多任务，他们的潜力
成分概括仍有待探索。在本文中，我们首先
实证研究成分泛化中流行的 ICL 方法。
我们发现他们在处理复杂的作文问题时遇到困难，因为
长推理步骤和复杂逻辑所需的累积错误
工具制造。因此，我们提出了一种人工引导的工具操作
框架（HTM），生成子问题的工具并集成多个
工具。我们的方法通过以下方式提高了工具创建和使用的效率
最少的人力。实验表明我们的方法达到了
在两个组合泛化基准上具有最先进的性能
在最具挑战性的测试中，其性能比现有方法高出 70%。
]]></description>
      <guid>http://arxiv.org/abs/2312.07763</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>数学语言模型：调查。 （arXiv：2312.07622v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07622</link>
      <description><![CDATA[近年来，在利用语言方面取得了显着进展
模型 (LM)，包括预训练语言模型 (PLM) 和大规模
数学领域内的语言模型（LLM）。本文进行了
对数学语言模型的全面调查，系统地对关键的语言模型进行分类
研究工作从两个不同的角度进行：任务和方法。这
景观揭示了大量提出的数学法学硕士，它们是
进一步划分为教学学习、基于工具的方法、基础
CoT 技术和先进的 CoT 方法。此外，我们的调查还包括
编译了 60 多个数学数据集，包括训练数据集，
基准数据集和增强数据集。解决主要挑战
并描绘了数学 LM 领域的未来轨迹，这
调查被定位为宝贵的资源，旨在促进和启发
投资于推进该领域的研究人员的未来创新。
]]></description>
      <guid>http://arxiv.org/abs/2312.07622</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>CLIP 作为 RNN：无需训练即可分割无数视觉概念。 （arXiv：2312.07661v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.07661</link>
      <description><![CDATA[现有的开放词汇图像分割方法需要微调
踩在掩模注释和/或图像文本数据集上。面膜标签有
劳动密集型，限制了细分中的类别数量
数据集。因此，预训练 VLM 的开放词汇能力为
微调后大幅降低。然而，在没有微调的情况下，VLM 训练
在弱图像文本监督下往往会做出次优的掩模预测
有文本查询引用图像中不存在的概念。到
为了缓解这些问题，我们引入了一种新颖的循环框架
逐步过滤掉不相关的文本并增强蒙版质量，而无需
培训工作。循环单元是一个基于 VLM 的两级分段器
与冷冻重量。因此，我们的模型保留了 VLM 广泛的词汇空间
并强化细分能力。实验结果表明我们的
该方法不仅优于未经训练的方法，而且优于那些
使用数百万个额外数据样本进行微调，并设置新的
零样本语义和参考图像的最先进记录
分割任务。具体来说，我们将当前记录提高了 28.8、16.0、
Pascal VOC、COCO 对象和 Pascal 上下文的 6.9 MIoU。
]]></description>
      <guid>http://arxiv.org/abs/2312.07661</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>阿拉伯语手写文本行数据集。 （arXiv：2312.07573v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07573</link>
      <description><![CDATA[将阿拉伯语手稿分割成文本行和单词是一种
使识别系统更加高效和准确的重要一步。这
分割成文本行的问题得到了解决，因为有仔细的
专用于该任务的带注释的数据集。然而，尽我们最大的努力
据了解，没有注释阿拉伯文本单词位置的数据集。
在本文中，我们提出了一个专门为历史数据设计的新数据集
我们在单词级别注释位置的阿拉伯文字。
]]></description>
      <guid>http://arxiv.org/abs/2312.07573</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>ConvD：用于知识图补全的注意力增强动态卷积嵌入。 （arXiv：2312.07589v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07589</link>
      <description><![CDATA[知识图通常存在不完整性，这可能是
通过补充缺失的信息可以缓解。深度知识卷积
基于神经网络的嵌入模型是目前流行的方法
知识图谱补全。然而，大多数现有方法使用外部
卷积核和传统的普通卷积过程，这限制了
模型的特征交互能力。在本文中，我们提出了一个
知识图谱的新型动态卷积嵌入模型ConvD
完成，直接将关系嵌入重塑为多个
内部卷积核来改进外部卷积核
传统的卷积嵌入模型。内部卷积核可以
有效增强关系嵌入之间的特征交互
实体嵌入，从而提高模型嵌入性能。此外，我们
设计一个先验知识优化的注意力机制，可以分配
不同贡献权重系数对多重关系卷积
动态卷积核以提高模型的表达能力
更远。对各种数据集的广泛实验表明，我们提出的模型
始终优于最先进的基线方法，平均
所有模型评估的改进范围为 11.30% 到 16.92%
指标。消融实验验证了各组成模块的有效性
ConvD 模型的。
]]></description>
      <guid>http://arxiv.org/abs/2312.07589</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>评估 ChatGPT 作为问答系统：与现有模型的综合分析和比较。 （arXiv：2312.07592v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07592</link>
      <description><![CDATA[当今时代，出现了多种语言模型来迎合
用户查询。值得注意的是，GPT-3.5 Turbo 语言模型获得了
作为 ChatGPT 的底层技术，受到了广泛关注。杠杆作用
该模型具有广泛的参数，可以熟练地回答各种问题。
然而，由于其依赖于内部知识，响应的准确性
可能不是绝对的。本文将 ChatGPT 作为问答系统进行仔细研究
系统 (QAS)，将其性能与其他现有 QAS 进行比较。首要的
重点是评估 ChatGPT 从以下内容中提取响应的能力：
提供的段落，核心 QAS 能力。此外，性能
比较是在没有周围通道的情况下进行的。多种的
实验，探索反应幻觉并考虑问题
复杂性，是在 ChatGPT 上进行的。评价采用知名问题
回答 (QA) 数据集，包括 SQuAD、NewsQA 和 PersianQuAD
英语和波斯语。 F 分数、精确匹配等指标
评估中采用了准确性。研究表明，虽然 ChatGPT
展示了作为生成模型的能力，但在问题上效果较差
与特定任务模型相比的答案。提供上下文可以提高其
性能和及时的工程提高了精度，特别是对于
所提供段落中缺乏明确答案的问题。 ChatGPT 擅长
与“如何”和“为什么”问题类型相比，事实问题更简单。这
评估突出显示幻觉的发生，ChatGPT 提供
对所提供上下文中没有可用答案的问题的回答。
]]></description>
      <guid>http://arxiv.org/abs/2312.07592</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>使用 BERT 跨双平台的文章和推文进行对比新闻和社交媒体链接。 （arXiv：2312.07599v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07599</link>
      <description><![CDATA[X（以前的 Twitter）已经发展成为一个当代的集市，提供
个人对时事表达意见和观点的平台。
Twitter 上讨论的大多数主题都与正在进行的直接相关
事件，使其成为监控公众言论的重要来源。然而，
将推文链接到特定新闻是一项重大挑战，因为它们
简洁和非正式的性质。以前的方法，包括主题模型，
基于图的模型和监督分类器在
有效捕捉推文和文章的独特特征。

受到计算机视觉领域 CLIP 模型成功的启发，该模型采用
对比学习来模拟图像和标题之间的相似性，这
论文介绍了一种用于训练表征的对比学习方法
链接的文章和推文表现出邻近性的空间。我们展示我们的
对比学习方法，CATBERT（对比文章推文 BERT），
利用预先训练的 BERT 模型。该模型经过训练和测试
包含手动标记的英语和波兰语推文和文章的数据集
与俄罗斯和乌克兰战争有关。我们评估 CATBERT 的性能
LDA等传统方法和基于OpenAI的新颖方法
嵌入，之前尚未应用于此任务。我们的发现
表明 CATBERT 在关联推文方面表现出卓越的性能
以及相关新闻文章。此外，我们还展示了
应用于查找主要主题（以文章为代表）的模型
整个推文级联。在这个新任务中，我们报告了
不同的模型取决于级联大小。
]]></description>
      <guid>http://arxiv.org/abs/2312.07599</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>短文本聚类的联邦学习。 （arXiv：2312.07556v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07556</link>
      <description><![CDATA[短文本聚类因其在以下领域的重要性而受到广泛研究：
从许多短文本中挖掘有价值的见解。在本文中，我们重点关注
联合短文本聚类（FSTC）问题，即短文本聚类
分布在不同的客户端，这是一个现实问题
隐私要求。与集中式短文本聚类相比
短文本存储在中央服务器上的问题，FSTC 问题
还没有被探索过。为了填补这一空白，我们提出了联邦稳健空头
文本聚类 (FSTC) 框架。 FSTC 包括两个主要模块，即鲁棒性
短文本聚类模块和联邦聚类中心聚合模块。
鲁棒的短文本聚类模块旨在训练有效的短文本
每个客户端中具有本地数据的聚类模型。我们创新地结合
使用高斯均匀混合模型生成伪标签的最佳传输
确保伪监督数据的可靠性。联邦集群
中心聚合模块旨在在客户之间交换知识，而无需
以有效的方式共享本地原始数据。服务器聚合本地
来自不同客户端的聚类中心，然后将全局中心发送回来
每轮沟通中的所有客户。我们对三个方面的实证研究
短文本聚类数据集表明 FSTC 显着优于
联合短文本聚类基线。
]]></description>
      <guid>http://arxiv.org/abs/2312.07556</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>PaperQA：用于科学研究的检索增强生成代理。 （arXiv：2312.07559v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07559</link>
      <description><![CDATA[大型语言模型 (LLM) 可以很好地泛化跨语言任务，但是
遭受幻觉和无法解释的困扰，使其难以
在没有事实依据的情况下评估其准确性。检索增强生成
（RAG）模型已被提出来减少幻觉并提供起源
了解如何生成答案。将此类模型应用于科学
文献可以实现大规模、系统化的科学处理
知识。我们推出 PaperQA，一个 RAG 代理，用于回答有关以下问题的问题
科学文献。 PaperQA 是执行信息检索的代理
跨全文科学文章，评估来源的相关性和
段落，并使用 RAG 提供答案。将该代理视为一个问题
回答模型，我们发现它超越了现有的LLM和LLM代理的性能
根据当前的科学 QA 基准。让这个领域更接近人类
对科学文献进行研究，我们还引入了 LitQA，一个更
复杂的基准，需要检索和综合来自
跨文献的全文科学论文。最后，我们演示一下
PaperQA 与 LitQA 上的人类专家研究人员进行匹配。
]]></description>
      <guid>http://arxiv.org/abs/2312.07559</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>语言模型与弹性重置对齐。 （arXiv：2312.07551v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07551</link>
      <description><![CDATA[通过强化学习（RL）微调语言模型，例如来自人类
反馈（HF）是一种重要的对齐方法。但针对
奖励模型可以提高奖励，同时降低其他领域的绩效，
这种现象被称为奖励黑客、联盟税或语言漂移。第一的，
我们认为常用的测试指标是不够的，而是衡量
不同的算法如何在奖励和漂移之间进行权衡。标准方法
修改了在线和在线之间的 Kullback-Lieber (KL) 惩罚奖励
初始模型。我们提出了 Elastic Reset，这是一种实现更高性能的新算法
在不明确修改训练目标的情况下以较小的漂移进行奖励。我们
定期将在线模型重置为指数移动平均线 (EMA)
本身，然后将 EMA 模型重置为初始模型。通过使用
EMA，我们的模型在重置后快速恢复并获得更高的奖励
相同步数下的漂移更少。我们证明了微调
具有 Elastic Reset 的语言模型可在
小规模枢轴翻译基准，优于所有基线
中等规模的类似 RLHF 的 IMDB 模拟情感任务，并带来更高的性能
以及与 LLaMA-7B 更加一致的技术 QA 聊天机器人。代码可在
github.com/mnoukhov/elastic-reset。
]]></description>
      <guid>http://arxiv.org/abs/2312.07551</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:44 GMT</pubDate>
    </item>
    <item>
      <title>用于意图驱动的会话推荐的大型语言模型。 （arXiv：2312.07552v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.07552</link>
      <description><![CDATA[意图感知会话推荐 (ISR) 对于辨别用户至关重要
会话中的意图以进行精确预测。传统方法，
然而，由于其假设的统一数量而面临局限性
所有会话的意图。这个假设忽视了动态的本质
用户会话，其中意图的数量和类型可能有很大差异。
此外，这些方法通常在潜在空间中操作，从而阻碍了
模型的透明度。为了解决这些挑战，我们引入了一种新颖的 ISR
方法，利用大语言的高级推理能力
模型（法学硕士）。首先，此方法首先生成一个初始提示：
指导法学硕士根据不同的意图预测会话中的下一个项目
体现在用户会话中。然后，为了完善这个过程，我们引入了一个
创新的提示优化机制，迭代自我反思和
调整提示。此外，我们的提示选择模块建立在法学硕士的基础上
适应性广泛，可在不同的环境中快速选择最优化的提示
域。这种新范式使法学硕士能够以不同的方式辨别不同的用户意图
语义级别，导致更准确和可解释的会话
建议。我们对三个真实世界数据集进行了广泛的实验
证明我们方法的有效性，标志着重大进步
在 ISR 系统中。
]]></description>
      <guid>http://arxiv.org/abs/2312.07552</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:44 GMT</pubDate>
    </item>
    <item>
      <title>大型多模态模型中的劫持上下文。 （arXiv：2312.07553v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.07553</link>
      <description><![CDATA[最近，大型多模态模型 (LMM) 已经证明了它们能够
根据相关说明理解图像的视觉内容
图片。 LMM 建立在大型语言模型 (LLM) 的基础上，还继承了它们的
能力和特征，例如情境学习，其中连贯一致
给出图像和文本序列作为输入提示。然而，我们
确定现成 LMM 的新限制，其中一小部分
不连贯的图像或文本描述会误导 LMM，使其产生偏见
有关被劫持上下文的输出，而不是最初预期的上下文。到
为了解决这个问题，我们提出了一种预过滤方法，可以去除不相关的内容
通过 GPT-4V 的上下文，基于其对内部分布转移的鲁棒性
上下文。我们进一步调查是否替换被劫持的视觉和
通过 GPT-4V 和文本到图像模型将文本上下文与相关上下文关联起来
可以帮助产生连贯的反应。
]]></description>
      <guid>http://arxiv.org/abs/2312.07553</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:44 GMT</pubDate>
    </item>
    <item>
      <title>理解文本到图像生成模型中的（非）预期记忆。 （arXiv：2312.07550v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.07550</link>
      <description><![CDATA[多模态机器学习，尤其是像 Stable 这样的文本到图像模型
Diffusion 和 DALL-E 3，对于将文本转换为文本具有重要意义
详细的图像。

尽管它们的使用不断增长且生成能力显着，但仍有
迫切需要对这些模型的行为进行详细检查，
特别是在记忆方面。从历史上看，记忆
机器学习一直依赖于上下文，并且出现了不同的定义
从分类任务到大型语言模型 (LLM) 等复杂模型
和扩散模型。然而，一个明确的记忆概念与
文本到图像合成的复杂性仍然难以捉摸。这
理解至关重要，因为记忆会带来隐私风险，但对于
满足用户期望，特别是在生成表示时
代表性不足的实体。在本文中，我们引入一个专门的定义
针对文本到图像模型定制的记忆，将其分为三类
根据用户期望的不同类型。我们仔细审视微妙之处
有意记忆和无意记忆之间的区别，强调
平衡用户隐私与模型生成质量的重要性
输出。使用稳定扩散模型，我们提供示例来验证我们的
记忆定义并阐明其应用。
]]></description>
      <guid>http://arxiv.org/abs/2312.07550</guid>
      <pubDate>Thu, 14 Dec 2023 03:14:43 GMT</pubDate>
    </item>
    </channel>
</rss>