<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Wed, 03 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>大型语言模型的公平性：分类学调查</title>
      <link>https://arxiv.org/abs/2404.01349</link>
      <description><![CDATA[arXiv:2404.01349v1 公告类型：新
摘要：大型语言模型（LLM）在各个领域都取得了显着的成功。然而，尽管它们在许多实际应用中表现良好，但大多数算法缺乏公平性考虑。因此，它们可能会导致针对某些社区，特别是边缘化人群的歧视性结果，从而促使公平的法学硕士进行广泛的研究。另一方面，法学硕士的公平性与传统机器学习的公平性相反，需要独特的背景、分类法和实现技术。为此，本次调查全面概述了有关公平法学硕士的现有文献的最新进展。具体来说，对法学硕士进行了简要介绍，然后分析了导致法学硕士偏见的因素。此外，还对法学硕士公平性的概念进行了分类讨论，总结了评估法学硕士偏见的指标以及促进公平性的现有算法。此外，还总结了用于评估法学硕士偏差的资源，包括工具包和数据集。最后，讨论了现有的研究挑战和悬而未决的问题。]]></description>
      <guid>https://arxiv.org/abs/2404.01349</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>关心你的邻居：利用类似实例为法律文件进行修辞角色标签</title>
      <link>https://arxiv.org/abs/2404.01344</link>
      <description><![CDATA[arXiv:2404.01344v1 公告类型：新
摘要：法律判决的修辞角色标签（RRL）对于案例摘要、语义搜索和论点挖掘等各种任务至关重要。然而，它提出了一些挑战，例如从上下文推断句子角色、相互关联的角色、有限的注释数据和标签不平衡。本研究引入了利用语义相似实例（邻居）的知识来增强 RRL 性能的新技术。我们探索基于推理和基于训练的方法，在具有挑战性的宏观 F1 分数方面取得了显着的进步。对于基于推理的方法，我们探索了无需重新训练即可增强标签预测的插值技术。在基于训练的方法中，我们将原型学习与直接作用于嵌入空间的新颖的话语感知对比方法相结合。此外，我们评估了我们的方法的跨领域适用性，证明了它们在跨不同法律领域转移知识方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.01344</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>使用双向门控循环单元和深度学习技术增强孟加拉假新闻检测</title>
      <link>https://arxiv.org/abs/2404.01345</link>
      <description><![CDATA[arXiv:2404.01345v1 公告类型：新
摘要：假新闻的兴起使得对有效检测方法（包括英语以外的语言）的需求变得越来越重要。该研究旨在解决孟加拉语所面临的挑战，因为孟加拉语被认为是不太重要的语言。为此，提出了包含约 50,000 条新闻的完整数据集。在此数据集上测试了多种深度学习模型，包括双向门控循环单元 (GRU)、长短期记忆 (LSTM)、一维卷积神经网络 (CNN) 和混合架构。在这项研究中，我们利用一系列有用的指标评估了模型的有效性，包括召回率、精确度、F1 分数和准确性。这是通过使用大型应用程序来完成的。我们进行了全面的试验，以证明这些模型在识别孟加拉语虚假新闻方面的有效性，其中双向 GRU 模型的准确率高达 99.16%。我们的分析强调了数据集平衡的重要性以及在很大程度上持续改进的必要性。这项研究为利用有限资源创建孟加拉假新闻检测系统做出了重大贡献，从而为未来检测过程的改进奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2404.01345</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>DiffAgent：使用大型语言模型快速准确地选择文本到图像 API</title>
      <link>https://arxiv.org/abs/2404.01342</link>
      <description><![CDATA[arXiv:2404.01342v1 公告类型：新
摘要：文本到图像（T2I）生成模型引起了人们的广泛关注，并在学术研究内外得到了广泛的应用。例如，Civitai 社区是一个 T2I 创新平台，目前拥有 74,492 个不同模型，令人印象深刻。然而，这种多样性给选择最合适的模型和参数带来了巨大的挑战，这个过程通常需要进行多次试验。从大型语言模型 (LLM) 的工具使用研究中汲取灵感，我们推出了 DiffAgent，这是一种 LLM 代理，旨在通过 API 调用在几秒钟内筛选出准确的选择。 DiffAgent 利用新颖的两阶段训练框架 SFTA，使其能够根据人类偏好准确地将 T2I API 响应与用户输入对齐。为了训练和评估 DiffAgent 的功能，我们推出了 DABench，这是一个包含来自社区的广泛 T2I API 的综合数据集。我们的评估表明，DiffAgent 不仅在识别合适的 T2I API 方面表现出色，而且还强调了 SFTA 培训框架的有效性。代码可在 https://github.com/OpenGVLab/DiffAgent 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.01342</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>CHOPS：与客户档案系统聊天，为法学硕士提供客户服务</title>
      <link>https://arxiv.org/abs/2404.01343</link>
      <description><![CDATA[arXiv:2404.01343v1 公告类型：新
摘要：企业和软件平台越来越多地转向大型语言模型 (LLM)，例如 GPT-3.5、GPT-4、GLM-3 和 LLaMa-2，以提供文件访问聊天帮助或作为客户服务的推理代理。然而，当前基于法学硕士的客户服务模型与客户档案的整合有限，并且缺乏有效服务所需的运营能力。此外，现有的 API 集成强调多样性，而不是现实客户服务场景中至关重要的精度和避免错误。为了解决这些问题，我们提出了一种名为 CHOPS（现有系统中与客户资料的 CHat）的 LLM 代理，旨在：（1）有效利用现有数据库或系统来访问用户信息或遵循现有准则与这些系统进行交互； （二）在系统中提供准确、合理的响应或进行所需的操作，同时避免有害操作； (3) 利用小型和大型法学硕士的组合，以合理的推理成本实现令人满意的性能。我们介绍了一个实用的数据集，即 CPHOS 数据集，其中包括从 CPHOS 收集的数据库、指导文件和 QA 对，CPHOS 是一个在线平台，有助于为高中教师和学生组织模拟物理奥林匹克竞赛。我们进行了广泛的实验，使用 CPHOS 数据集验证我们提出的 CHOPS 架构的性能，目的是展示法学硕士如何增强或替代人类客户服务。我们的代码和数据集将很快开源。]]></description>
      <guid>https://arxiv.org/abs/2404.01343</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>结合自然语言处理和机器学习检测财经新闻话语层面的时态性</title>
      <link>https://arxiv.org/abs/2404.01337</link>
      <description><![CDATA[arXiv:2404.01337v1 公告类型：新
摘要：彭博新闻、CNN Business 和福布斯等财经相关新闻是市场筛选系统的宝贵真实数据来源。在新闻中，专家分享的观点超出了简单的技术分析，包括政治、社会学和文化因素等背景。在同一篇文章中，专家经常讨论不同资产的表现。一些关键陈述仅仅是对过去事件的描述，而另一些则是预测。因此，了解文本中关键陈述的时间性对于将上下文信息与有价值的预测分开至关重要。我们提出了一种新颖的系统，可以在话语层面检测金融相关新闻的时效性，该系统结合了自然语言处理和机器学习技术，并利用句法和语义依赖性等复杂特征。更具体地说，我们试图提取主要陈述的主导时态，这些时态可以是明确的，也可以是隐含的。我们已经在由具有该领域知识的研究人员注释的金融相关新闻标记数据集上测试了我们的系统。实验结果表明，与替代的基于规则的基线方法相比，检测精度较高。最终，这项研究通过识别金融决策的预测知识，为最先进的市场筛选做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2404.01337</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>通过潜在狄利克雷分配的主题建模自动检测财经新闻中的相关信息、预测和预测</title>
      <link>https://arxiv.org/abs/2404.01338</link>
      <description><![CDATA[arXiv:2404.01338v1 公告类型：新
摘要：财经新闻是非结构化信息源，可以挖掘这些信息来提取市场筛选应用的知识。从源源不断的金融相关新闻中手动提取相关信息非常麻烦，并且超出了许多投资者的技能范围，他们最多只能关注一些消息来源和作者。因此，我们专注于分析财经新闻，以识别相关文本，并在该文本中进行预测和预测。我们提出了一种新颖的自然语言处理（NLP）系统，通过考虑话语层面的相关性和暂时性，帮助投资者检测非结构化文本源中的相关金融事件。首先，我们对文本进行分段，将密切相关的文本分组在一起。其次，我们应用共同引用解析来发现段内的内部依赖关系。最后，我们使用潜在狄利克雷分配（LDA）进行相关主题建模，以将相关文本与不太相关的文本分开，然后使用面向机器学习的时间方法分析相关文本以识别预测和推测性陈述。我们创建了一个由 2,158 条财经新闻条目组成的实验数据集，这些新闻条目由 NLP 研究人员手动标记，以评估我们的解决方案。用于识别相关文本和预测/预测的 ROUGE-L 值分别为 0.662 和 0.982。据我们所知，这是第一篇在话语层面共同考虑相关性和时间性的工作。它通过结合多段落主题分割和共指解析来分离作者表达模式，使用 LDA 进行主题建模来检测相关文本，以及话语时序分析来识别预测和预测，从而有助于将人类联想话语能力转移到专家系统。文本中的预测。]]></description>
      <guid>https://arxiv.org/abs/2404.01338</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>通过零样本情感和不流畅生成进行人性化语音合成</title>
      <link>https://arxiv.org/abs/2404.01339</link>
      <description><![CDATA[arXiv:2404.01339v1 公告类型：新
摘要：当代会话系统通常存在显着的局限性：它们的反应缺乏人类互动的情感深度和不流利的特征。当用户寻求更加个性化和同理心的互动时，这种缺失变得尤其明显。因此，这使得它们看起来很机械，与人类用户不太相关。认识到这一差距，我们踏上了人性化机器通信的旅程，以确保人工智能系统不仅能够理解，而且能够产生共鸣。为了解决这个缺点，我们设计了一种创新的语音合成管道。在此框架内，尖端的语言模型在零样本环境中引入了类人情感和不流畅性。这些错综复杂的内容在文本生成过程中通过语言模型无缝集成到生成的文本中，使系统能够更好地反映人类语音模式，从而促进更直观和自然的用户交互。然后，在文本转语音阶段，使用基于规则的方法将这些生成的元素巧妙地转换为相应的语音模式和情感声音。根据我们的实验，我们的新颖系统生成的合成语音几乎与真实的人类交流没有区别，使每次交互都感觉更加个性化和真实。]]></description>
      <guid>https://arxiv.org/abs/2404.01339</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>等等，这都是象征性的噪音？一直是：使用 Shapley 值解释 LLM 行为</title>
      <link>https://arxiv.org/abs/2404.01332</link>
      <description><![CDATA[arXiv:2404.01332v1 公告类型：新
摘要：大语言模型（LLM）的出现为模拟人类行为和认知过程开辟了令人兴奋的可能性，在营销研究和消费者行为分析等各个领域都有潜在的应用。然而，利用法学硕士作为人类受试者替代品的有效性仍然不确定，因为明显的分歧表明根本不同的潜在过程正在发挥作用，以及法学硕士对即时变化的反应的敏感性。本文提出了一种基于合作博弈论中的 Shapley 值的新颖方法，用于解释 LLM 行为并量化每个提示组件对模型输出的相对贡献。通过两个应用程序——离散选择实验和认知偏差调查——我们展示了沙普利值方法如何揭示我们所说的“令牌噪声”效应，即LLM决策不成比例地受到提供最少信息内容的令牌影响的现象。这种现象引起了人们对法学硕士在人类行为模拟背景下获得的见解的鲁棒性和普遍性的担忧。我们与模型无关的方法将其实用性扩展到专有的法学硕士，为营销人员和研究人员提供了一个有价值的工具，可以战略性地优化提示并减轻明显的认知偏差。我们的研究结果强调，在依赖法学硕士作为研究环境中人类受试者的替代品之前，需要更细致地了解驱动法学硕士反应的因素。我们强调研究人员根据特定提示模板报告结果的重要性，并在将人类行为与法学硕士进行比较时保持谨慎。]]></description>
      <guid>https://arxiv.org/abs/2404.01332</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>使用法学硕士增强 NER 数据集：迈向自动化和精细化注释</title>
      <link>https://arxiv.org/abs/2404.01334</link>
      <description><![CDATA[arXiv:2404.01334v1 公告类型：新
摘要：在自然语言处理（NLP）领域，命名实体识别（NER）被认为是一项关键技术，在广泛的应用中得到广泛应用。为 NER 模型注释数据集的传统方法受到高成本和数据集质量变化的挑战。这项研究引入了一种新颖的混合注释方法，该方法将人类的努力与大型语言模型（LLM）的功能相结合。这种方法不仅旨在改善手动注释中固有的噪声（例如遗漏），从而提高 NER 模型的性能，而且还以经济高效的方式实现这一目标。此外，通过采用标签混合策略，它解决了基于 LLM 的注释中遇到的类不平衡问题。通过对多个数据集的分析，即使在预算有限的情况下，与传统注释方法相比，该方法始终能够提供卓越的性能。这项研究阐明了利用法学硕士提高数据集质量的潜力，引入了一种减轻类别不平衡的新技术，并证明了以经济高效的方式实现高性能 NER 的可行性。]]></description>
      <guid>https://arxiv.org/abs/2404.01334</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>FineFake：用于细粒度多域假新闻检测的知识丰富的数据集</title>
      <link>https://arxiv.org/abs/2404.01336</link>
      <description><![CDATA[arXiv:2404.01336v1 公告类型：新
摘要：现有的假新闻检测基准极大地促进了评估新闻内容真实性的模型的进步。然而，这些基准通常只关注与单一语义主题或源自单一平台的新闻，从而无法捕捉真实场景中多领域新闻的多样性。为了理解各个领域的假新闻，外部知识和细粒度的注释对于提供精确的证据和揭示各种潜在的捏造策略是必不可少的，而现有的基准也忽略了这些策略。为了解决这一差距，我们引入了一种具有细粒度注释的新颖的多领域知识增强基准，名为 \textbf{FineFake}。 FineFake 包含 16,909 个数据样本，涵盖六个语义主题和八个平台。每条新闻都富含多模态内容、潜在的社会背景、半手动验证的常识以及超越传统二进制标签的细粒度注释。此外，我们基于 FineFake 制定了三个具有挑战性的任务，并提出了一个知识增强的域适应网络。 FineFake在各种场景下进行了广泛的实验，为未来的努力提供了准确可靠的基准。整个 FineFake 项目可作为开源存储库公开访问，网址为 \url{https://github.com/Accuser907/FineFake}。]]></description>
      <guid>https://arxiv.org/abs/2404.01336</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>多模态大语言和视觉模型综述</title>
      <link>https://arxiv.org/abs/2404.01322</link>
      <description><![CDATA[arXiv:2404.01322v1 公告类型：新
摘要：大型语言模型（LLM）最近已成为研究和应用的焦点，其驱动力是其前所未有的理解和生成具有人类质量的文本的能力。最近，LLM 已扩展到多模态大语言模型 (MM-LLM)，除了文本之外，还扩展了其处理图像、视频和音频信息的能力。这开辟了文本到视频生成、图像字幕、文本到语音等应用程序，并且可以通过改造具有多模态功能的法学硕士或从头开始构建 MM-LLM 来实现。本文对具有多模式能力的法学硕士以及最近的 MM-LLM 的现状进行了广泛的回顾。它涵盖了法学硕士的历史发展，特别是 OpenAI 的 GPT 系列和 Google 的 BERT 等基于 Transformer 的架构带来的进步，以及注意力机制在增强模型性能方面的作用。该论文涵盖了 LLM 和 MM-LLM 的主要和最重要的内容，还涵盖了模型调整技术，包括微调和即时工程，这些技术根据特定任务或领域定制预训练模型。还分析了数据偏差和模型滥用等道德考虑因素和挑战，以强调负责任的人工智能开发和部署的重要性。最后，我们讨论人工智能研究中开源模型与专有模型的影响。通过这次审查，我们深入了解了 MM-LLM 在各种应用中的变革潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.01322</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>娱乐聊天机器人，为没有抽象能力的老年人提供数字包容</title>
      <link>https://arxiv.org/abs/2404.01327</link>
      <description><![CDATA[arXiv:2404.01327v1 公告类型：新
摘要：当前的语言处理技术允许创建会话聊天机器人平台。尽管人工智能还不够成熟，无法在许多大众市场领域提供令人满意的用户体验，但会话界面已经进入呼叫中心和在线购物助理等临时应用程序。然而，迄今为止，它们尚未应用于老年人的社会融入，因为老年人特别容易受到数字鸿沟的影响。他们中的许多人通过电视和广播等传统媒体来缓解孤独感，众所周知，这些媒体可以创造一种陪伴感。在本文中，我们介绍了 EBER 聊天机器人，旨在缩小老年人的数字鸿沟。 EBER 在后台读取新闻并根据用户的情绪调整其响应。它的新颖之处在于“智能广播”的概念，根据该概念，不是简化数字信息系统以方便老年人使用，而是通过语音对话增强了他们熟悉的传统频道（背景新闻） 。我们通过结合人工智能建模语言、自动自然语言生成和情感分析使之成为可能。该系统允许通过将从用户对聊天机器人问题的回答中提取的单词与从新闻条目中提取的关键字相结合来访问感兴趣的数字内容。这种方法允许根据词空间的空间表示来定义用户的抽象能力的度量。为了证明所提出的解决方案的适用性，我们展示了对老年人进行的真实实验的结果，这些结果提供了有价值的见解。我们的方法在测试期间被认为是令人满意的，并且提高了参与者的信息搜索能力。]]></description>
      <guid>https://arxiv.org/abs/2404.01327</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>LLaVA-Gemma：使用紧凑语言模型加速多模态基础模型</title>
      <link>https://arxiv.org/abs/2404.01331</link>
      <description><![CDATA[arXiv:2404.01331v1 公告类型：新
摘要：我们使用流行的 LLaVA 框架和最近发布的 Gemma 系列大语言模型 (LLM) 来训练一套多模态基础模型 (MMFM)。特别令人感兴趣的是 2B 参数 Gemma 模型，它提供了构建小型 MMFM 的机会。根据该领域其他论文的发现，我们测试了消除三个设计特征的效果：预训练连接器、利用更强大的图像主干以及增加语言主干的大小。由此产生的模型（我们称之为 LLaVA-Gemma）在一系列评估中表现出中等的性能，但未能超越当前同等大小的 SOTA 模型。对性能的更仔细分析表明效果参差不齐；跳过预训练往往会降低性能，较大的视觉模型有时会提高性能，而增加语言模型大小会产生不一致的效果。我们公开发布了 LLaVA-Gemma 模型的训练方案、代码和权重。]]></description>
      <guid>https://arxiv.org/abs/2404.01331</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>智能学习率分布可减少 Transformers 中的灾难性遗忘</title>
      <link>https://arxiv.org/abs/2404.01317</link>
      <description><![CDATA[arXiv:2404.01317v1 公告类型：新
摘要：在大型文本语料库上预训练语言模型是自然语言处理中的常见做法。然后对这些模型进行微调，以在各种任务上获得最佳结果。在本文中，我们研究了变压器神经网络中的灾难性遗忘问题，并对在此背景下对整个网络进行平坦学习率微调的常见做法提出了质疑。我们执行超参数优化过程来找到比平坦学习率更好的学习率分布。我们结合了由此发现的学习率分布，并表明它们对于灾难性遗忘问题可以泛化为更好的性能。我们使用 GLUE 数据集中的各种 NLP 基准验证这些学习率分布。]]></description>
      <guid>https://arxiv.org/abs/2404.01317</guid>
      <pubDate>Wed, 03 Apr 2024 06:17:02 GMT</pubDate>
    </item>
    </channel>
</rss>