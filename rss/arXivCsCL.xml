<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Tue, 01 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>脆弱的精通：特定于领域的权衡是否破坏了设备语言模型？</title>
      <link>https://arxiv.org/abs/2503.22698</link>
      <description><![CDATA[ARXIV：2503.22698V1公告类型：新 
摘要：在资源受限的边缘设备上的应用程序语言模型（ODLM）是一个多维问题，在跨异构任务之间达到了计算效率，内存，功率使用和语言能力之间的良好平衡。这项整体研究对域特异性优化与跨域鲁棒性之间的权衡进行了彻底的研究，最终导致广义边缘模型（GEM）的建议，这是一种新的体系结构，旨在以和谐的方式平衡专业化和概括。通过严格的实验方法测试，在八个领域中进行了47个精心挑选的基准测试 - 健康，法律，财务，STEM，常识，对话，对话性AI，多语言和域名适应性任务 - 我们表明，常规优化技术将目标任务引起的目标降低了18-25％，但报告降低了一般的TASK率降低了F1的一般性降低。 GEM采用稀疏的跨注意路由器（SCAR）将计算分配给可变数量的计算资源，跨域F1精度在Raspberry PI 4，Pixel 6，iPhone 13，iPhone 13和定制的自定义神经处理单元（NPU）的跨域F1精度为0.89。与GPT-4 Lite相比，GEM在特定于域的性能方面的尊重和奇偶校验将一般任务水平提高了7％。我们提出了三个新的测量工具 - 域专业指数（DSI），概括差距（GG）和跨域转移比（CDTR），它们在模型压缩强度和勃tritsens之间表现出很强的相关性。]]></description>
      <guid>https://arxiv.org/abs/2503.22698</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Tridis：HTR和NER的全面的中世纪和早期现代语料库</title>
      <link>https://arxiv.org/abs/2503.22714</link>
      <description><![CDATA[ARXIV：2503.22714V1公告类型：新 
摘要：本文介绍了Tridis（Tria digita Scribunt），这是中世纪和早期现代手稿的开源语料库。 Tridis汇总了多个旧版集合（全部均根据公开许可发布），并包含大型元数据描述。虽然先前的出版物引用了本语料库的某些部分，但在这里，我们提供了一个统一的概述，并更加专注于其宪法。我们描述了（i）每个主要子孔的叙事，年代和编辑背景，（ii）其半单行转录规则（扩展，归一化，标点符号，标点符号），（iii）一种策略，是一种挑战跨域测试的策略，用于跨越跨层的测试，并使用联合嵌入空间和（IV）的前提实验，以及（iv）的前提实验，以及（iv）的前提。分区。总体而言，Tridis旨在激发共同强大的手写文本识别（HTR），并在中世纪和早期现代文本遗产之间进行指定的实体识别（NER）研究。]]></description>
      <guid>https://arxiv.org/abs/2503.22714</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从开放科学文献中得出的大规模视觉数据集，以推动生物医学通才AI</title>
      <link>https://arxiv.org/abs/2503.22727</link>
      <description><![CDATA[ARXIV：2503.22727V1公告类型：新 
摘要：尽管生物医学人工智能（AI）背后兴奋，但获得高质量，多样化和大规模数据的访问 - 现代AI系统的基础 - 仍然是瓶颈，可以释放其全部潜力。为了解决这一差距，我们介绍了BioMedica，这是一种开源数据集，该数据集衍生自PubMed Central Open Access子集，其中包含超过600万个科学文章和2400万个图像文本对，以及27个元数据领域（包括专家人类注释）。为了克服访问大规模数据集的挑战，我们通过Web服务器提供可扩展的流和搜索API，从而促进与AI系统的无缝集成。我们通过构建嵌入模型，聊天风格的模型和检索式聊天代理来证明BioMedica数据集的实用性。值得注意的是，我们所有的AI模型都超过了各自类别中以前的开放系统，强调了各种，高质量和大规模生物医学数据的关键作用。]]></description>
      <guid>https://arxiv.org/abs/2503.22727</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型对用户驱动因素的敏感性在医疗查询中</title>
      <link>https://arxiv.org/abs/2503.22746</link>
      <description><![CDATA[ARXIV：2503.22746V1公告类型：新 
摘要：大型语言模型（LLM）越来越多地用于医疗保健中，但是它们的可靠性受到用户驱动因素的影响，例如问题措辞和临床信息的完整性。在这项研究中，我们研究了错误信息框架，来源权威，模型角色以及关键临床细节的遗漏如何影响LLM产出的诊断准确性和可靠性。我们进行了两个实验：一项引入具有不同自信（扰动测试）的误导性外部意见，另一个删除特定类别的患者信息（消融测试）。使用公共数据集（MEDQA和MEDBULLETS），我们评估了专有模型（GPT-4O，Claude 3.5十四行诗，Claude 3.5 Haiku，Gemini 1.5 Pro，Gemini 1.5 1.5 Flash）和开放源模型（Llama 3 8b，Llama 3 8b，Llama 3 Med42 8b，deepseek R1 R1 8B）。所有模型都容易受到用户驱动的错误信息的影响，专有模型尤其受确定性和权威性语言影响。自信的语调对准确性产生了最大的负面影响。在消融测试中，省略身体检查结果和实验室结果导致最显着的性能下降。尽管专有模型的基线准确性较高，但其性能在错误信息下急剧下降。这些结果突出了结构良好的提示和完整的临床环境的需求。用户应避免对错误信息的权威框架，并提供完整的临床细节，尤其是对于复杂情况。]]></description>
      <guid>https://arxiv.org/abs/2503.22746</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用口罩微调来增强大型语言模型</title>
      <link>https://arxiv.org/abs/2503.22764</link>
      <description><![CDATA[ARXIV：2503.22764V1公告类型：新 
摘要：该模型通常在主流大语言模型（LLM）微调协议中保持不可或缺。没有疑问是否要维持模型的完整性对于性能是必不可少的。在这项工作中，我们介绍了面具微调（MFT），这是一种全新的LLM微调范式，以表明正确打破模型的完整性可以令人惊讶地导致性能提高。具体而言，MFT学习了一组由典型的LLM微调目标监督的二进制口罩。广泛的实验表明，MFT在各种域和骨架上都获得了一致的性能提升（例如，用Llama2-7b/3.1-8b的编码中的1.95％/1.88％的平均增益）。提供了详细的程序，以从不同的超参数角度研究拟议的MFT，以更好地洞悉。特别是，MFT自然会通过将其部署到完整训练的模型上来更新当前的LLM培训协议。这项研究将蒙版学习的功能从其常规的网络修剪环境中以模型压缩到更一般的范围。]]></description>
      <guid>https://arxiv.org/abs/2503.22764</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习推理长篇故事的创造</title>
      <link>https://arxiv.org/abs/2503.22828</link>
      <description><![CDATA[ARXIV：2503.22828V1公告类型：新 
摘要：产生跨越数千个令牌的高质量故事需要各种技能的能力，从跟踪情节和角色弧到保持一致而引人入胜的风格。由于难以采购标记数据集和精确的质量测量结果，大多数使用大型语言模型（LLM）进行长篇故事生成的工作使用了手工设计的提示技术的组合来引起作者般的行为。这是一个高度依赖特定故事生成任务的手动过程。由于最近在数学和编码等领域应用RL将RL应用于诸如数学和编码之类的领域的成功，我们提出了一项一般的故事生成任务（下一章预测）和奖励表述（通过完成的可能性改善验证的奖励），使我们能够将未标记的书数据集用作推理的学习信号。我们学会推理故事的凝结信息，并为下一章制定详细的计划。我们的推理是通过章节评估的，它有助于故事产生者创建，并与未经训练和监督的Finetunting（SFT）基线进行比较。成对的人类判断揭示了我们学到的推理所产生的章节在几乎所有指标中都优先，并且在Scifi和Fantasy类型中的效果更为明显。]]></description>
      <guid>https://arxiv.org/abs/2503.22828</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成合成甲骨文数据集以分析噪声影响：使用推文的建筑功能分类的研究</title>
      <link>https://arxiv.org/abs/2503.22856</link>
      <description><![CDATA[ARXIV：2503.22856V1公告类型：新 
摘要：推文为地球观察任务提供了宝贵的语义上下文，并作为遥感图像的互补方式。在建筑函数分类（BFC）中，通常使用地理启发式方法收集推文，并通过外部数据库进行标记，这是一个固有的弱监督过程，引入了标签噪声和句子级别的特征噪声（例如，无关或无信息推文）。尽管已广泛研究了标签噪声，但句子级别特征噪声的影响仍未被忽视，这主要是由于缺乏干净的基准数据集进行控制分析。在这项工作中，我们提出了一种使用LLM生成合成甲骨文数据集的方法，该方法仅包含与其相关建筑物相关的正确标记和语义相关的推文。该Oracle数据集可以系统地研究噪声影响，这些噪声影响很难在现实世界中隔离。为了评估其效用，我们在三种配置下使用天真的贝叶斯和Mbert分类器比较模型性能：实际与合成训练数据和跨域概括。结果表明，实际推文中的噪声会大大降低姆伯特的上下文学习能力，从而将其性能降低到基于简单的基于关键字的模型的性能。相比之下，干净的合成数据集使Mbert可以有效地学习，从而超过了幼稚的贝叶斯贝叶斯。这些发现强调，在此任务中，解决特征噪声比模型复杂性更为重要。我们的合成数据集为未来的噪声注射研究提供了一个新颖的实验环境，并在GitHub上公开可用。]]></description>
      <guid>https://arxiv.org/abs/2503.22856</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>了解使用代理和检索模型对LLM对地理区域进行事实检查的不平等</title>
      <link>https://arxiv.org/abs/2503.22877</link>
      <description><![CDATA[ARXIV：2503.22877V1公告类型：新 
摘要：事实检查是大型语言模型（LLM）的潜在有用的应用，以打击日益增长的虚假信息传播。但是，LLM的性能在各个地理区域都不同。在本文中，我们评估了各种区域和场景中开放模型和私人模型的事实准确性。
  使用包含600个事实检查的陈述的数据集在六个全球区域之间保持平衡，我们检查了事实检查的三个实验设置：（1）仅使用该陈述时，（2）当利用具有Wikipedia访问的基于LLM的代理商时，（2）将使用Wikipedia访问的代理，（3）当提供了与官方（rag in ag ins system a process in aig systare in Section the systarie feque）的最佳情况。我们的发现表明，不管使用GPT-4，Claude Sonnet和Llama在内的场景和LLM如何，全球北方的陈述的表现都比全球南方的声明要好得多。此外，对于基于Wikipedia代理的系统的更现实的情况，这一差距扩大了，强调过度通用知识库的解决方案的能力有限。这些结果强调了迫切需要更好的数据集平衡和强大的检索策略，以增强LLM事实检查功能，尤其是在地理上不同的环境中。]]></description>
      <guid>https://arxiv.org/abs/2503.22877</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Resona：通过检索改进线性复发模型中的上下文复制</title>
      <link>https://arxiv.org/abs/2503.22913</link>
      <description><![CDATA[ARXIV：2503.22913V1公告类型：新 
摘要：大语言模型（LLM）研究空间的最新变化表明，人们对新型体系结构的关注越来越多，以与长期以来一直主导该空间的典型变压器模型竞争。由于其计算效率，线性复发模型已被证明是可行的竞争对手。但是，与变压器相比，在需要从上下文中召回信息的其他任务和其他任务方面，这种模型仍然表现出很大的差距。 In this work, we introduce __Resona__, a simple and scalable framework for augmenting linear recurrent models with retrieval. __RESONA__〜增强模型，能够从提供的输入上下文中整合检索到的信息，从而使量身定制的行为达到各种任务要求。在各种线性复发模型上进行的实验表明，__Resona __-增强模型可在各种合成以及现实世界的自然语言任务上观察到显着的性能提高，从而强调了其作为提高近距离学习和语言建模能力的通用方法的能力。]]></description>
      <guid>https://arxiv.org/abs/2503.22913</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SUV：可扩展的大型语言模型版权符合正规选择性的符合</title>
      <link>https://arxiv.org/abs/2503.22948</link>
      <description><![CDATA[ARXIV：2503.22948V1公告类型：新 
摘要：大型语言模型（LLM）通过从大规模数据集中学习来改变了自然语言处理，但这种快速的进步也引起了法律审查，因为无意间产生受版权保护的内容的能力已经引发了几项突出的诉讼。在这项工作中，我们介绍了SUV（逐字数据的选择性学习性学习），这是一个选择性的刻板框架，旨在防止LLM在保留其整体实用程序的同时记住受版权保护的内容。详细介绍，提出的方法构建了一个数据集，该数据集捕获了目标LLM的受版权侵权案例的实例。使用数据集，我们通过直接偏好优化（DPO）从LLM中学习了内容，该内容将逐字感受的内容替换为合理且相干的替代方案。由于DPO可能会阻碍LLM在其他无关任务中的表现，因此我们集成了梯度投影和Fisher信息正则化以减轻降解。我们使用500本著名书籍（主要是受版权保护的作品）的大规模数据集验证了我们的方法，并证明SUV大大减少了逐字记忆的记忆，并且对无关任务的绩效的影响可忽略不计。对我们的数据集和公共基准测试的广泛实验证实了我们方法的可扩展性和功效，为减轻现实世界中LLM应用程序中的版权风险提供了有希望的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2503.22948</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM可以支持医学知识归纳吗？基于评估的观点</title>
      <link>https://arxiv.org/abs/2503.22954</link>
      <description><![CDATA[ARXIV：2503.22954V1公告类型：新 
摘要：医学知识图（KGS）对于临床决策支持和生物医学研究至关重要，但是由于知识差距和医学编码系统的结构限制，它们经常表现出不完整。这个问题在治疗映射中尤为明显，在治疗映射中，ICD，Mondo和ATC等编码系统缺乏全面的覆盖范围，从而导致疾病及其潜在治疗之间缺失或不一致的关联。为了解决这个问题，我们探索了大型语言模型（LLM）的使用来推出缺失的治疗关系。尽管LLM在知识增强方面具有有希望的能力，但它们在医学知识中的应用却带来了重大风险，包括事实上的不准确性，幻觉的关联以及LLMS内部和内部的不稳定。在这项研究中，我们系统地评估了LLM驱动的处理映射，并通过基准比较评估其可靠性。我们的发现突出了临界局限性，包括与已建立的临床准则和患者安全的潜在风险的矛盾。这项研究是研究人员和从业人员的警示指南，强调了当利用LLMS增强医学知识图上的治疗映射时，批判性评估和混合方法的重要性。]]></description>
      <guid>https://arxiv.org/abs/2503.22954</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>XL教学：跨语言开放式生成的合成数据</title>
      <link>https://arxiv.org/abs/2503.22973</link>
      <description><![CDATA[ARXIV：2503.22973V1公告类型：新 
摘要：跨语言开放式一代 - 即以所需的语言与用户查询不同的语言生成响应 - 是一个重要但经过深入研究的问题。我们介绍了XL-Alpacaeval，这是一种用于评估大语言模型（LLMS）跨语言生成能力的新基准，并提出了一种高质量的合成数据生成方法XL-Instruct。仅使用8K XL教学生成的指示进行微调可显着提高模型性能，从而将GPT-4O-Mini的获胜率从7.4％提高到21.5％，并改善了几种细粒度的质量指标。此外，在XL教学上进行了微调的模型表现出强烈的零射击转移到仅英语和多语言生成任务。鉴于其一致的收益，我们强烈建议将XL教学纳入未来多语言LLM的训练后管道中。为了促进进一步的研究，我们将公开，自由发布XL教学和XL-Alpacaeval数据集，这些数据集构成了文献中目前可用的少数几种跨语性资源中的两种。]]></description>
      <guid>https://arxiv.org/abs/2503.22973</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>弗莱姆：在长篇小说问题上快速而缓慢思考的灵活推理机制回答</title>
      <link>https://arxiv.org/abs/2503.22985</link>
      <description><![CDATA[ARXIV：2503.22985V1公告类型：新 
摘要：长篇小说提问（LCQA）系统从大型语言模型（LLMS）的强大推理能力（LLMS）中受益匪浅，可以将其归类为缓慢而快速的推理模式。但是，这两种模式都有其局限性。缓慢的思维通常倾向于探索所有可能的推理路径，这会导致大量思考和浪费时间。快速思考通常依赖于模式匹配，而不是真正理解查询逻辑，这错过了适当的理解。为了解决这些问题，我们提出了FREM：灵活的推理机制，该方法可根据每个问题的复杂性来调整推理深度。具体而言，FREM利用合成参考QA示例提供了明确的思想链，从而有效地处理了简单的查询，同时允许更深入地推理更复杂的查询。通过这样做，弗莱姆（Frem）帮助快速思考的模型超越了表面模式匹配，并缩小了慢速思维模型的推理空间，以避免不必要的探索。七个质量检查数据集的实验表明，FREM提高了推理的准确性和可扩展性，尤其是对于复杂的多主题问题，表明其潜力提高了LCQA方法。]]></description>
      <guid>https://arxiv.org/abs/2503.22985</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>专家的稀疏混合物作为统一的竞争学习</title>
      <link>https://arxiv.org/abs/2503.22996</link>
      <description><![CDATA[ARXIV：2503.22996V1公告类型：新 
摘要：专家（SMOE）的稀疏混合物通过将输入令牌引导到一部分专家来提高大语模型培训的效率。尽管它在发电任务方面取得了成功，但其概括能力仍然是一个悬而未决的问题。在本文中，我们证明了当前的Smoes分为两类：（1）令牌选择；（2）专家选择，与诸如大规模文本嵌入基准（MTEB）之类的任务斗争。通过通过竞争性学习的角度分析其机制，我们的研究发现，令牌选择方法可能会过于关注无关的专家，而专家选择方法则有可能丢弃重要代币，可能影响性能。在这种分析的驱动下，我们提出了统一的竞争学习SMOE（USMOE），这是一个新颖而高效的框架，旨在在两种情况下：有和没有培训。跨各种任务的广泛实验表明，USMOE比传统方法提高了10％的提高，或者在保持强劲绩效的同时，将计算推断成本降低了14％。]]></description>
      <guid>https://arxiv.org/abs/2503.22996</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>S2MOE：专家通过随机学习的稀疏混合物</title>
      <link>https://arxiv.org/abs/2503.23007</link>
      <description><![CDATA[ARXIV：2503.23007V1公告类型：新 
摘要：专家（SMOE）的稀疏混合物通过将输入令牌路由到选定的专家来实现大型语言模型的有效培训。但是，由于代表崩溃的问题，训练SMOE仍然具有挑战性。最近的研究重点是改善路由器以减轻此问题，但是现有方法面临两个关键局限性：（1）专家嵌入明显小于模型的维度，导致表示代表崩溃，并且（2）将每个输入路由到Top-K专家可以导致他们学习过度相似的特征。在这项工作中，我们提出了一种新颖的方法，称为专家通过随机学习（S2MOE）的稀疏混合物，该方法是专家的混合物，旨在通过在不确定性下学习从确定性和非确定性输入中学习。各种任务的广泛实验表明，S2MOE的性能与其他路由方法相当，同时将计算推断成本降低28％。]]></description>
      <guid>https://arxiv.org/abs/2503.23007</guid>
      <pubDate>Tue, 01 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>