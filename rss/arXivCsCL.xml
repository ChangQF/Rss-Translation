<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Mon, 18 Dec 2023 03:15:17 GMT</lastBuildDate>
    <item>
      <title>No-Skim：对基于略读的语言模型进行效率鲁棒性评估。 （arXiv：2312.09494v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.09494</link>
      <description><![CDATA[减少大语言的计算成本和能耗
模型（LLM），基于略读的加速动态删除不重要的标记
输入序列沿着LLM的层逐步进行，同时保留
语义重要性的标记。然而，我们的工作首次揭示了
加速可能容易受到拒绝服务 (DoS) 攻击。在这个
论文中，我们提出了 No-Skim，一个帮助所有者的通用框架
基于略读的法学硕士，以了解和衡量其稳健性
加速方案。具体来说，我们的框架搜索最少并且
在字符级和标记级生成不明显的扰动
充分增加剩余代币比例的对抗性输入，因此
增加计算成本和能源消耗。我们系统地
评估各种LLM中略读加速的脆弱性
GLUE 基准上的架构包括 BERT 和 RoBERTa。在最坏的情况下
在这种情况下，No-Skim 发现的扰动大大增加了运行速度
LLM 的成本平均降低 145% 以上。此外，No-Skim 扩展了评估范围
框架适应各种场景，使评估能够进行
不同的知识水平。
]]></description>
      <guid>http://arxiv.org/abs/2312.09494</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>IndicIRSuite：印度语言的多语言数据集和神经信息模型。 （arXiv：2312.09508v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.09508</link>
      <description><![CDATA[在本文中，我们介绍了 11 个神经信息检索资源
广泛使用的印度语言（阿萨姆语、孟加拉语、古吉拉特语、印地语、卡纳达语、
马拉雅拉姆语、马拉地语、奥里亚语、旁遮普语、泰米尔语和泰卢固语）来自两个主要印度语
语系（印度-雅利安语和德拉威语）。这些资源包括 (a)
INDIC-MARCO，MSMARCO 数据集的多语言版本 11 印度语
使用机器翻译创建的语言，以及 (b) Indic-ColBERT
11 个不同的单语言神经信息检索模型的集合，每个模型
使用 INDIC-MARCO 数据集中 11 种语言之一进行训练。尽最大努力
据我们所知，IndicIRSuite是构建大规模神经网络的首次尝试
大量印度语言的信息检索资源，我们
希望这将有助于加速印度语言神经IR的研究。
实验表明，Indic-ColBERT 在性能方面取得了 47.47% 的提升
所有 11 名印度人在 INDIC-MARCO 基线上的平均 MRR@10 分数
除奥里亚语外的其他语言，NDCG@10 分数平均提高 12.26%
MIRACL 孟加拉语和印地语基线，以及 20% 的改进
MRR@100 分数高于 Mr.Tydi 孟加拉语基线。 IndicIRSuite 是
位于 https://github.com/saifulhaq95/IndicIRSuite
]]></description>
      <guid>http://arxiv.org/abs/2312.09508</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>多阶段 ASR 的部分重写。 （arXiv：2312.09463v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.09463</link>
      <description><![CDATA[对于许多流式自动语音识别任务，重要的是
提供及时的中间流结果，同时提炼高质量
最后结果。这可以使用多级架构来完成，其中一个小的
仅左上下文模型创建流结果和更大的左和
右上下文模型最后产生最终结果。虽然这
在不影响的情况下显着提高最终结果的质量
系统的流式发射延迟，流式结果不会受益
来自品质的提升。在这里，我们建议使用文本操作
合并两个模型的流输出的算法。我们改进了
在不改变最终结果的情况下，流媒体结果的质量提高了约 10%。
我们的方法不会引入额外的延迟并减少闪烁。这是
也轻量级，不需要重新训练模型，就可以应用
到各种多级架构。
]]></description>
      <guid>http://arxiv.org/abs/2312.09463</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>用于高效预训练和改进临床任务的临床文本重复数据删除实践。 （arXiv：2312.09469v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.09469</link>
      <description><![CDATA[尽管它是有关患者状况和疾病的独特信息来源
进展，临床记录的特点是高水平的重复和
信息冗余。在一般领域文本中，已经表明
重复数据删除不会损害语言模型 (LM) 预训练，从而有助于
减少培训成本。尽管大型 LM 已被证明可以学习医学
知识，他们仍然需要专门的领域适应来改进
下游临床任务。通过利用大型现实世界临床语料库，我们
首先提供了源自重复项的细粒度特征
常见的写作习惯和临床相关性。其次，我们证明了
重复数据删除临床文本可以帮助临床 LM 编码更少的冗余
以更有效的方式提供信息，并且不会损害分类任务
基于提示的学习。
]]></description>
      <guid>http://arxiv.org/abs/2312.09469</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>MANTIS 在 #SMM4H 2023：利用混合模型和集成模型检测 Reddit 上的社交焦虑症。 （arXiv：2312.09451v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.09451</link>
      <description><![CDATA[本文介绍了我们用于社交媒体挖掘的系统
Health 2023 共享任务 4：英语 Reddit 帖子的二元分类
自我报告社交焦虑症诊断。我们系统地
研究并对比混合模型和集成模型的功效
利用专门的医疗领域适应变压器结合
BiLSTM 神经网络。评估结果表明我们表现最佳
模型在验证集上获得 89.31% F1，在测试集上获得 83.76% F1。
]]></description>
      <guid>http://arxiv.org/abs/2312.09451</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:15 GMT</pubDate>
    </item>
    <item>
      <title>用于课程开发和理解的文档排序的功能分析。 （arXiv：2312.09457v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.09457</link>
      <description><![CDATA[我们提出了多种自动文档订单生成技术
(1) 课程开发以及 (2) 创建最佳阅读顺序
用于学习、培训和其他内容排序应用程序。这样的
技术可以潜在地用于提高理解力、识别领域
需要阐述、生成课程并改进搜索引擎结果。我们
推进两项主要技术：第一个通过以下方式使用文档相似性：
各种方法。第二个在主题背景下使用熵
通过潜在狄利克雷分配（LDA）生成。此外，我们尝试
对汇总文档使用相同的方法并将其与结果进行比较
使用完整的文档获得。我们的结果表明，虽然
我们的控制文档集（传记、小说和
维基百科文章）无法使用我们的方法、我们的测试进行预测
提供的文档（教科书、课程、期刊论文、论文）更多
可靠性。我们还证明了总结文档是很好的替代品
获取订购所需的完整文件。
]]></description>
      <guid>http://arxiv.org/abs/2312.09457</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:15 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱的开放领域知识提取。 （arXiv：2312.09424v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.09424</link>
      <description><![CDATA[知识图谱的质量直接影响下游的质量
应用程序（例如使用图表可回答的问题数量）。一
构建知识图时持续的挑战是确保完整性和
图表实体和事实的新鲜度。在本文中，我们介绍ODKE，
一个可扩展的框架，可获取高质量的实体和
来自大规模开放网络的事实。 ODKE 利用多种提取模型
并支持不同延迟的流处理和批处理。我们
反思所面临的挑战和所做的设计决策并分享经验教训
构建和部署 ODKE 以发展行业规模的开放域时
知识图。
]]></description>
      <guid>http://arxiv.org/abs/2312.09424</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:14 GMT</pubDate>
    </item>
    <item>
      <title>用于开放词汇脑电图到文本解码的深度表示学习。 （arXiv：2312.09430v1 [eess.SP]）</title>
      <link>http://arxiv.org/abs/2312.09430</link>
      <description><![CDATA[之前的研究已经证明了使用预训练的潜力
用于解码开放词汇的语言模型脑电图 (EEG)
通过非侵入性脑机接口（BCI）捕获的信号。
然而，在语言模型的背景下嵌入脑电图信号的影响
和主观性的影响仍未得到探索，导致不确定性
增强解码性能的最佳方法。此外，当前
用于评估解码效果的评估指标主要是
语法并且不提供对解码的可理解性的见解
人类理解的输出。我们提出了端到端的深度学习
非侵入性脑记录框架，带来现代代表性
神经科学的学习方法。我们的提案介绍了以下内容
创新点：1）开放词汇的端到端深度学习架构
脑电图解码，结合主题相关的表征学习模块
用于原始 EEG 编码、BART 语言模型和 GPT-4 句子细化
模块; 2) 更全面的句子级评估指标
BERT 分数； 3）消融研究，分析每个模块的贡献
在我们的提案中，为未来的研究提供了宝贵的见解。我们
在两个公开可用的数据集 ZuCo v1.0 和 v2.0 上评估我们的方法，
包括 30 名从事自然阅读任务的受试者的脑电图记录。我们的
模型的 BLEU-1 得分为 42.75%，ROUGE-1-F 得分为 33.28%，
BERTcore-F 为 53.86%，优于之前最先进的方法
分别为 3.38%、8.43% 和 6.31%。
]]></description>
      <guid>http://arxiv.org/abs/2312.09430</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:14 GMT</pubDate>
    </item>
    <item>
      <title>具有大量标签的多标签文本分类的经过良好校准的置信度测量。 （arXiv：2312.09304v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09304</link>
      <description><![CDATA[我们将之前的归纳保形预测 (ICP) 工作扩展到
多标签文本分类并提出了一种解决该问题的新方法
Label Powerset (LP) ICP 的计算效率低下，出现在
处理大量独特的标签。我们展示实验结果
使用原始的和提议的高效 LP-ICP 来处理两个英语和一个
捷克语数据集。具体来说，我们将 LP-ICP 应用于三个深度
人工神经网络 (ANN) 分类器有两种类型：一种基于
上下文化（bert）和两个非上下文化（word2vec）词嵌入。
在 LP-ICP 设置中，我们将不合格分数分配给标签集，其中
确定相应的 p 值和预测集。我们的方法
通过消除来处理 LP 增加的计算负担
考虑大量肯定具有 p 值的标签集
低于指定的显着性水平。这大大减少了
该方法的计算复杂性，同时充分尊重标准 CP
保证。我们的实验结果表明，基于情境的
分类器超越了基于非上下文的分类器并获得
所有检查的数据集均具有最先进的性能。良好的表现
底层分类器的 ICP 对应项无需
任何显着的精度损失，但具有 ICP 的额外优势，即
封装在预测集中的置信信息。我们实验性地
证明所得到的预测集可以足够严格
尽管所有可能的标签集包含更多内容，但实际上很有用
比 $1e+16$ 组合。此外，经验错误率
获得的预测集证实我们的输出经过良好校准。
]]></description>
      <guid>http://arxiv.org/abs/2312.09304</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:13 GMT</pubDate>
    </item>
    <item>
      <title>阿拉伯语迷你气候GPT：气候变化和可持续发展定制的阿拉伯语法学硕士。 （arXiv：2312.09366v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.09366</link>
      <description><![CDATA[气候变化是我们共同面临的最重大挑战之一
一个社会。提高认识并对政策制定者进行广泛的教育
气候变化的影响是迈向可持续未来的重要一步。
最近，像 ChatGPT 和 Bard 这样的大型语言模型 (LLM) 已经表明
令人印象深刻的会话能力，并且在各种 NLP 任务中表现出色。
虽然这些模型是闭源的，但最近出现了替代的开源法学硕士，例如
斯坦福羊驼毛和骆驼毛已经显示出有希望的结果。然而，这些
开源模型并非专门针对气候相关领域量身定制
具体信息，也很难产生有意义的回应
其他语言，例如阿拉伯语。为此，我们提出了一个轻量级的阿拉伯语
Mini-ClimateGPT 基于开源 LLM 构建，专门用于
在对话式指令调整策划的阿拉伯语数据集上进行微调
Clima500-提供超过 50 万条有关气候变化和气候变化的说明
可持续性。此外，我们的模型还利用基于向量嵌入
推理期间的检索机制。我们通过验证我们提出的模型
对气候相关查询的定量和定性评估。我们的模型
在基于 ChatGPT 的评估中，88.3% 的案例超过了 LLM 基线。
此外，我们的人类专家评估显示，81.6% 的人更喜欢我们的
模型对多个流行开源模型的响应。我们的开源
此处提供演示、代码库和模型
https://github.com/mbzuai-oryx/ClimateGPT。
]]></description>
      <guid>http://arxiv.org/abs/2312.09366</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:13 GMT</pubDate>
    </item>
    <item>
      <title>弱到强泛化：通过弱监督激发强能力。 （arXiv：2312.09390v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.09390</link>
      <description><![CDATA[广泛使用的对齐技术，例如人类的强化学习
反馈（RLHF），依靠人类监督模型行为的能力——
例如，评估模型是否忠实地遵循指令或
生成安全输出。然而，未来的超人模型将表现在
人类难以可靠评估的复杂方式；人类只会
能够弱监督超人模型。我们研究一个与此类似的类比
问题：弱模型监督能否激发出更多人的全部能力？
更强的模型？我们使用一系列预先训练的语言模型来测试这一点
关于自然语言处理 (NLP)、国际象棋和奖励建模的 GPT-4 系列
任务。我们发现，当我们天真地微调标签上强大的预训练模型时
由弱模型生成，它们始终比弱模型表现得更好
监督者，我们称之为弱到强泛化的现象。然而，我们
距离恢复强大模型的全部能力还很远
单独进行微调，表明像 RLHF 这样的技术可能无法很好地扩展
无需进一步工作的超人模型。我们发现简单的方法往往可以
显着提高弱到强的泛化能力：例如，当
使用 GPT-2 级别的监督器和辅助置信度微调 GPT-4
损失后，我们可以在 NLP 任务上恢复接近 GPT-3.5 级别的性能。我们的
结果表明，今天在以下方面取得实证进展是可行的
调整超人模型的根本挑战。
]]></description>
      <guid>http://arxiv.org/abs/2312.09390</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:13 GMT</pubDate>
    </item>
    <item>
      <title>OTOv3：从结构化修剪到擦除运算符的自动架构无关神经网络训练和压缩。 （arXiv：2312.09411v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09411</link>
      <description><![CDATA[将预定义的深度神经网络 (DNN) 压缩为紧凑的子网络
具有竞争力的性能对于高效的机器学习至关重要
领域。本主题涵盖从结构化剪枝到神经网络的各种技术
架构搜索，包括修剪和擦除运算符
观点。尽管取得了进步，但现有方法仍存在复杂性、
需要大量工程和领域知识的多阶段过程，
限制了它们更广泛的应用。我们推出第三代
Only-Train-Once (OTOv3)，首先自动训练和压缩
通用DNN通过剪枝和擦除操作，创建一个紧凑且
竞争子网络，无需微调。 OTOv3 简化了
自动化训练和压缩过程，最大限度地减少工程设计
需要用户的努力。它提供了关键的技术进步：(i)
基于依赖图的通用 DNN 自动搜索空间构建
分析; (ii) 双半空间投影梯度（DHSPG）及其增强
具有分层搜索（H2SPG）的版本可以可靠地解决（分层）
结构化稀疏问题并确保子网络有效性； (三)
使用 DHSPG/H2SPG 的解决方案进行自动化子网建设
依赖图。我们的实证结果证明了 OTOv3 的功效
跨越结构化剪枝和神经架构搜索的各种基准。
OTOv3 生成的子网络达到或超过了最先进的水平。这
源代码可在 https://github.com/tianyic/only_train_once 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.09411</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:13 GMT</pubDate>
    </item>
    <item>
      <title>基于神经变压器的巴西葡萄牙语语音声学模型。 （arXiv：2312.09265v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2312.09265</link>
      <description><![CDATA[声学模型，经过大量未标记数据的训练，
由自我监督学习的语音表示组成，可用于解决
下游任务，也许在对各自的模型进行微调之后
下游任务。在这项工作中，我们建立了巴西的声学模型
通过 Transformer 神经网络进行葡萄牙语语音。这个模型是
使用超过 800 小时的巴西葡萄牙语语音进行预训练
预训练技术的组合。使用收集的标记数据集
检测巴西葡萄牙语使用者的呼吸功能不全，我们
针对以下任务微调预训练的 Transformer 神经网络：
呼吸功能不全检测、性别识别和年龄组
分类。我们比较了预训练 Transformer 在这些方面的性能
任务与 Transformers 的任务没有事先预训练，注意到
巨大的进步。尤其是呼吸系统的表现
不足检测获得了迄今为止最好的报告结果，表明
这种声学模型作为语音生物标记的有前途的工具
方法。此外，性别识别的表现与
最先进的英语模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.09265</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:12 GMT</pubDate>
    </item>
    <item>
      <title>权重亚克隆：使用较大的预训练变压器直接初始化变压器。 （arXiv：2312.09299v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09299</link>
      <description><![CDATA[为目标任务从头开始训练大型变压器模型需要
数据量大，计算量大。转让的通常做法
学习通过使用权重初始化模型来克服这一挑战
预训练相同尺寸和规格的模型以增加收敛性
和训练速度。但是，如果没有所需大小的预训练模型怎么办
有空吗？在本文中，我们介绍了一种简单而有效的技术
将预训练模型的知识转移到更小的变体。我们的方法
称为权重亚克隆的方法可加快按比例缩小的变压器的训练
从更大的预训练模型初始化它们的权重。

权重亚克隆涉及对预训练模型进行操作以获得
等效初始化的缩小模型。它包括两个关键步骤：首先，
我们引入神经元重要性排序来减少每个神经元的嵌入维度
预训练模型中的层。然后，我们从变压器中删除块
模型以匹配缩小网络中的层数。结果是
网络准备好接受培训，这在以下方面取得了显着改进
与随机初始化相比的训练速度。例如，我们实现了 4x
更快地训练图像分类和语言方面的视觉转换器
为下一个代币预测而设计的模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.09299</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:12 GMT</pubDate>
    </item>
    <item>
      <title>自我评估提高了大型语言模型中的选择性生成。 （arXiv：2312.09300v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.09300</link>
      <description><![CDATA[大型语言模型 (LLM) 的安全部署可能会受益于可靠的
评估其生成内容以确定何时放弃或放弃的方法
选择性地生成。虽然基于可能性的指标（例如困惑度）
广泛应用，最近的研究表明使用的局限性
法学硕士给出的序列水平概率估计作为可靠的指标
一代品质。相反，法学硕士在以下方面表现出了很强的校准能力：
令牌级别，特别是在选择正确答案时
多项选择题或评估真/假陈述。在这项工作中，我们
将开放式生成任务重新表述为代币级别的预测任务，以及
利用法学硕士在代币层面的卓越校准。我们指导法学硕士
自我评估其答案，采用多向比较或
逐点评估方法，可以选择包括“没有一个”
上述”选项明确表达模型的不确定性。我们对标
一系列基于自我评价的评分方法并评估他们的
使用 TruthfulQA 和 TL;DR 进行选择性生成的性能。通过
通过 PaLM-2 和 GPT-3 的实验，我们证明了基于自我评估的方法
分数不仅提高准确性，而且与整体更好地相关
生成内容的质量。
]]></description>
      <guid>http://arxiv.org/abs/2312.09300</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:12 GMT</pubDate>
    </item>
    </channel>
</rss>