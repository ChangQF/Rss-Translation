<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Wed, 08 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>大型语言模型的因果可解释护栏</title>
      <link>https://arxiv.org/abs/2405.04160</link>
      <description><![CDATA[arXiv:2405.04160v1 公告类型：新
摘要：大型语言模型（LLM）在自然语言任务中表现出了令人印象深刻的性能，但它们的输出可能表现出不良的属性或偏差。引导法学硕士走向所需属性的现有方法通常假设无偏见的表示，并且仅依赖于引导提示。然而，从预训练中学到的表示可能会引入影响转向过程的语义偏差，从而导致次优结果。我们提出了 LLMGuardaril，这是一种新颖的框架，它结合了因果分析和对抗性学习，以在法学硕士中获得无偏见的指导表示。 LLMGuardaril 系统地识别并阻止偏差的混杂影响，从而能够提取无偏差的转向表示。此外，它还包括一个可解释的组件，可以深入了解生成的输出和所需方向之间的一致性。实验证明了 LLMGuardaril 能够有效引导法学硕士获得所需的属性，同时减少偏见。我们的工作有助于开发符合所需属性的安全可靠的法学硕士。我们讨论了局限性和未来的研究方向，强调需要进行持续研究来解决大型语言模型的伦理影响。]]></description>
      <guid>https://arxiv.org/abs/2405.04160</guid>
      <pubDate>Wed, 08 May 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>弱监督下优化语言模型的推理能力</title>
      <link>https://arxiv.org/abs/2405.04086</link>
      <description><![CDATA[arXiv:2405.04086v1 公告类型：新
摘要：虽然大型语言模型（LLM）已经证明了处理复杂查询的能力，但过去的大部分工作都依赖于人类专家广泛注释的数据集。然而，这种对完全监督注释的依赖带来了可扩展性挑战，特别是随着模型和数据需求的增长。为了缓解这一问题，我们探索了在最少的人工监督下增强法学硕士推理能力的潜力。在这项工作中，我们引入了自我强化，首先使用一小部分带注释的问题对模型进行监督微调（SFT）。然后，它通过学习 SFT 和未微调模型对未标记问题的响应差异，迭代地改进 LLM。我们的方法提供了一种有效的方法，而无需严重依赖广泛的人工注释解释。然而，当前的推理基准通常只包括黄金参考答案或基本原理。因此，我们提出了 \textsc{PuzzleBen}，这是一个弱监督基准，包含 25,147 个复杂的问题、答案和人类生成的跨不同领域的基本原理，例如脑筋急转弯、谜题、谜语、副谜语和批判性推理任务。我们数据集的一个独特之处是包含 10,000 个未注释的问题，使我们能够探索利用更少的超大数据来提高法学硕士的推理能力。我们的实验强调了 \textsc{PuzzleBen} 的重要性，以及我们的方法作为未来努力的一个有希望的方向的有效性。我们的数据集和代码将很快发布在 \texttt{Anonymity Link} 上。]]></description>
      <guid>https://arxiv.org/abs/2405.04086</guid>
      <pubDate>Wed, 08 May 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>基于大规模预训练模型的中文心理支持热线细粒度语音情感分析</title>
      <link>https://arxiv.org/abs/2405.04128</link>
      <description><![CDATA[arXiv:2405.04128v1 公告类型：新
摘要：自杀和自杀行为仍然是公共政策和医疗保健的重大挑战。为此，世界范围内设立了心理支持热线，为陷入精神危机的个人提供即时帮助。这些热线的有效性很大程度上取决于准确识别呼叫者的情绪状态，特别是表明自杀风险增加的潜在负面情绪。然而，对心理干预的高需求往往导致专业操作人员的短缺，这就凸显了对有效的语音情感识别模型的需求。该模型将自动检测和分析呼叫者的情绪，从而促进与热线服务的集成。此外，它还可以对心理支持热线互动进行大规模数据分析，以探索不同人群的心理现象和行为。我们的研究利用了中国最大的自杀热线——北京心理支持热线的数据。我们分析了 105 个呼叫者的语音数据，包含 20,630 个片段，并将它们分为 11 类负面情绪。我们使用大规模预训练模型开发了负面情绪识别模型和细粒度多标签分类模型。我们的实验表明，负面情绪识别模型的 F1 分数最大为 76.96%。然而，它在细粒度多标签分类任务中的效果有限，最佳模型仅获得 41.74% 的加权 F1 分数。我们对此任务进行了错误分析，讨论了未来潜在的改进，并考虑了我们研究的临床应用可能性。所有代码都是公开的。]]></description>
      <guid>https://arxiv.org/abs/2405.04128</guid>
      <pubDate>Wed, 08 May 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 OpenAI 的 GPT 评估大型语言模型生成的文本摘要</title>
      <link>https://arxiv.org/abs/2405.04053</link>
      <description><![CDATA[arXiv:2405.04053v1 公告类型：新
摘要：本研究检验了 OpenAI 的 GPT 模型作为 Hugging Face 的六个基于 Transformer 的模型生成的文本摘要的独立评估器的有效性：DistilBART、BERT、ProphetNet、T5、BART 和 PEGASUS。我们根据高质量摘要的基本属性（简洁性、相关性、连贯性和可读性）使用 ROUGE 和潜在语义分析 (LSA) 等传统指标来评估这些摘要。独特的是，我们还使用 GPT 不是作为摘要器，而是作为评估器，使其能够在没有预定义指标的情况下独立评估摘要质量。我们的分析揭示了 GPT 评估与传统指标之间的显着相关性，特别是在评估相关性和一致性方面。结果证明了 GPT 作为评估文本摘要的强大工具的潜力，提供了补充既定指标的见解，并为自然语言处理任务中基于 Transformer 的模型的比较分析提供了基础。]]></description>
      <guid>https://arxiv.org/abs/2405.04053</guid>
      <pubDate>Wed, 08 May 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>FlashBack：用于长上下文推理的高效检索增强语言建模</title>
      <link>https://arxiv.org/abs/2405.04065</link>
      <description><![CDATA[arXiv:2405.04065v1 公告类型：新
摘要：检索增强语言建模（RALM）通过将大型语言模型（LLM）与外部语料库的相关文档集成，是一种行之有效的方法，使 LLM 能够生成超出其预训练语料库范围的信息。以前的工作通过简单地将检索到的内容添加到输入中来利用检索到的内容会带来很高的运行时问题，这会降低 LLM 的推理效率，因为它们无法有效地使用键值 (KV) 缓存。在本文中，我们提出了 \textsc{FlashBack}，这是一种模块化 RALM，旨在通过附加上下文模式来提高 RALM 的推理效率，同时在特定微调后保持良好的性能，而不会严重破坏 LLM 的知识完整性。 \textsc{FlashBack} 将检索到的文档附加在上下文的末尾，以便有效地利用 KV 缓存，而不是将它们放在前面。我们的实验表明，\textsc{FlashBack} 的推理速度比 7B LLM (Llama 2) 上的前置方法快高达 $4\times$。通过绕过不必要的重新计算，它通过实现显着更快的推理速度来展示进步，并且这种提高的效率将大大降低推理成本。我们的代码将公开。]]></description>
      <guid>https://arxiv.org/abs/2405.04065</guid>
      <pubDate>Wed, 08 May 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>利用 GPT 增强文本摘要：一种减少幻觉的策略</title>
      <link>https://arxiv.org/abs/2405.04039</link>
      <description><![CDATA[arXiv:2405.04039v1 公告类型：新
摘要：在本研究中，我们使用 DistilBERT 模型生成提取摘要，并使用 T5 模型生成摘要摘要。此外，我们还通过结合 DistilBERT 和 T5 模型来生成混合摘要。我们研究的核心是实施基于 GPT 的精炼流程，以最大限度地减少人工智能生成的摘要中出现的幻觉这一常见问题。我们评估未精炼的摘要，精炼后，我们还使用一系列传统和新颖的指标评估精炼的摘要，表明摘要的准确性和可靠性显着提高。结果强调了在减少幻觉内容方面的显着改进，从而提高了摘要的事实完整性。]]></description>
      <guid>https://arxiv.org/abs/2405.04039</guid>
      <pubDate>Wed, 08 May 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>深度学习时代的认知科学哲学</title>
      <link>https://arxiv.org/abs/2405.04048</link>
      <description><![CDATA[arXiv:2405.04048v1 公告类型：新
摘要：深度学习使人工智能研究的大多数领域取得了重大进展。这一显着的进步超越了单纯的工程成就，并且与认知科学哲学具有重要意义。深度神经网络在克服旧联结主义模型的局限性方面取得了重大进展，这些模型曾经占据了认知哲学辩论的中心舞台。这一发展与认知科学哲学中长期存在的理论争论直接相关。此外，与深度神经网络的比较评估相关的持续方法论挑战将从哲学和认知科学的跨学科合作中受益匪浅。哲学家探索与深度学习和认知相关的基础问题的时机已经成熟；这份前瞻性文件调查了他们的贡献可以特别富有成效的关键领域。]]></description>
      <guid>https://arxiv.org/abs/2405.04048</guid>
      <pubDate>Wed, 08 May 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>ESIHGNN：事件状态交互注入异构图神经网络，用于会话情感识别</title>
      <link>https://arxiv.org/abs/2405.03960</link>
      <description><![CDATA[arXiv:2405.03960v1 公告类型：新
摘要：会话情绪识别（CER）旨在预测对话期间话语（称为“事件”）所表达的情绪。现有的基于图的方法主要关注事件交互以理解会话上下文，而忽略了说话者情绪状态对事件的直接影响。此外，对话的实时建模对于现实世界的应用至关重要，但很少被考虑。为此，我们提出了一种新颖的基于图的方法，即事件状态交互注入异构图神经网络（ESIHGNN），它结合了说话者的情绪状态并构建了异构事件状态交互图来对对话进行建模。具体来说，采用异构有向无环图神经网络来动态更新和增强每个回合的事件和情绪状态的表示，从而提高会话的连贯性和一致性。此外，为了进一步提高 CER 的性能，我们用外部知识丰富了图的边缘。在四个公开可用的 CER 数据集上的实验结果表明了我们方法的优越性以及引入的异构事件状态交互图的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.03960</guid>
      <pubDate>Wed, 08 May 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>多语言、多模态领域独立欺骗检测路线图</title>
      <link>https://arxiv.org/abs/2405.03920</link>
      <description><![CDATA[arXiv:2405.03920v1 公告类型：新
摘要：欺骗是人类交流中普遍存在的一个方面，在数字时代发生了重大转变。随着在线互动的全球化，个人在社交媒体上使用多种语言进行交流并混合使用多种语言，每种语言和方言都有不同的数据。同时，检测欺骗的技术在各方面都是相似的。最近的研究表明，在英语中，跨领域存在通用的欺骗语言线索的可能性；然而，其他语言中是否存在这样的线索仍然未知。此外，由于缺乏标记数据，在资源匮乏的语言中检测欺骗的实际任务并不是一个研究得很好的问题。欺骗的另一个维度是多模态性。例如，在假新闻或虚假信息中，可能存在带有更改标题的图片。本文呼吁全面研究计算机安全和自然语言处理领域中跨语言界限和模态的欺骗性语言的复杂性，以及使用多语言转换模型和各种语言的标记数据来普遍解决欺骗检测任务的可能性。]]></description>
      <guid>https://arxiv.org/abs/2405.03920</guid>
      <pubDate>Wed, 08 May 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>长上下文与短指令和综合位置的对齐</title>
      <link>https://arxiv.org/abs/2405.03939</link>
      <description><![CDATA[arXiv:2405.03939v1 公告类型：新
摘要：有效处理具有极长上下文的指令仍然是大型语言模型（LLM）的一个挑战，通常需要高质量的长数据和大量的计算资源。本文介绍了跳步对齐（SkipAlign），这是一种新技术，旨在增强LLM在对齐阶段的长上下文能力，而无需在原始数据长度训练之外进行额外的工作。 SkipAlign 的开发前提是远程依赖关系对于增强 LLM 的长上下文能力至关重要。与仅仅扩展输入样本的长度不同，SkipAlign从位置索引方面综合了长程依赖关系。这是通过在指令跟踪样本中战略性地插入跳过的位置来实现的，它利用数据的语义结构来有效地扩展上下文。通过对具有各种上下文窗口大小的基础模型进行大量实验，SkipAlign 证明了其在一系列长上下文任务中的有效性。特别值得注意的是，通过仔细选择基础模型和对齐数据集，仅使用 6B 参数的 SkipAlign 就实现了最佳性能，并且可以与 LongBench 上的 GPT-3.5-Turbo-16K 等强大基线相媲美。]]></description>
      <guid>https://arxiv.org/abs/2405.03939</guid>
      <pubDate>Wed, 08 May 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>Guylingo：圭亚那共和国克里奥尔语语料库</title>
      <link>https://arxiv.org/abs/2405.03832</link>
      <description><![CDATA[arXiv:2405.03832v1 公告类型：新
摘要：虽然主要语言通常享有大量关注和资源，但全球的语言多样性涵盖了众多较小的、本土的和区域性的语言，这些语言缺乏相同水平的计算支持。加勒比地区就是这样一个地区。虽然通常被称为“英语国家”，但前英国加勒比地区由无数与英语一起蓬勃发展的克里奥尔语组成。在本文中，我们介绍了 Guylingo：一个全面的语料库，旨在推进克里奥尔语（圭亚那英语词典克里奥尔语）领域的 NLP 研究，克里奥尔语是文化丰富的圭亚那使用最广泛的语言。我们首先概述了收集和数字化这个多样化语料库的框架，包括资源匮乏的语言中的口语表达、习语和区域差异。然后，我们展示了训练和评估克里奥尔语机器翻译的 NLP 模型的挑战。最后，我们讨论了最近的 NLP 进步为加速克里奥尔语正式成为加勒比地区官方语言而提供的独特机会。]]></description>
      <guid>https://arxiv.org/abs/2405.03832</guid>
      <pubDate>Wed, 08 May 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>基于法学硕士的自我改进客户评论响应生成</title>
      <link>https://arxiv.org/abs/2405.03845</link>
      <description><![CDATA[arXiv:2405.03845v1 公告类型：新
摘要：之前的研究表明，主动与用户评论互动会对应用程序用户的看法产生积极影响，并鼓励他们提交修改后的评分。然而，开发人员在管理大量评论时遇到了挑战，特别是对于每日评论大量涌入的流行应用程序。因此，需要旨在简化响应用户评论的过程的自动化解决方案。为了解决这个问题，我们开发了一种新系统，通过在检索增强生成 (RAG) 和高级大型语言模型 (LLM) 的帮助下利用用户贡献的文档来生成自动回复。我们的解决方案名为 SCRABLE，代表了一种自适应客户评论响应自动化，它通过自我优化提示和基于法学硕士的判断机制来增强自身。此外，我们引入了一种自动评分机制，模仿人类评估员的角色来评估客户评论领域中生成的响应的质量。对现实世界数据集进行的大量实验和分析表明，我们的方法可以有效地产生高质量的响应，与基线相比，性能提高了 8.5% 以上。通过手动检查生成的响应进行进一步验证，强调了我们提出的系统的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.03845</guid>
      <pubDate>Wed, 08 May 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>治理：多教师强化蒸馏的梯度定向投票集成</title>
      <link>https://arxiv.org/abs/2405.03764</link>
      <description><![CDATA[arXiv:2405.03764v1 公告类型：新
摘要：预训练语言模型已成为问答系统的组成部分，并取得了显着的性能。对于实际部署，进行知识蒸馏以在计算限制下保持高性能至关重要。在本文中，我们解决了一个关键问题：鉴于无监督蒸馏对学生表现的重要性，在没有真实标签指导的情况下，如何在这一阶段有效地整合来自多个教师的知识？我们提出了一种新颖的算法 GOVERN 来解决这个问题。 GOVERN 在离线和在线实验中都展示了显着的改进。所提出的算法已成功部署在现实世界的商业问答系统中。]]></description>
      <guid>https://arxiv.org/abs/2405.03764</guid>
      <pubDate>Wed, 08 May 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>使用基于 Transformer 的大型语言模型检测反犹太仇恨言论</title>
      <link>https://arxiv.org/abs/2405.03794</link>
      <description><![CDATA[arXiv:2405.03794v1 公告类型：新
摘要：努力识别仇恨言论的学术研究人员和社交媒体实体面临着重大挑战，这主要是由于数据规模庞大和仇恨言论的动态性质。鉴于像 ChatGPT 这样的大型预测模型在直接解决此类敏感问题方面存在伦理和实践局限性，我们的研究自 2019 年以来一直在探索替代的先进的基于变压器的生成人工智能技术。具体来说，我们开发了一种新的数据标记技术并建立了概念验证针对反犹太仇恨言论，利用各种 Transformer 模型，例如 BERT (arXiv:1810.04805)、DistillBERT (arXiv:1910.01108)、RoBERTa (arXiv:1907.11692) 和 LLaMA-2 (arXiv:2307.09288)，并辅以 LoRA微调方法（arXiv：2106.09685）。本文描述并评估了这些尖端方法在解决仇恨言论检测的复杂性方面的比较功效，强调了在敏感环境中负责任且精心管理的人工智能应用程序的必要性。]]></description>
      <guid>https://arxiv.org/abs/2405.03794</guid>
      <pubDate>Wed, 08 May 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>评估大型语言模型以选择材料</title>
      <link>https://arxiv.org/abs/2405.03695</link>
      <description><![CDATA[arXiv:2405.03695v1 公告类型：新
摘要：材料选择是概念设计中的关键步骤，因为它对最终产品的功能、美观、可制造性和可持续性影响重大。本研究调查了在产品设计过程中使用大型语言模型 (LLM) 进行材料选择，并将 LLM 的性能与专家针对各种设计场景的选择进行了比较。通过收集专家材料偏好的数据集，该研究为评估法学硕士通过即时工程和超参数调整与专家建议的一致性程度提供了基础。 LLM 和专家建议之间的差异是通过不同的模型配置、提示策略和温度设置来衡量的。这种方法可以详细分析影响法学硕士推荐材料有效性的因素。这项研究的结果突出了两种失效模式，并确定并行提示是使用法学硕士进行材料选择时有用的提示工程方法。研究结果进一步表明，虽然法学硕士可以提供宝贵的帮助，但他们的建议往往与人类专家的建议存在很大差异。这种差异凸显了需要进一步研究如何更好地定制法学硕士以复制材料选择方面的专家决策。这项工作有助于不断增长关于如何将法学硕士融入设计过程的知识体系，并深入了解其当前的局限性和未来改进的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.03695</guid>
      <pubDate>Wed, 08 May 2024 06:16:44 GMT</pubDate>
    </item>
    </channel>
</rss>