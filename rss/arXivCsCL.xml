<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Thu, 08 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>忠实性与合理性：论大型语言模型解释的（不）可靠性</title>
      <link>https://arxiv.org/abs/2402.04614</link>
      <description><![CDATA[大型语言模型 (LLM) 被部署为多种自然语言处理 (NLP) 应用程序的强大工具。最近的研究表明，现代法学硕士可以生成自我解释（SE），从而引出他们的中间推理步骤来解释他们的行为。自我解释因其对话性和合理性而被广泛采用。然而，人们对他们的忠诚却知之甚少。在这项工作中，我们讨论了法学硕士生成的 SE 中的忠实性和合理性之间的二分法。我们认为，虽然法学硕士善于生成看似合理的解释——对人类用户来说似乎是合乎逻辑且连贯的——但这些解释不一定与法学硕士的推理过程一致，引发了人们对其忠诚度的担忧。我们强调，当前增加解释合理性的趋势主要是由对用户友好界面的需求驱动的，但可能会以降低解释的可信度为代价。我们断言，解释的忠实度对于从事高风险决策的法学硕士来说至关重要。此外，我们敦促社区确定现实世界应用程序的忠实性要求，并确保解释满足这些需求。最后，我们提出了未来工作的一些方向，强调需要新的方法和框架，以增强自我解释的真实性，同时又不损害其合理性，这对于法学硕士在不同高风险领域的透明部署至关重要。]]></description>
      <guid>https://arxiv.org/abs/2402.04614</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:55 GMT</pubDate>
    </item>
    <item>
      <title>TinyLLM：从多个大型语言模型中学习小学生</title>
      <link>https://arxiv.org/abs/2402.04616</link>
      <description><![CDATA[将推理能力从更强的大型语言模型 (LLM) 转移到较小的模型非常有吸引力，因为较小的 LLM 部署起来更灵活，成本也更低。在现有的解决方案中，知识蒸馏因其出色的效率和泛化性而脱颖而出。然而，现有方法存在一些缺点，包括知识多样性有限和缺乏丰富的上下文信息。为了解决这些问题并促进紧凑语言模型的学习，我们提出了 TinyLLM，一种新颖的知识蒸馏范式，用于从多个大型教师 LLM 中学习小型学生 LLM。特别是，我们鼓励法学硕士学生不仅要生成正确的答案，还要理解这些答案背后的基本原理。鉴于不同的法学硕士拥有不同的推理技能，我们引导学生模型吸收不同教师法学硕士的知识。我们进一步引入了上下文示例生成器和教师强制思想链策略，以确保基本原理准确并基于上下文适当的场景。对两个推理任务的六个数据集进行的广泛实验证明了我们方法的优越性。结果表明，尽管模型规模要小得多，但 TinyLLM 的表现仍显着优于大型教师 LLM。]]></description>
      <guid>https://arxiv.org/abs/2402.04616</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:55 GMT</pubDate>
    </item>
    <item>
      <title>Alirector：对齐增强的中文语法错误纠正器</title>
      <link>https://arxiv.org/abs/2402.04601</link>
      <description><![CDATA[当使用序列到序列（Seq2Seq）模型和仅解码器的大型语言模型（LLM）等自回归生成模型时，中文语法错误校正（CGEC）面临严重的过度校正挑战。虽然以前的方法旨在解决 Seq2Seq 模型中的过度校正问题，但它们很难适应仅解码器的 LLM。在本文中，我们针对过度校正问题提出了一种对齐增强校正器，该校正器适用于 Seq2Seq 模型和仅解码器的 LLM。我们的方法首先训练一个校正模型来生成源句子的初始校正。然后，我们将源句子与初始校正结合起来，并通过对齐模型进行另一轮校正，旨在强制对齐模型关注潜在的过度校正。此外，为了增强模型识别细微差别的能力，我们进一步探索源句子和初始校正的反向对齐。最后，我们将两个对齐模型的对齐知识转移到校正模型，指导其如何避免过度校正。三个 CGEC 数据集上的实验结果证明了我们的方法在减轻过度校正和提高整体性能方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.04601</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:54 GMT</pubDate>
    </item>
    <item>
      <title>通过 LLM 后期编辑改进跨域低资源文本生成：程序员-口译员方法</title>
      <link>https://arxiv.org/abs/2402.04609</link>
      <description><![CDATA[事实证明，后期编辑可以有效提高 GPT-3.5 或 GPT-4 等大型语言模型 (LLM) 生成的文本质量，特别是当直接更新其参数以提高文本质量不可行或成本高昂时。然而，仅仅依靠较小的语言模型进行后期编辑可能会限制法学硕士跨领域泛化的能力。此外，这些方法中的编辑策略并不是针对文本生成任务进行最佳设计的。为了解决这些限制，我们提出了一种神经程序员解释器方法，该方法在编辑法学硕士的输出时保留了法学硕士的领域泛化能力。该框架中的编辑操作是专门为文本生成而设计的。大量实验表明，程序员解释器显着增强了 GPT-3.5 在逻辑形式到文本转换和低资源机器翻译方面的性能，在交叉方面超越了其他最先进的 (SOTA) LLM 译后编辑方法。 - 域设置。]]></description>
      <guid>https://arxiv.org/abs/2402.04609</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:54 GMT</pubDate>
    </item>
    <item>
      <title>分享您已了解的内容：代码混合数据中情感检测的跨语言脚本传输和对齐</title>
      <link>https://arxiv.org/abs/2402.04542</link>
      <description><![CDATA[语码转换需要混合多种语言。这是社交媒体文本中越来越多出现的现象。通常，代码混合文本是用单个脚本编写的，即使所涉及的语言具有不同的脚本。预训练的多语言模型主要利用该语言的本机脚本中的数据。在现有的研究中，语码转换文本按原样使用。然而，由于预先训练的知识，使用每种语言的本机脚本可以生成更好的文本表示。因此，本研究提出了一种利用各个语言脚本中文本表示的交叉关注和对齐的跨语言脚本知识共享架构。在包含尼泊尔语-英语和印地语-英语语码转换文本的两个不同数据集上的实验结果证明了该方法的有效性。使用模型可解释性技术对模型的解释说明了特定语言表示之间特定语言知识的共享。]]></description>
      <guid>https://arxiv.org/abs/2402.04542</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:53 GMT</pubDate>
    </item>
    <item>
      <title>UltraLink：开源知识增强多语言监督微调数据集</title>
      <link>https://arxiv.org/abs/2402.04588</link>
      <description><![CDATA[开源大语言模型 (LLM) 在各个领域都获得了显着的优势。然而，大多数研究主要集中在英语上，对多语言监督微调领域的探索有限。因此，在这项工作中，我们构建了一个开源多语言监督微调数据集。与之前简单翻译英语说明的作品不同，我们同时考虑了法学硕士的特定语言和与语言无关的能力。对于特定语言的能力，我们引入了一种基于知识的数据增强方法，以引出法学硕士更多的特定文化知识，提高他们为不同国家的用户服务的能力。对于与语言无关的能力，我们通过实验发现现代法学硕士表现出很强的跨语言迁移能力，因此不需要重复学习各种语言的相同内容。因此，我们可以大幅修剪与语言无关的 SFT 数据，而不会降低任何性能，从而使 SFT 过程更加高效。由此产生的 UltraLink 数据集包含五种语言的大约 100 万个样本，并且所提出的数据构建方法也可以轻松扩展到其他语言。 UltraLink-LM 在 UltraLink 上进行训练，在许多任务中优于几个代表性基线。]]></description>
      <guid>https://arxiv.org/abs/2402.04588</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:53 GMT</pubDate>
    </item>
    <item>
      <title>通过叙述检测语言模型中的模式崩溃</title>
      <link>https://arxiv.org/abs/2402.04477</link>
      <description><![CDATA[没有两个作者写得一样。从词汇到修辞手段，书面叙述中引用的个人华丽辞藻都暗示着某个特定的作者——文学理论家将其称为隐含的或虚拟的作者；与文本的真实作者或叙述者不同。早期的大型语言模型在来自各种不一致来源的未经过滤的训练集上进行训练，产生了不连贯的个性，这对于对话任务来说是有问题的，但事实证明对于从多个角度采样文献是有用的。近年来对齐研究的成功使研究人员能够通过指令调整和人类反馈的强化学习（RLHF）将主观一致的角色强加于语言模型，但对齐模型是否保留对任意虚拟作者进行建模的能力却很少受到关注。通过研究从三种 OpenAI 语言模型中采样的 4,374 个故事，我们发现 GPT-3 的连续版本遭受了越来越严重的“模式崩溃”，从而在对齐过程中过度拟合模型限制了它对作者身份的泛化：遭受模式崩溃的模型变得无法假设多种观点。我们的方法和结果对于寻求在社会学模拟中使用语言模型的研究人员来说具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2402.04477</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:52 GMT</pubDate>
    </item>
    <item>
      <title>自然语言歧义的层理论模型的发展</title>
      <link>https://arxiv.org/abs/2402.04505</link>
      <description><![CDATA[滑轮是由构成拓扑空间的基底和与其每个开集相关联的数据组成的数学对象，例如在开集上定义的连续函数。滑轮最初用于代数拓扑和逻辑。最近，他们还对物理实验和自然语言消歧过程等事件进行了建模。我们将后一种模型从词汇歧义扩展到由照应引起的语篇歧义。首先，我们为基本照应话语数据集计算了一种新的语境性衡量标准，得到了更高比例的语境模型——82.9%——而之前的工作仅产生了 3.17% 的语境模型。然后，我们展示了如何在语境分数为 0.096 的 Bell-CHSH 场景上对自然语言处理挑战的扩展（称为 Winograd 模式）进行建模，该挑战涉及照应歧义。]]></description>
      <guid>https://arxiv.org/abs/2402.04505</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:52 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行结构化实体提取</title>
      <link>https://arxiv.org/abs/2402.04437</link>
      <description><![CDATA[机器学习的最新进展对信息提取领域产生了重大影响，其中大型语言模型 (LLM) 在从非结构化文本中提取结构化信息方面发挥着关键作用。本文探讨了结构化实体提取中当前方法的挑战和局限性，并介绍了一种解决这些问题的新方法。我们首先介绍并形式化结构化实体提取 (SEE) 任务，然后提出近似实体集重叠 (AESOP) 指标，旨在适当评估该任务的模型性能，从而为该领域做出贡献。后来，我们提出了一种新模型，通过将整个提取任务分解为多个阶段，利用法学硕士的力量来提高有效性和效率。定量评估和人类并行评估证实我们的模型优于基线，为结构化实体提取的未来进步提供了有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2402.04437</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:51 GMT</pubDate>
    </item>
    <item>
      <title>评估人工智能医生咨询一次性分类的嵌入</title>
      <link>https://arxiv.org/abs/2402.04442</link>
      <description><![CDATA[医疗保健提供者和患者之间的有效沟通对于提供高质量的患者护理至关重要。在这项工作中，我们研究了如何使用最先进的嵌入和一次性分类系统对医疗保健咨询中医生编写和人工智能生成的文本进行分类。通过分析词袋、字符 n-gram、Word2Vec、GloVe、fastText 和 GPT2 嵌入等嵌入，我们检查了一次性分类系统在医疗咨询中捕获语义信息的效果。结果表明，嵌入能够以可靠且适应性强的方式从文本中捕获语义特征。总体而言，Word2Vec、GloVe 和 Character n-gram 嵌入表现良好，表明它们适合针对此任务进行建模。 GPT2 嵌入也显示出显着的性能，表明它也适用于针对此任务定制的模型。当训练数据稀缺时，我们的机器学习架构显着提高了健康对话的质量，改善了患者和医疗保健提供者之间的沟通。]]></description>
      <guid>https://arxiv.org/abs/2402.04442</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:51 GMT</pubDate>
    </item>
    <item>
      <title>通过个性化参数高效微调使大型语言模型大众化</title>
      <link>https://arxiv.org/abs/2402.04401</link>
      <description><![CDATA[大语言模型 (LLM) 中的个性化变得越来越重要，旨在使 LLM 的交互、内容和推荐与个人用户偏好保持一致。 LLM个性化的最新进展突出了有效的提示设计，通过行为历史检索和文本配置文件用非参数知识丰富用户查询。然而，由于缺乏模型所有权，这些方法受到限制，导致定制受限和隐私问题。此外，它们常常无法准确捕获用户行为模式，特别是在用户数据复杂且动态的情况下。为了解决这些缺点，我们引入了 One PEFT Per User (OPPU)，它采用个性化参数高效微调 (PEFT) 模块来存储用户特定的行为模式和偏好。通过插入用户的个人 PEFT 参数，他们可以个人拥有和使用他们的 LLM。 OPPU 将个人 PEFT 参数中的参数化用户知识与通过检索和配置文件获取的非参数化知识相结合。这种集成使各个法学硕士适应用户行为的变化。实验结果表明，OPPU 在 LaMP 基准测试中的七个不同任务中显着优于现有的基于提示的方法。进一步的深入研究揭示了 OPPU 在处理用户行为变化、对不同活跃级别的用户进行建模、在各种用户历史格式中保持鲁棒性以及通过不同 PEFT 方法显示多功能性方面的增强能力。]]></description>
      <guid>https://arxiv.org/abs/2402.04401</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:50 GMT</pubDate>
    </item>
    <item>
      <title>聊天机器人遇见管道：用定有限自动机增强大型语言模型</title>
      <link>https://arxiv.org/abs/2402.04411</link>
      <description><![CDATA[本文介绍了定有限自动机增强大语言模型 (DFA-LLM)，这是一种新颖的框架，旨在增强使用大语言模型 (LLM) 的会话代理的功能。传统的法学硕士面临着在特殊情况下通过预定的响应指南（例如情感支持和客户服务）生成规范且合规的响应的挑战。我们的框架通过在法学硕士中嵌入从培训对话中学到的定有限自动机（DFA）来解决这些挑战。这种结构化方法使法学硕士能够遵循由 DFA 指导的确定性响应路径。 DFA-LLM 的优点包括通过人类可读的 DFA 实现的可解释结构、对话中响应的上下文感知检索以及与现有 LLM 的即插即用兼容性。广泛的基准验证了 DFA-LLM 的有效性，表明它有可能为对话代理做出有价值的贡献。]]></description>
      <guid>https://arxiv.org/abs/2402.04411</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:50 GMT</pubDate>
    </item>
    <item>
      <title>通过细粒度奖励训练语言模型以生成带有引文的文本</title>
      <link>https://arxiv.org/abs/2402.04315</link>
      <description><![CDATA[虽然最近的大型语言模型（LLM）已被证明在回答用户查询方面很有用，但它们很容易产生幻觉，并且由于缺少对可靠来源的引用，它们的响应往往缺乏可信度。这些问题的直观解决方案是在文本中引用外部文档作为证据。虽然之前的工作直接促使法学硕士生成文本引用，但它们的表现远不能令人满意，尤其是对于规模较小的法学硕士。在这项工作中，我们提出了一个有效的培训框架，使用细粒度的奖励来教导法学硕士生成高度支持性和相关的引文，同时确保他们的回答的正确性。我们还对将这些细粒度奖励应用于常见的 LLM 培训策略进行了系统分析，证明了其相对于传统做法的优势。我们对取自 ALCE 基准的问答 (QA) 数据集进行了广泛的实验，并使用 EXPERTQA 验证了模型的通用性。在 LLaMA-2-7B 上，细粒度奖励的结合实现了基线中最好的性能，甚至超过了 GPT-3.5-turbo。]]></description>
      <guid>https://arxiv.org/abs/2402.04315</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:49 GMT</pubDate>
    </item>
    <item>
      <title>LESS：选择有影响力的数据进行目标指令调优</title>
      <link>https://arxiv.org/abs/2402.04333</link>
      <description><![CDATA[指令调优释放了大型语言模型 (LLM) 的强大功能，有效地使用组合数据集来开发通用聊天机器人。然而，现实世界的应用程序通常需要一套专门的技能（例如推理）。挑战在于从这些广泛的数据集中识别最相关的数据，以有效地开发特定的功能，我们将这种设置称为有针对性的指令调整。我们提出了 LESS，一种优化器感知且实用高效的算法，可有效估计数据影响并执行低秩梯度相似性搜索以进行指令数据选择。至关重要的是，LESS 适应了现有的影响公式，以与 Adam 优化器和可变长度指令数据一起使用。 LESS 首先构建具有低维梯度特征的高度可重用和可转移的梯度数据存储，然后根据示例与体现特定功能的少数样本的相似性来选择示例。实验表明，在不同的下游任务中，对较少选择的 5% 数据进行训练通常可以优于对完整数据集进行训练。此外，所选数据具有高度可转移性：可以利用较小的模型为较大的模型和来自不同系列的模型选择有用的数据。我们的定性分析表明，我们的方法超越了表面形式线索，可以识别能够体现预期下游应用所需推理技能的数据。]]></description>
      <guid>https://arxiv.org/abs/2402.04333</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:49 GMT</pubDate>
    </item>
    <item>
      <title>LegalLens：利用法学硕士进行非结构化文本中的法律违规识别</title>
      <link>https://arxiv.org/abs/2402.04335</link>
      <description><![CDATA[在本研究中，我们重点关注两项主要任务，第一个任务是检测非结构化文本数据中的违法行为，第二个任务是将这些违法行为与潜在受影响的个人相关联。我们使用大型语言模型（LLM）构建了两个数据集，随后由领域专家注释者进行了验证。这两项任务都是专门针对集体诉讼案件而设计的。实验设计结合了 BERT 系列和开源 LLM 的微调模型，并使用闭源 LLM 进行了几次实验。我们的结果，F1 分数为 62.69%（违规识别）和 81.02%（关联受害者），表明我们的数据集和设置可用于这两项任务。最后，我们公开发布实验所用的数据集和代码，以推进法律自然语言处理（NLP）领域的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2402.04335</guid>
      <pubDate>Thu, 08 Feb 2024 09:13:49 GMT</pubDate>
    </item>
    </channel>
</rss>