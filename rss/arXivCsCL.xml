<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Wed, 17 Jan 2024 06:18:50 GMT</lastBuildDate>
    <item>
      <title>ToolkenGPT：通过工具嵌入使用大量工具增强冻结的语言模型。 （arXiv：2305.11554v4 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2305.11554</link>
      <description><![CDATA[使用外部工具增强大型语言模型 (LLM) 已成为一种
解决复杂问题的有前途的方法。然而，传统的方法，
利用工具演示数据对法学硕士进行微调，可能既昂贵又困难
仅限于一组预定义的工具。最近的情境学习范式
缓解了这些问题，但有限的上下文长度只允许少数
演示镜头，导致对工具的理解不佳。
此外，当有大量工具可供选择时，情境学习
可能完全无法工作。在本文中，我们提出了一种替代方案
方法$\textbf{ToolkenGPT}$，它结合了双方的优点。我们的
方法将每个 $\underline{tool}$ 表示为 to$\underline{ken}$
($\textit{toolken}$) 并学习它的嵌入，从而在
与生成常规单词标记的方式相同。一旦工具被触发，
系统会提示 LLM 填写要执行的工具的参数。工具肯GPT
通过扩展可灵活地插入任意数量的工具
一组动态工具。此外，它还通过允许
用于学习工具嵌入的广泛演示数据。在多样化的
领域，包括数字推理、基于知识的问答，以及
体现计划生成，我们的方法有效地增强了法学硕士的工具和
大大优于各种最新基线。 ToolkenGPT 演示了
有希望在复杂的情况下使用大型工具集中的相关工具的能力
场景。
]]></description>
      <guid>http://arxiv.org/abs/2305.11554</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:49 GMT</pubDate>
    </item>
    <item>
      <title>使用曲率和扭转的基于运动的手语视频摘要。 （arXiv：2305.16801v3 [cs.CV] 已更新）</title>
      <link>http://arxiv.org/abs/2305.16801</link>
      <description><![CDATA[许多基于视频的应用程序中一个有趣的问题是生成
通过选择信息最丰富的帧来生成简短的概要，该过程是
称为视频摘要。对于手语视频，使用的好处
二维签名者手腕曲率的 $t$ 参数化对应项
识别关键帧的轨迹，最近在
文学。在本文中，我们通过对 3D 手部运动进行建模来扩展这些想法
这是从视频的每一帧中提取的。为此，我们提出一个新的
基于 $t$ 参数化曲率和扭转的信息函数
3-D 轨迹。将视频帧表征为关键帧的方法
取决于运动是发生在 2-D 还是 3-D 空间中。具体来说，在
在 3-D 运动的情况下，我们寻找曲率调和平均值的最大值
和目标轨迹的扭转；在平面运动的情况下，我们寻求
轨迹曲率的最大值。建议的 3-D 特征是
在手语视频的应用中进行了实验评估 (1)
使用真实关键帧注释的客观测量，(2) 基于人的
理解评估，以及（3）光泽度分类和结果
所获得的都是有希望的。
]]></description>
      <guid>http://arxiv.org/abs/2305.16801</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:49 GMT</pubDate>
    </item>
    <item>
      <title>DinoSR：用于自监督语音表示学习的自蒸馏和在线聚类。 （arXiv：2305.10005v2 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2305.10005</link>
      <description><![CDATA[在本文中，我们介绍了自蒸馏和在线聚类
自监督语音表示学习（DinoSR）结合了掩蔽
语言建模、自蒸馏和在线聚类。我们表明这些
概念相互补充并产生强大的表征学习
演讲模型。 DinoSR 首先从
使用教师网络输入音频，然后在其上运行在线集群系统
嵌入产生机器发现的电话库存，最后使用
指导学生网络的离散化令牌。我们证明 DinoSR
在几个下游任务中超越了之前最先进的性能，
并提供模型和学习到的离散单元的详细分析。
]]></description>
      <guid>http://arxiv.org/abs/2305.10005</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:48 GMT</pubDate>
    </item>
    <item>
      <title>扩散语言模型的生成可以提前停止。 （arXiv：2305.10818v2 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2305.10818</link>
      <description><![CDATA[扩散语言模型 (DLM) 是一种很有前景的文本生成途径
由于它们在易于控制的发电方面的实用特性。他们
还具有不必自回归预测文本的优点。
然而，尽管有这些显着的功能，DLM 尚未达到
自回归同行的绩效水平。其中一种方法是
缩小这两类语言模型之间的性能差距是
加速 DLM 的生成。因此，我们提出了一种开创性的方法论
在这项工作中解决这个问题。它使更多一代人能够执行
在给定的时间范围内采取步骤，可能会带来更高质量的输出。
具体来说，我们的方法估计 DLM 文本生成的完整性和
允许自适应停止生成过程。我们测试并完善我们的
Plaid、SSD 和 CDCD DLM 的方法，并为其创建一个有凝聚力的视角
生成工作流程。最后，我们确认我们的方法允许停止 Plaid，
SSD 和 CDCD 型号，无需安装即可将生成时间减少 $10$-$40$%
模型样本质量下降。
]]></description>
      <guid>http://arxiv.org/abs/2305.10818</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:48 GMT</pubDate>
    </item>
    <item>
      <title>从字符串中学习化学结构的 Transformer 架构的手性识别困难。 （arXiv：2303.11593v4 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2303.11593</link>
      <description><![CDATA[近年来，基于特征的描述符生成技术得到了快速发展
极其多样化的分子的表征学习，尤其是那些
将自然语言处理 (NLP) 模型应用于 SMILES（一种文字）
分子结构的表示。然而，这方面的研究却很少
关于这些模型如何理解化学结构。为了解决这个黑匣子问题，
我们研究了 SMILES 的学习进度与
使用代表性 NLP 模型 Transformer 的化学结构。我们展示
虽然 Transformer 可以快速学习分子的部分结构，但它
需要进一步的培训才能理解整体结构。一致地，
使用生成的描述符进行分子特性预测的准确性
不同学习步骤的模型从开始到结束都是相似的
训练。此外，我们发现 Transformer 需要特别长的时间
学习手性的培训有时会由于以下原因而停滞不前，表现不佳
对映体的误解。这些发现预计将加深
了解化学中的 NLP 模型。
]]></description>
      <guid>http://arxiv.org/abs/2303.11593</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:47 GMT</pubDate>
    </item>
    <item>
      <title>SwissBERT：瑞士的多语言语言模型。 （arXiv：2303.13310v3 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2303.13310</link>
      <description><![CDATA[我们推出了 SwissBERT，这是一种专门为
处理瑞士相关文本。 SwissBERT 是我们预训练的模型
改编为用瑞士国家语言撰写的新闻文章——
德语、法语、意大利语和罗曼什语。我们在自然语言方面评估 SwissBERT
了解与瑞士相关的任务并发现它往往表现出色
这些任务的先前模型，特别是在处理当代新闻时
和/或罗曼什·格里春。由于 SwissBERT 使用语言适配器，因此可能是
在未来的工作中扩展到瑞士德语方言。该模型和我们的开源
代码公开发布于 https://github.com/ZurichNLP/swissbert。
]]></description>
      <guid>http://arxiv.org/abs/2303.13310</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:47 GMT</pubDate>
    </item>
    <item>
      <title>NLP 中的不良偏差：应对测量挑战。 （arXiv：2211.13709v4 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2211.13709</link>
      <description><![CDATA[作为大型语言模型和自然语言处理（NLP）技术
迅速发展并传播到日常生活中，预测变得至关重要
它们的使用会如何伤害人们。一个受到很多关注的问题
近年来人们关注的是这项技术表现出了有害的偏见，
从产生贬义的刻板印象到产生不同的结果
不同的社会群体。虽然投入了很多努力
评估和减轻这些偏差，我们测量偏差的方法
NLP 模型存在严重问题，而且常常不清楚它们实际上是什么
措施。在本文中，我们提供了一种跨学科的方法来讨论
采用心理测量学的视角来解决 NLP 模型偏差问题——一个领域
专门用于测量诸如偏见之类的概念，但这些概念并不直接
可观察到的。特别是，我们将探讨以下两个核心概念：
心理测量学，测量工具的结构有效性和可靠性，
并讨论如何在测量模型偏差的背景下应用它们。我们的
目标是为 NLP 从业者提供设计方法论工具
更好的偏见措施，并激发他们更广泛地探索工具
使用偏差测量工具时的心理测量学。
]]></description>
      <guid>http://arxiv.org/abs/2211.13709</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:46 GMT</pubDate>
    </item>
    <item>
      <title>以数据为中心的机器学习的重新标记方法。 （arXiv：2302.04391v7 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2302.04391</link>
      <description><![CDATA[在行业深度学习应用中，我们手动标记的数据具有
一定数量的噪声数据。解决这个问题，达到90以上
开发数据集中的分数，我们提出了一种简单的方法来查找噪声数据和
将模型预测作为参考，由人类重新标记噪声数据
人类标签。在本文中，我们阐述了我们对一系列广泛的深入研究的想法
学习任务，包括分类、序列标记、对象检测、
序列生成，点击率预测。开发数据集评估
结果和人类评估结果验证了我们的想法。
]]></description>
      <guid>http://arxiv.org/abs/2302.04391</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:46 GMT</pubDate>
    </item>
    <item>
      <title>关于 Covid-19 疫苗接种的波斯推文的大规模分析。 （arXiv：2302.04511v3 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2302.04511</link>
      <description><![CDATA[Covid-19 大流行对我们的生活产生了巨大影响，尤其是
人们的互动。通过引入 Covid-19 疫苗，无论是阳性疫苗还是
对于是否接种疫苗的问题提出了负面意见。在
本文使用从 Twitter 收集的数据，包括推文和用户
概况，我们对伊朗公众舆论进行全面分析
冠状病毒疫苗。为此，我们应用了搜索查询技术
结合主题建模方法来提取与疫苗相关的推文。我们
利用基于变压器的模型对推文内容进行分类
提取围绕疫苗接种的主题。我们还进行了一次情感
分析以评估公众围绕该主题的高兴和愤怒。我们的
结果表明，Covid-19 疫苗接种吸引了相当多的人
来自不同角度的关注，例如政府问题、安全问题或
犹豫和副作用。此外，与冠状病毒相关的现象，例如
公众疫苗接种和感染率深刻影响公众情绪
状态和用户交互。
]]></description>
      <guid>http://arxiv.org/abs/2302.04511</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:46 GMT</pubDate>
    </item>
    <item>
      <title>NLP 中忠实的模型解释：一项调查。 （arXiv：2209.11326v4 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2209.11326</link>
      <description><![CDATA[端到端神经自然语言处理 (NLP) 模型是出了名的
很难理解。这引起了模型方面的大量努力
近年来的可解释性。模型解释的一个迫切需要是
忠实性，即解释应准确表达推理
模型预测背后的过程。在本次调查中，我们回顾了 110 多个型号
NLP 中通过忠实性视角的解释方法。我们首先讨论
忠诚的定义、评价及其意义
可解释性。然后我们介绍忠实解释的最新进展，
将现有方法分为五类：基于相似性的方法，
模型内部结构分析、基于反向传播的方法、
反事实干预和不言自明的模型。对于每个类别，我们
综合其代表性研究、优点和缺点。最后，我们
总结他们的共同优点和仍然面临的挑战，并反思未来
NLP 中忠实可解释性的工作方向。
]]></description>
      <guid>http://arxiv.org/abs/2209.11326</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:45 GMT</pubDate>
    </item>
    <item>
      <title>NormSAGE：从即时对话中发现多语言多文化规范。 （arXiv：2210.08604v2 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2210.08604</link>
      <description><![CDATA[规范发现对于理解和推理非常重要
人类交流中可接受的行为和潜在的违规行为
互动。我们引入 NormSage，一个用于解决新任务的框架
基于对话的多语言、多文化规范发现
语言模型提示和自我验证。 NormSAGE 利用
预训练 GPT-3 语言模型的表达能力和隐含知识
骨干，通过定向问题引出有关规范的知识
代表规范发现任务和对话上下文。它进一步
通过自我验证解决语言模型幻觉的风险
确保发现的规范正确且实质上有效的机制
扎根于他们的对话来源。评估结果表明我们的
方法发现了更加相关和富有洞察力的规范
与基线相比，即时对话（李克特量表评分&gt;10+%）。
从汉语会话中发现的规范也与规范具有可比性
从英语会话中发现洞察力和正确性
(差异＜3％)。此外，针对特定文化的规范也很有希望
质量，使文化对人类识别的准确率达到 80%。
最后，我们在规范发现自我验证中的基础过程可以是
扩展用于实例化对给定的任何规范的遵守和违反
即时对话，具有可解释性和透明度。规范SAGE
基础方面的 AUC 达到 95.4%，并有自然语言解释
匹配人类书写的质量。
]]></description>
      <guid>http://arxiv.org/abs/2210.08604</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:45 GMT</pubDate>
    </item>
    <item>
      <title>使用动态容量槽注意力从字符序列中归纳有意义的单元。 （arXiv：2102.01223v3 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2102.01223</link>
      <description><![CDATA[字符不能传达意义，但字符序列可以。我们建议
一种无监督的分布式方法来学习抽象的有意义的单元
字符序列。我们的动态不是对序列进行分段，而是
容量槽注意力模型发现了容量槽的连续表示
序列中的对象，扩展了对象发现的架构
图片。我们用不同的语言训练我们的模型并评估语言的质量
使用正向和反向探测分类器获得的表示。
这些实验表明我们的模型成功地发现了以下单位：
与之前提出的形式、内容和抽象层次相似，
并有望在更高层次上捕获有意义的信息
的抽象。
]]></description>
      <guid>http://arxiv.org/abs/2102.01223</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:44 GMT</pubDate>
    </item>
    <item>
      <title>弱监督关系提取的表示学习。 （arXiv：2105.00815v2 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2105.00815</link>
      <description><![CDATA[近年来信息提取领域也取得了快速发展
作为其子任务，关系提取。关系提取能够检测
句子中实体之间的语义关系。目前，许多高效
方法已应用于关系提取任务。监督学习
方法尤其具有良好的性能。然而，仍然有很多
困难的挑战。最严重的问题之一是手动标记
数据获取困难。在大多数情况下，用于监督的数据有限
方法等于糟糕的表现。因此，在这里，在只有
训练数据有限，我们专注于如何提高我们的性能
具有无监督预训练的有监督基线系统。特征是其中之一
改进监督方法的关键组成部分。传统的
方法通常应用手工制作的特征，这需要专业知识
和昂贵的人力。然而，这种类型的功能可能会受到数据的影响
稀疏性：当训练集规模较小时，模型参数可能为
估计不好。在这篇论文中，我们提出了一些新颖的无监督
预训练模型来学习分布式文本表示特征，
它们被编码为丰富的句法语义关系模式
表达式。实验证明，这种类型的特征，
结合传统手工制作的特点，可以提高
用于关系提取的逻辑分类模型的性能，
尤其是在仅经过少量训练的关系分类方面
实例。
]]></description>
      <guid>http://arxiv.org/abs/2105.00815</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:44 GMT</pubDate>
    </item>
    <item>
      <title>发现深度 NLP 模型中的显着神经元。 （arXiv：2206.13288v2 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2206.13288</link>
      <description><![CDATA[虽然在理解所学表征方面已经做了很多工作
在深度 NLP 模型及其捕获的知识中，很少有人关注
已支付给单个神经元。我们提出了一种称为
语言相关分析提取模型中的显着神经元，
尊重任何外在财产 - 目的是了解这样的财产如何
知识保存在神经元内。我们进行细粒度的分析
回答以下问题：（i）我们可以识别神经元的子集吗？
捕获特定语言属性的网络？ (ii) 如何本地化或
分布式神经元遍布网络？ iii) 有多冗余
信息保留？ iv) 如何微调预训练模型
下游的 NLP 任务，会影响学到的语言知识吗？ iv) 如何做
架构在学习不同语言特性方面有所不同？我们的
数据驱动的定量分析揭示了有趣的发现：（i）我们
发现可以预测不同语言任务的小神经元子集，ii)
神经元捕获基本词汇信息（例如后缀）
位于最底层，iii) 而那些学习复杂概念的人
（例如句法角色）主要在中层和高层，iii)
显着的语言神经元从较高层迁移到较低层
迁移学习，因为网络为特定任务保留了更高层
信息，iv) 我们发现预训练模型之间存在有趣的差异，
关于如何保存语言信息，以及 v) 我们发现
该概念在不同语言中表现出相似的神经元分布
多语言变压器模型。我们的代码作为公开的一部分
NeuroX 工具包。
]]></description>
      <guid>http://arxiv.org/abs/2206.13288</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:44 GMT</pubDate>
    </item>
    <item>
      <title>学习人类如何纠正。 （arXiv：2102.00225v19 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2102.00225</link>
      <description><![CDATA[在行业NLP应用中，我们人工标注的数据有一定数量
的噪声数据。我们提出了一种简单的方法来查找噪声数据并重新标记
手动进行修正，同时我们收集修正信息。然后我们呈现
将人类校正信息融入深度学习的新方法
模型。人类知道如何纠正噪声数据。所以修正信息可以
注入深度学习模型。我们用自己的文本做实验
分类数据集，这是手动标记的，因为我们需要重新标记
我们的行业应用数据集中的噪声数据。本实验
结果表明我们的校正学习方法改善了分类
测试数据集中的准确率从 91.7% 到 92.5%。 91.7% 的准确率经过训练
修正后的数据集，在测试中将基线从 83.3% 提高到 91.7%
数据集。人工评估准确率达到97%以上。
]]></description>
      <guid>http://arxiv.org/abs/2102.00225</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:43 GMT</pubDate>
    </item>
    </channel>
</rss>