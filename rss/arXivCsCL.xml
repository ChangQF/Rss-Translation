<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 01 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>隐式有害内容的目标跨度检测</title>
      <link>https://arxiv.org/abs/2403.19836</link>
      <description><![CDATA[arXiv:2403.19836v1 公告类型：新
摘要：识别仇恨言论的目标是掌握此类言论的性质并最终改善在线论坛上攻击性帖子检测的关键一步。在线平台上的许多有害内容都使用隐性语言，尤其是在针对弱势群体和受保护群体时，例如使用刻板特征而不是明确的目标名称，从而使检测和缓解语言变得更加困难。在这项研究中，我们专注于识别仇恨言论的隐含目标，这对于识别更微妙的仇恨言论和加强对数字平台上有害内容的检测至关重要。我们定义了一项新任务，旨在识别目标，即使目标没有明确说明。为了解决该任务，我们在三个著名的隐式仇恨言论数据集中收集并注释目标跨度：SBIC、DynaHate 和 IHC。我们将生成的合并集合称为隐式目标跨度。该集合是使用创新的池方法实现的，该方法具有基于人工注释和大型语言模型 (LLM) 的匹配分数。我们的实验表明，Implicit-Target-Span 为目标跨度检测方法提供了一个具有挑战性的测试平台。]]></description>
      <guid>https://arxiv.org/abs/2403.19836</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>本地化语言模型中的段落记忆</title>
      <link>https://arxiv.org/abs/2403.19851</link>
      <description><![CDATA[arXiv:2403.19851v1 公告类型：新
摘要：我们能否本地化语言模型用于记忆和背诵其训练数据的整个段落的权重和机制？在本文中，我们表明，虽然记忆分布在多个层和模型组件中，但记忆段落的梯度具有可区分的空间模式，在较低模型层中比未记忆示例的梯度更大。此外，可以通过仅微调高梯度权重来忘记记忆的示例。我们定位了一个低层注意力头，它似乎特别参与段落记忆。该头主要将注意力集中在语料库级一元分布中最不常见的独特、稀有标记上。接下来，我们通过扰动标记并测量解码中引起的变化来研究前缀中标记的本地化记忆如何。前缀中早期的一些独特标记通常会破坏整个延续。总体而言，记忆的延续不仅更难忘记，而且比未记忆的延续更容易损坏。]]></description>
      <guid>https://arxiv.org/abs/2403.19851</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>自动语音识别的多阶段多模态预训练</title>
      <link>https://arxiv.org/abs/2403.19822</link>
      <description><![CDATA[arXiv:2403.19822v1 公告类型：新
摘要：机器学习的最新进展表明，与随机初始化模型相比，多模态预训练可以提高自动语音识别（ASR）性能，即使模型在单模态任务上进行了微调。现有的 ASR 任务多模态预训练方法主要集中于单阶段预训练，即使用单个无监督任务进行预训练，然后对下游任务进行微调。在这项工作中，我们介绍了一种将多模式和多任务无监督预训练与基于翻译的监督中间训练方法相结合的新颖方法。我们凭经验证明，这种多阶段方法可使 Librispeech 和 SUPERB 的相对字错误率 (WER) 比基线提高高达 38.45%。此外，我们分享了选择预训练方法和数据集的几个重要发现。]]></description>
      <guid>https://arxiv.org/abs/2403.19822</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:58 GMT</pubDate>
    </item>
    <item>
      <title>语言模型从不太罕见的现象中学习罕见的现象：AANN 缺失的案例</title>
      <link>https://arxiv.org/abs/2403.19827</link>
      <description><![CDATA[arXiv:2403.19827v1 公告类型：新
摘要：语言模型学习罕见的句法现象，但有人认为它们依赖于死记硬背，而不是语法概括。在人类规模的语料库（1 亿字）上进行训练，我们在系统操作的语料库上迭代训练 Transformer 语言模型，然后评估它们对一种特殊罕见语法现象的学习：英语冠词+形容词+数字+名词（AANN）结构（“美好的五天”）。我们首先比较了默认语料库和删除了 AANN 句子的反事实语料库中这种结构的学习效果。 AANN 的学习效果仍然比结构的系统扰动变体更好。使用额外的反事实语料库，我们建议这种学习是通过相关结构（例如“几天”）的概括来进行的。另一项实验表明，当输入存在更多变化时，这种学习能力会得到增强。总而言之，我们的结果提供了一个存在证明，即模型可以通过从不太罕见的现象中进行泛化来学习罕见的语法现象。代码可在 https://github.com/kanishkamisra/aannaanalysis 获取]]></description>
      <guid>https://arxiv.org/abs/2403.19827</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:58 GMT</pubDate>
    </item>
    <item>
      <title>EmoScan：自动筛查罗马化僧伽罗语推文中的抑郁症状</title>
      <link>https://arxiv.org/abs/2403.19728</link>
      <description><![CDATA[arXiv:2403.19728v1 公告类型：新
摘要：这项工作探讨了利用罗马化僧伽罗语社交媒体数据来识别有抑郁风险的个人。提出了一种基于机器学习的框架，通过分析社交媒体帖子综合数据集中的语言模式、情绪和行为线索来自动筛查抑郁症症状。该研究的目的是比较神经网络与经典机器学习技术的适用性。所提出的带有注意力层的神经网络能够处理长序列数据，在检测抑郁症状方面达到了 93.25% 的惊人准确率，超越了当前最先进的方法。这些发现强调了这种方法在查明需要主动干预和支持的个人方面的有效性。心理健康专业人士、政策制定者和社交媒体公司可以通过拟议的模型获得宝贵的见解。这项工作利用自然语言处理技术和机器学习算法，为数字时代的心理健康筛查提供了一条有前途的途径。通过利用社交媒体数据的潜力，该框架引入了一种主动方法来识别和帮助有抑郁症风险的个人。总之，这项研究有助于推进心理健康的主动干预和支持系统，从而影响该领域的研究和实际应用。]]></description>
      <guid>https://arxiv.org/abs/2403.19728</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>金奖：通过分布外引导语言数据生成进行广义知识蒸馏</title>
      <link>https://arxiv.org/abs/2403.19754</link>
      <description><![CDATA[arXiv:2403.19754v1 公告类型：新
摘要：法学硕士的知识蒸馏对于语言模型的有效部署至关重要。之前的工作已经提出使用法学硕士来生成数据来准备蒸馏模型。我们认为，使用法学硕士生成数据很容易主要从原始内容分发的中心进行采样。这种限制阻碍了蒸馏模型学习真实的底层数据分布并忘记分布的尾部（概率较低的样本）。为此，我们提出了 GOLD，一种与任务无关的数据生成和知识蒸馏框架，它为法学硕士采用了迭代的非分布引导反馈机制。因此，生成的数据提高了精炼模型的通用性。还引入了基于能量的 OOD 评估方法来处理生成的噪声数据。我们对 NLP 中 10 种不同的分类和序列到序列任务进行的广泛实验表明，GOLD 分别优于现有技术和 LLM，平均提高了 5% 和 14%。我们还将证明所提出的方法适用于较少探索和新颖的任务。代码可用。]]></description>
      <guid>https://arxiv.org/abs/2403.19754</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>开发医疗保健语言模型嵌入空间</title>
      <link>https://arxiv.org/abs/2403.19802</link>
      <description><![CDATA[arXiv:2403.19802v1 公告类型：新
摘要：预训练的大型语言模型 (LLM) 通常难以处理域外数据集，例如以医疗保健为重点的文本。我们探索专门的预培训，以使较小的法学硕士适应不同的医疗数据集。评估了三种方法：传统的屏蔽语言模型、无监督文本表示的深度对比学习 (DeCLUTR) 以及利用来自医疗保健环境的元数据类别的新颖的预训练目标。这些方案在每个数据集的下游文档分类任务上进行评估，并对所得嵌入空间进行额外分析。对比训练的模型在分类任务上优于其他方法，可以利用有限的标记数据提供强大的性能，并且所需的模型参数更新更少。虽然基于元数据的预训练并不能进一步改善数据集的分类，但它产生了有趣的嵌入集群可分离性。所有适应领域的法学硕士都优于其公开的通用基础法学硕士，验证了领域专业化的重要性。这项研究说明了即使在计算预算紧张的情况下也可以向紧凑型法学硕士灌输医疗保健能力的有效方法，这是在当地医疗保健环境中负责任和可持续部署的基本能力。我们为专业医疗保健法学硕士提供预培训指南，激励对对比目标的持续探究，并演示使小型法学硕士与隐私敏感的医疗任务保持一致的适应技术。]]></description>
      <guid>https://arxiv.org/abs/2403.19802</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>法语临床命名实体识别的基准评估</title>
      <link>https://arxiv.org/abs/2403.19726</link>
      <description><![CDATA[arXiv:2403.19726v1 公告类型：新
摘要：背景：基于 Transformer 的语言模型在许多自然语言处理（NLP）任务中表现出了强大的性能。掩码语言模型 (MLM) 吸引了持续的兴趣，因为它们可以通过对特定语料库的训练或微调来适应不同的语言和子领域，同时保持比现代大型语言模型 (LLM) 更轻的性能。最近，针对生物医学领域的多个 MLM 发布了法语版本，实验表明它们的性能优于标准的法语版本。然而，还没有比较同一语料库上所有模型的系统评估。目的：本文提出了对临床命名实体识别任务中的生物医学法语屏蔽语言模型的评估。材料和方法：我们评估生物医学模型 CamemBERT-bio 和 DrBERT，并将它们与标准法语模型 CamemBERT、FlauBERT 和 FrALBERT 以及多语言模型进行比较mBERT 使用三个公开可用的语料库进行法语临床命名实体识别。评估设置依赖于语料库开发人员发布的黄金标准语料库。结果：结果表明 CamemBERT-bio 的性能始终优于 DrBERT，而 FlauBERT 提供有竞争力的性能，FrAlBERT 实现最低的碳足迹。结论：这是对用于法国临床实体识别的生物医学掩码语言模型的第一个基准评估，该评估使用涵盖性能和环境影响的指标来一致地比较嵌套实体识别上的模型性能。]]></description>
      <guid>https://arxiv.org/abs/2403.19726</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>法语口语理解媒体基准的新语义任务</title>
      <link>https://arxiv.org/abs/2403.19727</link>
      <description><![CDATA[arXiv:2403.19727v1 公告类型：新
摘要：意图分类和槽填充是口语理解（SLU）的基本任务。在大多数SLU系统中，这些任务是由独立的模块实现的。大约十五年来，人们提出了共同实现这两者并利用它们相互增强的模型。设想使用联合模型的多语言模块来为欧洲项目 HumanE-AI-Net 创建旅游对话系统。建议结合多个数据集（包括媒体数据集）来训练该联合模型。 MEDIA SLU 数据集是 ELRA 自 2005 年起发布的法国数据集，自 2020 年起主要供法国研究界和免费学术研究使用。不幸的是，它仅在插槽中进行注释，而没有注释。已经构建了带有意图注释的增强版 MEDIA，以将其用途扩展到更多任务和用例。本文介绍了用于获取此增强版本的半自动方法。此外，我们还展示了使用联合模型进行意图分类和槽填充的 SLU 实验在此增强数据集上的第一个结果。]]></description>
      <guid>https://arxiv.org/abs/2403.19727</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>HGT：利用异构图增强型大型语言模型进行少量复杂表理解</title>
      <link>https://arxiv.org/abs/2403.19723</link>
      <description><![CDATA[arXiv:2403.19723v1 公告类型：新
摘要：表理解（TU）已经取得了有希望的进步，但它面临着手动标记表的稀缺和复杂表结构的存在的挑战。为了解决这些挑战，我们提出了 HGT，一种具有异构图（HG）的框架-增强型大语言模型（LLM）来处理少镜头TU任务。它通过软提示和指令转换将表语义与LLM的参数化知识对齐来利用LLM，并通过多任务预训练方案处理复杂的表涉及三个新颖的多粒度自监督 HG 预训练目标。我们凭经验证明了 HGT 的有效性，表明它在几个基准上优于少样本复杂 TU 的 SOTA。]]></description>
      <guid>https://arxiv.org/abs/2403.19723</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>MUGC：机器生成内容与用户生成内容检测</title>
      <link>https://arxiv.org/abs/2403.19725</link>
      <description><![CDATA[arXiv:2403.19725v1 公告类型：新
摘要：随着深度神经网络（DNN）和生成人工智能等先进的现代系统不断增强其生成令人信服且真实的内容的能力，区分用户生成的内容和机器生成的内容的需求变得越来越明显。在这项研究中，我们对八种传统机器学习算法进行了比较评估，以区分三个不同数据集（诗歌、摘要和散文）中机器生成的数据和人类生成的数据。我们的结果表明，传统方法在识别机器生成的数据方面表现出很高的准确性，反映了 RoBERT 等流行的预训练模型的有效性。我们注意到，与人类生成的内容相比，机器生成的文本往往更短，单词多样性也更少。虽然人类常用的特定领域相关关键字（尽管当前的 LLM（大型语言模型）忽略了这些关键字）可能有助于实现如此高的检测精度，但我们表明，像 word2vec 这样的更深层次的单词表示可以捕获微妙的语义差异。此外，可读性、偏见、道德和情感比较揭示了机器生成的内容和人类生成的内容之间明显的对比。数据源（人类和机器生成）的表达风格存在差异，并且存在潜在的潜在偏差。这项研究为各个领域的机器生成内容的进步能力和挑战提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.19725</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>STRUM-LLM：归因和结构化对比总结</title>
      <link>https://arxiv.org/abs/2403.19710</link>
      <description><![CDATA[arXiv:2403.19710v1 公告类型：新
摘要：用户经常在两个选项（A 与 B）之间做出决策时遇到困难，因为它通常需要跨多个网页进行耗时的研究。我们提出 STRUM-LLM，通过生成归因的、结构化的和有用的对比摘要来应对这一挑战，突出显示两个选项之间的关键差异。 STRUM-LLM 识别出有用的对比：两个选项显着不同且最有可能影响用户决策的特定属性。我们的技术与领域无关，并且不需要任何人工标记数据或固定属性列表作为监督。 STRUM-LLM 将所有提取内容与文本证据一起归因于输入源，并且它对其可以处理的输入源的长度没有限制。 STRUM-LLM Distilled 的吞吐量比具有同等性能的型号高出 100 倍，同时尺寸缩小 10 倍。在本文中，我们对我们的方法进行了广泛的评估，并为我们当前部署的系统制定了未来的方向。]]></description>
      <guid>https://arxiv.org/abs/2403.19710</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>NJUST-KMG 在 TRAC-2024 任务 1 和 2：离线危害潜在识别</title>
      <link>https://arxiv.org/abs/2403.19713</link>
      <description><![CDATA[arXiv:2403.19713v1 公告类型：新
摘要：本报告详细描述了我们在 TRAC-2024 离线危害潜在识别中提出的方法，该方法包含两个子任务。该调查利用了由多种印度语言的社交媒体评论组成的丰富数据集，并由专家评委进行了精确注释，以捕捉线下环境伤害的细微差别。分配给参与者的目标是设计能够准确评估给定情况下造成伤害的可能性并识别最有可能的离线伤害目标的算法。我们的方法在两个单独的赛道中排名第二，F1 值分别为 0.73 和 0.96。我们的方法主要涉及选择预训练模型进行微调，结合对比学习技术，最终形成测试集的集成方法。]]></description>
      <guid>https://arxiv.org/abs/2403.19713</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>用于文本到图像生成的能力感知提示重构学习</title>
      <link>https://arxiv.org/abs/2403.19716</link>
      <description><![CDATA[arXiv:2403.19716v1 公告类型：新
摘要：文本到图像生成系统已成为艺术创作领域的革命性工具，为将文本提示转化为视觉艺术提供了前所未有的便利。然而，这些系统的功效与用户提供的提示的质量密切相关，这通常会给不熟悉提示制作的用户带来挑战。本文通过利用交互日志中的用户重新表述数据来开发自动提示重新表述模型来解决这一挑战。我们对这些日志的深入分析表明，用户提示重新制定在很大程度上取决于单个用户的能力，从而导致重新制定对的质量存在显着差异。为了有效地使用这些数据进行训练，我们引入了能力感知提示重构（CAPR）框架。 CAPR 通过两个关键组件创新地将用户能力集成到重构过程中：条件重构模型 (CRM) 和可配置能力特征 (CCF)。 CRM 根据指定的用户能力重新制定提示，如 CCF 所示。反过来，CCF 提供了调整和指导 CRM 行为的灵活性。这使得 CAPR 能够有效地学习跨不同用户能力的不同重构策略，并在推理过程中模拟高能力用户重构。对标准文本到图像生成基准的大量实验展示了 CAPR 相对于现有基准的卓越性能及其在未见过的系统上的卓越鲁棒性。此外，综合分析验证了不同组件的有效性。 CAPR 可以促进与文本到图像系统的用户友好交互，并使更广泛的用户更容易实现先进的艺术创作。]]></description>
      <guid>https://arxiv.org/abs/2403.19716</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>AttentionStore：大型语言模型服务中跨多轮对话的经济有效的注意力重用</title>
      <link>https://arxiv.org/abs/2403.19708</link>
      <description><![CDATA[arXiv:2403.19708v1 公告类型：新
摘要：通过多轮对话与人类交互是大型语言模型（LLM）的基本特征。然而，现有用于执行多轮会话的LLM服务引擎​​由于需要重复计算历史令牌的键值（KV）缓存而效率低下，从而产生高昂的服务成本。为了解决这个问题，本文提出了AttentionStore，一种新的注意力机制，可以在多轮对话中重用KV缓存（即注意力重用），从而显着减少重复计算开销。 AttentionStore维护一个分层的KV缓存系统，利用经济高效的内存/存储介质来保存所有请求的KV缓存。为了减少慢速介质的 KV 缓存访问开销，AttentionStore 采用分层预加载和异步保存方案，将 KV 缓存访问与 GPU 计算重叠。为了确保要访问的 KV 缓存放置在最快的层次结构中，AttentionStore 采用调度程序感知的获取和驱逐方案，根据推理作业调度程序的提示有意识地将 KV 缓存放置在不同的层中。为了避免上下文窗口溢出导致已保存的 KV 缓存失效，AttentionStore 通过解耦位置编码并有效截断 KV 缓存，使已保存的 KV 缓存保持有效。大量实验结果表明，AttentionStore 显着缩短了第一个令牌 (TTFT) 的时间高达 88%，将多轮对话的提示预填充吞吐量提高了 8.2$\times$，并降低了端到端推理成本高达 56%。对于长序列推理，AttentionStore 将 TTFT 降低高达 95%，并将提示预填充吞吐量提高 22$\times$。]]></description>
      <guid>https://arxiv.org/abs/2403.19708</guid>
      <pubDate>Mon, 01 Apr 2024 06:17:53 GMT</pubDate>
    </item>
    </channel>
</rss>