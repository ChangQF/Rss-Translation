<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Mon, 27 Nov 2023 11:48:01 GMT</lastBuildDate>
    <item>
      <title>最大限度地减少大型语言模型中的事实不一致和幻觉。 （arXiv：2311.13878v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13878</link>
      <description><![CDATA[大型语言模型 (LLM) 广泛应用于关键领域，例如
医疗保健、教育和金融领域，因为他们在
各种与语言相关的任务。然而，LLM 很容易产生事实上的
不正确的反应或“幻觉”，这可能会导致失去
用户之间的信誉和信任。为了解决这个问题，我们提出一个
首先生成理由、验证和完善的多阶段框架
错误的，并使用它们作为支持参考来生成答案。
生成的理由增强了答案的透明度和我们的
框架提供了关于模型如何得出这个答案的见解，通过使用
这个基本原理和对上下文的引用。在本文中，我们展示了
其在提高毒品相关反应质量方面的有效性
生命科学行业的查询。我们的框架改进了传统
通过启用 OpenAI GPT-3.5-turbo 来实现检索增强生成 (RAG)
两个数据集的可信度提高 14-25%，准确度提高 16-22%。此外，
基于我们的框架微调样本提高了较小样本的准确性
开放获取法学硕士的比例提高了 33-42%，并在商业模式上与 RAG 竞争。
]]></description>
      <guid>http://arxiv.org/abs/2311.13878</guid>
      <pubDate>Mon, 27 Nov 2023 11:48:00 GMT</pubDate>
    </item>
    <item>
      <title>General Phrase Debiaser：在多标记级别消除屏蔽语言模型的偏差。 （arXiv：2311.13892v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13892</link>
      <description><![CDATA[预训练语言揭示的社会偏见和不受欢迎的刻板印象
模型正在成为其应用的障碍。与众多相比
针对词级的去偏方法，目前相对较少
注意短语层面存在的偏差，限制了性能
学科领域的去偏见。在本文中，我们提出了一种自动
称为 \textbf{General Phrase Debiaser} 的多令牌去偏管道，其中
能够减轻屏蔽语言模型中的短语级偏差。
具体来说，我们的方法由 \textit{短语过滤阶段} 组成，
从维基百科页面生成刻板短语以及 \textit{model
debias stage}，可以在多令牌级别对模型进行 debias 以解决偏差
对短语的挑战。后者搜索触发模型的提示
偏置，然后使用它们进行去偏置。标准的最先进结果
数据集和指标表明我们的方法可以显着减少性别
跨不同模型的职业和多个学科存在偏见
参数大小。
]]></description>
      <guid>http://arxiv.org/abs/2311.13892</guid>
      <pubDate>Mon, 27 Nov 2023 11:48:00 GMT</pubDate>
    </item>
    <item>
      <title>通过混合粒度加权训练进行语法错误纠正。 （arXiv：2311.13848v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13848</link>
      <description><![CDATA[语法错误纠正（GEC）任务旨在自动纠正
自然文本中的语法错误。以前的作品几乎都是注释的
训练数据平等，但数据固有的差异被忽略。在
本文的内在差异表现在两个方面，即
数据注释的准确性和潜在注释的多样性。对此
最后，我们提出MainGEC，它设计了token级别和sentence级别的训练
基于准确性和潜在多样性的固有差异的权重
分别对数据进行标注，然后进行混合粒度加权
培训，提高GEC培训效果。实证评价表明
无论是Seq2Seq还是Seq2Edit方式，MainGEC都实现了一致且
两个基准数据集的显着性能改进，证明
混合粒度加权训练的有效性和优越性。
进一步的消融实验验证了设计权重的有效性
MainGEC 中的两种粒度。
]]></description>
      <guid>http://arxiv.org/abs/2311.13848</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:59 GMT</pubDate>
    </item>
    <item>
      <title>心理健康咨询大型语言模型的挑战。 （arXiv：2311.13857v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13857</link>
      <description><![CDATA[全球心理健康危机迫在眉睫，心理健康问题迅速增加。
疾病、资源有限以及寻求治疗的社会耻辱。作为
人工智能（AI）领域取得了重大进展
近年来的进步，大型语言模型（LLM）能够
理解和生成类人文本可用于支持或
提供心理咨询。然而，LLM 的应用
心理健康领域引起了人们对准确性、有效性和
所提供信息的可靠性。本文主要探讨了
与心理学法学硕士发展相关的挑战
咨询，包括模型幻觉、可解释性、偏见、隐私和
临床疗效。我们探索应对这些挑战的潜在解决方案
实用且适用于当前的人工智能范式。根据我们的经验
在开发和部署心理健康法学硕士方面，人工智能前景广阔
为了改善心理健康保健，如果我们能够仔细导航并克服
LLM 的陷阱。
]]></description>
      <guid>http://arxiv.org/abs/2311.13857</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:59 GMT</pubDate>
    </item>
    <item>
      <title>DaG LLM 1.0 版：韩国 NLP 的开创性指令调整语言建模。 （arXiv：2311.13784v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13784</link>
      <description><![CDATA[本文介绍了 DaG LLM（David and Goliath Large Language Model），一个
专门针对韩语并通过指令调整进行微调的语言模型
涵盖 13 个不同类别的 41 项任务。
]]></description>
      <guid>http://arxiv.org/abs/2311.13784</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:58 GMT</pubDate>
    </item>
    <item>
      <title>AdaTyper：自适应语义列类型检测。 （arXiv：2311.13806v1 [cs.DB]）</title>
      <link>http://arxiv.org/abs/2311.13806</link>
      <description><![CDATA[理解关系表的语义有助于
数据探索和准备系统的自动化。一个关键来源
理解表就是了解其列的语义。随着深度的崛起
学习，学习表表示现在可用，可以应用
用于语义类型检测并在基准测试中取得良好的性能。
然而，我们观察到这种性能与其适用性之间存在差距
在实践中。在本文中，我们提出 AdaTyper 来解决最常见的问题之一
关键的部署挑战：适应。 AdaTyper 使用弱监督来
使混合类型预测器适应新的语义类型和转移的数据
使用最少的人类反馈在推理时进行分布。混合型
AdaTyper 的预测器结合了基于规则的方法和轻型机器学习
语义列类型检测模型。我们评估适应性
AdaTyper 在手动注释的真实数据库表上的性能
通过众包进行语义列类型，发现f1-score有所提高
对于新的和现有的类型。 AdaTyper 的平均精度达到 0.6
仅看到 5 个示例后，就明显优于现有的适应方案
基于人类提供的正则表达式或字典的方法。
]]></description>
      <guid>http://arxiv.org/abs/2311.13806</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:58 GMT</pubDate>
    </item>
    <item>
      <title>乐高：学习在文本到图像扩散模型中解开和反转超越对象外观的概念。 （arXiv：2311.13833v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.13833</link>
      <description><![CDATA[扩散模型彻底改变了生成内容的创建和
文本到图像（T2I）扩散模型尤其增加了创意
通过允许使用自然语言进行场景合成来赋予用户自由。 T2I型号
擅长综合名词、外观和风格等概念。到
启用基于概念的一些示例图像的定制内容创建，
文本反转和 DreamBooth 等方法反转所需的概念并
启用在新场景中合成它。然而，颠倒更一般的概念
超越物体的外观和风格（形容词和动词）
自然语言，仍然是一个挑战。这些的两个关键特征
概念导致了当前反演方法的局限性。 1）
形容词和动词与名词（主语）纠缠在一起，可能会阻碍
基于外观的反演方法，其中主题外观泄漏到
概念嵌入和 2）描述这些概念通常超出单一范围
词嵌入（被冰冻、走钢丝等）
当前方法无法处理。

在这项研究中，我们引入了乐高，一种文本倒置方法，旨在
从一些示例图像中反转主题纠缠的概念。乐高解开
使用简单而有效的主题从相关主题中提取概念
分离步骤并采用上下文丢失来指导反转
单/多嵌入概念。在彻底的用户研究中，乐高生成
与基线相比，超过 70% 的时间概念更受青睐。
此外，建议使用大型语言模型进行视觉问答
乐高生成的概念与文本描述更好地一致
概念。
]]></description>
      <guid>http://arxiv.org/abs/2311.13833</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:58 GMT</pubDate>
    </item>
    <item>
      <title>澳大利亚建筑供应链风险管理中基于变压器的命名实体识别。 （arXiv：2311.13755v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13755</link>
      <description><![CDATA[澳大利亚建筑业的特点是错综复杂
供应链和面对无数风险的脆弱性。因此，有效供给
连锁风险管理（SCRM）势在必行。本文采用不同
变压器模型，并在上下文中训练命名实体识别 (NER)
澳大利亚建筑SCRM。利用 NER，变压器模型可以识别并
对新闻文章中特定的风险相关实体进行分类，提供
详细洞察供应链漏洞。通过分析新闻文章
通过不同的变压器模型，我们可以提取相关实体并
与澳大利亚当地（环境）特定风险分类法相关的见解
建筑景观。这项研究强调了 NLP 驱动的潜力
解决方案，例如变压器模型，彻底改变了建筑业的 SCRM
地理媒体特定背景。
]]></description>
      <guid>http://arxiv.org/abs/2311.13755</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:57 GMT</pubDate>
    </item>
    <item>
      <title>用于端到端关系提取的管道、序列到序列和 GPT 模型的比较：罕见疾病用例的实验。 （arXiv：2311.13729v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13729</link>
      <description><![CDATA[端到端关系抽取（E2ERE）是一个重要且现实的方法
自然语言处理（NLP）在生物医学中的应用。在本文中，
我们的目标是使用复杂的数据集来比较 E2ERE 的三种流行范例
专注于涉及不连续和嵌套实体的罕见疾病。我们用
RareDis 信息提取数据集用于评估三个竞争者
方法（对于 E2ERE）：NER $\rightarrow$ RE 管道，联合序列
序列模型和生成预训练 Transformer (GPT) 模型。我们用
每个模型的可比较的最先进模型和最佳实践
方法并进行错误分析以评估其故障模式。我们的
研究结果表明，管道模型仍然是最好的，而
序列到序列模型也不甘落后； GPT 模型的八倍
许多参数甚至比序列到序列模型还要差，并且输给了
超过 10 个 F1 点的管道模型。部分匹配和不连续
实体导致许多 NER 错误，导致整体 E2E 性能降低。
我们还在第二个 E2ERE 化学蛋白质数据集上验证了这些发现
互动。虽然基于生成 LM 的方法更适合
零样本设置，当训练数据可用时，我们的结果表明
最好使用为 E2ERE 训练和定制的更传统模型。
需要更多创新方法将两全其美结合起来
较小的编码器-解码器管道模型和较大的 GPT 模型需要改进
E2ERE。到目前为止，我们看到精心设计的管道模型提供了大量的
E2ERE 以更低的成本和碳足迹提高性能。我们的
贡献也是第一个对RareDis数据集进行E2ERE。
]]></description>
      <guid>http://arxiv.org/abs/2311.13729</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:56 GMT</pubDate>
    </item>
    <item>
      <title>采用两阶段方法超越 GPT-4 医学编码。 （arXiv：2311.13735v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13735</link>
      <description><![CDATA[大语言模型 (LLM) 的最新进展显示出临床应用的潜力
应用程序，例如临床决策支持和试验建议。
然而，GPT-4 LLM 预测医疗领域的 ICD 代码数量过多
编码任务，导致高召回率但低准确率。为了解决这个问题
为了迎接挑战，我们引入了 LLM-codex，一种预测 ICD 代码的两阶段方法
首先使用法学硕士生成证据建议，然后采用
基于LSTM的验证阶段。 LSTM 学习了 LLM 的高召回率
和人类专家的高精度，使用自定义损失函数。我们的模型是
唯一能够同时实现最先进结果的方法
医学编码准确性、稀有代码准确性以及句子级证据
识别支持编码决策，无需接受人工注释培训
根据 MIMIC 数据集实验得出的证据。
]]></description>
      <guid>http://arxiv.org/abs/2311.13735</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:56 GMT</pubDate>
    </item>
    <item>
      <title>高效变压器知识蒸馏：性能审查。 （arXiv：2311.13657v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13657</link>
      <description><![CDATA[随着预训练 Transformer 语言模型不断实现
最先进的性能，自然语言处理社区已经
推动模型压缩和高效注意力机制的进步
解决高计算要求和有限的输入序列长度。
尽管做出了这些单独的努力，但尚未对此事进行调查
这两个字段的交集。在这项工作中，我们提供了一个评估
通过有效注意力的知识蒸馏进行模型压缩
变压器。我们为压缩提供性价比权衡
最先进的高效注意力架构以及在
与全神贯注的同行相比的表现。此外，我们
引入新的长上下文命名实体识别数据集 GONERD 来训练
并测试 NER 模型在长序列上的性能。我们发现
蒸馏有效的注意力变压器可以保留大量
原始模型性能，在短上下文任务中保留高达 98.6%
（GLUE、SQUAD、CoNLL-2003），长上下文中高达 94.6%
问答任务（HotpotQA、TriviaQA），高达 98.8%
长上下文命名实体识别（GONERD），同时减少推理
倍，高达 57.8%。我们发现，对于大多数任务的大多数模型来说，执行
知识蒸馏是产生高性能的有效方法
低成本的高效注意力模型。
]]></description>
      <guid>http://arxiv.org/abs/2311.13657</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:55 GMT</pubDate>
    </item>
    <item>
      <title>MAIRA-1：用于生成放射学报告的专用大型多模态模型。 （arXiv：2311.13668v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13668</link>
      <description><![CDATA[我们提出了一种放射学特定的多模态模型，用于生成
胸部 X 光检查 (CXR) 的放射学报告。我们的工作建立在这样的理念之上
大型语言模型可以通过以下方式配备多模式功能
与预先训练的视觉编码器对齐。在自然图像上，这已经
显示允许多模态模型获得图像理解和描述
能力。我们提出的模型 (MAIRA-1) 利用 CXR 特定图像
编码器与基于微调的大语言模型相结合
Vicuna-7B 和基于文本的数据增强，用于生成报告
最先进的品质。特别是，MAIRA-1 显着改善了
与放射科医生对齐的 RadCliQ 指标以及所有考虑的词汇指标。
模型输出的手动审查表明了有希望的流畅性和准确性
生成报告，同时发现现有的故障模式未捕获的故障模式
评价实践。更多信息和资源可以在
项目网站：https://aka.ms/maira。
]]></description>
      <guid>http://arxiv.org/abs/2311.13668</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:55 GMT</pubDate>
    </item>
    <item>
      <title>基于知识图谱的变电站隐患动态分析方法。 （arXiv：2311.13708v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13708</link>
      <description><![CDATA[解决识别和理解潜在危险的挑战
从非结构化文本数据中提取变电站，一种新颖的动态分析方法是
建议的。该方法首先从分析和提取数据开始
与隐患相关的非结构化文本。然后它利用灵活的、
基于 Elastic-Search 构建的分布式数据搜索引擎来处理这个问题
信息。接下来，使用隐马尔可夫模型来训练
引擎内的数据。集成维特比算法来破译
隐藏状态序列，便于实体的分割和标记
与隐患有关。最后一步涉及使用 Neo4j 图
数据库动态创建知识图谱，隐患可视化
在变电站。该方法的有效性通过
利用具体变电站隐患数据进行实例分析。
]]></description>
      <guid>http://arxiv.org/abs/2311.13708</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:55 GMT</pubDate>
    </item>
    <item>
      <title>及时的风险控制：负责任地部署大型语言模型的严格框架。 （arXiv：2311.13628v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.13628</link>
      <description><![CDATA[最近大型语言模型能力的爆炸性增长导致
对如何最好地促使模型执行给定任务的兴趣浪潮。尽管
简单地根据平均表现来选择提示可能很诱人
验证集，这可能会导致部署响应异常差
产生的，特别是对于境况最差的用户。为了缓解这种前景，
我们提出了 Prompt Risk Control，一个用于选择提示的轻量级框架
基于信息风险度量系列的严格上限。我们
提供在一组不同的指标上产生界限的方法，包括
衡量最坏情况反应和发电差异的数量
整个用户群体的质量。此外，我们还扩展了底层
统计边界技术以适应分布的可能性
部署上的转变。开放式聊天等应用程序的实验，
医学问题总结和代码生成突出了这样的
框架可以通过降低最坏情况的风险来促进负责任的部署
结果。
]]></description>
      <guid>http://arxiv.org/abs/2311.13628</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:54 GMT</pubDate>
    </item>
    <item>
      <title>语言模型反转。 （arXiv：2311.13647v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13647</link>
      <description><![CDATA[语言模型生成下一个标记的分布；我们可以用这个吗
恢复提示令牌的信息？我们考虑语言问题
模型反演并表明下一个令牌概率包含令人惊讶的
有关前面文本的信息量。通常我们可以恢复文本
如果它对用户隐藏，则激发恢复方法
未知提示仅给出模型的当前分布输出。我们认为
各种模型访问场景，并展示即使没有预测
词汇表中的每个标记我们都可以通过以下方式恢复概率向量
搜索。在 Llama-2 7b 上，我们的反演方法用 BLEU 重建提示
$59$ 和 $78$ 的代币级 F1，并准确恢复 $27\%$ 的提示。代码
如需重现所有实验，请访问
此 http 网址
]]></description>
      <guid>http://arxiv.org/abs/2311.13647</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:54 GMT</pubDate>
    </item>
    </channel>
</rss>