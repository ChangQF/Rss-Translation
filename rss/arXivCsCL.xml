<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Tue, 02 Jan 2024 06:17:53 GMT</lastBuildDate>
    <item>
      <title>大规模大型语言模型的红队：解决数学任务中的幻觉。 （arXiv：2401.00290v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00290</link>
      <description><![CDATA[我们考虑了法学硕士在基本计算方面的红队问题，以及
代数任务来评估各种提示技术如何影响质量
输出。我们提出了一个按程序生成数字问题的框架
和谜题，并比较应用和不应用的结果
几种红队技术。我们的研究结果表明，尽管
结构化推理和提供经过验证的示例会减慢
答案质量恶化，gpt-3.5-turbo 和 gpt-4 模型
不太适合基本计算和推理任务，也适用于
被红队。
]]></description>
      <guid>http://arxiv.org/abs/2401.00290</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>华尔兹“国际政治的新​​兴结构”中的论证。(arXiv:2401.00366v1 [cs.CL])</title>
      <link>http://arxiv.org/abs/2401.00366</link>
      <description><![CDATA[我们提出了一种针对论证和特定领域方面的注释方案
关于国际关系理论的学术文章。在
论证级别我们确定主张和支持/攻击关系。在域
我们根据理论和数据相关的层面对话语内容进行建模
声明。我们对 Waltz 1993 年关于结构现实主义的文本进行了注释，并表明
我们的方案可以由领域专家可靠地应用，从而能够深入了解两个方面
关于索赔理由的研究问题。
]]></description>
      <guid>http://arxiv.org/abs/2401.00366</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>评估就是您所需要的。促进生成大型语言模型用于社会科学中的注释任务。使用开放模型的入门知识。 （arXiv：2401.00284v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00284</link>
      <description><![CDATA[本文探讨了开放式生成大型语言模型 (LLM) 的使用
用于社会科学中的注释任务。该研究强调
与专有模型相关的挑战，例如有限的再现性
和隐私问题，以及采用开放（源代码）模型的倡导者
可以在独立设备上运行。注释任务的两个示例，
推文中的情感分析和休闲活动识别
提供童年抱负的文章。研究评估绩效
不同的提示策略和模型（neural-chat-7b-v3-2，
Starling-LM-7B-alpha、openchat_3.5、zephyr-7b-alpha 和 zephyr-7b-beta）。这
结果表明需要仔细验证和定制提示
工程。该研究强调了开放数据模型的优势
隐私性和可重复性。
]]></description>
      <guid>http://arxiv.org/abs/2401.00284</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>防御的艺术：法学硕士安全性和过度防御性防御策略的系统评估和分析。 （arXiv：2401.00287v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00287</link>
      <description><![CDATA[随着大型语言模型 (LLM) 在自然领域发挥着越来越重要的作用
语言处理应用程序的安全问题成为关键领域
NLP 研究的一部分。本文提出了安全性和过度防御性评估
(SODE) 基准：各种安全和不安全提示的集合
精心设计的评估方法有利于系统评估，
对“安全”与“过度防御”进行比较和分析。借助 SODE，我们
研究多个最先进的法学硕士的各种法学硕士防御策略，
它揭示了一些有趣且重要的发现，例如（a）
广泛流行的“自检”技术确实提高了安全性
不安全的输入，但这是以极端过度防御为代价的
安全输入，(b) 提供安全说明以及上下文示例
（安全和不安全的输入）持续提高安全性，并且
减轻模型的过度防御性，(c) 提供上下文
知识轻松打破安全护栏，让模型更
容易产生不安全的反应。总的来说，我们的工作揭示了许多
我们相信这些重要的发现将为进一步铺平道路并促进
提高法学硕士安全性的研究。
]]></description>
      <guid>http://arxiv.org/abs/2401.00287</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>用于语音合成的大型语言模型：实证研究。 （arXiv：2401.00246v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00246</link>
      <description><![CDATA[大型语言模型 (LLM) 在自然领域取得了重大进展
语言处理并同时将语言能力扩展到
其他形式，例如言语和视觉。尽管如此，之前的大部分
工作重点是培养法学硕士的听觉等感知能力
理解力，以及通过演讲增强法学硕士的有效方法
合成能力仍然不明确。在本文中，我们进行了
全面的实证探索，以提高法学硕士的能力
通过结合预训练的 LLM LLaMA/OPT 和文本转语音来生成语音
合成模型VALL-E。我们比较了法学硕士和法学硕士之间的三种整合方法
语音合成模型，包括直接微调的 LLM、叠加层
法学硕士和 VALL-E，以及将法学硕士和 VALL-E 结合起来，使用法学硕士作为强大的文本
编码器。实验结果表明，利用LoRA方法对LLMs进行微调
直接提升语音合成能力效果并不好，并且
叠加的 LLM 和 VALL-E 可以提高生成语音的质量
说话者相似度和单词错误率 (WER)。在这三种方法中，
利用 LLM 作为文本编码器的耦合方法可以实现最佳效果
性能，使其优于原始语音合成模型
说话者相似度持续提高，WER 显着降低 (10.9%)。
]]></description>
      <guid>http://arxiv.org/abs/2401.00246</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>研究具有自我监督和弱监督的最新基础模型的普通话-英语代码转换 ASR 和语音到文本翻译的零样本泛化性。 （arXiv：2401.00273v1 [eess.AS]）</title>
      <link>http://arxiv.org/abs/2401.00273</link>
      <description><![CDATA[这项工作评估了几种基于前沿大型基础模型
关于自我监督或弱监督，包括SeamlessM4T、SeamlessM4T v2、
和 Whisper-large-v3，基于三个代码交换语料库。我们发现
自监督模型可以达到接近监督模型的性能，
表明多语言自监督预训练的有效性。我们
还观察到这些模型仍然有改进的空间，因为它们保持了
犯过类似的错误，建模表现也不尽如人意
句内语码转换。此外，几个变体的有效性
对 Whisper 进行了探索，我们得出的结论是，它们在以下方面仍然有效
语码转换场景以及自监督模型的类似技术是
值得研究以提高代码转换任务的性能。
]]></description>
      <guid>http://arxiv.org/abs/2401.00273</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>技术和科学翻译中的原则干扰。 （arXiv：2401.00177v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00177</link>
      <description><![CDATA[在这篇文章中，我将探讨翻译中干扰的本质，
特别是在技术和科学文本中，使用描述主义方法。我
将简要回顾干涉的历史之旅
技术和科学翻译。我的目的是解释这个现象并
其原因及其所有悖论，而不是简单地谴责它是一个
据说翻译不好的例子。因此，我将重点关注它在
翻译参考书目，论翻译的动机和后果
对专业翻译的干扰以及对专业翻译性质的干扰
支持和反对这一现象的论据。因此关系
不同社会之间始终可以通过以下行为实现：
翻译。当审视整个历史中的文明时，就会发现
知识在不同社会之间的传播已经实现
通过翻译。这些社会往往已经意识到在
通过翻译来传播技术和科学。所以;翻译成
对于社会和人类之间的技术接触非常重要。自从
技术文本的翻译是本论文的初步研究范围，它将
简要回顾一下技术翻译的历史是有益的
世界。
]]></description>
      <guid>http://arxiv.org/abs/2401.00177</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>对齐问题。 （arXiv：2401.00210v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00210</link>
      <description><![CDATA[大型语言模型产生作为统计模式学习的序列
大型语料库。为了不重现语料库偏差，在初始训练后
模型必须与人类价值观保持一致，优先考虑某些延续
超过其他人。对齐，可以看作是规范的叠加
结构到统计模型上，揭示了一个矛盾且复杂的问题
语言与技术之间的相互关系。这种关系塑造了
语言理论、语言实践和主体性
特别是与当前人工生产的复杂性相关
文本。我们将这种结构化实践视为双向交互
通过分析 ChatGPT4 如何编辑感知的用户和模型之间的关系
乔伊斯《尤利西斯》片段中的“异常”语言和新语言
即时工程实践。然后我们将这个对齐问题定位
从历史上看，重新审视战后早期的语言辩论，这些辩论反对
意义的两种观点：离散结构和连续概率
分布。我们讨论莫斯科语言研究所大部分闭塞的工作
学校试图调和这种对立。我们对莫斯科的关注
学校以及塞尔和克里斯蒂娃后来的相关论点提出了以下问题：
以新的视角进行调整：作为一种涉及社会关注的调整
语言实践的结构化，包括异常的结构化
就像乔伊斯的文本一样，它的存在是对表达惯例的蔑视。这些
围绕语言的交际取向的争论可以帮助解释
发生的一些当代行为和相互依存关系
用户和法学硕士之间。
]]></description>
      <guid>http://arxiv.org/abs/2401.00210</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>如何评估文学文本中的共指？ （arXiv：2401.00238v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00238</link>
      <description><![CDATA[在这篇简短的论文中，我们研究了用于评估文本的主要指标
共指，我们详细介绍了它们的一些局限性。我们展示了一种独特的
分数不能代表所涉问题的全部复杂性，因此
缺乏信息，甚至具有误导性。我们提出了一种新的评估方法
共指，考虑到上下文（在我们的例子中，分析
小说，特别是。小说）。更具体地说，我们建议区分长
共指链（对应于主要角色），来自短链
（对应于次要字符）和单例（孤立的元素）。
通过这种方式，我们希望获得更具可解释性、信息更丰富的结果
通过评价。
]]></description>
      <guid>http://arxiv.org/abs/2401.00238</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>通过对比置信度正则化减轻密集检索中误报的影响。 （arXiv：2401.00165v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00165</link>
      <description><![CDATA[在开放域问答 (QA) 中，密集检索对于
找到生成答案的相关段落。通常，对比
学习用于训练检索模型，将段落和查询映射到
相同的语义空间。目的是让相似的人更亲近
不相似者相距更远。然而，训练这样的系统具有挑战性
由于漏报问题，相关段落可能会被遗漏
数据注释。硬负采样，通常用于改进
对比学习，可以在训练中引入更多噪音。这是因为
硬否定是那些更接近给定查询的，因此更有可能
假阴性。为了解决这个问题，我们提出了一种新颖的对比
用于噪声对比估计 (NCE) 损失的置信度正则化器，这是一种常见的
使用损失进行密集检索。我们的分析表明正则化器有助于
密集检索模型对于假阴性具有更强的鲁棒性
理论保证。此外，我们提出了一种与模型无关的方法
过滤掉数据集中嘈杂的负面段落，改善任何下游
密集检索模型。通过对三个数据集的实验，我们证明了
与现有方法相比，我们的方法实现了更好的检索性能
最先进的密集检索系统。
]]></description>
      <guid>http://arxiv.org/abs/2401.00165</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>L3Cube-MahaSocialNER：基于社交媒体的马拉地语 NER 数据集和 BERT 模型。 （arXiv：2401.00170v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00170</link>
      <description><![CDATA[这项工作介绍了 L3Cube-MahaSocialNER 数据集，这是第一个也是最大的数据集
专为命名实体识别 (NER) 设计的社交媒体数据集
用马拉地语。该数据集包含 18,000 个手动标记的
句子涵盖八个实体类别，解决社会带来的挑战
媒体数据，包括非标准语言和非正式习语。深度学习
模型（包括 CNN、LSTM、BiLSTM 和 Transformer 模型）的评估基于
具有 IOB 和非 IOB 符号的单个数据集。结果表明
这些模型在准确识别命名实体方面的有效性
马拉地语非正式文本。 L3Cube-MahaSocialNER 数据集提供以用户为中心的
信息提取并支持实时应用，提供
社交媒体舆情分析、新闻和营销的宝贵资源
媒体平台。我们还展示了常规 NER 的零样本结果
模型在社交 NER 测试集上表现不佳，因此强调需要更多
社会 NER 数据集。数据集和模型可公开获取
https://github.com/l3cube-pune/MarathiNLP
]]></description>
      <guid>http://arxiv.org/abs/2401.00170</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>知识是因果推理所需的所有大型语言模型吗？ （arXiv：2401.00139v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.00139</link>
      <description><![CDATA[本文探讨了大型语言模型 (LLM) 的因果推理
增强其在推进人工智能方面的可解释性和可靠性
智力。尽管法学硕士精通一系列任务，但他们的
理解因果关系的潜力需要进一步探索。我们建议
一种新颖的因果归因模型，利用“do-operator”构建
反事实场景，使我们能够系统地量化影响
输入数值数据和法学硕士关于其因果关系的现有知识
推理过程。我们新开发的实验装置评估法学硕士的
依赖不同领域的背景信息和固有知识
域。我们的评估表明法学硕士的因果推理能力取决于
提供的上下文和特定领域的知识，并支持论点
“知识确实是法学硕士获得合理因果关系的主要要求
相反，在缺乏知识的情况下，LLM 仍然保持着一种
使用可用数字数据进行因果推理的程度，尽管
计算的局限性。
]]></description>
      <guid>http://arxiv.org/abs/2401.00139</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>ReasoningLM：在预先训练的语言模型中启用结构子图推理，以进行知识图问答。 （arXiv：2401.00158v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00158</link>
      <description><![CDATA[知识图谱问答（KGQA）旨在寻找答案实体
针对来自大规模知识图谱~（KG）的自然语言问题。到
更好地在 KG 上进行推理，最近的工作通常采用预训练的
语言模型~（PLM）对问题进行建模，以及图神经网络~（GNN）
基于模块对KG进行多跳推理。尽管
有效性，由于模型架构的差异，PLM 和 GNN
集成不紧密，限制了知识共享和细粒度功能
互动。为了解决这个问题，我们的目标是简化上述两个模块的方法，
并开发一个功能更强大的 PLM，可以直接支持子图推理
KGQA，即 ReasoningLM。在我们的方法中，我们提出了一个子图感知
自注意力机制模仿 GNN 执行结构化
推理，并采用自适应调优策略来适应模型
包含 20,000 个带有综合问题的子图的参数。适应后，
PLM 可以对下游任务进行参数高效的微调。实验
表明 ReasoningLM 大幅超越了最先进的模型，甚至
更新参数和训练数据较少。我们的代码和数据是
公开发布于~\url{https://github.com/RUCAIBox/ReasoningLM}。
]]></description>
      <guid>http://arxiv.org/abs/2401.00158</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>ChatEd：利用 ChatGPT 增强高等教育学习体验的聊天机器人。 （arXiv：2401.00052v1 [cs.CY]）</title>
      <link>http://arxiv.org/abs/2401.00052</link>
      <description><![CDATA[随着自然语言处理（NLP）的快速发展，大语言
ChatGPT 等模型 (LLM) 已成为强大的工具，能够
改变各个部门。他们庞大的知识库和动态的互动
能力代表着改善教育的巨大潜力
作为个性化助理进行操作。然而，产生的可能性
不正确、有偏见或无益的答案是需要解决的关键挑战
在教育背景下部署法学硕士。这项工作引入了一种创新
该架构将 ChatGPT 的优势与传统的
基于信息检索的聊天机器人框架，提供增强的学生支持
在高等教育中。我们的实证评估强调了高前景
这种方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.00052</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>巴西场景中的自动作文评分。 （arXiv：2401.00095v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.00095</link>
      <description><![CDATA[本文提出了一种量身定制的新颖的自动作文评分（AES）算法
巴西国家考试葡萄牙语论文
(ENEM)，解决传统人类评分系统中的挑战。我们的
方法利用先进的深度学习技术来紧密结合
人工评分标准，以评估效率和可扩展性为目标
大量的学生论文。这项研究不仅回应了
巴西教育中手工评分的后勤和财务限制
评估，还承诺提高评分的公平性和一致性，
标志着AES大规模应用向前迈出了重要一步
学术设置。
]]></description>
      <guid>http://arxiv.org/abs/2401.00095</guid>
      <pubDate>Tue, 02 Jan 2024 06:17:47 GMT</pubDate>
    </item>
    </channel>
</rss>