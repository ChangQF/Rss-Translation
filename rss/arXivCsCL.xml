<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 09 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>采样温度对大型语言模型问题解决的影响</title>
      <link>https://arxiv.org/abs/2402.05201</link>
      <description><![CDATA[在这项研究中，我们实证研究了采样温度对大型语言模型（LLM）在各种问题解决任务中的性能的影响。我们通过从标准 LLM 基准中随机抽取问题来创建多项选择题与答案 (MCQA) 考试。然后，我们使用四个流行的法学硕士和五种即时工程技术来解决 MCQA 问题，同时将采样温度从 0.0 提高到 1.0。尽管有相反的传闻，但我们的实证结果表明，0.0 至 1.0 范围内的温度变化不会对 LLM 解决问题任务的表现产生统计上的显着影响。此外，无论法学硕士、即时工程技术或问题领域如何，这些结果似乎都成立。所有代码、数据和补充材料均可在 GitHub 上获取：https://github.com/matthewrenze/jhu-llm-Temperature。]]></description>
      <guid>https://arxiv.org/abs/2402.05201</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>根据个性化人类反馈进行个性化语言建模</title>
      <link>https://arxiv.org/abs/2402.05133</link>
      <description><![CDATA[来自人类反馈的强化学习（RLHF）是当前的主导框架，用于微调大型语言模型以更好地符合人类偏好。然而，当人类反馈中编码的用户偏好多种多样时，在此框架下开发的算法的基本前提可能会出现问题。在这项工作中，我们的目标是通过开发构建个性化语言模型的方法来解决这个问题。我们首先正式介绍从个性化人类反馈中学习的任务，并解释为什么普通 RLHF 在这种情况下可能会出现问题。然后，我们提出了一种通用的个性化 RLHF（P-RLHF）框架，该框架需要联合学习用户模型和语言（或奖励）模型。用户模型接收用户信息并输出用户表示。它的结构编码了我们对反馈数据背后的用户偏好的假设。我们为个性化奖励建模和个性化直接偏好优化制定新的学习目标。为了证明我们方法的有效性，我们在带有注释偏好和注释者信息的真实文本摘要数据上对其进行了测试。我们对 GPT-J 6B 进行微调以获得个性化语言（和奖励）模型，该模型在符合个人偏好方面优于非个性化模型。]]></description>
      <guid>https://arxiv.org/abs/2402.05133</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>LV-Eval：平衡的长上下文基准，具有 5 个长度级别，最高可达 256K</title>
      <link>https://arxiv.org/abs/2402.05136</link>
      <description><![CDATA[最先进的大型语言模型 (LLM) 现在声称可支持 256k 甚至更长的上下文长度。相比之下，主流基准的平均上下文长度不足（5k-21k），并且存在潜在的知识泄漏和指标不准确的问题，导致评估有偏差。本文介绍了 LV-Eval，这是一个具有挑战性的长上下文基准测试，具有五个长度级别（16k、32k、64k、128k 和 256k），最高可达 256k 字。 LV-Eval 具有两个主要任务，单跳 QA 和多跳 QA，包含 11 个双语数据集。 LV-Eval的设计融合了三个关键技术，即混淆事实插入、关键词和短语替换以及基于关键词回忆的度量设计。 LV-Eval 的优点包括跨不同上下文长度的可控评估、用令人困惑的事实挑战测试实例、减少知识泄漏以及更客观的评估。我们评估了 10 名法学硕士的 LV-Eval，并对 LV-Eval 构建中使用的技术进行了消融研究。结果表明：（i）在比其声称的上下文长度更短的长度水平内进行评估时，商业法学硕士通常优于开源法学硕士。然而，它们的整体表现被上下文长度较长的开源法学硕士所超越。 (ii) 极长上下文的法学硕士，例如 Yi-6B-200k，表现出相对温和的性能下降，但其绝对性能不一定高于上下文长度较短的法学硕士。 (iii) 法学硕士的表现在存在混乱信息的情况下可能会显着下降，尤其是在“大海捞针”的压力测试中。 (iv) 与知识泄漏和不准确的指标相关的问题会在评估中引入偏差，而这些担忧在 LV-Eval 中得到了缓解。所有数据集和评估代码均发布于：https://github.com/infinigence/LVEval。]]></description>
      <guid>https://arxiv.org/abs/2402.05136</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>财务报告分块以实现有效检索增强生成</title>
      <link>https://arxiv.org/abs/2402.05131</link>
      <description><![CDATA[信息分块是检索增强生成 (RAG) 的关键步骤。目前的研究主要集中在段落级分块上。这种方法将所有文本视为平等，并忽略了文档结构中包含的信息。我们提出了一种对块文档的扩展方法，超越了单纯的段落级分块，而是通过文档的结构元素组件对主要块进行了分块。将文档分解为这些组成元素创建了一种对文档进行分块的新方法，无需调整即可产生最佳的分块大小。我们引入了一种新颖的框架，该框架评估基于文档理解模型注释的元素类型的分块如何有助于检索信息的整体上下文和准确性。我们还演示了这种方法如何影响 RAG 辅助问答任务的绩效。我们的研究包括对各种元素类型、它们在有效信息检索中的作用以及它们对 RAG 输出质量的影响进行全面分析。研究结果支持基于元素类型的分块在很大程度上改善了财务报告的 RAG 结果。通过这项研究，我们还能够回答如何发现高度准确的 RAG。]]></description>
      <guid>https://arxiv.org/abs/2402.05131</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>TexShape：语言模型的信息理论句子嵌入</title>
      <link>https://arxiv.org/abs/2402.05132</link>
      <description><![CDATA[随着数据量的指数级增长和数据密集型应用程序的出现，特别是在机器学习领域，与资源利用、隐私和公平性相关的担忧变得至关重要。本文重点关注数据的文本领域，并通过信息论的视角解决了将句子编码为其优化表示的挑战。特别是，我们使用互信息的经验估计，使用 Kullback-Leibler 散度的 Donsker-Varadhan 定义。我们的方法利用这种估计来训练信息论句子嵌入，称为 TexShape，用于（基于任务的）数据压缩或过滤敏感信息，增强隐私和公平性。在本研究中，我们采用基准语言模型来进行初始文本表示，并辅之以用于信息理论压缩和互信息估计的神经网络。我们的实验表明，在使用压缩数据训练的下游模型的预测准确性方面，在逆压缩率下保留最大目标信息和最小敏感信息方面取得了显着进步。]]></description>
      <guid>https://arxiv.org/abs/2402.05132</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型文本注释的最佳实践</title>
      <link>https://arxiv.org/abs/2402.05129</link>
      <description><![CDATA[大型语言模型 (LLM) 开创了文本注释的新时代，因为其易用性、高精度和相对较低的成本意味着它们的使用在最近几个月出现了爆炸式增长。然而，该领域的快速发展意味着基于法学硕士的注释已成为学术上的狂野西部：缺乏既定的实践和标准导致了对研究质量和有效性的担忧。研究人员警告说，法学硕士表面上的简单性可能会产生误导，因为它们很容易出现偏见、误解和不可靠的结果。认识到法学硕士的变革潜力，本文提出了一套全面的标准和最佳实践，以实现其可靠、可重复和合乎道德的使用。这些指南涵盖了模型选择、提示工程、结构化提示、提示稳定性分析、严格的模型验证以及道德和法律影响的考虑等关键领域。该论文强调需要采用结构化、定向和形式化的方法来使用法学硕士，旨在确保文本注释实践的完整性和稳健性，并倡导法学硕士在社会科学研究中进行细致入微和批判性的参与。]]></description>
      <guid>https://arxiv.org/abs/2402.05129</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>LB-KBQA：大语言模型和基于BERT的知识问答系统</title>
      <link>https://arxiv.org/abs/2402.05130</link>
      <description><![CDATA[生成式人工智能（AI）以其新兴能力赋能各个领域，其中典型的就是大型语言模型（LLM）。生成式人工智能的典型应用领域之一是大语言模型（LLM），与传统的基于人工智能的方法相比，LLM的自然语言理解能力得到了显着提高。自然语言理解能力一直是基于知识的问答（KBQA）系统意图识别性能的障碍，这是由于语言多样性和新出现的意图而产生的。传统的基于人工智能的意图识别方法可以分为基于语义解析的方法和基于模型的方法。然而，这两种方法在意图识别方面都受到资源有限的影响。为了解决这个问题，我们提出了一种基于大语言模型（LLM）和 BERT（LB-KBQA）的新型 KBQA 系统。在生成人工智能的帮助下，我们提出的方法可以检测新出现的意图并获取新知识。在金融领域问答实验中，我们的模型表现出了卓越的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.05130</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络和基于 NER 的文本摘要</title>
      <link>https://arxiv.org/abs/2402.05126</link>
      <description><![CDATA[当今时代，数据和信息非常丰富，人类甚至机器几乎不可能逐行浏览所有数据。人们通常所做的就是尝试快速浏览并保留绝对重要的信息，用更正式的术语来说，这称为总结。文本摘要是一项重要任务，旨在将冗长的文档或文章压缩为较短、连贯的表示形式，同时保留核心信息和含义。该项目引入了一种创新的文本摘要方法，利用图神经网络 (GNN) 和命名实体识别 (NER) 系统的功能。 GNN 具有捕获和处理文本信息中固有的关系数据的卓越能力，擅长理解大型文档中的复杂结构。同时，NER 系统通过识别和强调关键实体来做出贡献，确保摘要过程始终关注文本的最关键方面。通过整合这两种技术，我们的方法旨在提高摘要的效率，并试图确保浓缩内容的高度相关性。因此，该项目为在信息饱和的世界中处理不断增加的文本数据量提供了一个有前途的方向。]]></description>
      <guid>https://arxiv.org/abs/2402.05126</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>Illuminate：一种使用即时工程进行可解释分析和主动治疗的抑郁症检测新方法</title>
      <link>https://arxiv.org/abs/2402.05127</link>
      <description><![CDATA[本文介绍了一种使用高级大型语言模型 (LLM) 进行抑郁症检测和治疗的新颖范例：生成式预训练 Transformer 4 (GPT-4)、Llama 2 chat 和 Gemini。这些法学硕士通过专门的提示进行微调，以诊断、解释和建议抑郁症的治疗干预措施。独特的几次提示方法增强了模型根据 DSM-5 标准分析和解释抑郁症状的能力。在互动阶段，模型利用 PsychDB 和认知行为治疗 (CBT) 指南等资源进行移情对话管理，促进与患有重度抑郁症的个体的支持性互动。此外，该研究还引入了 Illuminate 数据库，其中包含各种 CBT 模块，有助于提出个性化治疗建议。该研究使用不同测试集的 F1 分数、精确度、召回率、余弦相似度和面向召回率的 Gisting 评估 (ROUGE) 等指标来评估法学硕士的表现，证明了其有效性。这种综合方法将尖端人工智能与既定的心理学方法相结合，为心理健康护理提供了新的可能性，并展示了法学硕士在彻底改变抑郁症诊断和治疗策略方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2402.05127</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型和检索增强生成增强教科书问答任务</title>
      <link>https://arxiv.org/abs/2402.05128</link>
      <description><![CDATA[由于上下文和多模态数据的复杂性，教科书问答（TQA）是人工智能中的一项具有挑战性的任务。尽管之前的研究已经显着改进了该任务，但仍然存在一些局限性，包括模型推理能力较弱以及无法在冗长的上下文中捕获上下文信息。大语言模型（LLM）的引入彻底改变了人工智能领域，然而，直接应用LLM往往会导致不准确的答案。本文提出了一种处理 TQA 中域外场景的方法，其中概念通过结合检索增强生成（RAG）技术分布在不同的课程中，并利用迁移学习来处理长上下文并增强推理能力。通过对 LLM 模型 Llama-2 的监督微调和 RAG 的结合，我们的架构优于基线，在非图多项选择题的验证集上实现了 4.12% 的准确度提升，在测试集上实现了 9.84% 的准确度提升。]]></description>
      <guid>https://arxiv.org/abs/2402.05128</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>LLM指令调整数据选择的调查</title>
      <link>https://arxiv.org/abs/2402.05123</link>
      <description><![CDATA[指令调优是训练大型语言模型（LLM）的重要一步，因此如何增强指令调优的效果越来越受到关注。现有工作表明，在LLM的指令调整过程中，数据集的质量比数量更重要。因此，最近很多研究集中在探索从指令数据集中选择高质量子集的方法，旨在降低法学硕士的训练成本并增强其指令跟踪能力。本文对法学硕士指令调整的数据选择进行了全面的调查。首先，我们介绍广泛使用的指令数据集。然后，我们提出了数据选择方法的新分类法，并详细介绍了最新进展，并对数据选择方法的评估策略和结果进行了详细阐述。最后，我们强调了这项任务的开放挑战和新领域。]]></description>
      <guid>https://arxiv.org/abs/2402.05123</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>零样本临床试验患者与法学硕士匹配</title>
      <link>https://arxiv.org/abs/2402.05125</link>
      <description><![CDATA[将患者与临床试验相匹配是将新药推向市场的一个尚未解决的关键挑战。如今，识别符合试验资格标准的患者需要高度手工操作，每个患者最多需要 1 小时。然而，自动筛选具有挑战性，因为它需要理解非结构化的临床文本。大型语言模型（LLM）提供了一个有前途的解决方案。在这项工作中，我们探索了它们在试验匹配中的应用。首先，我们设计一个基于法学硕士的系统，将患者的病史作为非结构化临床文本，评估该患者是否符合一组纳入标准（也指定为自由文本）。我们的零样本系统在 n2c2 2018 队列选择基准上取得了最先进的分数。其次，我们通过确定一种提示策略来提高我们方法的数据和成本效率，该策略比现状更快、更便宜地匹配患者一个数量级，并开发了一个两阶段检索管道，减少了处理的令牌数量到三分之一，同时保持高性能。第三，我们通过让临床医生评估法学硕士为每个资格决策生成的自然语言理由来评估我们系统的可解释性，并表明它可以为 97% 的正确决策和 75% 的错误决策输出连贯的解释。我们的结果证实了使用法学硕士加速临床试验操作的可行性。]]></description>
      <guid>https://arxiv.org/abs/2402.05125</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>仔细看看指令调优的局限性</title>
      <link>https://arxiv.org/abs/2402.05119</link>
      <description><![CDATA[指令调优 (IT) 是使用指令-响应对训练大型语言模型 (LLM) 的过程，已成为将基本预训练的 LLM 转换为开放域会话代理的主要方法。尽管 IT 取得了显着的成功并得到广泛采用，但其局限性和缺点仍未得到充分探讨。在本文中，通过严格的实验和深入分析法学硕士通过IT所经历的变化，我们揭示了IT的各种局限性。我们特别指出，(1) IT 未能增强法学硕士的知识或技能。 LoRA微调仅限于学习响应启动和风格标记，全参数微调会导致知识退化。 (2) 从知识来源获取的 IT 数据集中复制响应模式会导致响应质量下降。 (3) 全参数微调通过不准确地从 IT 数据集中概念上相似的实例借用令牌来生成响应，从而增加了幻觉。 (4) 改进 IT 的流行方法不会比简单的 LoRA 微调模型带来性能改进。我们的研究结果表明，仅根据预先训练的知识生成的响应始终优于通过开源数据集上的 IT 学习任何形式的新知识的模型的响应。我们希望所揭示的见解和挑战能够对未来的工作有所启发。]]></description>
      <guid>https://arxiv.org/abs/2402.05119</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>您只需要更多代理</title>
      <link>https://arxiv.org/abs/2402.05120</link>
      <description><![CDATA[我们发现，只需通过采样和投票方法，大型语言模型（LLM）的性能就会随着实例化代理的数量而变化。此外，该方法与现有的复杂方法正交，以进一步增强LLM，而增强程度与任务难度相关。我们对各种 LLM 基准进行了全面的实验，以验证我们的发现的存在，并研究可以促进其发生的属性。我们的代码公开于：\url{https://anonymous.4open.science/r/more_agent_is_all_you_need}。]]></description>
      <guid>https://arxiv.org/abs/2402.05120</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>量化相似性：评估 ChatGPT 和 Google Bard 内容与生物医学文献相关的文本挖掘方法</title>
      <link>https://arxiv.org/abs/2402.05116</link>
      <description><![CDATA[背景：在大型语言模型（LLM）的支持下，生成式人工智能工具的出现，显示出了强大的内容生成能力。迄今为止，对由所谓的即时工程生成的此类内容的有用性进行评估已成为一个有趣的研究问题。目标 使用即时工程的手段，我们评估这些内容与科学家创作的真实文献的相似性和接近度。方法 在本次探索性分析中，(1) 我们提示设计 ChatGPT 和 Google Bard 来生成临床内容以与文献对应内容进行比较，(2) 我们通过将生成的内容与生物医学文献中的对应内容进行比较来评估生成内容的相似性。我们的方法是使用文本挖掘方法来比较文档和相关的二元组，并使用网络分析来评估术语的中心性。结果实验表明，ChatGPT 在余弦文档相似度（38% 到 34%）、Jaccard 文档相似度（23% 到 19%）、TF-IDF 二元相似度（47% 到 41%）和术语网络中心性（47% 到 41%）方面优于 Google Bard（程度和亲密程度）。我们还发现 ChatGPT 二元网络中出现的新链接在文学二元网络中不存在。结论：获得的相似度结果表明，ChatGPT 在文档相似度、二元组、度和接近中心性方面优于 Google Bard。我们还观察到 ChatGPT 提供了与文献中相关术语的链接。这种联系可以激发提出有趣的问题并产生新的假设。]]></description>
      <guid>https://arxiv.org/abs/2402.05116</guid>
      <pubDate>Fri, 09 Feb 2024 06:16:49 GMT</pubDate>
    </item>
    </channel>
</rss>