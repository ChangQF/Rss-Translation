<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Tue, 05 Dec 2023 03:15:19 GMT</lastBuildDate>
    <item>
      <title>大型语言模型是零样本文本分类器。 （arXiv：2312.01044v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.01044</link>
      <description><![CDATA[重新训练的大型语言模型 (LLM) 已广泛应用于各个领域
自然语言处理（NLP）的各个子学科。在 NLP 中，文本
分类问题已经引起了人们的广泛关注，但仍然面临着
一些与昂贵的计算成本、时间消耗相关的限制
对未见过的类具有强大的性能。随着思路的提出
提示（CoT），法学硕士可以使用零样本学习（ZSL）来实现
循序渐进的推理提示，而不是常规的问答
格式。文本分类问题中的零样本法学硕士可以缓解
通过直接利用预训练模型来预测所看到的这些限制
和看不见的课程。我们的研究主要验证了 GPT 的能力
文本分类中的模型。我们专注于有效利用即时
各种文本分类场景的策略。此外，我们比较
零样本法学硕士与其他最先进的文本分类的性能
方法，包括传统机器学习方法、深度学习方法、
和 ZSL 方法。实验结果表明，LLM 的表现
强调了它们作为零样本文本分类器在三个领域中的有效性
分析了四个数据集。熟练程度对于小型企业尤其有利
可能不具备丰富的文本知识的企业或团队
分类。
]]></description>
      <guid>http://arxiv.org/abs/2312.01044</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:19 GMT</pubDate>
    </item>
    <item>
      <title>从古怪的语言模型中提取潜在知识。 （arXiv：2312.01037v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.01037</link>
      <description><![CDATA[引发潜在知识（ELK）旨在寻找神经网络的模式
激活可以稳健地跟踪世界的真实状态，即使
网络的公开输出是错误的或具有误导性的。为了进一步开展 ELK 研究，我们
引入一套经过 LoRA 微调的“古怪”语言模型
回答数学问题时出现系统错误当且仅当关键字
提示中出现“Bob”。我们证明简单的探测方法可以
引出模型在这些上下文中对正确答案的潜在知识，
即使是比探测器训练的问题更难的问题。然后我们比较
ELK 探测方法并发现一个简单的均值差分分类器
概括性最好。我们还发现机械异常检测方法
可以以高达 99% AUROC 的速度标记不诚实行为。我们的结果显示
承诺从有能力的模型中获取超人的知识，我们的目标是
促进未来的研究扩展我们的发现，采用更多样化的方法
和具有挑战性的数据集。
]]></description>
      <guid>http://arxiv.org/abs/2312.01037</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:18 GMT</pubDate>
    </item>
    <item>
      <title>从初学者到专家：将医学知识建模为普通法学硕士。 （arXiv：2312.01040v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.01040</link>
      <description><![CDATA[最近，基于大语言模型（LLM）的人工智能（AI）
系统在自然语言方面表现出了卓越的能力
理解和生成。然而，这些模型面临着重大挑战
当涉及敏感应用程序时面临挑战，例如推理
医学知识并以医生般的方式回答医学问题。
先前的研究试图通过增加模型大小来克服这一挑战
(&gt;100B) 学习更多一般医学知识，同时还有空间
法学硕士的模型尺寸较小（&lt;100B）的改进。在这项工作中，我们
从预训练的通用 LLM 模型 (AntGLM-10B) 开始，并从
从医学初学者到医学专家（称为 AntGLM-Med-10B），
利用 3 阶段优化程序，\textit{i.e.}，一般医疗
知识注入、医学领域指令调优、特定医学
任务适应。我们的贡献有三重：(1) 我们特别
研究如何在医学领域调整预训练的普通法学硕士，
特别是对于特定的医疗任务。 (2)我们收集并建造
优化过程每个阶段的大规模医疗数据集。这些
数据集包含各种数据类型和任务，例如问答、
医学推理、多项选择题和医学对话。 (3)
特别针对医学领域的多项选择题，我们提出了
用于促进工程的新颖的选择验证方法，该方法
显着增强了法学硕士的推理能力。值得注意的是，通过结合
通过上述方法，我们的 AntGLM-Med-10B 模型可以优于大多数 LLM
PubMedQA，包括普通法学硕士和医学法学硕士，即使这些法学硕士拥有
更大的模型尺寸。
]]></description>
      <guid>http://arxiv.org/abs/2312.01040</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:18 GMT</pubDate>
    </item>
    <item>
      <title>用于多域假新闻检测的双师去偏蒸馏框架。 （arXiv：2312.01006v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.01006</link>
      <description><![CDATA[多域假新闻检测旨在识别各种新闻是否来自
不同领域的真假已变得紧迫而重要。然而，
现有方法致力于提高假的整体性能
新闻检测，忽略了数据不平衡导致差异的事实
针对不同领域的处理，即领域偏差问题。为了解决这个问题
问题，我们提出了双师去偏蒸馏框架（DTDBD）
减少不同领域之间的偏见。经过知识蒸馏
DTDBD采用师生结构，预先训练大量
教师指导学生模型。特别是，DTBDD 包括
公正的老师和清廉的老师共同引导学生的榜样
减轻领域偏差并保持性能。对于公正的老师来说，
我们引入了对抗性去偏蒸馏损失来指导
学习公正领域知识的学生模型。为了干净的老师，我们
设计领域知识蒸馏损失，有效激励
学生模型专注于表示领域特征，同时保持
表现。此外，我们提出了一种基于动量的动态调整算法
权衡两位老师的影响。对中文和中文进行了广泛的实验
英语数据集表明，所提出的方法大大优于
在偏差指标方面最先进的基线方法，同时保证
有竞争力的表现。
]]></description>
      <guid>http://arxiv.org/abs/2312.01006</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>利用基于提示的技术的力量，使用大型语言模型生成学校级别的问题。 （arXiv：2312.01032v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.01032</link>
      <description><![CDATA[设计高质量的教育问题是一项具有挑战性和挑战性的工作
耗时的任务。在这项工作中，我们提出了一种利用
基于提示的技术来生成描述性和推理性问题。
然而，当前的问答（QA）数据集不足以进行
我们在教育中基于提示的问题生成（QG）的实验
环境。因此，我们为学校级别策划了一个名为 EduProbe 的新 QG 数据集
主题，利用 NCERT 教科书的丰富内容。我们小心翼翼地
将该数据集注释为 1) Context 的四元组：
问题已形成； 2) 长提示：针对问题的长文本提示（即
较长的单词或短语序列，涵盖上下文的主题）；
3) 简短提示：针对问题的简短文字提示（即，浓缩的
关键信息或上下文焦点的表示）； 4）问题：一
与上下文相符且与提示一致的深刻问题。我们
通过微调预训练来研究几种基于提示的 QG 方法
基于 Transformer 的大语言模型 (LLM)，即 PEGASUS、T5、MBART 和
巴特。此外，我们还探讨了两种通用预训练的性能
法学硕士，例如 Text-Davinci-003 和 GPT-3.5-Turbo，无需任何进一步培训。
通过执行自动评估，我们表明T5（带有长提示）
优于所有其他模型，但仍低于人类基线。
在人类评估标准下，TextDavinci-003通常表现出更好的结果
各种提示设置下均优于其他机型。即使就人类而言
评估标准中，QG 模型大多低于人类基线。我们的
代码和数据集可在：https://github.com/my625/PromptQG
]]></description>
      <guid>http://arxiv.org/abs/2312.01032</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>Omni-SMoLA：通过低级专家的软混合来促进通才多模式模型。 （arXiv：2312.00968v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00968</link>
      <description><![CDATA[大型多模态模型 (LMM) 在各个方面表现出卓越的性能
众多的任务。然而，多面手 LMM 常常会受到性能的影响
当对大量任务进行调整时，性能会下降。最近的研究
表明专家混合 (MoE) 架构对于教学很有用
调整，但对于参数大小约为 O(50-100B) 的 LMM，成本过高
复制和存储专家模型的方法严重限制了专家模型的数量
我们可以利用的专家。我们提出 Omni-SMoLA，一种使用 Soft 的架构
MoE 方法（温和地）混合许多多模式低级别专家，并避免
与传统 MoE 相比引入了大量新参数
楷模。这里的核心直觉是大型模型提供了基础
骨干，而不同的轻量级专家则剩余学习专业知识
知识，无论是按模态还是多模态。广泛的实验
证明 SMoLA 方法有助于提高通才表现
跨越广泛的生成视觉和语言任务，实现新的
SoTA 多面手性能通常可与单个人相媲美或胜过
专门的 LMM 基线，以及新的 SoTA 专家性能。
]]></description>
      <guid>http://arxiv.org/abs/2312.00968</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>用于大型语言模型指令调优的超参数优化。 （arXiv：2312.00949v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00949</link>
      <description><![CDATA[大型语言模型（LLM）的微调使他们最近能够
实现自然语言处理应用的里程碑。的出现
越来越大的法学硕士为更有效的微调方法铺平了道路。
其中，低秩适应（LoRA）方法保留了大部分权重
预训练的 LLM 被冻结，同时引入了低阶分解
权重矩阵，只允许调整很小一部分
网络。使用 LoRA 微调的模型在下游任务上的性能
严重依赖于一组超参数，包括
分解。在这项工作中，我们研究了这些超参数的选择
通过两种主要的黑盒优化（BBO）技术。我们检查整体
对预训练的 LLM 进行微调和验证的管道
黑盒并使用 \nomad 有效地探索超参数空间
算法，实现了调谐的性能和人体对齐的提升
模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.00949</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:15 GMT</pubDate>
    </item>
    <item>
      <title>压缩的成本：研究压缩对语言模型中参数知识的影响。 （arXiv：2312.00960v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00960</link>
      <description><![CDATA[压缩大型语言模型 (LLM)，通常包含数十亿个
参数，提供更快的推理、更小的内存占用，并启用
本地部署。两种标准压缩技术是修剪和
量化，前者消除模型层中的冗余连接
后者用较少的位数表示模型参数。关键的权衡
介于压缩程度和对质量的影响之间
压缩模型。现有的LLM压缩研究主要集中在
一般指标（如困惑度或下游任务）方面的性能
准确性。更细粒度的指标，例如测量参数的指标
知识，仍然未被充分探索。为了帮助弥合这一差距，我们
提供跨多个模型系列（编码器、
ENCODER-DECODER 和 DECODER）按顺序使用 LAMA 和 LM-HARNESS 基准
系统地量化常用压缩的效果
模型性能的技术。特别关注的是涉及的权衡
参数化知识，旨在为从业者提供实用的知识
有助于做出明智的压缩决策的见解。我们发布我们的
codebase1 以便进一步研究。
]]></description>
      <guid>http://arxiv.org/abs/2312.00960</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:15 GMT</pubDate>
    </item>
    <item>
      <title>Hi-ArG：探索语言预训练中分层论证图的集成。 （arXiv：2312.00874v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00874</link>
      <description><![CDATA[知识图谱是一种存储和表示知识的结构，并且
最近的研究讨论了它协助语言模型的能力
各种应用程序。知识图的一些变体旨在记录
计算论证任务的论点及其关系。然而，
许多必须简化语义类型以适应特定模式，从而失去
灵活性和表达能力。在本文中，我们提出了分层
论证图（Hi-ArG），一种组织论证的新结构。我们也
介绍两种利用 Hi-ArG 的方法，包括文本图多模态
模型 GreaseArG 和一个用图增强的新预训练框架
信息。两个论证任务的实验表明，经过
进一步预训练和微调，GreaseArG 取代同规模语言
这些任务的模型，同时在进一步的过程中结合图形信息
预训练还可以提高普通语言模型的性能。代码
本文可在 https://github.com/ljcleo/Hi-ArG 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.00874</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:14 GMT</pubDate>
    </item>
    <item>
      <title>无监督机器翻译的快速回译。 （arXiv：2312.00912v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00912</link>
      <description><![CDATA[无监督机器翻译领域已经取得了重大进展
Transformer 和反向翻译联姻带来的进步
算法。 Transformer 是一个强大的生成模型和反向翻译
利用 Transformer 的高质量翻译进行迭代
自我提升。然而，Transformer 的运行时间受到了阻碍
反向翻译期间的自回归推理，反向翻译是
由于缺乏综合数据效率而受到限制。我们建议买二送一
对 Transformer 反向翻译的改进：快速反向翻译 (QBT)。 QBT
将编码器重新用作生成模型，并使用编码器生成的
与原始自回归结合训练解码器的序列
反向翻译步骤，提高数据吞吐量和利用率。实验
各种 WMT 基准测试表明，相对较少的数量
QBT 的细化步骤改进了当前的无监督机器翻译模型，
并且 QBT 在以下方面显着优于标准的仅反向翻译方法
就可比翻译质量的培训效率而言。
]]></description>
      <guid>http://arxiv.org/abs/2312.00912</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:14 GMT</pubDate>
    </item>
    <item>
      <title>用于旅行行为预测的大型语言模型。 （arXiv：2312.00819v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00819</link>
      <description><![CDATA[出行行为预测是交通需求中的一项基础任务
管理。传统的出行行为预测方法依赖于
用于构建数学模型和校准模型参数的数值数据
来代表人类的偏好。大型语言模型的最新进展
（法学硕士）表现出解决复杂问题的强大推理能力。在这个
研究中，我们建议使用法学硕士来预测旅行行为
无需基于数据的参数学习的工程。具体来说，我们仔细
设计我们的提示，包括 1) 任务描述，2) 旅行特征，
3) 个人属性，4) 领域知识的思维指南，以及
要求法学硕士预测个人的旅行行为并解释
结果。我们选择出行方式选择任务作为案例研究。结果显示
尽管没有提供训练样本，但基于 LLM 的预测已经
竞争准确性和 F1 分数作为规范的监督学习方法，例如
如多项式 Logit、随机森林和神经网络。 LLM 还可以输出
支持他们预测的理由。然而，尽管在大多数情况下，
输出解释是合理的，我们仍然观察到违反的情况
逻辑或幻觉。
]]></description>
      <guid>http://arxiv.org/abs/2312.00819</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:13 GMT</pubDate>
    </item>
    <item>
      <title>RLHF-V：通过细粒度矫正人类反馈的行为调整，迈向值得信赖的 MLLM。 （arXiv：2312.00849v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00849</link>
      <description><![CDATA[多模态大型语言模型 (MLLM) 最近已证明
令人印象深刻的多模态理解、推理能力
相互作用。然而，现有的 MLLM 普遍存在严重的问题
幻觉问题，生成不符合事实的文本
相关图像。这个问题使得现有的 MLLM 不值得信任，因此
在现实世界（尤其是高风险）应用程序中不切实际。为了解决
挑战，我们提出了 RLHF-V，它通过行为增强 MLLM 的可信度
根据细粒度的矫正人类反馈进行调整。具体来说，RLHF-V
以分段级别修正的形式收集人类偏好
幻觉，并对
人类反馈。在自动驾驶和自动驾驶方面对五个基准进行综合实验
人类评估表明，RLHF-V 可以实现更多
值得信赖的 MLLM 行为，具有良好的数据和计算效率。
值得注意的是，使用 1.4k 个带注释的数据样本，RLHF-V 显着降低了
基础 MLLM 的幻觉率提高了 34.8%，优于并发
LLaVA-RLHF 使用 10k 个带注释的数据进行训练。最终模型实现
开源 MLLM 中最先进的可信度表现，以及
在防止幻觉引起的方面表现出比 GPT-4V 更好的鲁棒性
过度概括。我们在以下位置开源我们的代码、模型和数据：
https://github.com/RLHF-V/RLHF-V。
]]></description>
      <guid>http://arxiv.org/abs/2312.00849</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:13 GMT</pubDate>
    </item>
    <item>
      <title>机器人会梦想虚构的参考文献吗？与 ChatGPT3.5 的书目对话。 （arXiv：2312.00789v1 [cs.DL]）</title>
      <link>http://arxiv.org/abs/2312.00789</link>
      <description><![CDATA[本文重点介绍由 ChatGPT3.5 生成的参考书目
工具。使用这个基于训练好的GPT生成模型ChatGPT3.5的工具，
由 OpenAI 公司开发，我们探索了六个不同的主题并进行了分析
模型生成的参考样本（法语和英语）。这
结果显示多个领域的虚构参考文献比例很高，
强调使用前仔细检查这些参考文献的重要性
他们从事研究工作。尽管如此，结果还是有所改善
5 月和 7 月关于 ChatGPR3.5 主题的英文参考资料
虽然经过专门培训，但情况仍不令人满意
以法语为例。还应该指出的是，书中的大部分文字
本文由 ChatGPT 与人类作者共同努力生成。
]]></description>
      <guid>http://arxiv.org/abs/2312.00789</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:12 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型从在线文本中自动检测问题赌博迹象。 （arXiv：2312.00804v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00804</link>
      <description><![CDATA[问题赌博是一个主要的公共卫生问题，并且与
严重的心理困扰和经济问题。有无数
互联网上的赌博社区，用户可以在这里交换信息
游戏、赌博策略以及与赌博相关的问题。个人
表现出较高水平的问题赌博者更多地参与此类社区。
在线赌博社区可以提供对问题赌博的见解
行为。使用从德国主要赌博讨论板上抓取的数据，我们
微调大型语言模型，特别是双向编码器
Transformers (BERT) 模型的表示，用于预测
来自论坛帖子的问题赌博。训练数据由人工生成
注释并考虑诊断标准和赌博相关
认知扭曲。使用 k 折交叉验证，我们的模型实现了
精度为 0.95，F1 分数为 0.71，表明令人满意
分类性能可以通过生成高质量的训练来实现
根据诊断标准通过手动注释材料。目前的
研究证实基于 BERT 的模型可以可靠地用于小数据集
并检测在线通信数据中问题赌博的特征。这样的
计算方法可能具有检测变化的潜力
在线用户中赌博问题的普遍存在。
]]></description>
      <guid>http://arxiv.org/abs/2312.00804</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:12 GMT</pubDate>
    </item>
    <item>
      <title>性别推断：chatGPT 能否胜过常见的商业工具？ （arXiv：2312.00805v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.00805</link>
      <description><![CDATA[越来越多的研究使用性别信息来理解
诸如性别偏见、获取和参与方面的不平等或
Covid大流行应对措施的影响。不幸的是，大多数数据集没有
包括自我报告的性别信息，这使得研究人员有必要
从其他信息（例如姓名或姓名和国家/地区）推断性别
信息。这些工具的一个重要限制是它们无法
适当地捕捉性别以非二元尺度存在的事实，
然而，评估和比较这些工具的效果仍然很重要
在各种环境中执行。在本文中，我们比较了
生成式人工智能 (AI) 工具 ChatGPT 具有三个商业功能
可用的基于列表和基于机器学习的性别推断工具（Namsor，
Gender-API 和性别化.io）在一个独特的数据集上。具体来说，我们使用一个大的
奥林匹克运动员数据集并报告输入的变化（例如，第一
姓名（包括或不包括国家/地区信息）会影响
他们的预测的准确性。我们报告全套结果，以及
对于子集：奖牌与非奖牌获得者、来自最大的运动员
英语国家和东亚运动员。在这些集合上，我们发现
Namsor 是最好的传统商用工具。然而，
ChatGPT 的性能至少与 Namsor 一样好，并且常常优于它，
特别是对于女性样本，当国家和/或姓氏信息是
可用的。与非奖牌获得者相比，所有工具在奖牌获得者上的表现都更好
来自英语国家的名字。虽然不是为此目的而设计的，
ChatGPT 可能是一种经济高效的性别预测工具。未来，它
ChatGPT 或其他大规模语言模型甚至有可能
更好地识别自我报告的性别，而不是二元报告性别
规模。
]]></description>
      <guid>http://arxiv.org/abs/2312.00805</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:12 GMT</pubDate>
    </item>
    </channel>
</rss>