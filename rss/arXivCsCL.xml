<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Tue, 30 Jan 2024 06:17:37 GMT</lastBuildDate>
    <item>
      <title>MultiHop-RAG：多跳查询的基准检索增强生成。 （arXiv：2401.15391v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15391</link>
      <description><![CDATA[检索增强生成 (RAG) 通过以下方式增强大型语言模型 (LLM)
检索相关知识，显示出减轻 LLM 的巨大潜力
幻觉并提高反应质量，从而促进伟大的
在实践中采用法学硕士。然而，我们发现现有的 RAG 系统
不足以回答多跳查询，这需要检索和
对多个支持证据进行推理。此外，对于我们的
据了解，现有的 RAG 基准测试数据集都不关注多跳查询。
在本文中，我们开发了一个新颖的数据集 MultiHop-RAG，它由
知识库、大量多跳查询及其基本事实
答案以及相关的支持证据。我们详细介绍了流程
构建数据集，利用英语新闻文章数据集作为
底层 RAG 知识库。我们展示了基准测试的实用性
两个实验中的 MultiHop-RAG。第一个实验比较了不同
用于检索多跳查询证据的嵌入模型。在第二
实验，我们检查各种最先进的法学硕士的能力，
包括 GPT-4、PaLM 和 Llama2-70B，用于多跳推理和回答
给出证据后提出质疑。这两个实验都表明现有的 RAG 方法
在检索和回答多跳查询方面表现不佳。我们希望
MultiHop-RAG 将成为社区开发的宝贵资源
有效的 RAG 系统，从而促进法学硕士在
实践。 MultiHop-RAG 和实施的 RAG 系统可在以下位置公开获取：
https://github.com/yixuantt/MultiHop-RAG/。
]]></description>
      <guid>http://arxiv.org/abs/2401.15391</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的模型中多词表达式的语义：调查。 （arXiv：2401.15393v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15393</link>
      <description><![CDATA[多词表达式（MWE）由多个词组成并表现出
不同程度的组合性。因此，它们的含义是众所周知的
难以建模，并且尚不清楚这个问题会在多大程度上影响
变压器架构。为了解决这一差距，我们提供了第一个深入的
使用变压器模型进行 MWE 处理的调查。我们总体上发现他们
不一致地捕获 MWE 语义，如对表面模式的依赖所示
并记住了信息。 MWE 的含义也具有很强的本地化性，
主要在架构的早期层。代表受益于
特定的语言属性，例如较低的语义特质和
目标表达的歧义。我们的研究结果总体上质疑了
转换器模型可以稳健地捕获细粒度语义。此外，我们
强调需要更直接可比的评估设置。
]]></description>
      <guid>http://arxiv.org/abs/2401.15393</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>用于文档级神经机器翻译的重要性感知数据增强。 （arXiv：2401.15360v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15360</link>
      <description><![CDATA[文档级神经机器翻译（DocNMT）旨在生成
与它的翻译相比，它既连贯又具有凝聚力
句子级对应。然而，由于其输入长度较长且有限
训练数据的可用性，DocNMT经常面临数据的挑战
稀疏性。为了解决这个问题，我们提出了一种新颖的重要性感知数据
DocNMT 的增强 (IADA) 算法，增强基于训练数据的
关于通过隐藏状态的范数估计的令牌重要性信息以及
训练梯度。我们对三种广泛使用的产品进行了全面的实验
DocNMT 基准。我们的实证结果表明，我们提出的 IADA
优于强大的 DocNMT 基线以及多种数据增强
方法，在句子级别和级别上都具有统计显着性
文档级 BLEU。
]]></description>
      <guid>http://arxiv.org/abs/2401.15360</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>LegalDuet：通过双视图法律线索推理学习法律判决预测的有效表示。 （arXiv：2401.15371v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15371</link>
      <description><![CDATA[大多数现有的法律判决预测 (LJP) 模型侧重于发现
犯罪事实描述中的法律触发因素。然而，在现实世界中
专业法官不仅需要融会贯通案例
丰富的经验取决于过去的法律判决，但也取决于
从专业法律中学到的专业法律基础推理
知识。在本文中，我们提出了一个 LegalDuet 模型，该模型预训练
语言模型来学习定制的嵌入空间以做出法律判断。
它提出了一种双视图法律线索推理机制，该机制源自两个
法官的推理链：1）法律案例推理，做出法律判断
根据类比/混淆法律的判断经验
案例； 2）法律依据推理，在于匹配法律线索
刑事案件和法律判决之间的关系。我们的实验表明 LegalDuet
在 CAIL2018 数据集上实现了最先进的性能并优于其他数据集
平均提高约 4% 的基线。我们基于双视图推理
预训练可以捕获关键的法律线索来学习定制的嵌入
刑事案件的区分空间。它减少了 LegalDuet 期间的不确定性
预测，并为令人困惑/低频的问题带来预训练的进步
收费。所有代码均可在 https://github.com/NEUIR/LegalDuet 获取。
]]></description>
      <guid>http://arxiv.org/abs/2401.15371</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>用于理解伊斯兰教的基于 RAG 的问答系统提案：MufassirQAS LLM。 （arXiv：2401.15378v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15378</link>
      <description><![CDATA[学习和理解宗教作为
宗教教义和教义的复杂性和深度。聊天机器人
因为问答系统可以帮助解决这些挑战。法学硕士
聊天机器人使用 NLP 技术在主题和主题之间建立联系
准确回答复杂的问题。这些功能使其完美
作为问答聊天机器人用于宗教启蒙。然而，
法学硕士也有产生虚假信息的倾向，称为
幻觉。聊天机器人的响应可能包含侮辱性内容
个人宗教信仰、宗教间冲突以及有争议或
敏感话题。它需要在不宣扬仇恨言论或
冒犯某些群体或他们的信仰。本研究使用向量
基于数据库的检索增强生成（RAG）方法来增强
法学硕士的准确性和透明度。我们的问答系统称为
“穆法西尔QAS”。我们创建了一个包含几本开放获取书籍的矢量数据库
包括土耳其语背景。这些是土耳其语翻译和解释
伊斯兰教。我们精心创建系统提示，确保它们提供
防止有害、攻击性或不尊重反应的指示。我们
还用敏感问题测试了 MufassirQAS 和 ChatGPT。我们变得更好了
我们的系统的性能。研究和改进仍在进行中。
给出了结果和未来的工作。
]]></description>
      <guid>http://arxiv.org/abs/2401.15378</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>利用上下文线索从语音中提取事件。 （arXiv：2401.15385v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15385</link>
      <description><![CDATA[虽然基于文本的事件提取一直是一个活跃的研究领域，并且已经
在许多领域都看到了成功的应用，从其中提取语义事件
直接语音是一个尚未充分研究的问题。在本文中，我们介绍了
语音事件提取（SpeechEE）任务并构建三个合成训练
集和一个人类口语测试集。与从文本中提取事件相比，
SpeechEE 提出了更大的挑战，主要是由于复杂的语音信号
连续且没有单词边界。此外，与可感知的声音不同
事件、语义事件更加微妙，需要更深入的理解。到
为了应对这些挑战，我们引入了序列到结构的生成
可以以端到端的方式从语音信号产生事件的范式，
与利用语音识别的条件生成方法一起
文字记录作为上下文线索。我们进一步建议代表事件
一种平面格式，使输出更加自然语言。我们的实验
结果表明我们的方法对所有数据集带来了显着的改进，
实现最大F1增益10.7%。代码和数据集发布于
https://github.com/jodie-kang/SpeechEE。
]]></description>
      <guid>http://arxiv.org/abs/2401.15385</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>为语言模型配备金融表格数据分析的工具使用功能。 （arXiv：2401.15328v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15328</link>
      <description><![CDATA[大型语言模型（LLM）展示了一系列推理能力
能力，但面临错误传播和幻觉等挑战，
特别是在金融等数据异构的专业领域，
精度至关重要。我们探索语言模型的潜力
使用外部工具进行增强以减轻这些限制并减轻负担
更适合该任务的外部工具的某些推理步骤，
而不是仅仅依靠LLM的固有能力。更具体地说，
使用金融领域问答数据集，我们应用监督
对 LLaMA-2 13B 聊天模型进行微调，以充当“任务路由器”和
“任务解决者”。 “任务路由器”动态地将问题定向为
由法学硕士内部回答或通过工具中的正确工具外部回答
放。我们配备工具的 SFT 模型 Raven 的性能提升了 35.2%
分别比基本模型和仅 SFT 基线提高了 5.06%，并且
具有强大的 GPT-3.5 成绩，极具竞争力。据我们所知，
我们的工作是第一个研究语言模型工具增强的工作
对于金融领域。
]]></description>
      <guid>http://arxiv.org/abs/2401.15328</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>语言模型压缩算法的综合综述。 （arXiv：2401.15347v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15347</link>
      <description><![CDATA[我们如何在不牺牲准确性的情况下压缩语言模型？号码
语言模型的压缩算法正在快速增长并从中受益
来自最近语言模型的显着进步，并且没有副作用
语言模型的巨大规模，例如碳排放的增加和
昂贵的维护费用。虽然许多压缩算法已经表明
具有讽刺意味的是，在压缩语言模型方面取得了显着的进展
捕捉新兴趋势并确定基本概念具有挑战性
由于算法数量过多，它们成为了底层。在本文中，我们
调查和总结各种压缩算法，包括剪枝、
量化、知识蒸馏、低秩近似、参数
共享、高效的架构设计。我们不仅总结了整体
多样化压缩算法的趋势同时也选择有代表性的
算法并对其进行深入分析。我们讨论每个的价值
压缩算法的类别，以及低成本所需的属性
由于压缩算法的出现而产生重大影响
大语言模型。最后，我们介绍了未来有前景的研究主题
根据我们的调查结果。
]]></description>
      <guid>http://arxiv.org/abs/2401.15347</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>神经主题模型调查：方法、应用和挑战。 （arXiv：2401.15351v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15351</link>
      <description><![CDATA[主题模型已经流行了几十年，用于发现潜在主题和
以无监督的方式推断文档的主题比例。他们已
广泛应用于文本分析和上下文等各种应用
推荐。近年来，神经网络的兴起促进了
一个新的研究领域的出现——神经主题模型（NTM）。不同于
传统主题模型，NTM直接优化参数，无需
特定于模型的推导。这赋予了 NTM 更好的可扩展性和
灵活性，导致大量的研究关注和大量的新成果
方法和应用。在本文中，我们对
关于方法、应用和挑战的神经主题模型。
具体来说，我们根据当前的 NTM 方法系统地组织了它们
网络结构并介绍各种场景（例如短线）的NTM
文本和跨语言文档。我们还讨论了广泛的流行
构建在 NTM 上的应用程序。最后，我们强调了所面临的挑战
NTM 激发未来的研究。
]]></description>
      <guid>http://arxiv.org/abs/2401.15351</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>Unlearning 揭示了有影响力的语言模型训练数据。 （arXiv：2401.15241v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15241</link>
      <description><![CDATA[为了提高语言模型的性能，同时减轻
产生有害内容的风险，确定哪些培训至关重要
数据集影响模型的输出。理想情况下，我们可以衡量以下因素的影响：
将每个数据集从训练中删除；然而，这是令人望而却步的
多次重新训练模型的成本很高。本文介绍了 UnTrac，
通过从训练数据中忘却训练数据集的影响来估计训练数据集的影响
模型。 UnTrac 非常简单；每个训练数据集都被遗忘
梯度上升，我们评估模型的预测在之后发生了多少变化
忘记学习。我们凭经验检验我们的方法是否可以评估
关于生成有毒、有偏见和不真实内容的预训练数据集。
实验结果表明我们的方法很大程度上估计了它们的影响
比现有方法更准确，同时不需要过多的内存
空间或多个模型检查点。
]]></description>
      <guid>http://arxiv.org/abs/2401.15241</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>通过检索增强大型语言模型的检索和自我反思来改进医学推理。 （arXiv：2401.15269v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15269</link>
      <description><![CDATA[最近专有的大语言模型 (LLM)，例如 GPT-4，已经实现了
这是应对生物医学领域各种挑战的里程碑，
从多项选择题到长式生成。应对挑战
仍然无法用法学硕士的编码知识来处理，各种
检索增强生成（RAG）方法是通过搜索开发的
来自知识库的文档并无条件附加它们或
有选择地输入法学硕士的输入以进行生成。不过，申请时
针对不同领域特定问题的现有方法，泛化性差
变得明显，导致获取不正确的文档或做出不准确的
判断。在本文中，我们介绍了 Self-BioRAG，一个可靠的框架
专门用于生成解释、检索的生物医学文本
特定领域的文档以及自我反思生成的响应。我们利用
84k 经过过滤的生物医学指令集，用于训练可评估的 Self-BioRAG
它使用定制的反射标记生成解释。我们的工作证明
特定于域的组件，例如检索器、域相关文档
语料库和指令集对于遵守领域相关的内容是必要的
指示。使用三大医学问答基准数据集，
Self-BioRAG 的实验结果表明性能显着提升
与最先进的技术相比，平均绝对提高了 7.2%
参数大小为 7B 或更小的开放基础模型。总的来说，我们分析
Self-BioRAG找到问题中的线索，检索相关文档
如果需要，并了解如何使用检索到的信息进行回答
像医学专家一样记录和编码知识。我们发布我们的数据
以及用于训练我们的框架组件和模型权重的代码（7B 和 13B）
增强生物医学和临床领域的能力。
]]></description>
      <guid>http://arxiv.org/abs/2401.15269</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>我们如何反驳索赔：通过缺陷识别和解释进行自动事实检查。 （arXiv：2401.15312v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15312</link>
      <description><![CDATA[自动事实核查是互联网治理中的一项关键任务
内容。尽管各种研究利用先进模型来解决这个问题，
在解决复杂的现实世界谣言和
欺骗性的主张。为了应对这一挑战，本文探讨了新任务
面向缺陷的事实检查，包括方面生成和缺陷
鉴别。我们还介绍了 RefuteClaim，一个新设计的框架
专门为了这个任务。由于缺乏现有数据集，我们
展示 FlawCheck，这是一个通过提取和转换见解创建的数据集
从专家评审到相关方面并找出缺陷。这
实验结果强调了 RefuteClaim 的功效，特别是在
对虚假陈述进行分类和澄清。
]]></description>
      <guid>http://arxiv.org/abs/2401.15312</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>UNSEE：无监督非对比句子嵌入。 （arXiv：2401.15316v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15316</link>
      <description><![CDATA[我们推出了 UNSEE：无监督非对比句子嵌入，一本小说
该方法在大规模文本嵌入基准测试中优于 SimCSE。我们的
探索始于解决代表性崩溃的挑战，
当 SimCSE 中的对比目标替换为
非对比性目标。为了解决这个问题，我们提出了一个简单的方法
称为目标网络的解决方案，有效减轻代表性
坍塌。目标网络的引入使我们能够利用
非对比性目标，保持训练稳定性，同时实现
与对比目标相当的性能改进。我们的方法有
通过以下方式在非对比句子嵌入中取得了最高性能
细致的微调和优化。这项综合努力已取得成果
优越的句子表示模型，展示了我们的有效性
方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.15316</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士的可扩展定性编码：思想链推理在某些解释学任务中与人类表现相匹配。 （arXiv：2401.15170v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15170</link>
      <description><![CDATA[定性编码或内容分析从文本中提取含义
辨别文本语料库中的定量模式。最近，在
大语言模型（LLM）的解释能力提供了潜力
自动化编码过程（将类别标签应用于文本），从而
使人类研究人员能够专注于更具创造性的研究方面，
同时将这些解释任务委托给人工智能。我们的案例研究包括一组
代表一个社会历史代码的密集的、长段落的段落
人文研究。我们证明 GPT-4 能够与人类等效
解释，而 GPT-3.5 则不然。与人类提取的黄金相比
标准，GPT-4 提供出色的内部编码器可靠性（Cohen 的 $\kappa \geq
9 个代码中的 3 个代码为 0.79$)，8 个代码的可靠性很高 ($\kappa \geq 0.6$)
共 9 个代码。相比之下，GPT-3.5 对于所有代码都表现不佳
（$mean（\kappa）= 0.34$；$max（\kappa）= 0.55$）。重要的是，我们发现编码
当法学硕士被提示给出理由时，保真度会大大提高
证明其编码决策的合理性（思维链推理）。我们呈现这些
和其他发现以及一套适应传统的最佳实践
LLM 的密码本。我们的结果表明，对于某些密码本，
最先进的法学硕士已经擅长大规模内容分析。
此外，他们认为下一代模型可能会渲染人工智能
为大多数密码本编写可行的选项。
]]></description>
      <guid>http://arxiv.org/abs/2401.15170</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>用于预测临床文本中实体修饰符的迁移学习：在阿片类药物使用障碍病例检测中的应用。 （arXiv：2401.15222v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.15222</link>
      <description><![CDATA[背景：从临床文本中提取的实体的语义可以是
被修饰语显着改变，包括实体否定、不确定性、
条件、严重性和主题。现有模型用于确定
临床实体的修饰符涉及正则表达式或特征权重
为每个修饰符独立训练。

方法：我们开发并评估多任务变压器架构设计
使用公开可用的信息联合学习和预测修饰符
SemEval 2015 Task 14 语料库和新的阿片类药物使用障碍 (OUD) 数据集
包含与 SemEval 共享的修饰符以及特定于的新颖修饰符
沉香木。我们评估了多任务学习方法的有效性
先前发布的系统并评估迁移学习的可行性
对于临床实体修饰语，当只有一部分临床修饰语是
共享。

结果：我们的方法在 Sharee 语料库上取得了最先进的结果
来自 SemEval 2015 Task 14，显示加权准确率提高了 1.1%，
未加权准确度为 1.7%，微 F1 分数为 10%。

结论：我们表明从共享模型中学习到的权重可以是
有效地转移到新的部分匹配的数据集，验证使用
临床文本修饰符的迁移学习
]]></description>
      <guid>http://arxiv.org/abs/2401.15222</guid>
      <pubDate>Tue, 30 Jan 2024 06:17:33 GMT</pubDate>
    </item>
    </channel>
</rss>