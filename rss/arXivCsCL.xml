<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Tue, 05 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>信息流路线：大规模自动解释语言模型</title>
      <link>https://arxiv.org/abs/2403.00824</link>
      <description><![CDATA[arXiv:2403.00824v1 公告类型：新
摘要：信息通过模型中实现的机制在网络内部的路由流动。这些路由可以表示为图形，其中节点对应于令牌表示，边对应于网络内部的操作。我们以自上而下的方式自动构建这些图，对于每个预测只留下最重要的节点和边。与依赖激活修补的现有工作流程相比，我们通过归因来做到这一点：这使我们能够仅通过一次前向传递就有效地发现现有电路。此外，我们的方法的适用性远远超出了修补的范围：我们不需要人类仔细设计预测模板，我们可以为任何预测（而不仅仅是允许模板中的预测）提取信息流路线。因此，我们可以讨论特定类型的预测或不同领域的一般模型行为。我们对 Llama 2 进行了实验，结果表明一些注意力头的作用总体上很重要，例如先前的标记头和子词合并头。接下来，我们发现 Llama 2 在处理相同词性的标记时的行为有相似之处。最后，我们展示了一些模型组件可以专门用于编码或多语言文本等领域。]]></description>
      <guid>https://arxiv.org/abs/2403.00824</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:37 GMT</pubDate>
    </item>
    <item>
      <title>DenseMamba：具有密集隐藏连接的状态空间模型，用于高效的大型语言模型</title>
      <link>https://arxiv.org/abs/2403.00818</link>
      <description><![CDATA[arXiv:2403.00818v1 公告类型：新
摘要：由于常用的 Transformer 架构对计算和内存的要求过高，大型语言模型（LLM）面临着艰巨的挑战。虽然状态空间模型（SSM）是一种新型的基础网络架构，计算复杂度较低，但其性能尚未完全与 Transformer 相媲美。本文介绍了 DenseSSM，这是一种增强 SSM 层之间隐藏信息流的新方法。通过选择性地将浅层隐藏状态集成到更深的层中，DenseSSM 保留了对最终输出至关重要的细粒度信息。密集连接增强的DenseSSM仍然保持了训练的并行性和推理效率。所提出的方法可以广泛适用于各种 SSM 类型，如 RetNet 和 Mamba。在模型大小相似的情况下，DenseSSM 实现了显着改进，例如 DenseRetNet 的性能优于原始 RetNet，在公共基准测试中准确率提高了 5%。]]></description>
      <guid>https://arxiv.org/abs/2403.00818</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:36 GMT</pubDate>
    </item>
    <item>
      <title>社交媒体作为传感器：使用自然语言处理分析 Twitter 数据以了解乳腺癌药物效果</title>
      <link>https://arxiv.org/abs/2403.00821</link>
      <description><![CDATA[arXiv:2403.00821v1 公告类型：新
摘要：乳腺癌是一个重要的公共卫生问题，也是女性癌症相关死亡的主要原因。尽管乳腺癌治疗取得了进展，但不坚持用药仍然是一个主要问题。由于电子健康记录通常不会捕获患者报告的结果，而这些结果可能会揭示有关药物相关经历的信息，因此社交媒体为增强我们对患者治疗经历的了解提供了一个有吸引力的资源。在本文中，我们开发了基于自然语言处理（NLP）的方法来研究社交媒体上自动管理的乳腺癌队列发布的信息。我们采用基于 Transformer 的分类器根据 X (Twitter) 上的乳腺癌患者/幸存者自我报告的信息来识别他们，并从他们的个人资料中收集纵向数据。然后，我们设计了一个基于规则的多层模型来开发乳腺癌治疗相关的副作用词典，并检测乳腺癌患者的药物使用模式和相关副作用。 583,962 个唯一用户提供了 1,454,637 个帖子，其中 62,042 人使用我们基于 Transformer 的模型被检测为乳腺癌成员。 198 名队列成员提到了乳腺癌药物，其中最常见的是他莫昔芬。我们的副作用词典确定了激素和化疗的众所周知的副作用。此外，它还发现受试者对癌症和药物有感觉，这可能表明存在副作用或情绪困扰的临床前阶段。该分析不仅强调了 NLP 技术在非结构化社交媒体数据中识别自我报告的乳腺癌帖子、药物使用模式和治疗副作用的效用，还强调了此类临床问题的社交数据的丰富性。]]></description>
      <guid>https://arxiv.org/abs/2403.00821</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:36 GMT</pubDate>
    </item>
    <item>
      <title>UrbanGPT：时空大语言模型</title>
      <link>https://arxiv.org/abs/2403.00813</link>
      <description><![CDATA[arXiv:2403.00813v1 公告类型：新
摘要：时空预测旨在预测和洞察城市环境在时间和空间上不断变化的动态。其目的是预测城市生活各个方面的未来模式、趋势和事件，包括交通、人口流动和犯罪率。尽管人们致力于开发神经网络技术来准确预测时空数据，但值得注意的是，其中许多方法在很大程度上依赖于拥有足够的标记数据来生成精确的时空表示。不幸的是，数据稀缺的问题在实际的城市传感场景中普遍存在。因此，有必要建立一个跨不同时空学习场景的、具有强大泛化能力的时空模型。从大型语言模型 (LLM) 的卓越成就中汲取灵感，我们的目标是创建一个时空 LLM，能够在广泛的下游城市任务中展现出卓越的泛化能力。为了实现这一目标，我们提出了 UrbanGPT，它将时空依赖编码器与指令调整范例无缝集成。这种集成使法学硕士能够理解跨时间和空间的复杂相互依赖关系，从而有助于在数据稀缺的情况下进行更全面、更准确的预测。为了验证我们方法的有效性，我们对各种公共数据集进行了广泛的实验，涵盖不同的时空预测任务。结果一致表明，我们的 UrbanGPT 凭借其精心设计的架构，始终优于最先进的基准。这些发现凸显了为时空学习构建大型语言模型的潜力，特别是在标记数据稀缺的零样本场景中。]]></description>
      <guid>https://arxiv.org/abs/2403.00813</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:35 GMT</pubDate>
    </item>
    <item>
      <title>RAM-EHR：检索增强满足电子健康记录的临床预测</title>
      <link>https://arxiv.org/abs/2403.00815</link>
      <description><![CDATA[arXiv:2403.00815v1 公告类型：新
摘要：我们提出了 RAM-EHR，这是一种检索增强管道，用于改进电子健康记录 (EHR) 的临床预测。 RAM-EHR首先收集多个知识源，将其转换为文本格式，并使用密集检索来获取与医学概念相关的信息。该策略解决了与概念的复杂名称相关的困难。然后，RAM-EHR 增强了与一致性正则化共同训练的本地 EHR 预测模型，以从患者就诊和总结的知识中捕获补充信息。对两个 EHR 数据集的实验显示了 RAM-EHR 相对于之前的知识增强基线的功效（AUROC 增益 3.4%，AUPR 增益 7.2%），强调了 RAM-EHR 总结的知识对于临床预测任务的有效性。该代码将发布在 \url{https://github.com/ritaranx/RAM-EHR}。]]></description>
      <guid>https://arxiv.org/abs/2403.00815</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:35 GMT</pubDate>
    </item>
    <item>
      <title>IPED：基于扩散模型的关系三元组提取的隐式视角</title>
      <link>https://arxiv.org/abs/2403.00808</link>
      <description><![CDATA[arXiv:2403.00808v1 公告类型：新
摘要：关系三元组提取是信息提取领域的一项基本任务，基于表格填充的有前景的框架最近作为实体关系提取的潜在基线而受到关注。然而，信息冗余和三重识别不完整等固有缺陷仍然存在问题。为了应对这些挑战，我们提出了一种基于扩散模型（IPED）的关系三元组提取的隐式视角，这是一种提取关系三元组的创新方法。我们的无分类器解决方案采用隐式策略，使用块覆盖来完成表格，避免了显式标记方法的限制。此外，我们引入了一种生成模型结构，即块去噪扩散模型，以与我们的隐式视角协作并有效地规避冗余信息中断。两个流行数据集上的实验结果表明，IPED 实现了最先进的性能，同时获得了卓越的推理速度和较低的计算复杂度。为了支持未来的研究，我们已在线公开源代码。]]></description>
      <guid>https://arxiv.org/abs/2403.00808</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:34 GMT</pubDate>
    </item>
    <item>
      <title>Abdelhak 在 SemEval-2024 任务 9：解码脑筋急转弯，专用模型与 ChatGPT 的功效</title>
      <link>https://arxiv.org/abs/2403.00809</link>
      <description><![CDATA[arXiv:2403.00809v1 公告类型：新
摘要：本研究引入了一个旨在解决 BRAINTEASER 任务 9 的专用模型，这是一项新颖的挑战，旨在通过句子和单词谜题评估模型的横向思维能力。我们的模型表现出了显着的功效，在测试阶段以 0.98 的总分在句子谜题解决中排名第一。此外，我们还探讨了 ChatGPT 的比较性能，特别分析了温度设置的变化如何影响其横向思维和解决问题的能力。我们的研究结果表明专用模型和 ChatGPT 之间存在显着的性能差异，强调了专用方法在增强人工智能创造性推理方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.00809</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:34 GMT</pubDate>
    </item>
    <item>
      <title>统一框架下 LoRA 遇见 Dropout</title>
      <link>https://arxiv.org/abs/2403.00812</link>
      <description><![CDATA[arXiv:2403.00812v1 公告类型：新
摘要： 凭借卓越的功能，大语言模型（LLM）已成为众多 NLP 应用中的基本元素，而参数高效的微调，尤其是 LoRA，作为一种轻量级的模型定制方法已广受欢迎。同时，各种 dropout 方法最初是为更新所有参数进行完全微调而设计的，减轻了与过多参数冗余相关的过度拟合。因此，LoRA 的可训练参数可以忽略不计，与以前的 dropout 方法的有效性之间可能存在矛盾，而这一点在很大程度上被忽视了。为了填补这一空白，我们首先确认参数高效的 LoRA 也容易出现过度拟合。然后，我们重新审视变压器特定的 dropout 方法，并从数学和经验上建立它们的等价性和区别。在此比较分析的基础上，我们引入了一个综合调查的统一框架，该框架根据下降位置、结构模式和补偿措施实例化了这些方法。通过这个框架，我们揭示了它们在涉及有限的可训练参数时的新偏好和性能比较。这个框架还允许我们将最有利的方面合并到一种名为 HiddenKey 的新颖的 dropout 方法中。大量的实验验证了 HiddenKey 在多个模型和任务中的显着优越性和充分性，这凸显了它作为 LLM 高性能和参数高效微调的首选方法。]]></description>
      <guid>https://arxiv.org/abs/2403.00812</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:34 GMT</pubDate>
    </item>
    <item>
      <title>受大脑启发的两阶段方法：通过模仿人类思维过程增强数学推理</title>
      <link>https://arxiv.org/abs/2403.00800</link>
      <description><![CDATA[arXiv:2403.00800v1 公告类型：新
摘要：虽然大型语言模型在解决数学应用问题方面表现出了新兴的能力，但复杂的多步骤数学推理任务仍然具有挑战性。为了提高模型在数学推理任务上的性能，之前的工作通过提高数据的质量和数量对开源模型进行有监督的微调。在本文中，我们提出了一种名为“Brain”的新方法来模仿人类思维过程来增强数学推理能力，使用额叶模型生成计划，然后使用顶叶模型生成代码并执行以获得答案。首先，通过这种方法，我们与基于 Code LLaMA 7B 的模型相比实现了 SOTA 性能。其次，我们发现计划可以从自然语言、代码或形式语言中明确提取。我们的代码和数据可在 https://github.com/cyzhh/Brain 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2403.00800</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:33 GMT</pubDate>
    </item>
    <item>
      <title>通过拓扑自然语言分析发现客户问题</title>
      <link>https://arxiv.org/abs/2403.00804</link>
      <description><![CDATA[arXiv:2403.00804v1 公告类型：新
摘要：电子商务公司每天处理大量的客户服务请求。虽然简单的注释系统通常用于总结客户联系人的主题，但彻底探索每个具体问题可能具有挑战性。这是一个严重的问题，特别是在新爆发的疫情期间，公司必须快速识别并解决具体问题。为了应对这一挑战，我们提出了一种新颖的机器学习算法，该算法利用自然语言技术和拓扑数据分析来监控新兴和趋势客户问题。我们的方法涉及一个端到端深度学习框架，该框架同时标记每个客户成绩单的主要问题句子并生成句子嵌入向量。然后，我们对嵌入向量进行白化，并使用它们构建无向图。从那里，我们根据每个转录本的拓扑特性定义趋势和新出现的问题。我们通过各种方法验证了我们的结果，发现它们与新闻来源高度一致。]]></description>
      <guid>https://arxiv.org/abs/2403.00804</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:33 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型执行自然语言描述的算法：一项调查</title>
      <link>https://arxiv.org/abs/2403.00795</link>
      <description><![CDATA[arXiv:2403.00795v1 公告类型：新
摘要：执行以自然语言描述的计算机程序长期以来一直是计算机科学的追求。随着大型语言模型 (LLM) 所展示的增强的自然语言理解能力的出现，实现这一目标的道路已经被照亮。在本文中，我们试图检验当今法学硕士理解和执行自然​​语言概述算法的能力。我们建立的算法测试集来源于著名教材《算法导论》，其中包含许多具有代表性的广泛使用的算法。为了系统地评估LLM的代码执行能力，我们选择了30种算法，总共生成了300个随机采样实例，并评估了流行的LLM是否能够理解和执行这些算法。我们的研究结果表明，只要不涉及繁重的数值计算，法学硕士（尤其是 GPT-4）就可以有效地执行用自然语言描述的程序。我们相信我们的研究结果有助于评估法学硕士的代码执行能力，并将鼓励对法学硕士的计算能力进行进一步的研究和应用。]]></description>
      <guid>https://arxiv.org/abs/2403.00795</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:32 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士数学推理中数据能力边界的实证研究</title>
      <link>https://arxiv.org/abs/2403.00799</link>
      <description><![CDATA[arXiv:2403.00799v1 公告类型：新
摘要： 大型语言模型（LLM）在数学推理任务中展现出新兴的能力，并且通过监督微调（SFT）来增强开源LLM的能力越来越受到关注。在本文中，我们旨在探索一种监督数据的通用数据策略，以帮助优化和扩展数学推理能力。首先，我们通过识别这些路径的最小最优集来确定推理路径增强的能力边界。其次，我们验证模型的不同能力可以通过以下方式累积增强：相应类型数据的最小最优集的混合，而我们的模型 MMOS 在系列基础模型上以低得多的构建成本实现了 SOTA 性能。此外，我们指出 GSM-HARD 并不难，今天的 LLM 不再缺乏数值鲁棒性。而且，我们为稳健性测试和教育应用提供自动问题生成器。我们的代码和数据可在 https://github.com/cyzhh/MMOS 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2403.00799</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:32 GMT</pubDate>
    </item>
    <item>
      <title>PRECISE 框架：基于 GPT 的文本，提高放射学报告的可读性、可靠性和可理解性，实现以患者为中心的护理</title>
      <link>https://arxiv.org/abs/2403.00788</link>
      <description><![CDATA[arXiv:2403.00788v1 公告类型：新
摘要：本研究介绍并评估了 PRECISE 框架，利用 OpenAI 的 GPT-4 在六年级阅读水平上提供更清晰、更易于理解的胸部 X 光报告，从而提高患者参与度。该框架在 500 份报告上进行了测试，显示出在可读性、可靠性和可理解性方面的显着改进。统计分析证实了 PRECISE 方法的有效性，突显了其在医疗保健决策中促进以患者为中心的护理服务的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.00788</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:31 GMT</pubDate>
    </item>
    <item>
      <title>$\textit{L+M-24}$：构建语言+分子数据集 @ ACL 2024</title>
      <link>https://arxiv.org/abs/2403.00791</link>
      <description><![CDATA[arXiv:2403.00791v1 公告类型：新
摘要：语言分子模型已成为分子发现和理解的一个令人兴奋的方向。然而，由于分子语言对数据集的稀缺，训练这些模型具有挑战性。目前，数据集已经发布，这些数据集 1）很小，从现有数据库中抓取；2）大但有噪音，通过对科学文献执行实体链接来构建；3）通过使用模板将属性预测数据集转换为自然语言来构建。在本文档中，我们详细介绍了 $\textit{L+M-24}$ 数据集，该数据集是为 ACL 2024 的语言 + 分子研讨会共享任务创建的。特别是 $\textit{L+M-24}$旨在关注自然语言在分子设计中的三个关键优势：组合性、功能性和抽象性。]]></description>
      <guid>https://arxiv.org/abs/2403.00791</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:31 GMT</pubDate>
    </item>
    <item>
      <title>认真对待幽默：用无趣的大型语言模型制作幽默数据集</title>
      <link>https://arxiv.org/abs/2403.00794</link>
      <description><![CDATA[arXiv:2403.00794v1 公告类型：新
摘要：幽默是人类认知和互动的一个基本方面。然而，尽管自然语言处理最近取得了进展，幽默检测仍然是一项具有挑战性的任务，由于缺乏将幽默文本与类似的非幽默文本配对的数据集，该任务变得更加复杂。在我们的工作中，我们研究大型语言模型（LLM）是否可以通过编辑文本生成用于幽默检测的合成数据。我们在现有的人类数据集上对法学硕士进行了基准测试，结果表明，根据人类的判断以及幽默检测的下游任务的衡量，当前的法学硕士表现出了令人印象深刻的“搞笑”笑话能力。我们将我们的方法扩展到代码混合的英语-印地语幽默数据集，我们发现 GPT-4 的合成数据受到双语注释者的高度评价，并为幽默分类器提供了具有挑战性的对抗性示例。]]></description>
      <guid>https://arxiv.org/abs/2403.00794</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:31 GMT</pubDate>
    </item>
    </channel>
</rss>