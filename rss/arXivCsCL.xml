<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 22 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>上下文质量在训练融合解码器以进行提取式开放域问答时很重要</title>
      <link>https://arxiv.org/abs/2403.14197</link>
      <description><![CDATA[arXiv:2403.14197v1 公告类型：新
摘要：检索增强生成模型通过在生成过程中提供额外的相关外部知识（上下文）来增强语言模型中编码的知识。尽管已经证明上下文的数量和质量会影响检索增强生成模型在推理过程中的性能，但有限的研究探索了这些特征如何影响模型训练。本文探讨了模型训练期间的上下文数量和质量如何影响 Fusion-in-Decoder (FiD)（最先进的检索增强生成模型）在提取式开放域问答任务中的性能。实验结果表明，FiD 模型在训练期间过度拟合上下文质量，并且在不同上下文质量上进行评估时表现出次优性能。通过实验结果，我们还揭示了用不同上下文质量训练的 FiD 模型具有不同的交叉注意力分布模式。具体来说，随着训练期间上下文质量的提高，FiD 模型往往会更一致地关注上下文中的每个段落。最后，基于这些观察，我们提出了一种通过向交叉注意力分布引入偏差来减轻对特定上下文质量的过度拟合的方法，我们证明该方法可以有效提高 FiD 模型在不同上下文质量上的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.14197</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>从手工制作的功能到法学硕士：机器翻译质量评估的简要调查</title>
      <link>https://arxiv.org/abs/2403.14118</link>
      <description><![CDATA[arXiv:2403.14118v1 公告类型：新
摘要： 机器翻译质量估计（MTQE）是在不需要参考译文的情况下实时估计机器翻译文本的质量的任务，这对于机器翻译的发展具有重要意义。经过二十年的演变，量化宽松已经取得了丰硕的成果。本文全面概述了 QE 数据集、注释方法、共享任务、方法、挑战和未来的研究方向。首先介绍了QE的背景和意义，然后解释了词级QE、句子级QE、文档级QE和可解释QE的概念和评估指标。该论文将 QE 历史上开发的方法分为基于手工特征、深度学习和大型语言模型（LLM）的方法，并将基于深度学习的方法进一步分为经典深度学习和结合预训练语言的方法模型（LM）。此外，本文还详细介绍了每种方法的优点和局限性，并提供了不同方法的直接比较。最后，本文讨论了当前量化宽松研究面临的挑战，并对未来的研究方向进行了展望。]]></description>
      <guid>https://arxiv.org/abs/2403.14118</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>M$^3$AV：多模式、多流派、多用途视听学术讲座数据集</title>
      <link>https://arxiv.org/abs/2403.14168</link>
      <description><![CDATA[arXiv:2403.14168v1 公告类型：新
摘要：发布开源学术视频记录是一种新兴且普遍的在线共享知识的方法。此类视频携带丰富的多模态信息，包括语音、讲话者的面部和身体动作，以及幻灯片甚至论文中的文本和图片。尽管已经构建并发布了多个学术视频数据集，但很少有支持多模态内容识别和理解任务的数据集，部分原因是缺乏高质量的人工注释。在本文中，我们提出了一种新颖的多模式、多流派和多用途视听学术讲座数据集（M$^3$AV），其中包含来自五个来源的近 367 小时的视频，涵盖计算机科学、数学、医学和生物学主题。通过对口头和书面文字（特别是高价值名称实体）的高质量人工注释，该数据集可用于多种视听识别和理解任务。对上下文语音识别、语音合成以及幻灯片和脚本生成任务进行的评估表明，M$^3$AV 的多样性使其成为一个具有挑战性的数据集。]]></description>
      <guid>https://arxiv.org/abs/2403.14168</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>MMIDR：教授大型语言模型通过知识蒸馏解释多模态错误信息</title>
      <link>https://arxiv.org/abs/2403.14171</link>
      <description><![CDATA[arXiv:2403.14171v1 公告类型：新
摘要：多模态错误信息的自动检测最近引起了广泛的关注。然而，强大的大型语言模型（LLM）用于多模式错误信息检测的潜力仍未得到充分开发。此外，如何教导法学硕士以经济有效且易于理解的方式解释多模式错误信息仍然是一个悬而未决的问题。为了解决这个问题，我们提出了 MMIDR，这是一个旨在教导法学硕士为多模式错误信息决策过程提供流畅和高质量文本解释的框架。为了将多模态错误信息转换为适当的指令跟踪格式，我们提出了数据增强视角和管道。该管道由视觉信息处理模块和证据检索模块组成。随后，我们通过处理内容提示专有法学硕士提取解释多模式错误信息真实性的理由。此外，我们设计了一种有效的知识蒸馏方法，将专有法学硕士在解释多模式错误信息方面的能力提炼为开源法学硕士。为了探索有关法学硕士在多模态错误信息检测任务中性能的几个研究问题，我们构建了一个遵循指令的多模态错误信息数据集并进行了全面的实验。实验结果表明，我们的 MMIDR 表现出足够的检测性能，并有能力提供令人信服的理由来支持其评估。]]></description>
      <guid>https://arxiv.org/abs/2403.14171</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>NLP 歧义类型分类</title>
      <link>https://arxiv.org/abs/2403.14072</link>
      <description><![CDATA[arXiv:2403.14072v1 公告类型：新
摘要：歧义是语言的一个重要组成部分，它可以让说话者之间进行更有效的沟通，但在 NLP 中经常被忽视。最近的研究表明，NLP 系统可能难以掌握人类语言理解的某些要素，因为它们可能无法像人类在交流中自然处理的那样处理歧义。此外，不同类型的歧义可能有不同的目的，需要不同的解决方法，我们的目标是研究语言模型的能力如何因类型而异。我们提出了一种英语歧义类型的分类法，以促进 NLP 分析。我们的分类法可以帮助对语言歧义数据进行有意义的分割，从而可以对数据集和模型性能进行更细粒度的评估。]]></description>
      <guid>https://arxiv.org/abs/2403.14072</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士的中文常识推理基准：从中文具体到推理-记忆相关性</title>
      <link>https://arxiv.org/abs/2403.14112</link>
      <description><![CDATA[arXiv:2403.14112v1 公告类型：新
摘要：我们介绍了CHARM，这是第一个全面深入评估中文大语言模型（LLM）常识推理能力的基准，它涵盖了全球已知的常识和中国特有的常识。我们在CHARM上对7位英语和12位汉语方向的法学硕士进行了评估，采用了Chain-of-Thought等5种有代表性的提示策略来提高法学硕士的推理能力。我们的研究结果表明，法学硕士的语言取向和任务领域会影响提示策略的有效性，这丰富了之前的研究成果。我们构建了紧密相连的推理和记忆任务，发现一些法学硕士在记忆中文常识方面存在困难，影响了他们的推理能力，而另一些法学硕士尽管记忆表现相似，但在推理上却表现出差异。我们还评估了法学硕士的独立记忆推理能力并分析了典型错误。我们的研究准确地识别了法学硕士的优势和劣势，为优化提供了明确的方向。也可为其他领域的研究提供参考。我们将在 https://github.com/opendatalab/CHARM 发布 CHARM。]]></description>
      <guid>https://arxiv.org/abs/2403.14112</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>情感计算中ChatGPT的提示灵敏度研究</title>
      <link>https://arxiv.org/abs/2403.14006</link>
      <description><![CDATA[arXiv:2403.14006v1 公告类型：新
摘要：最近的研究证明了像 ChatGPT 这样的基础模型在多个领域（包括情感计算）的新兴功能。然而，通过快速工程可以促进获得这些新兴功能。尽管存在一些提示技术，但该领域仍在快速发展，许多提示想法仍然需要研究。在这项工作中，我们介绍了一种基于不同提示或生成参数来评估和研究基础模型性能敏感性的方法。我们在情感计算的范围内对情感分析、毒性检测和讽刺检测这三个主要问题进行了对 ChatGPT 的评估。首先，我们对自回归文本生成中的关键参数进行敏感性分析，特别是 Nucleus 采样中的温度参数 $T$ 和 top-$p$ 参数，指示模型在生成过程中应该有多保守或创造性。此外，我们探讨了几种激励想法的功效，其中我们探讨了给予不同的激励或结构如何影响绩效。我们的评估考虑了情感计算任务的性能指标，以及模型遵循规定指令的有效性，从而生成易于解析的响应，以便在下游应用程序中顺利使用。]]></description>
      <guid>https://arxiv.org/abs/2403.14006</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>用于高性能语言技术的新的海量多语言数据集</title>
      <link>https://arxiv.org/abs/2403.14009</link>
      <description><![CDATA[arXiv:2403.14009v1 公告类型：新
摘要：我们提出了 HPLT（高性能语言技术）语言资源，这是一个新的大规模多语言数据集，包括从 CommonCrawl 中提取的单语和双语语料库以及从互联网档案馆中提取的以前未使用的网络爬虫。我们描述了大型语料库的数据采集、管理和处理方法，这些方法依赖于开源软件工具和高性能计算。我们的单语集合侧重于中低资源语言，涵盖 75 种语言，并在文档级别删除了总计约 5.6 万亿个单词标记。我们以英语为中心的平行语料库源自其单语对应语料库，涵盖 18 个语言对和超过 9600 万个对齐句子对，以及大约 14 亿个英语标记。 HPLT 语言资源是迄今为止发布的最大的开放文本语料库之一，为语言建模和机器翻译培训提供了丰富的资源。我们公开发布本工作中使用的语料库、软件和工具。]]></description>
      <guid>https://arxiv.org/abs/2403.14009</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>Ax-to-Grind Urdu：乌尔都语假新闻检测基准数据集</title>
      <link>https://arxiv.org/abs/2403.14037</link>
      <description><![CDATA[arXiv:2403.14037v1 公告类型：新
摘要：错误信息会严重影响社会，影响从公众舆论到制度信心和国家政治视野的各个方面。在线网站和在线社交网络 (OSN) 上的假新闻 (FN) 激增。各种事实核查网站都包含英文新闻，但几乎不提供有关 FN 的地方语言信息。因此，无法使用事实检查门户来识别乌尔都语 FN 供应商。假新闻检测 (FND) 的 SOTA 方法依赖于适当标记的大型数据集。由于缺乏有限的数据集和合法的词汇资源，区域语言和资源有限语言的 FND 滞后。乌尔都语 FND 之前的数据集大小有限、域受限、公开不可用，并且在新闻从英语翻译成乌尔都语时未经手动验证。在本文中，我们策划并贡献了乌尔都语 FND 的第一个最大的公开数据集 Ax-to-Grind Urdu，以弥补文献中现有乌尔都语数据集已确定的差距和局限性。它包含从巴基斯坦和印度领先且真实的乌尔都语报纸和新闻频道网站收集的 15 个领域的 10,083 条虚假和真实新闻。 Ax-to-Grind 数据集的 FN 是从网站和众包收集的。该数据集包含 2017 年至 2023 年乌尔都语新闻。专家记者对数据集进行了注释。我们使用 mBERT、XLNet 和 XLM RoBERTa 的集成模型对数据集进行基准测试。所选模型最初是在多语言大型语料库上进行训练的。所提出模型的结果基于性能指标、F1 分数、准确度、精确度、召回率和 MCC 值。]]></description>
      <guid>https://arxiv.org/abs/2403.14037</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>视觉基础语音模型具有相互排斥性偏差</title>
      <link>https://arxiv.org/abs/2403.13922</link>
      <description><![CDATA[arXiv:2403.13922v1 公告类型：新
摘要：当孩子们学习新单词时，他们会采用诸如相互排他性（ME）偏差之类的约束：新单词会映射到新的物体而不是熟悉的物体。这种偏差已经通过计算进行了研究，但仅限于使用离散单词表示作为输入的模型，忽略了口语单词的高度可变性。我们在从自然图像和连续语音音频中学习的视觉基础语音模型的背景下研究 ME 偏差。具体来说，我们用熟悉的单词训练一个模型，并通过要求它在使用新词查询时在新奇和熟悉的对象之间进行选择来测试其 ME 偏差。为了模拟先前的声学和视觉知识，我们使用预训练的语音和视觉网络尝试了几种初始化策略。我们的研究结果揭示了不同初始化方法之间的 ME 偏差，其中具有更多先验（特别是视觉）知识的模型的偏差更大。即使考虑不同的损失函数，其他测试也证实了我们结果的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2403.13922</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>减少大型语言模型偏差，重点关注“受限行业”：自动数据集扩充和偏见量化</title>
      <link>https://arxiv.org/abs/2403.13925</link>
      <description><![CDATA[arXiv:2403.13925v1 公告类型：新
摘要：尽管大型语言模型的能力不断增强，但人们仍然担心它们会产生偏差。在本文中，我们提出了一种新颖的自动化机制，通过在偏差生产者的视角和数据有限的“受限行业”的背景下通过指定的数据集增强来消除偏差。考虑到偏差是由于内在模型架构和数据集造成的，我们还创建了两个新的附加指标，即 mb-index 和 db-index 来量化偏差。]]></description>
      <guid>https://arxiv.org/abs/2403.13925</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>评估预训练句子嵌入的无监督降维方法</title>
      <link>https://arxiv.org/abs/2403.14001</link>
      <description><![CDATA[arXiv:2403.14001v1 公告类型：新
摘要：预训练语言模型（PLM）生成的句子嵌入因其在众多下游应用程序中表示文本时的卓越性能而受到了 NLP 社区的广泛关注。然而，当在内存或计算受限的设备中表示大量句子时，PLM 生成的句子嵌入的高维性会出现问题。作为解决方案，我们评估无监督降维方法来降低 PLM 生成的句子嵌入的维度。我们的实验结果表明，主成分分析（PCA）等简单方法可以将句子嵌入的维数减少近 50\%$，而不会在多个下游任务中造成性能的显着损失。令人惊讶的是，对于某些 PLM 在某些任务中生成的句子嵌入，降低维数比原始高维版本进一步提高了性能。]]></description>
      <guid>https://arxiv.org/abs/2403.14001</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>训练和约束：从主题和释义中生成语音绕口令</title>
      <link>https://arxiv.org/abs/2403.13901</link>
      <description><![CDATA[arXiv:2403.13901v1 公告类型：新
摘要：以前在语音和语音基础语言生成方面的工作主要集中在双关语和诗歌等领域。在本文中，我们提出了关于绕口令生成的新工作，绕口令是一种需要以音素级别为条件的语言形式，以最大化声音重叠，同时保持与输入主题的语义一致性，并且语法仍然正确。我们推出了 TwisterLister，这是一个从大型语言模型 (LLM) 生成语音绕口令的管道，我们用它来生成 TwistList 2.0，这是迄今为止最大的带注释绕口令数据集，由来自人类和 LLM 组合的 17K 多个示例组成作者。我们的生成流程涉及使用语音受限词汇以及法学硕士，提示生成新颖的、非衍生的绕口令示例。我们还展示了对在我们生成的数据集上训练的较小模型的自动和人工评估的结果，以证明在不显式注入语音知识的情况下可以生成语音驱动的语言类型的程度。此外，我们引入了一个音素感知约束解码模块（PACD），它可以集成到任何因果语言模型中，并证明该方法无论是否微调底层语言模型都可以生成高质量的绕口令。我们还设计并实现了一系列用于绕口令生成任务的自动指标，该指标以语音为动机，并基于音素编辑距离（PED）捕捉绕口令的独特本质。]]></description>
      <guid>https://arxiv.org/abs/2403.13901</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>利用语言增强的嵌入进行开放信息提取</title>
      <link>https://arxiv.org/abs/2403.13903</link>
      <description><![CDATA[arXiv:2403.13903v1 公告类型：新
摘要：开放信息提取 (OIE) 是自然语言处理 (NLP) 中的一项结构化预测 (SP) 任务，旨在从自由文本中提取结构化 $n$ 元组（通常是主语-关系-宾语三元组）。输入文本中的词嵌入可以通过语言特征来增强，通常是词性（PoS）和句法依存解析（SynDP）标签。然而，过去的增强技术无法利用预训练语言模型 (PLM) 的强大功能，而 PLM 本身几乎没有用于 OIE。为了弥补这一差距，我们率先利用 OIE 的 Seq2Seq PLM 的语言特征。我们通过引入两种方法来实现这一点 - 加权加法和线性化串联。我们的工作可以一次性为任何神经 OIE 架构提供 PLM 和语言特征的关键性能提升。在我们的设置中，精度、召回率和 F1 分数较基线分别提高了 24.9%、27.3% 和 14.9%。除此之外，我们还解决了该领域的其他重要挑战：为了减少功能的计算开销，我们是第一个利用语义依赖解析（SemDP）标签的人；为了解决当前数据集中的缺陷，我们创建了一个干净的合成数据集；最后，我们贡献了第一个已知的 SP 模型中 OIE 行为的研究。]]></description>
      <guid>https://arxiv.org/abs/2403.13903</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>你支持哪一方呢？调查大型语言模型的政治立场</title>
      <link>https://arxiv.org/abs/2403.13840</link>
      <description><![CDATA[arXiv:2403.13840v1 公告类型：新
摘要：大型语言模型（LLM）因其在文本生成、摘要和信息检索等各种日常任务中的应用而受到广泛欢迎。随着法学硕士的广泛采用持续激增，确保这些模型产生政治公正的反应变得越来越重要，目的是防止信息泡沫，维护代表性的公平性并减轻确认偏差。在本文中，我们提出了一个定量框架和管道，旨在系统地调查法学硕士的政治倾向。我们的调查深入探讨了法学硕士在八个两极分化主题中的政治立场，从堕胎到 LGBTQ 问题。在各个主题中，结果表明，当用户查询包含有关职业、种族或政治派别的详细信息时，法学硕士倾向于提供与自由主义或左倾观点紧密一致的回答，而不是保守或右倾观点。这项研究中提出的结果不仅重申了早期关于法学硕士左倾特征的观察结果，而且还揭示了一些特殊属性，例如职业，即使直接转向保守主义，这些属性也特别容易受到这种倾向的影响。作为避免这些模型提供政治化响应的建议，用户在设计查询时应小心，并谨慎选择中立的提示语言。]]></description>
      <guid>https://arxiv.org/abs/2403.13840</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    </channel>
</rss>