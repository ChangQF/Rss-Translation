<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 04 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>从文本到图：利用图形神经网络以增强NLP的解释性</title>
      <link>https://arxiv.org/abs/2504.02064</link>
      <description><![CDATA[ARXIV：2504.02064V1公告类型：新 
摘要：研究人员将自然语言处理任务降级为变压器型模型，尤其是生成模型，因为这些模型在执行生成和分类任务时表现出很高的多功能性。随着这些模型的规模的增加，它们取得了出色的结果。鉴于它们的广泛使用，许多解释性技术是根据这些模型开发的。但是，由于模型的尺寸较大，该过程在计算上变得昂贵。此外，变形金刚通过令牌解释输入信息，将片段输入单词输入到缺乏固有语义含义的序列中，从一开始就使模型的解释变得复杂。这项研究提出了一种新的方法，可以通过自动将句子转换为图形并通过表达基本语言概念的节点和关系来维持语义来实现自然语言处理任务。它还允许随后在随后的任务中剥削这些知识，从而有可能获得趋势，并了解模型如何将文本中的不同元素与解释的任务联系起来。这些实验在确定给定分类的文本结构中最关键的组成部分方面带来了有希望的结果。]]></description>
      <guid>https://arxiv.org/abs/2504.02064</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过与人工智能的对话增加幸福感</title>
      <link>https://arxiv.org/abs/2504.02091</link>
      <description><![CDATA[ARXIV：2504.02091V1公告类型：新 
摘要：由人工智能提供支持的聊天机器人（AI）已迅速成为日常生活的重要组成部分，其中四分之一的美国成年人每周使用它们多次。尽管这些工具提供了潜在的好处和风险，但一个基本问题仍然没有探索：与AI的对话如何影响主观幸福感？为了调查这一点，我们进行了一项研究，参与者要么与AI聊天机器人（n = 334）进行对话，要么以随机分配的主题为单位（n = 193），然后报告了他们之后的暂时幸福。我们发现，AI聊天机器人对话后的幸福比日记后要高，尤其是在讨论诸如抑郁或内gui之类的负面话题时。利用大型语言模型进行情感分析，我们发现AI聊天机器人在保持一致的阳性偏见的同时反映了参与者的情感。在讨论负面话题时，参与者逐渐使自己的情绪与人工智能的积极性保持一致，从而导致幸福感的总体增长。我们假设参与者的情感预测错误的历史，对AI聊天机器人做出回应时的预期和实际情感语气之间的差异可能解释了这种幸福效果。使用计算建模，我们发现在对话过程中这些情感预测错误的历史预测了会议后的幸福感，这表明了对话期间情感期望的核心作用。我们的发现强调了AI相互作用对人类福祉的影响。]]></description>
      <guid>https://arxiv.org/abs/2504.02091</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ContrastScore：朝着更高质量，偏见，更有效的评估指标和对比度评估</title>
      <link>https://arxiv.org/abs/2504.02106</link>
      <description><![CDATA[ARXIV：2504.02106V1公告类型：新 
摘要：自动评估生成文本的质量仍然是一个重大挑战。已显示基于常规参考的指标与人类评估表现出相对较弱的相关性。最近的研究主张使用大型语言模型（LLM）作为基于源的自然语言生成（NLG）评估的指标。在有希望的同时，基于LLM的指标，尤其是使用较小模型的指标，仍然与人类判断保持一致。在这项工作中，我们引入了对比度，这是一种旨在实现更高质量，偏见和更有效评估的对比度评估指标。我们在两个NLG任务上评估对比度：机器翻译和摘要。实验结果表明，与单模型和基于集合的基线相比，对比度始终达到与人类判断更强的相关性。值得注意的是，基于QWEN 3B和0.5B的ContrastScore甚至均超过QWEN 7B，尽管只有一半的参数，但表明其效率只有一半。此外，它有效地减轻了常见的评估偏见，例如长度和可能性偏好，从而产生了更强大的自动评估。]]></description>
      <guid>https://arxiv.org/abs/2504.02106</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语法模型界面上的语言模型：中国反思性Ziji长距离结合的案例研究</title>
      <link>https://arxiv.org/abs/2504.02116</link>
      <description><![CDATA[ARXIV：2504.02116V1公告类型：新 
摘要：本文探讨了语言模型是否可以有效地解决普通话反射Ziji的复杂结合模式，这些模型受到句法和语义因素的约束。我们使用模板和句法文献中的示例以及BCC语料库的320个自然句子构建了240个合成句子的数据集。根据该数据集评估21种语言模型，并将其表现与本机普通话者的判断进行比较，我们发现这些模型都没有始终如一地复制类似人类的判断。结果表明，现有的语言模型倾向于在很大程度上依赖顺序提示，尽管并不总是偏爱最接近的字符串，并且经常忽略了微妙的语义和句法约束。与动词相关语义相比，它们往往对名词相关的语义更敏感。]]></description>
      <guid>https://arxiv.org/abs/2504.02116</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用像素级后备克服词汇约束</title>
      <link>https://arxiv.org/abs/2504.02122</link>
      <description><![CDATA[ARXIV：2504.02122V1公告类型：新 
摘要：子词令牌化需要平衡计算效率和词汇覆盖范围，这通常会导致在培训期间未优先考虑的语言和脚本上的次优表现。我们建议使用无词汇编码器来增强审计的语言模型，该模型从呈现为像素的文本中生成输入嵌入。通过以英语为中心的语言模型进行的实验，我们证明了我们的方法可以大大提高机器翻译性能，并促进有效的跨语言转移，优于基于令牌的方法。此外，我们发现基于像素的表示优于字节级的方法和标准词汇扩展。我们的方法增强了单语言模型的多语言能力，而无需大量的重新训练和通过输入压缩减少解码延迟。]]></description>
      <guid>https://arxiv.org/abs/2504.02122</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一张图片仅需花费：中毒视觉文档检索增强世代用一张图像</title>
      <link>https://arxiv.org/abs/2504.02132</link>
      <description><![CDATA[ARXIV：2504.02132V1公告类型：新 
摘要：多模式检索增强发电（M-rag）最近已成为一种通过事实知识库（KB）抑制大型多模型（LMM）幻觉的方法。但是，M-RAG还引入了针对对手的新攻击向量，旨在通过将恶意条目注入KB来破坏系统。在这项工作中，我们提出了针对M-rag靶向视觉文档检索应用的中毒攻击，其中KB包含文档页面的图像。我们的目标是制作一个用于各种不同用户查询的单个图像，并始终影响生成模型产生的输出，从而对M-rag系统产生通用的拒绝服务（DOS）攻击。我们证明，虽然我们的攻击对各种广泛使用的，最先进的检索器（嵌入模型）和发电机（LMM）有效，但它也可能对可靠的嵌入模型无效。我们的攻击不仅突出了M云管道对中毒攻击的脆弱性，而且还阐明了根本的弱点，即使在良性环境中，也可能阻碍其表现。]]></description>
      <guid>https://arxiv.org/abs/2504.02132</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LL4G：基于图的人格检测的自我监督动态优化</title>
      <link>https://arxiv.org/abs/2504.02146</link>
      <description><![CDATA[ARXIV：2504.02146V1公告类型：新 
摘要：基于图的个性检测构造从文本数据，尤其是社交媒体帖子中的图形结构。当前的方法通常会在稀疏或嘈杂的数据中挣扎，并依靠静态图，从而限制了它们捕获节点和关系之间动态变化的能力。本文介绍了LL4G，这是一个自我监督的框架，利用大型语言模型（LLMS）优化图形神经网络（GNNS）。 LLM提取丰富的语义特征以生成节点表示并推断出明确和隐式关系。图形结构根据输入数据自适应地添加节点和边缘，从而不断优化自身。然后，GNN使用这些优化的表示形式进行节点重建，边缘预测和对比度学习任务的联合培训。语义和结构信息的这种整合产生了强大的个性概况。 Kaggle和Pandora数据集的实验结果表明，LL4G的表现优于最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2504.02146</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SUBASA-僧伽罗的低资源进攻语言检测的适应语言模型</title>
      <link>https://arxiv.org/abs/2504.02178</link>
      <description><![CDATA[ARXIV：2504.02178V1公告类型：新 
摘要：准确检测进攻性语言对于许多与社交媒体安全有关的应用至关重要。低资源语言和高资源语言之间的这项任务的性能形成了鲜明的对比。在本文中，我们适应了以前在进攻性语言检测的下游任务中尚未探索过僧伽罗的微调策略。使用这种方法，我们介绍了四个模型：“ subasa-xlm-r”，该模型使用蒙版的理性预测结合了中间的预处理步骤。 “ Subasa-Lalama”和“ Subasa-Mistral”的两个变体分别是Llama（3.2）和Mistral（v0.3）的微调版本，具有特定于任务的策略。我们在出售的基准数据集上评估了我们的模型，以供僧伽罗进攻性语言检测。我们所有模型的表现都优于现有基线。 SUBASA-XLM-R在在同一售出的基准数据集中评估时，达到了最高的宏F1得分（0.84）超过最新的大语言模型，例如GPT-4O。模型和代码可公开使用。]]></description>
      <guid>https://arxiv.org/abs/2504.02178</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM作为欺骗性代理人：如何基于角色的促使诱使语义歧义在拼图任务中</title>
      <link>https://arxiv.org/abs/2504.02254</link>
      <description><![CDATA[ARXIV：2504.02254V1公告类型：新 
摘要：大型语言模型（LLMS）的最新进展不仅展示了令人印象深刻的创造力，而且还揭示了新兴的代理行为，这些行为利用了对抗性环境中语言歧义。在这项研究中，我们研究了一个LLM作为自治药物的扮演，利用语义歧义产生欺骗性的难题，这些难题误导和挑战了人类用户。受到流行的益智游戏“连接”的启发，我们系统地比较了通过零射击提示，注射角色的对抗提示和人工制作的例子产生的拼图，并强调理解基本的代理商决策过程。通过Hatebert进行计算分析来量化语义歧义，并在主观的人类评估中进行了表明，明确的对抗性药物行为显着提高了语义歧义 - 从而增加了认知载荷并减少拼图解决方案的公平性。这些发现为LLM的新兴代理质量提供了重要的见解，并强调了在教育技术和娱乐中评估和安全地部署自主语言系统的重要道德考虑因素。]]></description>
      <guid>https://arxiv.org/abs/2504.02254</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用MBART的文本到光线的最先进的翻译：孟加拉的案例研究</title>
      <link>https://arxiv.org/abs/2504.02293</link>
      <description><![CDATA[ARXIV：2504.02293V1公告类型：新 
摘要：尽管聋人和愚蠢的人口为170万，但孟加拉语手语（BDSL）仍然是一个研究的领域。具体而言，关于孟加拉文本到斜体翻译任务没有任何作品。要解决此差距，我们首先解决数据集问题。我们从德国和美国标志Langauage（ASL）（ASL）的基于语法规则的光泽产生中汲取灵感，并适应BDSL。我们还利用LLM生成合成数据并使用反向翻译，文本生成进行数据增强。准备好数据集后，我们开始实验。我们在数据集上微调了预审计的MBART-50和MBERT-MELTICLASS-IND模型。我们还训练了GRU，RNN和具有多头关注的新型SEQ-to-Seq模型。我们观察到高性能（Scarebleu = 79.53），并通过Facebook进行了微调的MBART-50多语言模型。然后，我们探讨了为什么我们观察到Mbart的高性能。我们很快就会注意到Mbart的一个有趣的属性 - 经过改组和掩盖的文本数据的培训。众所周知，Gloss表格具有洗牌财产。因此，我们假设Mbart固有地擅长文本到光线任务。为了找到反对这一假设的支持，我们在Phoenix-14T基准测试中培训了MBART-50，并通过现有文献进行了评估。我们的MBART-50 FINETUNE在Phoenix-14T基准测试中表现出最先进的性能，在所有6个指标中的现有模型远远超过现有型号（Scarebleu = 63.89，Bleu-1 = 55.14，Bleu-2 = 38.07，Bleu-3，Bleu-3 = 27.13，Bleu-4 = 27.13，Bleu-4 = 20.68，Comet = 0.68，Comet = 0.68，Comet = 0.624。基于结果，本研究提出了一种使用MBART模型的新范式，用于文本到光线任务。此外，我们的结果表明，基于规则的合成数据集，BDSL文本到格洛斯任务可以大大受益。]]></description>
      <guid>https://arxiv.org/abs/2504.02293</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM的人性哲学的衡量</title>
      <link>https://arxiv.org/abs/2504.02304</link>
      <description><![CDATA[ARXIV：2504.02304V1公告类型：新 
摘要：人工智能（AI）在各种任务中的广泛应用，以及涉及AI的冲突或违规行为的经常报道引发了人们对与AI系统互动的社会关注。基于赖特斯曼（Wrightsman）的人性量表（PHN）的哲学，这一量表在经验上几十年来经验验证，以有效地评估个人对人性的态度，我们设计了标准化的心理量表，专门针对大型语言模型（LLM），名为基于机器的人类自然量表（M-PHNS）。通过评估LLMS对六个维度的人性的态度，我们揭示了当前的LLMS对人类的系统缺乏信任，并且模型的智能水平与其对人类的信任之间存在显着的负相关。此外，我们提出了一个心理循环学习框架，该框架使LLM能够通过构建道德场景在虚拟互动期间不断优化其价值体系，从而提高其对人性的态度。实验表明，与角色或指导提示相比，心理循环学习可显着增强他们对人类的信任。这一发现突出了LLM基于人类的心理评估的潜力，LLM不仅可以诊断认知偏见，而且还为人工智能中的道德学习提供了潜在的解决方案。我们在https://github.com/kodenii/m-phns上发布M-PHN评估代码和数据。]]></description>
      <guid>https://arxiv.org/abs/2504.02304</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过联合检索和外部知识改善有害文本检测</title>
      <link>https://arxiv.org/abs/2504.02310</link>
      <description><![CDATA[ARXIV：2504.02310V1公告类型：新 
摘要：有害文本检测已成为大型语言模型开发和部署的至关重要的任务，尤其是随着AI生成的内容继续在数字平台上扩展。这项研究提出了一个联合检索框架，该框架将预训练的语言模型与知识图相结合，以提高有害文本检测的准确性和鲁棒性。实验结果表明，联合检索方法显着优于单模基准，尤其是在低资源训练方案和多语言环境中。提出的方法通过利用外部上下文信息来有效地捕获细微的有害内容，并解决传统检测模型的局限性。未来的研究应着重于优化计算效率，增强模型的解释性以及扩展多模式检测功能，以更好地解决不断发展的有害内容模式。这项工作有助于AI安全的发展，确保更加值得信赖和可靠的内容审核系统。]]></description>
      <guid>https://arxiv.org/abs/2504.02310</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>COTAL：人类及时的工程，经过思考的推理和积极学习，以进行可推广的形成性评估</title>
      <link>https://arxiv.org/abs/2504.02323</link>
      <description><![CDATA[ARXIV：2504.02323V1公告类型：新 
摘要：大型语言模型（LLM）创造了新的机会来协助教师并支持学生学习。诸如《经营链》（COT）之类的方法促使LLMS能够在科学中对形成性评估进行评分，从而为学生提供分数和相关的反馈。但是，这些方法在多个领域（例如科学，计算和工程）中跨课程推广的程度仍然很大程度上未经测试。 In this paper, we introduce Chain-of-Thought Prompting + Active Learning (CoTAL), an LLM-based approach to formative assessment scoring that (1) leverages Evidence-Centered Design (ECD) principles to develop curriculum-aligned formative assessments and rubrics, (2) applies human-in-the-loop prompt engineering to automate response scoring, and (3) incorporates teacher and student feedback to iteratively refine assessment questions, grading专栏和LLM提示进行自动分级。我们的发现表明，Cotal提高了GPT-4的得分表现，在非宣传工程基线的基线上获得了高达24.5％的收益。老师和学生都认为Cotal在评分和解释学生的反应方面都有有效的评分，每种都提供了有价值的改进，以提高评分准确性和解释质量。]]></description>
      <guid>https://arxiv.org/abs/2504.02323</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Learnat：通过AST指导的任务分解来学习NL2SQL的大型语言模型</title>
      <link>https://arxiv.org/abs/2504.02327</link>
      <description><![CDATA[ARXIV：2504.02327V1公告类型：新 
摘要：SQL的自然语言（NL2SQL）已成为实现与数据库无缝互动的关键任务。大型语言模型（LLM）的最新进展表明在该领域表现出色。但是，现有的NL2SQL方法主要依赖于封闭源LLMS利用及时的工程，而开源模型通常需要微调来获取特定领域的知识。尽管做出了这些努力，但由于用户查询目标的间接表达以及用户查询和数据库模式之间的语义差距，开源LLM与复杂的NL2SQL任务斗争。受到在数学问题解决方案中的应用中的应用来鼓励LLMS中的逐步推理的灵感，我们提出了Learnat（通过AST引导的任务分解学习NL2SQL（学习NL2SQL），这是一个新颖的框架，可改善复杂的NL2SQL任务通过任务分解和增强巩固和增强方案学习的开源NL2SQL任务的性能。 LEALAT介绍了三个关键组成部分：（1）分解合成程序，该过程利用抽象的语法树（AST）指导有效的搜索和修剪任务分解的策略，（2）利润率的增强学习，通过使用DPO进行良好的dpo进行良好的验证效果，并适应了（3）适应性的（3）适应性，并适应3）分解功能。在两个基准数据集（Spider和Bird）上进行的广泛实验表明，Learnat可以使7B参数开源LLM实现与GPT-4相当的性能，同时提供提高的效率和可访问性。]]></description>
      <guid>https://arxiv.org/abs/2504.02327</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMS的准语义能力：有关零件整个关系的案例研究</title>
      <link>https://arxiv.org/abs/2504.02395</link>
      <description><![CDATA[ARXIV：2504.02395V1公告类型：新 
摘要：了解\ emph {大语言模型}（LLMS）语义能力的程度和深度是人工智能（AI）和计算语言学（CL）当前科学议程的中心。我们通过调查他们对\ emph {part-phole}关系的了解，又称\ emph {meronymy}，在词汇组织中起着至关重要的作用，为这项工作做出了贡献。我们使用了概念网络关系\ citep {speer2016conceptnet}的数据和人类生成的语义特征规范\ citep {mcrae：2005}来探索LLMS处理\ textit {part-whole}关系的能力。我们采用了基于三个分析级别的几种方法：i。）\ textbf {行为}通过提示进行测试，在那里我们直接询问了模型的词，ii。）句子\ textbf {概率}得分，我们在其中测试了模型的模型，以区分正确的（真实）和不正确的（immetric contractial contractial and textiT）。 \ textbf {概念表示}在向量空间中的分析，我们在其中证明了\ textit {part-whole}概念的线性组织在嵌入式和无用的空间中。这些分析提出了一个复杂的图片，表明LLMS对这种关系的了解只是部分。他们只有``\ emph {quasi}  - 道义&#39;&#39;能力，但仍然没有捕获深厚的推论属性。]]></description>
      <guid>https://arxiv.org/abs/2504.02395</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>