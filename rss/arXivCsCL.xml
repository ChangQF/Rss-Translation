<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Thu, 13 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>智能法律助理：法律问题回答的互动澄清系统</title>
      <link>https://arxiv.org/abs/2502.07904</link>
      <description><![CDATA[ARXIV：2502.07904V1公告类型：新 
摘要：大型语言模型的兴起为寻求法律建议的用户开辟了新的途径。但是，用户通常缺乏专业的法律知识，这可能会导致省略关键信息的问题。这种缺陷使传统的法律提问系统能够准确确定用户的实际需求，这通常会导致不精确或广义建议。在这项工作中，我们开发了一种称为智能法律助理的法律提问系统，该系统与用户互动以精确地捕获他们的需求。当用户提出问题时，系统要求用户选择其地理位置以查明适用的法律。然后，它根据用户初始问题中缺少的关键信息生成澄清的问题和选项。这使用户可以选择并提供必要的详细信息。提供了所有必要的信息后，系统将产生深入的法律分析，其中包括三个方面：总体结论，法学分析和解决方案建议。]]></description>
      <guid>https://arxiv.org/abs/2502.07904</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提升法律LLM的回应：通过法律推理利用可训练的逻辑结构和语义知识</title>
      <link>https://arxiv.org/abs/2502.07912</link>
      <description><![CDATA[ARXIV：2502.07912V1公告类型：新 
摘要：大型语言模型（LLMS）在众多领域取得了令人印象深刻的结果，但他们在法律提问的任务中遇到了显着的缺陷。 LLMS通常会产生一般的回答，这些答案缺乏专家法律建议所需的逻辑特异性，并且容易幻觉，提供了看似正确但不可靠的答案。检索增强的一代（RAG）技术提供了部分解决方案来应对这一挑战，但是现有的方法通常仅着眼于语义相似性，忽略了法律推理必不可少的逻辑结构。在本文中，我们提出了逻辑语义集成模型（LSIM），这是一个桥梁语义和逻辑连贯性的新型监督框架。 LSIM包括三个组成部分：强化学习预测每个问题的结构化事实规则链，一个可训练的深层结构化语义模型（DSSM）通过整合语义和逻辑特征来检索最相关的候选问题，并且在逻辑上进行逻辑特征，并在内部上下文学习生成最终答案。检索的内容。我们对现实世界中法律质量检查数据集进行了实验，通过自动指标和人类评估证明，与现有方法相比，LSIM显着提高了准确性和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2502.07912</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将多语言嵌入模型调整为历史卢森堡</title>
      <link>https://arxiv.org/abs/2502.07938</link>
      <description><![CDATA[ARXIV：2502.07938V1公告类型：新 
摘要：数字化的历史文本的日益增长需要使用文本嵌入的有效语义搜索。但是，经过预先训练的多语言模型，通常对当代文本进行评估，由于OCR噪声和过时的拼写而面临历史数字化内容的挑战。我们探讨了多语言嵌入的使用，用于对历史卢森堡（Luxembourgish）的跨语义语义搜索，这是一种低资源语言。我们收集历史悠久的卢森堡新闻文章，这些新闻文章涵盖了各个时间段，并使用GPT-4O来细分并将其转化为密切相关的语言，从而创建了每种语言对的20,000个平行培训句子。我们进一步创建了一个历史性的bitext挖掘评估集，发现这些模型努力对历史卢森堡历史进行跨语性搜索。为了解决这个问题，我们提出了一种使用内域培训数据的简单适应方法，在跨语性评估中最多可实现98％的精度。我们发布了适应性的模型和历史卢克斯堡 - 德国/法语bitexts，以支持进一步的研究。]]></description>
      <guid>https://arxiv.org/abs/2502.07938</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>陷入文字网络中：LLM会在医学文献中旋转吗？</title>
      <link>https://arxiv.org/abs/2502.07963</link>
      <description><![CDATA[ARXIV：2502.07963V1公告类型：新 
摘要：医学研究在将新型治疗转化为临床实践方面面临着据可查的挑战。发表激励措施鼓励研究人员提出“积极”的发现，即使经验结果是模棱两可的。因此，有充分记录的作者经常旋转研究结果，尤其是在文章摘要中。这种旋转会影响临床医生对证据的解释，并可能影响患者护理决策。在这项研究中，我们询问大语模型（LLMS）对试验结果的解释是否受自旋的影响。这很重要，因为LLM越来越多地用于拖网并合成已发表的医学证据。我们评估了22个LLM，发现它们的整个局部比人更容易旋转。他们可能还会传播旋转到自己的输出中：我们发现证据，例如，LLMS隐式将旋转纳入它们产生的普通语言摘要中。但是，我们还发现LLM通常能够识别自旋，并且可以以一种减轻旋转对LLM输出的影响的方式提示。]]></description>
      <guid>https://arxiv.org/abs/2502.07963</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>培训专家的稀疏混合物文本嵌入模型</title>
      <link>https://arxiv.org/abs/2502.07972</link>
      <description><![CDATA[ARXIV：2502.07972V2公告类型：新 
摘要：基于变压器的文本嵌入模型通过增加其参数计数来改善其在Miracl和Beir等基准上的性能。但是，这种缩放方法引入了重大部署挑战，包括增加的推理潜伏期和内存使用情况。这些挑战在检索功能生成（RAG）应用中尤为严重，其中大型模型的增加内存需求限制了数据集的摄入能力，并且它们的较高延迟直接影响了查询时间的性能。尽管因果语言模型使用专家（MOE）体系结构解决了类似的效率挑战，但这种方法尚未成功适应一般文本嵌入设置。在本文中，我们介绍了NOMIC EMBED V2，这是第一个通用MOE文本嵌入模型。我们的模型在单语和多语言基准上都优于同一参数类中的模型，同时还可以维持其尺寸两倍的竞争性能。我们打开所有代码，模型和评估数据，以确保我们的培训管道完全可重复可重复，请{https://github.com/nomic-ai/contrastors} {https：//github.com/nomic-amic-aimic-ai aimic-ai ai aimic-ai ai aimic-ai ai aimic-ai ai。 /对比度}。]]></description>
      <guid>https://arxiv.org/abs/2502.07972</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Metasc：语言模型的测试时间安全规范优化</title>
      <link>https://arxiv.org/abs/2502.07985</link>
      <description><![CDATA[ARXIV：2502.07985V1公告类型：新 
摘要：我们提出了一个新型的动态安全框架，该框架在推理时间优化了语言模型（LM）安全推理，而无需修改模型权重。我们的方法以最新进展为基础，我们的方法利用了一种迭代的机制，该机制迭代地更新安全提示的规格，以推动批评和修订过程。该测试时间优化不仅可以提高针对对抗性越狱请求的绩效，还可以在与一般安全有关的任务中，例如避免道德伤害或追求诚实的回应。我们在几种语言模型上进行的经验评估表明，与固定系统提示和静态自我评价防御相比，动态优化的安全提示得出的安全得分明显更高。代码将在https://github.com/vicgalle/meta-self-critique.git上发布。]]></description>
      <guid>https://arxiv.org/abs/2502.07985</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提示的几何形状：在语言模型中揭示任务适应的不同机制</title>
      <link>https://arxiv.org/abs/2502.08009</link>
      <description><![CDATA[ARXIV：2502.08009V1公告类型：新 
摘要：仅解码器语言模型可以根据输入提示在各种计算任务之间动态切换。尽管有许多成功的提示应用，但对这种灵活性背后的内部机制的了解非常有限。在这项工作中，我们研究了不同的提示方法如何影响这些模型中表示的几何形状。我们采用以统计物理为基础的框架，揭示了各种提示技术在实现相似性能的同时，通过独特的代表机制进行任务适应。我们的分析强调了输入分布样本和标签语义在几次镜头中的关键作用。我们还展示了在表示层面上不同任务之间协同和干扰相互作用的证据。我们的工作有助于对大语言模型的理论理解，并为制定更有效的，表现意义的提示策略奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2502.08009</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推测，然后协作：在解码过程中融合语言模型的知识</title>
      <link>https://arxiv.org/abs/2502.08020</link>
      <description><![CDATA[ARXIV：2502.08020V1公告类型：新 
摘要：大型语言模型（LLM）通常在特定领域中表现出色，但由于培训的局限性而在其他领域中脱颖而出。因此，使LLM可以通过整合其互补知识来协作解决问题，这有望提高其跨领域的绩效。为了实现这一潜力，我们介绍了一种新颖的协作投机解码（COSD）算法，该算法在不需要其他模型培训的情况下在测试时间实现有效的LLM知识融合。 COSD采用草稿模型来生成初始序列和易于学习的规则或决策树，以决定何时调用助手模型以改善这些草稿。 COSD不仅可以增强知识融合，而且可以提高推理效率，可以在域和模型之间转移，并提供更大的解释性。实验结果表明，与现有方法相比，COSD的精度最多可提高10 \％，为基于LLM的应用提供了可扩展有效的解决方案]]></description>
      <guid>https://arxiv.org/abs/2502.08020</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>上下文的子空间歧管投影，用于大语模型表示的结构改进</title>
      <link>https://arxiv.org/abs/2502.08026</link>
      <description><![CDATA[ARXIV：2502.08026V1公告类型：新 
摘要：深度神经体系结构中的内部表示编码语言结构的高维抽象，但是它们经常在特征分布方面表现出效率低下，限制了表现力和适应性。上下文子空间歧管投影引入了一种结构化的改进技术，该技术通过受控子空间约束选择性地重新配置令牌嵌入，从而确保更稳定且几何定义明确的特征分布。经验评估表明，结构化干预措施降低了各向异性，从而改善了表示的紧凑性，同时保留了跨变压器层的语义忠诚度。聚类分析表明，令牌嵌入表现出更大的特征可分离性，从而增强了结构化投影技术增强内部表示组织而不牺牲语言相干性的假设。梯度幅度分布表明，该方法引入了更平稳的优化轨迹，有可能导致整个训练中更稳定的参数更新。与投影操作相关的计算开销仍然很少，从而确保精炼没有引入模型效率或推理速度的重大权衡。与标准嵌入精炼技术的比较强调了结构化的多种限制为改善表示质量的直接机制，而无需进行额外的基于梯度的优化。困惑评估证实，调整并没有对序列的连贯性产生负面影响，从而进一步验证了所提出的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.08026</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Franken-Adapter：通过嵌入手术对LLM的跨语性改编</title>
      <link>https://arxiv.org/abs/2502.08037</link>
      <description><![CDATA[ARXIV：2502.08037V1公告类型：新 
摘要：低资源语言的大语言模型（LLMS）的功能远远落后于英语，这使得其普遍的可访问性成为了重大挑战。为了减轻这一点，我们提出了$ \ textit {Franken-Adapter} $，这是一种仅解码LLM的模块化语言适应方法。我们的方法首先是为目标语言创建自定义的词汇，并通过嵌入多语言数据来执行语言适应性。这些预训练的嵌入随后与在英语对齐数据上进行了指导的LLM集成，以实现零摄像的跨语性转移。我们在$ \ texttt {gemma2} $模型上的实验最多显示了96种语言的高达20％的改进，涵盖了歧视性和生成性任务，英文回归（$ &lt;$ 1％）。进一步的深入分析揭示了定制引导者在增强语言适应性的同时提高推理效率的关键作用。此外，我们通过在20种语言中比数学优化的LLM提高了14％的方法来展示我们的方法的多功能性，从而提供了一个模块化解决方案，以转移跨HOC的语言传输推理能力。]]></description>
      <guid>https://arxiv.org/abs/2502.08037</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>打破复选框：LLMS中文化对齐的挑战性封闭式评估</title>
      <link>https://arxiv.org/abs/2502.08045</link>
      <description><![CDATA[ARXIV：2502.08045V1公告类型：新 
摘要：大量研究依靠封闭式多项选择调查来评估大语言模型（LLMS）中的文化一致性。在这项工作中，我们挑战了这一受限制的评估范式，并探索了更现实，不受约束的方法。使用世界价值调查（WVS）和霍夫斯泰德文化维度作为案例研究，我们证明了LLM在不强迫反应的情况下表现出更强的文化对准。此外，我们表明，即使是较小的变化，例如重新排序的调查选择，导致输出不一致，从而暴露了封​​闭式评估的局限性。我们的发现倡导更加健壮，更灵活的评估框架，这些框架专注于特定的文化代理，鼓励对LLM中的文化一致性进行更细微和准确的评估。]]></description>
      <guid>https://arxiv.org/abs/2502.08045</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于提取问题的机械电路</title>
      <link>https://arxiv.org/abs/2502.08059</link>
      <description><![CDATA[ARXIV：2502.08059V1公告类型：新 
摘要：大型语言模型越来越多地用于处理文档并促进对其进行提问。在我们的论文中，我们针对这种现实世界的语言建模任务提取机械电路：用于提取问题的上下文提问（QA）任务的上下文启动语言建模，并了解电路对下游应用程序的潜在好处，例如数据归因于上下文信息。我们使用因果中介分析技术提取电路作为内部模型组件（例如注意力头，MLP）的函数。利用提取的电路，我们首先了解模型的参数内存使用和检索上下文之间的相互作用，以对上下文授权语言模型有更好的机械理解。然后，我们确定电路中的一小部分注意力头，默认情况下执行可靠的数据归因，从而在模型的正向通行证中免费获得归因。然后，使用此见解，我们引入了Attnattrib，这是一种快速数据归因算法，该算法在各种提取QA基准中获得最新的归因结果。最后，我们展示了将语言模型引导到上下文回答的可能性，而不是通过将attnattrib的归因作为远期通过期间的附加信号来回答。除了机械理解之外，我们的论文还以可靠的数据归因和模型转向的形式提供了电路的切实应用。]]></description>
      <guid>https://arxiv.org/abs/2502.08059</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>显微镜下的NLI：什么原子假设分解揭示了</title>
      <link>https://arxiv.org/abs/2502.08080</link>
      <description><![CDATA[ARXIV：2502.08080V1公告类型：新 
摘要：将文本分解为原子命题是一个灵活的框架，可以仔细检查输入和输出文本。我们在两个自然语言推理任务（传统的NLI和不诚实的NLI）中使用假设的原子分解来形成原子亚问题，或者在解决整体问题时必须权衡模型的颗粒状推断。这些原子亚问题是一种工具，可以进一步了解NLI和不可避免的推理的结构，探测模型的一致性和对不同推论的理解，并衡量基准数据集中示例的多样性。我们的结果表明，LLMS仍在原子NLI和不可不稳定的NLI子问题上与逻辑一致性抗争。最后，我们确定了可de弱的NLI示例的关键原子亚问题，或最大程度贡献整体标签的示例，并提出了一种测量模型的推论一致性的方法，该度量是一种旨在捕获模型始终如一的程度的度量标准。在不同情况下，对相同事实的正确预测或不正确的预测。]]></description>
      <guid>https://arxiv.org/abs/2502.08080</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GCOT：经过经济链的及时学习图表</title>
      <link>https://arxiv.org/abs/2502.08092</link>
      <description><![CDATA[ARXIV：2502.08092V1公告类型：新 
摘要：经过思考链（COT）提示在自然语言处理（NLP）方面取得了巨大的成功。但是，它的巨大潜力在很大程度上尚未探索图形。这提出了一个有趣的问题：我们如何设计COT提示图形指导图形模型以逐步学习？一方面，与自然语言不同，图是非线性的，并以复杂的拓扑结构为特征。另一方面，许多图形缺乏文本数据，因此很难制定基于语言的COT提示。在这项工作中，我们提出了第一个针对无文本图的COT提示学习框架，GCOT。具体而言，我们将每个下游任务的适应过程分解为一系列推理步骤，每个步骤都包含基于及时的推理，``思想&#39;&#39;一代以及经过思考的及时学习。尽管步骤模仿了NLP中的COT，但确切的机制却显着不同。具体来说，在每个步骤中，输入图以及提示都首先被送入预先训练的图形编码器中以进行及时的推理。然后，我们将编码器的隐藏层汇总以构造``思想&#39;&#39;，该&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;在当前步骤中捕获了每个节点的工作状态。以这种想法为条件，我们根据当前状态学习了针对每个节点的提示。这些提示被馈入下一个推理步骤，重复周期。为了评估和分析GCOT的有效性，我们在八个公共数据集上进行了全面的实验，这证明了我们的方法的优势。]]></description>
      <guid>https://arxiv.org/abs/2502.08092</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Hudex：整合幻觉检测和解释性，以提高LLM响应的可靠性</title>
      <link>https://arxiv.org/abs/2502.08109</link>
      <description><![CDATA[ARXIV：2502.08109V1公告类型：新 
摘要：大型语言模型（LLMS）的最新进展已显示出令人鼓舞的改进，通常超过了自然语言处理中各种下游任务的现有方法。但是，这些模型仍然面临挑战，这可能会阻碍其实际的适用性。例如，已知幻觉现象会损害LLM的可靠性，尤其是在需要高度精确度的领域。当前的基准主要集中在幻觉检测和事实评估上，但并不能超出识别范围。本文提出了一个解释增强的幻觉检测模型，旨在通过检测幻觉和提供详细的解释来增强LLM生成的响应的可靠性。提出的模型提供了一种新颖的方法，可以将检测与解释整合在一起，并使用户和LLM本身都能理解和减少错误。我们的测量结果表明，在幻觉检测准确性中，提出的模型超过了较大的LLM，例如Llama3 70B和GPT-4，同时保持了可靠的解释。此外，所提出的模型在零射击和其他测试环境中都表现良好，从而在各种基准数据集中展示了其适应性。提出的方法通过引入一种将解释性与幻觉检测相结合的新方法，进一步增强了幻觉检测研究，从而进一步增强了评估语言模型中幻觉的性能和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2502.08109</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>