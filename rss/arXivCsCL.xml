<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 11 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>SemEval 2024 上的 JMI 任务 3：使用 GPT 和指令调整的 Llama 模型进行上下文学习的多模式 ECAC 两步法</title>
      <link>https://arxiv.org/abs/2403.04798</link>
      <description><![CDATA[arXiv:2403.04798v1 公告类型：新
摘要：本文介绍了我们针对 SemEval-2024 任务 3：“对话中多模态情感原因分析的竞赛”的系统开发。有效捕捉人类对话中的情感需要集成文本、音频和视频等多种模式。然而，这些不同模式的复杂性给开发高效的多模式情绪原因分析（ECA）系统带来了挑战。我们提出的方法通过两步框架解决这些挑战。我们在实施中采用两种不同的方法。在方法 1 中，我们采用两个独立的 Llama 2 模型的指令调整来进行情绪和原因预测。在方法 2 中，我们使用 GPT-4V 进行对话级视频描述，并使用 GPT 3.5 通过带注释的对话进行上下文学习。我们的系统获得了第四名，系统消融实验表明我们提出的解决方案实现了显着的性能提升。所有实验代码均可在Github上获取。]]></description>
      <guid>https://arxiv.org/abs/2403.04798</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>低资源语言的人工智能素养：在约鲁巴视频中创建人工智能的见解</title>
      <link>https://arxiv.org/abs/2403.04799</link>
      <description><![CDATA[arXiv:2403.04799v1 公告类型：新
摘要：为了有效驾驭人工智能革命，人工智能素养至关重要。然而，内容主要以主流语言存在，这给约鲁巴语（4100 万母语人士）等资源匮乏的语言造成了差距。本案例研究探索通过在约鲁巴语中创建和分发 AI 视频来弥合这一差距。该项目利用讲故事和易于理解的解释，开发了 26 个视频，涵盖基础、中级和高级 AI 概念。这些视频采用经济高效的方法制作，并在 YouTube、LinkedIn 和 Twitter 上发布，预计覆盖全球 22 个国家/地区的观众。对 YouTube 的分析揭示了对观看模式的深入了解，25-44 岁年龄段的观看次数最多。值得注意的是，超过一半的流量来自外部来源，凸显了跨平台推广的潜力。这项研究证明了用低资源语言创建人工智能素养内容的可行性和影响。它强调准确的口译既需要人工智能的技术专业知识，又需要流利的目标语言。这项工作提供了一种可复制的方法、22 个字的约鲁巴语人工智能词汇，以及对受众人口统计和获取渠道的数据驱动洞察]]></description>
      <guid>https://arxiv.org/abs/2403.04799</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>消防工程中的大型语言模型：根据领域知识检查技术问题</title>
      <link>https://arxiv.org/abs/2403.04795</link>
      <description><![CDATA[arXiv:2403.04795v1 公告类型：新
摘要：本次交流通过评估最近的两个聊天机器人（OpenAI 的 ChatGPT 和 Google 的 Bard）在消防工程背景下在处理消防安全相关查询时的响应，提出了比较的初步结果。创建并检查了各种消防工程问题和场景，包括结构消防设计、防火策略、疏散、建筑规范合规性和灭火系统（其中一些类似于消防考试（FPE）中常见的问题和场景） 。结果揭示了聊天机器人性能的一些关键差异，其中 ChatGPT 表现出相对优越的性能。然后，本次交流强调了聊天机器人技术通过提供对关键信息的即时访问，同时概述了需要进一步改进和研究的领域，从而彻底改变消防工程实践的潜力。显然，当这项技术成熟时，它可能会成为我们工程师的实践和教育的基础。]]></description>
      <guid>https://arxiv.org/abs/2403.04795</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>中间发现：语言模型如何通过即插即用位置编码更好地使用长上下文</title>
      <link>https://arxiv.org/abs/2403.04797</link>
      <description><![CDATA[arXiv:2403.04797v1 公告类型：新
摘要：本文旨在克服大型语言模型（LLM）的“迷失在中间”的挑战。虽然最近的进展已成功使法学硕士能够使用多达 400 万个标记执行稳定的语言建模，但大多数法学硕士在识别位于上下文中间的相关信息方面所面临的持续困难尚未得到充分解决。为了解决这个问题，本文引入了多尺度位置编码（Ms-PoE），这是一种简单而有效的即插即用方法，可以增强 LLM 处理位于上下文中间的相关信息的能力，而无需微调或引入任何额外的开销。 Ms-PoE 利用位置指数重新缩放来缓解 RoPE 引入的长期衰减效应，同时精心地将不同的缩放比例分配给不同的注意力头，以保留在预训练步骤中学到的基本知识，形成多尺度上下文融合短距离到长距离。对各种法学硕士进行的广泛实验证明了我们方法的有效性。值得注意的是，与原始法学硕士相比，Ms-PoE 在零滚动基准测试中的平均准确度提高了 3.8。代码可在 https://github.com/VITA-Group/Ms-PoE 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.04797</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型在线训练：边聊天边学习</title>
      <link>https://arxiv.org/abs/2403.04790</link>
      <description><![CDATA[arXiv:2403.04790v1 公告类型：新
摘要：大型语言模型（LLM）极大地改变了自然语言处理（NLP）领域，提供了广泛使用的卓越功能。然而，法学硕士和用户之间现有的交互范式要么缺乏灵活性，要么定制化有限，要么缺乏持续学习。当用户（尤其是那些没有编程技能的用户）增强或个性化模型的途径受到限制时，这种不灵活性尤其明显。由于计算效率低下且缺乏用户友好的界面，现有框架使模型训练和部署过程进一步复杂化。为了克服这些挑战，本文引入了一种新颖的交互范式——“使用外部交互的在线训练”——它将持久、实时模型更新的优点与通过外部交互（例如人工智能代理或在线/离线）进行个性化定制的灵活性结合在一起知识库。]]></description>
      <guid>https://arxiv.org/abs/2403.04790</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士与律师：在英国大型判例法数据集中识别简易判决的子集</title>
      <link>https://arxiv.org/abs/2403.04791</link>
      <description><![CDATA[arXiv:2403.04791v1 公告类型：新
摘要：为了进行法律的计算研究，有效识别与特​​定法律问题相关的法院判决数据集是一项至关重要但具有挑战性的工作。这项研究解决了与大型法律语料库合作的文献中关于如何将案件（在我们的案件简易判决中）与英国法院判决的大型语料库分离出来的空白。我们介绍了两种计算方法的比较分析：(1) 基于传统自然语言处理的方法，利用专家生成的关键字和逻辑运算符；(2) Claude 2 大语言模型的创新应用，根据内容对案例进行分类具体提示。我们使用包含 356,011 个英国法院判决的剑桥法律语料库，并确定大型语言模型的加权 F1 分数为 0.94，而关键字的加权 F1 分数为 0.78。尽管进行了迭代细化，基于关键字的搜索逻辑仍无法捕捉法律语言中的细微差别。我们识别并提取了 3,102 个简易判决案件，使我们能够绘制它们在一段时间内在英国各个法院的分布情况。该论文标志着采用先进的自然语言处理来解决核心法律研究任务的开创性一步，展示了这些技术如何弥合系统性差距并提高法律信息的可访问性。我们共享提取的数据集指标以支持对总结判断的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2403.04791</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>打破语言障碍：在多语言法学硕士申请中，直接推理能否优于预翻译？</title>
      <link>https://arxiv.org/abs/2403.04792</link>
      <description><![CDATA[arXiv:2403.04792v1 公告类型：新
摘要：大型语言模型在多语言应用中具有重大前景。然而，主要以英语为中心的预训练所产生的固有偏差导致了预翻译的广泛实践，即在推理之前将非英语输入翻译成英语，从而导致复杂性和信息丢失。这项研究重新评估了 PaLM2 模型（Anil 等人，2023）背景下预翻译的需求，该模型已被证明在多语言任务中具有高性能。我们提供了针对 108 种语言和 6 个不同基准的全面调查，包括开放式生成任务，这些任务被排除在之前的类似研究之外。我们的研究结果挑战了先前研究中建立的预翻译范式，强调了 PaLM2 中直接推理的优势。具体来说，PaLM2-L 在 108 种语言中的 94 种中始终优于预翻译。这些发现为更高效和有效的多语言应用铺平了道路，减轻了与预翻译相关的限制并释放了语言的真实性。]]></description>
      <guid>https://arxiv.org/abs/2403.04792</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>通过融合和提炼过去来不断发展的记忆</title>
      <link>https://arxiv.org/abs/2403.04787</link>
      <description><![CDATA[arXiv:2403.04787v1 公告类型：新
摘要：对于类人聊天机器人来说，构建长期记忆至关重要。一种幼稚的记忆方法可能是简单地列出总结的对话。然而，当说话者的状态随着时间的推移而变化并且矛盾的信息积累时，这可能会导致问题。重要的是，记忆保持井井有条，以减少响应生成器的混乱。在本文中，我们提出了一种用于长期对话的新颖记忆方案 CREEM。与仅基于当前会话构建记忆的现有方法不同，我们提出的模型在记忆形成过程中混合了过去的记忆。此外，我们引入精炼流程来处理冗余或过时的信息。这种创新方法通过确保更明智和动态发展的长期记忆来寻求聊天机器人响应的整体改进和一致性。]]></description>
      <guid>https://arxiv.org/abs/2403.04787</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>航空事故报告主题建模分析：LDA与NMF模型对比研究</title>
      <link>https://arxiv.org/abs/2403.04788</link>
      <description><![CDATA[arXiv:2403.04788v1 公告类型：新
摘要：航空安全在现代世界中至关重要，不断致力于减少事故和提高安全标准。这项工作的核心是对航空事故报告的分析，这些丰富的文本资源可以深入了解航空事故背后的原因和影响因素。本文在航空事故报告分析的背景下比较了两种著名的主题建模技术：潜在狄利克雷分配 (LDA) 和非负矩阵分解 (NMF)。该研究利用国家运输安全委员会 (NTSB) 数据集，其主要目标是自动化和简化识别事故报告中潜在主题和模式的过程。连贯性值 (C_v) 指标用于评估生成主题的质量。 LDA 表现出更高的主题连贯性，表明主题内单词之间更强的语义相关性。与此同时，NMF 擅长提出独特且细致的主题，从而能够对航空事故的具体方面进行更有针对性的分析。]]></description>
      <guid>https://arxiv.org/abs/2403.04788</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>TopicDiff：用于多模态会话情绪检测的主题丰富扩散方法</title>
      <link>https://arxiv.org/abs/2403.04789</link>
      <description><![CDATA[arXiv:2403.04789v1 公告类型：新
摘要：多模态会话情感（MCE）检测通常跨越声学、视觉和语言模态，引起了多媒体社区越来越多的兴趣。以往的研究主要集中在学习对话中的上下文信息，只有少数考虑单一语言模态的主题信息，而总是忽略听觉和视觉主题信息。在此基础上，我们提出了一种与模型无关的主题丰富扩散（TopicDiff）方法，用于捕获 MCE 任务中的多模态主题信息。特别是，我们将扩散模型集成到神经主题模型中，以缓解神经主题模型在捕获主题信息时的多样性不足问题。详细的评估表明 TopicDiff 相对于最先进的 MCE 基线有显着改进，证明了多模态主题信息对 MCE 的重要性以及 TopicDiff 在捕获此类信息方面的有效性。此外，我们观察到一个有趣的发现，即与语言相比，声学和视觉中的主题信息更具辨别力和鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2403.04789</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>时态知识图综述：表示学习及其应用</title>
      <link>https://arxiv.org/abs/2403.04782</link>
      <description><![CDATA[arXiv:2403.04782v1 公告类型：新
摘要：知识图谱引起了广泛的研究关注，并被广泛用于增强下游应用。然而，目前大多数研究主要集中在静态知识图谱上，其事实不随时间变化，而忽视了它们随时间的动态演化。因此，时间知识图引起了更多的关注，因为大量的结构化知识只存在于特定的时期内。知识图表示学习旨在学习知识图中实体和关系的低维向量嵌入。时态知识图的表示学习将时间信息纳入标准知识图框架中，可以对实体和关系随时间的动态进行建模。在本文中，我们对时间知识图表示学习及其应用进行了全面的调查。我们首先介绍时态知识图表示学习的定义、数据集和评估指标。接下来，我们提出了一种基于时间知识图谱表示学习方法核心技术的分类法，并对每个类别中的不同方法进行了深入分析。最后，我们提出了与时间知识图相关的各种下游应用。最后我们对全文进行了总结并对这一领域未来的研究方向进行了展望。]]></description>
      <guid>https://arxiv.org/abs/2403.04782</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 EHR 数据进行 5 年慢性病队列预测的大语言多模态模型</title>
      <link>https://arxiv.org/abs/2403.04785</link>
      <description><![CDATA[arXiv:2403.04785v1 公告类型：新
【摘要】：糖尿病等慢性病是全球发病率和死亡率的主要原因。人们在诊断中尝试了各种深度学习模型的大量研究。然而，之前的大多数研究都有一定的局限性，包括使用公开的数据集（例如 MIMIC）和不平衡的数据。在这项研究中，我们从台湾医院数据库中收集了五年的电子健康记录（EHR），包括1,420,596条临床记录、387,392条实验室检查结果和超过1,505个实验室检查项目，重点研究预训练大语言模型。我们提出了一种新颖的大语言多模态模型（LLMM）框架，该框架结合了来自临床记录和实验室测试结果的多模态数据，用于预测慢性病风险。我们的方法结合了文本嵌入编码器和多头注意力层来学习实验室测试值，利用深度神经网络（DNN）模块将血液特征与慢性疾病语义合并到潜在空间中。在我们的实验中，我们观察到，clinicalBERT 和 PubMed-BERT 与注意力融合相结合，在多类慢性病和糖尿病预测中可以达到 73% 的准确率。通过将实验室测试值转换为文本描述并采用 Flan T-5 模型，我们实现了 76% 的 ROC 曲线下面积 (AUROC)，证明了利用数字文本数据进行语言模型训练和推理的有效性。这种方法显着提高了早期糖尿病预测的准确性。]]></description>
      <guid>https://arxiv.org/abs/2403.04785</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>QASE 增强型 PLM：改进 MRC 文本生成的控制</title>
      <link>https://arxiv.org/abs/2403.04771</link>
      <description><![CDATA[arXiv:2403.04771v1 公告类型：新
摘要：为了解决机器阅读理解（MRC）生成模型中生成失控的挑战，我们引入了问题参与跨度提取（QASE）模块。 QASE 在预训练生成语言模型 (PLM) 的微调过程中进行集成，使这些 PLM 能够匹配 SOTA 提取方法，并在 MRC 任务中优于 GPT-4 等领先的 LLM，而不会显着增加计算成本。]]></description>
      <guid>https://arxiv.org/abs/2403.04771</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>MuseGraph：用于通用图挖掘的大型语言模型的面向图的指令调优</title>
      <link>https://arxiv.org/abs/2403.04780</link>
      <description><![CDATA[arXiv:2403.04780v1 公告类型：新
摘要：具有丰富属性的图对于互连实体建模和改进各种现实应用中的预测至关重要。传统的图神经网络（GNN）通常用于建模属性图，每次应用于不同的图任务和数据集时都需要重新训练。尽管大型语言模型（LLM）的出现引入了自然语言处理的新范式，但 LLM 在图挖掘中的生成潜力在很大程度上仍未得到充分开发。为此，我们提出了一种新颖的框架 MuseGraph，它无缝地集成了 GNN 和 LLM 的优势，并为跨不同任务和数据集的图挖掘提供了更有效和通用的方法。具体来说，我们首先通过所提出的自适应输入生成引入紧凑的图描述，以在语言标记限制的约束下封装图中的关键信息。然后，我们提出了一种多样化的指令生成机制，该机制从 LLM（例如 GPT-4）中提炼推理能力，为不同的图形任务创建特定于任务的基于思想链的指令包。最后，我们提出了一种图形感知指令调优，具有跨任务和数据集的动态指令包分配策略，确保训练过程的有效性和泛化性。我们的实验结果证明了不同图形任务的显着改进，展示了我们的 MuseGraph 在提高面向图形的下游任务的准确性方面的潜力，同时保持了 LLM 的生成能力。]]></description>
      <guid>https://arxiv.org/abs/2403.04780</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>社会取向：对话分析的新特征</title>
      <link>https://arxiv.org/abs/2403.04770</link>
      <description><![CDATA[arXiv:2403.04770v1 公告类型：新
摘要：在许多情况下，预测和解释对话的成功或失败很有用。心理学中的迂回理论对对话参与者的社会取向（例如，热情好客、傲慢精算）进行了建模，可用于预测和解释社交互动的结果。我们的工作的新颖之处在于系统地应用社交取向标签来建模对话结果。在本文中，我们介绍了一个新的对话话语数据集，机器标记有社交取向标签。我们表明，在英语和中文语言基准上，社交取向标签可以提高任务绩效，尤其是在资源匮乏的环境中。我们还演示了社交取向标签在神经模型中使用时如何帮助解释社交互动的结果。基于这些显示社交取向标签在对话结果预测任务中的实用性的结果，我们发布了经过微调的数据集、代码和模型，以预测对话话语中的社交取向标签。]]></description>
      <guid>https://arxiv.org/abs/2403.04770</guid>
      <pubDate>Mon, 11 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    </channel>
</rss>