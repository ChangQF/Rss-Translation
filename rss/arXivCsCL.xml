<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 19 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>具有关系解开的多方响应生成</title>
      <link>https://arxiv.org/abs/2403.10827</link>
      <description><![CDATA[arXiv:2403.10827v1 公告类型：新
摘要：现有的神经响应生成模型在两方对话方面取得了令人印象深刻的改进，该模型假设话语是按顺序组织的。然而，许多现实世界的对话涉及多个对话者，并且对话上下文的结构要复杂得多，例如不同对话者的话语可以“并行”发生。面对这一挑战，有些工作试图对话语或对话者之间的关系进行建模，以促进在更清晰的上下文中生成响应。尽管如此，这些方法严重依赖于这种关系，并且都假设这些关系是预先给定的，这是不切实际的并且阻碍了此类方法的通用性。在这项工作中，我们建议通过关系思维对对话上下文中的微妙线索自动推断关系，而无需任何人类标签，并利用这些关系来指导神经响应的生成。具体来说，我们首先应用深度图随机过程来充分考虑对话上下文中话语之间的所有可能关系。然后将推断的关系图与变分自动编码器框架集成，以训练 GAN 来生成结构感知响应。 Ubuntu Internet Relay Chat (IRC) 通道基准测试和最新的 Movie Dialogues 的实验结果表明，我们的方法优于多方响应生成的各种基线模型。]]></description>
      <guid>https://arxiv.org/abs/2403.10827</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>利用自适应估计融合对大型语言模型进行高效剪枝</title>
      <link>https://arxiv.org/abs/2403.10799</link>
      <description><![CDATA[arXiv:2403.10799v1 公告类型：新
摘要：大型语言模型（LLM）对于许多生成性下游任务至关重要，这导致了在资源受限的设备上有效部署它们的必然趋势和重大挑战。结构化修剪是解决这一挑战的广泛使用的方法。然而，当处理多个解码器层的复杂结构时，一般方法通常采用常见的估计方法进行剪枝。这些方法会导致特定下游任务的准确性下降。在本文中，我们介绍了一种简单而有效的方法，可以自适应地对每个子结构的重要性进行建模。同时，它可以根据复杂和多层结构的结果自适应地融合粗粒度和细粒度估计。我们设计的所有方面都无缝集成到端到端修剪框架中。与主流数据集上最先进的方法相比，我们的实验结果表明 LLaMa-7B、Vicuna-7B、Baichuan-7B 和 Bloom 的平均准确度提高了 1.1%、1.02%、2.0% 和 1.2%分别为-7b1。]]></description>
      <guid>https://arxiv.org/abs/2403.10799</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型能够理解医疗代码吗？</title>
      <link>https://arxiv.org/abs/2403.10822</link>
      <description><![CDATA[arXiv:2403.10822v1 公告类型：新
摘要：近期人工智能研究的总体目标是在实现通用人工智能（AGI）方面取得稳步进展，促进跨各种任务和领域的大型语言模型（LLM）的评估。其中一个领域是医疗保健，法学硕士可以通过协助完成广泛的任务来极大地有益于临床实践。然而，当面对它们无法充分解决的问题时，这些模型也容易产生“幻觉”或不正确的反应，从而引起担忧和怀疑，尤其是在医疗保健界。因此，在这项工作中，我们调查法学硕士是否理解医疗保健实践中广泛使用的医疗代码的内在含义。我们评估各种现成的法学硕士（例如 GPT、LLaMA 等）和专门为生物医学应用设计的法学硕士，以评估他们对这些特定领域术语的认识和理解。我们的结果表明，这些模型不理解医疗代码的含义，这凸显了需要更好地表示这些在医疗保健中广泛使用的字母数字代码。我们呼吁改进策略，以有效捕捉和表达法学硕士内医学规范和术语的细微差别，使它们成为医疗保健专业人员更可靠和值得信赖的工具。]]></description>
      <guid>https://arxiv.org/abs/2403.10822</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士对话式人工智能治疗师通过日常智能设备进行日常功能筛查和心理治疗干预</title>
      <link>https://arxiv.org/abs/2403.10779</link>
      <description><![CDATA[arXiv:2403.10779v1 公告类型：新
摘要：尽管存在全球精神健康危机，但获得筛查、专业人员和治疗的机会仍然很高。我们与有执照的心理治疗师合作，提出了一种具有心理治疗干预功能的对话式人工智能治疗师 (CaiTI)，这是一个利用大语言模型 (LLM) 和智能设备来实现更好的心理健康自我护理的平台。 CaiTI 可以使用自然和心理治疗对话来筛选日常功能。 CaiTI 利用强化学习来提供个性化的对话流程。 CaiTI能够准确理解和解读用户的反应。当用户在对话过程中需要进一步关注时，CaiTI可以提供对话心理治疗干预，包括认知行为治疗（CBT）和动机访谈（MI）。利用持证心理治疗师准备的数据集，我们对各种法学硕士在 CaiTI 对话流程中的任务表现进行实验和微基准测试，并讨论他们的优点和缺点。我们与心理治疗师一起实施 CaiTI 并进行为期 14 天和 24 周的研究。研究结果经治疗师验证，表明CaiTI可以与用户自然地交谈，准确理解和解释用户的反应，并提供适当有效的心理治疗干预。我们展示了 CaiTI 法学硕士在协助心理治疗诊断和治疗以及改善日常功能筛查和预防性心理治疗干预系统方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.10779</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>探索中国幽默的产生：两部分寓言的研究</title>
      <link>https://arxiv.org/abs/2403.10781</link>
      <description><![CDATA[arXiv:2403.10781v1 公告类型：新
摘要：幽默是人类语言中文化上微妙的一个方面，对计算理解和生成提出了挑战，尤其是中文幽默，这在 NLP 社区中仍然相对未经探索。本文研究了最先进的语言模型理解和生成中国幽默的能力，特别侧重于训练它们创造寓言谚语。我们采用两种著名的训练方法：微调中型语言模型和提示大型语言模型。我们新颖的微调方法结合了融合拼音嵌入来考虑同音词，并采用对比学习和合成硬底片来区分幽默元素。人工注释的结果表明，这些模型可以生成幽默的寓言谚语，并提示被证明是一种实用且有效的方法。然而，在生成与人类创造力相匹配的寓言谚语方面仍有改进的空间。]]></description>
      <guid>https://arxiv.org/abs/2403.10781</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>从单词到路线：将大型语言模型应用于车辆路由</title>
      <link>https://arxiv.org/abs/2403.10795</link>
      <description><![CDATA[arXiv:2403.10795v1 公告类型：新
摘要：法学硕士在自然语言任务描述的机器人技术（例如操纵和导航）方面取得了令人瞩目的进展。法学硕士在这些任务中的成功让我们想知道：法学硕士用自然语言任务描述解决车辆路径问题（VRP）的能力如何？在这项工作中，我们分三个步骤研究这个问题。首先，我们构建了一个包含 21 种单车或多车路径问题的数据集。其次，我们评估了法学硕士在文本到代码生成的四种基本提示范例中的表现，每种范例都涉及不同类型的文本输入。我们发现直接从自然语言任务描述生成代码的基本提示范式在 GPT-4 中表现最佳，实现了 56% 的可行性、40% 的最优性和 53% 的效率。第三，基于LLMs可能无法在初次尝试时提供正确解决方案的观察，我们提出了一个框架，使LLMs能够通过自我反思（包括自我调试和自我验证）来完善解决方案。通过 GPT-4，我们提出的框架实现了可行性提高 16%、优化性提高 7%、效率提高 15%。此外，我们检查了 GPT-4 对任务描述的敏感性，特别关注当任务描述中省略某些细节但保留核心含义时，其性能如何变化。我们的研究结果表明，此类遗漏会导致性能显着下降：可行性下降 4%，最优性下降 4%，效率下降 5%。网站：https://sites.google.com/view/words-to-routes/]]></description>
      <guid>https://arxiv.org/abs/2403.10795</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>规则仍然适用于开放信息提取</title>
      <link>https://arxiv.org/abs/2403.10758</link>
      <description><![CDATA[arXiv:2403.10758v1 公告类型：新
摘要：开放信息提取（OIE）旨在从自然语言文本中提取表面关系及其相应的参数，而不考虑领域。本文提出了一种专为中文文本量身定制的创新 OIE 模型 APRCOIE。与以前的模型不同，我们的模型自主生成提取模式。该模型为中国 OIE 定义了一种新的模式形式，并提出了一种自动模式生成方法。这样，该模型就可以处理各种复杂多样的汉语语法现象。我们设计了一个基于张量计算的初步滤波器，以有效地进行提取过程。为了训练模型，我们手动注释了大型中国 OIE 数据集。在比较评估中，我们证明 APRCOIE 优于中国最先进的 OIE 模型，并显着扩展了 OIE 可实现的绩效范围。 APRCOIE的代码和带注释的数据集发布在GitHub上（https://github.com/jialin666/APRCOIE_v1）]]></description>
      <guid>https://arxiv.org/abs/2403.10758</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>ECRC：GCN 韩语对话中的情感因果关系识别</title>
      <link>https://arxiv.org/abs/2403.10764</link>
      <description><![CDATA[arXiv:2403.10764v1 公告类型：新
摘要：在这项关于在对话环境中同时分析情绪及其根本原因的多任务学习研究中，采用深度神经网络方法来有效处理和训练大型标记数据集。然而，这些方法通常仅限于在整个语料库中进行上下文分析，因为它们依赖于两种方法之一：单词或句子级嵌入。前者与多义词和同音异义词作斗争，而后者在处理长句子时会导致信息丢失。在这项研究中，我们通过利用单词级和句子级嵌入来克服以前嵌入的局限性。此外，我们提出了对话中的情感因果关系识别（ECRC）模型，该模型基于新颖的图结构，从而利用了两种嵌入方法的优点。该模型独特地集成了双向长短期记忆（Bi-LSTM）和图神经网络（GCN）模型，用于韩语对话分析。与仅依赖一种嵌入方法的模型相比，所提出的模型有效地构造了抽象概念，例如语言特征和关系，从而最大限度地减少了信息损失。为了评估模型性能，我们比较了具有不同图结构的三个深度神经网络模型的多任务学习结果。此外，我们使用韩语和英语数据集评估了所提出的模型。实验结果表明，当将节点和边特征纳入图结构时，所提出的模型在情感和因果多任务学习中表现更好（分别为74.62％和75.30％）。韩国 ECC 和 Wellness 数据集也记录了类似的结果（分别为 74.62% 和 73.44%），IEMOCAP 英语数据集为 71.35%。]]></description>
      <guid>https://arxiv.org/abs/2403.10764</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>检测大型语言模型中的偏差：微调 KcBERT</title>
      <link>https://arxiv.org/abs/2403.10774</link>
      <description><![CDATA[arXiv:2403.10774v1 公告类型：新
摘要：大语言模型（LLM）的快速发展使得自然语言处理能力与人类相似，并且 LLM 正在教育和医疗保健等各个社会领域得到广泛应用。虽然这些模型的多功能性有所增加，但它们有可能产生主观和规范性语言，导致社会群体之间的歧视性待遇或结果，特别是由于网络攻击性语言。在本文中，我们将此类危害定义为社会偏见，并在一个模型中评估种族、性别和种族偏见，该模型使用 Transformers 双向编码器表示 (KcBERT) 和 KOLD 数据通过基于模板的掩码语言模型 (MLM) 与韩国评论进行微调）。为了定量评估偏差，我们采用 LPBS 和 CBS 指标。与 KcBERT 相比，微调模型显示种族偏见有所减少，但性别和种族偏见发生了显着变化。根据这些结果，我们提出了两种减轻社会偏见的方法。首先，预训练阶段的数据平衡方法通过对齐特定单词出现的分布并将周围的有害单词转换为无害单词来调整数据的均匀性。其次，在训练阶段，我们通过调整 dropout 和正则化来应用去偏正则化，确认训练损失的减少。我们的贡献在于证明由于语言依赖的特征，韩语语言模型中存在社会偏见。]]></description>
      <guid>https://arxiv.org/abs/2403.10774</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>通过整合法学硕士揭示社交媒体消息传递的潜在主题：气候运动案例研究</title>
      <link>https://arxiv.org/abs/2403.10707</link>
      <description><![CDATA[arXiv:2403.10707v1 公告类型：新
摘要：本文介绍了一种发现和分析社交媒体消息传递主题的新颖方法。认识到传统主题级分析往往仅捕获总体模式的局限性，本研究强调需要进行更细粒度、以主题为中心的探索。传统的主题发现方法（涉及手动流程和人机交互方法）很有价值，但在时间和成本方面面临可扩展性、一致性和资源强度方面的挑战。为了应对这些挑战，我们提出了一种机器在环方法，该方法利用大型语言模型 (LLM) 的高级功能。这种方法可以更深入地调查社交媒体话语的主题方面，使我们能够发现各种不同的主题，每个主题都具有独特的特征和相关性，从而全面了解更广泛主题中存在的细微差别。此外，这种方法有效地映射了文本和新发现的主题，增强了我们对社交媒体消息传递中主题细微差别的理解。我们采用气候活动作为案例研究，并证明与传统主题模型相比，我们的方法可以产生更准确和可解释的结果。我们的结果不仅证明了我们的方法在发现潜在主题方面的有效性，而且还阐明了如何针对社交媒体环境中的人口目标定制这些主题。此外，我们的工作揭示了社交媒体的动态本质，揭示了针对现实世界事件的消息传递主题焦点的变化。]]></description>
      <guid>https://arxiv.org/abs/2403.10707</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型对社交媒体进行抑郁症检测</title>
      <link>https://arxiv.org/abs/2403.10750</link>
      <description><![CDATA[arXiv:2403.10750v1 公告类型：新
摘要：抑郁症的危害。然而，由于缺乏心理健康意识和害怕耻辱，许多患者不积极寻求诊断和治疗，导致不良后果。抑郁症检测旨在通过分析一个人在社交媒体上的帖子历史来确定一个人是否患有抑郁症，这对早期发现和干预有很大帮助。它主要面临两个关键挑战：1）需要专业的医学知识，2）需要高精度和可解释性。为了解决这个问题，我们提出了一种名为 DORIS 的新型抑郁症检测系统，该系统结合了医学知识和大语言模型 (LLM) 的最新进展。具体来说，为了解决第一个挑战，我们提出了一种基于LLM的解决方案，首先注释高风险文本是否符合医学诊断标准。此外，我们检索情绪强度高的文本，并从用户的历史情绪记录中总结关键信息，即所谓的情绪课程。为了解决第二个挑战，我们将LLM和传统分类器结合起来，整合医学知识引导的特征，模型也可以解释其预测结果，实现高精度和可解释性。在基准数据集上的大量实验结果表明，与当前最佳基线相比，我们的方法在 AUPRC 中提高了 0.036，这可以认为是显着的，证明了我们方法的有效性及其作为 NLP 应用的高价值。]]></description>
      <guid>https://arxiv.org/abs/2403.10750</guid>
      <pubDate>Tue, 19 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>MYTE：形态驱动的字节编码，用于更好、更公平的多语言语言建模</title>
      <link>https://arxiv.org/abs/2403.10691</link>
      <description><![CDATA[arXiv:2403.10691v1 公告类型：新
摘要：多语言语言建模的一个主要考虑因素是如何最好地表示具有不同词汇和脚本的语言。尽管当代文本编码方法涵盖了世界上大多数书写系统，但它们对全球西方的高资源语言表现出偏见。因此，代表性不足的语言的文本往往被分割成语言上无意义的单元的长序列。为了解决这种差异，我们引入了一种新的范式，该范式可以跨不同语言使用大小一致的片段对相同的信息进行编码。我们的编码约定（MYTE）基于语素，因为它们的库存在不同语言之间比以前方法中使用的字符更加平衡。我们表明，MYTE 为所有 99 种分析语言生成了更短的编码，其中对于非欧洲语言和非拉丁文字的改进最为显着。这反过来又提高了多语言 LM 的性能，并缩小了不同语言之间的困惑差距。]]></description>
      <guid>https://arxiv.org/abs/2403.10691</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>EXPLORER：文本强化学习的探索引导推理</title>
      <link>https://arxiv.org/abs/2403.10692</link>
      <description><![CDATA[arXiv:2403.10692v1 公告类型：新
摘要：基于文本的游戏（TBG）已成为 NLP 任务的重要集合，要求强化学习（RL）代理将自然语言理解与推理结合起来。对于尝试解决此类任务的代理来说，一个关键挑战是在多个游戏中进行泛化，并在可见和不可见的对象上展示良好的性能。纯粹基于深度强化学习的方法可能在所见物体上表现良好；然而，他们未能在看不见的物体上展示出相同的性能。注入常​​识的深度强化学习代理可能在看不见的数据上表现得更好；不幸的是，他们的政策往往难以解释或轻易转移。为了解决这些问题，在本文中，我们提出了 EXPLORER，它是一种用于文本强化学习的探索引导推理代理。 EXPLORER 本质上是神经符号的，因为它依赖于神经模块进行探索和符号模块进行利用。它还可以学习广义的符号策略，并在未见过的数据上表现良好。我们的实验表明，EXPLORER 在文本世界烹饪 (TW-Cooking) 和文本世界常识 (TWC) 游戏上的表现优于基线代理。]]></description>
      <guid>https://arxiv.org/abs/2403.10692</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>探讨性别偏见的多语言视角</title>
      <link>https://arxiv.org/abs/2403.10699</link>
      <description><![CDATA[arXiv:2403.10699v1 公告类型：新
摘要：性别偏见代表了一种基于性别针对个人的系统性负面治疗形式。这种歧视的范围可以从微妙的性别歧视言论和性别刻板印象到公然的仇恨言论。先前的研究表明，忽视网络虐待不仅会影响目标个人，还会产生更广泛的社会影响。这些后果阻碍了妇女在公共领域的参与和知名度，从而加剧了性别不平等。本论文研究了性别偏见如何通过语言和语言技术表达的细微差别。值得注意的是，本文将性别偏见的研究扩展到多语言背景，强调多语言和多文化视角在理解社会偏见方面的重要性。在这篇论文中，我采用跨学科的方法，将自然语言处理与政治学和历史学等其他学科联系起来，探讨自然语言和语言模型中的性别偏见。]]></description>
      <guid>https://arxiv.org/abs/2403.10699</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>神经侵蚀：在人工智能系统中模拟受控的神经退行性变和衰老</title>
      <link>https://arxiv.org/abs/2403.10596</link>
      <description><![CDATA[arXiv:2403.10596v1 公告类型：新
摘要：创建受控方法来模拟人工智能（AI）中的神经退行性疾病对于模拟大脑功能衰退和认知障碍的应用至关重要。我们使用大型语言模型 (LLM) 执行的 IQ 测试，更具体地说，LLaMA 2 来引入“神经侵蚀”的概念。这种故意侵蚀涉及消融突触或神经元，或者在训练期间或之后添加高斯噪声，从而导致法学硕士的表现有控制地进行性下降。我们能够描述智商测试中的神经退行性变，并表明法学硕士首先失去了数学能力，然后失去了语言能力，同时进一步失去了理解问题的能力。据我们所知，与计算机视觉领域的其他工作相比，这是第一个用文本数据模拟神经退行性变的工作。最后，我们的研究与涉及测试对象的认知衰退临床研究之间存在相似之处。我们发现，在神经退行性方法的应用中，法学硕士失去了抽象思维能力，随后是数学退化，最终失去了语言能力，对提示的反应不连贯。这些发现与人类研究一致。]]></description>
      <guid>https://arxiv.org/abs/2403.10596</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:58 GMT</pubDate>
    </item>
    </channel>
</rss>