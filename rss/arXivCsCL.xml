<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 31 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>榆树：从病理报告中预测肿瘤组的语言模型合奏</title>
      <link>https://arxiv.org/abs/2503.21800</link>
      <description><![CDATA[ARXIV：2503.21800V1公告类型：新 
摘要：基于人群的癌症注册表（PBCRS）在手动从非结构化病理报告中提取数据时面临着重要的瓶颈，这是诸如肿瘤组分配等任务至关重要的过程，该任务可以消耗900个人小时的时间，以供大约100,000个报告。为了解决这个问题，我们介绍了ELM（语言模型的集合），这是一种基于新颖的集合方法，利用小语言模型（SLM）和大语言模型（LLMS）。 Elm使用了六个微型SLM，其中三个SLM使用病理报告的顶部，三个SLM使用底部。这样做是为了最大程度地提高报告覆盖范围。 ELM需要进行五分之一的肿瘤组分类一致。分歧是由LLM和经过精心策划的提示进行仲裁的。我们在十九个肿瘤组中进行的评估表明，ELM的平均精度和回忆为0.94，表现优于单模型和合奏 - 无数方法。 ELM部署在不列颠哥伦比亚省癌症注册表中，展示了如何成功地应用于PBCR环境中的LLM，以实现最先进的结果并显着提高了运营效率，从而节省了数百人小时。]]></description>
      <guid>https://arxiv.org/abs/2503.21800</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IMF：大语言模型的隐式指纹</title>
      <link>https://arxiv.org/abs/2503.21805</link>
      <description><![CDATA[ARXIV：2503.21805V1公告类型：新 
摘要：培训大语言模型（LLMS）是资源密集且昂贵的，使知识产权（IP）保护至关重要。大多数现有的模型指纹方法将指纹注入LLMS以保护模型所有权。这些方法创建了具有弱语义相关性的指纹对，缺乏在LLMS中正常问答（QA）对中建立的上下文连贯性和语义相关性。在本文中，我们提出了一生的修订干预（GRI）攻击，该攻击可以有效利用这种缺陷来擦除指纹，从而强调了对更安全的模型指纹方法的需求。因此，我们提出了一种新颖的指纹范式，称为隐式指纹（IMF）。 IMF构建具有强烈语义相关性的指纹对，将它们掩盖为LLM中的天然QA对。这样可以确保指纹与正常模型行为一致，从而使它们无法区分且可抵抗检测和去除。我们对多个LLM的实验表明，IMF在对抗条件下保留了高验证成功率，为保护LLM所有权提供了可靠的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2503.21805</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型符合对比度学习：跨语言的零拍情感识别</title>
      <link>https://arxiv.org/abs/2503.21806</link>
      <description><![CDATA[ARXIV：2503.21806V1公告类型：新 
摘要：多语言语音情感识别旨在使用跨不同语言的非接触式方法来估计说话者的情绪状态。但是，语音特征和语言多样性的变化为零击语音情感识别带来了重大挑战，尤其是在多语言数据集中。在本文中，我们建议利用对比学习来完善多语言语音特征，并扩展大型语言模型以零击的多语言语音情感估计。具体来说，我们采用一个新颖的两阶段训练框架来使语音信号与情感空间中的语言特征保持一致，从而捕捉情感感知和语言语言的语音表示。为了推进该领域的研究，我们引入了一个大规模的合成多语言语音情感数据集M5SER。我们的实验证明了所提出的方法在语音情感识别和零击的多语言语音情感识别（包括以前看不见的数据集和语言）中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.21806</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Oaei-llm-t：用于理解本体匹配系统中LLM幻觉的Tbox基准数据集</title>
      <link>https://arxiv.org/abs/2503.21813</link>
      <description><![CDATA[ARXIV：2503.21813V1公告类型：新 
摘要：使用大语言模型（LLM）的下游任务不可避免地幻觉。尽管解决幻觉成为基于LLM的本体匹配（OM）系统的重大挑战，但我们引入了一个名为OAEI-LLM-T的新基准数据集。数据集从本体学评估计划（OAEI）中的Tbox（即模式匹配）数据集演变，捕获执行OM任务的不同LLMS的幻觉。这些特定于OM特异性的幻觉被仔细地分为两个主要类别和六个子类别。我们展示了数据集在构建基于LLM的OM系统的LLM排行榜和微调基础LLMS方面的实用性。]]></description>
      <guid>https://arxiv.org/abs/2503.21813</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化安全且一致的语言生成：一种多目标GRPO方法</title>
      <link>https://arxiv.org/abs/2503.21819</link>
      <description><![CDATA[ARXIV：2503.21819V1公告类型：新 
摘要：将大语言模型（LLM）与人类价值观和安全限制保持一致，尤其是当诸如帮助，真实性和避免伤害冲突之类的目标时。从人类反馈中学习（RLHF）在转向模型中取得了显着的成功，但很复杂，可能是不稳定的。诸如直接偏好优化（DPO）之类的最新方法简化了基于偏好的微调，但可能引入偏见或权衡某些目标〜\ cite {dpo}。在这项工作中，我们提出了一个具有多标签奖励回归模型的小组相对政策优化（GRPO）框架，以实现安全且一致的语言生成。 GRPO算法通过比较采样响应的组来优化政策，从而消除了对单独的价值评论家的需求并提高培训效率〜\ cite {grpo}。我们训练一个奖励模型，以预测多个对齐分数（例如，安全性，有益性等），这些分数合并为单个奖励信号。我们提供了一种理论推导，用于在GRPO中使用这种学到的多种奖励奖励并讨论其优势和局限性。从经验上讲，我们的方法改善了在模型量表（0.5b，7b和14b参数）上评估的所有安全性和质量指标，表明了目标的强大平衡。我们将GRPO与基于PPO的RLHF和DPO进行了比较，这强调了GRPO的计算成本明显降低和明确的多目标处理。 \ textbf {我们将在https://huggingface.co/hydroxai上开放所有受过训练的模型。]]></description>
      <guid>https://arxiv.org/abs/2503.21819</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大语言模型提炼时间序列探测器</title>
      <link>https://arxiv.org/abs/2503.21833</link>
      <description><![CDATA[ARXIV：2503.21833V1公告类型：新 
摘要：时间序列异常检测（TSAD）在许多行业（包括金融，医疗保健和制造）中引起了广泛关注。尽管开发了许多用于检测异常的自动方法，但人类的监督仍然需要审查和对检测到的异常行动以及验证其准确性。我们研究了多模式大语言模型（LLM）的使用来部分自动化此过程。我们发现，LLM可以通过将时间序列图的目视检查与数据生成过程的文本描述进行视觉检查来有效地识别错误警报。通过利用LLM的能力，我们旨在减少对维护TSAD系统所需的人类努力的依赖]]></description>
      <guid>https://arxiv.org/abs/2503.21833</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MSPLORA：多尺度金字塔低级适应性适应有效模型</title>
      <link>https://arxiv.org/abs/2503.21838</link>
      <description><![CDATA[ARXIV：2503.21838V1公告类型：新 
摘要：参数有效的微调（PEFT）已成为适应大规模预训练模型的同时降低计算成本的重要方法。在PEFT方法中，Lora通过将重量更新分解为低级矩阵来大大降低了可训练的参数。但是，传统洛拉（Lora）在所有层中都采用固定等级，但未能说明层次信息的复杂性不同，从而导致适应性和冗余效率低下。为了解决这个问题，我们提出了MSPLORA（多尺度金字塔Lora），它介绍了全局共享的LORA，中层共享的Lora和特定层的Lora，以捕获全局模式，中级特征和细粒度的信息。这种分层结构可降低层间冗余，同时保持强大的适应能力。对各种NLP任务的实验表明，MSPlora可以实现更有效的适应性和更好的性能，同时显着减少了可训练的参数的数量。此外，基于单数值分解的其他分析验证了其信息解耦能力，从而突出了MSPlora作为大型语言模型中参数有效微调的可扩展有效优化策略。我们的代码可在https://github.com/oblivioniss/msplora上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.21838</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新通讯：心理健康社会支持互动数据集 - 了解有效的社会支持以完善AI驱动的支持工具</title>
      <link>https://arxiv.org/abs/2503.21888</link>
      <description><![CDATA[ARXIV：2503.21888V1公告类型：新 
摘要：有效的心理健康支持对于减轻心理困扰至关重要。尽管基于大型语言模型（LLM）的助手在心理健康干预措施中表现出了希望，但现有研究通常主要定义“有效”支持，主要是在善解人意的承认方面，忽略了其他基本维度，例如信息指导，社区验证，有形应对策略。为了解决这一限制并更好地了解什么构成有效的支持，我们介绍了Redditess，这是一种从Reddit帖子中得出的新颖的现实世界数据集，包括支持性评论和原始海报的后续响应。基于既定的社会科学理论，我们开发了一种合奏标签机制，以注释支持性评论是否有效，并进行定性评估以确保注释的可靠性。此外，我们通过使用它来指导LLM Alignment来产生更高上下文敏感且真正有用的支持响应来证明Redditess的实际实用性。通过扩大对有效支持的理解，我们的研究为先进的AI驱动心理健康干预铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2503.21888</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Jeem：四个阿拉伯语方言中的视觉理解</title>
      <link>https://arxiv.org/abs/2503.21910</link>
      <description><![CDATA[ARXIV：2503.21910V1公告类型：新 
摘要：我们介绍了Jeem，这是一种基准，旨在评估四个讲阿拉伯语国家的视觉理解的视觉语言模型（VLM）：约旦，阿联酋，埃及和摩洛哥。 Jeem包括图像字幕和视觉问题的任务，并具有文化丰富和多样的内容。该数据集旨在评估VLM跨方言概括并准确解释视觉环境中的文化元素的能力。在评估五个著名的开源阿拉伯VLM和GPT-4V时，我们发现阿拉伯VLM始终表现不佳，在视觉理解和特定方言特定的一代中都挣扎。尽管GPT-4V在此比较中排名最佳，但该模型的语言能力在方言各不相同，其视觉理解能力却落后。这强调了对更多包容性模型的需求和文化多样性评估范式的价值。]]></description>
      <guid>https://arxiv.org/abs/2503.21910</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>验尸：与大语言模型的半结构化访谈中自动识别心理动力冲突</title>
      <link>https://arxiv.org/abs/2503.21911</link>
      <description><![CDATA[ARXIV：2503.21911V1公告类型：新 
摘要：心理动力冲突是持久的，通常会塑造出一个人的行为和经验的无意识主题。精神动力冲突的准确诊断对于有效的患者治疗至关重要，通常是通过长期，手动评分的半结构化访谈来完成的。现有用于精神诊断的自动化解决方案倾向于集中于对抑郁症等广泛疾病类别的识别，并且尚不清楚在多大程度上可以从对话中自动认识到，即使患者本身也无法有意识地获得这种冲突。在本文中，我们提出了尸检，这是使用大语言模型（LLMS）的全长手术心理动力学诊断（OPD）访谈的第一种认识到心理动力冲突的存在和意义的方法。我们的方法结合了参数有效的微调和检索功能生成（RAG）的最新进展以及摘要策略，以有效地处理整个90分钟长的对话。在对141次诊断访谈的数据集的评估中，我们表明尸检始终在识别四起高度相关的心理动力冲突的识别方面始终优于所有基准和消融条件。]]></description>
      <guid>https://arxiv.org/abs/2503.21911</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合情绪识别：通过声学和文本分析增强客户互动</title>
      <link>https://arxiv.org/abs/2503.21927</link>
      <description><![CDATA[ARXIV：2503.21927V1公告类型：新 
摘要：本研究提出了一个混合情绪识别系统，该系统整合了先进的深度学习，自然语言处理（NLP）和大型语言模型（LLMS），以分析音频和文本数据，以增强联系中心的客户互动。通过将声学特征与文本情感分析相结合，该系统实现了细微的情感检测，解决了传统方法在理解复杂情绪状态方面的局限性。该方法利用LSTM和CNN模型进行音频分析和Distilbert进行文本评估，在确保实时处理的同时，可以适应语言和文化变化。对各种数据集进行严格的测试证明了系统的稳健性和准确性，突出了其通过实现个性化的，善解人意的互动并提高运营效率来转变客户服务的潜力。这项研究为更智能和以人为中心的数字通信，重新定义客户服务标准奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2503.21927</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当地的标准化失真和大型语言模型解码策略的热力学形式主义</title>
      <link>https://arxiv.org/abs/2503.21929</link>
      <description><![CDATA[ARXIV：2503.21929V1公告类型：新 
摘要：硬件和语言模型体系结构的进步激发了自然语言产生的革命。但是，自回归模型在下一步选择上计算概率分布，而这些分布（称为解码）的取样比其他设计选择的关注明显少得多。现有的解码策略在很大程度上基于启发式方法，从而导致难以以原则性的方式应用或改进的方法。我们通过以千古理论语言表达流行的解码算法来开发语言模型解码策略的理论，并说明它们优化的功能。使用此过程，我们分析了TOP-K，核和温度采样的局部归一化步骤的效果，用于使概率总和达到一个。我们认为，局部归一化扭曲是解码策略的根本缺陷，并量化了这种失真的大小及其对数学代理的影响对生成文本的质量和多样性的影响。与普遍的解释相反，我们认为，相对于核抽样的TOP-K采样不足的主要原因是局部归一化扭曲。这给出了解码算法的未来设计和机器生成文本的检测的结论。]]></description>
      <guid>https://arxiv.org/abs/2503.21929</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>证明还是虚张声势？评估2025年美国数学奥林匹克运动会上的LLM</title>
      <link>https://arxiv.org/abs/2503.21934</link>
      <description><![CDATA[ARXIV：2503.21934V1公告类型：新 
摘要：Matharena等大型语言模型（LLM）（LLM）的最新数学基准表明，最新的推理模型在AIME等数学竞赛中实现了令人印象深刻的表现，并具有领先的模型O3-Mini，取得了与顶级人类竞争对手可比的分数。但是，这些基准测试仅基于最终数值答案评估模型，忽略了严格的推理和证明生成，这对于现实世界中的数学任务至关重要。为了解决这一问题，我们介绍了针对数学问题的全面推理的首次全面评估。使用专家人注释者，我们评估了几个最新的推理模型，该模型在释放后数小时内的2025年USAMO的六个问题上进行了评估。我们的结果表明，所有经过测试的模型都在挣扎中很大，平均达到了不到5％。通过对推理轨迹的详细分析，我们确定了最常见的故障模式，并找到了由模型培训过程中采用的优化策略引起的几种不必要的伪像。总体而言，我们的结果表明，当前的LLM不足以进行严格的数学推理任务，这突出了对推理和证明产生能力的实质性改进的需求。]]></description>
      <guid>https://arxiv.org/abs/2503.21934</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于改进数学推理的熵感知分支</title>
      <link>https://arxiv.org/abs/2503.21961</link>
      <description><![CDATA[Arxiv：2503.21961V1公告类型：新 
摘要：尽管大型语言模型（LLM）通过广泛的预训练和微调有效地保持一致，但它们在代币产生过程中仍然在不同程度的不确定性方面挣扎。在我们对数学推理的研究中，我们观察到，在模型输出分布中表现出高熵和熵方差的令牌中，错误更有可能出现。基于观察结果，我们提出了一种新颖的方法，该方法可以动态地按需分支生成过程，而不是默认为最可能的令牌。通过探索来自关键决策点的高概率令牌的并行多个分支，该模型可以发现可能遗漏的各种推理路径。我们进一步利用来自较大模型的外部反馈，以排名并选择最连贯和准确的推理分支。我们在数学单词问题和计算问题上的实验结果表明，与常规的Argmax解码相比，这种分支策略将小LLMS的推理能力提高了4.6％。]]></description>
      <guid>https://arxiv.org/abs/2503.21961</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>群集自动机</title>
      <link>https://arxiv.org/abs/2503.22000</link>
      <description><![CDATA[ARXIV：2503.22000V1公告类型：新 
摘要：我们介绍了一类新的摩尔自动机（CMA），研究其时间行为并描述某些应用。]]></description>
      <guid>https://arxiv.org/abs/2503.22000</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>