<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 11 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Endive：大语言模型中公平和表现的跨划分基准</title>
      <link>https://arxiv.org/abs/2504.07100</link>
      <description><![CDATA[ARXIV：2504.07100V1公告类型：新 
摘要：由社会，文化和区域影响塑造的人类语言的多样性对自然语言处理（NLP）系统提出了重大挑战。现有的基准通常会忽略语言内语言的变化，从而使非标准方言的扬声器服务不足。为了解决这一差距，我们介绍了Endive（英语多样性），这是一个基准，该基准在语言理解，算法推理，数学和逻辑方面评估了五个广泛使用的大型语言模型（LLM）。我们的框架将标准的美国英语数据集转化为五个代表性不足的方言，并使用以母语者的验证示例进行了验证，并通过流畅的评估，偏好测试和语义相似性指标将这些翻译与基于规则的方法进行比较。人类评估证实了高翻译质量，忠诚，流利性和形式的平均得分至少为6.02/7。通过滤除近乎相同的翻译，我们创建了一个具有挑战性的数据集，该数据集揭示了重大的性能差异 - 与标准的美国英语相比，方言输入的模型始终表现不佳。因此，通过发现模型偏见并促进更公平的语言技术，可以推进方言感知的NLP。]]></description>
      <guid>https://arxiv.org/abs/2504.07100</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>路由器插座的健壮程度如何？ LLM路由功能的脆弱性分析</title>
      <link>https://arxiv.org/abs/2504.07113</link>
      <description><![CDATA[ARXIV：2504.07113V1公告类型：新 
摘要：大型语言模型（LLM）路由已成为一种至关重要的策略，用于通过基于查询复杂性将查询动态分配给最合适的模型，以平衡计算成本与性能。尽管最近的进展表明，基于偏好的路由器的表现可以胜过传统方法，但当前的评估基准仍有限。他们在很大程度上专注于通用模型能力，同时忽略了特定于任务的行为以及通过偏好数据引入的隐私，安全性和潜在的后门漏洞等关键问题。作为回应，我们提出了DSC基准：多样，简单和分类，这是一个评估框架，将路由器性能分类为各种查询类型，包括编码，翻译，数学，数学，人类的指导，常识和LLM越狱。此外，它集成了隐私和安全评估以揭示隐藏的风险。我们对三个基于偏好的路由器和两个商业对应物进行的实验表明，尽管这些系统提高了效率，但它们通常会做出次优的类别驱动的决策。例如，基于BERT的路由器将所有编码和数学查询都引导到最强大的LLM，即使更简单的模型就足够，同时越狱尝试较弱的模型，从而提高了安全风险。]]></description>
      <guid>https://arxiv.org/abs/2504.07113</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>聊天板：从静态基准到人类评估</title>
      <link>https://arxiv.org/abs/2504.07114</link>
      <description><![CDATA[ARXIV：2504.07114V1公告类型：新 
摘要：随着基于LLM的聊天机器人的迅速采用，迫切需要评估人类和LLM可以共同实现的目标。但是，标准的基准（例如MMLU）孤立地测量LLM功能（即“ Ai-horone”）。在这里，我们通过向用户播种问题并让他们与LLM进行对话以回答他们的问题，从而设计和进行用户研究，以将MMLU问题转换为用户对话。我们发布ChatBench，这是一个新的数据集，具有AI-OLONE，单词和用户-AI数据，用于396个问题和两个LLM，包括144K Answers和7,336个用户-AI对话。我们发现AI-ORONOME精度无法预测用户AI的准确性，并且在多个受试者（数学，物理和道德推理）之间存在显着差异，并且我们分析了用户-AI对话，以提供有关它们与AI-Olone基准分歧的见解。最后，我们表明，在Chatbench子集中对用户模拟器进行微型模拟器提高了其估计用户-AI精度的能力，从而将持有问题的相关性提高了20点以上，从而为扩展交互式评估提供了可能性。]]></description>
      <guid>https://arxiv.org/abs/2504.07114</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>均衡：减轻检索模型中的语言偏见</title>
      <link>https://arxiv.org/abs/2504.07115</link>
      <description><![CDATA[ARXIV：2504.07115V1公告类型：新 
摘要：这项研究发现，现有信息检索（IR）模型基于输入查询的语言复杂性显示出明显的偏见，在语言上更简单（或更复杂的）查询上表现良好，而在语言上更为复杂（或更简单）的查询方面表现不佳。为了解决这个问题，我们提出了Equalizeir，这是一种减轻IR模型中语言偏见的框架。 Earleizeir使用语言偏见的弱学习者来捕获IR数据集中的语言偏见，然后通过使用有偏见的弱学习者正规化和完善其预测来训练强大的模型。这种方法有效地防止了鲁棒模型在数据中过度拟合到特定的语言模式。我们提出了四种开发语言偏见模型的方法。在几个数据集上进行的广泛实验表明，我们的方法降低了语言上简单且复杂的查询之间的性能差异，同时改善了整体检索性能。]]></description>
      <guid>https://arxiv.org/abs/2504.07115</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>清晰：将文本反馈与专家和业余爱好者进行对比</title>
      <link>https://arxiv.org/abs/2504.07116</link>
      <description><![CDATA[ARXIV：2504.07116V1公告类型：新 
摘要：我们介绍了清晰的（将文本反馈与专家和业余爱好者进行推理对比），这是一种新型的语言模型推理方法，利用了较大（专家）模型和较小（业余）模型的优势。专家和业余模型各自提供有关模型初始输出的反馈，并将彼此形成鲜明对比。随后将此反馈应用于迭代改善Clear的响应。我们的实验表明，在几项具有挑战性的推理任务中，明确的实验胜过最先进的方法，包括故事大纲的改进（兴趣相对相对增加），发电约为18.5％（覆盖范围提高了18.5％），数学推理，数学推理（准确性高达6.7％）和毒性降低毒性（高达6.7％）和毒性的降低（降低毒性降低22％）。]]></description>
      <guid>https://arxiv.org/abs/2504.07116</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek-R1思维学：让我们<Think>关于LLM推理</title>
      <link>https://arxiv.org/abs/2504.07128</link>
      <description><![CDATA[ARXIV：2504.07128V1公告类型：新 
摘要：诸如DeepSeek-R1之类的大型推理模型标志着LLMS处理复杂问题的基本转变。 DeepSeek-R1没有直接为给定输入提供答​​案，而是创建详细的多步推理链，在提供答案之前似乎对问题“思考”。用户公开使用此推理过程，为研究模型的推理行为和开放思想学领域创造了无尽的机会。从DeepSeek-R1的基本推理基本构件的分类学开始，我们对DeepSeek-R1的分析研究了思想长度的影响和可控性，长期或令人困惑的环境，文化和安全问题的管理以及DeepSeek-R1 Vis-\ a-Vis认知现象的状态，例如人类的语言处理和类似人类的世界模型。我们的发现描绘了细微的图片。值得注意的是，我们表明DeepSeek-R1具有“最佳选择”推理，额外的推理时间可以损害模型性能。此外，我们发现DeepSeek-R1持续反思以前探讨的问题制剂，阻碍进一步探索的趋势。我们还注意到，与其非争议的同行相比，DeepSeek-R1的强烈安全漏洞，这也可能损害与安全一致的LLM。]]></description>
      <guid>https://arxiv.org/abs/2504.07128</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>次生：自然语言产生的假设引导评估</title>
      <link>https://arxiv.org/abs/2504.07174</link>
      <description><![CDATA[ARXIV：2504.07174V1公告类型：新 
摘要：大型语言模型（LLM）表现出了自动化自然语言生成评估的巨大潜力。 LLM-AS-A-a-gudge的先前框架以两种方式下降了：他们要么使用零拍设置而无需咨询任何人类输入，这会导致较低的对齐方式，或者在标记的数据上进行了微调LLM，这需要非平凡的样品。此外，以前的方法通常在自动化评估背后几乎没有推理。在本文中，我们提出了假设的假设引导的评估框架，该框架首先使用一小部分人类评估来为人类判断生成更详细的专栏，然后将类似清单的清单样方法结合在一起，以结合LLM对每个分解的维度分配的分数，以获取整体分数。只有30次人力评估，低词与人类排名（Spearman相关性）和人类得分（Pearson相关性）的一致性达到最先进的表现，平均表现G-eval的G-eval的G-eval比11.86％和微调的Llama-3.1-8B结构至少比至少3倍的人为人为评估，以占11.95％。此外，我们进行系统的研究以评估降压管的鲁棒性，从而强调了其有效性作为可靠且可解释的自动化评估框架。]]></description>
      <guid>https://arxiv.org/abs/2504.07174</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SEMEVAL-2025任务5：LLMS4SUBEXTS-基于LLM的自动化主题标记国家技术图书馆的开放访问目录</title>
      <link>https://arxiv.org/abs/2504.07199</link>
      <description><![CDATA[ARXIV：2504.07199V1公告类型：新 
摘要：我们介绍了Semeval-2025任务5：LLMS4Subjects，这是使用GND分类法的科学和技术记录的自动化主题标记的共享任务。参与者开发了基于LLM的系统来推荐TOP-K受试者，并通过主题专家通过定量指标（精度，召回，F1得分）和定性评估进行评估。结果突出了LLM合奏，合成数据生成和多语言处理的有效性，从而为应用LLMS用于数字图书馆分类提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2504.07199</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概念节：证据的动态实现</title>
      <link>https://arxiv.org/abs/2504.07228</link>
      <description><![CDATA[ARXIV：2504.07228V1公告类型：新 
摘要：在大规模上找到人类意见和行为的证据是一项艰巨的任务，通常需要了解社交媒体上广阔的在线社区中的复杂思维模式。例如，研究枪支所有权与对自由的看法如何相关，需要一个可以通过社交媒体帖子进行大规模运行的检索系统，同时应对两个关键挑战：（1）确定抽象概念实例，（2）可以在不同社区之间实例化。为了解决这些问题，我们介绍了ConceptCarve，这是一个证据检索框架，该框架利用传统的猎犬和LLMS在检索过程中动态表征搜索空间。我们的实验表明，ConceptCarve超过了传统的检索系统，可以在社交媒体社区中找到证据。它还为该社区的证据提供了可解释的代表，我们用来分析在整个社区中表现出不同不同的复杂思维模式。]]></description>
      <guid>https://arxiv.org/abs/2504.07228</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉吸引的语音识别噪声场景</title>
      <link>https://arxiv.org/abs/2504.07229</link>
      <description><![CDATA[ARXIV：2504.07229V1公告类型：新 
摘要：人类有能力利用视觉提示，例如唇部运动和视觉场景，以增强听觉感知，尤其是在嘈杂的环境中。但是，当前的自动语音识别（ASR）或视听语音识别（AVSR）模型通常在嘈杂的情况下挣扎。为了解决此任务，我们提出了一个模型，该模型通过将噪声源与视觉提示相关联，改善转录。与依靠唇部运动并需要说话者的可见性的作品不同，我们利用环境中的更广泛的视觉信息。这使我们的模型可以自然地从噪声中滤除语音并改善转录，就像人类在嘈杂的情况下一样。我们的方法重新验证了预测的语音和视觉编码器，将它们与多头关注联系起来。这种方法可以使语音转录和视频输入中噪声标签的预测。我们引入了可扩展的管道来开发视听数据集，其中视觉提示与音频中的噪声相关。在嘈杂的场景中，我们对现有的唯一音频模型显示出显着改善。结果还强调，视觉提示在提高转录精度中起着至关重要的作用。]]></description>
      <guid>https://arxiv.org/abs/2504.07229</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>财务未来的语言建模：对指标，任务和数据机会的定量调查</title>
      <link>https://arxiv.org/abs/2504.07274</link>
      <description><![CDATA[ARXIV：2504.07274V1公告类型：新 
摘要：语言建模的最新进展导致人们对将自然语言处理（NLP）技术应用于财务问题的兴趣日益增加，从而实现了分析和决策的新方法。为了系统地检查这一趋势，我们回顾了38个会议和讲习班之间在2017年至2024年之间发表的374个NLP研究论文，并对221篇论文进行了重点分析，这些论文直接解决了与财务相关的任务。我们在11个定性和定量维度上评估了这些论文，并确定了关键趋势，例如通用语言模型的使用日益增加，情感分析和信息提取中的稳定进步以及围绕解释性和隐私保护方法的新兴努力。我们还讨论了评估指标的使用，强调了特定于域的标准机器学习指标的重要性。我们的发现强调了需要更容易访问，自适应数据集的必要性，并强调了将金融危机期纳入在现实世界条件下增强模型鲁棒性的重要性。这项调查提供了适用于金融的NLP研究的结构化概述，并为在此交叉路口工作的研究人员和从业人员提供了实用的见解。]]></description>
      <guid>https://arxiv.org/abs/2504.07274</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>加薪：大语言模型的加强自适应教学选择</title>
      <link>https://arxiv.org/abs/2504.07282</link>
      <description><![CDATA[ARXIV：2504.07282V1公告类型：新 
摘要：在大型语言模型（LLMS）的指令中，已经达成共识，即一些高质量的说明优于大量低质量指令。目前，已经提出了许多指导选择方法，但是这些方法中的大多数基于启发式质量指标选择了指令，并且仅在培训前考虑数据选择。这些设计导致教学微调的优化不足，固定的启发式指标通常很难针对特定任务进行优化。因此，我们设计了一个动态的，任务 - 目标驱动的指令选择框架提高（增强自适应指令选择），该框架将整个指令微调过程纳入优化，并根据指令对模型性能改进的预期影响在每个步骤中选择指令。我们的方法是易于解释的，并且具有特定于任务的优化功能。通过将动态指导选择建模为顺序决策过程，我们使用RL来训练我们的选择策略。与其他指导选择方法相比，广泛的实验和结果分析证明了我们方法的优越性。值得注意的是，与全DATA培训相比，RAIS仅通过更新1 \％的培训步骤来实现卓越的性能，从而证明其效率和有效性。]]></description>
      <guid>https://arxiv.org/abs/2504.07282</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MDIT：一种用于多种说明调整的无模型数据插值方法</title>
      <link>https://arxiv.org/abs/2504.07288</link>
      <description><![CDATA[ARXIV：2504.07288V1公告类型：新 
摘要：随着大型语言模型（LLM）越来越多地在各种任务中应用，指令调整已成为增强模型性能的关键方法。但是，当前的数据管理策略在产生多样化和全面的数据方面面临着重大挑战，从而限制了模型性能的进一步改进。为了解决这一差距，我们提出了MDIT，这是一种用于不同指令调整的新型无模型数据插值方法，该方法通过执行任务插值来生成多样化和高质量的指令数据。此外，它包含基于多样性的聚类策略，以确保培训数据的多样性。广泛的实验表明，我们的方法在多个基准任务中实现了卓越的性能。使用MDIT进行的LLMS对LLMS进行了重大改进，例如一般问答，数学推理和代码生成等许多任务。 MDIT提供了一种高效且自动的数据合成方法，生成了不同的指令数据，而无需依赖外部资源，同时扩大了LLM在复杂环境中的应用潜力。]]></description>
      <guid>https://arxiv.org/abs/2504.07288</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Payador：一种在结构化数据上进行互动故事和角色扮演游戏的简约方法的方法</title>
      <link>https://arxiv.org/abs/2504.07304</link>
      <description><![CDATA[ARXIV：2504.07304V1公告类型：新 
摘要：每次交互式讲故事（IS）系统获得播放器的输入时，它就会面临世界更新的问题。该问题的经典方法包括将输入映射到已知的预编程动作，什么可以严重限制玩家的自由意志。当预期的体验重点放在即兴演奏上，例如角色扮演游戏（RPG），此问题至关重要。在本文中，我们介绍了Payador，另一种侧重于预测行动结果而不是代表行动本身的方法。为了实施这种方法，我们将大型语言模型扎根，以最小化虚构的世界，从而获得了有希望的结果。我们为开源做出了这种贡献，因此可以对其进行调整并用于释放RPG的共同创造力的其他相关研究。]]></description>
      <guid>https://arxiv.org/abs/2504.07304</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多语言MFA：低资源相关语言上的强制对齐</title>
      <link>https://arxiv.org/abs/2504.07315</link>
      <description><![CDATA[ARXIV：2504.07315V1公告类型：新 
摘要：我们比较了具有类似语音库存的相关和无关澳大利亚语言的多语言和跨语言培训的结果。我们使用蒙特利尔强迫对准器从头开始训练声学模型，并适应大型英语模型，评估结果针对可见的数据，看不见的数据（见到语言）以及看不见的数据和语言。结果表明，适应以前看不见的语言的英语基线模型的好处。]]></description>
      <guid>https://arxiv.org/abs/2504.07315</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>