<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Thu, 11 Jan 2024 06:18:40 GMT</lastBuildDate>
    <item>
      <title>到底是谁的妻子呢？评估机器翻译中对同性关系的偏见。 （arXiv：2401.04972v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04972</link>
      <description><![CDATA[机器翻译经常受到有偏见的数据和算法的影响
导致系统输出出现不可接受的错误。尽管性别规范存在偏见
已被调查，但人们对 MT 系统是否编码偏见知之甚少
社会关系，例如诸如“律师亲吻了她的妻子”之类的句子。我们
研究机器翻译系统中对同性关系的偏见程度，
使用从几种名词性别语言中提取的生成模板句子
（例如西班牙语）。我们发现三种流行的 MT 服务始终无法
准确翻译有关名词之间关系的句子
同性别。错误率根据上下文的不同而有很大差异，例如
提及女性代表性较高的职业的同性别句子是
翻译的准确性较低。我们将这项工作作为案例研究提供
评估 NLP 系统中与社会相关的内在偏差
关系。
]]></description>
      <guid>http://arxiv.org/abs/2401.04972</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:40 GMT</pubDate>
    </item>
    <item>
      <title>推理步长对大型语言模型的影响。 （arXiv：2401.04925v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04925</link>
      <description><![CDATA[思维链（CoT）对于提高推理能力具有重要意义
大语言模型（LLM）。然而，之间的相关性
CoT 的有效性和提示中推理步骤的长度仍然存在
很大程度上不为人所知。为了阐明这一点，我们进行了一些实证研究
进行实验来探索其中的关系。具体来说，我们设计的实验是
扩展和压缩 CoT 演示中的基本原理推理步骤，
同时保持所有其他因素不变。我们有以下主要发现。
首先，结果表明，延长提示中的推理步骤，
即使没有在提示中添加新信息，也大大增强了
法学硕士跨多个数据集的推理能力。或者，缩短
即使在保留关键信息的情况下，推理步骤也显着
降低模型的推理能力。这一发现凸显了
CoT 中步骤数量的重要性提示并提供实用的
更好地利用法学硕士解决复杂问题的潜力的指导
场景。其次，我们还研究了两者之间的关系。
CoT 的性能以及演示中使用的基本原理。令人惊讶的是，
结果表明，即使是不正确的理由也能产生有利的结果，如果
他们保持必要的推理长度。第三，我们观察到
增加推理步骤的优点取决于任务：更简单的任务
需要更少的步骤，而复杂的任务则可以通过更长的时间获得显着的效果
推理序列。
]]></description>
      <guid>http://arxiv.org/abs/2401.04925</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:39 GMT</pubDate>
    </item>
    <item>
      <title>从反事实自然语言中学习音频概念。 （arXiv：2401.04935v1 [cs.MM]）</title>
      <link>http://arxiv.org/abs/2401.04935</link>
      <description><![CDATA[传统的音频分类依赖于预定义的类别，缺乏
从自由格式文本中学习的能力。最近的方法解锁了学习关节
来自原始音频文本对的音频文本嵌入，以自然方式描述音频
语言。尽管最近取得了进展，但很少有探索
训练识别声音事件和来源的模型的系统方法
其他场景，例如区分烟花和枪声
类似情况下的户外活动。这项研究引入了因果推理
以及音频领域的反事实分析。我们使用反事实
实例并将它们包含在我们的模型中的不同方面。我们的模型
考虑来自的声学特性和声源信息
人工注释的参考文本。为了验证我们模型的有效性，我们
利用多个音频字幕数据集进行预训练。然后我们
通过几个常见的下游任务进行评估，展示该方法的优点
提出的方法是利用反事实信息的首批工作之一
在音频领域。具体来说，基于开放式语言的 top-1 准确度
音频检索任务增加了 43% 以上。
]]></description>
      <guid>http://arxiv.org/abs/2401.04935</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:39 GMT</pubDate>
    </item>
    <item>
      <title>AI能像人类一样写古典诗词吗？受图灵测试启发的实证研究。 （arXiv：2401.04952v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04952</link>
      <description><![CDATA[一些人认为，人类的本质，例如创造力和情感，
机器永远无法模仿。本文对这一信念提出了质疑
研究一个至关重要的问题：人工智能可以像人类一样创作诗歌吗？回答
为了解决这个问题，我们提出了 ProFTAP，这是一种新颖的评估框架，其灵感来自于
图灵测试评估人工智能的诗歌写作能力。我们将其应用到当前
大型语言模型（LLM）并发现最近的 LLM 确实拥有
写古典诗词的能力与其他人几乎没有区别
人类。我们还揭示了各种开源 LLM 在以下方面的表现优于 GPT-4：
这个任务。
]]></description>
      <guid>http://arxiv.org/abs/2401.04952</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:39 GMT</pubDate>
    </item>
    <item>
      <title>多用户聊天助手（MUCA）：使用法学硕士促进群组对话的框架。 （arXiv：2401.04883v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04883</link>
      <description><![CDATA[大型语言模型 (LLM) 的最新进展提供了新的方法
聊天机器人开发的途径，而大多数现有研究主要
以单用户聊天机器人为中心，专注于决定之后回答“什么”
用户输入。在本文中，我们发现多用户聊天机器人有更多
复杂的 3W 设计维度——“说什么”、“何时”回应以及“谁”回应
回答。此外，我们提出了多用户聊天助手（MUCA），这是一个
基于 LLM 的聊天机器人框架，专为小组讨论而设计。
MUCA由三个主要模块组成：副主题生成器、对话分析器和
言语策略仲裁员。这些模块共同确定合适的
回复内容、时间和适当的收件人。为了使
为了更轻松地优化 MUCA 流程，我们进一步提出了一种基于 LLM 的多用户
可以模仿真实用户行为的模拟器（MUS）。这使得更快
模拟聊天机器人和模拟用户之间的对话，使得
聊天机器人框架的早期开发效率要高得多。穆卡
展示有效性，包括适当的插话时机、相关
内容和积极的用户参与，以目标为导向的对话
中小数量的参与者，如案例研究和
用户研究的实验结果。
]]></description>
      <guid>http://arxiv.org/abs/2401.04883</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>ANGO：中文领域面向生成语言模型的下一级评估基准。 （arXiv：2401.04898v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04898</link>
      <description><![CDATA[最近，各种大型语言模型（LLM）评估数据集已
出现了，但大多数都存在排名扭曲和难以获取的问题
模型能力分析。针对这些问题，本文介绍了
ANGO，中国选择题评估基准。非政府组织提议
\textit{Keypoint} 首次分类标准，每个问题都在
ANGO可以对应多个关键点，有效增强
评估结果的可解释性。基于真人的表现，我们
建立可量化的题目难度标准，划分ANGO题目
分为9个难度级别，为模型提供更精准的指导
训练。最大限度地减少数据泄露的影响并充分利用非政府组织的创新
功能，我们设计了独家采样策略和新的评估
支持快速测试集迭代的框架。我们的实验证明
非政府组织对模型提出了更强的挑战，并揭示了更多细节
评估结果与现有基准进行比较。
]]></description>
      <guid>http://arxiv.org/abs/2401.04898</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>客观评估口语对话系统的用户行为分析。 （arXiv：2401.04867v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04867</link>
      <description><![CDATA[建立口语对话系统的评估方案很重要，但是
它也可能具有挑战性。虽然主观评价通常用于
研究比较需要用户实验、客观评价
和再现性。为了解决这个问题，我们提出了一个框架
根据用户的行为间接但客观地评估系统。在
本文，为此，我们调查用户之间的关系
社会对话任务中的行为和主观评价分数：注意力
倾听、工作面试和初次见面的谈话。结果显示
在以用户话语为主的对话任务中，例如注意力集中
听力和工作面试，话语数量和单词数等指标
评价中发挥重要作用。观察不流畅也可以表明
正式任务的有效性，例如工作面试。另一方面，在
交互性高的对话任务，比如初次见面的对话，
与轮流相关的行为，例如平均轮流停顿长度，变成
更重要。这些发现表明，选择适当的用户
行为可以为每个方面的客观评估提供有价值的见解
社会对话任务。
]]></description>
      <guid>http://arxiv.org/abs/2401.04867</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>使用语音活动投影进行实时连续轮流预测。 （arXiv：2401.04868v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04868</link>
      <description><![CDATA[实时连续轮流预测系统的演示
被呈现。该系统基于语音活动投影（VAP）模型，
它将对话立体声音频直接映射到未来的语音活动。虚拟接入点
模型包括对比预测编码（CPC）和自注意力
变压器，然后是交叉注意力变压器。我们检验一下效果
输入上下文音频长度并证明所提出的系统可以
根据 CPU 设置实时运行，性能下降最小。
]]></description>
      <guid>http://arxiv.org/abs/2401.04868</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>attendre：等待通过基于内存的变压器中的逐出查询进行检索以进行长上下文处理。 （arXiv：2401.04881v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04881</link>
      <description><![CDATA[随着法学硕士已经能够处理更复杂类型的输入，
研究人员最近研究了如何高效且经济地处理
可能是任意长的序列。一种有效的方法是使用 FIFO
用于存储过去块中注意力子层的键和值的内存
允许后续查询参加。然而，这种方法需要大量
内存和/或考虑特定的 LM 架构。
此外，由于先前上下文中的键值与
目前的查询，这种方法不能扩展到双向
注意力，例如在编码器-解码器或仅 PrefixLM 解码器架构中。
在本文中，我们建议使用 LRA 和 LFA 等驱逐政策来
减少内存大小并适应各种架构，我们还提出
attendre 层，通过检索键值进行等待参加机制
内存（K/V 内存），并在查询内存（Q 内存）中驱逐查询。作为一个
第一步，我们在上下文长度扩展设置中评估该方法
TriviaQA 阅读理解任务，并展示了该任务的有效性
方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.04881</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>口语文本中的实体识别。 （arXiv：2401.04853v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04853</link>
      <description><![CDATA[从非正式文本中提取感兴趣的概念和实体，例如
社交媒体帖子和非正式沟通是一项重要能力
许多领域的决策支持系统，包括医疗保健、客户
关系管理等。尽管最近在训练方面取得了进步
用于各种自然语言处理任务的大型语言模型
开发的模型和技术主要集中在正式文本上，而不是
在口语数据上表现也很好，其特点是许多
独特的挑战。在我们的研究中，我们专注于医疗保健领域
研究口语文本中的症状识别问题
设计和评估基于 BERT 模型的几种训练策略
微调。这些策略的区别在于基础的选择
模型、训练语料库以及术语扰动的应用
训练数据。使用这些策略训练的表现最好的模型
远远超过最先进的专业症状识别器
利润。通过一系列的实验，我们发现了特定的模式
与我们设计的训练策略相关的模型行为。我们提出
有效实体识别训练策略的设计原则
基于我们的发现的口语文本。
]]></description>
      <guid>http://arxiv.org/abs/2401.04853</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>语言模型更像图书馆还是图书馆员？图书馆技术、新颖的参考问题和法学硕士的态度。 （arXiv：2401.04854v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04854</link>
      <description><![CDATA[法学硕士是否属于文化技术，例如复印机或印刷机？
传输信息却无法创造新内容？对这个想法的挑战，
我们称之为文献技术主义，法学硕士通常确实会产生完全新颖的作品
文本。我们首先捍卫图书馆技术主义以应对这一挑战，展示如何
小说文本可能仅在派生意义上才有意义，因此内容
这个生成的文本在很大程度上取决于原始内容
人类文本。我们继续提出一个不同的、新颖的挑战
文献技术主义，源于法学硕士产生“小说”的例子
参考”，使用新颖的名称来指代新颖的实体。这样的例子可以
如果法学硕士不是文化技术而是拥有
有限形式的代理（信念、愿望和意图）。根据
心灵哲学中的解释主义，一个系统有信念、欲望和
意图当且仅当它的行为可以通过以下假设得到很好的解释：
它有这样的状态。根据这一观点，我们认为新颖的案例
参考文献提供证据证明法学硕士确实有信念、愿望和
意图，因此具有有限的代理形式。
]]></description>
      <guid>http://arxiv.org/abs/2401.04854</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>用于个性化语言提示的用户嵌入模型。 （arXiv：2401.04858v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04858</link>
      <description><![CDATA[对悠久历史进行建模在增强推荐方面发挥着关键作用
系统，允许捕获用户不断变化的偏好，从而产生更多
精准、个性化的推荐。在这项研究中，我们解决
对长期用户历史进行建模以了解偏好的挑战
自然语言。具体来说，我们引入了一个新的用户嵌入模块（UEM）
通过压缩和处理，有效地处理自由格式文本中的用户历史记录
将它们表示为嵌入，将它们用作 LM 的软提示。我们的
实验证明了该方法在处理方面具有卓越的能力
与传统的基于文本的提示相比，历史记录明显更长
方法，从而显着提高预测性能。主要的
这项研究的贡献是证明了语言偏见的能力
将用户信号表示为嵌入的模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.04858</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>MoSECroT：使用静态词嵌入进行模型拼接，实现跨语言零样本迁移。 （arXiv：2401.04821v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04821</link>
      <description><![CDATA[基于 Transformer 的预训练语言模型 (PLM) 取得了令人瞩目的成就
在各种自然语言处理（NLP）任务中的表现。然而，
预训练此类模型可能会占用大量资源，而这些资源几乎仅
可用于高资源语言。相反，静态词嵌入
在计算资源和数据量方面更容易训练
必需的。在本文中，我们介绍了 MoSECroT 静态字模型拼接
跨语言零样本迁移的嵌入），一项新颖且具有挑战性的任务
这与静态词特别相关的低资源语言
可以使用嵌入。为了解决这个任务，我们提出了第一个框架
利用相对表示来构建一个公共空间
源语言 PLM 的嵌入和目标的静态词嵌入
语言。这样，我们就可以在源语言训练数据上训练 PLM
通过简单地交换
嵌入层。然而，通过对两种分类的大量实验
数据集，我们表明，尽管我们提出的框架与弱的框架具有竞争力
解决 MoSECroT 问题时的基线，未能取得有竞争力的结果
与一些强基线相比。在本文中，我们试图解释这一点
负面结果并提供一些可能改进的想法。
]]></description>
      <guid>http://arxiv.org/abs/2401.04821</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>迁移学习时代的阿拉伯文本变音：标记分类就是您所需要的。 （arXiv：2401.04848v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.04848</link>
      <description><![CDATA[阿拉伯文本的自动变音符号涉及添加变音标记
（变音符号）到文本中。这项任务提出了重大挑战
对计算处理和理解具有显着的影响。在这个
论文中，我们介绍了 PTCAD（阿拉伯语的 Pre-FineTuned Token Classification）
变音符号，一种新颖的阿拉伯文本变音符号两阶段方法
任务。 PTCAD包括预微调阶段和微调阶段，处理
阿拉伯语文本变音作为预训练的标记分类任务
楷模。 PTCAD 的有效性通过对两个项目的评估得到证明
源自 Tashkeela 数据集的基准数据集，它实现了
最先进的结果，包括字错误率 (WER) 降低 20\%
与现有基准相比，ATD 中的性能优于 GPT-4
任务。
]]></description>
      <guid>http://arxiv.org/abs/2401.04848</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>Translate-Distill：通过翻译和蒸馏学习跨语言密集检索。 （arXiv：2401.04810v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.04810</link>
      <description><![CDATA[之前关于英语单语检索的工作表明，交叉编码器
使用大量查询-文档对的相关性判断进行训练
可以作为老师进行训练，效率更高，但同样有效，
双编码器学生模型。应用类似的知识蒸馏方法
训练跨语言信息的高效双编码器模型
检索 (CLIR)，其中查询和文档采用不同的语言，
由于缺乏足够大的训练集而具有挑战性
查询语言和文档语言不同。因此，CLIR 的最新技术
依赖于大型英语 MS 的查询、文档或两者的翻译
MARCO 训练集，一种称为 Translate-Train 的方法。本文提出了一个
另一种方法是翻译-蒸馏，其中知识从任一
单语言交叉编码器或 CLIR 交叉编码器用于训练
双编码器 CLIR 学生模型。这种更丰富的设计空间使教师能够
模型在优化设置中执行推理，同时训练学生
直接为 CLIR 建立模型。经过训练的模型和工件可在以下位置公开获取
抱脸。
]]></description>
      <guid>http://arxiv.org/abs/2401.04810</guid>
      <pubDate>Thu, 11 Jan 2024 06:18:34 GMT</pubDate>
    </item>
    </channel>
</rss>