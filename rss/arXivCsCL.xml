<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Wed, 29 Nov 2023 06:18:37 GMT</lastBuildDate>
    <item>
      <title>CDEval：衡量大型语言模型文化维度的基准。 （arXiv：2311.16421v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.16421</link>
      <description><![CDATA[随着大型语言模型 (LLM) 的规模显着增强
他们的能力，人们越来越关注对齐问题
确保其负责任且合乎道德的使用。虽然现有的协调努力
主要集中于普世价值，例如 HHH 原则、
文化本质上是多元化和多样化的，但它并没有
得到了足够的重视。这项工作引入了一个新的基准，CDEval，
旨在评估法学硕士的文化维度。 CDEval 的构造方法是
结合了 GPT-4 的自动生成和人工验证，
涵盖七个领域的六个文化维度。我们的综合
实验为主流法学硕士的文化提供了有趣的见解，
突出不同维度的一致性和变化，
域。研究结果强调了整合文化的重要性
LLM发展中的考虑因素，特别是对于不同领域的应用
文化环境。通过 CDEval，我们的目标是拓宽 LLM 的视野
通过纳入文化维度进行调整研究，从而提供更多
法学硕士未来发展和评估的整体框架。这
基准是法学硕士文化研究的宝贵资源，为法学硕士的文化研究铺平了道路
培养更具文化意识和敏感度的模特的方式。
]]></description>
      <guid>http://arxiv.org/abs/2311.16421</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>发布 CRaQAn（问答中的共指解析）：一种使用指令跟踪模型的开源数据集和数据集创建方法。 （arXiv：2311.16338v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.16338</link>
      <description><![CDATA[指令跟随语言模型需要稳健的方法
信息检索以增强问答指令
应用程序。一个主要的挑战是解决
长文档的分块策略的上下文。的关键障碍
处理共指的实验缺乏开源数据集，
特别是在需要共指解析的问答任务中。
在这项工作中，我们在问答中展示了我们的共指消解
(CRaQAn) 数据集，一个满足细微信息的开源数据集
问答任务中共指消解的检索要求
提供超过 250 个包含共指的问答对。发展
在此数据集上，我们开发了一种创建高质量数据集的新方法
使用指令跟踪模型（GPT-4）和递归批评
改进循环。
]]></description>
      <guid>http://arxiv.org/abs/2311.16338</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>通过反事实数据生成减少机器翻译中的性别偏见。 （arXiv：2311.16362v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.16362</link>
      <description><![CDATA[神经方法的最新进展导致了
神经机器翻译 (NMT) 系统的质量。然而，这些系统
经常产生性别不准确的翻译（Stanovsky 等人，
2019），这可以追溯到训练数据的偏差。桑德斯与伯恩 (2020)
使用包含平衡性别的手工数据集解决这个问题
专业的话。通过使用这些数据来微调现有的 NMT 模型，他们
表明性别偏见可以显着减轻，尽管代价是
由于灾难性遗忘导致翻译质量下降。他们恢复了一些
修改训练目标或附加模型后质量会下降
推理。然而，我们发现只需补充手工制作的数据集
使用基本模型训练语料库中的随机样本就足以
显着减少灾难性遗忘。我们还推荐一本小说
利用域内数据创建的域适应技术
Zmigrod 等人提出的反事实数据生成技术。 (2019) 至
进一步提高 WinoMT 挑战测试集的准确性，且没有显着影响
翻译质量的损失。我们展示了它在 NMT 系统中的有效性
将英语翻译成法语、西班牙语和意大利语三种形态丰富的语言。
相关数据集和代码将在 Github 上提供。
]]></description>
      <guid>http://arxiv.org/abs/2311.16362</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>大规模影响力分数以实现高效的语言数据采样。 （arXiv：2311.16298v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.16298</link>
      <description><![CDATA[现代机器学习系统摄取从不同来源聚合的数据，例如
合成的、人工注释的、实时的客户流量。理解
\textit{哪些}示例对于学习的表现很重要
算法对于高效的模型训练至关重要。最近，越来越多的机构
文献产生了各种“影响力分数”，这些分数使用训练
诸如模型置信度或检查点梯度之类的工件来识别
重要的数据子集。然而，这些方法主要是开发
在计算机视觉设置中，目前还不清楚它们的推广效果如何
使用预训练模型的基于语言的任务。

在本文中，我们探讨了影响力分数在语言中的适用性
分类任务。我们在 SNLI 上评估这些分数的不同子集
通过量化响应修剪训练数据的准确性变化来构建数据集
通过随机和基于影响力得分的抽样。然后我们对其中之一进行压力测试
分数——来自 Agarwal 等人的“梯度方差”(VoG)。 (2022)——在
暴露于语音中的动态用户语音模式的 NLU 模型堆栈
助理类型的设置。我们的实验表明，在很多情况下，
基于编码器的语言模型可以在原始语言模型的大约 50% 上进行微调
数据不会降低性能指标。一路走来，我们总结
从应用影响力的开箱即用实施中吸取的经验教训
分数，量化噪声和类别不平衡数据的影响，并提供
关于基于分数的抽样的建议，以提高准确性和培训
效率。
]]></description>
      <guid>http://arxiv.org/abs/2311.16298</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>用于数据选择的基于熵和裕度的评分指标的综合基准测试。 （arXiv：2311.16302v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.16302</link>
      <description><![CDATA[虽然数据选择方法已在主动领域进行了广泛研究
学习、数据修剪和数据增强设置，几乎没有
这些方法在工业规模环境中有效性的证据，
尤其是在资源匮乏的语言中。我们的工作提出了评估方法
这些环境中的预期培训示例的“有用性”或
“困难”。我们还演示了如何使用这些措施来选择
训练监督机器学习模型的重要例子。我们
主要用熵和误差 L2-范数 (EL2N) 分数进行实验。我们用这些
从大量 \textit{Weak 中管理高质量数据集的指标
信号标记}数据，在期间分配无缺陷高置信度假设
推理作为基本事实标签。然后我们进行训练数据增强
使用这些去识别化数据集进行实验并证明基于分数
选择可以导致语义错误率降低2%，降低4%-7%
与基线技术相比，域分类错误率
随机选择。
]]></description>
      <guid>http://arxiv.org/abs/2311.16302</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型在数据处理中的应用：分割和更新信息的创新方法。 （arXiv：2311.16267v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.16267</link>
      <description><![CDATA[我们的论文研究了代码生成的有效方法
“特定领域”应用程序，包括使用大型语言模型
（法学硕士）用于数据细分和更新，以及激发更深入的研究
通过及时调整来思考法学硕士的问题。使用真实的公司产品作为
例如，我们提供用户手册、API 文档和其他数据。想法
本文讨论的帮助分割这些数据，然后将其转换为语义
向量以更好地反映其真实位置。随后，用户
需求被转换为向量以检索最相关的
内容，在简单到中等复杂的任务中实现约 70% 的准确率
通过各种提示技巧。本文首先增强
从这个角度来看特定领域代码生成的有效性。
此外，我们尝试从有限的数量中生成更多的脚本
使用基于llama2的微调来测试其在专业领域的有效性
代码生成。这是一个充满挑战和前景的领域，一旦实现，
它不仅会导致法学硕士在多个领域的发展取得突破
行业，还使法学硕士能够理解和学习任何新知识
有效地。
]]></description>
      <guid>http://arxiv.org/abs/2311.16267</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>学生掌握还是人工智能欺骗？分析 ChatGPT 的评估能力并评估检测策略。 （arXiv：2311.16292v1 [cs.CY]）</title>
      <link>http://arxiv.org/abs/2311.16292</link>
      <description><![CDATA[ChatGPT 等生成式人工智能系统对学习具有颠覆性影响
和评估。计算机科学需要实践来培养解决问题的技能
传统上使用作业开发的求解和编程。
生成式人工智能有能力为学生完成这些作业
具有高精度，这极大地增加了学术潜力
诚信问题和学生没有达到预期的学习成果。这
工作通过评估 ChatGPT 的三个方面来调查其性能
课程（CS1、CS2、数据库）。 ChatGPT 完成了几乎所有的入门
评价完美。现有的检测方法，如MOSS和JPlag
（基于相似性度量）和 GPTzero（人工智能检测），在以下方面取得了不同程度的成功
确定人工智能解决方案。使用评估教师和助教
区分学生代码和人工智能代码的启发式方法表明，他们的代码
检测不够准确。这些观察强调了需要
用于调整评估和改进检测方法。
]]></description>
      <guid>http://arxiv.org/abs/2311.16292</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>从文本到图像检索和生成的视觉和语言模型中删除 NSFW 概念。 （arXiv：2311.16254v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.16254</link>
      <description><![CDATA[诸如 CLIP 之类的视觉和语言模型已经表现出了卓越的性能
广泛任务的有效性。然而，这些模型通常是
对网络规模数据进行培训，这可能会引入不适当的内容并导致
导致不安全和偏见行为的发展。这反过来又阻碍了他们
在敏感和值得信赖的环境中的适用性，可以提高显着
对其采用的担忧。为了克服这些限制，我们引入了
通过删除视觉和语言模型来使视觉和语言模型更安全的方法
对不安全工作概念的敏感性。我们展示了如何做到这一点
从在安全和不安全之间转换的大型语言模型中提取
句子，并且从 100 个手动策划的开始进行微调
对。我们对由此产生的嵌入空间进行了广泛的实验
检索和文本到图像生成，我们表明我们的模型可以
也可以与预先训练的图像生成器一起正确使用。我们的源代码
训练有素的模型可在以下网址找到：https://github.com/aimagelab/safe-clip。
]]></description>
      <guid>http://arxiv.org/abs/2311.16254</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>左角变换的探索。 （arXiv：2311.16258v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.16258</link>
      <description><![CDATA[左角变换（Rosenkrantz 和 Lewis，1970）用于
从上下文无关语法中删除左递归，这是重要的一步
旨在通过简单的技术使语法可自上而下地解析。这张纸
概括先前的左角变换以支持半环加权
生产规则并提供更细粒度的控制
可能会被移动。我们的广义左角变换（GLCT）源自
统一左角变换和推测变换（Eisner
和 Blatz，2007），最初用于逻辑编程。我们的新转型和
推测定义了等效的加权语言。然而，他们的派生树
在结构上有一个重要的不同：GLCT 取代了左递归
具有正确的递归性，而推测则不然。我们还提供几种
关于输出之间正式关系的技术结果
GLCT、推测和原始语法。最后，我们通过实证研究
GLCT 从 9 的语法中消除左递归的效率
语言。
]]></description>
      <guid>http://arxiv.org/abs/2311.16258</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>预先训练的语言模型无助于自动回归文本到图像的生成。 （arXiv：2311.16201v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.16201</link>
      <description><![CDATA[图像标记器（例如 VQ-VAE）的最新进展已启用
使用自回归方法生成文本到图像，类似于语言
造型。然而，这些方法尚未利用预先训练的语言
模型，尽管它们能够适应各种下游任务。在这项工作中，
我们通过采用预先训练的语言模型来探索这一差距
自回归文本到图像生成，并找到预先训练的语言
模型提供的帮助有限。我们通过分析提供了两方面的解释
来自每种模式的令牌。首先，我们证明图像令牌具有
与文本标记、渲染相比，语义显着不同
预训练语言模型在建模方面并不比随机模型更有效
已初始化的。其次，图像文本数据集中的文本标记太
与普通语言模型预训练数据相比简单，这导致
语言模型能力的灾难性退化。
]]></description>
      <guid>http://arxiv.org/abs/2311.16201</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>ChatTraffc：通过扩散模型生成文本到流量。 （arXiv：2311.16203v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.16203</link>
      <description><![CDATA[流量预测是智能交通最重要的基础之一
运输系统（ITS）。传统的交通预测方法仅依赖于
根据历史流量数据来预测流量趋势，面临两个主要问题
挑战。 1）对异常事件不敏感。 2) 表现不佳
长期预测。在这项工作中，我们探索生成模型如何结合
带有描述交通系统的文本可应用于交通生成
并将任务命名为文本到流量生成 (TTG)。的主要挑战
TTG任务是如何将文本与道路的空间结构关联起来
用于生成交通状况的网络和交通数据。为此，我们
提出 ChatTraffic，第一个用于文本到流量生成的扩散模型。
为了保证合成数据和真实数据之间的一致性，我们增强了
使用图卷积网络（GCN）的扩散模型来提取空间
交通数据的相关性。此外，我们构建了一个大型数据集
包含 TTG 任务的文本-流量对。我们对模型进行了基准测试
对已发布的数据集进行定性和定量分析。实验的
结果表明 ChatTraffic 可以生成真实的交通情况
从文字来看。我们的代码和数据集可在
https://github.com/ChyaZhang/ChatTraffic。
]]></description>
      <guid>http://arxiv.org/abs/2311.16203</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>学习推理技能中长度概括的条件。 （arXiv：2311.16173v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2311.16173</link>
      <description><![CDATA[推理是人工智能代理的一项基本能力。最近，大语
模型（法学硕士）已显示出执行推理任务的卓越能力。
然而，对法学硕士推理能力的大量评估也表明
显示出一些局限性。一个突出的限制是长度泛化，
这意味着当接受较小长度或尺寸的推理问题训练时，
由此产生的模型难以解决较大尺寸或长度的问题。这
潜在地表明了泛化的一些理论局限性
学习推理能力。这些评价和他们的观察激发了
我们对长度泛化问题进行理论研究。这
工作重点是可以表述为马尔可夫动态的推理任务
过程（MDP）和/或有向无环图（DAG）。它识别并
证明决定长度泛化问题能否解决的条件
对于特定表示中的推理任务是否已解决。实验
还对理论结果进行了验证。
]]></description>
      <guid>http://arxiv.org/abs/2311.16173</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>通过异常值检测优化增强情感分析结果。 （arXiv：2311.16185v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.16185</link>
      <description><![CDATA[处理包含主观标签（如说话者）的文本数据时
贴标签者之间的情绪、不准确或差异并不罕见。这样的
差异会显着影响机器学习的性能
算法。这项研究调查了识别和解决问题的潜力
带有主观标签的文本数据中的异常值，旨在增强分类
结果。我们使用了 Deep SVDD 算法，这是一种一类分类
方法，检测九种基于文本的情感和情感分析中的异常值
数据集。通过采用小型语言模型（DistilBERT 基本模型
具有 6600 万个参数）和非深度学习机器学习算法
（决策树、KNN、逻辑回归和 LDA）作为分类器，我们的
研究结果表明，去除异常值可以提高结果
在大多数情况下。此外，由于此类数据集中的异常值不一定是
无法学习，我们体验了使用大型语言模型——DeBERTa v3
具有 1.31 亿个参数，可以捕获非常复杂的模式
数据。我们继续观察多个方面的性能增强
数据集。
]]></description>
      <guid>http://arxiv.org/abs/2311.16185</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>忽略此标题和 HackAPrompt：通过全球规模的即时黑客竞赛揭露法学硕士的系统漏洞。 （arXiv：2311.16119v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2311.16119</link>
      <description><![CDATA[大型语言模型 (LLM) 越来越多地部署在交互式环境中
涉及用户直接参与的环境，例如聊天机器人和写作
助理。这些部署越来越受到即时注入和
越狱（统称为提示黑客攻击），其中模型被操纵以
忽略他们的原始指令，而是遵循潜在的恶意指令
那些。尽管人们普遍认为这是一个重大的安全威胁，但仍有一个
缺乏关于即时黑客攻击的大规模资源和定量研究。到
为了解决这个缺陷，我们发起了一场全球即时黑客竞赛，
允许自由形式的人类输入攻击。我们引发了超过 60 万条对抗性提示
对抗三名最先进的法学硕士。我们描述了数据集，根据经验
验证当前的法学硕士确实可以通过即时黑客攻击进行操纵。我们
还提出了对抗类型的综合分类本体论
提示。
]]></description>
      <guid>http://arxiv.org/abs/2311.16119</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>利用人工智能技术将研究映射到可持续发展目标：案例研究。 （arXiv：2311.16162v1 [cs.DL]）</title>
      <link>http://arxiv.org/abs/2311.16162</link>
      <description><![CDATA[与可持续发展目标相关的出版物数量
（可持续发展目标）持续增长。这些出版物涵盖了不同的领域
研究范围从人文和社会科学到工程和健康。给定
供资机构必须监测成果和影响，将
相关可持续发展目标的出版物至关重要，但仍然耗时且
鉴于可持续发展目标的广度和复杂性，实现这一目标十分困难。出版物可能
与多个目标相关（目标的互连特征），因此
需要多学科知识才能准确标记。机器学习
方法很有前途，并且已被证明对于诸如此类的任务特别有价值
如手动数据标记和文本分类。在这项研究中，我们采用了
以澳大利亚大学的 82,000 多份出版物作为案例研究。我们
利用相似性测量将这些出版物映射到可持续发展
发展目标（SDG）。此外，我们利用 OpenAI GPT 模型
执行相同的任务，便于两者之间的比较分析
接近。实验结果表明，获得的结果约为82.89%
通过相似性度量与输出的重叠（至少一个标签）
GPT 模型。采用的模型（相似性度量）可以补充 GPT 模型
可持续发展目标分类。此外，深度学习方法，包括
这里使用的相似性度量，对于处理更容易访问和信任
无需使用商业人工智能服务或部署敏感数据
运行大型语言模型需要昂贵的计算资源。我们的研究
演示了这两种方法的巧妙组合如何实现可靠的
将研究成果映射到可持续发展目标。
]]></description>
      <guid>http://arxiv.org/abs/2311.16162</guid>
      <pubDate>Wed, 29 Nov 2023 06:18:30 GMT</pubDate>
    </item>
    </channel>
</rss>