<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 07 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>在大型语言模型中优化幽默的产生：温度配置和建筑折衷</title>
      <link>https://arxiv.org/abs/2504.02858</link>
      <description><![CDATA[ARXIV：2504.02858V1公告类型：新 
摘要：大型语言模型（LLMS）证明了创造性文本生成的能力不断提高，但对其幽默产生的系统评估仍未得到充实。这项研究对五个建筑家庭的13个最先进的LLM进行了全面分析，评估了它们在为软件开发人员带来技术相关的幽默方面的表现。通过完整的阶乘设计测试715温度设置和及时变化的独特配置，我们使用五个加权标准评估模型输出：幽默质量，域相关性，概念独创性，音调精度和交付效率。我们的方法采用了严格的统计分析，包括方差分析，相关研究和二次回归，以识别最佳配置和建筑影响。结果揭示了整个模型的显着性能变化，某些架构比基线系统实现了21.8％的优势。温度灵敏度分析表明，有73％的模型在较低的随机性设置下实现峰值性能（&lt;= 0.5），尽管最佳范围范围差异很大。我们确定不同的模型簇：保持效率质量平衡的紧凑型高性能与需要更长的边际收益产出的详细专家。统计验证确认模型体系结构解释了38.7％的性能差异，幽默质量和概念独创性之间存在显着相关性。该研究为模型选择和配置建立了实用指南，证明了温度调整和体系结构考虑如何影响幽默的产生有效性。这些发现提高了对创意技术写作中LLM功能的了解，并为实施幽默生成系统的开发人员提供了经验验证的配置策略。]]></description>
      <guid>https://arxiv.org/abs/2504.02858</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GS_DravidianLangtech@2025：妇女针对社交媒体上的虐待文本检测</title>
      <link>https://arxiv.org/abs/2504.02863</link>
      <description><![CDATA[ARXIV：2504.02863V1公告类型：新 
摘要：越来越多的社交媒体滥用已成为一个问题。但是，正在开发技术解决方案以有效地调节其内容。本文着重于检测针对女性在社交媒体平台上的虐待文本。虐待的言语是指旨在伤害或煽动仇恨弱势个人或团体的沟通。具体而言，本研究旨在确定针对女性的虐待语言。为了实现这一目标，我们利用逻辑回归和BERT作为基本模型来训练从DravidianLangtech@2025来获取泰米尔语和马拉雅拉姆语语言的数据集。在测试数据集上评估了这些模型，在泰米尔语和马拉雅拉姆语中分别为BERT的0.729宏F1得分和0.6279。]]></description>
      <guid>https://arxiv.org/abs/2504.02863</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>物质合同语料库</title>
      <link>https://arxiv.org/abs/2504.02864</link>
      <description><![CDATA[ARXIV：2504.02864V1公告类型：新 
摘要：本文介绍了材料合同语料库（MCC），这是一项公开可用的数据集，由2000年至2023年在美国证券交易委员会（SEC）提交的上市公司超过一百万个合同。MCC促进了有关合同设计和法律语言的经验研究，并支持基于AI的法律工具的开发。语料库中的合同按协议类型进行分类，并使用机器学习和自然语言处理技术与特定方链接，包括用于合同分类的微调Llama-2模型。 MCC进一步提供元数据，例如备案表，文件格式和修正状态。我们记录了随着时间的流逝，合同语言，长度和复杂性的趋势，并强调了SEC申请中就业和安全协议的主导地位。该资源可用于批量下载和在线访问，请访问https://mcc.law.stanford.edu。]]></description>
      <guid>https://arxiv.org/abs/2504.02864</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>幻觉主义者的提示：以语言上的细微差别揭露大语言模型的事实漏洞</title>
      <link>https://arxiv.org/abs/2504.02865</link>
      <description><![CDATA[ARXIV：2504.02865V1公告类型：新 
摘要：随着大型语言模型（LLMS）继续发展，非专家用户越来越依赖它们作为实时信息来源。为了确保其提供的信息的事实，许多研究集中在减轻LLM响应中的幻觉上，但仅在正式的用户查询的背景下而不是恶性制作的情况下。在这项研究中，我们介绍了幻觉主义者的提示，这是一种新颖的幻觉攻击，将语言细微差别纳入了对抗性查询中，从而挑战了LLMS对五种事实增强策略的事实准确性。我们的攻击会自动产生高度转移的虚幻提示，以引起内部事实错误，同时保留用户意图和语义。广泛的实验证实了我们攻击在损害黑盒LLM中的有效性，包括GPT-4O和Gemini-2.0等商业API，即使具有各种防御机制。]]></description>
      <guid>https://arxiv.org/abs/2504.02865</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多代理LLM法官：用于评估自然语言生成应用的自动个性化LLM法官设计</title>
      <link>https://arxiv.org/abs/2504.02867</link>
      <description><![CDATA[ARXIV：2504.02867V1公告类型：新 
摘要：大型语言模型（LLM）在各种领域表现出了令人印象深刻的表现，但它们仍然遇到挑战，例如特定于领域的知识，偏见和幻觉。这强调了对可靠的评估方法的需求，以准确评估基于LLM的应用程序。依靠单词重叠或文本嵌入的传统评估方法不足以捕获评估动态，开放式文本生成所需的细微差别语义信息。最近的研究探索了利用LLM模仿人类推理和决策过程的评估目的，称为LLM-AS-A-A-Gudge框架。但是，这些现有的框架有两个重大局限性。首先，他们缺乏适应不同文本样式的灵活性，包括各种答案和地面真相样式，从而降低了它们的概括性能。其次，这些框架产生的评估得分通常偏向且难以解释，显示出与人类判断的低相关性。为了应对这些挑战，我们提出了一个新型的动态多机构系统，该系统会自动为各种自然语言生成应用设计个性化的LLM法官。该系统迭代地完善评估的提示和平衡了下游任务的适应性要求与与人类感知的一致性之间的权衡。我们的实验结果表明，与现有方法相比，拟议的多代理LLM法官框架不仅提高了评估精度，而且还产生了与人类感知更好一致的评估评分。]]></description>
      <guid>https://arxiv.org/abs/2504.02867</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用LLMS招聘AI：一种恢复筛选的上下文感知和可解释的多代理框架</title>
      <link>https://arxiv.org/abs/2504.02870</link>
      <description><![CDATA[ARXIV：2504.02870V1公告类型：新 
摘要：恢复筛查是人才获取的关键但时间密集的过程，要求招聘人员分析大量的工作应用程序，同时保持客观，准确和公平。随着大语言模型（LLM）的进步，其推理能力和广泛的知识库展示了简化和自动化招聘工作流程的新机会。在这项工作中，我们提出了一个多代理框架，用于使用LLMS进行系统处理和评估简历的恢复筛查。该框架由四个核心代理组成，包括简历提取器，一个评估者，摘要和分数格式化器。为了增强候选人评估的上下文相关性，我们在简历评估者中整合了检索功能的生成（RAG），允许纳入外部知识来源，例如特定于行业的专业知识，专业认证，大学排名和公司特定的雇用标准。这种动态的适应能够实现个性化的招聘，弥合了AI自动化和人才掌握之间的差距。我们通过将AI生成的分数与人力资源专业人员在匿名在线简历的数据集上的评级进行比较，来评估我们的方法的有效性。这些发现突出了多代理RAG-LLM系统在自动化简历筛选中的潜力，从而实现了更有效，可扩展的招聘工作流程。]]></description>
      <guid>https://arxiv.org/abs/2504.02870</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>综合注释指南是用于临床信息提取的知识同名助推器</title>
      <link>https://arxiv.org/abs/2504.02871</link>
      <description><![CDATA[ARXIV：2504.02871V1公告类型：新 
摘要：使用大语言模型提取生成信息，尤其是通过几次学习，已成为一种流行的方法。最近的研究表明，提供详细的，可读的准则类似于传统训练人类注释者的注释指南可以显着提高性能。但是，构建这些准则既是劳动和知识密集型的。此外，这些定义通常是为满足特定需求而量身定制的，使其高度特定于任务，而且通常不可用。处理这些微妙的差异需要大量的努力和对细节的关注。在这项研究中，我们提出了一种自我改善方法，该方法可以收获LLM的知识摘要和文本生成能力，以合成注释指南，同时几乎不需要人类的投入。我们在临床指定实体识别基准，2012 I2B2事件，2012 I2B2 TimeX，2014 I2B2和2018 N2C2上进行的零射击实验显示25.86％，4.36％，0.20％和7.75％的scores scores scores score score vrom-not-not-not-noce scores scores scores scores scores scores scores scores的提高了25.86％，4.36％，0.20％。在大多数任务中，LLM合成指南与人写的指南相比表现出同等或更好的性能。总之，这项研究提出了一种新型的LLM自我改善方法，该方法需要最少的知识和人类的输入，并且适用于多个生物医学领域。]]></description>
      <guid>https://arxiv.org/abs/2504.02871</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>刮去阴影：深层网络智能中的深度学习突破</title>
      <link>https://arxiv.org/abs/2504.02872</link>
      <description><![CDATA[ARXIV：2504.02872V1公告类型：新 
摘要：DarkNet市场（DNM）在全球范围内促进了非法商品的贸易。在DNM上收集数据对于确保执法机构可以有效地打击犯罪至关重要。从DNM中手动提取数据是一项容易出错的和耗时的任务。 Aiming to automate this process we develop a framework for extracting data from DNMs and evaluate the application of three state-of-the-art Named Entity Recognition (NER) models, ELMo-BiLSTM \citep{ShahEtAl2022}, UniversalNER \citep{ZhouEtAl2024}, and GLiNER \citep{ZaratianaEtAl2023}, at the task of extracting complex DNM产品清单中的实体。我们提出了一个新的注释数据集，我们用来训练，微调和评估模型。我们的发现表明，最新的NER模型在DNM中的信息提取方面表现良好，达到91％的精度，96％的召回和94％的F1分数。此外，通过环球影业可以实现最佳性能，微调可以增强模型性能。]]></description>
      <guid>https://arxiv.org/abs/2504.02872</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>短phd：检测简短的LLM生成的文本，并在主题内容插入后使用拓扑数据分析</title>
      <link>https://arxiv.org/abs/2504.02873</link>
      <description><![CDATA[ARXIV：2504.02873V1公告类型：新 
摘要：大语言模型（LLM）的恶意用法激发了LLM生成的文本的检测。拓扑数据分析中的先前工作表明，与其他零射击方法相比，文本嵌入的持续同源性维度（PHD）可以作为更强和有希望的分数。但是，有效检测简短的LLM生成的文本仍然是一个挑战。本文介绍了短时间的零照片LLM生成的文本检测方法，该方法是针对短文本量身定制的。短phD通过在给定输入文本之前插入非主题内容，并根据已建立的检测阈值识别LLM生成的文本，从而稳定了先前的PHD方法的估计。公共和生成数据集的实验结果表明，在简短的LLM生成的文本检测中，短时间phD的表现优于现有的零摄像方法。实施代码可在线提供。]]></description>
      <guid>https://arxiv.org/abs/2504.02873</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>thebluescrubs-v1，一种从互联网得出的全面策划的医疗数据集</title>
      <link>https://arxiv.org/abs/2504.02874</link>
      <description><![CDATA[ARXIV：2504.02874V1公告类型：新 
摘要：鉴于目前可用的公共存储库通常被证明过于有限或范围，无法进行全面的医疗用途，因此对培训临床大语言模型（CLLM）的强大和多样化数据集的需求至关重要。尽管PubMed等资源提供了基础医学文献，但它们仅捕获了狭窄的正式出版物，并忽略了互联网上更广泛的医学话语。为了解决这些赤字，我们介绍了thebluescrubs -v1，这是一个超过250亿个医疗令牌的数据集（比PubMed大的三倍），是从广泛的互联网语料库中绘制的。我们的两阶段过滤管道采用逻辑回归模型进行文档筛选（在外部验证时达到约0.95的AUC），然后通过70B参数Llama 3.1指示模型进行验证。每个文本都分配了三个基于LLM的质量分数，其中包括医学相关性，精度和事实细节以及安全性和道德标准。临床医生的评论证实了与这些自动化评估的高度一致性，并且专门的癌症分类器进一步标记了约110亿个肿瘤学标记。两个演示任务突出了数据集的实际价值：首先，我们将安全性评估提炼成一个较小的BERT风格模型，该模型在看不见的数据上达到了接近0.96的AUC；其次，我们在过滤的子集上微调了紧凑型LLM，显示了对医疗基准和私人基准中标准基准的可测量改进。该数据描述符详细介绍了数据集的创建和验证，并强调了其在医疗AI研究中的潜在实用性。]]></description>
      <guid>https://arxiv.org/abs/2504.02874</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新访问现代LLM架构的漏斗变压器，并在培训和推理配置中进行全面消融</title>
      <link>https://arxiv.org/abs/2504.02877</link>
      <description><![CDATA[ARXIV：2504.02877V1公告类型：新 
摘要：基于变形金刚的大型语言模型，遭受了高度计算成本的影响，以至于不能保证为简化早期迭代而提出的技术受益于更现代的模型。在Dai和Le（2020）提出的漏斗变压器的基础上，该漏斗逐渐压缩了中间表示，我们研究了漏斗在当代Gemma2变形金刚建筑中的影响。我们系统地评估了各种漏斗配置和恢复方法，比较：（1）标准预处理与漏斗意识的预处理策略，（2）漏斗感知的微调的影响，以及（3）序列恢复操作的类型。我们的结果表明，漏斗会创建信息瓶颈，这些信息通过更深的网络层传播，尤其是在较大的模型（例如Gemma 7b）中，导致有时无法控制的性能丢失。但是，仔细选择漏斗层并采用有效的恢复策略，可以大大减轻绩效损失，从而减少44％的潜伏期。我们的发现突出了计算效率和模型准确性之间的关键权衡，为在大型自然语言应用中部署基于漏斗的方法提供了实用的指导。]]></description>
      <guid>https://arxiv.org/abs/2504.02877</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>更好的法案GPT：将大型语言模型与法律发票审稿人进行比较</title>
      <link>https://arxiv.org/abs/2504.02881</link>
      <description><![CDATA[ARXIV：2504.02881V1公告类型：新 
摘要：法律发票审查是一个昂贵，不一致且耗时的过程，传统上是由法律运营，律师或计费专家执行的，他们逐行审查计费合规性。这项研究介绍了大语模型（LLM）与人类发票审稿人的首次经验比较 - 早期职业律师，经验丰富的律师和法律运营专业人士，并评估其准确性，速度和成本效益。我们的经验证实的发现，根据专家法律专业人士设定的基本真理进行基准测试，表明LLM果断地超过了每个指标的人类。在发票批准的决定中，LLMS的准确性高达92％，超过了经验丰富的律师设定的72％上限。在颗粒状水平上，LLM占主导地位的行分类，顶级模型达到81％，而表现最佳的人类群体仅为43％。速度比较甚至更为惊人 - 虽然律师每张发票需要194至316秒，但LLMS能够在3.6秒内完成评论。费用？ AI将审查费用削减了99.97％，将发票处理成本从平均每张发票4.27美元降低到人类发票审稿人的平均$ 4.27。这些结果突出了AI在法律支出管理中的不断发展的作用。随着律师事务所和公司法律部门与效率低下的斗争，这项研究标志着地震转变：LLM驱动的法律支出管理的时代没有到来，它已经到来了。面临的挑战不是AI是否可以像人类审稿人一样执行，而是法律团队将如何战略性地纳入自动化与人类自由裁量权之间。]]></description>
      <guid>https://arxiv.org/abs/2504.02881</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Diatool-DPO：对工具增强大型语言模型的多转弯直接优先优化</title>
      <link>https://arxiv.org/abs/2504.02882</link>
      <description><![CDATA[ARXIV：2504.02882V1公告类型：新 
摘要：工具增强的Larage语言模型（TA-LLMS）在现实世界中显示了希望，但是在处理不完整的查询和范围内请求时面临挑战。尽管现有方法主要依赖于专家轨迹的监督微调，但我们提出了Diatool-DPO，这是一种新颖的方法，可以通过直接偏好优化来增强TA-LLM的对话能力。我们将TA-LLM交互作用模型为Markov决策过程，该过程具有5个不同的对话状态，并根据其状态过渡轨迹将用户查询分为3种类型。我们会自动构建正确和不正确的对话流的配对轨迹数据集，并引入对话控制的专门客观损失。我们的全面评估表明，Diatool-DPO的方法是GPT-4O的绩效（在信息收集中为94.8％，工具呼叫拒绝的91％），比基线进行了实质性改进（分别为44％和9.6％），同时保持核心功能。我们的方法为开发可以处理各种现实世界情景的ta-llms开辟了新的可能性，而无需其他专家演示或人类标签。]]></description>
      <guid>https://arxiv.org/abs/2504.02882</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Semeval-2025任务4：从大语言模型中学习敏感内容</title>
      <link>https://arxiv.org/abs/2504.02883</link>
      <description><![CDATA[ARXIV：2504.02883V1公告类型：新 
摘要：我们介绍了Semeval-2025任务4：来自大语言模型（LLMS）的敏感内容。该任务具有3个针对LLM学习的子任务，涵盖了不同的用例：（1）跨越不同类型的综合形式的综合创意文档； （2）未读书的简短形式的合成传记，其中包含个人身份信息（PII），包括伪造名称，电话号码，SSN，电子邮件和家庭地址，以及（3）从目标模型的培训数据集中采样的未了解的真实文档。我们收到了来自30多个机构的100多种提交，并总结了本文的关键技术和课程。]]></description>
      <guid>https://arxiv.org/abs/2504.02883</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LVMED-R2：医学报告生成的感知和反射驱动的复杂推理</title>
      <link>https://arxiv.org/abs/2504.02885</link>
      <description><![CDATA[ARXIV：2504.02885V1公告类型：新 
摘要：大型视觉模型（LVM）对自动化医学报告的生成有很大的希望，可能减少手动报告的负担。最先进的（SOTA）研究通过医学数据进行微型LVM，以使放射学图像与相应的医学报告保持一致。但是，有两个关键因素限制了这些LVM的性能。首先，LVM缺乏复杂的推理能力，从而导致逻辑上的不一致和生成报告中的潜在诊断错误。其次，LVM缺乏反射机制，从而导致无法在思维过程中发现错误。为了解决这些差距，我们提出了LVMED-R2，这是一种新的微调策略，介绍了LVM的复杂推理和反思机制，以增强医疗报告的生成。据我们所知，这是第一项将复杂推理引入医疗报告（MRG）任务的工作。我们提出的复杂推理包含医学知识注入和感知增强模块，可提高LVMS诊断的准确性，并与感知树相结合，以提供指导以限制感知范围。此外，反射机制迫使输出自我验证以纠正潜在误差。我们使用IU-XRAR和MIMIC-CXR数据集对我们提出的LVMED-R2策略进行了微调LVM的实验。我们的结果是根据自然语言产生（NLG）指标和临床功效（CE）指标衡量的，表明，使用拟议的反射机制对LVM进行了微调，具有有效地纠正输出和复杂推理并改善MRG的LVMS性能的能力。]]></description>
      <guid>https://arxiv.org/abs/2504.02885</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>