<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Fri, 12 Jan 2024 03:15:21 GMT</lastBuildDate>
    <item>
      <title>DrawTalking：通过素描和演讲构建互动世界。 （arXiv：2401.05631v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2401.05631</link>
      <description><![CDATA[我们引入了一种交互式方法，DrawTalking，用户可以在其中构建
通过素描和说话来互动世界。它强调用户控制和
灵活性，并且无需代码即可提供类似编程的功能。我们实施了
在 iPad 上。一项开放式研究表明，这些机制会产生共鸣，并且
适用于许多创意探索用例。我们希望能够启发和
为未来以用户为中心的自然界面的研究提供信息。
]]></description>
      <guid>http://arxiv.org/abs/2401.05631</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:21 GMT</pubDate>
    </item>
    <item>
      <title>语言方言的自然语言处理：调查。 （arXiv：2401.05632v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.05632</link>
      <description><![CDATA[最先进的自然语言处理 (NLP) 模型经过以下方面的训练
海量训练语料库，并在评估中表现出色
数据集。这项调查深入研究了这些数据集的一个重要属性：
一种语言的方言。受 NLP 模型性能下降的推动
辩证数据集及其对语言公平性的影响
技术，我们根据数据集调查了过去的 NLP 方言研究，
和方法。我们用以下两个方面描述了广泛的 NLP 任务
类别：自然语言理解（NLU）（用于方言等任务
分类、情感分析、解析和 NLU 基准）和自然
语言生成 (NLG)（用于摘要、机器翻译和对话
系统）。该调查的语言覆盖面也很广泛，其中包括
英语、阿拉伯语、德语等。我们观察到 NLP 领域过去的工作
关于方言的内容比单纯的方言分类更深入，并且。这
包括使用句子转导的早期方法，这些方法导致
最近将超网络集成到 LoRA 中的方法。我们期望这
调查对于有兴趣建立公平的 NLP 研究人员很有用
通过重新思考 LLM 基准和模型架构来改进语言技术。
]]></description>
      <guid>http://arxiv.org/abs/2401.05632</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:21 GMT</pubDate>
    </item>
    <item>
      <title>微调大型语言模型时遗忘的缩放定律。 （arXiv：2401.05605v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.05605</link>
      <description><![CDATA[我们研究并量化微调预训练时的遗忘问题
下游任务的大型语言模型（LLM）。我们发现
参数高效微调（PEFT）策略，例如低阶适配器
（LoRA），仍然遭受灾难性遗忘。特别是，我们确定了一个
微调性能与
使用 LoRA 微调 LLM 时的遗忘量。我们进一步得到精确的
表明遗忘随着幂律变化而增加的标度律
微调参数的数量和更新步骤的数量。我们还检查
遗忘对知识、推理和安全护栏的影响
训练进入 Llama 2 7B 聊天。我们的研究表明遗忘不可能
通过提前停止或改变参数数量来避免
微调。我们相信这为以下领域开辟了一个重要的安全关键方向：
未来的研究来评估和开发微调方案，以减轻
遗忘
]]></description>
      <guid>http://arxiv.org/abs/2401.05605</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:20 GMT</pubDate>
    </item>
    <item>
      <title>在大型语言模型中解决问题的简洁思想链的好处。 （arXiv：2401.05618v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.05618</link>
      <description><![CDATA[在本文中，我们介绍了简洁思维链（CCoT）提示。我们
比较标准 CoT 和 CCoT 提示，了解简洁性如何影响响​​应
长度和正确答案的准确性。我们使用 GPT-3.5 和 GPT-4 对此进行了评估
具有多项选择问答（MCQA）基准。 CCoT 降低
GPT-3.5 和 GPT-4 的平均响应长度增加了 48.70%，同时具有
对解决问题的能力的影响可以忽略不计。然而，在数学问题上，
带有 CCoT 的 GPT-3.5 会导致 27.69% 的性能损失。总体而言，CCoT 领先
每个代币的平均成本降低了 22.67%。这些成果具有实用性
对使用法学硕士解决现实问题的人工智能系统工程师的影响
使用 CoT 即时工程技术。此外，这些结果还提供了更多
人工智能研究人员研究突发行为的一般见解
法学硕士中的逐步推理。
]]></description>
      <guid>http://arxiv.org/abs/2401.05618</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:20 GMT</pubDate>
    </item>
    <item>
      <title>REBUS：理解符号的稳健评估基准。 （arXiv：2401.05604v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.05604</link>
      <description><![CDATA[我们提出了一个新的基准来评估多式联运大数据的性能
画画谜题的语言模型。该数据集涵盖 333 个原始示例
基于图像的双关语，线索 13 个类别，例如电影、作曲家、专业
城市、食物。在识别基准上取得良好的表现
线索单词或短语，模型必须结合图像识别和字符串
通过假设检验、多步推理和
对人类认知的理解，进行复杂的多模式评估
的能力。我们发现 GPT-4V 和 Gemini Pro 等专有型号
显着优于所有其他测试模型。然而，即使是最好的模型
最终准确率仅为 24%，这凸显了需要大量
推理方面的改进。此外，模型很少能够理解系统的所有部分
难题，并且几乎总是无法追溯地解释正确的
回答。因此，我们的基准可以用来识别主要缺陷
多模态大语言模型的知识和推理。
]]></description>
      <guid>http://arxiv.org/abs/2401.05604</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:19 GMT</pubDate>
    </item>
    <item>
      <title>潜伏特工：通过安全培训持续培训欺骗性法学硕士。 （arXiv：2401.05566v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2401.05566</link>
      <description><![CDATA[人类能够进行策略性的欺骗行为：在以下方面表现得有帮助：
大多数情况下，但为了追求而表现得非常不同
如果有机会的话，可以选择其他目标。如果人工智能系统学会了这样的
一种欺骗性策略，我们能否检测到它并使用电流将其删除
最先进的安全培训技术？为了研究这个问题，我们
用大语言构建欺骗行为的概念验证示例
模型（法学硕士）。例如，我们训练在以下情况下编写安全代码的模型：
提示指出年份是 2023 年，但在以下情况下插入可利用代码：
指定年份是 2024 年。我们发现可以进行这种后门行为
持久性，因此标准安全培训技术不会消除它，
包括监督微调、强化学习和对抗性
培训（引发不安全行为，然后进行培训以消除这种行为）。这
后门行为在最大的模型和模型中最为持久
接受训练以产生有关欺骗训练的思维链推理
过程，即使思想链已被打破，仍能坚持下去
蒸馏掉。此外，我们发现，不是删除后门，而是
对抗性训练可以教会模型更好地识别他们的后门
触发，有效隐藏不安全行为。我们的结果表明，
一旦模型表现出欺骗行为，标准技术可能无法
消除此类欺骗并造成安全的假象。
]]></description>
      <guid>http://arxiv.org/abs/2401.05566</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:18 GMT</pubDate>
    </item>
    <item>
      <title>POMP：针对低资源无监督神经机器翻译法学硕士的概率驱动元图提示器。 （arXiv：2401.05596v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.05596</link>
      <description><![CDATA[低资源语言（LRL）在监督神经机器中面临挑战
由于并行数据有限而导致翻译，促使研究无监督
方法。无监督神经机器翻译 (UNMT) 方法，包括
反向翻译、迁移学习和基于枢轴的翻译，提供
LRL 翻译的实用解决方案，但它们受到以下问题的阻碍
合成数据噪声、语言偏差和错误传播，这可以
大型语言模型 (LLM) 可能会缓解这一问题。 LLM 已取得进步
NMT 具有上下文学习（ICL）和监督微调方法，但是
训练数据不足会导致 LRL 性能不佳。我们认为
法学硕士可以通过辅助语言来减轻语言噪音，以提高
LRL 中的翻译。在本文中，我们提出了概率驱动的元图
Prompter (POMP)，一种采用动态、基于采样的图的新颖方法
多种辅助语言，增强法学硕士的翻译能力
LRL。 POMP 涉及为每个源构建有向非循环元图
语言，我们从中动态采样多个路径以提示法学硕士
在训练期间减轻语言噪音并改进翻译。我们用
用于评估翻译和反向传播奖励的 BLEURT 指标，
通过分数估计，更新辅助语言的概率
路径。我们的实验表明翻译质量显着提高
三个 LRL，证明了我们方法的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2401.05596</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:18 GMT</pubDate>
    </item>
    <item>
      <title>有用的错误：自动语音识别错误可以改善下游痴呆症分类吗？ （arXiv：2401.05551v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.05551</link>
      <description><![CDATA[\textbf{目标}：我们旨在研究自动语音中的错误是如何产生的
识别 (ASR) 系统会影响痴呆症分类的准确性，特别是
在“饼干盗窃”图片描述任务中。我们的目的是评估是否
不完美的 ASR 生成的转录本可以为以下方面提供有价值的信息：
区分来自认知健康个体的语言样本
以及患有阿尔茨海默病 (AD) 的人。

\textbf{方法}：我们使用各种 ASR 模型进行了实验，改进了
他们的成绩单采用后期编辑技术。这两个都不完美的 ASR
转录本和手动转录的转录本被用作
下游痴呆分类。我们进行了全面的错误分析
比较模型性能并评估 ASR 生成的转录本有效性
在痴呆症分类中。

\textbf{结果}：令人惊讶的是，ASR 生成的转录本不完美
在区分具有以下特征的个体方面优于手动转录
AD 和那些没有参与“Cookie 盗窃”任务的人。这些基于 ASR 的模型
超越了之前最先进的方法，表明 ASR 错误
可能包含与痴呆症相关的有价值的线索。 ASR 和 ASR 之间的协同作用
分类模型提高了痴呆症分类的整体准确性。

\textbf{结论}：不完美的 ASR 转录本有效地捕获了语言
与痴呆症相关的异常现象，提高分类任务的准确性。这
ASR 和分类模型之间的协同作用凸显了 ASR 作为
评估认知障碍和相关临床的宝贵工具
应用程序。
]]></description>
      <guid>http://arxiv.org/abs/2401.05551</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>TrustLLM：大型语言模型中的可信度。 （arXiv：2401.05561v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.05561</link>
      <description><![CDATA[以 ChatGPT 为代表的大型语言模型 (LLM) 已经取得了进展
其出色的自然语言处理能力备受关注
能力。尽管如此，这些法学硕士提出了许多挑战，特别是在
诚信的境界。因此，确保法学硕士的可信度
成为一个重要的话题。本文介绍了 TrustLLM，一个综合性的
法学硕士的可信度研究，包括不同维度的原则
的可信度，建立基准，评估和分析
主流法学硕士的可信度，以及对开放挑战和问题的讨论
未来发展方向。具体来说，我们首先提出了一套原则
值得信赖的法学硕士，涵盖八个不同的维度。基于这些
原则，我们进一步建立了六个维度的基准，包括
真实性、安全性、公平性、稳健性、隐私性和机器道德。我们
然后提出了一项评估 TrustLLM 中 16 个主流法学硕士的研究，其中包括
超过30个数据集。我们的研究结果首先表明，总体而言，可信度和
效用（即功能有效性）呈正相关。其次，我们的
观察表明，专有法学硕士通常优于大多数开源法学硕士
同行的可信度，引起人们对潜在的担忧
广泛使用的开源法学硕士的风险。然而，一些开源法学硕士
非常接近专有的。第三，值得注意的是，有些
法学硕士可能会过度校准以表现出可信度，在某种程度上
他们错误地将良性提示视为
有害并因此不响应。最后我们强调一下重要性
不仅要确保模型本身的透明度，还要确保模型本身的透明度
支撑可信度的技术。了解具体的值得信赖
已采用的技术对于分析其技术至关重要
效力。
]]></description>
      <guid>http://arxiv.org/abs/2401.05561</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>InfiAgent-DABench：评估代理的数据分析任务。 （arXiv：2401.05507v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.05507</link>
      <description><![CDATA[在本文中，我们介绍了第一个基准测试“InfiAgent-DABench”
专门设计用于评估数据分析任务中基于 LLM 的代理。这
benchmark包含DAEval，一个由311个数据分析问题组成的数据集
源自 55 个 CSV 文件，以及一个将 LLM 作为数据进行评估的代理框架
分析剂。我们采用格式提示技术，确保问题
是可以自动评估的封闭形式。我们广泛的基准测试
23 位最先进的法学硕士揭示了当前数据中遇到的挑战
分析任务。此外，我们还开发了DAAgent，一种专门的代理
在指令调整数据集上进行训练。评估数据集和工具包
InfiAgent-DABench 发布于 https://github.com/InfiAgent/InfiAgent。
]]></description>
      <guid>http://arxiv.org/abs/2401.05507</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>从潘帕斯草原到像素：微调加乌乔遗产的扩散模型。 （arXiv：2401.05520v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.05520</link>
      <description><![CDATA[生成式人工智能已在社会中普及，并见证了重大变革
各个领域的进步。特别是在文本到图像领域
(TTI) 模型、潜在扩散模型 (LDM) 展示了卓越的功能
根据文本提示生成视觉内容。本文讨论了
LDM在代表当地文化概念、历史人物、
和濒危物种。在这项研究中，我们利用里约热内卢的文化遗产
巴西南大州 (RS) 作为说明性案例。我们的目标是
有助于更广泛地理解生成模型如何帮助
捕捉并保存地区的文化和历史特征。论文
概述了方法，包括主题选择、数据集创建和
微调过程。结果展示了生成的图像，以及
每个概念的挑战和可行性。总之，这项工作表明
这些模型代表和保留多样化的独特方面的力量
地区和社区。
]]></description>
      <guid>http://arxiv.org/abs/2401.05520</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>CodePrompt：通过即时学习利用知识特征改进源代码相关分类。 （arXiv：2401.05544v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.05544</link>
      <description><![CDATA[研究人员探索了利用预训练语言的潜力
模型，例如 CodeBERT，用于改进与源代码相关的任务。以前的
研究主要依赖于 CodeBERT 的文本嵌入能力和
“[CLS]”句子嵌入信息作为语义表示
微调下游源代码相关任务。然而，这些方法
需要额外的神经网络层来提取有效特征，
导致更高的计算成本。此外，现有的方法已经
没有利用源代码和相关内容中包含的丰富知识
文本，这可能会导致准确性降低。本文提出了一种新颖的方法，
CodePrompt，利用从预先训练的模型中调用的丰富知识
提示学习和注意机制，以改进源代码相关
分类任务。我们的方法最初通过以下方式激发语言模型
提示信息检索与输入相关的丰富知识
代表性特征，从而避免需要额外的神经网络
层并降低计算成本。随后，我们使用注意力
为每个任务聚合多层相关知识的机制
最终特征以提高其准确性。我们进行了广泛的实验
四个与下游源代码相关的任务来评估我们的方法和我们的
结果表明 CodePrompt 实现了新的最先进性能
提高准确性指标，同时还节省计算成本
能力。
]]></description>
      <guid>http://arxiv.org/abs/2401.05544</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>通过对抗性权重扰动和特定于指标的注意力池来提高论文评分。 （arXiv：2401.05433v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.05433</link>
      <description><![CDATA[这项研究的目的是改进设计的自动反馈工具
通过利用数据科学为英语语言学习者 (ELL) 提供帮助
涵盖机器学习、自然语言处理等技术
教育数据分析。自动论文评分（AES）研究已取得进展
在评估书面论文方面取得了长足的进步，但往往忽视了具体的需求
英语语言学习者 (ELL) 语言发展的影响。这项研究
探索应用BERT相关技术来增强评估
AES 中 ELL 的写作能力。

为了满足 ELL 的特定需求，我们建议使用 DeBERTa，这是一个
最先进的神经语言模型，用于改进自动反馈工具。
DeBERTa，使用自我监督学习在大型文本语料库上进行预训练，
学习适应各种自然语言的通用语言表示
了解任务。该模型融合了多项创新技术，
包括通过对抗权重扰动（AWP）进行对抗训练
以及 Metric-specific AttentionPooling（6 种 AP），用于每个标签
竞赛。

这项研究的主要重点是调查
超参数，特别是对抗性学习率，对性能的影响
模型的。通过微调超参数调整过程，包括
6AP和AWP的影响，所得模型可以提供更准确的
评估语言能力并支持量身定制的学习任务
ELL。这项工作有可能通过改善 ELL 显着受益
他们的英语语言能力并促进他们的教育旅程。
]]></description>
      <guid>http://arxiv.org/abs/2401.05433</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:15 GMT</pubDate>
    </item>
    <item>
      <title>LLM4PLC：利用大型语言模型对工业控制系统中的 PLC 进行可验证的编程。 （arXiv：2401.05443v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2401.05443</link>
      <description><![CDATA[尽管大型语言模型 (LLM) 已在以下领域确立了主导地位：
自动代码生成，它们并非没有缺点。相关的
问题主要涉及生成的项目缺乏执行保证
代码，缺乏可解释性，以及对必要但利基市场的次优支持
编程语言。 GPT-4 和 LLaMa2 等最先进的法学硕士未能
为由以下机构运营的工业控制系统 (ICS) 生成有效的程序
可编程逻辑控制器 (PLC)。我们提出 LLM4PLC，一个用户引导的
利用用户反馈和外部验证工具的迭代管道
包括语法检查器、编译器和 SMV 验证器，以指导 LLM 的学习
一代。我们通过采用以下方式进一步增强法学硕士的生成潜力
通过创建和使用快速工程和模型微调
LoRA。我们使用 FischerTechnik Manufacturing TestBed 验证该系统
（MFTB），说明法学硕士如何从产生结构性缺陷中发展而来
为工业应用生成可验证正确的程序的代码。我们
在 GPT-3.5、GPT-4、Code Llama-7B（经过微调的代码）上运行完整的测试套件
Llama-7B 模型、Code Llama-34B 和经过微调的 Code Llama-34B 模型。这
拟议的管道将发电成功率从 47% 提高到 72%，并且
专家调查代码质量从 2.25/10 到 7.75/10。为推动开放
研究，我们分享完整的实验设置，法学硕士微调
重量，以及我们网站上不同程序的视频演示
专用网页。
]]></description>
      <guid>http://arxiv.org/abs/2401.05443</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:15 GMT</pubDate>
    </item>
    <item>
      <title>使用法学硕士自动评估学生的代码理解能力。 （arXiv：2401.05399v1 [cs.CY]）</title>
      <link>http://arxiv.org/abs/2401.05399</link>
      <description><![CDATA[评估学生的答案，特别是自然语言答案是一个
教育领域面临的重大挑战。机器学习的进步，
包括基于变压器的模型，例如大型语言模型（LLM），
导致各种自然语言任务取得重大进展。尽管如此，
在跨不同任务评估法学硕士的日益增长的趋势中，评估
自动答案评估领域的法学硕士尚未获得太多关注
注意力。为了解决这一差距，我们探索了使用法学硕士的潜力
自动评估学生的简短且开放式的答案。特别是，我们
使用法学硕士将学生的解释与专家的解释进行比较
计算机程序逐行解释的上下文。

出于比较目的，我们评估了大型语言模型 (LLM) 和
基于编码器的语义文本相似度（STS）模型
评估学生对计算机代码的解释的正确性。我们的
研究结果表明，法学硕士在少量镜头和思维链的提示下
在评估方面，设置的性能与基于微调编码器的模型相当
学生在编程领域的简短回答。
]]></description>
      <guid>http://arxiv.org/abs/2401.05399</guid>
      <pubDate>Fri, 12 Jan 2024 03:15:14 GMT</pubDate>
    </item>
    </channel>
</rss>