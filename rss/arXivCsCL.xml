<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Wed, 31 Jan 2024 03:14:19 GMT</lastBuildDate>
    <item>
      <title>利用专业放射科医生的专业知识来增强法学硕士对放射学报告的评估。 （arXiv：2401.16578v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.16578</link>
      <description><![CDATA[在放射学领域，人工智能 (AI) 显着推进了报告
生成，但对这些人工智能生成的报告的自动评估仍然存在
具有挑战性的。当前指标，例如传统自然语言生成
（NLG）和临床疗效（CE），通常无法捕捉语义
临床背景的复杂性或过分强调临床细节，破坏了
报告清晰。为了克服这些问题，我们提出的方法协同
拥有大型语言模型 (LLM) 的专业放射科医生的专业知识，例如
GPT-3.5 和 GPT-4 1. 利用上下文指令学习（ICIL）和链
思想（CoT）推理，我们的方法将法学硕士评估与
放射科医生标准，实现人类和人工智能之间的详细比较
生成的报告。回归模型进一步增强了这一点
汇总句子评估分数。实验结果表明我们的
“Detailed GPT-4 (5-shot)”模型获得了 0.48 的分数，优于
METEOR 指标提高了 0.19，而我们的“回归 GPT-4”模型显示出更高
与专家评估一致，超出现有最佳指标 0.35
利润。此外，我们的解释的稳健性已通过
彻底的迭代策略。我们计划公开发布注释
放射学专家，为未来评估的准确性制定了新标准。
这强调了我们的方法在提高质量方面的潜力
评估人工智能驱动的医疗报告。
]]></description>
      <guid>http://arxiv.org/abs/2401.16578</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:19 GMT</pubDate>
    </item>
    <item>
      <title>基于自动编码器的领域学习，用于与概念空间的语义通信。 （arXiv：2401.16569v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.16569</link>
      <description><![CDATA[沟通的目的是准确传达意思，而不是
准确地传输符号已成为人们日益关注的领域。这
范式，称为语义沟通，通常利用现代
人工智能和机器学习的发展，以改善
通信系统的效率和鲁棒性。然而，标准模型
缺乏捕捉和量化“意义”细节的方法，许多
采用黑盒框架的领先语义通信方法
对模型到底在学习什么知之甚少。一种解决方案
是利用概念空间框架，该框架明确地模拟意义
以几何方式。尽管之前的工作研究了语义交流
概念空间已经显示出有希望的结果，这些先前的尝试涉及
手工制作概念空间模型，严重限制了可扩展性和
该方法的实用性。在这项工作中，我们开发了一个学习框架
仅使用高级原始数据的概念空间模型的域
属性标签。在使用 MNIST 和 CelebA 数据集的实验中，我们展示了
使用该框架学习的领域保持语义相似性
关系并具有可解释的维度。
]]></description>
      <guid>http://arxiv.org/abs/2401.16569</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:18 GMT</pubDate>
    </item>
    <item>
      <title>超越图像-文本匹配：使用引导掩码的多模态转换器中的动词理解。 （arXiv：2401.16575v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.16575</link>
      <description><![CDATA[主要探测方法依赖于零样本性能
图像-文本匹配任务，以获得更细粒度的理解
最近的多模态图像语言转换器模型学习到的表示。
评估是在精心策划的数据集上进行的，重点关注
计数、关系、属性等。这项工作介绍了一个
另一种探测策略称为引导掩蔽。提议的方法
使用掩蔽消除不同的模式并评估模型的能力
高精度地预测屏蔽词。我们专注于研究多式联运
考虑对象获得的感兴趣区域 (ROI) 特征的模型
检测器作为输入令牌。我们使用引导探究对动词的理解
对 ViLBERT、LXMERT、UNTER 和 VisualBERT 进行掩蔽，并表明这些模型
可以高精度地预测正确的动词。这与之前的对比
从图像文本匹配探测技术中得出的结论经常
在需要动词理解的情况下失败。所有实验的代码
将公开 https://github.com/ivana-13/guided_masking。
]]></description>
      <guid>http://arxiv.org/abs/2401.16575</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:18 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士作为按需定制服务。 （arXiv：2401.16577v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.16577</link>
      <description><![CDATA[大型语言模型 (LLM) 展示了非凡的语言
理解和生成能力。然而，训练、部署和
访问这些模型带来了显着的挑战，包括资源密集型
需求、延长培训时间和可扩展性问题。为了解决这些
问题，我们引入了分层、分布式LLM架构的概念
旨在提高法学硕士的可访问性和可部署性
异构计算平台，包括通用计算机（例如，
笔记本电脑）和物联网式设备（例如嵌入式系统）。通过引入一个
“分层”方法，所提出的架构支持按需访问
向法学硕士提供可定制的服务。这种方法还确保了最佳
可用计算资源和用户资源之间的权衡
应用需求。我们预计分层法学硕士的概念将
授权广泛的众包用户群来利用
法学硕士，从而促进人工智能技术的总体进步。
]]></description>
      <guid>http://arxiv.org/abs/2401.16577</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:18 GMT</pubDate>
    </item>
    <item>
      <title>多样化但存在分歧：法学硕士可能会夸大与错误信息危害相关的性别差异。 （arXiv：2401.16558v1 [cs.CY]）</title>
      <link>http://arxiv.org/abs/2401.16558</link>
      <description><![CDATA[错误信息和虚假信息的普遍传播造成了重大影响
对社会的威胁。专业的事实核查人员在解决问题方面发挥着关键作用
这种威胁，但问题的严重性迫使他们优先考虑
有限的资源。这种优先顺序可能会考虑一系列因素，例如
对特定人群造成不同伤害的风险。在这项工作中，我们
研究使用大型语言模型 (LLM) 的潜在影响
促进这种优先顺序的确定。因为事实核查影响广泛
社会不同阶层，代表不同观点很重要
在索赔优先级排序过程中。本文探讨了法学硕士是否可以
在评估错误信息的危害时反映不同群体的观点，
关注性别作为主要变量。我们提出两个核心问题：（1）
带有明确性别提及的提示在多大程度上反映了性别
美国在与社会相关的话题上存在意见分歧吗？和
(2) 性别中立的提示在多大程度上符合性别观点
那些话题？为了分析这些问题，我们提供了 TopicMisinfo 数据集，
包含来自不同主题的 160 个经过事实核查的主张，并辅以近
1600 个具有主观感知和注释者人口统计的人工注释。
分析对特定性别和中性提示的反应，我们发现 GPT
3.5-Turbo 反映了经验观察到的性别观点差异，但
放大了这些差异的程度。这些发现阐明了人工智能
在调节在线交流方面发挥着复杂的作用，对
事实核查者、算法设计者以及使用众包工作者作为注释者。
我们还发布了 TopicMisinfo 数据集以支持继续研究
社区。
]]></description>
      <guid>http://arxiv.org/abs/2401.16558</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>印地文梵文脚本中的多类遗憾检测。 （arXiv：2401.16561v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.16561</link>
      <description><![CDATA[社交媒体上说印地语的人数急剧增加
最近几年。遗憾是我们日常生活中常见的情感体验。
许多发言人在社交媒体上分享了他们的遗憾经历和观点
经常。它可能会导致重新评估一个人的选择并产生做出决定的愿望
如果有机会的话，会有不同的选择。结果，知道了来源
后悔对于调查其对行为的影响至关重要
决策。这项研究的重点是遗憾及其表达方式，
特别是印地语，在各种社交媒体平台上。在我们的研究中，我们
呈现来自三个不同来源的新颖数据集，其中每个句子都有
被手动分类为三个类别之一“因行动而后悔”、“因行为而后悔”
by inaction”和“Noregret”。接下来，我们使用这个数据集来调查
印地语文本中遗憾的语言表达，并识别文本
最常与遗憾相关的领域。我们的研究结果表明
社交媒体平台上的个人经常对两者表示遗憾
过去的不作为和作为，特别是在人际交往领域
关系。我们使用预先训练的 BERT 模型来生成词嵌入
印地语数据集，并将深度学习模型与传统模型进行比较
机器学习模型以证明准确性。我们的结果表明
BERT 与 CNN 的嵌入始终优于其他模型。这描述了
BERT 在传达文本中单词的上下文和含义方面的有效性
遗憾域。
]]></description>
      <guid>http://arxiv.org/abs/2401.16561</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>InfoLossQA：表征和恢复文本简化中的信息丢失。 （arXiv：2401.16475v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.16475</link>
      <description><![CDATA[文本简化旨在使技术文本更容易被外行人理解
但往往会导致信息删除和含糊不清。这项工作提出
InfoLossQA，一个表征和恢复简化引起的框架
以问答（QA）对形式出现的信息丢失。建立在
讨论中的问题理论，问答对旨在帮助读者
加深他们对文本的了解。我们对此进行了一系列实验
框架。首先，我们收集 1,000 个语言学家策划的 QA 对的数据集
源自 104 个法学硕士对医学科学摘要的简化
学习。我们对这些数据的分析表明发生了信息丢失
经常，并且 QA 对对内容进行了高级概述
信息丢失。其次，我们为这项任务设计了两种方法：端到端
促进开源和商业语言模型以及自然语言
推理管道。考虑到新的评估框架
QA 对的正确性及其语言适用性，我们的专家评估
揭示模型难以可靠地识别信息丢失并应用
在构成信息丢失方面与人类有类似的标准。
]]></description>
      <guid>http://arxiv.org/abs/2401.16475</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>GuReT：区分内疚和遗憾相关文本。 （arXiv：2401.16541v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.16541</link>
      <description><![CDATA[人类决策与情感之间错综复杂的关系，
尤其是内疚和后悔，对行为和行为有重大影响
福利。然而，这些情绪的微妙区别和相互作用往往是
在计算模型中被忽视。本文介绍了一个专门针对
剖析内疚和后悔之间的关系及其独特的文本
标记，填补了情感计算研究的显着空白。我们的方法
将内疚和遗憾识别视为二元分类任务并采用
三种机器学习和六种基于 Transformer 的深度学习技术
对新创建的数据集进行基准测试。研究进一步创新
诸如思维链和思维树之类的推理方法来评估
模型解释逻辑。结果表明明显的性能优势
基于 Transformer 的模型，与
85.3% 的人获得了最佳机器学习分类器的评分，展示了他们的能力
区分复杂情绪状态的卓越能力。
]]></description>
      <guid>http://arxiv.org/abs/2401.16541</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>SelectLLM：LLM 可以选择重要说明进行注释吗？ （arXiv：2401.16553v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.16553</link>
      <description><![CDATA[通过大量且多样化的指令训练大型语言模型 (LLM)
数据集调整模型以理解和遵循人类指令。最近的
工作表明，使用一小组高质量的指令可以
优于使用大但噪音更大的。因为说明书没有标签
他们的回答是自然文本、传统的主动学习方案
模型的置信度不能直接应用于未标记的选择
指示。在这项工作中，我们提出了一种新颖的教学方法
选择，称为 SelectLLM，利用 LLM 来选择
高质量的指导。我们的高级想法是使用法学硕士来估计
每条指令的有用性和影响力，无需相应的
通过提示来标记（即响应）。 SelectLLM涉及两个步骤：划分
使用聚类算法（例如 CoreSet）的未标记指令
多个集群，然后促使法学硕士选择高质量的指令
每个簇内。 SelectLLM 的表现相当或略好
与最近最先进的技术相比，在流行的指令基准上
选择方法。所有代码和数据都是公开的
（https://github.com/minnesotanlp/select-llm）。
]]></description>
      <guid>http://arxiv.org/abs/2401.16553</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>KAUCUS：用于培训语言模型助手的知识增强用户模拟器。 （arXiv：2401.16454v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2401.16454</link>
      <description><![CDATA[可以通过以下方式开发有效的多轮指令跟随助手
创建一个可以生成有用的交互数据的模拟器。除了
依靠其内在权重，理想的用户模拟器还应该能够
以原始形式快速引导外部知识来模拟
互联网上提供的文本多种多样。以前的用户
模拟器通常缺乏多样性，大多是封闭域，并且
必要的严格模式使得它们无法快速扩展
吸收外部知识。在这方面，我们介绍考克斯（Kaucus）
知识增强用户模拟器框架，概述创建过程
多样化的用户模拟器，也可以无缝地利用外部知识
有利于下游辅助模型的训练。通过两个基于GPT-J的
模拟器，即检索增强模拟器和摘要控制模拟器
模拟器我们生成不同的模拟器辅助交互。通过奖励
和基于偏好模型的评估，我们发现这些交互服务
作为有用的培训数据并创建更有用的下游助手。我们也
发现通过检索增强或总结来整合知识
控制有助于创造更好的助手。
]]></description>
      <guid>http://arxiv.org/abs/2401.16454</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>信用风险遇到大型语言模型：根据 P2P 借贷中的贷款描述构建风险指标。 (arXiv:2401.16458v1 [q-fin.RM])</title>
      <link>http://arxiv.org/abs/2401.16458</link>
      <description><![CDATA[点对点（P2P）借贷已成为一种独特的融资机制，
通过在线平台将借款人和贷款人联系起来。然而，P2P借贷
面临信息不对称的挑战，贷款人往往缺乏足够的资金
评估借款人信用度的数据。本文提出了一种小说
通过利用提供的文本描述来解决此问题的方法
借款人在贷款申请过程中。我们的方法论涉及
使用大型语言模型（LLM）处理这些文本描述，
能够识别文本中的模式和语义的强大工具。
应用迁移学习使法学硕士适应手头的特定任务。

我们对 Lending Club 数据集的分析得出的结果表明
BERT（一种广泛使用的法学硕士）生成的风险评分显着提高了
信用风险分类器的性能。然而，其固有的不透明度
基于法学硕士的系统，加上潜在偏差的不确定性，
强调监管框架的关键考虑因素并产生
最终用户之间与信任相关的担忧，为未来研究开辟新途径
在 P2P 借贷和人工智能的动态格局中。
]]></description>
      <guid>http://arxiv.org/abs/2401.16458</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>ReGAL：重构程序以发现可概括的抽象。 （arXiv：2401.16467v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2401.16467</link>
      <description><![CDATA[虽然大型语言模型 (LLM) 越来越多地用于程序
综合而言，他们缺乏开发有用抽象所需的全局视角；
他们通常一次预测一个节目，并且经常重复相同的内容
功能。从头开始生成冗余代码不仅效率低下，而且
容易出错。为了解决这个问题，我们建议重构泛化
抽象学习（ReGAL），一种用于学习库的无梯度方法
通过代码重构可重用函数，即重构代码而无需
改变其执行输出。 ReGAL 从一小部分现有的数据中学习
程序，通过执行迭代验证和完善其抽象。我们
发现ReGAL发现的共享函数库使得程序
更容易跨不同领域进行预测。在三个数据集上（LOGO图形
生成、日期推理和 TextCraft（一款基于 Minecraft 的文本游戏），两者都
开源和专有的法学硕士在预测项目时提高了准确性
具有 ReGAL 功能。对于 CodeLlama-13B，ReGAL 的结果是绝对准确的
图形理解能力提高 11.5%，日期理解能力提高 26.1%，数据理解能力提高 8.1%
TextCraft，在三个领域中的两个领域优于 GPT-3.5。我们的分析表明
ReGAL 的抽象封装了常用的子例程以及
环境动态。
]]></description>
      <guid>http://arxiv.org/abs/2401.16467</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>结合主题建模和引文网络分析，研究欧洲人权法院关于尊重私人和家庭生活的权利的判例法。 （arXiv：2401.16429v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.16429</link>
      <description><![CDATA[随着 HUDOC 等法律判例法数据库持续快速增长，它已经
对于法律研究人员来说，寻找有效的方法来处理此类问题变得至关重要
大规模数据集。此类判例法数据库通常包含文本
案例内容以及案例之间的引用。本文重点
欧洲人权法院关于《公约》第 8 条的判例法
欧洲人权公约，尊重私人和家庭的权利
生活、家庭和信件。在这项研究中，我们展示并比较了
主题建模和引文网络查找和组织判例法的潜力
分别根据其一般主题和引用模式来了解第 8 条。
此外，我们还探讨了将这两种技术结合起来是否会带来更好的结果
与仅应用其中一种方法的结果进行比较。我们评估
组合方法对独特的手动收集和分析的有效性
Aricle 8 关于驱逐的判例法的注释数据集。我们的结果
实验表明，我们的组合（基于文本和引文）方法提供了
寻找和分组判例法的最佳结果，为学者提供了
提取和分析特定问题的相关案例的有效方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.16429</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>Covid-19 相关论文的信息检索和提取工具。 （arXiv：2401.16430v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.16430</link>
      <description><![CDATA[背景：COVID-19 大流行对卫生系统造成了严重影响
全世界。它的重要性以及个人和组织日益增长的兴趣
组织制定解决该问题的对策导致了
科学期刊上的新研究。目标：我们寻求开发一种工具
以一种新颖的方式结合了信息检索（IR）和
提取 (IE) 应用于 COVID-19 开放研究数据集 (CORD-19)。这
本文的主要重点是为研究人员提供更好的搜索工具
针对 COVID-19 相关论文，帮助他们找到参考论文并突出显示
文本中的相关实体。方法：我们应用潜在狄利克雷分配（LDA）
根据研究方面对所有英文摘要的主题进行建模
CORD-19。每个摘要的相关命名实体均被提取并链接到
相应的UMLS概念。正则表达式和 K 最近邻
使用算法对相关论文进行排名。结果：我们的工具显示了
通过自动化基于主题的 CORD-19 搜索来帮助研究人员的潜力
文件。尽管如此，我们发现更微调的主题建模
研究方面分类器模型的参数和准确性的提高可以
带来更准确、更可靠的工具。结论：我们强调需要
新的自动化工具可帮助研究人员找到相关的 COVID-19 文档
除了自动提取其中包含的有用信息之外。我们的
研究表明，结合不同的算法和模型可能会产生新的结果
浏览 COVID-19 纸质数据的方式。
]]></description>
      <guid>http://arxiv.org/abs/2401.16430</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>FaKnow：用于假新闻检测的统一库。 （arXiv：2401.16441v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.16441</link>
      <description><![CDATA[过去几年，大量基于算法的假新闻检测
关于深度学习的问题已经出现。然而，它们通常是在
不同的框架，每个框架都要求不同的使用方法，
从而阻碍再现性。此外，大量的
冗余是此类假新闻检测的代码开发的特征
楷模。为了解决这些问题，我们提出了 FaKnow，一个统一的、
综合假新闻检测算法库。它涵盖了多种
广泛使用的假新闻检测模型，分为基于内容和
基于社会背景的方法。该库涵盖了全部范围
模型训练和评估过程，有效组织数据、模型、
统一框架内的培训程序。此外，它还提供了
一系列辅助功能和工具，包括可视化和
记录。我们的工作有助于假货的标准化和统一
新闻检测研究，同时促进研究人员的努力
在这个领域里。开源代码和文档可以访问：
https://github.com/NPURG/FaKnow 和 https://faknow.readthedocs.io，
分别。
]]></description>
      <guid>http://arxiv.org/abs/2401.16441</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:14 GMT</pubDate>
    </item>
    </channel>
</rss>