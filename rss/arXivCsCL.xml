<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Tue, 26 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>面向跨度的信息抽取——信息抽取的统一视角</title>
      <link>https://arxiv.org/abs/2403.15453</link>
      <description><![CDATA[arXiv:2403.15453v1 公告类型：新
摘要：信息提取是指自然语言处理（NLP）中识别文本中的子序列及其标签的任务集合。这些任务多年来一直用于链接提取的相关信息以及将自由文本链接到结构化数据。然而，信息提取任务之间的异质性阻碍了该领域的进展。因此，我们提供了一个以我们定义的文本跨度为中心的统一视角。然后，我们将这些看似不协调的任务重新定位到这个统一的视角中，然后将各种信息提取任务重新呈现为相同的基本面向跨度的信息提取任务的变体。]]></description>
      <guid>https://arxiv.org/abs/2403.15453</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>使用变形金刚进行情绪检测：比较研究</title>
      <link>https://arxiv.org/abs/2403.15454</link>
      <description><![CDATA[arXiv:2403.15454v1 公告类型：新
摘要：在这项研究中，我们探索了基于变压器的模型在文本数据上的情感分类的应用。我们使用不同的 Transformer 变体在情感数据集上训练和评估几个预先训练的 Transformer 模型。论文还分析了影响模型性能的一些因素，例如transformer层的微调、层的可训练性以及文本数据的预处理。我们的分析表明，删除标点符号和停用词等常用技术可能会影响模型性能。这可能是因为变形金刚的优势在于理解文本中的上下文关系。标点符号和停用词等元素仍然可以传达情感或强调，删除它们可能会破坏这种上下文。]]></description>
      <guid>https://arxiv.org/abs/2403.15454</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>循环检索增强生成 (LoRAG)</title>
      <link>https://arxiv.org/abs/2403.15450</link>
      <description><![CDATA[arXiv:2403.15450v1 公告类型：新
摘要：本文提出了检索增强生成循环（LoRAG），这是一种新框架，旨在通过合并迭代循环机制来提高检索增强文本生成的质量。该架构集成了生成模型、检索机制和动态循环模块，允许通过与从输入上下文检索的相关信息交互来迭代细化生成的文本。对基准数据集的实验评估表明，LoRAG 在 BLEU 分数、ROUGE 分数和困惑度方面超越了现有的最先进模型，展示了其在实现生成文本的连贯性和相关性方面的有效性。定性评估进一步说明了 LoRAG 产生上下文丰富且连贯的输出的能力。这项研究为迭代循环在缓解文本生成挑战方面的潜力提供了宝贵的见解，将 LoRAG 定位为该领域的一项有前途的进步。]]></description>
      <guid>https://arxiv.org/abs/2403.15450</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型实现公平数据空间</title>
      <link>https://arxiv.org/abs/2403.15451</link>
      <description><![CDATA[arXiv:2403.15451v1 公告类型：新
摘要：数据空间最近在各个领域得到采用，包括文化等传统上数字化程度较低的领域。利用语义 Web 技术有助于使数据空间变得公平，但其复杂性对数据空间的采用提出了重大挑战，并增加了其成本。大型语言模型 (LLM) 的出现提出了这些模型如何支持 FAIR 数据空间的采用的问题。在这项工作中，我们通过一个具体的例子展示了法学硕士在数据空间中的潜力。我们还制定了探索这一新兴领域的研究议程。]]></description>
      <guid>https://arxiv.org/abs/2403.15451</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>到底什么是工具？语言模型视角的调查</title>
      <link>https://arxiv.org/abs/2403.15452</link>
      <description><![CDATA[arXiv:2403.15452v1 公告类型：新
摘要：语言模型（LM）功能强大，但主要用于文本生成任务。工具大大提高了需要复杂技能的任务的性能。然而，许多作品以不同的方式采用“工具”一词，提出了一个问题：到底什么是工具？接下来，工具在哪里以及如何帮助语言模型？在本次调查中，我们对语言模型使用的外部程序工具进行了统一定义，并对语言模型工具场景和方法进行了系统回顾。基于本次审查，我们通过在各种基准上测量所需的计算和性能增益来实证研究各种工具方法的效率，并强调该领域的一些挑战和潜在的未来研究。]]></description>
      <guid>https://arxiv.org/abs/2403.15452</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>通过社交网络上的 ARIMA 时间序列分析解码多语言主题动态和趋势识别：LDA/HDP 模型增强的新型数据翻译框架</title>
      <link>https://arxiv.org/abs/2403.15445</link>
      <description><![CDATA[arXiv:2403.15445v1 公告类型：新
摘要：在这项研究中，作者提出了一种新颖的方法，擅长解码多语言主题动态并识别危机期间的沟通趋势。我们重点关注冠状病毒大流行期间突尼斯社交网络内的对话以及体育和政治等其他值得注意的主题。我们首先聚合与这些主题相关的各种多语言评论语料库。该数据集在数据预处理过程中经过严格的细化。然后，我们介绍我们的非英语到英语机器翻译方法来处理语言差异。该方法的实证测试显示出较高的准确性和 F1 分数，突出了其对语言连贯任务的适用性。深入研究先进的建模技术，特别是 LDA 和 HDP 模型，用于从翻译内容中提取相关主题。这导致应用 ARIMA 时间序列分析来解码不断变化的主题趋势。将我们的方法应用于多语言突尼斯数据集，我们有效地识别了反映公众情绪的关键主题。事实证明，这些见解对于在危机期间努力了解公众观点的组织和政府至关重要。与标准方法相比，我们的模型表现优于标准方法，正如连贯性得分、U-mass 和主题连贯性等指标所证实的那样。此外，对已确定主题的深入评估揭示了讨论中显着的主题转变，我们的趋势识别显示出令人印象深刻的准确性，并得到基于 RMSE 的分析的支持。]]></description>
      <guid>https://arxiv.org/abs/2403.15445</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>解码压缩信任：审查压缩下高效法学硕士的可信度</title>
      <link>https://arxiv.org/abs/2403.15447</link>
      <description><![CDATA[arXiv:2403.15447v1 公告类型：新
摘要：压缩高性能大型语言模型（LLM）已成为资源高效推理的一种受欢迎的策略。虽然最先进的 (SoTA) 压缩方法在保持良性任务性能方面取得了令人印象深刻的进步，但压缩在安全性和可信度方面的潜在风险在很大程度上被忽视了。本研究使用五 (5) 种 SoTA 压缩技术，涵盖八 (8) 个可信度维度，对三 (3) 名领先的法学硕士进行了首次全面评估。我们的实验强调了压缩和可信度之间复杂的相互作用，揭示了一些有趣的模式。我们发现，在同时实现效率和可信度方面，量化目前是比剪枝更有效的方法。例如，4 位量化模型保留了其原始对应模型的可信度，但模型剪枝会显着降低可信度，即使稀疏度为 50% 也是如此。此外，在适度的比特范围内采用量化可以出乎意料地提高某些可信度维度，例如道德和公平性。相反，极端量化到非常低的位级别（3 位）往往会显着降低可信度。这种增加的风险不能仅通过观察良性表现来发现，进而要求在实践中进行全面的可信度评估。这些发现最终为法学硕士同时实现高实用性、效率和可信度提出了实用建议。模型和代码可在 https://decoding-comp-trust.github.io/ 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.15447</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>仇恨源于无知！对抗对话式仇恨言论的说服模式的提炼</title>
      <link>https://arxiv.org/abs/2403.15449</link>
      <description><![CDATA[arXiv:2403.15449v1 公告类型：新
摘要：检查反言论所使用的因素是理解在线对抗仇恨言论的最佳方法的核心。各种研究评估了反言论中使用的情感基础因素，例如情感同理心、冒犯性和敌意程度。为了更好地理解对话互动中使用的反言语，本研究将说服模式提炼为理性、情感和可信度，然后评估它们在两种类型的对话互动中的使用：封闭式（多轮）和开放式（单轮）对话关于种族主义、性别歧视和宗教的互动。该评估涵盖了人类与生成的反言论的不同行为。我们还评估了回复的立场与反言论中每种说服模式之间的相互作用。值得注意的是，我们观察到开放式和封闭式互动的反言论说服模式存在细微差别——尤其是在主题层面——普遍倾向于使用理性作为说服模式来表达仇恨评论的对立面。生成的反言语倾向于表现出情感说服模式，而人类反言语则倾向于使用推理。此外，我们的研究表明，与其他说服类型相比，理性作为一种说服模式往往会获得更多支持性答复。研究结果强调了将说服模式纳入有关反击仇恨言论的研究中的潜力，因为这些模式可以作为可解释性的最佳手段，并为进一步采用答复立场及其在评估最佳答复立场中所发挥的作用铺平道路。反言论。]]></description>
      <guid>https://arxiv.org/abs/2403.15449</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>ChatPattern：通过自然语言定制布局模式</title>
      <link>https://arxiv.org/abs/2403.15434</link>
      <description><![CDATA[arXiv:2403.15434v1 公告类型：新
摘要：现有的工作重点是固定尺寸的布局图案生成，而更实用的自由尺寸图案生成受到的关注有限。在本文中，我们提出了 ChatPattern，这是一种新颖的大语言模型 (LLM) 支持的框架，用于灵活的模式定制。 ChatPattern 采用由两部分组成的系统，其中包括专业的 LLM 代理和高度可控的布局模式生成器。 LLM 代理可以解释自然语言要求并操作设计工具来满足指定需求，而生成器则擅长条件布局生成、模式修改和内存友好型模式扩展。在具有挑战性的模式生成设置上的实验表明了 ChatPattern 合成高质量大规模模式的能力。]]></description>
      <guid>https://arxiv.org/abs/2403.15434</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>使用上下文信息进行句子级语素分割</title>
      <link>https://arxiv.org/abs/2403.15436</link>
      <description><![CDATA[arXiv:2403.15436v1 公告类型：新
摘要：词素分割的最新进展主要强调词级分割，常常忽略句子内的上下文相关性。在本研究中，我们将语素分割任务重新定义为序列到序列问题，将整个句子视为输入而不是隔离单个单词。我们的研究结果表明，与单语言模型相比，多语言模型始终表现出优越的性能。虽然我们的模型没有超越当前最先进的性能，但它表现出了与高资源语言相当的功效，同时揭示了低资源语言场景的局限性。]]></description>
      <guid>https://arxiv.org/abs/2403.15436</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>拓扑观点的语言学</title>
      <link>https://arxiv.org/abs/2403.15440</link>
      <description><![CDATA[arXiv:2403.15440v1 公告类型：新
摘要：语言学中的类型学数据库通常是分类值的。因此，很难对数据进行清晰的可视化。在本文中，我们描述了应用多重对应分析技术和拓扑数据分析方法来分析南美语言拓扑形状的工作流程。]]></description>
      <guid>https://arxiv.org/abs/2403.15440</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>通过基于注意力的双向循环神经网络从 Reddit 帖子中检测阿片类药物用户</title>
      <link>https://arxiv.org/abs/2403.15393</link>
      <description><![CDATA[arXiv:2403.15393v1 公告类型：新
摘要：阿片类药物流行病是指因阿片类药物过量使用和成瘾而导致的住院和死亡人数不断增加，已成为美国严重的健康问题。联邦和地方政府以及卫生界制定了许多战略来应对这场危机。其中，通过更好的健康监测来提高我们对疫情的了解是当务之急之一。除了直接测试之外，机器学习方法还可以让我们通过分析社交媒体的数据来检测阿片类药物使用者，因为许多阿片类药物使用者可能选择不进行测试，但可能会在社交媒体上匿名分享他们的经验。在本文中，我们利用机器学习的最新进展，收集并分析来自流行社交网络 Reddit 的用户帖子，目的是识别阿片类药物用户。我们收集了 1000 多名用户在一个月内在三个 Reddit 子版块上发布的帖子。除了包含阿片类药物、阿片类药物或海洛因等关键词的帖子外，我们还收集了包含阿片类药物俚语的帖子，例如黑色或巧克力。我们应用基于注意力的双向长短记忆模型来识别阿片类药物使用者。实验结果表明，这些方法在 F1 分数方面明显优于竞争算法。此外，该模型允许我们通过注意力层从帖子中提取信息最多的单词，例如鸦片、阿片类药物和黑色，这为机器学习算法如何区分吸毒者和非吸毒者提供了更多见解。]]></description>
      <guid>https://arxiv.org/abs/2403.15393</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>X-AMR 注释工具</title>
      <link>https://arxiv.org/abs/2403.15407</link>
      <description><![CDATA[arXiv:2403.15407v1 公告类型：新
摘要：本文提出了一种新颖的跨文档抽象含义表示（X-AMR）注释工具，旨在注释关键的语料库级事件语义。通过 Prodigy Annotation Tool 来利用机器辅助，我们增强了用户体验，确保注释过程的轻松和高效。通过实证分析，我们证明了我们的工具在增强现有事件语料库方面的有效性，突出了其与 GPT-4 集成时的优势。代码和注释：https://github.com/ahmeshaf/gpt_coref]]></description>
      <guid>https://arxiv.org/abs/2403.15407</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>从大型语言模型中提取濒危物种的命名实体识别模型</title>
      <link>https://arxiv.org/abs/2403.15430</link>
      <description><![CDATA[arXiv:2403.15430v1 公告类型：新
摘要：自然语言处理（NLP）从业者正在利用大型语言模型（LLM）从半结构化和非结构化数据源（例如专利、论文和论文）创建结构化数据集，而无需具备特定领域的知识。与此同时，生态专家正在寻找各种方法来保护生物多样性。为了为这些努力做出贡献，我们重点关注濒危物种，并通过情境学习从 GPT-4 中提取知识。实际上，我们通过两阶段过程创建了命名实体识别 (NER) 和关系提取 (RE) 的数据集：1) 我们从四类濒危物种的 GPT-4 中生成了合成数据，2) 人类验证了事实合成数据的准确性，产生黄金数据。最终，我们的新数据集总共包含 3.6K 个句子，均匀分布在 1.8K NER 和 1.8K RE 句子之间。然后使用构建的数据集来微调通用 BERT 和特定领域的 BERT 变体，完成从 GPT-4 到 BERT 的知识蒸馏过程，因为 GPT-4 是资源密集型的。实验表明，我们的知识转移方法可以有效地创建适合从文本中检测濒危物种的 NER 模型。]]></description>
      <guid>https://arxiv.org/abs/2403.15430</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>CapsF：用于从 Twitter 中提取自杀精神压力源的 Capsule Fusion</title>
      <link>https://arxiv.org/abs/2403.15391</link>
      <description><![CDATA[arXiv:2403.15391v1 公告类型：新
摘要：与癌症、血压、街头事故和中风等因素一样，自杀已成为伊朗的主要原因之一。自杀的主要原因之一是心理压力。识别高危人群的心理压力源有助于及早预防自杀和自杀行为。近年来，社交媒体实时信息共享的广泛普及和流动，使得对大规模甚至小规模人群的早期干预成为可能。然而，已经提出了一些从 Twitter 中提取精神压力源的自动化方法，但大部分研究都是针对非波斯语。本研究旨在调查使用基于学习的方法从波斯推文中检测与自杀相关的心理压力的技术。所提出的基于胶囊的方法实现了 0.83 的二元分类精度。]]></description>
      <guid>https://arxiv.org/abs/2403.15391</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:48 GMT</pubDate>
    </item>
    </channel>
</rss>