<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 07 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>交叉编码器可以产生有用的句子嵌入吗？</title>
      <link>https://arxiv.org/abs/2502.03552</link>
      <description><![CDATA[ARXIV：2502.03552V1公告类型：新 
摘要：交叉编码器（CES）接受句子对训练以检测相关性。由于CES需要在推理时对句子对，因此普遍的视图是它们只能用作信息检索管道中的重新率。双重编码器（DES）用于嵌入句子，其中句子对由两个单独的编码器编码，并在训练中具有共享权重，并且如果句子相关，则可以确保对副词的嵌入在向量空间中附近。但是，需要更大的数据集进行训练，并且不如CES准确。我们报告了一个奇怪的发现，即实际上可以在信息检索管道中使用较早的CES层的嵌入。我们展示了如何利用CES以5.15倍的推理时间提炼较轻的重量DE。]]></description>
      <guid>https://arxiv.org/abs/2502.03552</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在Babel中对Babble进行排序：评估Openalex数据库中语言检测算法的性能</title>
      <link>https://arxiv.org/abs/2502.03627</link>
      <description><![CDATA[ARXIV：2502.03627V1公告类型：新 
摘要：在最近关于Openalex语言元数据质量的研究之后（C \&#39;Espedes等，2025），本文旨在通过根据最新的各种语言分类程序进行设计，使用和评估后者优化后者以及最有效的自动语言检测算法。从数据库中索引的文章的一组多语言样本开始，然后根据一组来自索引文章的文本元数据的组合生成的一系列语料库中的一组语言检测算法的应用，然后设计不同的分类过程。 。首先，在样本级别上，根据精确，召回和处理时间评估了数据库中每种主要语言的这些不同过程的性能。然后，通过对谐波和加权分数的概率模拟在数据库级别估算总体过程性能。结果表明，过程性能在很大程度上取决于对所实施的每种措施的重要性：对于首选精度的上下文，使用文章标题上的langid算法，摘要和期刊名称可提供最佳结果；但是，对于所有认为召回至少比精度更重要的情况，或者一旦给予处理时间考虑任何考虑，请在文章标题上使用快速拼写算法仅优于所有其他选择。鉴于缺乏真正的多语言，大规模的书目数据库，希望这些结果有助于确认并促进Openalex数据库的无与伦比的潜力，以实现跨语言，基于书目计量的研究和分析。]]></description>
      <guid>https://arxiv.org/abs/2502.03627</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的上下文保留梯度调制：长篇文本生成中语义一致性的一种新颖方法</title>
      <link>https://arxiv.org/abs/2502.03643</link>
      <description><![CDATA[ARXIV：2502.03643V1公告类型：新 
摘要：维持扩展文本序列上的语义一致性仍然是长期文本生成中的一个基本挑战，传统的培训方法通常难以防止上下文漂移和连贯性退化。引入了一种新颖的梯度调制方法，旨在根据上下文相关性动态调整参数更新，以确保生成的文本与先前的话语保持一致。通过整合基于学习的上下文依赖性的选择性放大或减弱梯度的调制函数，提出的方法可以增强模型生成的叙述的稳定性，而无需施加大量的计算开销。针对基线模型的比较评估揭示了连贯性，上下文保留和远程依赖性跟踪的改善，这证明了在梯度级别修改学习过程的有效性。结果表明，句子结构的可变性和词汇多样性受到这种方法的好处，从而减轻重复的措辞并改善各种语言环境的适应性。一致性指标的统计验证进一步证实了观察到的增强功能，而不一致的不一致是调制机制的直接结果。计算效率评估确认，该框架可以实现这些收益，而无需对基础体系结构进行实质性修改，从而确保与现有的优化工作流程兼容。]]></description>
      <guid>https://arxiv.org/abs/2502.03643</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>寻找内在音乐：探究LLM对文学风格的理解</title>
      <link>https://arxiv.org/abs/2502.03647</link>
      <description><![CDATA[ARXIV：2502.03647V1公告类型：新 
摘要：最近的工作表明，可以训练语言模型来确定比传统风格学可行的文学段落短得多的作者。我们将这些结果复制为作者身份，并将其扩展到测量新型类型的新数据集。我们发现LLM能够区分作者身份和流派，但它们以不同的方式进行。有些模型似乎更多地依赖于记忆，而另一些模型则从培训中受益更多来学习作者/流派特征。然后，我们使用三种方法来探测一个定义样式的功能的高性能LLM。这些包括对输入文本的直接句法消融以及两种观察模型内部设备的方法。我们发现，作者样式比流派级别更容易定义，并且受到次要句法决策和上下文单词用法的影响更大。但是，某些特征（例如代词用法和单词顺序）对于定义两种文学风格都很重要。]]></description>
      <guid>https://arxiv.org/abs/2502.03647</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在大型语言模型中推进推理：有希望的方法和方法</title>
      <link>https://arxiv.org/abs/2502.03671</link>
      <description><![CDATA[ARXIV：2502.03671V1公告类型：新 
摘要：大型语言模型（LLM）在各种自然语言处理（NLP）任务中取得了显着成功，但其推理能力仍然是一个基本挑战。尽管LLM表现出令人印象深刻的流利性和事实回忆，但他们执行复杂的跨推理逻辑推论，数学解决问题，常识性推理和多步推理的能力，通常不足以达到人类的期望。这项调查提供了对新兴技术增强LLM中推理的全面综述。我们将现有方法分类为关键方法，包括提示策略（例如，经过思考的推理，自矛盾和经过思考的推理），建筑创新（例如，检索型模型，模块化推理和Neuro） - 符号集成）和学习范式（例如，通过特定于推理的数据集，强化学习和自我监督的推理目标进行微调）。此外，我们探讨了用于评估LLM中推理的评估框架，并突出了开放的挑战，例如幻觉，鲁棒性和跨不同任务的推理概括。通过综合最近的进步，这项调查旨在为未来的研究和实用应用LLMS的实践应用提供见解。]]></description>
      <guid>https://arxiv.org/abs/2502.03671</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>反射窗口解码：选择性改进的文本生成</title>
      <link>https://arxiv.org/abs/2502.03678</link>
      <description><![CDATA[ARXIV：2502.03678V1公告类型：新 
摘要：大型语言模型（LLMS）中文本生成的自动解码虽然缺乏内置机制来执行精炼和/或校正生成的内容，但本质上是次优的。在本文中，当共同考虑所有令牌同时考虑所有令牌时，我们从产生的响应的关节概率上考虑最佳性。从理论上讲，我们表征了自动加工产生的响应与其全球最佳长度相同长度的响应的潜在偏差。我们的分析表明，当文本生成期间出现明显的不确定性时，我们需要保持谨慎，这可能表明了一代历史的次要性。为了解决文本生成自回旋解码的陷阱，我们提出了一种包含滑动反射窗口和暂停标准的方法，以便可以在解码过程中互换进行细化和生成。我们的选择性改进框架达到了效率和最佳性之间的平衡，我们广泛的实验结果证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.03678</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过离散自动回归偏置来控制的LLM解码</title>
      <link>https://arxiv.org/abs/2502.03685</link>
      <description><![CDATA[ARXIV：2502.03685V1公告类型：新 
摘要：受控文本生成允许对大型语言模型输出的用户定义的约束，这是越来越重要的领域，因为LLMS在日常生活中变得更加普遍。一种常见的方法使用基于能量的解码，该解码通过能量函数定义目标分布，将多个约束结合到加权平均值中。但是，即使对能量函数的系数进行了广泛的调整，这些方法通常也很难平衡流利性和限制满意度。在本文中，我们确定了这种次优的平衡是由在连续空间中进行采样而不是文本令牌的自然离散空间。为了解决这个问题，我们提出了离散自动回归偏置，这是一种受控的解码算法，在完全在离散文本域中运行时利用梯度。具体而言，我们通过在生成的序列和辅助偏置序列上定义联合分布来引入一种新的公式，以实现受控文本生成。为了有效地从该联合分布中采样，我们提出了使用基于梯度的离散MCMC的langevin-gibbs采样算法。我们的方法显着提高了限制满意度，同时保持可比或更好的流利度，所有这些都以较低的计算成本。我们证明了我们受控解码方法在情感控制，语言排毒和关键字引导生成方面的优势。]]></description>
      <guid>https://arxiv.org/abs/2502.03685</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek和其他LLM的比较</title>
      <link>https://arxiv.org/abs/2502.03688</link>
      <description><![CDATA[ARXIV：2502.03688V1公告类型：新 
摘要：最近，DeepSeek一直是AI社区之外的关注焦点。一个有趣的问题是DeepSeek与其他大型语言模型（LLMS）的比较。 LLM可以执行许多任务，在本文中，我们使用的任务是使用简短文本进行比较来预测结果。我们考虑两个设置，一个作者分类设置和一个引文分类设置。在第一个目标中，目标是确定短文是由人类还是AI编写的。在第二个目标中，目标是使用文本内容将引文分类为四种类型之一。对于每个实验，我们将DeepSeek与$ 4 $流行的LLMS进行比较：Claude，Gemini，GPT和Llama。
  我们发现，就分类准确性而言，DeepSeek在大多数情况下都优于Gemini，GPT和Llama，但表现不佳。我们还发现，DeepSeek比其他人慢，但使用成本低，而克劳德（Claude）比其他所有人都要贵得多。最后，我们发现在相似性方面，DeepSeek的输出与Gemini和Claude的输出最相似（在所有$ 5 $ LLMS中，Claude和Gemini具有最相似的输出）。
  在本文中，我们还提出了自己收集的完全标记的数据集，并提出了一个食谱，可以在其中使用LLMS和最新的数据集MADSTAT来生成新的数据集。我们论文中的数据集可以用作将来在LLMS上进行研究的基准。]]></description>
      <guid>https://arxiv.org/abs/2502.03688</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM对齐作为检索器优化：信息检索透视图</title>
      <link>https://arxiv.org/abs/2502.03699</link>
      <description><![CDATA[ARXIV：2502.03699V1公告类型：新 
摘要：大型语言模型（LLMS）彻底改变了人工智能，具有推理，编码和沟通能力，并跨越行业的创新。它们的真正潜力取决于有效的一致性，以确保正确，值得信赖和道德行为，以应对诸如错误信息，幻觉，偏见和滥用等挑战。尽管现有的加固学习（RL）基于对齐方式是复杂的，但直接优化方法提供了更简单的替代方法。在这项工作中，我们通过利用既定信息检索（IR）原理来介绍一种新颖的LLM对齐方式直接优化方法。我们提出了一个系统的框架，该框架将LLM对齐和IR方法桥接，将LLM生成和奖励模型映射到IR的Retriever-Reranker范式中。在此基础的基础上，我们建议LLM Alignment作为回猎犬偏好优化（LARPO），这是一种新的对齐方法，可提高整体对齐质量。广泛的实验验证了LARPO的有效性，分别对羊角藻和Mixeval-Hard的38.9％和13.7％的平均有效性得到改善。我们的工作开辟了新的途径，以通过整合IR基金会来推进LLM对齐，并为未来的研究提供了有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2502.03699</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>汇总和征服：通过在多层上结合非线性预测因子来检测和转向LLM概念</title>
      <link>https://arxiv.org/abs/2502.03708</link>
      <description><![CDATA[ARXIV：2502.03708V1公告类型：新 
摘要：训练有素的大语言模型（LLM）包含许多人类知识。但是，很难衡量这些知识的程度或准确性，因为LLM并不总是``知道他们知道什么&#39;&#39;，甚至可能会积极误导。在这项工作中，我们提供了一种通用方法，用于检测LLMS内部激活中的语义概念。此外，我们表明我们的方法可以很容易地适应转向llms朝着理想的产出。我们的创新如下：（1）我们使用非线性特征学习方法来识别重要的线性方向，以预测每一层的概念； （2）我们跨层汇总了特征，以构建强大的概念探测器和转向机制。我们通过在七个基准测试中获得幻觉，有害性，毒性和不真实的内容来展示方法的力量。我们通过将LLMS转向新概念来强调我们方法的普遍性，据我们所知，这些概念以前在文献中没有被考虑，包括：语义歧义，人类语言，编程语言，幻觉的回答，科学主题，诗意/莎士比亚英语，甚至是多个概念。此外，我们的方法可以用数值属性（例如产品评论）引导概念。我们在https://github.com/dmbeaglehole/neural_controllers上提供代码（包括我们方法的简单API）。]]></description>
      <guid>https://arxiv.org/abs/2502.03708</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Multiq＆A：通过自动众包扰动和答案来测量鲁棒性的分析</title>
      <link>https://arxiv.org/abs/2502.03711</link>
      <description><![CDATA[ARXIV：2502.03711V1公告类型：新 
摘要：大型语言模型（LLM）的机构采用旅程中的一个关键挑战源于它们在产生的响应中对幻觉的倾向。为了解决这个问题，我们提出了Multiq＆amp; a，这是一种评估LLM生成答案的鲁棒性和一致性的系统方法。我们证明了Multiq＆amp; A众包扰动及其各自的答案通过独立的LLM代理的能力。我们的实验最终涉及190万个问题扰动和230万个答案。此外，Multiq＆amp;一种表明，诸如GPT-3.5-turbo之类的结合LLM在扰动下保持相对稳健且一致。 Multiq＆amp; A提供了响应生成空间的清晰度，提供了一种检查分歧和可变性的有效方法。因此，我们的系统提供了一种潜在的框架，以衡量信心，一致性和幻觉量化的能力。]]></description>
      <guid>https://arxiv.org/abs/2502.03711</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新考虑模型编辑中定位的然后编辑的方法的剩余分布</title>
      <link>https://arxiv.org/abs/2502.03748</link>
      <description><![CDATA[ARXIV：2502.03748V1公告类型：新 
摘要：模型编辑是一种更新大型语言模型（LLMS）知识的强大技术。定位 - 然后编辑方法是一种流行的方法类别，首先识别存储知识的关键层，然后根据编辑的知识计算最后一个临界层的残差，最后使用最小二乘解决方案执行多层更新将残差从第一个临界层均匀分布到最后一个。尽管这些方法获得了令人鼓舞的结果，但已被证明可以降低LLM的原始知识。我们认为剩余分布会导致这个问题。为了探讨这一点，我们从经验和理论观点均对定位方法中的剩余分布进行了全面分析，揭示了剩余分布引入了编辑错误，导致编辑不准确。为了解决此问题，我们提出了边界层更新（蓝色）策略，以增强定位 - 编辑方法。在三个LLM和两个数据集上进行的顺序批次编辑实验表明，蓝色不仅提供了35.59 \％的平均性能提高，在模型编辑中显着提高了最新技术的状态，而且还可以增强LLMS的一般能力。我们的代码可在https://github.com/xpq-tech/blue上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.03748</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在大语模型中构造潜在表示的层次结构上下文流形对齐</title>
      <link>https://arxiv.org/abs/2502.03766</link>
      <description><![CDATA[ARXIV：2502.03766V1公告类型：新 
摘要：潜在代币表示的组织在确定语言模型的稳定性，泛化和上下文一致性方面起着至关重要的作用，但是嵌入细化的常规方法通常依赖于引入其他计算额外开销的参数修改。引入了一种分层对齐方法，以在不改变核心模型权重的情况下进行重组令牌嵌入，从而确保代表性分布在不同语言环境中保持连贯性。实验评估表明，罕见的令牌检索，对抗性鲁棒性和远程依赖性跟踪的改善，突出了层次结构在减轻潜在太空组织中的不一致方面的优势。针对常规微调和嵌入扰动方法的比较分析表明，分层重组保持了计算效率，同时在表示质量方面可衡量。通过对齐过程引入的结构改进导致各种语言任务之间的上下文稳定性提高，从而减少了代币接近性关系的不一致，并增强了语言生成中的解释性。一项详细的计算评估证实，重组过程引入了最小的推理开销，确保了代表性改进不会损害模型效率。这些发现增强了结构化表示学习的更广泛的意义，表明层次结构嵌入修改可以作为精炼潜在空间分布的有效策略，同时保留预学的语义关联。]]></description>
      <guid>https://arxiv.org/abs/2502.03766</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全部都在[蒙版]中：简单的指令调节使类似于Bert的掩蔽语言模型作为生成分类器</title>
      <link>https://arxiv.org/abs/2502.03793</link>
      <description><![CDATA[ARXIV：2502.03793V1公告类型：新 
摘要：虽然诸如Bert和ModernBert之类的仅编码模型在现实世界NLP应用程序中无处不在，但与基于解码器的大型语言模型（LLMS）相比，它们对特定于任务的分类头的常规依赖可能会限制其适用性。在这项工作中，我们介绍了Modernbert-Large-Instruct，这是一个0.4B参数编码器模型，该模型利用其蒙版语言建模（MLM）负责人进行生成分类。我们的方法采用了有意的简单训练循环和推理机制，不需要大量的预处理，经过重大工程的提示或建筑修改。 Modernbert-Large-Instruct在分类和基于知识的任务上表现出强劲的零局部性，表现优于MMLU上的大小相似的LLM，并实现了Llama3-1b的MMLU表现的93％，参数少60％。我们还证明，在微调时，使用MLM头部匹配的生成方法，甚至超过了各种NLU任务的传统分类头方法。这能力专门出现在对现代，多样的数据组合培训的模型中，并在较低的较低型模型上培训了模型数量，多样性数据的性能较弱。尽管初步，但这些结果证明了使用原始的生成性掩盖语言建模主管在传统的特定任务方面进行下游任务的潜力。我们的工作表明，有必要进一步探索这一领域，这突出了许多未来改进的途径。]]></description>
      <guid>https://arxiv.org/abs/2502.03793</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过注入噪声增强幻觉检测</title>
      <link>https://arxiv.org/abs/2502.03799</link>
      <description><![CDATA[ARXIV：2502.03799V1公告类型：新 
摘要：大语言模型（LLM）容易产生合理但不正确的响应，称为幻觉。因此，有效检测幻觉对于LLM的安全部署至关重要。最近的研究将幻觉与建模不确定性联系起来，表明可以通过测量从模型中绘制的一组样品获得的分布分散分布来检测幻觉。虽然从模型定义的代币上的分布中汲取了一种自然的方式来获取样品，但在这项工作中，我们认为它是为了检测幻觉的目的是亚最佳选择。我们表明，通过考虑贝叶斯意义上的模型不确定性，可以显着改善检测。为此，我们提出了一种非常简单有效的方法，可以在采样过程中适当的模型参数子集或等效隐藏的单位激活。我们证明了它在各种数据集和模型架构中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.03799</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>