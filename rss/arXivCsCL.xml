<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Mon, 11 Dec 2023 03:15:09 GMT</lastBuildDate>
    <item>
      <title>首次尝试为印度东北部资源匮乏的语言建立机器翻译并行语料库。 （arXiv：2312.04764v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04764</link>
      <description><![CDATA[本文介绍了 13 个人的初始双语语料库的创建
印度资源非常匮乏的语言，全部来自印度东北部。它也是
展示了这些语言的初步翻译工作的结果。它
为这些语言创建了第一个并行语料库，并提供
这些语言的初始基准神经机器翻译结果。我们
打算扩展这些语料库以包括大量资源匮乏的印度人
语言并将这项工作与我们之前与非洲和非洲的工作结合起来
美洲-印度语言创建涵盖大量语言的语料库
来自世界各地的语言。
]]></description>
      <guid>http://arxiv.org/abs/2312.04764</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>高效的大型语言模型在图上进行微调。 （arXiv：2312.04737v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.04737</link>
      <description><![CDATA[从文本属性图（TAG）中学习已经吸引了很多人
由于其广泛的实际应用而受到关注。快速演变
大语言模型（LLM）的出现彻底改变了我们处理文本的方式
数据，这表明替代浅文本嵌入的强大潜力
通常用于图神经网络（GNN）。然而我们发现现有的
利用图表中文本信息的法学硕士方法存在较差的问题
计算和数据效率。在这部作品中，我们介绍了一部小说
大型语言模型端到端微调的有效方法
标签上的法学硕士（法学硕士），名为“领先”。所提出的方法保持了计算成本
和内存开销与 LLM 的无图微调相当。而且，
它将法学硕士中丰富的知识转移到下游图学习任务
在半监督学习中有效地利用有限的标记数据。其优越性
通过综合展示计算和数据效率
实验，为广泛的法学硕士和图形提供了一个有前途的解决方案
标签上的学习任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.04737</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>Quilt-LLaVA：通过从开源组织病理学视频中提取本地化叙述来调整视觉指令。 （arXiv：2312.04746v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.04746</link>
      <description><![CDATA[整张幻灯片图像 (WSI) 的十亿像素规模对
组织病理学多模式聊天机器人，需要进行全局 WSI 分析
诊断，综合来自不同 WSI 补丁的证据。当前视觉
通过大型语言模型生成的指令数据集，重点关注
为单个图像补丁创建问题/答案对，这可能缺乏
其在组织病理学中的诊断能力进一步复杂化
组织病理学图像说明中缺乏空间基础。为了弥补这一点
间隙，我们引入了 Quilt-Instruct，一个包含 107,131 个数据的大规模数据集
组织病理学特定的指导问题/答案对，由以下人员收集
利用 YouTube 上的教育组织病理学视频，该视频提供
通过自动提取叙述者的光标来实现字幕的空间定位
动作。此外，我们通过提取诊断来提供上下文推理
整个视频内容中的支持事实来指导推断
GPT-4 的推理。使用 Quilt-Instruct，我们训练 Quilt-LLaVA，它可以
推理超出给定的单个图像补丁，从而实现诊断推理和
空间意识的能力。为了评估 Quilt-LLaVA，我们提出了
由 985 张图像和 1283 个图像创建的综合评估数据集
人类生成的问题答案。我们还使用 Quilt-LLaVA 进行彻底评估
公共组织病理学数据集，其中 Quilt-LLaVA 显着优于
SOTA 在相对 GPT-4 分数上提高了 10% 以上，在开放和封闭集上分别提高了 4% 和 9%
质量保证。我们的代码、数据和模型可在 quilt-llava.github.io 上公开获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.04746</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>迫使生成模型退化：数据中毒攻击的力量。 （arXiv：2312.04748v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.04748</link>
      <description><![CDATA[第三方培训的大型语言模型 (LLM) 的应用不断增长
引起人们对法学硕士的安全漏洞的严重关注。
证明恶意行为者可以秘密利用这些漏洞
在法学硕士中，通过旨在产生不良输出的中毒攻击。
虽然中毒攻击在图像领域受到了广泛关注
（例如，对象检测）和分类任务，它们对
生成模型，特别是在自然语言生成领域
（NLG）任务，仍然知之甚少。为了弥补这一差距，我们执行
综合探索各种中毒技术，评估其
一系列生成任务的有效性。此外，我们还介绍了一个
一系列旨在量化中毒成功率和隐蔽性的指标
专门针对 NLG 任务的攻击。通过大量的实验
多个 NLG 任务、LLM 和数据集，我们证明可以
在微调阶段，仅使用 1\% 就成功毒害了 LLM
总调整数据样本。我们的论文提出了第一个系统的
理解针对 NLG 任务的中毒攻击的方法，考虑到广泛的
触发范围和攻击设置。我们希望我们的发现能够帮助人工智能
安全社区针对此类威胁制定适当的防御措施。
]]></description>
      <guid>http://arxiv.org/abs/2312.04748</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>跨语言的深层情感：多语言 WordNet 中情感传播的新方法。 （arXiv：2312.04715v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04715</link>
      <description><![CDATA[情感分析涉及使用富含情感元数据的 WordNet，
这是宝贵的资源。然而，手动标注非常耗时且
昂贵，导致只有少数 WordNet 词汇单元被注释。这
论文介绍了两种自动传播情绪的新技术
从部分注释的 WordNet 到整个 WordNet 的注释
使用不同的语言：多语言结构化同义词集嵌入（MSSE）和
跨语言深层神经情感传播（CLDNS）。我们评估了
广泛使用 Princeton WordNet 和 Polish 提出的 MSSE+CLDNS 方法
WordNet，其中有很多语言间的关系。我们的结果表明
MSSE+CLDNS方法优于现有的传播方法，表明其
使用跨多个情感元数据丰富 WordNets 的有效性
语言。这项工作为大规模、多语言的
情感分析具有学术研究和实践价值
应用程序。
]]></description>
      <guid>http://arxiv.org/abs/2312.04715</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>从大到小而不丢失全部：使用 ChatGPT 进行文本增强以进行高效的情感分析。 （arXiv：2312.04720v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04720</link>
      <description><![CDATA[人工智能时代，数据是黄金，但标注成本高昂。
该论文展示了使用 ChatGPT 解决这一困境的突破性解决方案
用于情感分析中的文本增强。我们利用 ChatGPT 的生成式
创建综合训练数据的能力，可显着提高
较小模型的性能，使它们具有竞争力，甚至
表现优于规模较大的同行。这项创新使模型能够
既高效又有效，从而降低计算成本、推理
时间和内存使用，而不影响质量。我们的工作标志着关键
在具有成本效益的开发和部署方面取得进展
情感分析模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.04720</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>您只需要反馈吗？在目标条件强化学习中利用自然语言反馈。 （arXiv：2312.04736v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04736</link>
      <description><![CDATA[尽管取得了许多成功，强化学习 (RL) 领域仍然存在
远远无法与人类行为令人印象深刻的泛化能力相比
学习。帮助弥补这一差距的一种可能方法是为 RL 代理提供
以自然语言表达的更丰富、更人性化的反馈。去弄清楚
这个想法，我们首先扩展BabyAI来自动生成语言反馈
来自环境动态和目标条件成功。然后，我们修改
Decision Transformer 架构可利用此附加信号。
我们发现用语言反馈进行的训练可以代替或补充
返回目的地或目标描述提高了代理的泛化能力
性能，并且代理可以从反馈中受益，即使这只是
在训练期间可用，但在推理时不可用。
]]></description>
      <guid>http://arxiv.org/abs/2312.04736</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>思想链推理的潜在技能发现。 （arXiv：2312.04684v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04684</link>
      <description><![CDATA[大型语言模型 (LLM) 的最新进展导致了一种新兴的
思维链（CoT）提示能力，一种提示推理策略，
在问题和答案之间添加中间的基本原理步骤来构建
提示。根据这些提示，法学硕士可以有效地学习
产生比回答问题时更准确的理由
直接问同样的问题。要设计 LLM 提示，一项重要的设置称为
演示选择，考虑从示例中选择演示
银行。现有方法使用各种启发式方法进行此选择，但对于 CoT
提示涉及独特的理由，因此必须以
根据 CoT 基本原理所需的内在技能进行选择，例如
数学应用题的加法或减法技巧。

为了满足这一要求，我们引入了一种名为 Reasoning 的新颖方法
使用无监督学习来创建潜在空间的技能发现（RSD）
基本原理的表示，称为推理技能。同时，RSD
学习推理策略以确定给定的推理所需的技能
问题。然后，这可以指导选择演示的示例
需要推理能力。我们的方法提供了几个理想的特性：
(1) 理论上有依据，(2) 样本效率高，不需要 LLM 推理
或手动提示设计，以及 (3) 与 LLM 无关。根据经验，RSD 表现优于
就多个问题的答案准确性而言，现有方法最多可提高 6%
推理任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.04684</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>Simul-LLM：利用大型语言模型探索高质量同声翻译的框架。 （arXiv：2312.04691v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04691</link>
      <description><![CDATA[具有数十亿参数并经过预训练的大型语言模型 (LLM)
海量数据现在能够接近或优于最先进的水平
在各种下游自然语言处理任务中的性能。
神经机器翻译（NMT）就是法学硕士已应用的任务之一
取得巨大成功。然而，很少有研究关注将法学硕士应用于
NMT 中更困难的子集称为同声翻译 (SimulMT)，
在整个源上下文可供使用之前，翻译就开始了
模型。在本文中，我们解决了法学硕士面临的主要挑战
SimulMT，在以下背景下验证经典 SimulMT 概念和实践
法学硕士，探索将针对 NMT 进行微调的法学硕士适应 SimulMT 的任务，
并推出Simul-LLM，第一个开源微调和评估
专注于 SimulMT 的法学硕士管道开发框架。
]]></description>
      <guid>http://arxiv.org/abs/2312.04691</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>使用基于 OpenAI GPT 的模型进行讽刺检测。 （arXiv：2312.04642v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04642</link>
      <description><![CDATA[讽刺是一种讽刺形式，需要读者或听众来解读
通过考虑上下文和社会线索来确定其预期含义。机器学习
分类模型长期以来很难检测讽刺，因为它
社会的复杂性和矛盾性。

本文探讨了生成式预训练 Transformer 的应用
(GPT) 模型，包括 GPT-3、InstructGPT、GPT-3.5 和 GPT-4，用于检测
自然语言中的讽刺。它测试了微调和零样本模型
不同的尺寸和版本。

GPT 模型在政治和平衡 (pol-bal) 部分进行了测试
流行的自注释 Reddit 语料库 (SARC 2.0) 讽刺数据集。在里面
微调案例，最大的微调GPT-3模型达到了精度和
$F_1$ - 得分为 0.81，优于之前的模型。在零样本情况下，其中之一
GPT-4 模型的准确度为 0.70，$F_1$ 得分为 0.75。其他型号
分数较低。此外，模型的性能可能会提高或恶化
每次发布时，都强调需要在每次发布后重新评估性能
发布。
]]></description>
      <guid>http://arxiv.org/abs/2312.04642</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>PyThaiNLP：Python 中的泰语自然语言处理。 （arXiv：2312.04649v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04649</link>
      <description><![CDATA[我们推出 PyThaiNLP，一种免费开源的自然语言处理
用 Python 实现的泰语 (NLP) 库。它提供了广泛的
泰语软件、模型和数据集。我们首先简单介绍一下
泰语开发之前的泰语工具的历史背景
PyThaiNLP。然后我们概述它提供的功能以及数据集
和预先训练的语言模型。我们稍后总结其发展里程碑
并讨论我们在其发展过程中的经验。我们通过证明得出结论
工业界和研究界如何在工作中利用 PyThaiNLP。这
库可在 https://github.com/pythainlp/pythainlp 免费获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.04649</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>自监督行为克隆变形金刚是文本游戏的路径爬虫。 （arXiv：2312.04657v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04657</link>
      <description><![CDATA[在这项工作中，我们引入了一种自监督行为克隆变压器
文本游戏，这是多步推理的挑战性基准
虚拟环境。传统上，行为克隆变形金刚擅长于
此类任务但依赖于监督训练数据。我们的方法自动生成
通过探索轨迹（由常见的宏观动作定义）来训练数据
序列）导致游戏中的奖励，同时确定
通过快速训练小模型来了解这些轨迹的通用性和实用性
然后评估他们在未见过的开发游戏中的表现。通过
实证分析，我们表明我们的方法始终揭示了可推广的
训练数据，实现监督系统约 90% 的性能
三款基准文字游戏。
]]></description>
      <guid>http://arxiv.org/abs/2312.04657</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>TOD-Flow：建模面向任务的对话结构。 （arXiv：2312.04668v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04668</link>
      <description><![CDATA[面向任务的对话（TOD）系统已成为以下领域的关键组成部分：
交互式人工智能应用。虽然最近的进展已经
利用预训练语言模型 (PLM)，它们表现出局限性
关于透明度和可控性。为了应对这些挑战，我们
提出一种专注于从对话中推断 TOD-Flow 图的新方法
用对话行为注释的数据，揭示了底层的任务结构
图表的形式。推断的 TOD-Flow 图可以轻松地与
任何对话模型，以提高其预测性能、透明度和
可控性。我们的 TOD-Flow 图了解模型可以做什么、应该做什么以及应该做什么
不预测，有效减少搜索空间并提供理由
用于模型的预测。我们表明所提出的 TOD-Flow 图更好
与之前的方法相比，类似于人工注释的图表。此外，
当与多种对话政策和端到端对话模式相结合时，我们
证明我们的方法显着改善了对话行为分类
MultiWOZ 和 SGD 中的端到端响应生成性能
基准。代码位于：https://github.com/srsohn/TOD-Flow
]]></description>
      <guid>http://arxiv.org/abs/2312.04668</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>基于开放评论 (ORB) 数据集：走向高能物理科学论文和实验建议的自动评估。 （arXiv：2312.04576v1 [cs.DL]）</title>
      <link>http://arxiv.org/abs/2312.04576</link>
      <description><![CDATA[随着开放科学方法对研究变得越来越重要，进化
开放科学论文评审正在对科学界产生影响
社区。但目前缺乏公共资源
开展与该主题相关的研究活动，但仅限于有限的
目前允许访问其评论的期刊和会议数量
相关方的流程。在本文中，我们介绍了新的
全面的基于开放评审的数据集（ORB）；它包括一个精选的列表
超过 36,000 篇科学论文及其超过 89,000 条评论和
最终决定。我们从两个来源收集此信息：
OpenReview.net 和 SciPost.org 网站。然而，考虑到其波动性
这个领域，我们引入的软件基础设施是为了补充
ORB 数据集旨在容纳未来的额外资源。这
ORB 可交付成果包括 (1) Python 代码（接口和实现）
将文档数据和元数据转换为结构化的高级数据
表示，(2) ETL 过程（提取、转换、加载）以促进
从定义的源自动更新和（3）数据文件代表
结构化数据。本文介绍了我们的数据架构和概述
收集的数据以及相关统计数据。出于说明目的，
我们还讨论了基于自然语言处理的初步实验
旨在根据文本嵌入来预测 (1) 论文的接受程度，以及
(2) 也从嵌入推断出分级统计数据。我们相信ORB
为对开放科学感兴趣的研究人员提供了宝贵的资源
审查，我们的实施简化了这些数据的进一步使用
分析和实验。我们计划随着该领域的成熟更新 ORB
以及引入更适合专门科学的新资源
高能物理等领域。
]]></description>
      <guid>http://arxiv.org/abs/2312.04576</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:04 GMT</pubDate>
    </item>
    <item>
      <title>走向心理通才人工智能：大型语言模型当前应用和未来前景的调查。 （arXiv：2312.04578v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.04578</link>
      <description><![CDATA[心理学原理的复杂性强调了重要的社会意义
鉴于心理问题的巨大社会影响，挑战。
弥合理解这些原则与其实际情况之间的差距
临床和现实世界的应用需要严格的探索和熟练的
执行。近年来，高度自适应和
可重复使用的人工智能（AI）模型已成为一种有前景的方法
释放心理学领域前所未有的能力。这张纸
强调了这些大规模人工智能的性能验证的重要性
模型，强调需要对其进行全面评估
多角度验证。此外，我们回顾了最前沿的
这些扩展模型的进步和实际实施
心理学，强调社交媒体等领域的关键工作
分析、临床护理见解、警惕的社区监测以及
对心理学理论的细致探索。根据我们的审查，我们预计
在这些因素的推动下，心理学领域的进步加速
大规模人工智能模型。这些未来的通用人工智能模型具有潜力
大幅降低劳动力成本，缓解社会压力。然而，这
前进的动力不会没有一系列的挑战，特别是当
考虑医疗所需的范式变化和升级
仪器仪表及相关应用。
]]></description>
      <guid>http://arxiv.org/abs/2312.04578</guid>
      <pubDate>Mon, 11 Dec 2023 03:15:04 GMT</pubDate>
    </item>
    </channel>
</rss>