<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Thu, 07 Dec 2023 03:15:01 GMT</lastBuildDate>
    <item>
      <title>编程教育中人工智能生成 (GPT-4) 和人工制作的 MCQ 的比较研究。 （arXiv：2312.03173v1 [cs.CY]）</title>
      <link>http://arxiv.org/abs/2312.03173</link>
      <description><![CDATA[教育工作者不断需要发展和保持有效的
最新的评估。尽管计算方面的研究越来越多
在生成和使用大语言模型（LLM）方面的教育
参与编码练习，使用法学硕士来生成编程
MCQ 尚未得到广泛探索。我们分析了 GPT-4 的能力
提出与特定学习相一致的多项选择题 (MCQ)
高等教育 Python 编程课程的目标 (LO)。
具体来说，我们开发了一个由 LLM 支持的 (GPT-4) 系统，用于生成 MCQ
来自高级课程背景和模块级 LO。我们评价了 651
LLM 生成的 449 个人工制作的 MCQ 与 6 个 Python 的 246 个 LO 一致
培训班。我们发现 GPT-4 能够生成语言清晰的 MCQ，
一个正确的选择和高质量的干扰因素。我们还观察到
生成的 MCQ 似乎与 LO 非常一致。我们的研究结果可以
希望利用最先进技术的教育工作者可以利用
支持 MCQ 创作工作的生成模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.03173</guid>
      <pubDate>Thu, 07 Dec 2023 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>使用领域适应 BERT 进行企业破产预测。 （arXiv：2312.03194v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03194</link>
      <description><![CDATA[本研究进行了基于BERT的分析，具有代表性
情境化语言模型，对企业披露数据进行预测
即将破产。之前的文献主要是破产预测
专注于开发更复杂的预测方法
财务变量。然而，在我们的研究中，我们专注于提高质量
输入数据集。具体来说，我们使用BERT模型来执行情感
MD&amp;A 披露分析。我们证明 BERT 优于基于字典的
预测和基于 Word2Vec 的预测（根据调整后的 R 方）
逻辑回归、k 最近邻 (kNN-5) 和线性核支持
向量机（SVM）。此外，不是预训练 BERT 模型
从头开始，我们将自学和基于置信的过滤应用于企业
披露数据 (10-K)。我们实现了 91.56% 的准确率并证明
域适应过程带来了显着的改进
预测准确性。
]]></description>
      <guid>http://arxiv.org/abs/2312.03194</guid>
      <pubDate>Thu, 07 Dec 2023 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>断言增强型小样本学习：大型语言模型生成教育解释的指导技术。 （arXiv：2312.03122v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03122</link>
      <description><![CDATA[人类教育者拥有预测和寻求的内在能力
学生的教育性解释，促使他们摆出姿势
当学生无法清楚地表达这些解释时提出发人深省的问题
独立。我们的目标是让智能辅导系统具备这种能力
使用大型语言模型的少样本学习能力。我们的工作提出
一种新颖的提示技术，断言增强小样本学习，
促进生成准确、详细的教育信息
解释。我们的中心假设是，在教育领域，很少有机会
演示是必要的，但不是保证质量的充分条件
解释生成。我们对 12 名在职教师进行了一项研究，
将我们的方法与传统的少样本学习方法进行比较。结果表明
断言增强型少样本学习将解释准确性提高了 15%
根据教师的评估，产生更高质量的解释。我们还进行了
定性消融研究，考虑断言的影响，以提供
教育者友好的提示指南，用于在他们的学习中产生解释
感兴趣的领域。
]]></description>
      <guid>http://arxiv.org/abs/2312.03122</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>FlexModel：分布式大型语言模型的可解释性框架。 （arXiv：2312.03140v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.03140</link>
      <description><![CDATA[随着大型语言模型的增长，现在包含了数十亿个
参数、训练和部署的硬件先决条件
看到了相应的增加。尽管现有工具有利于模型
并行化和分布式训练，更深入的模型交互，至关重要
对于可解释性和负责任的人工智能技术，仍然需要彻底
分布式计算知识。这通常会阻碍来自
具有机器学习专业知识但分布式计算有限的研究人员
背景。为了应对这一挑战，我们推出了 FlexModel，一个软件包
提供简化的界面，用于与分布在各处的模型进行交互
多 GPU 和多节点配置。该库兼容
现有模型分发库并封装 PyTorch 模型。它
公开用户可注册的 HookFunctions 以方便简单
与分布式模型内部交互，弥合之间的差距
分布式和单设备模型范例。 FlexModel 主要增强了
通过使模型交互民主化并促进更具包容性来实现可访问性
大规模神经网络领域的研究。该包位于
https://github.com/VectorInstitute/flex_model。
]]></description>
      <guid>http://arxiv.org/abs/2312.03140</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>将计数过程和分类相结合改进了技术辅助审查的停止规则。 （arXiv：2312.03171v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.03171</link>
      <description><![CDATA[技术辅助审查（TAR）停止规则旨在降低成本
通过最大限度地减少文档的数量来手动评估文档的相关性
需要检查以确保达到所需召回水平的文件。这
论文使用来自文本的信息扩展了有效的停止规则
无需任何额外注释即可训练的分类器。
在多个数据集上进行实验（CLEF e-Health、TREC Total Recall、TREC Legal
和 RCV1）表明所提出的方法持续提高性能
并且优于几种替代方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.03171</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>RESIN-EDITOR：模式引导的分层事件图可视化工具和编辑器。 （arXiv：2312.03093v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2312.03093</link>
      <description><![CDATA[在本文中，我们提出了 RESIN-EDITOR，一种交互式事件图可视化工具
和专为分析复杂事件而设计的编辑器。我们的 RESIN-EDITOR 系统
允许用户渲染和自由编辑从以下内容中提取的分层事件图
在人工策划的指导下的多媒体和多文档新闻集群
事件模式。 RESIN-EDITOR 的独特功能包括层次图
可视化、全面的源头追踪和交互式用户编辑，
比现有的信息提取（IE）更强大、更通用
可视化工具。在我们对 RESIN-EDITOR 的评估中，我们展示了以下方法：
我们的工具可以有效地理解复杂事件并增强
系统性能。源代码、视频演示和实时网站
RESIN-EDITOR 的版本已公开发布。
]]></description>
      <guid>http://arxiv.org/abs/2312.03093</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>了解环境帖子：社交媒体数据的情绪和情感分析。 （arXiv：2312.03095v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03095</link>
      <description><![CDATA[社交媒体现在是主要的信息来源，因为
立即获得公众回应。因此，社交媒体数据
成为了解民意的宝贵资源。研究有
表明它可以放大思想并影响公众情绪。这项研究
分析公众对气候变化和环境的看法
从 2014 年到 2023 年的十年。使用逐点互信息 (PMI)
算法，我们识别情绪并探索表达的流行情绪
在各种社交媒体平台上的环境推文中，即
推特、Reddit 和 YouTube。人工注释数据集的准确度为 0.65，
高于 Vader 分数，但低于专家评分者的分数 (0.90)。我们的
调查结果表明，负面环境推文比
积极或中性的。气候变化、空气质量、排放、塑料和
回收是所有社交媒体平台上讨论最多的话题，
凸显其对全球的巨大关注。环境中最常见的情绪
推文是恐惧、信任和期待，展示了广泛的公众反应
和复杂的性质。通过识别相关观点的模式和趋势
环境，我们希望提供有助于提高认识的见解
关于环境问题，为干预措施的制定提供信息，以及
采取进一步行动应对环境挑战。
]]></description>
      <guid>http://arxiv.org/abs/2312.03095</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>视觉程序蒸馏：将工具和程序推理蒸馏成视觉语言模型。 （arXiv：2312.03052v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.03052</link>
      <description><![CDATA[解决复杂的视觉任务，例如“谁发明了乐器”
正确的？”涉及一系列技能：理解空间、识别
工具，并检索先验知识。最近的工作显示出希望
使用大型语言模型 (LLM) 将此类任务分解为可执行文件
调用专门视觉模型的程序。然而，生成的程序是
容易出错：他们省略了必要的步骤，包括虚假的步骤，并且无法
当专用模型给出不正确的输出时进行恢复。而且，他们
需要加载多个模型，从而导致高延迟和计算成本。
我们提出了视觉程序蒸馏（VPD），一种指令调优框架
产生能够解决复杂视觉问题的视觉语言模型（VLM）
具有单个前向传递的任务。 VPD 通过以下方式提炼法学硕士的推理能力
使用它们对多个候选程序进行采样，然后执行这些程序并
已验证以识别正确的。它将每个正确的程序翻译成
推理步骤的语言描述，然后被提炼成
VLM。大量实验表明，VPD 提高了 VLM 的计数能力，
理解空间关系，并进行构图推理。我们接受过 VPD 培训
PaLI-X 优于所有先前的 VLM，实现了最先进的性能
跨越复杂的视觉任务，包括 MMBench、OK-VQA、A-OKVQA、TallyQA、POPE、
和可恨的模因。人类注释者的评估也证实了 VPD
提高模型响应的真实性和一致性。最后进行实验
内容审核表明 VPD 也有助于适应
数据有限的实际应用程序。
]]></description>
      <guid>http://arxiv.org/abs/2312.03052</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>临床记录显示医生疲劳。 （arXiv：2312.03077v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03077</link>
      <description><![CDATA[医生写关于病人的笔记。通过这样做，他们揭示了很多关于
他们自己。使用 129,228 次急诊室就诊的数据，我们训练一个模型
识别疲劳医生（那些工作了 5 次或以上的医生）所写的笔记
之前 7 天。在保留集中，模型准确识别音符
由这些高工作量的医生撰写，并且还标记以
其他高度疲劳的环境：夜班时以及高度疲劳后
卷。模型预测还与糟糕的决策相关
至少一个重要指标：心脏病发作检测率降低 18%
模型预测疲劳的每个标准差都会增加。最后是模型
表明关于黑人和西班牙裔患者的笔记有 12% 和 21%
比白人预测的疲劳程度更高——比夜间和白天的疲劳程度更高
差异。这些结果对于大型语言具有重要意义
模型（法学硕士）。我们的模型表明，疲劳的医生写的内容更可预测
笔记。也许这并不奇怪，因为单词预测是法学硕士的核心
工作中，我们发现 LLM 写的笔记的预测疲劳程度比
真正的医生的笔记。这表明法学硕士可能会引入扭曲
生成的文本尚未完全理解。
]]></description>
      <guid>http://arxiv.org/abs/2312.03077</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>用于情报/安全关键应用中多模式知识提取和分析的法学硕士。 （arXiv：2312.03088v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03088</link>
      <description><![CDATA[近年来，大型语言模型的能力进步很快；
这一进展一直在加速，他们的能力通过各种衡量标准
基准，开始接近人类的基准。有强烈的需求
在各种应用中使用此类模型，但是由于尚未解决
漏洞和限制，应用前需要格外小心
它们适用于智能和安全关键型应用。本文评论
最近与 LLM 评估和综合漏洞相关的文献
当前的研究前景并帮助了解哪些进展最为显着
对于在情报和情报领域使用这些技术至关重要
安全关键型应用。漏洞分为十个
高级类别并覆盖到法学硕士的高级生命周期上。一些
审查了缓解措施的一般类别。
]]></description>
      <guid>http://arxiv.org/abs/2312.03088</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>在多模态关系提取中，合成数据训练胜过真实数据。 （arXiv：2312.03025v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.03025</link>
      <description><![CDATA[多模态关系提取任务引起了重大研究
关注，但进展因缺乏可用培训而受到限制
数据。一种自然的想法是通过跨模式扩展现有数据集
生成模型。在本文中，我们考虑一个新颖的问题设置，其中
训练期间仅提供单峰数据（文本或图像）。我们的目标是
从合成数据中训练在真实情况下表现良好的多模态分类器
多模态测试数据。然而，使用合成数据进行训练有两个问题
障碍：缺乏数据多样性和标签信息丢失。为了缓解
问题，我们提出了相互信息感知的多模态迭代关系数据
GEeration (MI2RAGE)，将链式跨模态生成 (CCG) 应用于
促进生成数据的多样性并利用教师网络
选择具有高互信息的有价值的训练样本
地面实况标签。将我们的方法与合成数据的直接训练进行比较，
我们观察到合成文本的 F1 显着提高了 24.06%
合成图像的 F1 为 26.42%。值得注意的是，我们最好的模型完全训练
合成图像优于之前在真实图像上训练的最先进模型
F1 中的多模态数据领先 3.76%。我们的代码库将可供使用
接受后。
]]></description>
      <guid>http://arxiv.org/abs/2312.03025</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士关于空间信息的固有局限性。 （arXiv：2312.03042v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03042</link>
      <description><![CDATA[尽管自然语言处理取得了重大进展
ChatGPT 等大型语言模型所展示的功能
熟练理解和处理空间信息，尤其是
在 2D 和 3D 路线规划领域内，仍然明显不发达。
本文研究了 ChatGPT 和类似模型的固有局限性
在空间推理和导航相关任务中，这一领域至关重要
应用范围从自动驾驶车辆引导到辅助技术
对于视障人士。在本文中，我们介绍了一种新颖的评估
框架辅以为此精心设计的基线数据集
学习。该数据集围绕三个关键任务构建：绘制空间
点、在二维 (2D) 空间中规划路线并设计路径
在三维 (3D) 环境中。我们专门开发了这个数据集
评估 ChatGPT 的空间推理能力。我们的评估揭示了
对模型在空间方面的能力和局限性的关键见解
理解。
]]></description>
      <guid>http://arxiv.org/abs/2312.03042</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>探索、选择、推导和回忆：利用类人记忆增强法学硕士，实现移动任务自动化。 （arXiv：2312.03003v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2312.03003</link>
      <description><![CDATA[大型语言模型 (LLM) 的出现开辟了新的机遇
移动任务自动化领域。他们卓越的语言理解力和
推理功能允许用户自动执行复杂且重复的任务。
然而，由于LLM固有的不可靠性和较高的运营成本，
它们的实际应用性非常有限。为了解决这些问题，本
论文介绍了 MemoDroid，一种基于 LLM 的创新移动任务自动化工具
通过独特的应用程序内存进行增强。 MemoDroid 模拟认知过程
人类与移动应用程序交互——探索、选择、推导和回忆。
这种方法可以更精确、更有效地学习任务的
通过将其分解为更小的模块化组件来进行处理
为不同的目标而重新使用、重新安排和调整。我们实施
MemoDroid 使用在线法学硕士服务（GPT-3.5 和 GPT-4）并评估其
在 5 个广泛使用的移动应用程序中执行 50 个独特的移动任务时的性能。这
结果表明 MemoDroid 可以使学习的任务适应不同的环境
准确率 100%，延迟和成本分别降低 69.22% 和 77.36%
与 GPT-4 支持的基线相比。
]]></description>
      <guid>http://arxiv.org/abs/2312.03003</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>蛋白质语言模型支持的 3D 配体结合位点从蛋白质序列预测。 （arXiv：2312.03016v1 [q-bio.QM]）</title>
      <link>http://arxiv.org/abs/2312.03016</link>
      <description><![CDATA[蛋白质配体结合位点的预测是基础且重要的
了解蛋白质的功能和筛选潜在药物的任务。
大多数现有方法需要通过实验确定蛋白质全结构
作为输入。然而，这样的结构在新颖或研究较少的情况下可能不可用
蛋白质。为了解决这个限制，我们提出了 LaMPSite，它只需要
蛋白质序列和配体分子图作为配体结合位点的输入
预测。蛋白质序列用于检索残基水平
来自预训练的 ESM-2 蛋白质语言模型的嵌入和接触图。
将配体分子图输入图神经网络进行计算
原子级嵌入。然后我们计算并更新蛋白质配体
基于蛋白质残基水平嵌入和配体的相互作用嵌入
原子级嵌入，以及推断蛋白质中的几何约束
接触图和配体距离图。蛋白质配体的最终汇集
相互作用嵌入将表明哪些残基属于结合
网站。在没有任何蛋白质 3D 坐标信息的情况下，我们提出的模型
与需要 3D 的基准方法相比，实现了具有竞争力的性能
预测结合位点时的蛋白质结构。鉴于不到 50%
现阶段蛋白质有可靠的结构信息，LaMPSite
将为药物发现提供新的机遇。
]]></description>
      <guid>http://arxiv.org/abs/2312.03016</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>超越隔离：多智能体协同改进知识图构建。 （arXiv：2312.03022v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.03022</link>
      <description><![CDATA[知识图谱构建（KGC）是一项多方面的事业，涉及
实体、关系和事件的提取。传统上，大
语言模型（LLM）在这方面被视为单独的任务解决代理
复杂的景观。然而，本文通过引入
一个新颖的框架，CooperKGC。与传统方法不同，
CooperKGC建立协作处理网络，组装KGC
协作团队能够同时处理实体、关系和
事件提取任务。我们的实验明确地证明了
促进内部不同代理之间的协作和信息交互
与个人认知过程相比，CooperKGC 产生了更好的结果
孤立运行。重要的是，我们的研究结果表明，合作
CooperKGC 促进了知识的选择、修正和
跨多轮交互的聚合能力。
]]></description>
      <guid>http://arxiv.org/abs/2312.03022</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    </channel>
</rss>