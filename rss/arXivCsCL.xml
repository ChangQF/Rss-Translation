<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 13 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用于从 Energetics 语料库中进行知识发现和信息提取的 NLP</title>
      <link>https://arxiv.org/abs/2402.06964</link>
      <description><![CDATA[我们展示了 NLP 在帮助含能材料和相关系统研究方面的实用性。 NLP 方法使机器能够理解文本数据，提供从能量学文本中发现知识和提取信息的自动化途径。我们将三个已建立的无监督 NLP 模型：潜在狄利克雷分配、Word2Vec 和 Transformer 应用于能量学相关科学文章的大型精选数据集。我们证明每个 NLP 算法都能够识别充满活力的主题和概念，生成与主题专家知识相一致的语言模型。此外，我们提出了能量学文本的文档分类管道。根据所使用的 NLP 模型，我们的分类管道可实现 59-76% 的准确率，其中性能最高的 Transformer 模型可与注释器间一致性指标相媲美。这项工作中研究的 NLP 方法可以识别与能量学密切相关的概念，因此有望成为加速能量学研究工作和能量学材料开发的工具。]]></description>
      <guid>https://arxiv.org/abs/2402.06964</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:40 GMT</pubDate>
    </item>
    <item>
      <title>一次指导，多轮一致聊天：一种高效的对话调优框架</title>
      <link>https://arxiv.org/abs/2402.06967</link>
      <description><![CDATA[调整用于对话生成的预训练语言模型一直是构建有能力的对话代理的流行范例。然而，传统的调优狭隘地将对话生成视为类似于其他语言生成任务，忽略了两个说话者之间的角色差异以及对话应有的多轮交互过程。这种方式导致构建的代理的聊天一致性不理想。在这项工作中，我们强调对话的交互性、交流性，并认为单独建模代理和用户的说话者角色更为可行，使代理能够始终如一地坚持其角色。我们提出了一种高效的多轮交互式对话调整（Midi-Tuning）框架。它使用两个基于大型语言模型的适配器分别对代理和用户进行建模，它们以交替的顺序逐轮利用话语，并通过轮级内存缓存机制进行调整。大量的实验表明，我们的框架的性能优于传统的微调，并且具有提高对话一致性的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2402.06967</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:40 GMT</pubDate>
    </item>
    <item>
      <title>事件关键摘要</title>
      <link>https://arxiv.org/abs/2402.06973</link>
      <description><![CDATA[我们引入了事件键控摘要（EKS），这是一种将传统摘要和文档级事件提取相结合的新颖任务，其目标是在给定文档和提取的事件结构的情况下为特定事件生成上下文化摘要。我们为该任务引入了一个数据集 MUCSUM，它包含经典 MUC-4 数据集中所有事件的摘要，以及一组基线，其中包含摘要文献中预训练的 LM 标准以及更大的前沿模型。我们表明，将 EKS 简化为传统摘要或结构到文本的消融会产生较差的目标事件摘要，并且 MUCSUM 是此任务的稳健基准。最后，我们对参考和模型摘要进行了人工评估，并对结果进行了一些详细分析。]]></description>
      <guid>https://arxiv.org/abs/2402.06973</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:40 GMT</pubDate>
    </item>
    <item>
      <title>在为 NLP 任务微调预训练的 Transformer 时，我应该尝试多个优化器吗？我应该调整他们的超参数吗？</title>
      <link>https://arxiv.org/abs/2402.06948</link>
      <description><![CDATA[NLP 研究探索了不同的神经模型架构和大小、数据集、训练目标和迁移学习技术。然而，训练期间优化器的选择尚未得到广泛探索。通常，采用随机梯度下降 (SGD) 的某些变体，使用不明确的标准从众多变体中进行选择，通常对优化器的超参数进行极少的调整或不进行调整。使用五个 GLUE 数据集、两个模型（DistilBERT 和 DistilRoBERTa）和七个流行的优化器（SGD、SGD with Momentum、Adam、AdaMax、Nadam、AdamW 和 AdaBound）进行实验，我们发现当调整优化器的超参数时，有尽管训练损失存在差异，但五个更精细的（自适应）优化器的测试性能没有显着差异。此外，在大多数情况下，仅调整学习率与调整所有超参数一样好。因此，我们建议选择任何表现最好的自适应优化器（例如 Adam）并仅调整其学习率。当无法调整超参数时，带有 Momentum 的 SGD 是最佳选择。]]></description>
      <guid>https://arxiv.org/abs/2402.06948</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:39 GMT</pubDate>
    </item>
    <item>
      <title>SpeechCLIP+：通过 CLIP 和语音图像数据进行语音自监督多任务表示学习</title>
      <link>https://arxiv.org/abs/2402.06959</link>
      <description><![CDATA[最近提出的基于视觉的语音模型 SpeechCLIP 是一个创新框架，它通过 CLIP 通过图像连接语音和文本，而不依赖于文本转录。在此基础上，本文介绍了SpeechCLIP的两个扩展。首先，我们应用连续集成和启动（CIF）模块来替换级联架构中固定数量的CLS令牌。其次，我们提出了一种新的混合架构，将 SpeechCLIP 的级联和并行架构合并到多任务学习框架中。我们的实验评估是在 Flickr8k 和 SpokenCOCO 数据集上进行的。结果表明，在语音关键词提取任务中，基于 CIF 的级联 SpeechCLIP 模型优于之前使用固定数量 CLS 标记的级联 SpeechCLIP 模型。此外，通过我们的混合架构，级联任务学习提高了图像语音检索任务中并行分支的性能。]]></description>
      <guid>https://arxiv.org/abs/2402.06959</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:39 GMT</pubDate>
    </item>
    <item>
      <title>TL;DR进展：文本摘要的多方位文献探索</title>
      <link>https://arxiv.org/abs/2402.06913</link>
      <description><![CDATA[本文介绍了 TL;DR Progress，这是一种探索神经文本摘要文献的新工具。它基于文本摘要方法的综合注释方案组织了 514 篇论文，并实现了细粒度、多方面的搜索。每篇论文都经过手动注释，以捕获评估指标、质量维度、学习范式、解决的挑战、数据集和文档领域等方面。此外，还为每篇论文提供了简洁的指示性摘要，其中包括自动提取的上下文因素、问题和建议的解决方案。该工具可在 https://www.tldr-progress.de 在线获取，演示视频位于 https://youtu.be/uCVRGFvXUj8]]></description>
      <guid>https://arxiv.org/abs/2402.06913</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士时代解码方法的彻底审视</title>
      <link>https://arxiv.org/abs/2402.06925</link>
      <description><![CDATA[解码方法在将语言模型从下一个标记预测器转换为实际任务求解器的过程中发挥着不可或缺的作用。先前对解码方法的研究主要集中在特定于任务的模型，可能无法扩展到当前的通用大语言模型（LLM）时代。此外，最近解码策略的涌入使这一情况进一步复杂化。本文对法学硕士背景下的各种解码方法进行了全面、多方面的分析，评估了它们的性能、对超参数变化的鲁棒性以及跨各种任务、模型和部署环境的解码速度。我们的研究结果表明，解码方法的性能明显依赖于任务，并受到对齐、模型大小和量化等因素的影响。有趣的是，敏感性分析表明，某些方法以大量超参数调整为代价实现了卓越的性能，强调了在不同环境下获得最佳结果和实现实用性之间的权衡。]]></description>
      <guid>https://arxiv.org/abs/2402.06925</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>LiFi：具有细粒度控制代码的轻量级受控文本生成</title>
      <link>https://arxiv.org/abs/2402.06930</link>
      <description><![CDATA[在快速发展的文本生成领域，对更精确控制机制的需求变得越来越明显。为了满足这一需求，我们提出了一种新颖的方法，LIFI，它提供了一种轻量级方法，具有细粒度的控制来控制文本生成。与之前训练预训练语言模型以遵循离散、分类和排他控制代码的研究不同，LIFI 在连续、相对和非排他控制代码的指导下学习受控文本生成。这些细粒度代码是从属性分类器自动派生的，最初用少量标记数据进行训练，随后用于标记大量未标记数据，从而获得更广泛的监督信号。此外，为了实现高效控制，我们将细粒度控制代码与适配器结合起来，这是一种参数和计算高效的方法来引导预训练的语言模型。我们在两项传统任务（情绪控制和主题控制）和一项新提出的任务（文体小说写作）上评估 LIFI。综合实验结果验证了我们提出的方法的有效性，证明了相对于现有基线的显着性能改进。]]></description>
      <guid>https://arxiv.org/abs/2402.06930</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以识别毒性吗？结构化毒性调查框架和基于语义的度量</title>
      <link>https://arxiv.org/abs/2402.06900</link>
      <description><![CDATA[为了开发符合社会标准的大型语言模型 (LLM)，必须辨别生成的文本中是否存在毒性。大多数现有的毒性指标依赖于在特定毒性数据集上训练的编码器模型。然而，这些编码器容易受到分布外（OOD）问题的影响，并且取决于数据集中假设的毒性定义。在本文中，我们引入了一种基于 LLM 的自动鲁棒度量来区分模型响应是否有毒。我们首先分析毒性因素，然后检查法学硕士的内在毒性属性，以确定他们作为评估者的适合性。随后，我们在评估数据集上评估了我们的指标 LLM 作为毒性评估者 (LATTE)。实证结果表明，在测量毒性方面表现出色，在没有训练程序的情况下，F1 分数比最先进的指标提高了 12 分。我们还表明上游毒性对下游指标有影响。]]></description>
      <guid>https://arxiv.org/abs/2402.06900</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>研究基于查询的会议摘要的一致性：不同嵌入方法的比较研究</title>
      <link>https://arxiv.org/abs/2402.06907</link>
      <description><![CDATA[随着越来越多先进的数据分析技术的出现，人们将期望这些技术能够应用于更复杂的任务并解决我们日常生活中的问题。文本摘要是自然语言处理（NLP）领域的著名应用之一。它的目的是根据给定的上下文自动生成包含重要信息的摘要，这在您必须处理成堆的文档时非常重要。总结技巧可以帮助我们在短时间内抓住要点，给工作带来便利。适用的情况之一是会议总结，特别是对于往往时间长、复杂、多主题、多人的重要会议。因此，当人们想要查看会议的具体内容时，在会议记录中找到相关的跨度将是困难且耗时的。然而，以前的大部分工作都集中在对时事通讯、科学文章等进行摘要，它们具有清晰的文档结构和官方格式。对于像笔录这样结构复杂的文件，我们认为这些作品不太适合会议总结。此外，摘要的一致性是NLP领域经常讨论的另一个问题。为了克服会议总结的挑战，我们受到微软提出的“QMSum：基于查询的多域会议总结的新基准”的启发，我们还提出了我们的 Locater 模型，旨在根据给定的记录和查询提取相关跨度，这然后通过 Summarizer 模型进行总结。此外，我们通过应用不同的词嵌入技术来提高摘要的一致性来进行比较研究。]]></description>
      <guid>https://arxiv.org/abs/2402.06907</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的历史、发展和原理-介绍性调查</title>
      <link>https://arxiv.org/abs/2402.06853</link>
      <description><![CDATA[语言模型是自然语言处理（NLP）的基石，利用数学方法概括语言规律和知识以进行预测和生成。经过数十年的广泛研究，语言建模已经从最初的统计语言模型 (SLM) 发展到当代的大型语言模型 (LLM)。值得注意的是，法学硕士的迅速发展已经达到了处理、理解和生成人类水平文本的能力。然而，尽管法学硕士在改善工作和个人生活方面具有显着优势，但全科医生对这些模式的背景和原则的了解有限，阻碍了其充分发挥潜力。值得注意的是，大多数法学硕士的评审都集中在特定方面并使用专门的语言，这对缺乏相关背景知识的从业者提出了挑战。有鉴于此，本调查旨在提供法学硕士的全面概述，以帮助更广泛的受众。它致力于通过探索语言模型的历史背景并追踪其随时间的演变来促进全面理解。该调查进一步调查了影响法学硕士发展的因素，强调了关键贡献。此外，它还专注于阐明法学硕士的基本原理，为观众提供必要的理论知识。该调查还强调了现有工作的局限性，并指出了有希望的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2402.06853</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>GenTranslate：大型语言模型是生成多语言语音和机器翻译器</title>
      <link>https://arxiv.org/abs/2402.06894</link>
      <description><![CDATA[大语言模型 (LLM) 的最新进展通过减少表示错误并结合外部知识，推动了多语言语音和机器翻译的发展。然而，这两个翻译任务通常都利用波束搜索解码和 top-1 假设选择来进行推理。这些技术难以充分利用各种 N 最佳假设中的丰富信息，这使得它们对于需要单一高质量输出序列的翻译任务来说不太理想。在本文中，我们提出了一种新的翻译任务生成范式，即“GenTranslate”，它建立在法学硕士的基础上，从 N 最佳列表中的不同翻译版本中生成更好的结果。利用法学硕士丰富的语言知识和强大的推理能力，我们的新范式可以整合N个最佳候选者中的丰富信息，从而生成更高质量的翻译结果。此外，为了支持 LLM 微调，我们构建并发布了一个 HypoTranslate 数据集，其中包含 11 种语言的超过 592K 假设-翻译对。对各种语音和机器翻译基准（例如 FLEURS、CoVoST-2、WMT）的实验表明，我们的 GenTranslate 显着优于最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2402.06894</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>EntGPT：将生成式大语言模型与知识库联系起来</title>
      <link>https://arxiv.org/abs/2402.06738</link>
      <description><![CDATA[由于在训练和推理过程中缺乏事实检查和知识基础，大型语言模型（LLM）生成事实正确输出的能力仍然相对未被探索。在这项工作中，我们的目标是通过实体消歧（ED）任务来应对这一挑战。我们首先考虑提示工程，并设计了一种三步硬提示方法来探测法学硕士的 ED 性能，而无需监督微调（SFT）。总体而言，该提示方法大幅提高了原始普通模型的 micro-F_1 分数，在某些情况下高达 36% 甚至更高，并且与现有的 SFT 方法相比，在 10 个数据集上获得了可比的性能。我们通过类似提示和响应的指令调整（IT）进一步提高知识基础能力。与监督实体消歧任务上的几种基线方法相比，指令调整模型不仅实现了更高的 micro-F1 分数性能，平均 micro-F_1 比现有基线模型提高了 2.1%，而且在六个问答上获得了更高的准确性（QA）零样本设置中的任务。我们的方法适用于开源和闭源法学硕士。]]></description>
      <guid>https://arxiv.org/abs/2402.06738</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>NLP 中文本数据增强的评估指标</title>
      <link>https://arxiv.org/abs/2402.06766</link>
      <description><![CDATA[最近关于自然语言处理数据增强的调查报告了该领域的不同技术和进展。一些框架、工具和存储库促进了文本数据增强管道的实施。然而，由于任务、指标、数据集、架构和实验设置的不同，缺乏方法比较的评估标准和标准，使得比较毫无意义。此外，缺乏统一的方法，文本数据增强研究将受益于统一的指标来比较不同的增强方法。因此，学术界和业界致力于文本数据增强技术的相关评估指标。这项工作的贡献是为文本增强方法提供评估指标的分类，并作为统一基准的方向。拟议的分类法组织了包括实施和指标计算工具的类别。最后，通过这项研究，我们打算提供探索文本数据增强指标的统一和标准化的机会。]]></description>
      <guid>https://arxiv.org/abs/2402.06766</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>NICE：是否优化上下文示例？</title>
      <link>https://arxiv.org/abs/2402.06733</link>
      <description><![CDATA[最近的研究表明，通过上下文学习和上下文示例优化 (ICE)，大型语言模型 (LLM) 在各种任务上表现出色。然而，大多数这些研究都假设提示中提供了固定的说明或没有提供说明，这导致了明显的共识：上下文示例的优化对于更好的性能至关重要。我们通过调查在提供特定于任务的指令时优化上下文示例的必要性来挑战这种针对指令调整的 LLM 的共识，并发现对于某些任务，优化上下文示例的各种方法会产生收益递减的效果。我们引入了一个名为 \metriclong{} (\metric) 的特定于任务的指标，它量化给定指令中任务的可学习性，并提供启发式方法来帮助决定是否针对任何新任务优化指令或 ICE。在广泛的任务和逐渐添加细节的系统创建的指令集上，我们通过使用依赖于查询的示例箱计算 \metric、将不同指令与 ICE 选择方法进行比较以及执行标签扰动实验来实证验证我们的假设。我们得出的结论是，任务可以根据 \metric 指标分为两大类，其中当提示中提供指令时，ICE 优化的回报遵循可预测的趋势。]]></description>
      <guid>https://arxiv.org/abs/2402.06733</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:34 GMT</pubDate>
    </item>
    </channel>
</rss>