<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>https://arxiv.org/rss/</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 02 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>机器人说什么？大型语言模型在社交媒体机器人检测中的机遇和风险</title>
      <link>https://arxiv.org/abs/2402.00371</link>
      <description><![CDATA[社交媒体机器人检测一直是机器学习机器人检测器的进步与逃避检测的对抗性机器人策略之间的军备竞赛。在这项工作中，我们通过研究最先进的大型语言模型 (LLM) 在社交机器人检测中的机遇和风险，将军备竞赛提升到了一个新的水平。为了研究这些机会，我们通过提出一种异构专家混合框架来划分和征服不同的用户信息模式，设计了新颖的基于 LLM 的机器人检测器。为了阐明风险，我们探讨了法学硕士指导下操纵用户文本和结构化信息以逃避检测的可能性。在两个数据集上使用三个 LLM 进行的广泛实验表明，仅对 1,000 个带注释的示例进行指令调整就可以产生专门的 LLM，其在两个数据集上的性能均优于最先进的基线高达 9.1％，而 LLM 引导的操作策略可以显着降低现有机器人检测器的性能下降高达 29.6%，并损害机器人检测系统的校准和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2402.00371</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:10 GMT</pubDate>
    </item>
    <item>
      <title>从预训练到适应的意见总结偏差：政治偏见案例研究</title>
      <link>https://arxiv.org/abs/2402.00322</link>
      <description><![CDATA[意见摘要旨在将产品评论、论坛、社交媒体文本等文档中呈现的显着信息和意见总结成简短的摘要，使用户能够有效地理解其中的意见。生成有偏见的摘要可能会影响公众舆论。先前的研究主要集中于使用提取模型研究观点概括中的偏差，但有限的研究关注抽象概括模型。在本研究中，以政治偏见为案例研究，我们首先建立了一种量化抽象模型中偏见的方法，然后将其从预先训练的模型追溯到使用不同模型和适应方法总结社交媒体意见的任务。我们发现大多数模型都表现出内在偏差。使用社交媒体文本摘要数据集并对比各种适应方法，我们发现与标准微调相比，调整较少数量的参数偏差较小；然而，用于微调的训练数据主题的多样性至关重要。]]></description>
      <guid>https://arxiv.org/abs/2402.00322</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:09 GMT</pubDate>
    </item>
    <item>
      <title>IndiVec：利用大型语言模型通过细粒度偏差指标进行媒体偏差检测的探索</title>
      <link>https://arxiv.org/abs/2402.00345</link>
      <description><![CDATA[这项研究的重点是媒体偏见检测，这在当今有影响力的社交媒体平台塑造个人态度和观点的时代至关重要。与之前的工作主要依赖于训练针对特定数据集的特定模型，从而导致域外数据的适应性有限和性能不佳相比，我们引入了一种基于大型语言模型的通用偏差检测框架 IndiVec。 IndiVec 首先构建细粒度的媒体偏差数据库，利用大型语言模型和向量数据库技术强大的指令跟踪功能。当遇到用于偏差检测的新输入时，我们的框架会自动从向量数据库中选择最相关的指标，并采用多数投票来确定输入的偏差标签。与以前的方法相比，IndiVec 因其适应性（在不同来源的不同数据集上表现出一致的性能）和可解释性（提供明确的 top-k 指标来解释偏差预测）而表现出色。四个政治偏见数据集的实验结果凸显了 IndiVec 相对于基线的显着优势。此外，额外的实验和分析为该框架的有效性提供了深刻的见解。]]></description>
      <guid>https://arxiv.org/abs/2402.00345</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:09 GMT</pubDate>
    </item>
    <item>
      <title>不要产生幻觉，放弃：通过多法学硕士合作识别法学硕士知识差距</title>
      <link>https://arxiv.org/abs/2402.00367</link>
      <description><![CDATA[尽管努力扩展大型语言模型 (LLM) 的知识，但鉴于知识不断发展的性质，知识差距（LLM 中缺失或过时的信息）可能始终持续存在。在这项工作中，我们研究了识别法学硕士知识差距的方法，并在存在知识差距时避免回答问题。我们首先通过微调/提示来调整现有方法来进行模型校准或适应，并分析它们避免生成低置信度输出的能力。出于自我反思失败和过度依赖保留集的动机，我们提出了两种基于模型协作的新方法，即法学硕士以合作或竞争的方式探索其他法学硕士的知识差距。三位法学硕士在具有不同知识领域的四项 QA 任务上进行的广泛实验表明，与最强基线相比，揭示法学硕士知识差距的合作和竞争方法在弃权准确性方面实现了高达 19.3% 的提高。进一步的分析表明，我们提出的机制可以帮助识别检索增强中的失败案例，并查明多跳推理中的知识差距。]]></description>
      <guid>https://arxiv.org/abs/2402.00367</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:09 GMT</pubDate>
    </item>
    <item>
      <title>探索在公共语音识别语料库上训练的仅解码器模型的局限性</title>
      <link>https://arxiv.org/abs/2402.00235</link>
      <description><![CDATA[Whisper 和 USM 等工业规模语音识别 (ASR) 模型的出现，分别在 100 万小时的弱标记和 1200 万小时的纯音频专有数据上进行训练，导致对大规模公共 ASR 语料库和竞争性开放的需求更加强烈。源管道。与上述模型不同，大型语言模型通常基于 Transformer 解码器，目前尚不清楚仅在公共数据上训练的仅解码器模型是否可以提供有竞争力的性能。在这项工作中，我们研究了仅使用公共英语 ASR 语料库获得最佳性能所需的训练数据集和建模组件的选择等因素。我们的仅解码器 Transformer for ASR (DOTA) 模型在几乎所有英语 ASR 基准测试中全面优于 Whisper 的编码器-解码器开源复制 (OWSM)，并且在 15 个测试集中的 7 个测试集上优于 Whisper large-v3。我们在许可下发布代码库和模型检查点。]]></description>
      <guid>https://arxiv.org/abs/2402.00235</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:08 GMT</pubDate>
    </item>
    <item>
      <title>\textsc{DetectGPT} 是否充分利用了扰动？基于模型的对比学习检测器的选择性扰动会更好</title>
      <link>https://arxiv.org/abs/2402.00263</link>
      <description><![CDATA[大型语言模型（LLM）不断发展的能力引起了人们对滥用的日益关注。 DetectGPT 是一种基于零样本度量的无监督机器生成文本检测器，首先引入了扰动，并显示出巨大的性能改进。然而，DetectGPT 的随机扰动策略可能会引入噪声，限制可区分性和进一步的性能改进。而且，其logit回归模块依赖于阈值的设置，这损害了单个或小批量输入的通用性和适用性。因此，我们提出了一种新颖的检测器 \modelname{}，它使用选择性策略扰动来减轻随机掩蔽造成的重要信息丢失，并使用多对对比学习来捕获扰动期间的隐式模式信息，从而促进小样本性能。实验表明，\modelname{} 在四个公共数据集上的准确率平均优于 SOTA 方法 1.20\%。我们进一步分析了我们的扰动方法的有效性、鲁棒性和泛化性。]]></description>
      <guid>https://arxiv.org/abs/2402.00263</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:08 GMT</pubDate>
    </item>
    <item>
      <title>自然语言中排名频率关系的关键参数</title>
      <link>https://arxiv.org/abs/2402.00271</link>
      <description><![CDATA[经验表明 $f \propto r^{-\alpha} \cdot (r+\gamma)^{-\beta}$ 比朴素幂律 $f\propto r^{-\alpha} 更精确$ 来模拟自然语言中单词的排名频率 ($r$-$f$) 关系。这项工作表明，公式中唯一关键的参数是 $\gamma$，它描述了语料库上词汇量增长的阻力提出了一种通过搜索最优$\gamma$进行参数估计的方法，其中技术上引入了“零字”进行计算，并通过几个案例进一步讨论了公式和参数。]]></description>
      <guid>https://arxiv.org/abs/2402.00271</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:08 GMT</pubDate>
    </item>
    <item>
      <title>使用 EHR 多重嵌入模型 (MEME) 进行急诊科预测任务的多模态临床伪注释</title>
      <link>https://arxiv.org/abs/2402.00160</link>
      <description><![CDATA[在这项工作中，我们引入了 EHR 的多重嵌入模型 (MEME)，这是一种将电子健康记录 (EHR) 视为多模态数据的方法。这种方法结合了“伪注释”，即表格 EHR 概念（例如诊断和药物）的文本表示，并允许我们有效地采用大型语言模型 (LLM) 进行 EHR 表示。该框架还采用多模式方法，分别嵌入每个 EHR 模式。我们通过将 MEME 应用于多个医院系统急诊科的多项任务来证明 MEME 的有效性。我们的研究结果表明，MEME 超越了单一模态嵌入方法和传统机器学习方法的性能。然而，我们也观察到所有测试模型在医院机构中的普遍性存在显着局限性。]]></description>
      <guid>https://arxiv.org/abs/2402.00160</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:07 GMT</pubDate>
    </item>
    <item>
      <title>去识别化并不总是足够的</title>
      <link>https://arxiv.org/abs/2402.00179</link>
      <description><![CDATA[对于共享隐私敏感数据，去标识化通常被认为足以保护隐私。合成数据也被视为一种保护隐私的替代方案。最近数字和表格数据生成模型的成功以及大型生成语言模型的突破提出了一个问题：综合生成的临床笔记是否可以成为用于研究目的的真实笔记的可行替代方案。在这项工作中，我们证明了（i）真实临床记录的去识别并不能保护记录免受成员推理攻击，（ii）提出了一种使用当前最先进的大型记录生成合成临床记录的新方法。语言模型，（iii）评估了临床领域任务中综合生成的注释的性能，以及（iv）提出了一种发起成员推理攻击的方法，其中目标模型使用合成数据进行训练。我们观察到，当综合生成的注释与真实数据的性能非常匹配时，它们也表现出与真实数据类似的隐私问题。综合生成临床记录的其他方法是否可以提供更好的权衡，并成为敏感真实记录的更好替代品，值得进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2402.00179</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:07 GMT</pubDate>
    </item>
    <item>
      <title>语言适配器对 NLU 跨语言迁移的影响</title>
      <link>https://arxiv.org/abs/2402.00149</link>
      <description><![CDATA[模块化深度学习被提出来使预训练模型有效地适应新的任务、领域和语言。特别是，在语言不存在监督数据的情况下，将语言适配器与任务适配器相结合已显示出潜力。在本文中，我们探讨了语言适配器在自然语言理解（NLU）基准的零样本跨语言迁移中的作用。我们使用两个多语言模型和三个多语言数据集研究了在详细消融研究中包含目标语言适配器的效果。我们的结果表明，目标语言适配器的效果在不同任务、语言和模型之间高度不一致。相反，保留源语言适配器通常会带来同等的性能，有时甚至会带来更好的性能。训练后删除语言适配器仅产生微弱的负面影响，表明语言适配器对预测没有强烈影响。]]></description>
      <guid>https://arxiv.org/abs/2402.00149</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:06 GMT</pubDate>
    </item>
    <item>
      <title>用于数学推理的大型语言模型：进展与挑战</title>
      <link>https://arxiv.org/abs/2402.00157</link>
      <description><![CDATA[数学推理是评估人类智力基本认知能力的基石。近年来，旨在自动解决数学问题的大型语言模型（LLM）的发展显着激增。然而，数学问题类型的范围广阔且多种多样，面向法学硕士的技术正在不同的数据集和设置中进行评估。这种多样性使得辨别这个新兴领域的真正进步和障碍变得具有挑战性。这项调查致力于解决四个关键维度：i）对已调查的各种数学问题及其相应数据集的全面探索； ii) 对为解决数学问题而提出的法学硕士导向技术的范围进行检查； iii) 影响法学硕士解决数学问题的因素和关注点概述； iv) 阐明该领域持续存在的挑战。据我们所知，这项调查是对数学领域法学硕士前景的首次广泛调查之一，为这个快速发展的领域的当前状态、成就和未来挑战提供了整体视角。]]></description>
      <guid>https://arxiv.org/abs/2402.00157</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:06 GMT</pubDate>
    </item>
    <item>
      <title>卓玛：用于语言模型预训练研究的三万亿代币开放语料库</title>
      <link>https://arxiv.org/abs/2402.00159</link>
      <description><![CDATA[语言模型已成为解决各种自然语言处理任务的关键技术，但有关如何开发性能最佳的语言模型的许多细节尚未报道。特别是，有关其预训练语料库的信息很少被讨论：商业语言模型很少提供有关其数据的任何信息；即使是开放模型也很少发布它们所训练的数据集，或者重现它们的确切方法。因此，进行某些语言建模研究是具有挑战性的，例如了解训练数据如何影响模型功能并形成其局限性。为了促进语言模型预训练的开放研究，我们发布了 Dolma，这是一个包含 3 万亿个代币的英语语料库，由网络内容、科学论文、代码、公共领域书籍、社交媒体和百科全书材料的多种组合构建而成。此外，我们还开源数据管理工具包，以便进一步实验和复制我们的工作。在这份报告中，我们记录了卓玛，包括其设计原理、构造细节以及内容摘要。我们将这份报告与在卓玛中间状态上训练语言模型的分析和实验结果相结合，以分享我们对重要数据管理实践的了解，包括内容或质量过滤器、重复数据删除和多源混合的作用。 Dolma 已用于训练 OLMo，这是一种最先进的开放语言模型和框架，旨在构建和研究语言建模科学。]]></description>
      <guid>https://arxiv.org/abs/2402.00159</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:06 GMT</pubDate>
    </item>
    <item>
      <title>D-Nikud：使用 LSTM 和预训练模型增强希伯来语变音符</title>
      <link>https://arxiv.org/abs/2402.00075</link>
      <description><![CDATA[D-Nikud，一种希伯来语变音的新颖方法，集成了 LSTM 网络和基于 BERT（变压器）的预训练模型的优势。受到 Nakdimon 采用的方法的启发，我们将其与 TavBERT 预训练模型集成，我们的系统融合了先进的架构选择和多样化的训练数据。我们的实验展示了几个基准数据集的最新结果，特别强调现代文本和更具体的变音符号（例如性别）。]]></description>
      <guid>https://arxiv.org/abs/2402.00075</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:05 GMT</pubDate>
    </item>
    <item>
      <title>比较基于模板和无模板的语言模型探测</title>
      <link>https://arxiv.org/abs/2402.00123</link>
      <description><![CDATA[完形填空语言模型 (LM) 探测与 1) 专家制作的模板和 2) 自然出现的文本之间的差异经常被忽视。在这里，我们在一般和生物医学领域的 10 个探索性英语数据集（4 个基于模板和 6 个无模板）上评估 16 个不同的 LM，以回答以下研究问题：（RQ1）两种方法之间的模型排名是否不同？ (RQ2) 两种方法之间模型的绝对分数是否不同？ （RQ3）通用模型和特定领域模型之间 RQ1 和 RQ2 的答案是否不同？我们的发现是：1）无模板和基于模板的方法通常对模型进行不同的排名，除了顶级的特定领域模型。 2) 比较并行的无模板和基于模板的提示时，分数下降高达 42% Acc@1。 3）在无模板方法中，困惑度与准确性呈负相关，但与直觉相反，它们对于基于模板的探测呈正相关。 4) 模型倾向于在基于模板的探测提示中频繁预测相同的答案，这在采用无模板技术时不太常见。]]></description>
      <guid>https://arxiv.org/abs/2402.00123</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:05 GMT</pubDate>
    </item>
    <item>
      <title>长话短说对话建模</title>
      <link>https://arxiv.org/abs/2402.00143</link>
      <description><![CDATA[对话系统适应具有独特个性和独特写作风格的不同用户。在多轮对话建模领域，这项工作研究了不同的话语长度对对话模型生成的后续响应质量的影响。使用 GPT-3 作为基础模型、多个对话数据集和多个指标，我们对对话模型的这方面进行了彻底的探索。我们的分析揭示了话语长度与对话系统生成的后续响应质量之间的复杂关系。实证结果表明，对于某些类型的对话，话语长度最多可以减少 72%，而后续响应的质量没有任何明显差异。]]></description>
      <guid>https://arxiv.org/abs/2402.00143</guid>
      <pubDate>Fri, 02 Feb 2024 18:17:05 GMT</pubDate>
    </item>
    </channel>
</rss>