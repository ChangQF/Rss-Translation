<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 28 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>极端编码器输出帧率降低：改善大型端到端模型的计算延迟</title>
      <link>https://arxiv.org/abs/2402.17184</link>
      <description><![CDATA[arXiv:2402.17184v1 公告类型：新
摘要：随着规模扩大，端到端（E2E）自动语音识别（ASR）模型的准确性不断提高，有些模型现在已达到数十亿个参数。然而，这些模型的广泛部署和采用需要计算高效的解码策略。在目前的工作中，我们研究了一种这样的策略：在编码器中应用多个帧缩减层将编码器输出压缩为少量输出帧。虽然在之前的工作中已经研究了类似的技术，但与之前通过使用多个漏斗减少层所证明的相比，我们实现了显着更多的减少。通过消融，我们研究编码器中各种架构选择的影响，以确定最有效的策略。我们证明，我们可以为每 2.56 秒的输入语音生成一个编码器输出帧，而不会显着影响大规模语音搜索任务的单词错误率，同时相对于强大但计算成本昂贵的基线。]]></description>
      <guid>https://arxiv.org/abs/2402.17184</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>利用编码器解缠进行代码转换语音识别的有效专家混合方法</title>
      <link>https://arxiv.org/abs/2402.17189</link>
      <description><![CDATA[arXiv:2402.17189v1 公告类型：新
摘要：随着端到端（E2E）神经网络的大规模发展，近年来自动语音识别（ASR）取得了前所未有的突破。然而，语码转换现象仍然是阻碍 ASR 完善的主要障碍，因为标记数据的缺乏和语言之间的差异往往会导致 ASR 性能的下降。在本文中，我们专注于改进 E2E ASR 的声学编码器，以应对代码转换现象带来的挑战。我们的主要贡献有三个：首先，我们引入了一种新颖的解缠结损失，使编码器的较低层能够捕获语言间的声学信息，同时减轻编码器较高层的语言混乱。其次，通过全面的实验，我们验证了我们提出的方法优于使用预训练双编码器的现有技术方法，同时只能访问语码转换语料库并消耗一半的参数化。第三，编码器输出特征的明显差异也证实了解缠结损失和专家混合（MoE）架构之间的互补性。]]></description>
      <guid>https://arxiv.org/abs/2402.17189</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>事实与反思 (FaR) 提高大型语言模型的置信度校准</title>
      <link>https://arxiv.org/abs/2402.17124</link>
      <description><![CDATA[arXiv:2402.17124v1 公告类型：新
摘要：对于一个值得信赖的法学硕士来说，其置信水平应该与其实际表现进行良好的校准。虽然现在众所周知，法学硕士的表现很大程度上受到提示的影响，但提示法学硕士的信心校准尚未得到彻底探索。在本文中，我们探讨了不同的提示策略如何影响 LLM 信心校准以及如何改进。我们对问答环境中的六种提示方法进行了广泛的实验，我们观察到，虽然这些方法有助于提高预期的法学硕士校准，但它们也会导致法学硕士在应对某些情况时过于自信。受人类认知的启发，我们提出事实与反思（FaR）提示，分两步改进了 LLM 校准。首先，FaR 引出与 LLM 的输入提示相关的已知“事实”。然后它要求模型“反思”它们以生成最终答案。实验表明FaR提示取得了明显更好的校准效果；它使我们的多用途 QA 任务的预期校准误差降低了 23.5%。值得注意的是，FaR 提示甚至可以在不太自信的场景中引发口头表达担忧的能力，这有助于触发检索增强来解决这些更困难的情况。]]></description>
      <guid>https://arxiv.org/abs/2402.17124</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>聚类文档部分：从文档中检测和表征影响力活动</title>
      <link>https://arxiv.org/abs/2402.17151</link>
      <description><![CDATA[arXiv:2402.17151v1 公告类型：新
摘要：我们提出了一种新颖的聚类管道来检测和表征文档中的影响力活动。这种方法对文档的各个部分进行聚类，检测可能反映影响力活动的聚类，然后通过与高影响力聚类的关联来识别与影响力活动相关的文档。在预测文档是否是影响力活动的一部分方面，我们的方法优于直接文档级分类和直接文档级聚类方法。我们提出了各种新技术来增强我们的管道，包括使用现有的事件事实预测系统来获取文档部分，以及聚合多个聚类实验以提高聚类和文档分类的性能。在聚类顶部对文档进行分类不仅可以准确地提取文档中与影响力活动相关的部分，而且还可以将影响力活动捕获为协调的整体现象。我们的方法使得从文档中对影响力活动进行更细粒度和可解释的表征成为可能。]]></description>
      <guid>https://arxiv.org/abs/2402.17151</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型通过讲故事学习复杂的法律概念</title>
      <link>https://arxiv.org/abs/2402.17019</link>
      <description><![CDATA[arXiv:2402.17019v1 公告类型：新
摘要：向非专家提供法律知识对于提高普通法律素养和鼓励公民参与民主至关重要。然而，对于没有法律背景的人来说，法律文件往往难以理解。在本文中，我们提出了大语言模型（LLM）在法律教育中的新颖应用，以帮助非专家通过讲故事来学习复杂的法律概念，这是传达复杂和抽象概念的有效教学工具。我们还引入了一个新的数据集 LegalStories，它由 295 个复杂的法律原则组成，每个原则都附有一个故事和一组由法学硕士生成的多项选择题。为了构建数据集，我们尝试了各种法学硕士来生成解释这些概念的法律故事。此外，我们使用专家循环方法来迭代设计多项选择题。然后，我们通过对法律新手对数据集中的 10 个样本进行 RCT 实验来评估法学硕士讲故事的有效性。我们发现，与仅定义相比，法学硕士生成的故事增强了非母语人士对法律概念的理解和对法律的兴趣。此外，故事不断帮助参与者将法律概念与他们的生活联系起来。最后，我们发现在后续评估中，通过故事学习对于非母语人士来说具有更高的保留率。我们的工作对于利用法学硕士促进法律领域及其他领域的教学和学习具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2402.17019</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>重新表达：解释后进行修改可以减少 LLM 回复中的事实错误</title>
      <link>https://arxiv.org/abs/2402.17097</link>
      <description><![CDATA[arXiv:2402.17097v1 公告类型：新
摘要：减轻幻觉问题是法学硕士需要克服的主要挑战之一，以便在现实场景中可靠地使用它们。最近，人们提出了各种方法来检查LLM生成的文本中的事实错误并进行相应的修改，以减少幻觉问题。在本文中，我们提出了 Re-Ex，一种修改 LLM 生成文本的方法，它引入了一个被称为事实错误解释步骤的新颖步骤。 Re-Ex通过三个步骤修改LLM的初始回复：首先，使用外部工具获取回复中事实错误的证据；其次，要求法学硕士根据第一步收集的证据解释答复中存在问题的部分；最后，法学硕士使用第二步中获得的解释修改答案。除了解释步骤之外，我们还提出了新的提示技术，以减少响应修订过程所需的令牌数量和挂钟时间。与 Factool、CoVE 和 RARR 等现有方法相比，Re-Ex 在多个基准测试中以更少的时间和更少的标记提供了更好的修订性能。]]></description>
      <guid>https://arxiv.org/abs/2402.17097</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>创造悬疑故事：利用大型语言模型进行迭代规划</title>
      <link>https://arxiv.org/abs/2402.17119</link>
      <description><![CDATA[arXiv:2402.17119v1 公告类型：新
摘要：自动故事生成一直是 NLP 领域长期存在的挑战之一。在故事的各个维度中，悬念在人类编写的故事中非常常见，但在人工智能生成的故事中相对较少被探索。虽然大型语言模型 (LLM) 的最新进展总体上极大地促进了语言生成，但在生成悬疑故事时，最先进的 LLM 仍然不可靠。我们提出了一种新颖的基于迭代提示的规划方法，该方法基于认知心理学和叙事学的故事悬念两个理论基础。这种基于理论的方法以完全零样本的方式工作，并且不依赖于任何有监督的故事语料库。据我们所知，本文是法学硕士首次尝试生成悬疑故事。对生成的悬疑故事进行广泛的人类评估证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.17119</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>瑞士判断预测的可解释性和公平性：多语言数据集的基准测试</title>
      <link>https://arxiv.org/abs/2402.17013</link>
      <description><![CDATA[arXiv:2402.17013v1 公告类型：新
摘要：法律判决预测（LJP）系统的可解释性评估对于构建值得信赖和透明的系统至关重要，特别是考虑到这些系统对可能缺乏法律相关性或涉及敏感属性的因素的依赖。本研究利用唯一可用的多语言 LJP 数据集瑞士判断预测 (SJP)，深入探讨了 LJP 模型的可解释性和公平性领域。我们以德语、法语和意大利语收集了法律专家对 108 个案件的“支持”和“反对”判决的综合理由。通过采用基于遮挡的可解释性方法，我们评估了最先进的基于 BERT 的单语言和多语言 LJP 模型以及使用数据增强和跨语言传输等技术开发的模型的可解释性性能，这证明了预测性能改进。值得注意的是，我们的研究结果表明，预测性能的提高并不一定对应于可解释性性能的增强，这强调了从可解释性角度评估模型的重要性。此外，我们引入了一种新颖的评估框架，即下级法院插入（LCI），它使我们能够量化下级法院信息对模型预测的影响，揭示当前模型的偏差。]]></description>
      <guid>https://arxiv.org/abs/2402.17013</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>Z-AGI 实验室参加 ClimateActivism 2024：社交媒体上的立场和仇恨事件检测</title>
      <link>https://arxiv.org/abs/2402.17014</link>
      <description><![CDATA[arXiv:2402.17014v1 公告类型：新
摘要：在数字领域，丰富的数据是洞察社会、政治和经济格局复杂性的重要来源。为了满足对事件的高质量信息日益增长的需求以及打击仇恨言论的迫切需要，这项研究导致在 CASE 2024 上建立了气候行动主义立场和仇恨事件检测的共享任务。重点关注与仇恨言论作斗争的气候活动家社交媒体上，我们的研究有助于从推文中识别仇恨言论。分析三个子任务 - 仇恨言论检测（子任务 A）、仇恨言论识别目标（子任务 B）和姿态检测（子任务 C） - Z-AGI 团队实验室评估了各种模型，包括 LSTM、 Xgboost和基于Tf-Idf的LGBM。结果揭示了有趣的变化，Catboost 在子任务 B（F1：0.5604）和子任务 C（F1：0.7081）中表现出色，而 LGBM 成为子任务 A（F1：0.8684）中表现最好的模型。这项研究为经典机器学习模型在气候仇恨言论和立场检测中的适用性提供了宝贵的见解，有助于为稳健的机制选择明智的模型。]]></description>
      <guid>https://arxiv.org/abs/2402.17014</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>8192 个令牌双语文本嵌入的多任务对比学习</title>
      <link>https://arxiv.org/abs/2402.17016</link>
      <description><![CDATA[arXiv:2402.17016v1 公告类型：新
摘要：我们介绍了一套新颖的、最先进的双语文本嵌入模型，旨在支持英语和另一种目标语言。这些模型能够处理包含多达 8192 个标记的冗长文本输入，使其非常适用于一系列自然语言处理任务，例如文本检索、聚类和语义文本相似性 (STS) 计算。
  通过专注于双语模型并引入独特的多任务学习目标，我们显着提高了模型在STS任务上的性能，在目标语言理解和跨语言评估任务上都优于现有多语言模型的能力。此外，我们的双语模型更加高效，由于词汇量需求较小，因此需要更少的参数和内存。此外，我们还扩展了大规模文本嵌入基准 (MTEB)，以包括德语和西班牙语嵌入模型的基准。这种集成旨在促进这些语言的文本嵌入技术的进一步研究和进步。]]></description>
      <guid>https://arxiv.org/abs/2402.17016</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以像人类一样回忆参考位置吗？</title>
      <link>https://arxiv.org/abs/2402.17010</link>
      <description><![CDATA[arXiv:2402.17010v1 公告类型：新
摘要：人类在完成知识密集型任务时，有时不仅需要答案，还需要相应的参考文章来辅助阅读。以前的方法需要通过额外的检索模型获取预先分割的文章块。本文探索利用大型语言模型 (LLM) 预训练阶段存储的参数化知识，从任何起始位置独立回忆参考段落。我们提出了一个两阶段框架，模拟人类回忆容易忘记的参考文献的场景。最初，法学硕士会被提示回忆文档标题标识符以获得粗粒度的文档集。然后，根据获取的粗粒度文档集，回忆出细粒度的段落。在两阶段召回过程中，我们使用约束解码来确保不会生成存储文档之外的内容。为了提高速度，我们在第二阶段只回忆一个短前缀，然后找到它的位置来检索完整的段落。 KILT知识敏感任务的实验验证了LLM可以在各种任务形式中独立回忆参考段落位置，并且获得的参考显着辅助下游任务。]]></description>
      <guid>https://arxiv.org/abs/2402.17010</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>DiffuCOMET：上下文常识知识扩散</title>
      <link>https://arxiv.org/abs/2402.17011</link>
      <description><![CDATA[arXiv:2402.17011v1 公告类型：新
摘要：推断上下文相关且多样化的常识来理解叙述对于知识模型来说仍然具有挑战性。在这项工作中，我们开发了一系列知识模型 DiffuCOMET，利用扩散来学习重建叙事上下文和相关常识知识之间的隐式语义联系。通过多个扩散步骤，我们的方法逐步完善了以叙述为基础的常识事实的表示，为输入上下文生成上下文相关且多样化的常识推论。为了评估 DiffuCOMET，我们引入了新的常识推理指标，可以更密切地衡量知识多样性和上下文相关性。我们在 ComFact 和 WebNLG+ 两个不同基准上的结果表明，与基线知识模型相比，DiffuCOMET 生成的知识在常识多样性、上下文相关性和与已知黄金参考的一致性之间实现了更好的权衡。]]></description>
      <guid>https://arxiv.org/abs/2402.17011</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>长对话总结：分析</title>
      <link>https://arxiv.org/abs/2402.16986</link>
      <description><![CDATA[arXiv:2402.16986v1 公告类型：新
摘要：对话摘要在管理和理解跨不同领域的大规模对话方面变得越来越重要。这项任务在捕捉多轮长对话的要点、背景和细微差别以进行总结方面提出了独特的挑战。值得注意的是，摘要技术可能会根据具体要求而有所不同，例如在购物聊天机器人场景中，对话摘要有助于了解用户偏好，而在客户呼叫中心的情况下，摘要可能涉及以下问题属性：用户指定，并提供最终解决方案。这项工作强调了为各种应用程序中的有效沟通创建连贯且上下文丰富的摘要的重要性。我们探索了当前在不同领域进行长对话摘要的最先进方法，并且基于基准指标的评估表明，单一模型在不同领域的不同摘要任务中表现不佳。]]></description>
      <guid>https://arxiv.org/abs/2402.16986</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>语言模型听到什么？探索语言模型中的听觉表征</title>
      <link>https://arxiv.org/abs/2402.16998</link>
      <description><![CDATA[arXiv:2402.16998v1 公告类型：新
摘要：这项工作探讨了语言模型是否编码了物体声音的有意义的基础表示。我们学习一个线性探针，它可以在给定与该对象相关的音频片段的情况下检索该对象的正确文本表示，其中声音表示由预训练的音频模型给出。该探针通过对比损失进行训练，使对象的语言表示和声音表示彼此接近。训练后，测试探针泛化到训练期间未看到的对象的能力。在不同的语言模型和音频模型中，我们发现在许多情况下探测泛化高于偶然性，这表明尽管仅在原始文本上进行训练，但语言模型编码了某些对象的声音的基础知识。]]></description>
      <guid>https://arxiv.org/abs/2402.16998</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>语义重叠总结任务的法学硕士基准测试</title>
      <link>https://arxiv.org/abs/2402.17008</link>
      <description><![CDATA[arXiv:2402.17008v1 公告类型：新
摘要：语义重叠摘要（SOS）是一种受约束的多文档摘要任务，其中约束是捕获两个替代叙述之间的共同/重叠信息。虽然大型语言模型 (LLM) 的最新进展在众多摘要任务中取得了卓越的性能，但使用 LLM 的 SOS 任务的基准研究尚未进行。由于法学硕士的反应对提示设计中的细微变化很敏感，因此进行此类基准研究的一个主要挑战是在得出可靠的结论之前系统地探索各种提示。幸运的是，最近，TELeR 分类法被提出，可用于设计和探索法学硕士的各种提示。本文使用 TELeR 分类法和 15 个流行的法学硕士，全面评估了 SOS 任务的法学硕士，评估他们从多种替代叙述中总结重叠信息的能力。为了进行评估，我们在两个不同的替代叙述数据集上报告了成熟的指标，例如 ROUGE、BERTscore 和 SEM-F1$。我们通过分析各种法学硕士在捕获重叠信息的能力方面的优势和局限性来总结本文。用于进行这项研究的代码和数据集可在 https://anonymous.4open.science/r/llm_eval-E16D 上找到。]]></description>
      <guid>https://arxiv.org/abs/2402.17008</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:19 GMT</pubDate>
    </item>
    </channel>
</rss>