<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Wed, 24 Jan 2024 03:15:11 GMT</lastBuildDate>
    <item>
      <title>针对文本对抗性攻击的快速对抗性训练。 （arXiv：2401.12461v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12461</link>
      <description><![CDATA[人们提出了许多对抗性防御方法来增强
自然语言处理模型的对抗鲁棒性。然而，大多数
他们引入额外的预设语言知识并假设
攻击者使用的同义词候选者是可访问的，这是一个理想的选择
假设。我们深入研究嵌入空间中的对抗性训练
提出快速对抗训练（FAT）方法来改进模型
从单步角度看同义词不感知场景的鲁棒性
扰动生成和扰动初始化。基于
观察到由单步和
多步梯度上升类似，FAT 采用单步梯度上升
在嵌入空间中制作对抗性示例以加快训练
过程。基于对产生的扰动的观察
连续 epoch 中相同的训练样本相似，FAT 充分利用
初始化扰动时的历史信息。广泛的
实验证明 FAT 显着提高了 BERT 的鲁棒性
模型在同义词不知道的场景中，并且优于防御基线
受到字符级和单词级修改的各种攻击。
]]></description>
      <guid>http://arxiv.org/abs/2401.12461</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>蒸馏模型中的对比学习。 （arXiv：2401.12472v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12472</link>
      <description><![CDATA[像 BERT 这样的自然语言处理模型可以提供最先进的
下游 NLP 任务的词嵌入。然而，这些模型尚未执行
语义文本相似性很好，并且可能太大而无法部署为
轻量级边缘应用。我们寻求应用合适的对比学习
基于 SimCSE 论文的方法，改编自
基于知识蒸馏的模型 DistilBERT 可以解决这两个问题。
我们最终的轻量级模型 DistilFace 的平均得分为 72.1
Spearman 在 STS 任务上的相关性，比 BERT 基础提高了 34.2%。
]]></description>
      <guid>http://arxiv.org/abs/2401.12472</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是所有角色的叠加：通过自对准实现任意角色扮演。 （arXiv：2401.12474v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12474</link>
      <description><![CDATA[在增强角色扮演方面投入了大量精力
通过模拟来熟练掌握开源大语言模型（LLM）
专有的同行。尽管如此，我们认为法学硕士本质上具有
角色扮演能力，由于对角色和角色的广泛了解
潜在的对话根植于他们庞大的训练语料库中。因此，在这个
研究中，我们引入了 Ditto，一种角色扮演的自我调整方法。同上
利用性格知识，鼓励遵循指令的法学硕士
模拟角色扮演对话作为阅读理解的一种变体。这个方法
创建了包含 4,000 个角色的角色扮演训练集，超越了
就角色数量而言，当前可用数据集的规模扩大了十倍。
随后，我们使用这个自行生成的数据集对 LLM 进行微调，以增强
它的角色扮演能力。经过评估我们精心构建和
可重现的角色扮演基准和 MT-Bench 的角色扮演子集，同上，
各种参数尺度，始终保持一致的角色身份和
在多轮角色扮演中提供准确的特定角色知识
对话。值得注意的是，它的性能优于所有开源角色扮演基准，
展示了与高级专有聊天机器人相当的性能水平。
此外，我们提出了第一个全面的交叉监督调整
角色扮演领域的实验揭示了内在能力
的法学硕士将知识限制在角色扮演中。同时，角色扮演风格
在较小模型的指导下可以轻松获得。我们开源
相关资源位于 https://github.com/OFA-Sys/Ditto。
]]></description>
      <guid>http://arxiv.org/abs/2401.12474</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>100 个样本能走多远？通过微小的多并行数据解锁整体零样本多语言翻译。 （arXiv：2401.12413v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12413</link>
      <description><![CDATA[零样本翻译是一个悬而未决的问题，旨在在
多语言机器翻译训练期间未见的语言对
（现代货币理论）。一个常见但消耗资源的解决方案是开采尽可能多的资源
尽可能将翻译方向添加到平行语料库中。在这个
论文中，我们证明了以英语为中心的模型的零样本能力可以是
通过使用非常少量的多并行数据进行微调可以轻松增强。
例如，在 EC30 数据集上，我们显示高达 +21.7 ChrF 非英语
仅使用 100 个即可实现总体改进（870 个方向）
多并行样本，同时保留以英语为中心的能力
方向。我们进一步研究微调数据的尺寸效应及其
传输能力。令人惊讶的是，我们的实证分析表明
即使通过微调也可以实现类似的整体改进
小的、随机采样的方向集（10%）。此外，由此产生的非英语
性能非常接近上限（完整翻译）。由于
其高效率和实用性，我们鼓励社区1）考虑
使用微调方法作为零样本的强大基线
翻译和2）构建更全面和高质量的
多并行数据以满足现实世界的需求。
]]></description>
      <guid>http://arxiv.org/abs/2401.12413</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>视觉语言模型被忽视的尾巴。 （arXiv：2401.12425v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12425</link>
      <description><![CDATA[视觉语言模型 (VLM) 在零样本识别方面表现出色，但表现出
视觉概念之间的表现严重不平衡。例如，剪辑、
尽管 ImageNet 上的平均零样本准确率令人印象深刻（72.7%），但
十个概念（例如陀螺仪和夜蛇）的价格低于 10%，大概是因为
这些概念在 VLM 不平衡的预训练数据中代表性不足。然而，
评估这种不平衡具有挑战性，因为计算
VLM 大规模预训练数据中特定概念的出现频率。我们的
工作首次尝试通过分析来测量概念频率
预训练文本。我们使用现成的语言模型来帮助计算相关的
包含给定概念的同义词并解决语言问题的文本
歧义。我们确认像 LAION 这样的流行 VLM 数据集确实表现出了
长尾概念分布，与每个类别密切相关
准确性。此外，当代多模式系统，例如视觉聊天机器人和
文本到图像生成器，也与由
我们的方法。为了缓解 VLM 在零样本识别中的不平衡性能，
我们提出 REtrieval-Augmented Learning REAL。首先，不提示VLM
使用原始类名，REAL 使用最常见的同义词
VLM 的预训练文本。这已经超越了人类工程和
LLM 在九个基准数据集上生成提示，可能是因为 VLM 具有
看到更多与常用同义词相关的图像。二、真实
使用所有概念同义词来检索一个小的、类平衡的集合
预训练数据来训练鲁棒的分类器。 REAL 超越近期
检索增强解决方案 REACT，使用的存储空间减少 400 倍，存储空间减少 10,000 倍
训练时间！
]]></description>
      <guid>http://arxiv.org/abs/2401.12425</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>CIM-MLC：用于内存计算加速器的多级编译堆栈。 （arXiv：2401.12428v1 [cs.AR]）</title>
      <link>http://arxiv.org/abs/2401.12428</link>
      <description><![CDATA[近年来，各种内存计算（CIM）处理器已经被开发出来。
提出，显示出优于传统架构的性能。到
释放各种 CIM 架构的潜力，例如设备精度、
crossbar大小，以及crossbar数量，需要开发编译
充分了解 CIM 架构细节和实施的工具
多样性。但由于目前流行的架构缺乏支撑
开源编译堆栈，现有的CIM设计要么手动部署
网络或构建自己的编译器，这既耗时又
劳动密集型。尽管有些作品公开了特定的 CIM 设备编程
编译器接口，它们通常绑定到固定的 CIM 架构，
缺乏支持不同 CIM 架构的灵活性
计算粒度。另一方面，现有的编译作品通常
考虑有限操作类型的调度（例如 crossbar-bound
矩阵向量乘法）。与传统处理器不同，CIM 加速器
其特点是其架构、电路和器件多样化，无法
如果我们寻求充分探索
CIM带来的优势。因此，我们提出了CIM-MLC，一种通用的
适用于通用 CIM 架构的多级编译框架。我们首先
为 CIM 架构和计算建立通用硬件抽象
模式来表示各种 CIM 加速器。基于所提出的抽象，
CIM-MLC 可以将任务编译到各种 CIM 加速器上
不同的设备、架构和编程接口。更重要的是，
与现有的编译工作相比，CIM-MLC可以探索映射和
跨多个架构层的调度策略，形成
易于处理且有效的设计空间，以实现更好的调度和
指令生成结果。
]]></description>
      <guid>http://arxiv.org/abs/2401.12428</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>Reddit 帖子的纵向情感分类。 （arXiv：2401.12382v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12382</link>
      <description><![CDATA[我们报告 Reddit 帖子纵向情感分类的结果
由加拿大四所主要大学的学生撰写。我们与文本一起工作
职位，重点关注 2020-2023 年。通过微调
情绪阈值范围为[-0.075,0.075]，我们成功构建了
分类器擅长将帖子情绪分类为积极和
负面类别。值得注意的是，我们的情感分类结果是
四所大学数据集的一致性。
]]></description>
      <guid>http://arxiv.org/abs/2401.12382</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>通过线性探针校准增强情境学习。 （arXiv：2401.12406v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12406</link>
      <description><![CDATA[上下文学习（ICL）是自然语言处理的新范式
它利用类似生成式预训练 Transformer (GPT) 的模型。这
方法使用包含上下文演示的提示来生成
新查询输入的相应输出。然而，在实际案例中应用ICL
不随样本数量缩放，并且对不同的情况缺乏鲁棒性
提示模板和演示排列。在本文中，我们首先展示
使用 ICL 的类 GPT 模型会导致基于新模型的预测不可靠
基于香农熵的度量。然后，为了解决这个问题，我们提出了一个新的
称为线性探头校准 (LinC) 的技术，一种校准方法
模型的输出概率，产生可靠的预测和
改进的性能，同时只需要最少的额外样本（尽可能少
作为五个标记数据样本）。 LinC 显着增强 ICL 测试
GPT 模型在各种基准数据集上的平均性能
提高高达 21%，在某些情况下提高高达 50%，并且
显着提高 PEFT 方法的性能，特别是在低
资源制度。此外，LinC 实现了较低的预期校准误差，并且
对不同的标签比例、提示模板具有高度鲁棒性
演示排列。我们的代码位于
\url{https://github.com/mominabbass/LinC}。
]]></description>
      <guid>http://arxiv.org/abs/2401.12406</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>微调大型语言模型以实现多生成器、多域和多语言机器生成的文本检测。 （arXiv：2401.12326v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12326</link>
      <description><![CDATA[SemEval-2024 任务 8 引入了识别机器生成的挑战
来自各种语言的各种大语言模型 (LLM) 的文本和
域。该任务包含三个子任务：
单语和多语（子任务A），多类分类（子任务
B) 和混合文本检测（子任务 C）。本文重点关注子任务 A 和子任务 A。 B.
每个子任务由三个数据集支持，用于训练、开发和
测试。为了解决这个任务，有两种方法：1）使用传统机器
使用自然语言预处理 (NLP) 进行特征提取的学习 (ML)，
2) 微调法学硕士的文本分类。结果表明
变压器模型，特别是 LoRA-RoBERTa，在以下方面超越了传统的 ML 方法
有效性，多数表决在以下方面特别有效：
用于识别机器生成的文本的多语言上下文。
]]></description>
      <guid>http://arxiv.org/abs/2401.12326</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>基于子图提取的 HLS 反馈引导迭代调度。 （arXiv：2401.12343v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12343</link>
      <description><![CDATA[本文提出了 ISDC，一种新颖的反馈引导迭代系统
用于高级综合的差分约束（SDC）调度算法
（HLS）。 ISDC 利用基于子图提取的低级反馈
逻辑合成器等下游工具可迭代地完善 HLS 调度。
技术创新包括： (1) 增强的 SDC 配方，可有效
将低级反馈集成到线性规划 (LP) 问题中； (2) A
驱动反馈的扇出和基于窗口的子图提取机制
循环; (3) 无人参与的 ISDC 流程，兼容多种
下游工具和工艺设计套件（PDK）。评估表明ISDC
与工业级开源 HLS 相比，寄存器使用量减少了 28.5%
工具。
]]></description>
      <guid>http://arxiv.org/abs/2401.12343</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>为视障学生开发 NLP 驱动的计算机测试指南。 （arXiv：2401.12375v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12375</link>
      <description><![CDATA[近年来，自然语言处理（NLP）技术的进步
彻底改变了测试的可访问性和排他性领域，
特别是对于视障学生（VIS）。 CBT 早在几年前就已经表现出来
它在电子化考试方面的相关性，使得考试
过程更轻松，提供更快、更准确的结果，并提供
为候选人提供更大的灵活性和可及性。然而，它的相关性是
视障学生不会有这种感觉，因为他们无法阅读印刷品
文件。因此，在本文中，我们提出了一种 NLP 驱动的基于计算机的测试
视障学生指南。它采用了语音技术
预先训练的方法为视觉提供实时帮助和支持
有障碍的学生。该系统利用NLP技术将
基于文本的问题和机器可读格式的相关选项。
随后，语音技术预训练模型对转换后的数据进行处理
使 VIS 能够理解和分析内容的文本。此外，我们
通过准确性测试验证了这个预训练模型没有反常
使用示例音频数据集标签（A、B、C、D、E、F、G）与
从 20 个 VIS 获得的语音记录，系统预测
获得准确率、召回率和 F1 分数的值。这些指标用于
评估预训练模型的性能并表明它是
足够熟练，可以为评估的系统提供更好的性能。这
该系统采用的方法是面向对象的分析和设计
通过建模讨论和构建对象的方法论 (OOADM)
现实世界的实例。
]]></description>
      <guid>http://arxiv.org/abs/2401.12375</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>互动道德：减轻法学硕士的安全威胁。 （arXiv：2401.12273v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2401.12273</link>
      <description><![CDATA[本文全面探讨了以下问题所带来的伦理挑战：
对语言学习模型 (LLM) 的安全威胁。这些错综复杂的数字
存储库越来越融入我们的日常生活，使它们
可能损害其训练数据和网络的攻击的主要目标
其数据来源的机密性。这篇论文深入探讨了细致入微的
此类安全威胁对社会和个人的道德影响
隐私。我们审查五种主要威胁：即时注入、越狱、
个人身份信息 (PII) 暴露、露骨色情内容、
和基于仇恨的内容，超越单纯的识别来评估他们的
严重的道德后果以及它们为强有力的防御带来的紧迫性
策略。对法学硕士的日益依赖凸显了对法学硕士的迫切需要
确保这些系统在道德规范的范围内运作，特别是
因为它们的滥用可能会导致重大的社会和个人伤害。我们
建议概念化和开发专为法学硕士量身定制的评估工具，
这将有双重目的，指导开发人员和设计师
先发制人地强化后端系统并审查道德规范
测试阶段 LLM 聊天机器人响应的维度。通过比较LLM
与道德背景下人类期望的反应相比，我们的目标是辨别
人工智能行为与道德价值观的一致程度
更广泛的社会。最终，本文不仅强调了道德
法学硕士带来的麻烦，它也凸显了培养信任的途径
在这些系统中。
]]></description>
      <guid>http://arxiv.org/abs/2401.12273</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>GRATH：大型语言模型的逐步自我验证。 （arXiv：2401.12292v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12292</link>
      <description><![CDATA[真实性对于大型语言模型 (LLM) 至关重要，因为它们本身就是
越来越多地部署在实际应用中。然而，现有的法学硕士仍然
努力生成真实的答案和内容，正如他们所证明的那样
在 TruthfulQA 等基准测试中表现一般。为了解决这个问题，我们
提出 GRAdual self-truTHifying (GRATH)，一种新颖的后处理方法
提高法学硕士的真实性。 GRATH 利用域外问题提示来
生成相应的答案并通过直接自适应优化模型
偏好优化（DPO）。请注意，在此过程中，GRATH 学习到
以自我监督的方式诚实，不需要注释的答案。
特别是，GRATH 首先通过以下方式生成成对真实性训练数据：
提示 LLM 本身，每一对都包含一个问题及其正确的
以及错误的答案。然后使用 DPO 对该模型进行微调，以从
答案对之间的差异。随后，GRATH 迭代细化
数据的真实性并优化模型，从而逐步提高
模型的真实性。根据经验，我们使用不同的 7B-LLM 来评估 GRATH，
与基准数据集上具有相似甚至更大规模的法学硕士进行比较。我们的
结果表明，GRATH 有效提高了法学硕士的真实性，而无需
损害其他核心能力。值得注意的是，GRATH 实现了最先进的
在 TruthfulQA 上的表现，MC1 准确率为 54.71%，MC2 准确率为
69.10%，甚至超过了大型模型，例如
Llama2-Chat-70B 分别增长 23.62% 和 24.18%。
]]></description>
      <guid>http://arxiv.org/abs/2401.12292</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>廉价学习：使用最少的数据最大化社会数据科学语言模型的性能。 （arXiv：2401.12295v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12295</link>
      <description><![CDATA[机器学习领域最近在以下方面取得了重大进展
减少构建新模型时对标记训练数据的要求。
这些“更便宜”的学习技术对社会具有巨大的潜力
科学，大型标记训练数据集的开发通常是
使用机器学习进行分析的重大实际障碍
任务。在本文中，我们回顾了三种已开发的“廉价”技术
近年来：弱监督、迁移学习和即时工程。
对于后者，我们还回顾了零样本提示的特殊情况
大语言模型。对于每种技术，我们都提供了其工作原理的指南
并展示其在六种不同的现实社会科学中的应用
应用程序（两个不同的任务与三个不同的数据集组成配对）。
我们在所有技术上都表现出了良好的性能，特别是我们展示了
大语言模型的提示如何以非常低的成本实现高精度
成本。我们的结果附有一个代码存储库，以便于
其他人复制我们的工作并将其用于自己的研究。总体而言，我们的
文章旨在促进这些技术的进一步采用
社会科学。
]]></description>
      <guid>http://arxiv.org/abs/2401.12295</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>Orion-14B：开源多语言大语言模型。 （arXiv：2401.12246v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12246</link>
      <description><![CDATA[在这项研究中，我们介绍了 Orion-14B，这是一个多语言大型数据库的集合
具有 140 亿个参数的语言模型。我们利用数据调度
在 2.5 万亿的多样化语料库上训练基础模型的方法
标记，源自英文、中文、日文、韩文等文本
语言。此外，我们还微调了一系列量身定制的模型
会话应用程序和其他特定用例。我们的评价
结果表明 Orion-14B 在各个方面实现了最先进的性能
广泛的任务。我们制造 Orion-14B 模型系列及其
相关代码可公开访问 https://github.com/OrionStarAI/Orion，
旨在激发该领域未来的研究和实际应用。
]]></description>
      <guid>http://arxiv.org/abs/2401.12246</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:05 GMT</pubDate>
    </item>
    </channel>
</rss>