<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 26 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>SQL-CRAFT：通过交互式细化和增强推理实现文本到 SQL</title>
      <link>https://arxiv.org/abs/2402.14851</link>
      <description><![CDATA[arXiv:2402.14851v1 公告类型：新
摘要：现代法学硕士已经变得越来越强大，但它们仍然面临着文本到 SQL 等专业任务的挑战。我们提出了 SQL-CRAFT，这是一个通过交互式细化和增强推理来提高法学硕士 SQL 生成能力的框架。我们利用交互式校正循环（IC-Loop）让法学硕士自动与数据库交互，以及 Python 增强推理。我们在两个 Text-to-SQL 数据集 Spider 和 Bird 上进行了实验，与朴素提示方法相比，性能提升高达 5.7%。此外，我们的方法超越了蜘蛛排行榜上当前最先进的技术，证明了我们框架的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.14851</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>NMT 的异步分段双向编码</title>
      <link>https://arxiv.org/abs/2402.14849</link>
      <description><![CDATA[arXiv:2402.14849v1 公告类型：新
摘要：随着神经机器翻译（NMT）的快速发展，提高翻译效率和质量已成为研究的焦点。尽管 Transformer 等通用模型在各方面都有值得称赞的表现，但它们在处理长句子和充分利用双向上下文信息方面仍然存在不足。本文介绍了一种基于 Transformer 的改进模型，实现了异步分段双向解码策略，旨在提高翻译效率和准确性。与传统的从左到右或从右到左的单向翻译相比，我们的方法显示出更高的效率和更高的翻译质量，特别是在处理长句子时。 IWSLT2017 数据集上的实验结果证实了我们的方法在加速翻译和提高准确性方面的有效性，特别是在长句翻译方面超越了传统的单向策略。此外，本研究分析了句子长度对解码结果的影响，并探讨了模型在各种场景下的性能。该研究结果不仅为NMT领域提供了有效的编码策略，而且为未来的研究铺平了新的途径和方向。]]></description>
      <guid>https://arxiv.org/abs/2402.14849</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>CHATATC：大型语言模型驱动的会话代理，用于支持战略空中交通流量管理</title>
      <link>https://arxiv.org/abs/2402.14850</link>
      <description><![CDATA[arXiv:2402.14850v1 公告类型：新
摘要：生成人工智能（AI）和大语言模型（LLM）通过 ChatGPT 等公开工具迅速普及。人类用户与 ChatGPT 等计算机应用程序之间的自然交互以及强大的摘要和文本生成功能推动了法学硕士在个人和专业用途中的采用。鉴于此类生成式人工智能工具的广泛使用，在这项工作中，我们研究了如何在非安全关键的战略交通流管理环境中部署这些工具。具体来说，我们根据 2000 年至 2023 年期间的地面延误计划 (GDP) 发布的大型历史数据集来培训法学硕士 CHATATC，其中包括超过 80,000 个 GDP 实施、修订和取消。我们测试 CHATATC 的查询和响应能力，记录成功的地方（例如，提供正确的 GDP 率、持续时间和原因）和缺点（例如，最高级的问题）。我们还详细设计了图形用户界面，以便未来用户与 CHATATC 对话代理进行交互和协作。]]></description>
      <guid>https://arxiv.org/abs/2402.14850</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>坚守自己的角色！大型语言模型中表达的个人价值观的稳定性</title>
      <link>https://arxiv.org/abs/2402.14846</link>
      <description><![CDATA[arXiv:2402.14846v1 公告类型：新
摘要：通过基准测试或心理学问卷研究大型语言模型（LLM）的标准方法是从相似的最小上下文（例如多项选择问题）中提供许多不同的查询。然而，由于 LLM 高度依赖上下文的性质，这种最小上下文评估的结论可能无法提供有关模型在部署中的行为的信息（模型将暴露于许多新上下文）。我们认为，背景依赖性应该作为法学硕士比较的另一个维度与认知能力、知识或模型大小等其他维度一起研究。在本文中，我们提出了一个关于不同情境（不同主题的模拟对话）价值表达稳定性的案例研究，并使用标准心理学问卷（PVQ）和行为下游任务进行测量。我们考虑了来自 5 个家族的 19 名开源法学硕士。重用心理学的方法，我们研究群体（人际）层面的排序稳定性和个体（人际）层面的自驱稳定性。我们探索两种设置：有或没有指导法学硕士模拟特定的性格。我们观察到模型和模型家族稳定性的相似趋势 - Mixtral、Mistral 和 Qwen 家族比 LLaMa-2 和 Phi 更稳定 - 在这两种设置、两个不同的模拟群体中，甚至在下游行为任务中。当被指示模拟特定角色时，法学硕士表现出较低的排名稳定性，并且这种稳定性随着对话长度的增加而进一步减弱。这凸显了法学硕士未来研究方向的必要性，即能够连贯地模拟多样化的人物角色，以及如何以更彻底、更有效的方式研究情境依赖性。本文朝着这个方向迈出了基础性的一步，据我们所知，这是第一个关于法学硕士价值稳定性的研究。]]></description>
      <guid>https://arxiv.org/abs/2402.14846</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>相同的任务，更多的标记：输入长度对大型语言模型推理性能的影响</title>
      <link>https://arxiv.org/abs/2402.14848</link>
      <description><![CDATA[arXiv:2402.14848v1 公告类型：新
摘要：本文探讨了扩展输入长度对大型语言模型（LLM）功能的影响。尽管法学硕士近年来取得了进步，但它们在不同输入长度上的性能一致性尚不清楚。我们通过引入一种新颖的 QA 推理框架来研究这个方面，该框架专门用于评估输入长度的影响。我们使用同一样本的多个版本来隔离输入长度的影响，每个版本都使用不同长度、类型和位置的填充进行扩展。我们的研究结果表明，在比其技术最大值短得多的输入长度下，法学硕士的推理性能显着下降。我们表明，退化趋势出现在数据集的每个版本中，尽管强度不同。此外，我们的研究表明，传统的困惑度指标与法学硕士在长输入推理任务中的表现并不相关。我们分析我们的结果并确定失败模式，这些模式可以作为未来研究的有用指南，并有可能为解决法学硕士中观察到的局限性提供策略。]]></description>
      <guid>https://arxiv.org/abs/2402.14848</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>RJUA-MedDQA：医疗文档问答和临床推理的多模式基准</title>
      <link>https://arxiv.org/abs/2402.14840</link>
      <description><![CDATA[arXiv:2402.14840v1 公告类型：新
摘要：大型语言模型（LLM）和大型多模态模型（LMM）的最新进展在智能医疗诊断等各种医疗应用中显示出了潜力。尽管取得了令人印象深刻的结果，但我们发现现有的基准并不能反映真实医疗报告的复杂性和专门的深度推理能力。在这项工作中，我们引入了 RJUA-MedDQA，这是医学专业领域的综合基准，它提出了几个挑战：在各种具有挑战性的布局中全面解释图像内容，拥有识别异常指标的数字推理能力，并展示提供陈述的临床推理能力基于医疗背景的疾病诊断、状态和建议。我们精心设计了数据生成流程，并提出了高效结构恢复注释（ESRA）方法，旨在恢复医疗报告图像中的文本和表格内容。该方法极大地提高了标注效率，使每个标注者的生产力提高了一倍，并且准确率提高了 26.8%。我们进行了广泛的评估，包括对 5 个能够解决中国医学 QA 任务的 LMM 进行小样本评估。为了进一步研究当前 LMM 的局限性和潜力，我们使用 ESRA 方法生成的图像文本对一组强 LMM 进行了比较实验。我们报告了基线的性能并提供了一些观察结果：（1）现有 LMM 的整体性能仍然有限；然而，与 LLM 相比，LMM 对低质量和多样化结构的图像更稳健。 (3) 跨上下文和图像内容的推理提出了重大挑战。我们希望这个基准能够帮助社区在多模式医疗文档理解方面的这些具有挑战性的任务上取得进展，并促进其在医疗保健中的应用。]]></description>
      <guid>https://arxiv.org/abs/2402.14840</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>强化条件作用下的文本扩散</title>
      <link>https://arxiv.org/abs/2402.14843</link>
      <description><![CDATA[arXiv:2402.14843v1 公告类型：新
摘要：扩散模型在生成高质量图像、视频和音频方面表现出了卓越的能力。由于它们在迭代细化方面的适应性，它们为实现更好的非自回归序列生成提供了强大的潜力。然而，由于处理语言离散性方面的挑战，现有的文本扩散模型在性能上仍然存在不足。本文彻底分析了文本传播模型，并揭示了两个显着的局限性：训练过程中自我调节的退化以及训练和采样之间的错位。受我们研究结果的启发，我们提出了一种名为 TREC 的新型文本扩散模型，该模型可以通过强化条件调节来减轻退化，并通过时间感知方差缩放来减轻错位。我们广泛的实验证明了 TREC 相对于自回归、非自回归和扩散基线的竞争力。此外，定性分析显示其在精炼样品中充分利用扩散过程的先进能力。]]></description>
      <guid>https://arxiv.org/abs/2402.14843</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>通过集成小语言模型来净化大语言模型</title>
      <link>https://arxiv.org/abs/2402.14845</link>
      <description><![CDATA[arXiv:2402.14845v1 公告类型：新
摘要：大型语言模型（LLM）的新兴成功在很大程度上依赖于从外部（不可信）来源收集丰富的训练数据。尽管在数据清理和管理方面做出了大量努力，但据报道，构建良好的法学硕士仍遭受版权侵权、数据中毒和/或侵犯隐私的问题，这将阻碍法学硕士的实际部署。在这项研究中，我们提出了一种简单且易于实施的方法，用于净化法学硕士免受未经整理的数据造成的负面影响，即通过将法学硕士与良性小型语言模型（SLM）集成。除了理论保证之外，我们还进行了全面的实验来实证证实 LLM 与 SLM 集成的有效性，这可以有效保留 LLM 的性能，同时减轻版权侵权、数据中毒和隐私侵犯等问题。]]></description>
      <guid>https://arxiv.org/abs/2402.14845</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型提示技术的实证分类：从业者指南</title>
      <link>https://arxiv.org/abs/2402.14837</link>
      <description><![CDATA[arXiv:2402.14837v1 公告类型：新
摘要：由于大型语言模型（LLM）开发的快速进步，使用提示对这些模型进行编程最近引起了极大的关注。然而，可用的即时工程技术的绝对数量为希望利用这些工具的从业者创造了压倒性的前景。为了最有效地利用法学硕士，编制一份全面的提示技术清单并建立标准化的跨学科分类框架非常重要。在这项调查中，我们从学术和实践的角度研究了一些最著名的提示技巧，并将它们分为七个不同的类别。我们对每个类别进行概述，旨在阐明它们的独特贡献并展示它们在现实世界示例中的实际应用，以便为其他从业者提供一个结构化框架，用于理解和分类适合其特定领域的提示技术。我们相信，这种方法将有助于简化即时工程的复杂情况，并能够在各种应用中更有效地利用法学硕士。通过为从业者提供系统的提示分类方法，我们的目标是帮助经过对话预训练的法学硕士了解有效提示设计的复杂性，并在各自领域激发新的可能性。]]></description>
      <guid>https://arxiv.org/abs/2402.14837</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>RFBES 在 SemEval-2024 任务 8：研究句法和语义特征以区分人工智能生成的文本和人类编写的文本</title>
      <link>https://arxiv.org/abs/2402.14838</link>
      <description><![CDATA[arXiv:2402.14838v1 公告类型：新
摘要：如今，大型语言模型（LLM）的使用有所增加，LLM 已被用于生成不同语言和不同任务的文本。此外，由于谷歌和OpenAI等知名公司的参与，法学硕士现在更容易获得，人们可以轻松使用它们。然而，一个重要的问题是我们如何从人类编写的文本中检测人工智能生成的文本。在本文中，我们从语义和语法两个不同的方面研究了人工智能生成的文本检测问题。最后，我们提出了一个人工智能模型，可以使用 M4 数据集在多语言和单语言任务上高精度地区分人工智能生成的文本和人类编写的文本。根据我们的结果，使用语义方法对检测更有帮助。然而，句法方法还有很大的改进空间，这将是未来工作的一个很好的方法。]]></description>
      <guid>https://arxiv.org/abs/2402.14838</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>MIKE：细粒度多模态实体知识编辑的新基准</title>
      <link>https://arxiv.org/abs/2402.14835</link>
      <description><![CDATA[arXiv:2402.14835v1 公告类型：新
摘要：多模态知识编辑代表了增强多模态大语言模型（MLLM）能力的关键进步。尽管具有潜力，但当前的基准主要关注粗粒度知识，而细粒度（FG）多模态实体知识的复杂性在很大程度上尚未得到探索。这一差距提出了一个显着的挑战，因为 FG 实体识别对于 MLLM 在各种现实场景中的实际部署和有效性至关重要。为了弥补这一差距，我们引入了 MIKE，这是一个专门为 FG 多模态实体知识编辑设计的综合基准和数据集。 MIKE 包含一套专为评估不同观点而定制的任务，包括普通名称应答、实体级标题和复杂场景识别。此外，还引入了一种新的知识编辑形式——多步编辑来评估编辑效率。通过我们的广泛评估，我们证明当前最先进的方法在处理我们提出的基准方面面临着重大挑战，强调了 MLLM 中 FG 知识编辑的复杂性。我们的研究结果凸显了该领域对新方法的迫切需求，为社区内未来的研究和开发工作制定了明确的议程。]]></description>
      <guid>https://arxiv.org/abs/2402.14835</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>基于大语言模型的推荐的隐秘攻击</title>
      <link>https://arxiv.org/abs/2402.14836</link>
      <description><![CDATA[arXiv:2402.14836v1 公告类型：新
摘要：最近，强大的大语言模型（LLM）在推动推荐系统（RS）的进步方面发挥了重要作用。然而，尽管这些系统蓬勃发展，但它们对安全威胁的敏感性却在很大程度上被忽视了。在这项工作中，我们揭示了将法学硕士引入推荐模型会带来新的安全漏洞，因为它们强调项目的文本内容。我们证明，攻击者只需在测试阶段更改项目的文本内容即可显着提高项目的曝光率，而无需直接干扰模型的训练过程。此外，这种攻击非常隐蔽，因为它不会影响整体推荐性能，而且对文本的修改很微妙，使得用户和平台很难检测到。我们对四种主流的基于 LLM 的推荐模型进行了全面的实验，证明了我们方法的卓越功效和隐蔽性。我们的工作揭示了基于法学硕士的推荐系统中存在的重大安全漏洞，并为未来保护这些系统的研究铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2402.14836</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>CliqueParcel：一种联合优化效率和忠诚度的 LLM 提示批处理方法</title>
      <link>https://arxiv.org/abs/2402.14833</link>
      <description><![CDATA[arXiv:2402.14833v1 公告类型：新
摘要：大型语言模型（LLM）在最近的研究中已变得至关重要。然而，在推理过程中，法学硕士仍然需要大量资源。在本文中，我们提出了 CliqueParcel，一种旨在通过即时批处理提高 LLM 效率的方法。现有的优化推理效率的策略通常会损害输出质量，从而导致输出折扣问题。此问题可能会导致准确性降低或输出不太详细。 CliqueParcel 是我们应对这一挑战的答案。在确保准确性并最大限度地减少与原始输出的偏差（即忠实度）的同时，我们的方法显着提高了推理过程中的效率。
  为了奠定基础，我们首先重新定义效率测量，排除由于较短的长度而导致的运行时间的减少。然后，我们提供效率和忠诚度之间的全面权衡，以阐明“贴现产出”问题的本质。在 CliqueParcel 框架内，我们建议使用多种批处理子方法，并讨论它们可以应用的具体场景。在评估过程中，CliqueParcel 在八个广泛认可的数据集上进行了测试，这些数据集可分为三种类型：阅读理解、开源问答和推理。我们的实验探索了 CliqueParcel 的性能，包括效率、忠实度以及它们之间的权衡。这项工作为推理效率提供了新颖的见解，并展示了有前途的性能。]]></description>
      <guid>https://arxiv.org/abs/2402.14833</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>MSynFD：多跳语法感知假新闻检测</title>
      <link>https://arxiv.org/abs/2402.14834</link>
      <description><![CDATA[arXiv:2402.14834v1 公告类型：新
摘要：社交媒体平台的激增助长了假新闻的快速传播，对我们的现实社会构成了威胁。现有方法使用多模态数据或上下文信息，通过分析新闻内容和/或其社会背景来增强对假新闻的检测。然而，这些方法常常忽视重要的文本新闻内容（文章），并严重依赖顺序建模和全局注意力来提取语义信息。这些现有的方法无法处理新闻文章中复杂、微妙的扭曲，例如语法语义不匹配和先验偏差，当模式或社会背景缺失时，会导致性能下降和潜在的失败。为了弥补这些重大差距，我们提出了一种新颖的多跳语法感知假新闻检测（MSynFD）方法，该方法结合了补充语法信息来处理假新闻中的微妙变化。具体来说，我们引入了语法依赖图并设计了多跳子图聚合机制来捕获多跳语法。它扩展了单词感知的效果，从而实现有效的噪声过滤和相邻关系增强。随后，设计了一个顺序相对位置感知 Transformer 来捕获顺序信息，以及一个精心设计的关键字去偏差模块来减轻先验偏差。在两个公共基准数据集上的广泛实验结果验证了我们提出的 MSynFD 相对于最先进的检测模型的有效性和优越性能。]]></description>
      <guid>https://arxiv.org/abs/2402.14834</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>Orca-Math：释放 SLM 在小学数学中的潜力</title>
      <link>https://arxiv.org/abs/2402.14830</link>
      <description><![CDATA[arXiv:2402.14830v1 公告类型：新
摘要：长期以来，数学应用问题解决一直被认为是小语言模型（SLM）的一项复杂任务。最近的一项研究假设，在 GSM8K 基准上实现超过 80% 的准确度所需的最小模型大小为 340 亿个参数。为了使用较小的模型达到这种性能水平，研究人员经常训练 SLM 来生成 Python 代码或使用工具来帮助避免计算错误。此外，他们还采用集成，将多达 100 个模型运行的输出组合起来，以获得更准确的结果。结果选择是使用共识、多数投票或与 SLM 结合使用的单独验证者模型来完成的。集成极大地提高了准确性，但由于多次调用模型，成本显着增加（例如，Phi-GSM 使用 top-48 将性能从 68.2 提高到 81.5）。
  在这项工作中，我们提出了 Orca-Math，一种基于 Mistral-7B 的 70 亿参数 SLM，它在 GSM8k 上实现了 86.81%，无需多个模型调用或使用验证器、代码执行或任何其他外部工具。我们的方法具有以下关键要素：(1) 使用多代理设置创建的 20 万个数学问题的高质量综合数据集，其中代理协作创建数据，(2) 迭代学习技术，使 SLM 能够练习解决问题，接收有关其解决方案的反馈，并从结合了 SLM 解决方案和反馈的偏好对中学习。当单独使用监督微调进行训练时，Orca-Math 在 GSM8k pass@1 指标上达到了 81.50%。通过迭代偏好学习，Orca-Math 达到了 86.81% pass@1。 Orca-Math 的性能超越了较大模型的性能，例如 LLAMA-2-70B、WizardMath-70B、Gemini-Pro、ChatGPT-3.5。在使用更小的数据（数十万与数百万问题）时，它的性能也显着优于其他较小的模型。]]></description>
      <guid>https://arxiv.org/abs/2402.14830</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:19 GMT</pubDate>
    </item>
    </channel>
</rss>