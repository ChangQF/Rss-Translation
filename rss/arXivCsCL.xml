<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Tue, 08 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>统一的虚拟混合物框架：单模型系统中的推理和幻觉缓解</title>
      <link>https://arxiv.org/abs/2504.03739</link>
      <description><![CDATA[ARXIV：2504.03739V1公告类型：新 
摘要：GPT和BERT等生成模型在文本生成和摘要等任务中的性能大大提高。 However, hallucinations &quot;where models generate non-factual or misleading content&quot; are especially problematic in smaller-scale architectures, limiting their real-world applicability.In this paper, we propose a unified Virtual Mixture-of-Experts (MoE) fusion strategy that enhances inference performance and mitigates hallucinations in a single Qwen 1.5 0.5B model without increasing the parameter count.我们的方法利用多个特定领域的专家提示（可调节专家的数量）来指导模型。我们根据平均值和标准偏差应用统计异常值截断策略，以过滤出异常高的概率预测，并将噪声注入嵌入空间中以促进输出多样性。为了清楚地评估每个模块的贡献，我们采用了固定的投票机制，而不是动态的门控网络，从而避免了其他混杂因素。我们从统计和集合学习的角度提供了详细的理论推导，以证明我们的方法如何减少输出方差并抑制幻觉。关于对话生成任务的广泛消融实验表明，我们的方法显着提高了小型模型中的推理准确性和鲁棒性。此外，我们讨论了评估虚拟专家正交性的方法，并概述了使用门控网络分配动态专家体重分配的未来工作的潜力。]]></description>
      <guid>https://arxiv.org/abs/2504.03739</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>“新雪片”包含雪吗？大型语言模型过度依靠名称，以识别中国药物的成分</title>
      <link>https://arxiv.org/abs/2504.03786</link>
      <description><![CDATA[ARXIV：2504.03786V1公告类型：新 
摘要：中医（TCM）在医疗保健中的采用量增加，专门的大语言模型（LLMS）正在出现以支持临床应用。这些模型的基本要求是准确鉴定TCM药物成分。在本文中，我们评估了识别中国药物成分时的一般和TCM专业LLM的表现。我们的系统分析揭示了一致的失败模式：模型通常从字面上解释药物名称，过度使用常见的草药，无论相关性如何，并且在面对不熟悉的配方时表现出不稳定的行为。 LLM也无法理解验证任务。这些发现表明，当前LLM的主要依赖于药物名称，而不是具有系统的药理知识。为了解决这些限制，我们提出了一种重点是成分名称的检索增强生成（RAG）方法。 220个TCM配方的实验表明，在成分验证任务中，我们的方法将精度从约50％提高到82％。我们的工作强调了当前TCM特异性LLM中的临界弱点，并提供了提高其临床可靠性的实用解决方案。]]></description>
      <guid>https://arxiv.org/abs/2504.03786</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>示例，不要搜索：重新思考语言模型的测试时间对齐</title>
      <link>https://arxiv.org/abs/2504.03790</link>
      <description><![CDATA[ARXIV：2504.03790V1公告类型：新 
摘要：增加测试时间计算已成为改善语言模型性能的有希望的方向，尤其是在模型固定的情况下，由于计算限制或私人模型权重是不切实际或不可能的。但是，由于对固有不完美的奖励代理的过度优化，现有的使用奖励模型（RM）的现有测试时间搜索方法通常会降低质量作为计算量表。我们介绍了一种新的测试时间对准方法Qalign。随着测试时间计算的扩展，Qalign会收敛到每个个体提示的最佳排列分布的采样。通过在马尔可夫链蒙特卡洛（Monte Carlo）中采用最新进展来生成文本，我们的方法可以实现较好的输出，而无需修改基础模型甚至需要logit访问。我们使用特定于任务的RM证明了Qalign对数学推理基准（GSM8K和GSM-Symbolic）的有效性，显示了对现有测试时间计算方法（如最佳N和多数投票）的一致改进。此外，当在Tulu 3偏好数据集中使用更现实的RMS应用，Qalign优于直接偏好优化（DPO），最佳N，多数投票和多数投票，以多数投票在各种数据集上投票（GSM8K，MATH500，IFEVAL，IFEVAL，IFEVAL，MMLU-RU-REDUX和TORTERFULS和TORTERFULLQA）。我们的方法是在测试时间对齐语言模型的实用解决方案，而我们的方法不得降解，扩大了可以从现成的语言模型中获得的能力的限制，而无需进行进一步的培训。]]></description>
      <guid>https://arxiv.org/abs/2504.03790</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于熵的块修剪，用于有效的大语言模型</title>
      <link>https://arxiv.org/abs/2504.03794</link>
      <description><![CDATA[ARXIV：2504.03794V1公告类型：新 
摘要：随着大型语言模型继续扩展，它们不断增长的计算和存储要求对现实部署构成重大挑战。在这项工作中，我们研究了基于变压器的模型中的冗余，并提出了一种基于熵的修剪策略，以提高效率，同时保持性能。经验分析表明，隐藏表示形式的熵在早期块中减少，但在大多数随后的区块中逐渐增加。这种趋势表明，熵是计算块中信息丰富度的更有效度量。与主要捕获几何关系的余弦相似性不同，熵直接量化不确定性和信息内容，使其成为修剪的更可靠的标准。广泛的实验表明，我们的基于熵的修剪方法超过了基于余弦的相似性方法，可以降低模型大小，同时保持准确性，从而为有效的模型部署提供了有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2504.03794</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>哪些大型语言模型不谈论：对节制和审查实践的实证研究</title>
      <link>https://arxiv.org/abs/2504.03803</link>
      <description><![CDATA[ARXIV：2504.03803V1公告类型：新 
摘要：大型语言模型（LLMS）越来越多地作为信息门户部署，但其内容审核的做法仍然没有被逐渐解散。这项工作调查了LLM拒绝回答或忽略政治主题的信息的程度。为此，我们区分了硬审查（即产生的拒绝，错误消息或罐装拒绝响应）和软审查（即选择性的遗漏或关键元素的选择性遗漏或淡淡的关键元素），当我们在LLMS的响应中识别出广泛的政治图形信息时，我们会在LLMS的响应中识别。我们的分析涵盖了来自西方国家，中国和俄罗斯的14种最先进的模型，这些模式促使所有六种官方联合国（联合国）语言促使。我们的分析表明，尽管全面观察了审查制度，但它主要是针对LLM提供商的国内受众量身定制的，通常表现为艰苦的审查制度或软审查制度（尽管很少同时同时同时）。这些发现强调了公开可用的LLM中意识形态和地理多样性的需求，以及LLM审核策略的更高透明度以促进知情的用户选择。所有数据均可自由使用。]]></description>
      <guid>https://arxiv.org/abs/2504.03803</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM评估人员是否喜欢自己的原因？</title>
      <link>https://arxiv.org/abs/2504.03846</link>
      <description><![CDATA[ARXIV：2504.03846V1公告类型：新 
摘要：大型语言模型（LLMS）越来越多地用作基准测试，奖励建模和自我翻新等应用中的自动评估者。先前的工作突出了一个潜在的自我质量偏见，其中LLM倾向于自己产生的响应，这种趋势通常会随着模型的大小和能力而加剧。这提出了一个关键的问题：自我挑战是有害的，还是只是反映了功能更强大的模型的客观上优质输出？由于先前的研究中主观任务的使用，因此解开这些问题一直在挑战。为了解决这个问题，我们使用可验证的基准（数学推理，事实知识，代码生成）来研究自我质量，从而允许客观的基础评估。这使我们能够区分有害的自我挑战（偏爱客观上的更糟的反应）与合法的自我挑战（有利于真正优越的自我挑战）。我们在各种模型家族的受控评估条件下进行大规模实验（例如Llama，Qwen，Gemma，Mistral，Phi，Phi，GPT，DeepSeek）。我们的发现揭示了三个关键见解：（1）更好的生成器是更好的法官 -  LLM评估者的准确性与他们的任务绩效密切相关，并且在有能力的模型中的许多自我挑战都是合法的。 （2）有害的自我偏爱仍然存在，尤其是当评估器模型在特定任务实例上的发电机表现不佳时。当这种不正确的世代不太频繁时，更强大的模型在错误时表现出更明显的有害偏差。 （3）推理时间缩放策略，例如在评估前产生长长的经过思考，有效地减少了有害的自我挑战。这些结果为基于LLM的评估和改善其可靠性的实用见解提供了更细微的理解。]]></description>
      <guid>https://arxiv.org/abs/2504.03846</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>克莱姆：评估社交媒体上的多模式气候论述和气候一致性商（CAQ）</title>
      <link>https://arxiv.org/abs/2504.03906</link>
      <description><![CDATA[ARXIV：2504.03906V1公告类型：新 
摘要：大语言模型（LLM）的兴起提出了有关其了解与气候相关环境的能力的问题。尽管气候变化主导着社交媒体，但分析其多模式表达式的研究已被研究研究，并且当前的工具未能确定LLMS是否会放大可靠的解决方案或传播未经证实的主张。为了解决这个问题，我们介绍了Clime（气候变化多模式评估），这是一种首个多模式数据集，包括2579个Twitter和Reddit帖子。基准分配了各种各样的幽默模因和怀疑帖子，捕获了这些格式如何将复杂问题提炼成塑造公众舆论和政策讨论的病毒叙事。为了系统地评估LLM的性能，我们介绍了气候比对商（CAQ），这是一个包含五个不同维度的新型度量：表达，证据，共振，过渡和特异性。此外，我们提出了三种分析镜头：可行性，批判性和正义，以指导使用CAQ对LLM生成的气候话语进行评估。我们基于CAQ指标的发现表明，尽管大多数评估的LLM在批判性和正义上的表现相对较好，但它们在可行性轴上的表现始终表现不佳。在评估的模型中，Claude 3.7十四行诗的总体表现最高。我们公开发布我们的CLIME数据集和代码，以促进该领域的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2504.03906</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的改编</title>
      <link>https://arxiv.org/abs/2504.03931</link>
      <description><![CDATA[ARXIV：2504.03931V1公告类型：新 
摘要：有关LLMS适应的本教程旨在解决对模型不断增长的需求，这些模型通过提供动态，特定于域和任务适应LLM适应技术的概述，超越了通用LLM的静态功能。尽管一般LLM在各种任务中都表现出了强烈的概括，但他们经常难以在专业领域（例如财务，医疗保健和代码生成不足的语言）中表现出色。此外，他们的静态性质限制了它们随着不断变化的世界而发展的能力，而且它们的规模通常非常大，使其不切实际且昂贵。结果，自LLM诞生以来，LLM的适应引起了人们的关注，并且对于行业而言，这都是核心的关注，这对行业的重点是为目标用户服务，而学术界可以从小而有力的LLM中受益匪浅。为了解决这一差距，本教程旨在提供LLM适应技术的概述。从数据的角度和模型的角度来看，我们从LLM改编的介绍开始。然后，我们强调评估指标和基准与其他技术的不同。建立问题后，我们探索了各种适应技术。我们将适应技术分为两个主要家庭。第一个是参数知识适应，它重点是更新LLM中的参数知识。此外，我们将讨论实时适应技术，包括模型编辑，该技术允许LLMS在生产环境中动态更新。第二种适应性是半参数知识适应，其目标是通过诸如检索功能增强的生成（RAG）和基于代理的系统等技术更新LLM参数，以更好地利用外部知识或工具。]]></description>
      <guid>https://arxiv.org/abs/2504.03931</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>yalenlp @ peranssumm 2025：通过代理混合物进行多镜头集成，以增强医疗保健QA摘要</title>
      <link>https://arxiv.org/abs/2504.03932</link>
      <description><![CDATA[ARXIV：2504.03932V1公告类型：新 
摘要：医疗保健社区提问论坛的自动汇总是由于对每个问题的多个用户回答提出的各种观点，因此具有挑战性。因此，提出了Peranssumm共享的任务，以通过从不同答案中确定观点，然后对问题产生全面的答案来应对这一挑战。在这项研究中，我们使用两个互补范式解决了佩兰斯姆共同的任务：（i）通过Qlora Qlora微调Llama-3.3-70B-Instruct进行基于培训的方法，以及（ii）与Frontier llms（Llama-3.3-3.3-70b-instructs and GPT-4-4O）一起使用，包括零和少数提示的代理方法，以及一个混合了一个混合（MOA），通过组合多层反馈聚合的输出，多样化的LLMS集。对于透视跨度识别/分类，GPT-4O零射击的总分为0.57，显着超过了Llama基线的0.40得分。通过2层MOA配置，我们能够将美洲驼的性能提高28％，达到0.51。对于基于透视的摘要，GPT-4O零射击的总分为0.42，而最佳Llama零拍摄的总分为0.28，而我们的2层MOA方法将Llama的性能提高了32％至0.37。此外，在几次射击设置中，我们的结果表明，基于句子转换器嵌入的示例选择比在Llama模型上手动选择的示例提供了更多的增益，尽管少数发动的提示并不总是对GPT-4O有用。 Yalenlp团队的方法在共享任务中排名第二。]]></description>
      <guid>https://arxiv.org/abs/2504.03932</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型是隐式连续的</title>
      <link>https://arxiv.org/abs/2504.03933</link>
      <description><![CDATA[ARXIV：2504.03933V1公告类型：新 
摘要：语言通常以离散序列进行建模。但是，语言建模最成功的方法，即神经网络，是连续且平稳的函数近似值。在这项工作中，我们表明基于变压器的语言模型隐含地学习将句子表示为在连续输入空间上定义的连续时间函数。这种现象发生在大多数最先进的大语言模型（LLMS）中，包括Llama2，Llama3，Phi3，Gemma，Gemma2和Mistral，并建议以与人类根本上不同的方式进行LLMS关于语言的理由。我们的工作正式扩展了变压器，以捕获输入和输出空间中时间和空间连续性的细微差别。我们的结果挑战了LLM如何理解语言的传统解释，并具有几种语言和工程意义。]]></description>
      <guid>https://arxiv.org/abs/2504.03933</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>临床现代伯特：生物医学文本的高效而长的上下文编码器</title>
      <link>https://arxiv.org/abs/2504.03964</link>
      <description><![CDATA[ARXIV：2504.03964V1公告类型：新 
摘要：我们介绍了临床Modernbert，这是一种基于变压器的编码器，该编码器在大规模的生物医学文献，临床注释和医学本体论上进行了预测，其中包含了PubMed摘要，模拟IV临床数据以及医疗代码及其文本描述。建立在现代的基础上，当前的艺术自然语言文本编码器具有建筑升级，例如旋转位置嵌入（绳索），闪光注意力和扩展上下文长度，高达8,192个图形，我们的模型适应了这些创新，专门针对生物医学和临床领域。临床现代伯特（Clinical Modernbert）擅长生产针对长篇小说任务量身定制的语义丰富的代表。我们通过分析其预处理的权重以及通过对临床NLP基准的全面套件进行经验评估来验证这一点。]]></description>
      <guid>https://arxiv.org/abs/2504.03964</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>材料科学中过程结构属性关系的结构化提取</title>
      <link>https://arxiv.org/abs/2504.03979</link>
      <description><![CDATA[ARXIV：2504.03979V1公告类型：新 
摘要：随着大型语言模型（LLM）的出现，尽管仍然存在重大挑战，但材料发现中数以百万计的学术论文中的庞大非结构化文本越来越易于​​使用。尽管LLMS提供了有希望的很少和零照片的学习能力，尤其是在稀缺专家注释的材料领域中尤其有价值，但通用LLM通常无法在没有进一步适应的情况下解决特定于特定材料的问题。为了弥合这一差距，对人体标记数据的微调LLM对于有效的结构化知识提取至关重要。在这项研究中，我们介绍了一种新颖的注释模式，旨在从科学文献中提取一般的过程结构 - 实验关系。我们使用128个摘要的数据集证明了这种方法的实用性，并从两个不同的领域中绘制了注释：高温材料（域I）和模拟材料微结构（域II）中的不确定性定量。最初，我们开发了一个基于域特异性BERT变体Matbert的条件随机场（CRF）模型，并在相同条件下评估了其在域中的性能。随后，我们将该模型与微调的LLM（GPT-4O）（GPT-4O）进行了比较。我们的结果表明，微调LLM可以显着改善域I上BERT-CRF基线的实体提取性能。但是，当纳入了域II的其他示例时，BERT-CRF模型的性能与GPT-4O模型的性能相当。这些发现强调了我们模式在结构化知识提取方面的潜力，并突出了两种建模方法的互补优势。]]></description>
      <guid>https://arxiv.org/abs/2504.03979</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>算法迅速生成与大型语言模型的多样化的人类般的团队和沟通</title>
      <link>https://arxiv.org/abs/2504.03991</link>
      <description><![CDATA[ARXIV：2504.03991V1公告类型：新 
摘要：了解人类如何在团队中进行协作和交流对于改善人类代理团队和AI辅助决策至关重要。但是，仅依靠大规模用户研究的数据是不切实际的，这是由于后勤，道德和实际的约束，因此需要具有多种人类行为的合成模型。最近，已证明由大语言模型（LLM）提供动力的代理商在社交环境中模仿人类的行为。但是，获得大量不同的行为需要以设计提示的形式进行手动努力。另一方面，质量多样性（QD）优化已被证明能够产生多种增强学习（RL）代理行为。在这项工作中，我们将QD优化与LLM驱动的代理相结合，以迭代地搜索在长途，多步协作环境中产生多样化团队行为的提示。我们首先通过人类受试者实验（n = 54名参与者）表明，人类在该领域表现出多样化的协调和交流行为。然后，我们证明我们的方法可以有效地从人类团队数据中复制趋势，并捕获没有收集大量数据的情况下不容易观察到的行为。我们的发现突出了QD和LLM驱动代理的组合，作为研究多代理协作中的团队和沟通策略的有效工具。]]></description>
      <guid>https://arxiv.org/abs/2504.03991</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新思考预训练</title>
      <link>https://arxiv.org/abs/2504.04022</link>
      <description><![CDATA[ARXIV：2504.04022V1公告类型：新 
摘要：语言模型反思自己推理的能力为解决复杂问题提供了关键优势。尽管最近的研究集中在强化学习过程中这种能力如何发展，但我们表明，在模型的预训练期间，它实际上开始更早地出现。为了研究这一点，我们将故意的错误引入了思想链中，并测试该模型是否仍然可以通过识别和纠正这些错误来得出正确的答案。通过跟踪跨预训练阶段的性能，我们观察到这种自我校正能力出现早期，并且随着时间的流逝而稳步改善。例如，在4万亿代币上预先训练的OLMO2-7B模型在我们的六个自我反射任务上显示自校正。]]></description>
      <guid>https://arxiv.org/abs/2504.04022</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Myner：通过双向LSTM和FastText嵌入的联合培训和POS标签</title>
      <link>https://arxiv.org/abs/2504.04038</link>
      <description><![CDATA[ARXIV：2504.04038V1公告类型：新 
摘要：命名实体识别（NER）涉及在文本数据中识别和分类命名实体。尽管具有重要意义，但NER研究经常忽略了缅甸（缅甸）等低资源语言，这主要是由于缺乏公开可用的注释数据集。为了解决这个问题，我们介绍了Myner，这是一种新颖的单词级NER语料库，具有7标签注释方案，并具有言论部分（POS）标记，以提供其他句法信息。除了语料库之外，我们对NER模型进行了全面评估，包括条件随机场（CRF），双向LSTM（Bilstm）-CRF及其与FastText嵌入在不同设置中的组合。我们的实验揭示了上下文化的单词嵌入的有效性以及与POS标记的联合培训的影响，显示了整个模型的性能改善。带有FastText嵌入的传统CRF联合任务模型作为功能的最佳结果，具有0.9818的精度和0.9811加权F1得分，并获得0.7429的宏F1得分。具有微调FastText嵌入的Bilstm-CRF获得0.9791精度和0.9776加权F1得分的最佳结果，并获得0.7395宏F1得分。]]></description>
      <guid>https://arxiv.org/abs/2504.04038</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>