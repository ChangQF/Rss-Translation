<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Wed, 02 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>LLMS中的医学推理：深入介绍R1的深入分析</title>
      <link>https://arxiv.org/abs/2504.00016</link>
      <description><![CDATA[ARXIV：2504.00016V1公告类型：新 
摘要：将诸如DeepSeek R1之类的大型语言模型（LLM）集成到医疗保健中，需要对其与临床专业知识的推理一致性进行严格的评估。这项研究使用100例MEDQA临床病例评估了DeepSeek R1针对专家模式的医学推理。该模型达到了93％的诊断准确性，通过鉴别诊断，基于指南的治疗选择以及患者特异性因素的整合来证明系统的临床判断。但是，对七个不正确案件的错误分析显示出持续的局限性：锚定偏见，挑战矛盾的数据，对替代方案的探索不足，过度思考，知识差距，知识差距以及对中等护理的确定性治疗的优先级。至关重要的是，推理长度与准确性相关 - 较短的响应（&lt;5,000个字符）更可靠，这表明扩展的解释可能表明错误的不确定性或合理化。虽然DeepSeek R1具有基础临床推理能力，但反复出现的缺陷突出了精炼的关键领域，包括缓解偏见，知识更新和结构化推理框架。这些发现强调了LLMS通过人工推理增强医疗决策的潜力，但强调了对特定领域的验证，可解释性保障措施和信心指标（例如响应长度阈值）的需求，以确保对现实世界应用的可靠性。]]></description>
      <guid>https://arxiv.org/abs/2504.00016</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模糊的编码器：通过混淆接地为有效的代码LM预训练供电</title>
      <link>https://arxiv.org/abs/2504.00019</link>
      <description><![CDATA[ARXIV：2504.00019V1公告类型：新 
摘要：语言模型（LMS）已成为代码编写工具箱的主要内容。然而，近年来，他们的预培训食谱仍然停滞不前，禁止偶尔的数据采购和过滤策略发生变化。特别是，探索Code-LMS的预训练目标修改的研究，旨在提高数据效率并在语法和语义之间更好地解开，尤其是与自然语言LMS中的相应努力相比。在这项工作中，我们研究了对混淆的代码的基础，以此作为帮助代码-LM超越表面形式语法并提高其预训练样品效率的一种手段。为此，我们编译了大约5500万源的数据集，并用七种语言混淆代码对。随后，我们在272b token的语料库上预先训练了模型的模型，范围从255m到2.8b参数不等，其中包括Imbsubax，并证明我们基于混淆的预训练食谱可导致代码LMS的能力与vanilla Autorkemility tecressive-autoRealtime tecressive-de-de-de-de-de-de-bycrcative（以及现有的de-bobfus and de-obfus）相比，代码LMS的能力一致。 Migsuracoder展示了在多种语法和语义代码理解的多个测试中的巨大收益，以及改进的多语言代码完成，多语言代码提交摘要以及多功能库代码生成的功能。]]></description>
      <guid>https://arxiv.org/abs/2504.00019</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>保险丝：用于评估土著语言MT的山脊和随机森林指标</title>
      <link>https://arxiv.org/abs/2504.00021</link>
      <description><![CDATA[ARXIV：2504.00021V1公告类型：新 
摘要：本文介绍了Raava团队对Americasnlp 2025的获胜提交，共享了机器翻译自动评估指标（MT）中的“共享任务3”到美国的土著语言，我们的系统基于普通的Pearson与人类注释的平均相关性。我们介绍了特征工会得分手（保险丝）进行评估，Fuse集成了脊回归和梯度提升以建模翻译质量。除了保险丝外，我们还探索了利用语言相似性特征和学习范式不同组合的五种替代方法。 Fuse得分突出了将词汇，语音，语义和模糊代币与基于学习的建模相似的有效性，以改善形态丰富和低资源语言的MT评估。 MT进入土著语言，构成了多个多相合成，复杂的形态和非标准化拼字法引起的独特挑战。常规的自动指标，例如BLEU，TER和CHRF通常无法捕获更深层的语义充足性和流利性。我们提出的框架（以前称为保险丝）结合了多语言句子嵌入和语音编码，以更好地与人类评估保持一致。我们培训受监督的模型，以人为宣传的开发集并评估持有的测试数据。结果表明，保险丝始终达到较高的皮尔逊和斯皮尔曼与人类判断的相关性，为在低资源环境中提供了强大而语言知情的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2504.00021</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型中的概括科学研究摘要</title>
      <link>https://arxiv.org/abs/2504.00025</link>
      <description><![CDATA[ARXIV：2504.00025V1公告类型：新 
摘要：由大语言模型（LLM）驱动的人工智能聊天机器人有可能提高公共科学素养和支持科学研究，因为它们可以快速以可访问的术语来汇总复杂的科学信息。但是，当总结科学文本时，LLM可能会忽略限制研究结论范围的细节，从而导致结果的概括性比原始研究所保证的。我们测试了10个突出的LLM，包括Chatgpt-4O，Chatgpt-4.5，DeepSeek，Llama 3.3 70B和Claude 3.7十四行诗，将4900 LLM生成的摘要与其原始科学文本进行了比较。即使明确提示了准确性，大多数LLM都比原始文本中的科学结果更广泛地概括，DeepSeek，Chatgpt-4O和Llama 3.3 70B在26％至73％的案例中过度概括。在直接比较LLM生成和人为作者的科学摘要中，LLM摘要包含广泛的概括的可能性几乎是五倍（OR = 4.85，95％CI [3.06，7.70]）。值得注意的是，较新的模型的概括精度往往比早期的模型更差。我们的结果表明，在许多广泛使用的LLM中存在强烈的偏见，以使科学结论过于概括，从而引起了大规模误解研究结果的重大风险。我们重点介绍了潜在的缓解策略，包括降低LLM温度设置和基准测试LLMS以达到概括精度。]]></description>
      <guid>https://arxiv.org/abs/2504.00025</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Reddit的阿片类药物命名为实体识别（ONER-2025）</title>
      <link>https://arxiv.org/abs/2504.00027</link>
      <description><![CDATA[ARXIV：2504.00027V1公告类型：新 
摘要：阿片类药物过量流行仍然是一个严重的公共卫生危机，尤其是在美国，导致了重大死亡率和社会成本。像Reddit这样的社交媒体平台提供了大量的非结构化数据，这些数据为与阿片类药物使用相关的公众看法，讨论和经验提供了见解。这项研究利用自然语言处理（NLP），特别是名为“实体识别”（ONER-2025）的阿片类药物，从这些平台中提取可操作的信息。我们的研究做出了四个关键的贡献。首先，我们创建了一个来自Reddit的独特，手动注释的数据集，用户通过不同的管理路线共享自我报告的阿片类药物使用体验。该数据集包含331,285个令牌，其中包括八个主要的阿片类药物实体类别。其次，我们在讨论标记ONER-2025数据集的挑战时详细介绍了注释过程和指南。第三，我们在阿片类药物讨论中分析了关键的语言挑战，包括语，歧义，分散的句子和情绪激动的语言。第四，我们提出了一个实时监控系统，以处理社交媒体，医疗保健记录和紧急服务的流流数据，以识别过量的事件。在11个实验中，使用5倍的交叉验证，我们的系统将机器学习，深度学习和基于变压器的语言模型与高级上下文嵌入以增强理解。我们的基于变压器的模型（BERT-BASE-NER和ROBERTA-BASE）达到了97％的精度和F1得分，超过10.23％（RF = 0.88）。]]></description>
      <guid>https://arxiv.org/abs/2504.00027</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>令牌驱动的伽马能：用于凝固的投机解码的自适应校准</title>
      <link>https://arxiv.org/abs/2504.00030</link>
      <description><![CDATA[ARXIV：2504.00030V1公告类型：新 
摘要：通过使用较小的草稿模型提出令牌，投机解码会加速大语言模型（LLM）推断，然后通过较大的目标模型对其进行验证。但是，选择最佳推测长度对于最大程度地提高加速度至关重要，同时最大程度地减少浪费计算至关重要。我们介绍\ textit {gammatune}和\ textit {gammatune+}，无训练的自适应算法，这些算法使用基于启发式的切换机制，根据令牌接受率动态调整基于令牌接受率的推测长度。我们在多个任务和模型对上进行评估，我们的方法优于其他基于启发式的方法和固定长度的投机解码，并以\ textit {gammatune}的平均加速为15 \％（$ \ pm $ 5 \％），并与\ textiN cranivie cranivie cranivie craniges \ textIn+textune cranigiender cormand+textune+textune+textune+textune+textune。这使得\ textit {gammatune}成为现实部署的强大而有效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2504.00030</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于管理自然语言处理歧义的量子方法</title>
      <link>https://arxiv.org/abs/2504.00040</link>
      <description><![CDATA[ARXIV：2504.00040V1公告类型：新 
摘要：使用量子理论的数学框架在自然语言中含义的分类组成分布（DiscoCat）框架模型，以形式图表示。迪斯科图图可以与张量网络和量子电路相关联。在量子自然语言处理（QNLP）的各种情况下，迪斯科图图已连接到密度矩阵。 QNLP中的密度矩阵的先前使用需要将模拟歧义单词作为概率分布在更基本的单词上（例如\ texttt {queen}，例如，例如，可能意味着在统治的女王或国际象棋棋盘）。在本文中，我们使用概率分布对流程进行调查，以说明句子中的句法歧义。这些句子的含义由密度矩阵表示。我们展示了如何在代表句子含义的量子电路上创建概率分布，并解释了这种方法如何从文献中概括任务。我们进行了一个实验以验证提出的理论。]]></description>
      <guid>https://arxiv.org/abs/2504.00040</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越报告的截止：大型语言模型在财务知识上缺乏</title>
      <link>https://arxiv.org/abs/2504.00042</link>
      <description><![CDATA[ARXIV：2504.00042V1公告类型：新 
摘要：大型语言模型（LLM）经常被用作提问的知识来源。虽然众所周知，LLM可能无法访问模型截止日期后生成的实时数据或新的数据，但他们的知识如何跨越历史信息尚不清楚。在这项研究中，我们使用美国公开交易公司的财务数据来评估LLMS知识的广度，通过评估超过197k的问题并比较模型对事实数据的响应。我们进一步探讨了公司特征的影响，例如规模，零售投资，机构关注和金融申请的可读性，对LLMS代表的知识的准确性。我们的结果表明，LLM较少了解过去的财务绩效，但它们表现出对大型公司和最新信息的更强意识。有趣的是，与此同时，我们的分析还表明，LLM更有可能为大型公司幻觉，尤其是近年来数据。我们将在发布作品后将代码，提示和模型输出公开。]]></description>
      <guid>https://arxiv.org/abs/2504.00042</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>填字游戏：评估LLM和LVLM的推理能力具有可控拼图的生成</title>
      <link>https://arxiv.org/abs/2504.00043</link>
      <description><![CDATA[ARXIV：2504.00043V1公告类型：新 
摘要：大型语言模型（LLM）和大型视觉模型（LVLMS）的现有推理评估框架主要评估基于文本的推理或视觉语言理解能力，并且文本约束和视觉约束之间的动态相互作用有限。为了解决这一限制，我们介绍了填字游戏，这是一种基准测试，旨在通过填字游戏的媒介评估LLM和LVLMS的推理能力，这需要多模式依从性，以从基于文本的线索以及来自Visual Grid Grid结构的基于文本的线索和相互分裂的约束。填字游戏利用可控的拼图生成框架，该框架以多种格式（文本和图像）产生难题，并提供不同的评估策略，从直接拼图求解到交互式模式。我们对20多种模型的广泛评估表明，推理LLM通过有效利用交叉字母的约束而实质上优于非争议模型。我们进一步证明了LVLM在任务中挣扎，显示了它们的拼图性能与放映精度之间的密切相关性。我们的发现提供了有关当前LLM和LVLM的推理能力局限性的见解，并提供了一种有效的方法来创建多模式约束任务以进行将来的评估。]]></description>
      <guid>https://arxiv.org/abs/2504.00043</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用预训练的深度学习模型对4chan进行在线仇恨</title>
      <link>https://arxiv.org/abs/2504.00045</link>
      <description><![CDATA[ARXIV：2504.00045V1公告类型：新 
摘要：在线仇恨言论可能会有害影响个人和群体，特别是在未建模的平台（例如4chan）上，用户可以发布匿名内容。这项工作着重于使用最先进的自然语言处理（NLP）模型，特别是基于变压器的模型，例如罗伯塔和排毒的模型，分析和衡量4chan政治上不正确的董事会（/pol/）在线仇恨的普遍性。通过利用这些高级模型，我们提供了对仇恨言论动态的深入分析，并量化了在线仇恨非修改平台的程度。该研究通过对仇恨言论（种族主义，性别歧视，宗教等）的多级分类进行理解，同时还结合了有毒内容的分类（例如身份攻击和威胁）和进一步的主题建模分析。结果表明，该数据集的11.20％被确定为包含不同类别中的仇恨。这些评估表明，在线仇恨以各种形式表现出来，证实了野外检测的复杂性和动荡性。]]></description>
      <guid>https://arxiv.org/abs/2504.00045</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大语模型从社交媒体那里获得的多利益相关者灾难见解</title>
      <link>https://arxiv.org/abs/2504.00046</link>
      <description><![CDATA[ARXIV：2504.00046V1公告类型：新 
摘要：近年来，社交媒体已成为用户迅速在灾难和紧急情况下分享反馈和问题的主要渠道，在危机管理中发挥了关键作用。尽管在收集和分析社交媒体内容方面取得了重大进展，但仍需迫切需要增强该数据的自动化，聚合和定制，以提供针对各种利益相关者（包括新闻界，警察，EMS，EMS和消防员）量身定制的可行见解。这项工作对于改善诸如救济工作，资源分配和媒体传播等活动的协调至关重要。本文介绍了一种利用LLMS增强灾难响应和管理能力的方法。我们的方法将分类技术与生成AI结合在一起，以弥合原始用户反馈和特定于利益相关者的报告之间的差距。分析了在灾难性事件期间共享的社交媒体帖子，重点是用户报告的问题，服务中断并遇到挑战。我们采用全光谱LLM，使用BERT（例如BERT）的分析模型，以精确的内容类型，情感，情感，地理位置和主题的多维分类。然后使用诸如Chatgpt之类的生成模型来生成针对不同受众的人类可读性，内容丰富的报道，并综合了从详细的分类中得出的见解。我们将标准方法比较了我们的高级方法，该方法将使用Chatgpt中的提示直接分析帖子进行分析，该方法结合了多维分类，次活动选择和量身定制的报告生成。我们的方法证明了在定量指标中的卓越性能，例如文本相干分数和潜在表示，以及自动化工具和现场专家的定性评估，为各种灾难响应利益相关者提供了精确的见解。]]></description>
      <guid>https://arxiv.org/abs/2504.00046</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Distill-C：通过使用LLMS的蒸馏定制增强的NL2SQL</title>
      <link>https://arxiv.org/abs/2504.00048</link>
      <description><![CDATA[ARXIV：2504.00048V1公告类型：新 
摘要：在业务应用程序中，大型语言模型（LLM）的采用日益增长，将对自然语言的兴趣扩大到SQL（NL2SQL）解决方案，在该解决方案中，对高性能和效率的需求竞争。领域和特定客户的要求进一步使问题复杂化。为了解决这个难题，我们介绍了Distill-C，这是一个针对NL2SQL任务量身定制的蒸馏定制框架。 Distill-C利用大型教师LLM通过可靠且可扩展的管道来生产高质量的合成数据。在此综合数据上对较小和开源的LLM进行了较小和开源的LLM，这使他们能够竞争或超越教师建模的数量级。与来自三个不同LLM家族的基本模型相比，Distill-C在多个具有挑战性的基准测试中进行了评估，执行精度的平均提高36％。此外，在三个内部客户基准下，Distill-C比基本模型的性能提高了22.6％。我们的结果表明，Distill-C是一种有效，高性能且可推广的方法，用于部署轻巧但功能强大的NL2SQL模型，在保持低计算成本的同时提供出色的精确度。]]></description>
      <guid>https://arxiv.org/abs/2504.00048</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Judgelrm：大型推理模型作为法官</title>
      <link>https://arxiv.org/abs/2504.00050</link>
      <description><![CDATA[ARXIV：2504.00050V1公告类型：新 
摘要：作为评估者的大型语言模型（LLMS）的兴起提供了人类注释的可扩展替代方案，但对于法官的方法而言，现有的监督微调（SFT）通常在需要复杂推理的领域中缺乏。在这项工作中，我们调查了LLM法官是否真的从增强的推理能力中受益。通过对评估任务跨评估任务的推理要求的详细分析，我们揭示了SFT性能增长与推理要求样本的比例之间的负相关性 - 在这种情况下突出了SFT的局限性。为了解决这个问题，我们介绍了一个由判断力的LLM家族贾格尔姆（Judgelrm），该家族以判断力学习（RL）的判断力学习（RL），并以法官为驱动的奖励。 JudgelRM模型始终胜过SFT调整和最先进的推理模型。值得注意的是，JudgelRM-3B超过GPT-4，而JudgelRM-7B在F1得分中的表现优于DeepSeek-R1，尤其是需要深层推理的法官任务。]]></description>
      <guid>https://arxiv.org/abs/2504.00050</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在电子健康记录中将大型语言模型与人类专业知识进行疾病检测</title>
      <link>https://arxiv.org/abs/2504.00053</link>
      <description><![CDATA[ARXIV：2504.00053V1公告类型：新 
摘要：目标：电子健康记录（EHR）广泛可用于补充基于数据的疾病监视和医疗保健绩效评估。从EHR定义条件是劳动密集型的，需要大量的疾病预后手动标记。这项研究基于先进的大语言模型制定了有效的策略，以从EHR临床注释中识别多种条件。方法：我们在2015年将心脏注册人群与加拿大艾伯塔省的EHR系统联系起来。我们开发了一条管道，该管道利用生成的大语言模型（LLM）来分析，理解和解释EHR注释，该提示根据特定的诊断，治疗管理和临床指南。该管道用于检测急性心肌梗塞（AMI），糖尿病和高血压。将表现与临床医生验证的诊断作为参考标准进行了比较，并广泛采用了基于疾病的国际分类（ICD）代码。结果：该研究队列占3,088例患者和551,095例临床笔记。患病率分别为55.4％，27.7％，65.9％和AMI，糖尿病和高血压。基于LLM的管道检测条件的性能各不相同：AMI具有88％的灵敏度，63％的特异性和77％的阳性预测值（PPV）；糖尿病具有91％的敏感性，86％的特异性和71％的PPV；高血压具有94％的敏感性，32％的特异性和72％的PPV。与ICD代码相比，基于LLM的方法在所有条件下都表现出提高的灵敏度和负预测值。 LLM和参考标准从检测到的情况下的每月百分比趋势显示出一致的模式。]]></description>
      <guid>https://arxiv.org/abs/2504.00053</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估大语言模型在妇产科中进行病史的可行性和准确性</title>
      <link>https://arxiv.org/abs/2504.00061</link>
      <description><![CDATA[ARXIV：2504.00061V1公告类型：新 
摘要：在诊断前环境中，最特别是在复杂而敏感的医疗领域（例如不育）中，有效的医师与患者通信至关重要，但会消耗大量时间，因此会导致诊所工作流效率低下。大型语言模型（LLMS）的最新进展为自动化对话病史的自动化和提高诊断准确性提供了潜在的解决方案。这项研究评估了这些任务中LLM的可行性和性能。开发了一个AI驱动的对话系统，以模拟与Chatgpt-4O和Chatgpt-4O-Mini的医师相互作用。总共处理了70个现实世界中的不孕病例，产生了420个诊断历史。使用F1评分，鉴别诊断（DDS）精度以及不育类型判断（ITJ）的准确性评估模型性能。 ChatGPT-4o-mini outperformed ChatGPT-4o in information extraction accuracy (F1 score: 0.9258 vs. 0.9029, p = 0.045, d = 0.244) and demonstrated higher completeness in medical history-taking (97.58% vs. 77.11%), suggesting that ChatGPT-4o-mini is more effective in extracting detailed patient information, which is critical for improving diagnostic 准确性。相比之下，ChatGpt-4O在鉴别诊断准确性方面的表现稍好（2.0524 vs. 2.0048，p&gt; 0.05）。 CHATGPT-4O-MINI（0.6476 vs. 0.5905）的ITJ准确性较高，但一致性较低（Cronbach的$ \ alpha $ = 0.562），表明分类可靠性的可变性。这两种模型都表现出强大的可行性，可以使不育历史记录记录自动化，而Chatgpt-4o-Mini在完整性和提取准确性方面表现出色。在未来的研究中，必须优先考虑在临床环境，AI模型微调和较大数据集中的准确性和可靠性的专家验证。]]></description>
      <guid>https://arxiv.org/abs/2504.00061</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>