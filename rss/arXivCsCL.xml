<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Fri, 08 Dec 2023 03:14:59 GMT</lastBuildDate>
    <item>
      <title>DP-OPT：让大型语言模型成为您的隐私保护提示工程师。 （arXiv：2312.03724v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03724</link>
      <description><![CDATA[大型语言模型 (LLM) 已成为各种领域的主导工具
任务，特别是通过及时调整针对特定目标进行定制时。
尽管如此，围绕数据隐私的担忧仍然存在障碍，因为
调整提示对敏感私人信息的依赖。一个实用的
解决方案是托管本地法学硕士并使用私下优化软提示
数据。然而，当模型所有权被剥夺时，托管本地模型就会出现问题
受保护。替代方法，例如将数据发送给模型提供者
培训，加剧了不受信任的提供商面临的这些隐私问题。在这个
论文中，我们提出了一种新颖的解决方案，称为“差异私有异地提示”
调整（DP-OPT）来应对这一挑战。我们的方法包括调整
客户端离散提示，然后应用到所需的云
楷模。我们证明，法学硕士自己建议的提示可以
在不显着影响性能的情况下进行转移。为了确保
提示不要泄露隐私信息，我们先介绍一下隐私提示
生成机制，通过上下文中的差分私有（DP）集成
通过私人演示学习。通过 DP-OPT，生成
Vicuna-7b 的隐私保护提示可以产生具有竞争力的性能
与 GPT3.5 或本地私人提示上的非私人情境学习相比
调整。代码可在 https://github.com/VITA-Group/DP-OPT 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.03724</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>利用人工智能衍生的数据进行碳核算：从替代来源提取信息。 （arXiv：2312.03722v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03722</link>
      <description><![CDATA[碳核算是我们全球道路上的一个基本组成部分
减排脱碳，但实现目标仍面临诸多挑战
可靠且值得信赖的碳核算措施。我们激发碳
会计不仅需要更多的数据驱动，还需要更多的数据驱动
方法论上合理。我们讨论对替代性、更多样化数据的需求
在我们走向可信碳的道路上可以发挥重要作用的来源
会计程序，不仅详细说明原因，而且详细说明如何
一般智能 (AI) 和自然语言处理 (NLP)
特别是可以合理地访问替代数据宝库
根据该领域的最新进展，更好地实现
在此过程中利用非结构化数据。我们提出了一个案例研究
通过 NLP 支持的分析来了解现实世界数据的最新发展
OpenAI 针对金融和航运数据的 GPT API。我们以
讨论如何将这些方法和途径整合到更广泛的领域中
基于人工智能的综合碳核算框架。
]]></description>
      <guid>http://arxiv.org/abs/2312.03722</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 在总结成像深度学习技术演变中的应用：一项定性研究。 （arXiv：2312.03723v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03723</link>
      <description><![CDATA[对文章或文本摘要的追求已经引起了人们的注意
自然语言处理（NLP）从业者，将自己呈现为
巨大的挑战。 ChatGPT 3.5展现了压缩内容的能力
在单个页面中最多可包含 3000 个令牌，旨在保留关键信息
来自跨不同主题的给定文本。在进行的定性研究中
为了努力，我们选择了七篇科学文章并聘请了公众
可用 ChatGPT 服务来生成这些文章的摘要。
随后，我们聘请了六位文章的合著者进行了一项调查，提出了
与实际情况相比，评估摘要质量的五个问题
原创内容。调查结果显示，ChatGPT 生成的摘要
有效地概括了文章中存在的关键信息，
保留每份手稿的主要信息。尽管如此，还是有一个
与摘要的技术深度相比略有减少
原创文章。因此，我们的结论强调了 ChatGPT 的文本
总结能力作为提取基本见解的有效工具
一种比纯粹的科学话语更符合报道的方式。
]]></description>
      <guid>http://arxiv.org/abs/2312.03723</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>评估人工智能聊天机器人在综合标准化测试准备中的表现； GRE 案例研究。 （arXiv：2312.03719v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03719</link>
      <description><![CDATA[这篇研究论文对
三个人工智能 10 智能聊天机器人：Bing、ChatGPT 和 GPT-4
解决标准化测试问题。研究生入学考试，称为
GRE 作为本文的案例研究，涵盖定量
推理和语言能力。共有137道定量推理题，
具有不同的风格和 157 个口头问题，分为不同的类别
难度级别（简单、中等和困难）用于评估
聊天机器人的功能。本文提供了详细的检查
结果及其对人工智能应用的影响
通过展示每个聊天机器人的性能来进行标准化测试准备
涵盖考试中测试的各种技能和风格。另外，本文
探讨人工智能在处理基于图像的问题上的熟练程度
问题并说明每个聊天机器人的不确定性水平。结果
揭示了聊天机器人不同程度的成功，展示了
模型复杂度和训练数据的影响。 GPT-4 成为最
精通，尤其是复杂的语言理解任务，突出
人工智能在语言理解方面的演变及其
以高分通过考试的能力。
]]></description>
      <guid>http://arxiv.org/abs/2312.03719</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>与 LLMS 谈判：提示黑客、技能差距和推理缺陷。 （arXiv：2312.03720v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03720</link>
      <description><![CDATA[诸如 ChatGPT 之类的大型语言模型 LLM 已达到 100 Mio 用户大关
在创纪录的时间内，可能会越来越多地进入我们生活的各个领域，从而导致
这些人工智能模型和
人类。虽然许多研究讨论了治理和监管
从一阶原理演绎，很少有研究提供归纳，
基于观察人类和法学硕士之间对话的数据驱动镜头
尤其是当涉及到非合作、竞争的情况时
可能对人们构成严重威胁。在这项工作中，我们进行了
用户研究涉及各个年龄段的 40 多个人的价格
与法学硕士谈判。我们探索人们如何与法学硕士互动，
研究谈判结果和策略的差异。此外，
我们强调法学硕士在推理能力方面的缺点
反过来，也容易引发旨在操纵网络的黑客攻击
LLM 可以制定违反其指示或超出任何规定的协议
理性。我们还表明，人类设法实现的协商价格
跨越广泛的范围，这表明在有效互动方面存在读写能力差距
与法学硕士。
]]></description>
      <guid>http://arxiv.org/abs/2312.03720</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>探索模型分级评估的稳健性和自动解释性。 （arXiv：2312.03721v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03721</link>
      <description><![CDATA[人们对评估语言模型的兴趣越来越浓厚
各种风险和特征。基于自然语言的评估
对评分的理解通常可以通过使用其他方法来大规模执行
语言模型。我们测试这些模型分级评估的稳健性
对不同数据集的注入，包括新的欺骗评估。这些
注入类似于测试者和评估者之间的直接沟通
更改他们的评分。我们推断未来更智能的模型
可能会操纵或配合他们的评估模型。我们发现显着
在所有最先进的商业模型中对这些注射的敏感性
检查评价。此外，类似的注射可用于自动化
可解释性框架产生误导性的模型编写解释。
研究结果对未来的工作有启发，并应警惕对
评估和自动解释性。
]]></description>
      <guid>http://arxiv.org/abs/2312.03721</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>关于全球冲突的 Twitter 帖子的情绪分析。 （arXiv：2312.03715v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03715</link>
      <description><![CDATA[社交媒体数据的情感分析是一个具有广阔前景的新兴领域
各个领域的应用。在这项研究中，我们形成了一种情绪
分析模型，用于分析社交媒体情绪，尤其是推文
全球冲突场景。为了建立我们的研究实验，我们
识别了 Twitter 上最近发生的全球纠纷事件并收集了周围
几个月来过滤了 31,000 条推文，以分析全球人类情绪。
]]></description>
      <guid>http://arxiv.org/abs/2312.03715</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>多意图口语理解的共同指导。 （arXiv：2312.03716v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03716</link>
      <description><![CDATA[最近基于图的多意图 SLU 模型已经取得了良好的前景
通过建模指导从意图预测到结果
时隙填充的解码。然而，现有方法（1）仅对
从意图到槽位的单向引导，同时也有双向引导
意图和槽位之间的相互关系； (2)采用齐次图
对槽语义节点和意图标签节点之间的交互进行建模，
这限制了性能。在本文中，我们提出了一种新颖的模型，称为
Co-guiding Net，它实现了一个两阶段框架，实现了相互的
两项任务之间的指导。第一阶段，初步估计
生成两个任务的标签，然后在第二个任务中利用它们
阶段建立相互指导模型。具体来说，我们提出了两种异构
图注意力网络致力于提出的两种异构语义
标签图，有效表示语义之间的关系
节点和标签节点。此外，我们进一步提出Co-guiding-SCL Net，
利用单任务和双任务语义对比关系。为了
第一阶段，我们提出单任务监督对比学习，并且
第二阶段，我们提出共同指导监督对比学习，其中
考虑对比学习中两个任务的相互指导
程序。多意图 SLU 的实验结果表明，我们的模型
大幅优于现有模型，获得相对改进
总体准确度比 MixATIS 数据集上之前的最佳模型提高了 21.3%。
我们还在零样本跨语言场景和
结果表明我们的模型可以相对改进state-of-the-art模型
9 种语言的总体准确率平均提高了 33.5%。
]]></description>
      <guid>http://arxiv.org/abs/2312.03716</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>法律中的大型语言模型：调查。 （arXiv：2312.03718v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03718</link>
      <description><![CDATA[人工智能 (AI) 的出现极大地影响了
传统司法行业。而且，近来，随着
人工智能生成内容（AIGC）、人工智能和法律已在各个领域得到应用
领域，包括图像识别、自动文本生成和
互动聊天。随着大型企业的迅速崛起和普及
模型中，显然人工智能将推动传统行业的转型
司法行业。然而，合法的大语言模型的应用
（法学硕士）仍处于起步阶段。需要解决几个挑战。
在本文中，我们的目标是对法律法学硕士进行全面的调查。我们不
不仅对法学硕士进行了广泛的调查，而且还公开了他们在
司法系统。我们首先概述一下人工智能技术
法律领域并展示法学硕士的最新研究。然后，我们讨论
法律法学硕士提出的实际实施，例如提供法律
在审判期间向用户提供建议并协助法官。此外，我们还探索
法律法学硕士的局限性，包括数据、算法和司法实践。
最后，我们总结了切实可行的建议并提出了未来的发展建议
应对这些挑战的方向。
]]></description>
      <guid>http://arxiv.org/abs/2312.03718</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>UID 作为自动作者身份混淆的指导指标。 （arXiv：2312.03709v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03709</link>
      <description><![CDATA[鉴于
自动作者归属者的兴起。这些归因者有能力
非常准确地将文本的作者归属于一组作者中。
为了应对这些自动归因的兴起，还有
自动混淆器的兴起。这些混淆器能够采取
一些文本，以某种方式扰乱文本，如果成功的话，欺骗一个
自动归因错误归因于错误的作者。我们设计了三本小说
利用已知的心理语言学理论的作者身份混淆方法
作为统一信息密度（UID）理论。该理论指出，人类
在语音或文本之间均匀分布信息，以便最大化
效率。在我们的三种混淆方法中利用这一理论，我们
试图看看我们如何成功地欺骗两个不同的归因者。
混淆来自 TuringBench 的 50 篇人类文章和 50 篇 GPT-3 生成的文章
数据集中，我们观察了每种方法在欺骗归因者方面的表现。
虽然语义保存和混淆的质量
感官变化很高，我们无法找到任何证据表明
UID 是一个可行的混淆指导指标。但由于限制
随着时间的推移，我们无法测试足够大的文章样本或调整
供我们的归因者对混淆中的 UID 做出结论性评论的参数。
]]></description>
      <guid>http://arxiv.org/abs/2312.03709</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>不要忽视语法性别：印地语-英语机器翻译的偏差评估。 （arXiv：2312.03710v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03710</link>
      <description><![CDATA[神经机器翻译 (NMT) 模型，尽管是最先进的
翻译往往反映社会偏见，尤其是性别偏见。现存的
评估基准主要关注英语作为源语言
翻译。对于英语以外的源语言，研究经常采用
用于偏见评估的性别中立句子，而现实世界的句子
经常包含不同形式的性别信息。因此，它使得
使用此类源句子来评估偏差以确定 NMT 是否更有意义
模型可以从语法性别线索中辨别性别，而不是依赖
关于有偏见的联想。为了说明这一点，我们创建了两个特定性别的
印地语句子集自动评估各种性别偏见
印地语-英语 (HI-EN) NMT 系统。我们强调量身定制的重要性
偏见评估测试集，以解释语法性别标记
源语言。
]]></description>
      <guid>http://arxiv.org/abs/2312.03710</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 GloVe 和神经网络模型进行多标签文本分类。 （arXiv：2312.03707v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03707</link>
      <description><![CDATA[这项研究解决了多标签文本分类的挑战。这
困难来自于不平衡的数据集、不同的文本长度以及大量的
主观特征标签。现有的解决方案包括传统机器
用于预测的学习和深度神经网络。然而，这两种方法
有其局限性。传统的机器学习常常忽视
单词之间的关联，而深度神经网络，尽管它们更好
分类性能随着训练复杂性和时间的增加而增加。
本文提出了一种基于词袋模型的方法
GloVe 模型和 CNN-BiLSTM 网络。原则是用这个词
由 GloVe 模型训练的向量矩阵作为文本嵌入的输入
层。鉴于 GloVe 模型不需要进一步训练，神经网络
可以更有效地训练网络模型。该方法达到了准确率
测试集上的正确率高达 87.26%，F1 分数为 0.8737，展现出良好的前景
结果。
]]></description>
      <guid>http://arxiv.org/abs/2312.03707</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>通过范例进行抽象？ BERT 中词汇类别推断的代表性案例研究。 （arXiv：2312.03708v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03708</link>
      <description><![CDATA[基于示例的帐户通常被认为与
纯粹语言抽象解释语言学习者的能力
推广到新颖的表达方式。然而，最近神经网络的成功
语言敏感任务的语言模型表明也许
抽象可以通过范例的编码产生。我们提供经验
通过调整现有的实验来证明这一说法，该实验研究了如何
LM (BERT) 概括了属于词汇的新颖标记的使用
名词/动词/形容词/副词等类别仅接触到一个
它们的用法实例。我们分析小说的代表性行为
这些实验中的标记，并发现 BERT 的泛化能力
涉及使用这些新颖标记的看不见的表达构成了
新的标记表示向已知类别的区域移动
二维空间中的范例。我们的结果表明学习者的编码
样本的数量确实可以产生类似抽象的行为。
]]></description>
      <guid>http://arxiv.org/abs/2312.03708</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>通过词嵌入进行主题建模的过程。 （arXiv：2312.03705v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03705</link>
      <description><![CDATA[这项工作结合了基于词嵌入、维度​​的算法
减少和聚类。目标是从一组
未分类的文本。获取词嵌入的算法是BERT
模型，一种广泛应用于 NLP 任务的神经网络架构。由于高
维数，使用称为 UMAP 的降维技术。这
方法设法减少维度，同时保留部分局部和
原始数据的全局信息。 K-Means用作聚类
获取主题的算法。然后，使用 TF-IDF 评估主题
统计、主题多样性和主题连贯性，以了解主题的含义
集群上的单词。该过程的结果显示出良好的价值，因此
此过程的主题建模是分类或聚类的可行选择
没有标签的文本。
]]></description>
      <guid>http://arxiv.org/abs/2312.03705</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:53 GMT</pubDate>
    </item>
    <item>
      <title>用于讽刺检测的最先进大型语言模型的评估。 （arXiv：2312.03706v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03706</link>
      <description><![CDATA[根据韦氏词典的定义，讽刺是指某人使用以下词语：
意思与他想说的相反。在感情领域
分析自然语言处理，正确识别的能力
为了了解人们的真实想法，讽刺是必要的。因为使用
讽刺的表达通常是基于语境的，之前的研究已经使用了语言
表示模型，例如支持向量机 (SVM) 和长期短期
记忆（LSTM），通过基于上下文的信息识别讽刺。最近的
NLP 的创新为检测讽刺提供了更多可能性。在
BERT：语言深度双向变压器的预训练
理解，雅各布·德夫林等人。 (2018) 引入了一种新语言
表示模型并表现出更高的解释精度
语境化的语言。正如 Hazarika 等人提出的。 （2018），CASCADE 是
上下文驱动的模型可以为检测讽刺产生良好的结果。这
研究使用这两种最先进的模型来分析 Reddit 语料库
根据基线模型评估其性能，以找到理想的方法
讽刺检测。
]]></description>
      <guid>http://arxiv.org/abs/2312.03706</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:53 GMT</pubDate>
    </item>
    </channel>
</rss>