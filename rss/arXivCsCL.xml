<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 25 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>大型语言模型中的风险和响应：评估关键威胁类别</title>
      <link>https://arxiv.org/abs/2403.14988</link>
      <description><![CDATA[arXiv:2403.14988v1 公告类型：新
摘要：本文探讨了大型语言模型（LLM）中风险评估的紧迫问题，因为它们在各种应用中变得越来越普遍。我们专注于奖励模型（旨在微调预训练的法学硕士以符合人类价值观）如何感知和分类不同类型的风险，深入研究基于偏好的训练数据的主观性质所带来的挑战。通过利用 Anthropic 红队数据集，我们分析主要风险类别，包括信息危害、恶意使用和歧视/仇恨内容。我们的研究结果表明，法学硕士倾向于认为信息危害的危害较小，这一发现得到了专门开发的回归模型的证实。此外，我们的分析表明，与其他风险相比，法学硕士对信息危害的反应不太严格。该研究进一步揭示了法学硕士在信息危害场景中易受越狱攻击的重大漏洞，强调了法学硕士风险评估中的一个关键安全问题，并强调需要改进人工智能安全措施。]]></description>
      <guid>https://arxiv.org/abs/2403.14988</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>MasonTigers 参加 SemEval-2024 任务 8：基于 Transformer 的模型在机器生成文本检测方面的性能分析</title>
      <link>https://arxiv.org/abs/2403.14989</link>
      <description><![CDATA[arXiv:2403.14989v1 公告类型：新
摘要：本文介绍了 MasonTigers 进入 SemEval-2024 任务 8 - 多生成器、多域和多语言黑盒机器生成文本检测的情况。该任务包括二进制人类书写与机器生成的文本分类（轨道 A）、多路机器生成的文本分类（轨道 B）和人机混合文本检测（轨道 C）。我们性能最佳的方法主要利用判别器变换器模型的集合以及特定情况下的句子变换器和统计机器学习方法。此外，A、B轨均采用FLAN-T5的零镜头提示和微调。]]></description>
      <guid>https://arxiv.org/abs/2403.14989</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>证据驱动的检索增强在线错误信息的响应生成</title>
      <link>https://arxiv.org/abs/2403.14952</link>
      <description><![CDATA[arXiv:2403.14952v1 公告类型：新
【摘要】：网络虚假信息的泛滥对公共利益构成了重大威胁。尽管许多在线用户积极参与打击虚假信息的斗争，但许多此类回应的特点是缺乏礼貌和支持事实。作为一种解决方案，提出了文本生成方法来自动生成反错误信息响应。然而，现有方法通常是在不利用外部知识的情况下进行端到端训练，导致文本质量不佳和过度重复的响应。在本文中，我们提出针对在线错误信息的检索增强响应生成（RARG），它从科学来源收集支持证据，并根据证据生成反错误信息响应。具体来说，我们的 RARG 包括两个阶段：（1）证据收集，我们设计一个检索管道，使用包含超过 100 万篇学术文章的数据库来检索和重新排列证据文档； (2) 响应生成，其中我们调整大型语言模型 (LLM)，通过人类反馈的强化学习 (RLHF) 生成基于证据的响应。我们提出了一个奖励函数，以最大限度地利用检索到的证据，同时保持生成文本的质量，从而产生礼貌和事实的响应，明确驳斥错误信息。为了证明我们方法的有效性，我们研究了 COVID-19 的案例，并使用域内和跨域数据集进行了广泛的实验，其中 RARG 通过生成高质量的反错误信息响应，始终优于基线。]]></description>
      <guid>https://arxiv.org/abs/2403.14952</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>MasonTigers 参加 SemEval-2024 任务 9：用一系列思维链解决谜题</title>
      <link>https://arxiv.org/abs/2403.14982</link>
      <description><![CDATA[arXiv:2403.14982v1 公告类型：新
摘要：我们的论文介绍了 MasonTigers 团队向 SemEval-2024 任务 9 提交的内容，该任务提供了用于测试自然语言理解的谜题数据集。我们采用大型语言模型（LLM）通过多种提示技术来解决此任务。与开源模型相比，在使用专有法学硕士进行测试时，零样本和少样本提示会产生相当好的结果。我们通过思想链提示获得了进一步改进的结果，这是一种逐步分解推理过程的迭代提示方法。我们通过利用一系列思维链提示获得了最好的结果，在单词谜题子任务中排名第二，在句子谜题子任务中排名第 13。提示法学硕士的出色表现证明了他们在提供思维过程分解时进行复杂推理的能力。我们的工作揭示了逐步解释提示如何解锁大型模型参数中编码的更多知识。]]></description>
      <guid>https://arxiv.org/abs/2403.14982</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>单个线性层产生适应任务的低秩矩阵</title>
      <link>https://arxiv.org/abs/2403.14946</link>
      <description><![CDATA[arXiv:2403.14946v1 公告类型：新
摘要：低秩适应（LoRA）是一种广泛使用的参数高效微调（PEFT）方法，它用由两个低秩矩阵 $A 组成的 delta 矩阵 $\Delta W$ 更新初始权重矩阵 $W_0$ $和$B$。先前的研究表明 $W_0$ 和 $\Delta W$ 之间存在相关性。在本研究中，我们的目标是更深入地研究 $W_0$ 与低秩矩阵 $A$ 和 $B$ 之间的关系，以进一步理解 LoRA 的行为。特别是，我们分析了一个将 $W_0$ 转换为低秩矩阵的转换矩阵，该矩阵封装了有关关系的信息。我们的分析表明，每一层的转换矩阵都是相似的。受这些发现的启发，我们假设单个线性层以每层的 $W_0$ 作为输入，可以产生适应任务的低秩矩阵。为了证实这一假设，我们设计了一种名为条件参数化 LoRA (CondLoRA) 的方法，该方法使用从单个线性层导出的低秩矩阵更新初始权重矩阵。我们的实证结果表明，尽管 CondLoRA 的可训练参数比 LoRA 少，但 CondLoRA 的性能仍与 LoRA 相当。因此，我们得出的结论是“单个线性层产生适应任务的低秩矩阵”。]]></description>
      <guid>https://arxiv.org/abs/2403.14946</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>KnowLA：通过知识性适应增强参数高效的微调</title>
      <link>https://arxiv.org/abs/2403.14950</link>
      <description><![CDATA[arXiv:2403.14950v1 公告类型：新
摘要：参数高效微调（PEFT）是使大型语言模型（LLM）适应下游任务的关键技术。在本文中，我们研究利用知识图嵌入来提高 PEFT 的有效性。我们提出了一种称为 KnowLA 的知识适应方法。它将适应层插入到 LLM 中，以集成输入文本中出现的实体的嵌入。适配层结合 LoRA 对指令数据进行训练。使用两个流行的法学硕士和三个知识图在六个基准上进行的实验证明了 KnowLA 的有效性和稳健性。我们证明 \modelname 可以帮助激活 LLM 中的相关参数化知识来回答问题，而无需更改其参数或输入提示。]]></description>
      <guid>https://arxiv.org/abs/2403.14950</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>用于高效自回归文本生成的分层跳过解码</title>
      <link>https://arxiv.org/abs/2403.14919</link>
      <description><![CDATA[arXiv:2403.14919v1 公告类型：新
摘要：自回归解码策略是预训练语言模型文本生成任务的常用方法，而提前退出是加速推理阶段的有效方法。在这项工作中，我们提出了一种名为分层跳过解码（HSD）的新颖解码策略，用于高效的自回归文本生成。与需要额外可训练组件的现有方法不同，HSD是一种适用于自回归文本生成模型的即插即用方法，它根据当前序列长度以分层方式自适应地跳过解码层，从而减少计算工作量并分配计算资源。使用预训练语言模型对五个文本生成数据集进行综合实验，证明了 HSD 在平衡效率和文本质量方面的优势。与普通自回归解码相比，HSD 跳过了近一半的层，可以维持 90% 的文本质量，优于竞争方法。]]></description>
      <guid>https://arxiv.org/abs/2403.14919</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>注意力驱动推理：释放大型语言模型的潜力</title>
      <link>https://arxiv.org/abs/2403.14932</link>
      <description><![CDATA[arXiv:2403.14932v1 公告类型：新
摘要：大型语言模型（LLM）已经表现出了非凡的能力，但它们的推理能力和底层机制仍然知之甚少。我们提出了一种新颖的方法，通过注意力机制优化来增强法学硕士的推理能力，无需额外的训练数据。我们发现了非语义标记导致的注意力分配效率低下，并提出了一种重新平衡倾斜分布的算法，使模型能够抽象出更细致的知识。我们的实验证明推理能力显着提高，尤其是对于非 STEM 问题。我们深入探讨了注意力模式在法学硕士推理中的作用，并提出了一种增强这些能力的方法，为更强大、更通用的语言模型铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2403.14932</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>关于法学硕士的零样本反语音生成</title>
      <link>https://arxiv.org/abs/2403.14938</link>
      <description><![CDATA[arXiv:2403.14938v1 公告类型：新
摘要：随着大量大型语言模型（LLM）的出现，此类模型在各种自然语言处理（NLP）应用中的使用越来越广泛。反言语生成就是这样一项关键任务，人们努力通过使用仇恨言语-反言语对微调法学硕士来开发生成模型，但这些尝试都没有探索零样本设置中大型语言模型的内在属性。在这项工作中，我们对四种 LLM（即 GPT-2、DialoGPT、ChatGPT 和 FlanT5）在用于反语音生成的零样本设置中的性能进行了全面分析，这在同类研究中尚属首次。对于 GPT-2 和 DialoGPT，我们进一步研究了模型尺寸（小、中、大）方面的性能偏差。另一方面，我们提出了三种不同的提示策略来生成不同类型的反言语，并分析了这些策略对模型性能的影响。我们的分析表明，两个数据集的生成质量有所提高 (17%)，但毒性随着模型大小的增加而增加 (25%)。考虑到模型类型，GPT-2 和 FlanT5 模型在反语音质量方面明显更好，但与 DialoGPT 相比也具有较高的毒性。 ChatGPT 在所有指标上都比其他模型更擅长生成反驳言论。在提示方面，我们发现我们提出的策略有助于改善所有模型的反言语生成。]]></description>
      <guid>https://arxiv.org/abs/2403.14938</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>AutoRE：使用大型语言模型进行文档级关系提取</title>
      <link>https://arxiv.org/abs/2403.14888</link>
      <description><![CDATA[arXiv:2403.14888v1 公告类型：新
摘要：大型语言模型（LLM）在理解和生成文本方面表现出了卓越的能力，促使众多研究人员将其用于信息提取（IE）目的，包括关系提取（RE）。尽管如此，大多数现有方法主要是为句子级关系提取（SentRE）任务而设计的，该任务通常在单个句子中包含一组有限的关系和三元组事实。此外，某些方法将关系视为集成到提示模板中的候选选择，导致处理文档级关系提取（DocRE）任务时处理效率低下和性能不佳，这需要处理分布在给定文档中的多个关系和三元组事实，提出独特的挑战。为了克服这些限制，我们引入了 AutoRE，这是一种端到端的 DocRE 模型，它采用了一种名为 RHF（Relation-Head-Facts）的新型 RE 提取范例。与现有方法不同，AutoRE 不依赖于已知关系选项的假设，使其更能反映现实世界的场景。此外，我们还使用参数高效微调 (PEFT) 算法 (QLoRA) 开发了一个易于扩展的 RE 框架。我们在 RE-DocRED 数据集上的实验展示了 AutoRE 的最佳性能，达到了最先进的结果，在开发集和测试集上分别超过 TAG 10.03% 和 9.03%。]]></description>
      <guid>https://arxiv.org/abs/2403.14888</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:14 GMT</pubDate>
    </item>
    <item>
      <title>Stance Reasoner：通过显式推理在社交媒体上进行零射击姿势检测</title>
      <link>https://arxiv.org/abs/2403.14895</link>
      <description><![CDATA[arXiv:2403.14895v1 公告类型：新
摘要：社交媒体平台是固执己见内容的丰富来源。立场检测允许从此类内容中自动提取用户对各种主题的意见。我们专注于零样本姿态检测，其中模型的成功依赖于（a）了解目标主题； (b) 学习可用于新主题的一般推理策略。我们提出了 Stance Reasoner，这是一种在社交媒体上进行零样本立场检测的方法，它利用背景知识的显式推理来指导模型推断文档对目标的立场。具体来说，我们的方法使用预先训练的语言模型作为世界知识的来源，并使用上下文中的思想链学习方法来生成中间推理步骤。 Stance Reasoner 在 3 个 Twitter 数据集上的性能优于当前最先进的模型，包括完全监督的模型。它可以更好地跨目标进行概括，同时为其预测提供明确且可解释的解释。]]></description>
      <guid>https://arxiv.org/abs/2403.14895</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:14 GMT</pubDate>
    </item>
    <item>
      <title>TAMS：翻译辅助形态分割</title>
      <link>https://arxiv.org/abs/2403.14840</link>
      <description><![CDATA[arXiv:2403.14840v1 公告类型：新
摘要：规范形态分割是将单词分析为其构成语素的标准（也称为基础）形式的过程。这是语言文档的核心任务，NLP 系统有潜力显着加快这一过程。但在典型的语言文档环境中，规范语素分割的训练数据很少，因此很难训练高质量的模型。然而，翻译数据通常要丰富得多，在这项工作中，我们提出了一种尝试在规范分割任务中利用这些数据的方法。我们提出了一种字符级序列到序列模型，该模型将从预训练的高资源单语语言模型获得的翻译表示作为附加信号。我们的模型在超低资源设置中优于基线，但在使用更多数据进行训练分割时产生混合结果。虽然需要进一步的工作来使翻译在资源较多的环境中发挥作用，但我们的模型在资源严重受限的环境中显示出了希望。]]></description>
      <guid>https://arxiv.org/abs/2403.14840</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:13 GMT</pubDate>
    </item>
    <item>
      <title>比较基础和指令调整的大型语言模型的合理性估计</title>
      <link>https://arxiv.org/abs/2403.14859</link>
      <description><![CDATA[arXiv:2403.14859v1 公告类型：新
摘要：指令调整的法学硕士可以响应以提示形式表达的显式查询，这极大地促进了与人类用户的交互。然而，基于提示的方法可能并不总是能够利用法学硕士在预培训期间获得的大量隐性知识。本文对法学硕士语义合理性的评估方法进行了全面研究。我们通过（a）显式提示和（b）通过直接读出分配给字符串的概率模型进行隐式估计，比较英语句子合理性任务上的基础法学硕士和指令调整法学硕士的表现。实验 1 表明，在模型架构和合理性数据集上，(i) 对数似然 ($\textit{LL}$) 分数是句子合理性最可靠的指标，零样本提示会产生不一致且通常很差的结果； (ii) 基于 $\textit{LL}$ 的性能仍然不如人类的性能； (iii) 指令调整模型基于 $\textit{LL}$ 的性能比基本模型差。在实验 2 中，我们表明，跨模型的 $\textit{LL}$ 分数以预期的方式受上下文调节，在上下文敏感的合理性的三个指标上显示出高性能，并提供与明确的人类合理性判断的直接匹配。总体而言，$\textit{LL}$ 估计仍然是比直接提示更可靠的法学硕士合理性衡量标准。]]></description>
      <guid>https://arxiv.org/abs/2403.14859</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:13 GMT</pubDate>
    </item>
    <item>
      <title>口语对话话语的语用相似性判断集</title>
      <link>https://arxiv.org/abs/2403.14808</link>
      <description><![CDATA[arXiv:2403.14808v1 公告类型：新
摘要：自动测量话语之间的相似度对于训练语音合成器、评估机器翻译和评估学习者的作品非常有价值。虽然存在语义相似性和韵律相似性的衡量标准，但目前还没有语用相似性的衡量标准。为了能够训练这些措施，我们开发了第一个人类对话语对之间的语用相似性判断的集合。每对都包含从录制的对话中提取的话语和该话语的重演。重演是在各种条件下进行的，旨在创造不同程度的相似性。每对选手均由 6 至 9 名评委进行连续评分。英语法官间的平均相关性高达 0.72，西班牙语法官间的平均相关性高达 0.66。我们在 https://github.com/divettemarco/PragSim 提供此数据。]]></description>
      <guid>https://arxiv.org/abs/2403.14808</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:12 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型在心理健康领域的机遇和风险</title>
      <link>https://arxiv.org/abs/2403.14814</link>
      <description><![CDATA[arXiv:2403.14814v1 公告类型：新
摘要：全球心理健康问题的发生率正在上升，人们越来越认识到现有的心理保健模式将无法充分扩展以满足需求。随着大型语言模型（LLM）的出现，人们对它们创造新颖的、大规模的解决方案来支持心理健康的承诺感到非常乐观。尽管法学硕士刚刚起步，但它已经应用于与心理健康相关的任务。在这篇综述中，我们总结了关于利用法学硕士提供心理健康教育、评估和干预的现有文献，并强调了在每个领域产生积极影响的关键机会。然后，我们强调与法学硕士申请心理健康相关的风险，并鼓励采取策略来减轻这些风险。对心理健康支持的迫切需求必须与负责任的心理健康法学硕士的开发、测试和部署相平衡。尤其重要的是，确保心理健康法学硕士针对心理健康进行微调，增强心理健康公平性，遵守道德标准，并确保人们，包括那些有心理健康问题生活经验的人，参与从开发到部署的所有阶段。优先考虑这些努力将最大限度地减少对心理健康的潜在危害，并最大限度地提高法学硕士对全球心理健康产生积极影响的可能性。]]></description>
      <guid>https://arxiv.org/abs/2403.14814</guid>
      <pubDate>Mon, 25 Mar 2024 06:18:12 GMT</pubDate>
    </item>
    </channel>
</rss>