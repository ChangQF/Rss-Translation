<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 14 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>童话故事中对社会价值观的明确提及：三种欧洲文化的比较</title>
      <link>https://arxiv.org/abs/2402.08318</link>
      <description><![CDATA[对童话故事中社会价值观的研究为了解跨越时空的价值观交流提供了可能性。我们建议使用一种称为指南针词嵌入的技术来研究葡萄牙、意大利和德国童话故事中的价值观交流，以量化词汇差异和共性。我们研究这三个国家的童话传统在明确提及价值观方面有何不同。为此，我们指定一个有价值的标记列表，考虑它们的词干，并在定制的预训练 Word2Vec 模型中分析它们之间的距离。我们对这个定量模型得出的假设的有效性进行三角测量并批判性地讨论。我们认为，这是一种可重复使用和可重复的方法，用于研究历史语料库中明确引用的价值观。最后，我们的初步发现暗示了整个欧洲社会存在共同的文化理解和价值观的表达，例如仁慈、顺从和普遍主义，这表明泛欧洲文化记忆的存在。]]></description>
      <guid>https://arxiv.org/abs/2402.08318</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>培养忠实且稳健的法学硕士专家进行循证问答</title>
      <link>https://arxiv.org/abs/2402.08277</link>
      <description><![CDATA[大型语言模型 (LLM) 的更忠实和可追踪的答案的进步对于各种研究和实践活动至关重要。实现这一目标的途径之一是将答案建立在可靠的来源之上。然而，事实证明，这种基于证据的质量保证在引用正确的来源（来源质量）和真实地表示来源中的信息（答案归因）方面与法学硕士的配合不够。在这项工作中，我们系统地研究了如何稳健地微调法学硕士，以获得更好的来源质量和答案归因。具体来说，我们引入了带有自动数据质量过滤器的数据生成管道，它可以大规模合成多样化的高质量训练和测试数据。我们进一步引入了四个测试集来对微调专业模型的稳健性进行基准测试。广泛的评估表明，对合成数据进行微调可以提高分布内和分布外的性能。 %基于证据的 QA 案例。此外，我们表明，在改进基于证据的 QA 方面，数据质量（可以通过提出的质量过滤器大幅提高）比数量更重要。]]></description>
      <guid>https://arxiv.org/abs/2402.08277</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>ChatCell：利用自然语言促进单细胞分析</title>
      <link>https://arxiv.org/abs/2402.08303</link>
      <description><![CDATA[随着大型语言模型（LLM）的迅速发展，它们对科学的影响变得越来越突出。法学硕士在任务概括和自由形式对话方面的新兴能力可以显着推进化学和生物学等领域的发展。然而，构成生物体基本组成部分的单细胞生物学领域仍然面临着一些挑战。当前方法中的高知识壁垒和有限的可扩展性限制了法学硕士在掌握单细胞数据方面的充分利用，阻碍了直接访问和快速迭代。为此，我们引入了 ChatCell，它通过利用自然语言促进单细胞分析来实现范式转变。利用词汇适应和统一序列生成，ChatCell 获得了单细胞生物学方面深厚的专业知识以及适应各种分析任务的能力。大量实验进一步证明了 ChatCell 的强大性能和深化单细胞洞察的潜力，为这一关键领域更容易、更直观的探索铺平了道路。我们的项目主页位于 https://zjunlp.github.io/project/ChatCell。]]></description>
      <guid>https://arxiv.org/abs/2402.08303</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>通过实例混淆进行隐私保护语言模型推理</title>
      <link>https://arxiv.org/abs/2402.08227</link>
      <description><![CDATA[语言模型即服务 (LMaaS) 为开发人员和研究人员提供了使用预先训练的语言模型进行推理的便捷途径。然而，包含隐私信息的输入数据和推理结果在服务调用过程中以明文形式暴露，导致隐私问题。最近的研究开始通过噪声添加和内容扰动等技术将输入数据转换为来自用户端的隐私保护表示来解决隐私问题，而对推理结果保护（即决策隐私）的探索仍然是空白页。为了保持 LMaaS 的黑盒方式，进行数据隐私保护，尤其是决策数据隐私保护，是一项具有挑战性的任务，因为该过程必须与模型无缝连接，并且伴随着有限的通信和计算开销。因此，我们提出了实例模糊推理（IOI）方法，该方法专注于解决自然语言理解任务在其整个生命周期中的决策隐私问题。此外，我们还进行了全面的实验来评估所提出的方法在各种基准测试任务上的性能和隐私保护强度。]]></description>
      <guid>https://arxiv.org/abs/2402.08227</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型表推理综述</title>
      <link>https://arxiv.org/abs/2402.08259</link>
      <description><![CDATA[表格推理，旨在根据提供的表格，以及可选的表格的文字描述，根据用户需求生成对应问题的答案，有效提高获取信息的效率。最近，使用大型语言模型（LLM）已成为表推理的主流方法，因为它不仅显着降低了注释成本，而且超过了以前方法的性能。然而，现有研究仍缺乏对基于LLM的表推理工作的总结。由于目前研究的缺乏，法学硕士时代哪些技术可以提高表推理性能、法学硕士为什么擅长表推理以及未来如何增强表推理能力等问题仍然很大程度上没有被探索。这一差距极大地限制了研究的进展。为了回答上述问题并推进法学硕士的表格推理研究，我们提出这项调查来分析现有研究，启发未来的工作。在本文中，我们分析了LLM时代用于提高表推理性能的主流技术，以及LLM与pre-LLM相比在解决表推理方面的优势。我们从改进现有方法和扩展实际应用两个方面提供研究方向，以启发未来的研究。]]></description>
      <guid>https://arxiv.org/abs/2402.08259</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>CMA-R：解释谣言检测的因果中介分析</title>
      <link>https://arxiv.org/abs/2402.08155</link>
      <description><![CDATA[我们应用因果中介分析来解释 Twitter 上谣言检测的神经模型的决策过程。输入和网络级别的干预揭示了模型输出中推文和单词的因果影响。我们发现，我们的方法 CMA-R（用于谣言检测的因果中介分析）可以识别解释模型预测的显着推文，并与人类对确定故事真实性的关键推文的判断表现出强烈的一致性。 CMA-R 可以进一步突出显示显着推文中具有因果影响的词语，为这些黑盒谣言检测系统提供另一层可解释性和透明度。代码位于：https://github.com/ltian678/cma-r。]]></description>
      <guid>https://arxiv.org/abs/2402.08155</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>像素句子表示学习</title>
      <link>https://arxiv.org/abs/2402.08183</link>
      <description><![CDATA[众所周知，预训练的语言模型在捕获句子和文档级语义方面表现不佳。尽管经过大量研究，将基于扰动的方法从无监督视觉表示学习转移到 NLP 仍然是一个未解决的问题。这主要是由于语言模型标记化带来的子词单元的离散性，限制了输入的小扰动以形成语义保留的正对。在这项工作中，我们将句子级文本语义的学习概念化为视觉表示学习过程。我们借鉴认知和语言科学的经验，引入了一种无监督的视觉句子表示学习框架，采用基于视觉的文本扰动方法（例如打字错误和词序洗牌），与人类认知模式产生共鸣，并使对文本的扰动能够被感知为连续的。我们的方法得到大规模无监督主题对齐训练和自然语言推理监督的进一步支持，在语义文本相似性（STS）方面实现了与现有最​​先进的 NLP 方法相当的性能。此外，我们还揭示了我们的方法固有的零样本跨语言可迁移性以及迭代训练过程中独特的跨语言跳跃模式。据我们所知，这是第一个无需传统语言模型来理解句子和文档语义的表示学习方法，标志着向类人文本理解迈出了一步。我们的代码位于 https://github.com/gowitheflow-1998/Pixel-Linguist]]></description>
      <guid>https://arxiv.org/abs/2402.08183</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>BBox-Adapter：黑盒大语言模型的轻量级适配</title>
      <link>https://arxiv.org/abs/2402.08219</link>
      <description><![CDATA[使 GPT-4 和 Gemini 等最先进的大型语言模型 (LLM) 适应特定任务具有挑战性。由于其参数、嵌入甚至输出概率的不透明性，现有的微调适应方法不适用。因此，只有通过 API 服务才能适应这些黑盒法学硕士，这引发了人们对透明度、隐私和成本的担忧。为了应对这些挑战，我们推出了 BBox-Adapter，这是一种用于黑盒 LLM 的新型轻量级适配器。 BBox-Adapter 通过将目标数据视为正数据，将源数据视为负数据来区分目标域数据和源域数据。它采用基于排名的噪声对比估计（NCE）损失来提高目标域数据的可能性，同时惩罚源域数据的可能性。此外，它还具有在线适应机制，其中结合了来自地面实况、人类或人工智能反馈的实时正数据采样，以及之前适应的负数据。大量实验证明了 BBox-Adapter 的有效性和成本效率。它在不同的任务和领域中将模型性能提高了高达 6.77%，同时将训练和推理成本分别降低了 31.30 倍和 1.84 倍。]]></description>
      <guid>https://arxiv.org/abs/2402.08219</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>研究文本到 SQL 翻译中大型语言模型的数据污染的影响</title>
      <link>https://arxiv.org/abs/2402.08100</link>
      <description><![CDATA[理解文本描述来生成代码似乎是零样本场景中指令跟踪大型语言模型（LLM）所实现的能力。然而，这种翻译能力很可能会受到看到目标文本描述和相关代码的影响。这种效应称为数据污染。
  在本研究中，我们研究了数据污染对 GPT-3.5 在文本到 SQL 代码生成任务中性能的影响。因此，我们引入了一种新颖的方法来检测 GPT 中的数据污染，并使用已知的 Spider 数据集和我们新的不熟悉的数据集 Termite 检查 GPT-3.5 的文本到 SQL 性能。此外，我们通过对抗性表断开 (ATD) 方法分析了 GPT-3.5 对修改信息的数据库的功效，通过从数据库中删除结构性信息，使文本到 SQL 任务变得复杂。我们的结果表明，即使进行了 ATD 修改，GPT-3.5 在不熟悉的 Termite 数据集上的性能也会显着下降，这凸显了文本到 SQL 翻译任务中数据污染对 LLM 的影响。]]></description>
      <guid>https://arxiv.org/abs/2402.08100</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>解决医学语言模型中的认知偏差</title>
      <link>https://arxiv.org/abs/2402.08113</link>
      <description><![CDATA[大语言模型 (LLM) 与医学领域的集成因其在模拟临床决策环境中具有良好的准确性而受到广泛关注。然而，临床决策比模拟更复杂，因为医生的决策受到许多因素的影响，包括认知偏差的存在。然而，法学硕士在多大程度上容易受到影响人类临床医生的相同认知偏见的影响仍有待探索。我们的假设认为，当法学硕士面临包含认知偏差的临床问题时，与没有此类偏差的相同问题相比，他们给出的答案的准确度要低得多。在这项研究中，我们开发了 BiasMedQA，这是一种评估应用法学硕士认知偏差的新基准。到医疗任务。我们使用 BiasMedQA 评估了 6 个 LLM，即 GPT-4、Mixtral-8x70B、GPT-3.5、PaLM-2、Llama 2 70B-chat 和医学专业 PMC Llama 13B。我们对美国医疗执照考试 (USMLE) 第 1、2 和 3 步中的 1,273 个问题测试了这些模型，并进行了修改以复制常见的临床相关认知偏差。我们的分析揭示了偏见对这些 LLM 的不同影响，其中 GPT-4 因其对偏见的恢复能力而脱颖而出，而 Llama 2 70B-chat 和 PMC Llama 13B 则受到认知偏见的影响尤为严重。我们的研究结果强调了医学法学硕士发展中减少偏见的迫切需要，指出了医疗保健领域更安全、更可靠的应用。]]></description>
      <guid>https://arxiv.org/abs/2402.08113</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>粗心耳语：语音转文字幻觉的危害</title>
      <link>https://arxiv.org/abs/2402.08021</link>
      <description><![CDATA[语音转文本服务旨在尽可能准确地转录输入音频。它们在日常生活中发挥着越来越重要的作用，例如在个人语音助理或客户与公司的互动中。我们评估了 Open AI 的 Whisper，这是一项超越行业竞争对手的最先进服务。虽然 Whisper 的许多转录非常准确，但我们发现大约 1% 的音频转录包含整个幻觉短语或句子，而这些短语或句子在底层音频中并不以任何形式存在。我们对 Whisper 幻觉内容进行了主题分析，发现 38% 的幻觉包含明显的伤害，例如暴力、编造的个人信息或基于视频的虚假权威。我们进一步提供了关于幻觉发生原因的假设，揭示了由于言语类型和健康状况而导致的潜在差异。我们呼吁行业从业者改善 Whisper 中这些基于语言模型的幻觉，并提高对语音转文本模型下游应用中潜在偏差的认识。]]></description>
      <guid>https://arxiv.org/abs/2402.08021</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为两人游戏中的代理</title>
      <link>https://arxiv.org/abs/2402.08078</link>
      <description><![CDATA[通过在单一统一的机器学习范式中正式定义大型语言模型 (LLM) 的训练过程（通常包括预训练、监督微调和基于人类反馈的强化学习），我们可以收集推进 LLM 的关键见解技术。本立场文件描述了法学硕士的训练方法与两人游戏中代理开发策略之间的相似之处，如博弈论、强化学习和多代理系统中所研究的那样。我们建议根据基于语言的游戏中的代理学习来重新概念化 LLM 学习过程。该框架揭示了法学硕士发展的成功和挑战的创新视角，为解决其他战略考虑因素中的一致性问题提供了新的理解。此外，我们的两人游戏方法揭示了用于培训法学硕士的新颖数据准备和机器学习技术。]]></description>
      <guid>https://arxiv.org/abs/2402.08078</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>利用综合数据进行精细的直接偏好优化，以实现法学硕士的行为调整</title>
      <link>https://arxiv.org/abs/2402.08005</link>
      <description><![CDATA[在本文中，我们介绍了 \emph{refined Direct Preference Optimization} (rDPO)，这是一种无需人工注释数据即可改进大型语言模型 (LLM) 行为对齐的方法。该方法涉及使用 LLM 教师的自我批评提示来创建合成数据，然后利用广义 DPO 损失函数将其提炼为 LLM 学生。损失函数包含一个额外的外部奖励模型，以提高合成数据的质量，使 rDPO 对合成数据集中的潜在噪声具有鲁棒性。 rDPO 被证明在一系列不同的行为协调任务中是有效的，例如提高安全性、针对角色扮演的稳健性以及减少阿谀奉承。代码将在 https://github.com/vicgalle/refined-dpo 发布。]]></description>
      <guid>https://arxiv.org/abs/2402.08005</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>增强阿姆哈拉语-LLaMA：集成特定任务和生成数据集</title>
      <link>https://arxiv.org/abs/2402.08015</link>
      <description><![CDATA[大型语言模型（LLM）因其在理解和生成人类语言方面的卓越性能而在自然语言处理（NLP）研究中受到广泛关注。然而，低资源语言由于资源的缺乏而被抛在后面。在这项工作中，我们专注于通过集成特定任务和生成数据集来增强 LLaMA-2-Amharic 模型，以提高阿姆哈拉语的语言模型性能。我们编译了阿姆哈拉语指令微调数据集和微调的 LLaMA-2-Amharic 模型。微调模型在不同的 NLP 任务中显示出有希望的结果。我们开源数据集创建管道、指令数据集、训练模型和评估输出，以促进对这些模型的特定语言研究。]]></description>
      <guid>https://arxiv.org/abs/2402.08015</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>QACP：一个用于帮助中国Python编程学习者的带注释的问答数据集</title>
      <link>https://arxiv.org/abs/2402.07913</link>
      <description><![CDATA[在在线学习平台中，特别是在快速增长的计算机编程课程中，解决成千上万学生的学习查询需要相当大的人力成本。为编程教育量身定制的智能助理大语言模型（LLM）的创建需要独特的数据支持。然而，在实际应用场景中，用于训练此类LLM的数据资源相对匮乏。因此，针对编程智能教育系统中数据稀缺的问题，本文提出了一种新的Python学习者中文问答数据集。为保证试题来源的真实性和可靠性，我们从学生实际问题中收集试题，并按照试题类型、学习者类型等多个维度进行分类。该标注原则旨在提高在线编程教育的有效性和质量，为开发编程教学辅助工具（TA）提供坚实的数据基础。此外，我们对精通中文内容处理和生成的各类法学硕士进行了综合评估，突显了一般法学硕士作为计算机编程课程智能助教的潜在局限性。]]></description>
      <guid>https://arxiv.org/abs/2402.07913</guid>
      <pubDate>Wed, 14 Feb 2024 06:17:48 GMT</pubDate>
    </item>
    </channel>
</rss>