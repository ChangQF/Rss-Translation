<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Fri, 05 Jan 2024 03:14:52 GMT</lastBuildDate>
    <item>
      <title>Shayona@SMM4H23：使用 BERT 和 LightGBM 模型进行 COVID-19 自我诊断分类。 （arXiv：2401.02158v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.02158</link>
      <description><![CDATA[本文描述了共享任务 1 和 4 的方法和结果
SMMH4-23 由 Shayona 团队设计。共享任务1是英语的二元分类
推文自我报告了 COVID-19 诊断，共享任务 4 是二进制的
英语 Reddit 帖子的分类自我报告社交焦虑症
诊断。我们团队在Task-1中取得了最高的f​​1分数0.94
参与者。我们结合使用了 Transformer 模型 (BERT)
使用 LightGBM 模型来完成这两项任务。
]]></description>
      <guid>http://arxiv.org/abs/2401.02158</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:52 GMT</pubDate>
    </item>
    <item>
      <title>DCR-一致性：用于一致性评估和改进大型语言模型的分治推理。 （arXiv：2401.02132v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.02132</link>
      <description><![CDATA[评估大语言生成的文本的质量和可变性
模型（法学硕士）提出了重大但尚未解决的研究挑战。
传统的评估方法，如 ROUGE 和 BERTScore，衡量的是
标记相似性，通常无法捕获整体语义等价性。这
导致与人类判断和直觉的相关性较低，即
在医疗保健和金融等高风险应用中尤其成问题
其中可靠性、安全性和稳健的决策至关重要。这
工作提出了 DCR，一个用于评估和改进的自动化框架
使用分而治之的推理方法来保证法学硕士生成的文本的一致性。
与在段落级别操作的现有基于 LLM 的评估器不同，我们的
方法采用分而治之评估器（DCE）来分解
两个生成的响应之间的逐段比较
单独的句子到段落的比较，每个比较都基于
预定义的标准。为了促进这种方法，我们引入了一个自动
公制转换器 (AMC)，将 DCE 的输出转换为
可解释的数字分数。除了一致性评价之外，我们还进一步
提出一个利用分析原因的原因辅助改进器（RAI）
并由 DCE 确定解释，以产生新的应对措施，旨在减少
这些不一致之处。通过全面、系统的实证分析，
我们证明我们的方法大大优于最先进的方法
评估时的余量（例如，SummEval 数据集上的 +19.3% 和 +24.3%）
跨多个基准的 LLM 生成在语义、事实、
和总结一致性任务。我们的方法还大大减少了
近 90% 的输出不一致，显示出有效的希望
幻觉缓解。
]]></description>
      <guid>http://arxiv.org/abs/2401.02132</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:51 GMT</pubDate>
    </item>
    <item>
      <title>探索 GPT-4V 在海洋分析中的边界：初步案例研究。 （arXiv：2401.02147v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.02147</link>
      <description><![CDATA[大型语言模型 (LLM) 已展现出强大的回答能力
作为通用助手处理各种查询。连续多模态
大语言模型（MLLM）使法学硕士能够感知视觉
信号。 GPT-4（生成式预训练变压器）的推出
引起了研究界的极大兴趣。 GPT-4V(iso)有
作为焦点，在学术界和工业界展现了巨大的影响力
新一代人工智能的发展点。尽管取得了重大成功
是通过 GPT-4V 实现的，在特定领域的分析中探索 MLLM（例如，
海洋分析）需要特定领域的知识和专业知识
获得的关注较少。在本研究中，我们进行了初步和
利用 GPT-4V 进行海洋分析的综合案例研究。这份报告
对现有 GPT-4V 进行系统评估，评估性能
GPT-4V在海洋研究方面的应用，也为未来设定了新标准
MLLM 的发展。 GPT-4V的实验结果表明
GPT-4V 生成的响应仍远不能满足
海洋专业领域的特定要求。所有图像和提示
本研究中使用的可在
https://github.com/hkust-vgd/Marine_GPT-4V_Eval
]]></description>
      <guid>http://arxiv.org/abs/2401.02147</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 从候选人中选择正确的 SQL 查询。 （arXiv：2401.02115v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.02115</link>
      <description><![CDATA[文本到 SQL 模型可以生成候选 SQL 查询列表，以及最佳的
查询通常位于候选列表中，但不在列表顶部。一个
有效的重新排序方法可以从候选列表中选择正确的 SQL 查询
并提高模型的性能。之前对代码生成的研究
自动生成测试用例并使用它们对候选代码重新排序。
然而，文本转 SQL 的自动测试用例生成尚未得到充分研究。
场地。我们提出了一种自动测试用例生成方法，首先生成
一个数据库，然后使用 LLM 来预测基本事实，即
在此数据库上的真实 SQL 查询的预期执行结果。到
降低LLM预测的难度，我们通过实验来寻找
为法学硕士生成简单数据库和设计易于理解的提示的方法。
基于我们的测试用例生成方法，我们提出了一种重新排序方法来选择
候选列表中正确的 SQL 查询。给定一个候选列表，我们的方法
可以生成测试用例并根据其通过情况重新排列候选列表
这些测试用例的编号及其生成概率。本实验
Spider 验证数据集上的结果表明，一些模型的性能
应用我们的重新排名后，最先进的模型可以获得 3.6% 的改进
方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.02115</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:50 GMT</pubDate>
    </item>
    <item>
      <title>用于语音的 PEFT：揭示最佳放置、合并策略和集成技术。 （arXiv：2401.02122v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.02122</link>
      <description><![CDATA[参数高效微调（PEFT）越来越被认为是一种
语音处理的有效方法然而，最优方法和
PEFT 方法的放置仍无定论。我们的研究进行了广泛
比较不同 PEFT 方法及其分层放置的实验
采用可微架构搜索（DARTS）。我们还探索使用
集成学习利用不同的 PEFT 策略。结果表明
DARTS 的性能并不优于基线方法，该方法涉及插入
将相同的 PEFT 方法应用到自监督学习 (SSL) 模型的所有层中。在
相比之下，集成学习方法，特别是采用大多数人的方法
投票，展示卓越的表现。我们的统计证据表明
不同的 PEFT 方法以不同的方式学习。这种变化或许可以解释
为什么通过集成来协同集成各种 PEFT 方法
学习可以更有效地利用他们独特的学习能力
与单独的逐层优化相比。
]]></description>
      <guid>http://arxiv.org/abs/2401.02122</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:50 GMT</pubDate>
    </item>
    <item>
      <title>ICE-GRT：通过基于生成强化的 Transformer 来增强指令上下文。 （arXiv：2401.02072v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.02072</link>
      <description><![CDATA[ChatGPT 和 LLaMA 等大型语言模型 (LLM) 的出现
在特定领域的任务中遇到限制，这些模型通常缺乏
专业领域的深度和准确性，总体表现出下降
微调时的能力，特别是小尺寸的分析能力
楷模。为了解决这些差距，我们引入了 ICE-GRT，利用强化
从基于近端策略优化的人类反馈 (RLHF) 中学习
（PPO），在域内场景中展现出卓越的能力，无需
损害一般任务表现。我们对 ICE-GRT 的探索亮点
它的理解和推理能力不仅可以生成可靠的答案，而且
并提供答案背后原因的详细分析。这
能力标志着超出监督范围的重大进步
微调模型。 ICE-GRT 的成功取决于几个关键因素
因素，包括适当的数据、奖励规模调整、KL 控制、优势
归一化等。ICE-GRT 模型在以下方面展现了最先进的性能
特定领域的任务和跨 12 个通用语言任务的同等任务
规模甚至更大规模的法学硕士，凸显了我们方法的有效性。
我们提供了 ICE-GRT 的全面分析，强调
它给法学硕士领域带来了重大进步。
]]></description>
      <guid>http://arxiv.org/abs/2401.02072</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:49 GMT</pubDate>
    </item>
    <item>
      <title>重新评估内存平衡管道并行性：BPipe。 （arXiv：2401.02088v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.02088</link>
      <description><![CDATA[管道并行是大规模训练中的一项重要技术
变压器型号。然而，它存在内存消耗不平衡的问题，
导致内存利用率不足。 BPipe 技术的提出是为了
解决了这个问题，并在 GPT-3 模型中被证明是有效的。尽管如此，
我们的实验并未给 LLaMA 训练带来类似的好处。
此外，BPipe 仅在以下情况下对 GPT-3 训练产生微不足道的好处：
应用闪光注意。我们分析造成分歧的根本原因
BPipe 在 GPT-3 和 LLaMA 上的性能。另外，给大家介绍一部小说
评估 BPipe 性能的方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.02088</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:49 GMT</pubDate>
    </item>
    <item>
      <title>Text2MDT：从医学文本中提取医疗决策树。 （arXiv：2401.02034v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.02034</link>
      <description><![CDATA[了解医疗决策过程，可以将其建模为医疗决策过程
决策树（MDT）对于构建临床决策支持系统至关重要。
然而，目前的MDT构建方法严重依赖耗时
和费力的手动注释。在这项工作中，我们提出了一项新任务，
Text2MDT，探索从医学文本中自动提取 MDT，例如
作为医学指南和教科书。我们标准化 MDT 的形式并且
在以下人员的参与下创建一个带注释的 Text-to-MDT 中文数据集
医学专家。我们研究了两种不同的 Text2MDT 任务方法：
(a) 一个仅依赖于GPT风格的大语言的端到端框架
模型（LLM）指令调整生成所有节点信息和树
结构。 (b) 将 Text2MDT 任务分解为的管道框架
三个子任务。我们的 Text2MDT 数据集上的实验表明：(a)
基于 LLM（7B 参数或更大）的端到端方法显示出有前途
结果，并成功优于管道方法。 （二）
思想链（COT）提示方法 \cite{Wei2022ChainOT} 可以提高
微调 LLM 在 Text2MDT 测试集上的性能。 (三)
基于编码器的预训练模型的轻量级流水线方法可以
其表现与模型复杂度小两个数量级的法学硕士相当。
我们的 Text2MDT 数据集开源于
\url{https://tianchi.aliyun.com/dataset/95414}，源码为
开源于 \url{https://github.com/michael-wzhu/text2dt}。
]]></description>
      <guid>http://arxiv.org/abs/2401.02034</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>了解法学硕士：从训练到推理的全面概述。 （arXiv：2401.02038v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.02038</link>
      <description><![CDATA[ChatGPT 的引入导致了显着增加
利用大型语言模型 (LLM) 来解决下游任务。
人们越来越关注内部经济高效的培训和部署
这个背景。法学硕士的低成本培训和部署代表了未来
发展趋势。本文回顾大语言模型的演变
与此相一致的训练技术和推理部署技术
新兴趋势。关于培训的讨论包括各个方面，包括
数据预处理、训练架构、预训练任务、并行
训练，以及模型微调相关的相关内容。论推论
另一方面，本文涵盖了模型压缩、并行计算等主题，
内存调度和结构优化。它还探讨了法学硕士的
并提供对其未来发展的见解。
]]></description>
      <guid>http://arxiv.org/abs/2401.02038</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>对对齐算法的机械理解：DPO 和毒性的案例研究。 （arXiv：2401.01967v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01967</link>
      <description><![CDATA[虽然对齐算法现在通常用于调整预训练语言
针对用户偏好的模型，我们缺乏对底层的解释
模型变得“一致”的机制，因此很难
解释越狱等现象。在这项工作中，我们研究了一种流行的算法，
直接偏好优化（DPO），以及它减少的机制
毒性。也就是说，我们首先研究毒性是如何在
预训练语言模型，GPT2-medium。然后我们仔细地应用 DPO
精心制作的成对数据集以减少毒性。我们检查生成的模型如何
避免有毒输出，并发现从预训练中学到的能力是
没有被删除，而是被绕过。我们利用这一见解来演示一个简单的
取消模型对齐的方法，将其恢复到有毒行为。
]]></description>
      <guid>http://arxiv.org/abs/2401.01967</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>从位置偏差的角度重新审视大语言模型时代的零样本抽象概括。 （arXiv：2401.01989v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01989</link>
      <description><![CDATA[我们描述并研究了大规模的零样本抽象概括
通过测量位置偏差的语言模型（LLM），我们建议将其作为
研究的更具限制性的先导偏差现象的一般表述
以前在文献中。位置偏差捕捉模型的趋势
不公平地优先考虑输入文本某些部分的信息
其他人，导致不良行为。经过四次多次实验
不同的现实世界数据集，我们研究多个 LLM 模型中的位置偏差，例如
如 GPT 3.5-Turbo、Llama-2 和 Dolly-v2，以及最先进的预训练
编码器-解码器抽象概括模型，例如 Pegasus 和 BART。我们的
研究结果引发了关于绩效和职位偏见的新颖见解和讨论
零样本总结任务的模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.01989</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>自我对比：通过不一致的解决视角更好地反思。 （arXiv：2401.02009v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.02009</link>
      <description><![CDATA[大语言模型（LLM）的反思能力已获得广泛关注
注意力。事后激励策略，例如反思和自我完善，
根据自我评估或外部反馈完善法学硕士的回应。然而，
最近的研究表明，在没有外部反馈的情况下，法学硕士的内在反映
不稳定。我们的调查显示，关键瓶颈在于质量
的自我评价反馈。我们发现法学硕士经常表现出过度自信或
自我评估时的高度随机性，提供顽固或不一致的反馈，
从而导致反射不良。为了解决这个问题，我们提倡自我对比：
根据要求自适应地探索不同的解决视角，
对比差异，并将这些差异总结成清单
可以用来重新检查并消除差异。我们的方法
赋予法学硕士不同的观点，以减轻顽固的偏见。而且，
它们的差异表明潜在的错误或固有的不确定性
LLM经常被忽视。反思这些可以促进更准确和
稳定的反射。进行了一系列推理和实验
不同法学硕士的翻译任务有助于强调有效性和
我们战略的普遍性。
]]></description>
      <guid>http://arxiv.org/abs/2401.02009</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>通用嵌入模型比专用嵌入模型更适合短上下文临床语义搜索。 （arXiv：2401.01943v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.01943</link>
      <description><![CDATA[越来越多地使用基于大型语言模型的工具和解决方案
（法学硕士）在医学领域的各种任务已成为一个突出的趋势。
因此，它们在这个高度关键和敏感领域的使用引起了人们的关注。
关于其稳健性的重要问题，特别是响应
输入的变化以及生成的输出的可靠性。这项研究
通过构建基于文本数据集来解决这些问题
ICD-10-CM代码说明，广泛应用于美国医院，包含许多
临床术语及其易于重复的改写。然后我们进行了基准测试
现有的嵌入模型，无论是通才还是专门用于临床
域，在语义搜索任务中，目标是正确匹配
将文本改写为原始描述。我们的结果表明，通才
模型的表现优于临床模型，表明现有的临床模型
专门的模型对输入的微小变化更敏感，这些变化会造成混乱
他们。专门模型的突出问题可能是由于以下事实：
他们没有接受过足够数据的培训，特别是数据集方面的培训
不够多样化，无法获得可靠的全球语言理解，
这对于准确处理医疗文件仍然是必要的。
]]></description>
      <guid>http://arxiv.org/abs/2401.01943</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>Instruct-Imagen：使用多模式指令生成图像。 （arXiv：2401.01952v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01952</link>
      <description><![CDATA[本文提出了 instruct-imagen，一种处理异构图像的模型
生成任务并对未见过的任务进行概括。我们介绍*多式联运
用于图像生成的指令*，阐明范围的任务表示
准确地表达生成意图。它使用自然语言来合并
不同的模式（例如文本、边缘、样式、主题等），使得
丰富的生成意图可以以统一的格式标准化。

然后，我们通过微调预先训练的文本到图像来构建指令图像
具有两阶段框架的扩散模型。首先，我们使用
检索增强训练，以增强模型的能力
外部多模式环境下的生成。随后，我们对
适应需要视觉语言的各种图像生成任务的模型
理解（例如，主题驱动的生成等），每个都与一个配对
封装任务本质的多模式指令。人类评价
各种图像生成数据集表明，instruct-imagen 匹配或
超越了领域内先前的特定任务模型，并展示了有前途的
泛化到看不见的和更复杂的任务。
]]></description>
      <guid>http://arxiv.org/abs/2401.01952</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>AstroLLaMA-Chat：使用对话式和多样化的数据集扩展 AstroLLaMA。 （arXiv：2401.01916v1 [astro-ph.IM]）</title>
      <link>http://arxiv.org/abs/2401.01916</link>
      <description><![CDATA[我们探索提高以天文学为中心的法学硕士表现的潜力
通过有针对性的、持续的预训练来回答问题。通过雇用
紧凑的 7B 参数 LLaMA-2 模型，专门专注于一组精选的
天文学语料库——包括摘要、介绍和结论——我们
在专业主题理解方面取得显着进步。虽然一般
像 GPT-4 这样的法学硕士在更广泛的问答场景中表现出色，因为
卓越的推理能力，我们的研究结果表明，持续
使用有限资源进行预训练仍然可以提高模型性能
专门主题。此外，我们还提出了 AstroLLaMA 的扩展：
在特定领域的对话数据集上微调 7B LLaMA 模型，
最终发布了支持聊天的 AstroLLaMA 供社区使用。
目前正在进行全面的量化基准测试，并将
在即将发表的全文中详细介绍。该模型 AstroLLaMA-Chat 现已推出
可在 https://huggingface.co/universeTBD 获取，提供第一个
专为天文学社区量身定制的开源对话式人工智能工具。
]]></description>
      <guid>http://arxiv.org/abs/2401.01916</guid>
      <pubDate>Fri, 05 Jan 2024 03:14:45 GMT</pubDate>
    </item>
    </channel>
</rss>