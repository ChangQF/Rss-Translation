<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 14 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>SpeechColab Leaderboard：自动语音识别评估的开源平台</title>
      <link>https://arxiv.org/abs/2403.08196</link>
      <description><![CDATA[arXiv:2403.08196v1 公告类型：新
摘要：随着过去十年深度学习浪潮的兴起，自动语音识别（ASR）引起了广泛关注，导致大量可公开访问的 ASR 系统出现，并积极融入我们的日常生活。尽管如此，由于各种关键的微妙之处，对这些 ASR 系统的公正和可复制的评估遇到了挑战。在本文中，我们介绍了 SpeechColab Leaderboard，这是一个专为 ASR 评估而设计的通用开源平台。通过这个平台：（i）我们报告了一个全面的基准，揭示了 ASR 系统当前最先进的全景，涵盖开源模型和工业商业服务。 (ii) 我们量化评分流程中的不同细微差别如何影响最终基准结果。其中包括与大写、标点符号、感叹词、缩写、同义词使用、复合词等相关的细微差别。这些问题在向端到端未来过渡的背景下变得更加突出。 (iii) 受到柯尔莫哥洛夫复杂度和归一化信息距离（NID）的启发，我们提出了对传统令牌错误率（TER）评估指标的实际修改。这种适应称为修改的 TER (mTER)，实现了参考和假设的适当标准化和对称处理。通过利用该平台作为大规模测试场，本研究证明了 mTER 与 TER 相比的稳健性和向后兼容性。 SpeechColab 排行榜可通过 https://github.com/SpeechColab/Leaderboard 访问]]></description>
      <guid>https://arxiv.org/abs/2403.08196</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>用于低资源自动注释的嵌入式翻译</title>
      <link>https://arxiv.org/abs/2403.08189</link>
      <description><![CDATA[arXiv:2403.08189v1 公告类型：新
摘要：我们研究了资源匮乏环境中的自动行间注释。我们使用从行间注释文本中提取的嵌入翻译信息来增强硬注意力神经模型。使用大型语言模型（特别是 BERT 和 T5）对这些翻译进行编码后，我们引入了字符级解码器来生成注释输出。在这些增强的帮助下，我们的模型在 SIGMORPHON 2023 线间光泽共享任务的数据集上表现出比之前最先进技术水平平均提高了 3.97% 点。在模拟的超低资源环境中，仅接受 100 个句子的训练，我们的系统比普通的硬注意力基线平均提高了 9.78% 点。这些结果凸显了翻译信息在提高系统性能方面的关键作用，特别是在处理和解释适度数据源方面。我们的发现为语言的记录和保存提供了一条有前途的途径，我们对共享任务数据集的实验表明比现有技术取得了重大进步。]]></description>
      <guid>https://arxiv.org/abs/2403.08189</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>MoleculeQA：评估分子理解事实准确性的数据集</title>
      <link>https://arxiv.org/abs/2403.08192</link>
      <description><![CDATA[arXiv:2403.08192v1 公告类型：新
摘要：大型语言模型在分子研究中发挥着越来越重要的作用，但现有模型经常产生错误信息，对准确的分子理解提出了挑战。生成内容的传统评估指标无法评估模型在分子理解方面的准确性。为了纠正事实评估的缺失，我们提出了 MoleculeQA，这是一个新颖的问答 (QA) 数据集，拥有超过 23K 个分子的 62K 个 QA 对。每个问答对由一个手动问题、一个肯定选项和三个否定选项组成，与权威分子语料库中的分子描述具有一致的语义。 MoleculeQA 不仅是分子事实偏差评估的第一个基准，也是分子研究最大的 QA 数据集。对现有分子法学硕士的 MoleculeQA 进行的全面评估暴露了他们在特定领域的缺陷，并指出了分子理解的几个特别关键的因素。]]></description>
      <guid>https://arxiv.org/abs/2403.08192</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>BAGEL：通过语言引导探索引导智能体</title>
      <link>https://arxiv.org/abs/2403.08140</link>
      <description><![CDATA[arXiv:2403.08140v1 公告类型：新
摘要：通过在数字环境（例如网络浏览器和 REST API）中执行操作来遵循自然语言指令对于语言模型（LM）代理来说是一项具有挑战性的任务。不幸的是，如果没有人工演示，LM 代理通常无法推广到新环境。这项工作提出了 BAGEL，一种无需人工监督即可引导 LM 代理的方法。 BAGEL 通过两个噪声 LM 组件之间的往返，将随机探索的轨迹或合成指令的种子集转换为演示：LM 标记器将轨迹转换为合成指令，以及零样本 LM 代理将合成指令映射进入精细化轨迹。通过迭代执行这些往返，BAGEL 快速将轨迹的初始分布转换为自然语言可以很好描述的分布。我们使用 BAGEL 演示，通过对检索到的演示进行上下文学习，在测试时调整零样本 LM 代理，并发现 ToolQA 和 MiniWob++ 的绝对改进超过 2-13%，执行失败最多减少 13 倍。]]></description>
      <guid>https://arxiv.org/abs/2403.08140</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>重新思考事实验证的损失函数</title>
      <link>https://arxiv.org/abs/2403.08174</link>
      <description><![CDATA[arXiv:2403.08174v1 公告类型：新
摘要：我们在 FEVER 共享任务中探索用于事实验证的损失函数。虽然交叉熵损失是训练判决预测器的标准目标，但它无法捕获 FEVER 判决类别之间的异质性。在本文中，我们制定了两个针对 FEVER 的特定任务目标。实验结果证实，所提出的目标函数优于标准交叉熵。当这些目标与简单的类别加权相结合时，性能进一步提高，有效克服了训练数据的不平衡。源代码可在 https://github.com/yuta-mukobara/RLF-KGAT 获取]]></description>
      <guid>https://arxiv.org/abs/2403.08174</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>自动语音识别 (ASR) 用于诊断韩国儿童语音障碍的发音</title>
      <link>https://arxiv.org/abs/2403.08187</link>
      <description><![CDATA[arXiv:2403.08187v1 公告类型：新
摘要：本研究提出了一种自动语音识别（ASR）模型，旨在诊断患有言语声音障碍（SSD）的儿童的发音问题，以取代临床过程中的手动转录。由于针对通用目的训练的 ASR 模型主要将输入语音预测为真实单词，因此采用众所周知的高性能 ASR 模型来评估 SSD 儿童的发音是不切实际的。我们对 wav2vec 2.0 XLS-R 模型进行了微调，将语音识别为发音而不是现有单词。该模型使用来自 137 名言语能力不足的儿童的语音数据集进行了微调，这些儿童发出了 73 个韩语单词，这些单词被选用于实际临床诊断。该模型对单词发音的预测与人类注释的匹配率约为 90%。虽然该模型在识别不清楚的发音方面仍需要改进，但本研究表明 ASR 模型可以简化临床领域复杂的发音错误诊断程序。]]></description>
      <guid>https://arxiv.org/abs/2403.08187</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>大城市偏见：评估大都市规模对语言模型计算就业市场能力的影响</title>
      <link>https://arxiv.org/abs/2403.08046</link>
      <description><![CDATA[arXiv:2403.08046v1 公告类型：新
摘要：大语言模型 (LLM) 已成为一种对候选人和雇主而言有用的工作匹配技术。工作匹配通常基于特定的地理位置，例如城市或地区。然而，法学硕士存在已知的偏见，这些偏见通常源自他们的训练数据。在这项工作中，我们的目标是量化大型语言模型中编码的大都市规模偏差，评估美国 384 个大都市区的零样本工资、雇主存在和通勤时间预测。在所有基准中，我们观察到大都市规模与 LLMS 表现之间存在负相关性，这表明较小的地区确实代表性不足。更具体地说，最小的 10 个大都市地区的基准表现比最大的 10 个大都市地区差 300% 以上。]]></description>
      <guid>https://arxiv.org/abs/2403.08046</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>生成澄清合同的澄清问题</title>
      <link>https://arxiv.org/abs/2403.08053</link>
      <description><![CDATA[arXiv:2403.08053v1 公告类型：新
摘要：企业经常签订商业合同，这些合同可以作为项目特定要求的重要来源。合同条款是强制性的，由合同衍生的需求可以详细说明非法律利益相关者（包括需求分析师、工程师和交付人员）需要进行的下游实施活动。然而，由于法律术语的广泛使用和合同语言固有的复杂性，理解合同对于这些利益相关者来说是认知上的要求很高并且容易出错。此外，合同通常包含措辞含糊的条款，以确保全面覆盖。相比之下，非法律利益相关者需要详细且明确地理解合同条款，以制定可操作的要求。在这项工作中，我们引入了一项新颖的法律 NLP 任务，其中涉及生成合同的澄清问题。这些问题旨在识别文件层面上的合同歧义，从而帮助非法律利益相关者获得提出要求所需的详细信息。这项任务面临三个核心问题的挑战：（1）数据可用性，（2）合同的长度和非结构化性质，以及（3）法律文本的复杂性。为了解决这些问题，我们提出了 ConRAP，这是一种检索增强的提示框架，用于生成澄清问题以消除合同文本的歧义。对来自公开可用的 CUAD 数据集的合同进行的实验表明，ConRAP 与 ChatGPT 可以检测歧义，F2 得分为 0.87。人类评估者认为 70% 生成的澄清问题有用。]]></description>
      <guid>https://arxiv.org/abs/2403.08053</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>上下文清晰度：使用上下文反转数据通过 Transformer 模型生成句子</title>
      <link>https://arxiv.org/abs/2403.08103</link>
      <description><![CDATA[arXiv:2403.08103v1 公告类型：新
摘要：在信息丰富的时代，为用户提供上下文相关且简洁的信息的能力至关重要。上下文中的关键字 (KIC) 生成是一项在搜索引擎、个人助理和内容摘要等生成应用中发挥着至关重要作用的任务。在本文中，我们提出了一种新方法，利用从 Context-Reverso API 获得的数据，使用 T5 转换器模型为给定关键字生成明确且简短的句子上下文。该代码位于 https://github.com/Rusamus/word2context/tree/main 。]]></description>
      <guid>https://arxiv.org/abs/2403.08103</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>利用人工智能打击网络仇恨：探索大型语言模型在仇恨言论检测中的挑战和机遇</title>
      <link>https://arxiv.org/abs/2403.08035</link>
      <description><![CDATA[arXiv:2403.08035v1 公告类型：新
摘要：大型语言模型（LLM）在语言生成之外的许多不同应用中表现出色，例如翻译、摘要和情感分析。一种有趣的应用是文本分类。这在识别仇恨或有毒言论领域变得相关——这个领域充满了挑战和道德困境。在我们的研究中，我们有两个目标：首先，提供围绕法学硕士作为分类器的文献综述，强调它们在检测和分类仇恨或有毒内容方面的作用。随后，我们探讨了几位法学硕士在仇恨言论分类方面的功效：确定哪些法学硕士在这项任务中表现出色，以及他们的基本属性和培训。深入了解导致法学硕士熟练（或缺乏）识别仇恨内容的因素。通过将全面的文献综述与实证分析相结合，我们的论文致力于阐明法学硕士在仇恨言论检测这一关键领域的能力和限制。]]></description>
      <guid>https://arxiv.org/abs/2403.08035</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>带有策略优化的作者风格转移</title>
      <link>https://arxiv.org/abs/2403.08043</link>
      <description><![CDATA[arXiv:2403.08043v1 公告类型：新
摘要：作者风格迁移旨在将给定文本重写为指定的目标，同时保留源中的原始含义。现有方法依赖于大量目标风格样本的可用性来进行模型训练。然而，这些忽略了可用目标样式示例数量有限的情况。参数高效迁移学习技术和策略优化（PO）方法的发展表明，轻量级 PO 是低资源风格迁移的一种可行方法。在这项工作中，我们提出了一种简单的两步调整和优化技术，用于低资源文本样式传输。我们将我们的技术应用于作者身份转移以及更大数据的本机语言风格任务，并且在这两种情况下发现它都优于最先进的基线模型。]]></description>
      <guid>https://arxiv.org/abs/2403.08043</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>Pix2Pix-OnTheFly：利用法学硕士进行指令引导图像编辑</title>
      <link>https://arxiv.org/abs/2403.08004</link>
      <description><![CDATA[arXiv:2403.08004v1 公告类型：新
摘要：鉴于最近利用两个研究领域的综合优势取得的令人印象深刻的进展，语言处理和图像处理的结合不断吸引着越来越多的兴趣。在这些进步中，仅基于自然语言指令编辑图像的任务是最具挑战性的工作。虽然这项任务的最新方法以某种方式诉诸于某种形式的初步准备、训练或微调，但本文探索了一种新颖的方法：我们提出了一种无需准备的方法，允许在飞。这种方法按照三个步骤进行组织，这些步骤经过适当的协调，首先使用图像字幕和 DDIM 反转，然后获得编辑方向嵌入，最后进行适当的图像编辑。虽然无需进行初步准备，但在 MAGICBRUSH 数据集上进行评估时，我们的方法证明是有效且有竞争力的，优于该任务的最新最先进模型。]]></description>
      <guid>https://arxiv.org/abs/2403.08004</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>Debatrix：基于LLM的迭代时间分析的多维度辩论法官</title>
      <link>https://arxiv.org/abs/2403.08010</link>
      <description><![CDATA[arXiv:2403.08010v1 公告类型：新
摘要：我们如何构建一个自动辩论法官来评估广泛、充满活力、多回合的辩论？这项任务具有挑战性，因为判断辩论涉及冗长的文本、错综复杂的论点关系和多维度的评估。同时，目前的研究主要集中在简短的对话上，很少涉及对整个辩论的评估。在本文中，通过利用大型语言模型（LLM），我们提出了 Debatrix，它使得多轮辩论的分析和评估更符合大多数人的偏好。具体来说，Debatrix 具有纵向、迭代的时序分析和横向、多维度的评估协作。为了与现实世界的辩论场景保持一致，我们引入了 PanelBench 基准，将我们的系统性能与实际辩论结果进行比较。研究结果表明，与直接使用法学硕士进行辩论评估相比，有显着的增强。源代码和基准数据可在线获取：https://github.com/ljcleo/Debatrix。]]></description>
      <guid>https://arxiv.org/abs/2403.08010</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>使用口语集成预测的古吉拉特语-英语语码转换语音识别</title>
      <link>https://arxiv.org/abs/2403.08011</link>
      <description><![CDATA[arXiv:2403.08011v1 公告类型：新
摘要： 语码转换语音识别中的一项重要且困难的任务是识别语言，因为两种语言中的许多单词可能听起来相似，尤其是在某些口音上。我们专注于通过以每层监督的方式根据输出中的单词和字符的语言 ID 调节转换器层来提高端到端自动语音识别模型的性能。为此，我们提出了两种在多头注意机制中引入语言特定参数和可解释性的方法，并实现有助于保持输入对齐连续性的时间损失。尽管无法显着降低 WER，但我们的方法在仅根据口语数据预测正确语言方面表现出了希望。我们通过在序列中删除 LID 来在语言预测中引入正则化，这有助于对齐长重复输出序列。]]></description>
      <guid>https://arxiv.org/abs/2403.08011</guid>
      <pubDate>Thu, 14 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>训练小型多模态模型以弥合生物医学能力差距：放射成像案例研究</title>
      <link>https://arxiv.org/abs/2403.08002</link>
      <description><![CDATA[arXiv:2403.08002v1 公告类型：新
摘要：大型基础模型的标度规律和非凡的性能激发了此类大型模型在生物医学中的开发和利用。然而，尽管一些生物医学基准的早期结果令人鼓舞，但在这些模型用于实际应用之前，仍然需要解决重大挑战。 GPT-4V 等前沿模型在生物医学应用的多模式功能方面仍然存在重大能力差距。此外，访问、成本、延迟和合规性等实用问题使得临床医生很难直接在私人患者数据上使用私人托管的最先进的大型模型。在本文中，我们探索训练开源小型多模式模型（SMM），以弥补未满足的临床需求的生物医学能力差距。为了最大限度地提高数据效率，我们采用模块化方法，结合最先进的图像和文本模态预训练模型，并专注于训练轻量级适配器，将每种模态植入文本嵌入空间。我们对这种放射成像方法进行了全面的研究。为了进行训练，我们组装了一个包含超过 100 万个图像文本对的大型数据集。为了进行评估，我们提出了一种使用 GPT-4 的临床驱动的新方法，并证明了其与专家评估的同等性。我们还利用注意力定性地研究接地。为了获得最佳实践，我们对数据工程和多模式训练中的各种选择进行了系统的消融研究。由此产生的 LLaVA-Rad (7B) 模型在报告生成和跨模式检索等放射学任务上获得了最先进的结果，甚至优于 GPT-4V 和 Med-PaLM M (84B) 等更大的模型。 LLaVA-Rad 速度很快，可以在私人环境中在单个 V100 GPU 上运行，为现实临床应用提供了一个有前途的最先进的工具。]]></description>
      <guid>https://arxiv.org/abs/2403.08002</guid>
      <pubDate>Thu, 14 Mar 2024 06:16:59 GMT</pubDate>
    </item>
    </channel>
</rss>