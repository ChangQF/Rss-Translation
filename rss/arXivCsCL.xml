<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>https://arxiv.org/rss/</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 01 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>传播和陷阱：通过反事实任务对知识编辑进行基于推理的评估</title>
      <link>https://arxiv.org/abs/2401.17585</link>
      <description><![CDATA[当前的知识编辑方法很难有效地将更新传播到相互关联的事实。在这项工作中，我们深入研究了阻碍这些模型中更新的知识适当传播的障碍，以进行准确的推理。为了支持我们的分析，我们引入了一种新颖的基于推理的基准——ReCoE（基于推理的反事实编辑数据集）——它涵盖了现实世界中的六种常见推理方案。我们对现有的知识编辑技术进行了彻底的分析，包括输入增强、微调以及定位和编辑。我们发现所有模型编辑方法在此数据集上的性能都明显较低，尤其是在某些推理方案中。我们对编辑模型的思想链生成的分析进一步从推理的角度揭示了现有知识编辑方法不足的关键原因，涉及事实编辑、事实回忆能力和生成连贯性等方面。我们将公开我们的基准。]]></description>
      <guid>https://arxiv.org/abs/2401.17585</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:39 GMT</pubDate>
    </item>
    <item>
      <title>本地和全球对话环境</title>
      <link>https://arxiv.org/abs/2401.17588</link>
      <description><![CDATA[对话中的上下文是对多轮对话至关重要的对话历史。从对话历史中的相关上下文中学习基础对话是一个具有挑战性的问题。局部上下文是最邻近的，对后续响应更敏感，而全局上下文与整个对话的相关性远远超出邻近的话语。目前，用于对话的预训练 Transformer 模型面临捕获本地和全局上下文之间的相关性和连接的挑战。我们引入了一种本地和全局对话模型（LGCM），用于开放域中的通用对话。它是一种局部-全局分层变压器模型，擅长准确识别和同化生成响应所需的相关上下文。它使用本地编码器来掌握个体话语级别的本地上下文，并使用全局编码器来理解对话级别的更广泛的上下文。这些本地和全局上下文编码的无缝融合确保了对对话的全面理解。对流行数据集的实验表明，LGCM 在自动指标的性能上明显优于现有的对话模型。]]></description>
      <guid>https://arxiv.org/abs/2401.17588</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:39 GMT</pubDate>
    </item>
    <item>
      <title>SPECTRUM：针对长对话总结的演讲者增强预训练</title>
      <link>https://arxiv.org/abs/2401.17597</link>
      <description><![CDATA[多轮对话的特点是长度较长且存在轮流对话。传统的语言模型经常将这些对话视为常规文本，从而忽略了它们的独特特征。在本文中，我们提出了一种用于长对话摘要的说话人增强预训练方法，该方法利用了多轮对话的固有结构。为了支持我们的研究，我们整理了一个多样化的数据集，其中包括现实世界场景的转录本、电影或电视节目的转录本以及大型语言模型生成的对话。然后，我们进行预训练，其中包括检测说话者变化和屏蔽话语生成。微调模型的实验结果表明，我们的模型在具有长上下文的下游基准上实现了最先进的性能，超越了基线模型并突出了我们方法的有效性。我们的研究结果强调了整理预训练数据集的重要性，这些数据集表现出长度分布的多样性和变化，以确保与下游数据集的有效对齐。]]></description>
      <guid>https://arxiv.org/abs/2401.17597</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:39 GMT</pubDate>
    </item>
    <item>
      <title>擅长字幕，不擅长计数：在地球观测数据上对 GPT-4V 进行基准测试</title>
      <link>https://arxiv.org/abs/2401.17600</link>
      <description><![CDATA[大型视觉语言模型 (VLM) 在涉及自然语言指令视觉输入的复杂任务中表现出了令人印象深刻的性能。然而，目前尚不清楚自然图像在多大程度上能够转移到地球观测（EO）数据，这些数据主要是卫星和航空图像，在 VLM 训练数据中不太常见。在这项工作中，我们提出了一个全面的基准，通过评估 VLM 在场景理解、定位和计数以及变化检测任务方面的能力，来衡量 VLM 成为 EO 数据有用工具的进展。在现实世界应用的推动下，我们的基准包括城市监控、救灾、土地利用和保护等场景。我们发现，尽管像 GPT-4V 这样最先进的 VLM 拥有广泛的世界知识，可以在位置理解和图像字幕等开放式任务上表现出色，但它们糟糕的空间推理能力限制了对象定位和计数任务的实用性。我们的基准测试将在 https://vleo.danielz.ch/ 和 Hugging Face 上公开发布：https://huggingface.co/collections/mit-ei/vleo-benchmark-datasets-65b789b0466555489cce0d70，以便于模型评估。]]></description>
      <guid>https://arxiv.org/abs/2401.17600</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:39 GMT</pubDate>
    </item>
    <item>
      <title>FEUDA：基于无监督域适应的极其简单的提示</title>
      <link>https://arxiv.org/abs/2401.17514</link>
      <description><![CDATA[无监督域适应（UDA）方法的主线使用来自源域和目标域的未标记数据来学习域不变表示以进行适应。然而，这些方法存在一定的局限性，鼓励通过持续的预训练来使用自我监督学习。在基于提示的分类框架中，持续预训练或学习域不变表示的必要性仍不清楚，其中输入示例由模板修改，然后输入语言模型（LM）以生成标签字符串。为了在基于提示的设置中检查这种新的 UDA 范式，我们提出了一种极其简单的 UDA 方法 (FEUDA)，该方法使用两种不同的指令调整任务在未标记和标记的示例上训练自回归 LM。具体来说，第一个任务通过掩码语言模型 (MLM) 在来自两个领域的未标记文本上训练 LM，另一个任务对源标记数据使用监督指令调整来进行分类。我们对 24 个真实世界的域对进行了广泛的实验，以证明我们的方法相对于强大的域不变学习方法的有效性。我们的分析揭示了为什么掩码语言建模可以提高基于提示的 UDA 中的目标域分类性能。我们发现 MLM 帮助模型学习某个领域的语义和背景知识，这都有利于下游分类。]]></description>
      <guid>https://arxiv.org/abs/2401.17514</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:38 GMT</pubDate>
    </item>
    <item>
      <title>PipeNet：通过知识图进行语义剪枝的问答</title>
      <link>https://arxiv.org/abs/2401.17536</link>
      <description><![CDATA[众所周知，结合显式知识图（KG）可以有利于问答。现有方法通常遵循基础推理管道，其中实体节点首先针对查询（问题和候选答案）进行基础，然后推理模块对匹配的多跳子图进行推理以进行答案预测。尽管该管道在很大程度上缓解了从巨型知识图谱中提取基本信息的问题，但在扩大子图接地的跳跃时，效率仍然是一个公开的挑战。在本文中，我们的目标是找到子图中语义相关的实体节点，以提高利用知识图谱进行图推理的效率。我们提出了一种基础剪枝推理管道来剪枝噪声节点，显着降低计算成本和内存使用量，同时还获得良好的子图表示。具体来说，剪枝模块首先根据匹配跨度之间的依赖距离对概念节点进行评分，然后根据得分排名对节点进行剪枝。为了便于评估修剪后的子图，我们还提出了一个基于图注意网络（GAT）的模块来对子图数据进行推理。 CommonsenseQA 和 OpenBookQA 上的实验结果证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2401.17536</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:38 GMT</pubDate>
    </item>
    <item>
      <title>清除鬣狗：将 Transformer 提炼为长卷积模型</title>
      <link>https://arxiv.org/abs/2401.17574</link>
      <description><![CDATA[以 GPT-4 等架构为代表的大型语言模型 (LLM) 的快速发展重塑了自然语言处理的格局。本文介绍了一种解决与 LLM 预训练相关的效率问题的开创性方法，提出使用知识蒸馏进行跨架构迁移。利用高效鬣狗机制的见解，我们的方法取代了鬣狗变压器模型中的注意力头，为传统预训练提供了一种经济高效的替代方案，同时应对二次注意力机制固有的处理长上下文信息的挑战。与传统的以压缩为重点的方法不同，我们的技术不仅提高了推理速度，而且在准确性和效率方面也超越了预训练。在法学硕士不断发展的时代，我们的工作有助于追求可持续的人工智能解决方案，在计算能力和环境影响之间取得平衡。]]></description>
      <guid>https://arxiv.org/abs/2401.17574</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:38 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM Agent 生成合成对话数据集</title>
      <link>https://arxiv.org/abs/2401.17461</link>
      <description><![CDATA[线性规划（LP）问题在现实生活应用中普遍存在。然而，尽管它们看起来很简单，但未经训练的用户可能会发现很难确定其特定问题的线性模型。我们设想创建一个面向目标的对话代理，它将与用户进行对话以获取所需的所有信息，以便后续代理可以生成线性模型。在本文中，我们提出了一种生成示例对话的方法，可用于开发和训练此类对话代理。使用即时工程，我们开发了两个相互“交谈”的代理，一个充当会话代理，另一个充当用户。使用 NL4Opt 中仅对用户可用的一组线性问题文本描述，代理和用户进行对话，直到代理从原始问题描述中检索到所有关键信息。我们还通过评估对话生成的摘要与原始问题描述的匹配程度，提出对对话的外在评估。我们进行人工和自动评估，包括使用 GPT-4 模仿人工评估指标的评估方法。评估结果显示对话的整体质量良好，但仍需要研究来提高 GPT-4 评估指标的质量。由此产生的对话，包括子集的人工注释，可供研究界使用。用于生成对话的对话代理可以用作基线。]]></description>
      <guid>https://arxiv.org/abs/2401.17461</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:37 GMT</pubDate>
    </item>
    <item>
      <title>通过抽象链推理有效使用工具</title>
      <link>https://arxiv.org/abs/2401.17464</link>
      <description><![CDATA[为了实现符合人类期望的忠实推理，大型语言模型 (LLM) 需要将其推理建立在现实世界知识（例如网络事实、数学和物理规则）的基础上。工具可以帮助法学硕士访问这些外部知识，但微调法学硕士代理（例如 Toolformer）以在多步骤推理问题中调用工具仍然存在挑战，其中互连的工具调用需要全面且高效的工具使用规划。
  在这项工作中，我们提出了一种让法学硕士更好地利用多步推理工具的新方法。我们的方法抽象链（CoA）训练法学硕士首先用抽象占位符解码推理链，然后调用领域工具通过填充特定知识来具体化每个推理链。这种抽象链的规划使法学硕士能够学习更通用的推理策略，这些策略对于与不同推理问题相关的领域知识（例如数学结果）的变化具有鲁棒性。它还允许LLM并行执行外部工具的解码和调用，从而避免因等待工具响应而导致的推理延迟。在数学推理和 Wiki QA 领域，我们表明我们的方法在分布内和分布外测试集上始终优于先前的思想链和工具增强基线，平均绝对 QA 准确度提高约 6% 。使用我们的方法训练的 LLM 代理还显示出更有效的工具使用，推理速度平均比基线工具增强的 LLM 快约 1.4 倍。]]></description>
      <guid>https://arxiv.org/abs/2401.17464</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:37 GMT</pubDate>
    </item>
    <item>
      <title>检测社交媒体上的精神障碍：ChatGPT 增强的可解释方法</title>
      <link>https://arxiv.org/abs/2401.17477</link>
      <description><![CDATA[在数字时代，社交媒体上表达的抑郁症状的普遍存在引起了严重关注，需要先进的方法来及时发现。本文通过提出一种新颖的方法来解决可解释的抑郁症检测的挑战，该方法有效地将大型语言模型 (LLM) 与可解释人工智能 (XAI) 和 ChatGPT 等会话代理结合起来。在我们的方法中，解释是通过将 BERTweet（BERT 的 Twitter 特定变体）集成到一种新颖的自解释模型（即 BERT-XDD）中来实现的，该模型能够通过屏蔽注意力提供分类和解释。使用 ChatGPT 将技术解释转化为人类可读的评论进一步增强了可解释性。通过引入有效的模块化方法来检测可解释的抑郁症，我们的方法可以有助于开发对社会负责的数字平台，在合格的医疗保健专业人员的指导下促进早期干预和支持心理健康挑战。]]></description>
      <guid>https://arxiv.org/abs/2401.17477</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:37 GMT</pubDate>
    </item>
    <item>
      <title>通过制图接种提高 QA 模型性能</title>
      <link>https://arxiv.org/abs/2401.17498</link>
      <description><![CDATA[QA 模型面临复杂且开放式的上下文推理问题，但通常可以通过利用训练数据中特定于数据集的模式来学习性能良好的解决方案启发法。这些模式或“数据集工件”降低了模型泛化到现实世界 QA 问题的能力。利用针对 QA 训练的 ElectraSmallDiscriminator 模型，我们使用对抗性挑战集来分析数据集伪影的影响和发生率，该挑战集旨在混淆依赖伪影进行预测的模型。扩展了减轻伪影影响方法的现有工作，我们提出了制图接种，这是一种新方法，可以在挑战数据的优化子集上微调模型，以减少模型对数据集伪影的依赖。我们表明，通过对挑战集中的模糊对抗示例选择性地微调模型，可以在完整的挑战数据集上实现显着的性能改进，同时将模型对其他具有挑战性的环境和 QA 数据集的泛化性损失降至最低。]]></description>
      <guid>https://arxiv.org/abs/2401.17498</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:37 GMT</pubDate>
    </item>
    <item>
      <title>阿拉伯语推文行为：用于对 Twitter 上的阿拉伯语语音行为进行分类的加权集成预训练 Transformer 模型</title>
      <link>https://arxiv.org/abs/2401.17373</link>
      <description><![CDATA[言语行为是说话者在对话中执行话语时的行为，例如询问、推荐、问候或感谢某人，表达想法或提出建议。理解言语行为有助于解释说话者或作者话语背后的意图和行为。本文提出了一种基于 Transformer 深度学习神经网络的 Twitter 方言阿拉伯语言语行为分类方法。 Twitter 和社交媒体越来越融入日常生活。因此，它们已发展成为代表用户观点和态度的重要信息来源。我们提出了一种基于 BERT 的加权集成学习方法，以整合各种 BERT 模型在阿拉伯语方言语音行为分类中的优势。我们将所提出的模型与阿拉伯语 BERT 模型和基于序列的模型的几种变体进行了比较。我们通过基于六个言语行为类别注释现有大型阿拉伯语情感分析数据集 (ASAD) 的子集，开发了阿拉伯语方言推文行为数据集。我们还在之前开发的阿拉伯推文法案数据集 (ArSAS) 上评估了模型。为了克服言语行为问题中常见的类别不平衡问题，实现了基于变压器的数据增强模型来生成相等比例的言语行为类别。结果表明，最好的 BERT 模型是 araBERTv2-Twitter 模型，其宏观平均 F1 分数、准确度分别为 0.73 和 0.84。使用基于 BERT 的集成方法提高了性能，在我们的数据集上平均 F1 分数和准确度分别为 0.74 和 0.85。]]></description>
      <guid>https://arxiv.org/abs/2401.17373</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:36 GMT</pubDate>
    </item>
    <item>
      <title>Infini-gram：将无界 n-gram 语言模型扩展到万亿代币</title>
      <link>https://arxiv.org/abs/2401.17377</link>
      <description><![CDATA[n-gram 语言模型在这个神经大语言模型 (LLM) 时代仍然相关吗？我们的答案是肯定的，我们在文本分析和改进神经法学硕士方面展示了它们的价值。然而，这需要在两个方面对 n-gram 模型进行现代化改造。首先，我们以与神经 LLM 相同的数据规模（1.4 万亿个令牌）训练它们。这是有史以来最大的 n-gram 模型。其次，现有的n-gram模型使用较小的n，这阻碍了它们的性能；相反，我们通过引入带有退避功能的新 $\infty$-gram LM 来允许 n 任意大。我们开发了一个名为 infini-gram 的引擎（由后缀数组提供支持），而不是预先计算 n-gram 计数表（这会非常昂贵），它可以计算 $\infty$-gram （以及 n-gram）具有任意 n) 概率和毫秒级延迟。 $\infty$-gram 框架和 infini-gram 引擎使我们能够对人类编写的和机器生成的文本进行许多新颖且有趣的分析：我们发现 $\infty$-gram LM 对于下一个-令牌预测（47%），并且可以补充神经法学硕士，大大减少其语言建模的复杂性。在分析机器生成的文本时，我们还观察到机器-$\infty$-gram 在后缀长度方面的一致性水平存在不规则性，这表明神经 LLM 预训练和 Transformer 的位置嵌入存在缺陷。我们开源无限语法引擎，希望能够就如何最好地利用从大型文本语料库中检索到的逐字信息进行更多研究。]]></description>
      <guid>https://arxiv.org/abs/2401.17377</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:36 GMT</pubDate>
    </item>
    <item>
      <title>通过对比情境学习定制语言模型响应</title>
      <link>https://arxiv.org/abs/2401.17390</link>
      <description><![CDATA[大型语言模型 (LLM) 对于机器学习应用程序变得越来越重要。然而，让法学硕士与我们的意图保持一致可能具有挑战性，特别是当我们想要生成比其他内容更好的内容时，或者当我们希望法学硕士以某种难以描述的风格或语气做出回应时。为了应对这一挑战，我们提出了一种使用对比示例来更好地描述我们的意图的方法。这包括提供说明真实意图的正面例子，以及显示我们希望法学硕士避免哪些特征的负面例子。负面例子可以从人类编写的标记数据中检索，也可以由法学硕士本身生成。在生成答案之前，我们要求模型分析示例，以教会自己应该避免什么。此推理步骤为模型提供了用户需求的适当表达，并指导其生成更好的答案。我们在合成数据集和真实数据集（包括 StackExchange 和 Reddit）上测试了我们的方法，发现与标准的几次提示相比，它显着提高了性能]]></description>
      <guid>https://arxiv.org/abs/2401.17390</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:36 GMT</pubDate>
    </item>
    <item>
      <title>针对土耳其语言理解任务微调基于 Transformer 的编码器</title>
      <link>https://arxiv.org/abs/2401.17396</link>
      <description><![CDATA[过去几年，基于深度学习和最近基于 Transformer 的语言模型一直主导着自然语言处理的研究。由于其准确和快速的微调特性，它们的性能优于传统的基于机器学习的方法，并在许多具有挑战性的自然语言理解（NLU）问题上取得了最先进的结果。最近的研究表明，基于 Transformer 的模型（例如 BERT（Transformers 的双向编码器表示））在许多任务上取得了令人印象深刻的成就。此外，由于它们的迁移学习能力，这些架构允许我们迁移预构建的模型并将其微调到特定的 NLU 任务，例如回答问题。在这项研究中，我们提供了一个基于 Transformer 的模型和土耳其语言的基线基准。我们成功地对土耳其 BERT 模型（即 BERTurk）进行了微调，该模型使用基础设置进行训练，适用于许多下游任务，并使用土耳其基准数据集进行评估。我们表明，我们的研究在土耳其语命名实体识别、情感分析、问答和文本分类方面明显优于其他现有的基线方法。我们公开发布了这四个经过微调的模型和资源，以确保可重复性，并支持其他土耳其研究人员和应用程序。]]></description>
      <guid>https://arxiv.org/abs/2401.17396</guid>
      <pubDate>Thu, 01 Feb 2024 21:11:36 GMT</pubDate>
    </item>
    </channel>
</rss>