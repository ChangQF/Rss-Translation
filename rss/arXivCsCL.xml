<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Thu, 29 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用于产生移情反应的迭代联想记忆模型</title>
      <link>https://arxiv.org/abs/2402.17959</link>
      <description><![CDATA[arXiv:2402.17959v1 公告类型：新
摘要：共情反应生成是理解对话话语中的认知和情感状态并产生适当的反应。心理学理论认为，理解情绪和认知状态需要迭代地捕捉和理解对话话语中的相关单词。然而，现有的方法将对话话语视为长序列或独立的话语来进行理解，这很容易忽略它们之间的关联词。为了解决这个问题，我们提出了一种迭代联想记忆模型（IAMM）来生成同理心响应。具体来说，我们采用一种新颖的二阶交互注意机制来迭代捕获对话话语和情境、对话历史和记忆模块（用于存储关联词）之间的重要关联词，从而准确而细致地理解话语。我们在 Empathetic-Dialogue 数据集上进行了实验。自动评估和人工评估都验证了模型的有效性。同时，法学硕士的变体实验也表明，关注相关单词可以提高同理心理解和表达能力。]]></description>
      <guid>https://arxiv.org/abs/2402.17959</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>表格数据的大型语言模型——一项调查</title>
      <link>https://arxiv.org/abs/2402.17944</link>
      <description><![CDATA[arXiv:2402.17944v1 公告类型：新
摘要：大语言建模的最新突破促进了对其在与表格数据建模相关的各种任务中的应用的严格探索，例如预测、表格数据合成、问答和表格理解。每项任务都带来独特的挑战和机遇。然而，目前缺乏对该研究领域的关键技术、指标、数据集、模型和优化方法进行总结和比较的全面综述。本调查旨在通过巩固这些领域的最新进展，对所使用的数据集、指标和方法进行全面的调查和分类来解决这一差距。它确定了现有文献中的优势、局限性、未探索的领域和差距，同时为这个重要且快速发展的领域的未来研究方向提供了一些见解。它还提供了相关代码和数据集参考。通过这次全面的审查，我们希望为感兴趣的读者提供相关的参考资料和富有洞察力的观点，为他们提供必要的工具和知识，以有效地应对和解决该领域普遍存在的挑战。]]></description>
      <guid>https://arxiv.org/abs/2402.17944</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>预训练语言模型的无梯度自适应全局剪枝</title>
      <link>https://arxiv.org/abs/2402.17946</link>
      <description><![CDATA[arXiv:2402.17946v1 公告类型：新
摘要：LLaMA 和 GPT 等大型语言模型 (LLM) 对自然语言处理的变革性影响因其过高的计算需求而受到抵消。修剪已成为一种关键的压缩策略，引入稀疏性以提高内存和计算效率。然而，由于可扩展性问题，传统的全局修剪对于法学硕士来说是不切实际的，而局部修剪尽管效率很高，但会导致解决方案次优。为了应对这些挑战，我们提出了自适应全局剪枝（AdaGP），这是一种新颖的框架，它将全局剪枝过程重新定义为可管理的、协调的子问题，从而实现具有全局最优性的资源高效优化。 AdaGP 的方法将 LLM 概念化为一系列模块化函数，并利用辅助变量进行问题分解，不仅促进了 LLM 的实用应用，而且还展示了显着的性能改进，特别是在高稀疏性情况下，它超越了当前的状态-艺术方法。]]></description>
      <guid>https://arxiv.org/abs/2402.17946</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>用于自动语音识别的多语言语音模型表现出性别性能差距</title>
      <link>https://arxiv.org/abs/2402.17954</link>
      <description><![CDATA[arXiv:2402.17954v1 公告类型：新
摘要：当前的语音识别方法使用多任务、多语言模型来执行自动语音识别（ASR）等语音任务，使其适用于多种语言而无需进行实质性更改。然而，广泛的语言覆盖范围仍然可以掩盖语言内部的表现差距，例如跨性别的差距。我们系统地评估多语言 ASR 系统的性别绩效差距。在七个语系、19 种语言的三个数据集上使用两个流行模型，我们发现了明显的性别差异。然而，不同语言的优势群体有所不同。虽然各组之间的语音变量（音高、语速等）没有显着差异，但探索模型的内部状态揭示了探测性能与性别性能差距之间的负相关性。也就是说，越容易区分语言中说话者的性别，模型就越有利于女性说话者。我们的结果表明，尽管在多任务处理和多语言能力方面取得了巨大进步，但群体差异仍未得到解决。我们为评估多语言 ASR 系统中的性别差距提供了第一个有价值的见解。我们在 https://github.com/g8a9/multilingual-asr-gender-gap 发布了所有代码和工件。]]></description>
      <guid>https://arxiv.org/abs/2402.17954</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>具有特征化低阶混合的多任务多语言模型适应</title>
      <link>https://arxiv.org/abs/2402.17934</link>
      <description><![CDATA[arXiv:2402.17934v1 公告类型：新
摘要：使预训练的大语言模型（LLM）适应数十或数百种人类语言的各种下游任务在计算上是昂贵的。参数高效微调（PEFT）通过仅调整少量参数来显着降低适应成本。然而，由于有限的参数容量和不同数据集之间的负面干扰，直接将 LoRA（Hu et al., 2022）等 PEFT 方法应用于不同的数据集混合可能会导致性能欠佳。在这项工作中，我们提出了 Featurized Low-rank Mixtures (FLix)，这是一种新颖的 PEFT 方法，专为有效的多任务多语言调优而设计。 FLix 将每个独特的数据集特征（例如数据集的语言或任务）与其自己的低秩权重更新参数相关联。通过为每个数据集组合特定于特征的参数，FLix 可以适应不同的数据集混合，并更好地泛化到未见过的数据集。我们的实验表明，FLix 使用不同的训练数据混合对监督学习和零样本设置的各种任务带来了显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2402.17934</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>从多模态输入中获取语言知识</title>
      <link>https://arxiv.org/abs/2402.17936</link>
      <description><![CDATA[arXiv:2402.17936v1 公告类型：新
摘要：与儿童相比，语言模型（LM）在习得语言时表现出相当低的数据效率。在提交给 BabyLM 挑战赛（Warstadt 等人，2023）的文章中，我们测试了这样一个假设：这种数据效率差距部分是由于缺乏多模态输入和典型语言模型学习环境的基础造成的。尽管之前研究这个问题的工作发现多模式训练甚至会损害纯语言的表现，但我们推测这些发现可以归因于由于字幕数据的微调而导致的复杂语言的灾难性遗忘。为了检验我们的假设，我们对 FLAVA（Singh 等人，2022）进行了消融研究，FLAVA 是一种多模态视觉和语言模型，独立地改变文本和视觉输入的量，以量化有多少文本数据（如果有）可以被不同数据尺度的视觉所抵消。我们的目标是通过多任务预训练机制来限制灾难性遗忘，该机制包括单模式纯文本任务和从 WiT（相对多样化的基于维基百科的数据集）采样的数据（Srinivasan 等人，2021）。我们的结果在很大程度上是负面的：多模式预训练不会损害我们模型的语言性能，但也不能始终如一地有所帮助。也就是说，我们的结论受到我们只能进行少量运行的限制。虽然我们必须保留多模态输入解释 LM 和人类之间数据效率差距的可能性，但这一假设的积极证据将需要更好的多模态训练架构和技术。]]></description>
      <guid>https://arxiv.org/abs/2402.17936</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>通过可解释的方言分类器从方言中提取词汇特征</title>
      <link>https://arxiv.org/abs/2402.17914</link>
      <description><![CDATA[arXiv:2402.17914v1 公告类型：新
摘要：识别语言方言之间的语言差异通常需要专业知识和细致的人类分析。这主要是由于研究各种方言的复杂性和细微差别。我们提出了一种新颖的方法，即使在没有人类专家的情况下，也可以利用可解释的方言分类器来提取方言的词汇特征。我们探索事后和内在的可解释性方法，对普通话、意大利语和低撒克逊语进行实验，并通过实验证明我们的方法成功识别了导致方言变化的关键语言特定词汇特征。]]></description>
      <guid>https://arxiv.org/abs/2402.17914</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>通过对抗性攻击生成抗法学硕士数学应用题</title>
      <link>https://arxiv.org/abs/2402.17916</link>
      <description><![CDATA[arXiv:2402.17916v1 公告类型：新
摘要：大型语言模型（LLM）极大地改变了教育格局。由于当前的抄袭检测工具难以跟上法学硕士的快速发展，教育界面临着在法学硕士存在的情况下评估学生真正解决问题的能力的挑战。在这项工作中，我们探索了一种确保公平评估的新范式——生成对抗性示例，这些示例保留了旨在评估的原始问题的结构和难度，但法学硕士无法解决。专注于数学应用题领域，我们利用抽象语法树在结构上生成对抗性示例，这些示例导致法学硕士通过简单地编辑问题中的数值来产生错误的答案。我们对各种开源和闭源法学硕士进行了实验，定量和定性地证明我们的方法显着降低了他们解决数学问题的能力。我们识别了法学硕士之间的共同漏洞，并提出了一种经济高效的方法来攻击高成本模型。此外，我们对数学问题进行自动分析，并调查失败的原因，以指导未来LLM数学能力的研究。]]></description>
      <guid>https://arxiv.org/abs/2402.17916</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>JMLR：联合医学法学硕士和检索培训，增强推理和专业问答能力</title>
      <link>https://arxiv.org/abs/2402.17887</link>
      <description><![CDATA[arXiv:2402.17887v1 公告类型：新
摘要：随着医疗数据的爆发式增长和人工智能技术的快速发展，精准医疗已成为提升医疗服务质量和效率的关键。在这种背景下，大型语言模型（LLM）在医学知识获取和问答系统中发挥着越来越重要的作用。为了进一步提高这些系统在医学领域的性能，我们引入了一种创新方法，在微调阶段联合训练信息检索（IR）系统和法学硕士。这种方法，我们称之为联合医学法学硕士和检索训练（JMLR），旨在克服传统模型在处理医学问答任务时面临的挑战。通过采用同步训练机制，JMLR 减少了对计算资源的需求，并增强了模型利用医学知识进行推理和回答问题的能力。我们的实验结果表明，JMLR-13B（Amboos 上为 81.2%，MedQA 上为 61.3%）优于使用传统预训练和微调 Meditron-70B 的模型（AMBOSS 上为 76.4%，MedQA 上为 60.3%）。对于相同 7B 规模的模型，JMLR-7B（Amboos 上为 68.7%，MedQA 上为 51.7%）显着优于其他公共模型（Meditron-7B：50.1%、47.9%），证明了其在成本（我们的训练时间）方面的优越性：37小时，传统方法：144小时），医疗问答任务的效率和效果。通过这项工作，我们为医疗保健提供了一种新的、高效的知识增强工具，展示了将 IR 和 LLM 培训整合到精准医疗信息检索和问答系统中的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2402.17887</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>研究问题：LLM Web 代理的多视角、分解问题数据集</title>
      <link>https://arxiv.org/abs/2402.17896</link>
      <description><![CDATA[arXiv:2402.17896v1 公告类型：新
摘要：现有的问答（QA）数据集不再对最强大的大型语言模型（LLM）构成挑战。 TriviaQA、NaturalQuestions、ELI5 和 HotpotQA 等传统的 QA 基准主要研究“已知的未知数”，并明确指出缺少哪些信息以及如何找到它来回答问题。因此，这些基准测试的良好表现会带来一种错误的安全感。 NLP 社区尚未满足的需求是一系列非事实的、多视角的问题，涉及大量不明确的信息需求，即“未知的未知数”。我们声称我们可以在搜索引擎日志中找到此类问题，这令人惊讶，因为大多数问题意图查询确实是事实。我们提出了研究问题，这是一个搜索引擎查询的数据集，经过繁琐的过滤，成为非事实、“分解”和多视角的。我们表明，用户在这些问题上花费了大量的“努力”，从点击次数和会话长度等信号来看，他们也对 GPT-4 提出了挑战。我们还表明，“缓慢思考”的回答技巧（例如分解为子问题）比直接回答更有好处。我们发布了 $\sim$ 100k 研究问题，以及被点击的 Clueweb22 URL。]]></description>
      <guid>https://arxiv.org/abs/2402.17896</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>基于语言模型的本体新概念放置框架</title>
      <link>https://arxiv.org/abs/2402.17897</link>
      <description><![CDATA[arXiv:2402.17897v1 公告类型：新
摘要：我们研究使用语言模型将从文本中提取的新概念插入到本体中的任务。我们探索了一种包含三个步骤的方法：边缘搜索，即找到一组要插入的候选位置（即概念之间的包含），边缘形成和丰富，利用本体结构来生成和增强边缘候选，以及边缘选择最终找到要放入的边缘。在所有步骤中，我们建议利用神经方法，其中我们应用基于嵌入的方法和与预训练语言模型（PLM）的对比学习，例如用于边缘搜索的 BERT，并采用基于 BERT 微调的多标签边缘- 交叉编码器和大型语言模型 (LLM)，例如 GPT 系列、FLAN-T5 和 Llama 2，用于边缘选择。我们评估了使用 SNOMED CT 本体和 MedMentions 实体链接基准创建的最新数据集的方法。我们框架中的最佳设置使用经过微调的 PLM 进行搜索，并使用多标签交叉编码器进行选择。 LLM 的零样本提示仍然不足以完成任务，我们提出了 LLM 的可解释指令调整以提高性能。我们的研究展示了 PLM 的优势，并强调了 LLM 令人鼓舞的表现，这激励了未来的研究。]]></description>
      <guid>https://arxiv.org/abs/2402.17897</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>按照我的指示泄露秘密：从检索增强生成系统中提取可扩展的数据</title>
      <link>https://arxiv.org/abs/2402.17840</link>
      <description><![CDATA[arXiv:2402.17840v1 公告类型：新
摘要：检索增强生成（RAG）通过在测试时结合外部知识来改进预训练模型，以实现定制适应。我们研究上下文检索 RAG 语言模型 (LM) 中数据存储泄漏的风险。我们表明，对手可以利用 LM 的指令跟踪功能，通过提示注入轻松地从使用指令调整 LM 构建的 RAG 系统的数据存储中逐字提取文本数据。该漏洞存在于 Llama2、Mistral/Mixtral、Vicuna、SOLAR、WizardLM、Qwen1.5 和 Platypus2 等多种现代 LM 中，并且随着模型规模的扩大，可利用性会加剧。将我们的研究扩展到生产 RAG 模型 GPT，我们设计了一种攻击，该攻击可以导致数据存储泄漏，在 25 个随机选择的自定义 GPT 上最多进行 2 次查询，成功率为 100%，并且我们以 41% 的速度逐字提取文本数据。通过仅用自己生成的 100 个查询来提示 GPT，可以从包含 77,000 个单词的书中提取 1,569,000 个单词的语料库中的 3%。]]></description>
      <guid>https://arxiv.org/abs/2402.17840</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>BlendSQL：一种可扩展的方言，用于统一关系代数中的混合问答</title>
      <link>https://arxiv.org/abs/2402.17882</link>
      <description><![CDATA[arXiv:2402.17882v1 公告类型：新
摘要：许多现有的用于混合问答任务的端到端系统通常可以归结为“提示和祈祷”范例，其中用户对用于实现最终结果的中间推理步骤的控制和洞察力有限。此外，由于许多基于 Transformer 的 LLM 的上下文大小限制，期望完整的结构化和非结构化上下文能够适应零样本设置中的给定提示通常是不合理的，更不用说少数样本设置了。我们引入 BlendSQL，它是 SQLite 的超集，充当跨非结构化和结构化数据编排推理的统一方言。对于涉及多跳推理的混合问答任务，我们将完整分解的推理路线图编码为单个可解释的 BlendSQL 查询。值得注意的是，我们表明 BlendSQL 可以扩展到海量数据集并提高端到端系统的性能，同时使用的令牌减少 35%。我们的代码可作为包在 https://github.com/parkervg/blendsql 上获取和安装。]]></description>
      <guid>https://arxiv.org/abs/2402.17882</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>TruthX：通过在真实空间中编辑大型语言模型来减轻幻觉</title>
      <link>https://arxiv.org/abs/2402.17811</link>
      <description><![CDATA[arXiv:2402.17811v1 公告类型：新
摘要：大型语言模型（LLM）在各种任务中表现出了卓越的能力。然而，他们有时会产生幻觉，特别是在尽管拥有正确的知识但仍可能产生不真实反应的情况下。在本文中，我们提出了 TruthX，这是一种推理时间方法，通过编辑真实空间中的内部表示来得出法学硕士的真实性。 TruthX 采用自动编码器将 LLM 的表示分别映射到语义和真实潜在空间，并应用对比学习来识别真实空间内的真实编辑方向。在推理过程中，通过编辑LLM在真实空间中的内部表示，TruthX有效地增强了LLM的真实性。实验表明，TruthX 在 TruthfulQA 基准上有效地将 13 个高级法学硕士的真实性平均提高了 20%。进一步分析表明，TruthX获得的真实空间在控制LLM产生真实或幻觉反应方面发挥着关键作用。]]></description>
      <guid>https://arxiv.org/abs/2402.17811</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>稳定的LM 2 1.6B技术报告</title>
      <link>https://arxiv.org/abs/2402.17834</link>
      <description><![CDATA[arXiv:2402.17834v1 公告类型：新
摘要：我们推出了 StableLM 2 1.6B，这是我们新一代语言模型系列中的第一个。在这份技术报告中，我们详细介绍了 StableLM 2 1.6B 的基础版本和指令调整版本的数据和训练过程。两种模型的权重均可通过 Hugging Face 提供，任何人都可以下载和使用。该报告包含对这些模型的全面评估，包括零样本和少样本基准、多语言基准以及专注于多轮对话的 MT 基准。在发布本报告时，StableLM 2 1.6B 是 2B 参数下最先进的开放模型，遥遥领先。鉴于其较小的尺寸，我们还提供了许多边缘设备的吞吐量测量。此外，我们还开源了几个量化检查点，并提供了它们与原始模型相比的性能指标。]]></description>
      <guid>https://arxiv.org/abs/2402.17834</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:28 GMT</pubDate>
    </item>
    </channel>
</rss>