<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Fri, 01 Dec 2023 06:18:55 GMT</lastBuildDate>
    <item>
      <title>INarIG：用于字级自动完成的迭代非自回归指令生成模型。 （arXiv：2311.18200v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18200</link>
      <description><![CDATA[计算机辅助翻译 (CAT) 旨在提高人工翻译效率
在机器翻译无法满足的场景下仍然很重要
质量要求。该领域的一项基本任务是字级自动
完成（WLAC）。 WLAC 在给定源句子的情况下预测目标单词，
翻译上下文和人工输入的字符序列。以前的作品
要么采用单词分类模型来利用上下文信息
目标词的两侧或直接忽略来自目标词的依赖关系
右侧上下文。此外，关键信息，即人工输入的
序列，仅用作解码模块中的前缀约束。在这个
论文中，我们提出了 INarIG（迭代非自回归指令生成）
模型，它将人类类型序列构建成指令单元和
采用带有子字的迭代解码来充分利用输入信息
任务中给出。我们的模型在处理低频方面更胜任
词（该任务的核心场景），并在
WMT22和基准数据集，最大增幅超过10%
预测准确性。
]]></description>
      <guid>http://arxiv.org/abs/2311.18200</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:54 GMT</pubDate>
    </item>
    <item>
      <title>自动构建韩语有毒指令数据集，用于大型语言模型的道德调整。 （arXiv：2311.18215v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18215</link>
      <description><![CDATA[警告：本文可能包含令人反感的材料或
令人痛苦。

大型语言模型 (LLM) 的出现需要开发
减少不道德语言产生的培训方法
妥善管理有毒用户查询。鉴于与人力相关的挑战
由于数据稀缺，我们提出了 KoTox，其中包含 39K 不道德的内容
指令输出对。本集合自动生成有毒
指令完善了法学硕士的培训并建立了基础
提高法学硕士的道德意识和对各种有毒物质的反应的框架
输入，促进自然语言中更安全和负责任的交互
处理（NLP）应用程序。
]]></description>
      <guid>http://arxiv.org/abs/2311.18215</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:54 GMT</pubDate>
    </item>
    <item>
      <title>LMRL Gym：使用语言模型进行多轮强化学习的基准。 （arXiv：2311.18232v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18232</link>
      <description><![CDATA[大型语言模型 (LLM) 提供出色的文本生成功能，
但标准的提示和生成方法通常不会导致
有意或目标导向的代理人，可能需要大量的提示
调整。这在多轮对话中变得尤为明显：甚至
当前最好的法学硕士很少提出澄清问题，从事明确的
收集信息，或立即采取行动，以便在事后做出更好的决策
多转。强化学习有潜力利用
法学硕士强大的建模能力，以及他们的内部
文本交互的表示，以创建有能力的目标导向
语言代理。这可以实现有意且暂时的延长
通过协调的说服和谨慎的互动，例如与人类的互动
精心设计的问题，或通过文字游戏进行有目标的游戏，以实现
期望的最终结果。然而，实现这一点需要社区
开发稳定可靠的强化学习算法
有效地培训法学硕士。开发此类算法需要的任务可以
衡量算法设计的进展，提供可访问且可重复的
多轮交互的评估，并涵盖一系列任务属性
以及改进强化学习算法的挑战。我们的论文
引入了 LMRL-Gym 基准，用于评估法学硕士的多轮强化学习，
以及一个开源研究框架，其中包含一个基本工具包
开始使用基于离线价值和基于策略的 RL 进行多轮 RL
方法。我们的基准测试由 8 种不同的语言任务组成，这些任务需要
多轮语言交互并涵盖一系列任务
开放式对话和文字游戏。
]]></description>
      <guid>http://arxiv.org/abs/2311.18232</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:54 GMT</pubDate>
    </item>
    <item>
      <title>位置信息对于不变上下文学习很重要：简单函数类的案例研究。 （arXiv：2311.18194v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.18194</link>
      <description><![CDATA[情境学习 (ICL) 是指模型以特定条件为条件的能力
很少有上下文演示（基础任务的输入输出示例）
生成新查询输入的答案，而不更新参数。尽管
法学硕士的 ICL 能力令人印象深刻，而且还发现法学硕士的 ICL 是
对输入演示敏感并且仅限于较短的上下文长度。到
了解成功 ICL 的限制和原则，我们进行
使用变压器的 ICL 线性回归进行研究。我们表征
受现实 LLM ICL 启发的几个 ICL 分配外 (OOD) 案例
故障并将 Transformer 与 DeepSet 进行比较，DeepSet 是一个简单但功能强大的
ICL 的架构。令人惊讶的是，DeepSet 在各个方面都优于 Transformer
各种分布变化，意味着保持排列不变性
输入演示的对称性对于 OOD ICL 至关重要。现象
指定了 ICL 的一个基本要求，我们将其称为 ICL 不变性。
然而，LLM 中的位置编码将打破 ICL 不变性。到
为此，我们进一步评估具有相同位置编码的变压器
并发现在 Transformer 中保持 ICL 不变性达到了最先进的水平
各种 ICL 分布变化的性能
]]></description>
      <guid>http://arxiv.org/abs/2311.18194</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:53 GMT</pubDate>
    </item>
    <item>
      <title>中等收入国家的 COVID-19 疫苗错误信息。 （arXiv：2311.18195v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18195</link>
      <description><![CDATA[本文介绍了 COVID-19 疫苗的多语言数据集
错误信息，由来自三个中等收入国家的带注释的推文组成
国家：巴西、印度尼西亚和尼日利亚。专业整理的数据集
包括 5,952 条推文的注释，评估它们与 COVID-19 的相关性
疫苗、错误信息的存在以及错误信息的主题。到
解决领域特殊性、资源匮乏环境带来的挑战，以及
数据不平衡，我们采用两种方法来开发 COVID-19 疫苗
错误信息检测模型：特定领域的预训练和文本
使用大型语言模型进行增强。我们最好的错误信息检测
模型展示了 2.7 至 15.9 个百分点的改进
与基线模型相比的宏观 F1 分数。此外，我们应用我们的
对 1900 万人进行的大规模研究中的错误信息检测模型
2020 年至 2022 年这三个国家的推文，展示了实用的
应用我们的数据集和模型来检测和分析疫苗
多个国家和语言的错误信息。我们的分析表明
新的 COVID-19 病例数的百分比变化呈正值
与 COVID-19 疫苗错误信息率呈交错相关
巴西和印度尼西亚之间存在显着的正相关关系
这三个国家的错误信息率。
]]></description>
      <guid>http://arxiv.org/abs/2311.18195</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:53 GMT</pubDate>
    </item>
    <item>
      <title>ROBBIE：大型生成语言模型的鲁棒偏差评估。 （arXiv：2311.18140v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18140</link>
      <description><![CDATA[随着生成式大语言模型 (LLM) 的性能变得越来越好，
流行，我们必须开发足够全面的工具来衡量和改进
他们的公平性。不同的基于提示的数据集可用于衡量社交
跨多个文本域和人口统计轴的偏见，这意味着测试
更多数据集上的法学硕士可以帮助我们更多地描述他们的偏见
充分并更好地确保边缘化群体得到平等和公正的待遇
人口群体。在这项工作中，我们的重点有两个：

(1) 基准测试：比较 6 种不同的基于提示的偏差和毒性
跨 12 个人口统计轴和 5 个生成法学硕士系列的指标。在......之外
这 6 个指标、AdvPromptSet 和 HolisticBiasR 是 中提出的新颖数据集
纸。这些基准的比较让我们了解了偏差
和比较模型的毒性。因此，我们探讨了
常见的法学硕士预训练语料库中的人口统计术语及其与
模型偏差。

(2) 缓解：我们对 3 偏倚/毒性的效果进行了全面研究
缓解技术在我们的测量套件中发挥作用。罗比的目标是
在部署模型时为从业者提供见解，强调
不仅需要衡量潜在危害，还需要了解它们是如何产生的
描述数据的特征，减轻发现的危害，并平衡任何权衡。
我们开源我们的分析代码，希望鼓励更广泛的测量
未来法学硕士的偏见。
]]></description>
      <guid>http://arxiv.org/abs/2311.18140</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:52 GMT</pubDate>
    </item>
    <item>
      <title>DisCGen：基于话语的反言语生成框架。 （arXiv：2311.18147v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18147</link>
      <description><![CDATA[反言论可以成为对抗仇恨内容的有效方法
社交媒体。自动反语音生成可以帮助这一过程。
然而，生成的反言论只有在扎根于
主题背景、受众和敏感性，因为这些因素都会影响
有效性和适当性。在这项工作中，我们提出了一个基于新框架
论话语理论研究连接反面的推理环节
针对仇恨言论的演讲。在此框架内，我们建议： i)
来自话语框架的反言语分类，以及 ii)
用于生成基于上下文的话语提示策略
反言。为了构建和验证该框架，我们提出了一个流程
用于从 Reddit 收集野外的反言论数据集。使用这个
过程中，我们手动注释了 3.9k Reddit 评论对的数据集
存在仇恨言论和反言论。正对注释为
我们提议的分类法中有 10 个类。我们用释义来注释这些对
同行消除冒犯性和第一人称参考。我们表明
通过使用我们的数据集和框架，大型语言模型可以生成
以话语理论为依据的基于上下文的反言语。
根据我们的人工评估，我们的方法可以起到保障作用
防止与话语无关的模型的严重失败。
]]></description>
      <guid>http://arxiv.org/abs/2311.18147</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:52 GMT</pubDate>
    </item>
    <item>
      <title>不确定性引导的全局记忆改善了多跳问答。 （arXiv：2311.18151v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18151</link>
      <description><![CDATA[Transformer 已成为许多自然语言的黄金标准
处理任务，特别是多跳问答（MHQA）。
此任务包括处理长文档并对多个文档进行推理
它的一部分。 MHQA 方法的前景可分为两类
主要类别。第一组侧重于提取支持证据，
从而将 QA 模型的上下文限制为预测事实。相反，
第二组依赖于长输入编码模型的注意力机制
以促进多跳推理。然而，基于注意力的令牌
表示缺乏明确的全局上下文信息来连接
推理步骤。为了解决这些问题，我们提出了 GEMFormer，一个两阶段的
首先将整个文档的相关信息收集到的方法
记忆，然后将其与本地上下文相结合来解决任务。我们的
实验结果表明，对预训练模型进行微调
记忆增强输入，包括最确定的全局元素，提高了
与基线相比，该模型在三个 MHQA 数据集上的性能。我们
还发现全局显性记忆包含来自支持的信息
正确答案所需的事实。
]]></description>
      <guid>http://arxiv.org/abs/2311.18151</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:52 GMT</pubDate>
    </item>
    <item>
      <title>使用小型大型语言模型进行零样本会话摘要评估。 （arXiv：2311.18041v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18041</link>
      <description><![CDATA[大型语言模型 (LLM) 表现出强大的概括能力。
然而，他们的会话总结能力仍然不足
探索过。在这项工作中，我们评估了 LLM（大约 100 亿个参数）
对话总结并展示他们在各种提示下的表现。
我们表明模型生成的摘要取决于指令和
法学硕士的表现会因不同的指令而有所不同，有时会导致
如果没有仔细选择提示，ROUGE 分数会急剧下降。我们也
通过人类评估来评估模型并讨论其局限性
会话总结模型
]]></description>
      <guid>http://arxiv.org/abs/2311.18041</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:51 GMT</pubDate>
    </item>
    <item>
      <title>我知道那不是你写的！用于识别机器生成文本的基于采样的水印方法。 （arXiv：2311.18054v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18054</link>
      <description><![CDATA[大型语言模型的潜在危害，例如大量错误信息和
如果存在可靠的检测方法，可以部分减轻抄袭行为
机器生成的文本。在本文中，我们提出了一种新的水印方法
检测机器生成的文本。我们的方法在其中嵌入了独特的模式
生成的文本，确保内容保持连贯和自然
人类读者，它带有可以识别的独特标记
从算法上来说。具体来说，我们干预令牌采样过程
一种使我们能够在检测期间追溯我们的令牌选择的方法
阶段。我们展示水印如何影响文本质量并比较我们的
提出的方法与最先进的水印方法有关
鲁棒性和可检测性。通过大量的实验，我们证明了
我们的水印方案在区分水印的方面的有效性
和无水印文本，实现高检测率，同时保持
文本质量。
]]></description>
      <guid>http://arxiv.org/abs/2311.18054</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:51 GMT</pubDate>
    </item>
    <item>
      <title>TurkishBERTweet：用于社交媒体分析的快速可靠的大型语言模型。 （arXiv：2311.18063v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18063</link>
      <description><![CDATA[土耳其语是世界上最流行的语言之一。我们广泛了解这一点
Twitter、Instagram 或 Tiktok 等社交媒体平台上的语言，以及
该国在世界政治中的战略地位使其具有吸引力
社交网络研究人员和行业。为了解决这个需求，我们引入
土耳其语BERTweet，第一个大规模预训练土耳其语语言模型
使用近 9 亿条推文构建的社交媒体。型号相同
架构作为基础 BERT 模型，具有较小的输入长度，使得
TurkishBERTweet 比 BERTurk 更轻，并且推理能力明显较低
时间。我们使用与 RoBERTa 模型相同的方法来训练我们的模型
对两个文本分类任务进行评估：情感分类和仇恨
语音检测。我们证明土耳其BERTweet 优于其他
泛化性的可用替代方案及其较短的推理时间给出了
处理大规模数据集的显着优势。我们还比较了我们的
模型与商业 OpenAI 解决方案在成本和性能方面
展示土耳其BERTweet 是可扩展且经济高效的解决方案。作为...的一部分
我们的研究中，我们发布了 TurkeyBERTweet 和微调的 LoRA 适配器
麻省理工学院许可证下提到的任务，以促进未来的研究和
土耳其社交媒体上的应用程序。我们的土耳其BERTweet 模型可用
网址：https://github.com/ViralLab/TurkishBERTweet
]]></description>
      <guid>http://arxiv.org/abs/2311.18063</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:51 GMT</pubDate>
    </item>
    <item>
      <title>自填充代码生成。 （arXiv：2311.17972v1 [cs.PL]）</title>
      <link>http://arxiv.org/abs/2311.17972</link>
      <description><![CDATA[这项工作介绍了一个通用的代码生成框架，其中包含
将操作填充到自回归解码中。我们的方法利用了
观察到最近的代码语言模型具有填充功能
可以执行 \emph{自填充}：而填充操作的目的是填充
中间根据预定义的前缀和后缀，依次自行填充
生成这样的周围上下文和填充内容。我们利用
利用此功能来开发填充增强解码过程
促进非单调生成。这种方法可以推迟
生成不确定的代码片段，直到建立明确的后缀，
从而改善对生成序列的控制。此外，它
促进循环机制，可以迭代更新和同步
每一代都以循环的方式进行。大量的实验是
进行以证明我们提出的解码过程是有效的
提高多个代码生成基准的规律性和质量。
]]></description>
      <guid>http://arxiv.org/abs/2311.17972</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:50 GMT</pubDate>
    </item>
    <item>
      <title>过滤半马尔可夫 CRF。 （arXiv：2311.18028v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18028</link>
      <description><![CDATA[半马尔可夫 CRF 已被提议作为传统线性的替代方案
用于文本分割任务的链 CRF，例如命名实体识别 (NER)。
与 CRF 将文本分割视为 token 级预测不同，Semi-CRF
以段为基本单位，使其更具表现力。然而，
Semi-CRF 有两个主要缺点：（1）二次复杂度
序列长度，因为它对输入序列的每个跨度进行操作，并且 (2)
与 CRF 相比，对于 NER 等序列标记任务，性能较差。在
在本文中，我们介绍了 Filtered Semi-Markov CRF，它是 Semi-CRF 的一种变体
通过合并过滤步骤来消除这些问题
不相关的段，减少复杂性和搜索空间。我们的方法是
在多个 NER 基准上进行评估，其性能优于 CRF 和 Semi-CRF
同时速度明显更快。我们的方法的实现是可用的
在 \href{https://github.com/urchade/Filtered-Semi-Markov-CRF}{Github} 上。
]]></description>
      <guid>http://arxiv.org/abs/2311.18028</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:50 GMT</pubDate>
    </item>
    <item>
      <title>超多语言法学硕士：令牌嵌入的跨语言可解释性。 （arXiv：2311.18034v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.18034</link>
      <description><![CDATA[跨语言迁移学习是多语言的重要属性
大语言模型（LLM）。但法学硕士如何表示之间的关系
语言？每个语言模型都有一个将标记映射到向量的输入层。
这种无处不在的语言模型层经常被忽视。我们发现
这些输入嵌入之间的相似性是高度可解释的，并且
这些嵌入的几何形状在模型系列之间有所不同。在一种情况下
(XLM-RoBERTa)，嵌入编码语言：不同书写系统中的标记
可以线性分离，平均准确度为99.2%。另一个家庭
(mT5)表示跨语言语义相似度：50个最近邻
对于任何标记，平均代表 7.61 个书写系统，并且经常出现
翻译。鉴于没有明确的结果，这个结果令人惊讶
并行的跨语言训练语料库并且没有明确的激励
预训练目标的翻译。我们的研究为
1）预训练和模型架构对
语言的表示以及2）跨语言的应用
嵌入语言模型中的表示。
]]></description>
      <guid>http://arxiv.org/abs/2311.18034</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:50 GMT</pubDate>
    </item>
    <item>
      <title>DreamSync：将文本到图像的生成与图像理解反馈结合起来。 （arXiv：2311.17946v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.17946</link>
      <description><![CDATA[尽管文本到图像模型 (T2I) 取得了广泛的成功，但仍然举步维艰
产生既美观又忠实于主题的图像
用户输入的文本。我们引入 DreamSync，一种与模型无关的训练算法
通过设计改进 T2I 模型以忠实于文本输入。梦同步
基于 TIFA 评估框架的最新见解——大
视觉语言模型（VLM）可以有效地识别细粒度的
生成的图像和文本输入之间的差异。 DreamSync 使用这个
在没有任何标记数据的情况下训练 T2I 模型的洞察力；它改进了 T2I 模型
使用自己的世代。首先，它提示模型生成几个
给定输入文本的候选图像。然后，它使用两个 VLM 来选择
最佳一代：测量对齐的视觉问答模型
生成的图像到文本，另一个衡量生成的
审美品质。选择后，我们使用 LoRA 迭代微调 T2I
模型引导其一代走向选定的最佳一代。梦同步
不需要任何额外的人工注释。模型架构变化，或者
强化学习。尽管很简单，DreamSync 仍改进了
两个基于扩散的 T2I 模型的语义对齐和审美吸引力，
多个基准证明了这一点（TIFA +1.7%、DSG1K +2.9%、VILA +3.4%）
审美）和人类评价。
]]></description>
      <guid>http://arxiv.org/abs/2311.17946</guid>
      <pubDate>Fri, 01 Dec 2023 06:18:49 GMT</pubDate>
    </item>
    </channel>
</rss>