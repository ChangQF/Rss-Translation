<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 计算和语言 (cs.CL) 更新</description>
    <lastBuildDate>Fri, 15 Dec 2023 03:15:01 GMT</lastBuildDate>
    <item>
      <title>JPIS：基于配置文件的意图检测和具有槽位到意图注意的槽位填充的联合模型。 （arXiv：2312.08737v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08737</link>
      <description><![CDATA[基于配置文件的意图检测和槽位填充是旨在实现的重要任务
通过利用特定于用户的信息来减少用户话语中的歧义
支持个人资料信息。然而，这两项任务的研究尚未
被广泛探索。为了填补这一空白，我们提出了一个联合模型，即
JPIS，旨在增强基于配置文件的意图检测和槽位填充。联合工业信息系统
将支持配置文件信息合并到其编码器中并引入
用于传输槽信息的槽到意图注意机制
意图检测的表示。实验结果表明我们的JPIS
大大优于以前的基于配置文件的模型，建立了一个新的
在中国基准测试中整体准确率达到最先进的水平
数据集 ProSLU。
]]></description>
      <guid>http://arxiv.org/abs/2312.08737</guid>
      <pubDate>Fri, 15 Dec 2023 03:15:01 GMT</pubDate>
    </item>
    <item>
      <title>通过统计测试和自动数据增强来剖析词汇偏差数据集，以减轻自然语言推理中的伪影。 （arXiv：2312.08747v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08747</link>
      <description><![CDATA[近年来，大规模注释数据集的出现，例如
斯坦福自然语言推理和多流派自然语言
推理，加上预训练语言模型的出现，已经
对自然语言推理的发展做出了重大贡献
领域。然而，这些众包注释数据集通常包含偏见或
数据集伪影，导致高估模型性能并且较差
概括。在这项工作中，我们重点研究数据集工件和
制定解决这些问题的策略。通过利用
新颖的统计测试程序，我们发现了显着的关联
在词汇分布和文本蕴涵类之间，强调
词汇是偏见的一个显着来源。为了缓解这些问题，我们建议
几种涵盖字符到单词的自动数据增强策略
水平。通过微调 ELECTRA 预训练语言模型，我们比较了
增强模型的性能与基线相比的增强数据
同行。实验表明所提出的方法
有效提升模型精度，降低偏差高达0.66%和1.14%，
分别。
]]></description>
      <guid>http://arxiv.org/abs/2312.08747</guid>
      <pubDate>Fri, 15 Dec 2023 03:15:01 GMT</pubDate>
    </item>
    <item>
      <title>用于金融情绪分析的微调法学硕士和法学硕士的小样本学习的比较分析。 （arXiv：2312.08725v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.08725</link>
      <description><![CDATA[金融情绪分析在发现潜在风险方面发挥着至关重要的作用
模式并检测新兴趋势，使个人能够
明智的决策可能会在行业内产生巨大的优势
不断变化的金融领域。最近，大型语言模型（LLM）
已在不同领域展示了其有效性，展现了非凡的
即使在零样本和少样本的上下文学习中也具有多种能力
自然语言处理 (NLP) 任务。尽管如此，他们的潜力和
金融情绪分析的适用性尚未得到证实
还没有彻底探索过。为了弥补这一差距，我们采用两种方法：
情境学习（重点关注 gpt-3.5-turbo 模型）和微调 LLM
在金融领域数据集上。考虑到相关的计算成本
微调具有大参数大小的 LLM，我们的重点在于较小的 LLM，
涵盖从 250M 到 3B 的参数进行微调。然后我们比较
具有最先进结果的表演来评估其有效性
金融领域。我们的结果表明，经过微调的小型法学硕士可以
达到与最先进的微调法学硕士相当的性能，即使
具有较少参数和较小训练数据集的模型。此外，
法学硕士的零次和一次性能产生了与
微调较小的法学硕士和最先进的成果。此外，我们的
分析表明，没有观察到性能的提高
当上下文中的镜头数量时，进行金融领域的情感分析
学习增加了。
]]></description>
      <guid>http://arxiv.org/abs/2312.08725</guid>
      <pubDate>Fri, 15 Dec 2023 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>标签也需要提示用于自然语言理解任务的掩码匹配。 （arXiv：2312.08726v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08726</link>
      <description><![CDATA[文本标签名称（描述）通常在许多方面具有丰富的语义
自然语言理解（NLU）任务。在本文中，我们将
广泛用于丰富模型输入的提示方法
第一次贴标签面。具体来说，我们提出了一种掩模匹配方法，
它为输入配备了提示，并为其标签配备了另一个，然后使
通过匹配它们的掩码表示来进行预测。我们评估我们的方法
广泛涉及 8 个 NLU 任务和 14 个数据集。实验结果表明
掩模匹配显着优于微调和
传统的即时调音，在几个方面设置最先进的性能
数据集。 Mask Matching 特别擅长处理大型 NLU 任务
标签计数和信息标签名称。作为开创性的努力
研究标签侧提示，我们还讨论未来的未决问题
学习。
]]></description>
      <guid>http://arxiv.org/abs/2312.08726</guid>
      <pubDate>Fri, 15 Dec 2023 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>SEF-VC：扬声器嵌入具有交叉注意力的免费零样本语音转换。 （arXiv：2312.08676v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2312.08676</link>
      <description><![CDATA[零样本语音转换（VC）旨在将源说话人的音色转移到
任意看不见的目标说话者音色，同时保留语言内容
不变。虽然生成语音的声音可以通过以下方式控制
提供目标说话人的说话人嵌入、说话人相似度
仍然落后于地面真实记录。在本文中，我们建议
SEF-VC，一种嵌入免费语音转换模型的扬声器，旨在
通过强大的功能从参考语音中学习并合并说话者的音色
位置不可知的交叉注意机制，然后从
HuBERT 以非自回归方式语义标记。简洁的设计
SEF-VC增强了其训练稳定性和语音转换性能。
客观和主观评价表明 SEF-VC 优于
生成与目标参考具有更好相似度的高质量语音
强大的零样本 VC 基线，即使对于非常短的参考演讲也是如此。
]]></description>
      <guid>http://arxiv.org/abs/2312.08676</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>TigerBot：开放式多语言多任务法学硕士。 （arXiv：2312.08688v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08688</link>
      <description><![CDATA[我们发布并推出了 TigerBot 系列大型语言模型 (LLM)，
由基础模型和聊天模型组成，大小为 7、13、70 和 1800 亿
参数。我们从 Llama-2 和 BLOOM 出发开发模型，并推动
数据、训练算法、基础设施等方面的边界进一步扩大
应用工具。我们的模型比 SOTA 带来了有意义的性能提升
开源模型，例如 Llama-2，具体而言，英语增益为 6\%，英语增益为 20\%
增益 中文. TigerBot模型家族在以下方面也取得了领先的表现
主要学术和工业基准和排行榜。我们相信
TigerBot 只是 LLM 闪电般快速进步的一个缩影
开源社区。因此，我们很高兴能够公开回馈
发布我们的模型并报告我们背后的方法，以及额外的
强调以民主化的方式建立 SOTA LLM 并使 LLM 能够在
现实世界的应用程序。
]]></description>
      <guid>http://arxiv.org/abs/2312.08688</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>Zebra：通过分层分组局部全局注意力扩展上下文窗口。 （arXiv：2312.08618v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08618</link>
      <description><![CDATA[本文介绍了一种增强大型计算机能力的新方法
处理和理解大量文本的语言模型（LLM）
序列，是需要深入理解的应用程序的一个关键方面
大量信息的综合。认识到固有的挑战
扩展法学硕士的上下文窗口，主要基于 Transformer
架构方面，我们提出了一种新的模型架构，简称Zebra。这
架构有效地管理二次时间和内存复杂性
通过采用分组方式充分关注 Transformer 中的相关问题
局部-全局注意力层。我们的模型，类似于斑马的交替
条纹，平衡局部和全局注意力层，显着减少
计算要求和内存消耗。综合实验，
包括从头开始预训练、持续长上下文适应
进行训练和长期指令调整来评估 Zebra
表现。结果表明，Zebra 达到了可比或优于
在短序列和长序列基准上的性能，同时还增强
训练和推理效率。
]]></description>
      <guid>http://arxiv.org/abs/2312.08618</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>元认知增强的小样本提示与正强化。 （arXiv：2312.08642v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08642</link>
      <description><![CDATA[少量提示激发了大型语言模型的非凡能力
通过在输入中为他们配备一些演示示例。但是，那
提供大型语言模型并进行所有演示的传统方法
一次输入输出对可能无法有效地指导大型语言模型
了解具体的输入输出映射关系。在本文中，受到启发
通过元认知在学生学习中的调节和支持作用，
我们提出了一种新颖的元认知增强的小样本提示，它可以指导
大型语言模型可以全面反映他们的思维过程
学习给定的演示示例。此外，考虑到积极的
强化可以提高学生的学习动机，我们引入正向强化
强化我们的元认知增强的几次提示，以促进
通过提供基于响应的积极信息来进行大型语言模型的小样本学习
反馈。在两个真实世界数据集上的实验结果表明，我们的
元认知增强的带有正强化的几次提示超越
传统的小样本提示在分类精度和宏 F1 方面。
]]></description>
      <guid>http://arxiv.org/abs/2312.08642</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>识别天文学论文中的行星名称：多步方法。 （arXiv：2312.08579v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08579</link>
      <description><![CDATA[天文学中行星特征名称的自动识别
出版物提出了许多挑战。这些特征包括陨石坑、
定义为由撞击或火山作用造成的大致圆形凹陷
活动;背部，是细长的凸起结构或皱纹脊；和
lacus，月球上不规则的小块黑色光滑物质，称为
称为“湖”（行星名称工作组，n.d.）。许多功能名称重叠
以地名或人名命名，例如叙利亚，
坦佩、爱因斯坦和萨根，仅举几例（美国地质调查局，日期不详）。一些
特征名称已在许多上下文中使用，例如 Apollo，它可以
指任务、计划、样本、宇航员、地震、地震仪、核心、时代、
数据、收集、仪器和空间站，以及陨石坑
月亮。某些特征名称可以作为形容词出现在文本中，例如月球
陨石坑有黑色、绿色和白色。某些功能名称在其他上下文中用作
方向，就像月球上西边和南边的陨石坑。此外，一些
不同天体的特征共享相同的名称，要求
消歧义，例如月球和月球上都存在的亚当斯陨石坑
火星。我们提出了一个结合基于规则的过滤的多步骤管道，
统计相关性分析、词性 (POS) 标记、命名实体
识别（NER）模型、混合关键词收获、知识图谱（KG）
与本地安装的大语言模型（LLM）进行匹配和推理
尽管存在这些挑战，但仍能可靠地识别行星名称。当评估
天体物理学数据系统（ADS）的天文学论文数据集，这个
该方法在消除行星特征歧义方面取得了超过 0.97 的 F1 分数
名称。
]]></description>
      <guid>http://arxiv.org/abs/2312.08579</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>ZeroQuant(4+2)：通过针对多样化生成任务的新的以 FP6 为中心的策略重新定义法学硕士量化。 （arXiv：2312.08583v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08583</link>
      <description><![CDATA[这项研究探讨了大型语言中的 4 位量化方法，例如 GPTQ
模型（法学硕士），强调了 GPTQ 的过度拟合和有限的增强
零射击任务。虽然之前的工作仅仅关注零样本测量，但我们
将任务范围扩展到更具生成性的类别，例如代码生成和
抽象总结，其中我们发现INT4量化可以
表现明显不佳。然而，只需转向更高精度
像 FP6 这样的格式特别具有挑战性，因此被忽视，因为
由于缺乏复杂的集成和系统而导致性能不佳
当前人工智能硬件上的加速策略。我们的结果表明 FP6，甚至
采用粗粒度量化方案，在各种
算法和任务，展示了其在准确性和准确性方面的优越性
多功能性。值得注意的是，通过 FP6 量化，\codestar-15B 模型执行
与代码生成方面的 FP16 版本相当，并且适用于较小的模型
与 406M 一样，它在总结方面与他们的基线非常匹配。也不可以
通过INT4来实现。为了更好的适配各种AI硬件，实现
最佳系统性能，我们为 FP6 提出了一种新颖的 4+2 设计来实现
与最先进的 INT4 细粒度量化类似的延迟。跟我们
设计上，FP6可以成为当前4位量化的一个有前途的解决方案
法学硕士中使用的方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.08583</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>揭示知识蒸馏的关键因素。 （arXiv：2312.08585v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08585</link>
      <description><![CDATA[知识蒸馏，一种模型压缩和性能技术
增强，在神经机器翻译领域获得了巨大的关注
（神经机器翻译）。然而，现有的研究主要集中于实证应用，
对学生如何建模缺乏全面的了解
容量、数据复杂性和解码策略共同影响
蒸馏效率。为了解决这一差距，我们的研究进行了深入
调查这些因素，特别关注它们之间的相互作用
NMT 中的字级和序列级蒸馏。通过广泛
跨数据集进行实验，例如 IWSLT13 En$\rightarrow$Fr、IWSLT14
En$\rightarrow$De 等人，我们凭经验验证与以下相关的假设
这些因素对知识蒸馏的影响。我们的研究不仅
阐明了模型容量、数据复杂性和
关于蒸馏有效性的解码策略还引入了一种新颖的，
优化的蒸馏方法。当应用于 IWSLT14 时，该方法
de$\rightarrow$en 翻译任务，实现了最先进的性能，
展示了其在推进 NMT 领域的实际功效。
]]></description>
      <guid>http://arxiv.org/abs/2312.08585</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>超越准确性：大型现实世界临床文本数据集的自动去识别。 （arXiv：2312.08495v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08495</link>
      <description><![CDATA[最近的研究进展实现了人类级别的去识别准确度
关于研究数据集的自由文本临床记录，但在复制方面仍存在差距
这是在大型现实世界环境中。本文总结了经验教训
建立一个系统，用于对超过 10 亿条真实临床记录进行去识别处理
完全自动化的方式，经过多个独立认证
生产用途的组织。完全自动化的解决方案需要非常
准确度高，无需人工审核。混合动力
描述了基于上下文的模型架构，其性能优于命名实体
识别 (NER) - 仅在 i2b2-2014 基准上提高 10% 的模型。拟议的
与同类 AWS、Azure、
和 GCP 服务，同时也比 ChatGPT 好 33%。它
跨 7 种欧洲语言的敏感数据覆盖率超过 98%，无需
需要进行微调。第二组描述的模型支持数据混淆
-- 用随机代理替换敏感数据 -- 同时保留名称，
日期、性别、临床和格式一致性。无论是实际需要还是
提供可靠且可靠的解决方案架构链接的匿名文档
进行了描述。
]]></description>
      <guid>http://arxiv.org/abs/2312.08495</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>在自然语言指导下学习自适应规划表示。 （arXiv：2312.08566v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.08566</link>
      <description><![CDATA[现实世界中的有效规划不仅需要世界知识，还需要
能够利用这些知识来构建正确的表示形式
手头的任务。几十年来，分层规划技术已被使用
特定领域的时间动作抽象，以支持高效和准确
规划，几乎总是依赖人类先验和领域知识
将困难任务分解为适合某个目标或一组目标的较小子问题
目标。本文介绍了 Ada（Action Domain Acquisition），一个用于
使用自动构建特定于任务的规划表示
来自语言模型（LM）的任务一般背景知识。从一个开始
通用分层规划器和低级目标条件策略，
Ada 交互式学习与规划器兼容的高级操作库
适应特定领域的抽象和低级控制器
规划任务。关于两个语言引导的交互式规划基准（Mini
Minecraft 和 ALFRED 家务任务），Ada 明显优于其他
使用 LM 进行顺序决策的方法可以提供更准确的结果
计划和更好地概括复杂的任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.08566</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>探索基于图的作者姓名消歧方法。 （arXiv：2312.08388v1 [cs.SI]）</title>
      <link>http://arxiv.org/abs/2312.08388</link>
      <description><![CDATA[在许多应用中，例如科学文献管理、研究人员
搜索、社交网络分析等、名称消歧（针对
消除 WhoIsWho 的歧义）一直是一个具有挑战性的问题。除此之外
科学文献的增长使这个问题变得更加困难和紧迫。
尽管名称消歧已在学术界进行了广泛研究
行业内，由于数据混乱，问题一直没有得到很好的解决。
同名场景的复杂性。在这项工作中，我们旨在探索
可以使用网络执行名称消歧任务的模型
问题的内在结构并提供对问题的分析
楷模。
]]></description>
      <guid>http://arxiv.org/abs/2312.08388</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>超越英语：评估阿拉伯语语法错误纠正的法学硕士。 （arXiv：2312.08400v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08400</link>
      <description><![CDATA[经过微调以遵循人类指令的大型语言模型 (LLM)
最近在各种英语 NLP 任务中表现出了显着的能力。
然而，它们在语法错误纠正（GEC）方面的表现，尤其是在
除英语以外的其他语言仍然有待探索。在这项工作中，
我们评估阿拉伯语 GEC 教学微调法学硕士的能力，
由于阿拉伯语丰富的形态，这项任务非常复杂。我们的研究结果表明，各种
提示方法，加上（上下文中的）小样本学习，展示
相当有效，GPT-4 得分高达 $65.49$ F$_{1}$
在专家提示下（比我们既定的点高出约 5 美元点）
基线）。尽管取得了这些积极的成果，但我们发现教学进行了微调
模型，无论其大小如何，仍然优于完全微调的模型
，即使它们的尺寸要小得多。这种差距凸显
LLM 的改进空间很大。受到所使用方法的启发
低资源机器翻译，我们还开发了一种利用合成的方法
数据在两种标准阿拉伯语上的表现明显优于以前的模型
基准。我们最好的模型在阿拉伯语 GEC 上取得了新的 SOTA，价格为 73.29 美元，
与 2014 年和 2015 年 QALB 数据集相比，分别为 $73.26$ F$_{1}$
同行评审的已发布基线。
]]></description>
      <guid>http://arxiv.org/abs/2312.08400</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    </channel>
</rss>