<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 23 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>公平文本嵌入的内容条件去偏</title>
      <link>https://arxiv.org/abs/2402.14208</link>
      <description><![CDATA[arXiv:2402.14208v1 公告类型：新
摘要：减轻机器学习模型中的偏差在自然语言处理（NLP）领域受到越来越多的关注。然而，只有少数研究关注公平文本嵌入，这对于现实世界的应用至关重要但具有挑战性。在本文中，我们提出了一种学习公平文本嵌入的新方法。我们通过确保敏感属性和以内容为条件的文本嵌入之间的条件独立性来实现公平，同时保持效用权衡。具体来说，我们强制具有不同敏感属性但相同内容的文本的嵌入与其相应的中性文本的嵌入保持相同的距离。此外，我们通过使用大型语言模型（LLM）将文本扩展到不同的敏感群体来解决缺乏适当训练数据的问题。我们的广泛评估表明，我们的方法有效地提高了公平性，同时保留了嵌入的实用性，代表了在实现公平文本嵌入的条件独立性方面的开创性努力。]]></description>
      <guid>https://arxiv.org/abs/2402.14208</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>有支持数据的框架：美国经济新闻的案例研究</title>
      <link>https://arxiv.org/abs/2402.14224</link>
      <description><![CDATA[arXiv:2402.14224v1 公告类型：新
摘要：主流媒体在选择报道内容和报道方式方面有很大的回旋余地。这些选择会对人们的认知及其后续行为产生现实影响。然而，缺乏评估编辑选择的客观措施使得这一领域的研究特别困难。在本文中，我们认为存在有新闻价值的主题，其中客观测量以支持数据的形式存在，并提出了一个计算框架来分析这种设置中的编辑选择。我们关注经济，因为经济指标的报告为我们提供了一种相对简单的方法来确定各种出版物的选择和框架。他们的价值观提供了经济运行状况以及出版物选择报道方式的基本事实。为此，我们将帧预测定义为一组相互依赖的任务。在文章层面，我们学习识别所报道的对经济总体状况的立场。然后，对于文章中报告的每个数字，我们学会识别它是否与经济指标相对应，以及它是以积极还是消极的方式报告的。为了进行分析，我们跟踪了 6 家美国出版商以及 2015 年至 2023 年间出现在其登陆页面前 10 位的每篇文章。]]></description>
      <guid>https://arxiv.org/abs/2402.14224</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>理解咨询对话：领域知识和大型语言模型</title>
      <link>https://arxiv.org/abs/2402.14200</link>
      <description><![CDATA[arXiv:2402.14200v1 公告类型：新
摘要：理解咨询对话的动态是一项重要任务，但尽管基于 Transformer 的预训练语言模型最近取得了进展，但它仍然是一个具有挑战性的 NLP 问题。本文提出了一种系统方法来检查领域知识和大型语言模型（LLM）在更好地表示危机咨询师和寻求帮助者之间的对话方面的有效性。我们的经验表明，最先进的语言模型（例如基于 Transformer 的模型和 GPT 模型）无法预测对话结果。为了为对话提供更丰富的上下文，我们结合了人工注释的领域知识和法学硕士生成的特征；领域知识和 LLM 功能的简单集成可将模型性能提高约 15%。我们认为，当将领域知识和法学硕士生成的特征用作对话的附加上下文时，可以利用它们来更好地描述咨询对话的特征。]]></description>
      <guid>https://arxiv.org/abs/2402.14200</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型协助从头开始编写类似维基百科的文章</title>
      <link>https://arxiv.org/abs/2402.14207</link>
      <description><![CDATA[arXiv:2402.14207v1 公告类型：新
摘要：我们研究如何应用大型语言模型从头开始编写扎根且有组织的长篇文章，其广度和深度与维基百科页面相当。这个尚未充分探讨的问题在写作前阶段提出了新的挑战，包括如何在写作前研究主题并准备大纲。我们提出了 STORM，一种通过检索和多视角提问来综合主题大纲的写作系统。 STORM 通过以下方式对预写作阶段进行建模：(1) 在研究给定主题时发现不同的观点，(2) 模拟对话，持不同观点的作者向基于可信互联网来源的主题专家提出问题，(3) 整理收集到的信息创建一个轮廓。
  为了进行评估，我们策划了 FreshWiki（最新高质量维基百科文章的数据集），并制定了大纲评估来评估预写作阶段。我们进一步收集经验丰富的维基百科编辑的反馈。与由大纲驱动的检索增强基线生成的文章相比，STORM 的更多文章被认为是有组织的（绝对增加了 25%）并且覆盖范围广泛（增加了 10%）。专家反馈还有助于识别生成接地气的长文章的新挑战，例如来源偏见转移和不相关事实的过度关联。]]></description>
      <guid>https://arxiv.org/abs/2402.14207</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>TOOLVERIFIER：通过自我验证推广新工具</title>
      <link>https://arxiv.org/abs/2402.14158</link>
      <description><![CDATA[arXiv:2402.14158v1 公告类型：新
摘要：教授语言模型使用工具是构建通用助理的一个重要里程碑，但仍然是一个悬而未决的问题。尽管在通过微调学习使用特定工具方面取得了重大进展，但语言模型仍然难以通过少数演示来学习如何稳健地使用新工具。在这项工作中，我们引入了一种自我验证方法，该方法通过在（1）工具选择过程中自问对比问题来区分相近的候选者； (2)参数生成。我们使用 Llama-2 70B 构建合成的、高质量的、自行生成的数据，并打算公开发布。对 ToolBench 基准测试中的 4 个任务（包括 17 个未见过的工具）进行的广泛实验表明，即使在候选工具之间的差异非常细微的情况下，也比少数样本基线平均提高了 22%。]]></description>
      <guid>https://arxiv.org/abs/2402.14158</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>Bangla AI：利用大型语言模型进行民族媒体的机器翻译框架</title>
      <link>https://arxiv.org/abs/2402.14179</link>
      <description><![CDATA[arXiv:2402.14179v1 公告类型：新
摘要：少数民族媒体迎合东道国的侨民社区，是这些社区制作内容和获取信息的重要平台。少数民族媒体不是使用东道国的语言，而是使用移民社区的语言来传播新闻。例如，在美国，孟加拉族媒体用孟加拉语而不是英语播放新闻。这项研究深入探讨了大语言模型 (LLM) 和多语言机器翻译 (MMT) 在民族媒体行业内的前瞻性整合。它的重点是在新闻翻译、搜索和分类的各个方面使用 MMT 中的法学硕士的变革潜力。本文概述了一个理论框架，阐明了法学硕士和现代机器翻译在少数民族媒体新闻搜索和翻译过程中的整合。此外，它还简要讨论了将 LLM 和 MMT 纳入新闻翻译程序所带来的潜在道德挑战。]]></description>
      <guid>https://arxiv.org/abs/2402.14179</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>学习减少：结构化数据在提示大型语言模型中的最佳表示</title>
      <link>https://arxiv.org/abs/2402.14195</link>
      <description><![CDATA[arXiv:2402.14195v1 公告类型：新
摘要：大型语言模型（LLM）已被广泛用作通用人工智能代理，在许多下游任务上表现出可比的性能。然而，现有的工作表明，法学硕士将结构化数据（例如知识图谱、表格、数据库）集成到他们的提示中具有挑战性；法学硕士需要理解长文本数据或在推理之前选择最相关的证据，这两种方法都不是微不足道的。
  在本文中，我们提出了一个框架“学习减少”，该框架可以在给定任务描述和上下文输入的情况下微调语言模型以生成输入上下文的简化版本。该模型学习使用策略强化学习来减少输入上下文，旨在提高固定 LLM 的推理性能。实验结果表明，我们的模型不仅在从输入上下文中选择相关证据方面达到了相当的准确性，而且还显示了在不同数据集上的普遍性。我们进一步表明，我们的模型有助于提高法学硕士在下游任务上的表现，尤其是在上下文很长的情况下。]]></description>
      <guid>https://arxiv.org/abs/2402.14195</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>MM-Soc：社交媒体平台中多模态大型语言模型的基准测试</title>
      <link>https://arxiv.org/abs/2402.14154</link>
      <description><![CDATA[arXiv:2402.14154v1 公告类型：新
摘要：社交媒体平台是多模式信息交换的中心，包括文本、图像和视频，这使得机器难以理解与在线空间交互相关的信息或情感。多模态大型语言模型 (MLLM) 已成为解决这些挑战的有前途的解决方案，但难以准确解释人类情感和错误信息等复杂内容。本文介绍了 MM-Soc，这是一个综合基准，旨在评估 MLLM 对多模式社交媒体内容的理解。 MM-Soc 编译了著名的多模态数据集，并合并了一个新颖的大规模 YouTube 标记数据集，针对错误信息检测、仇恨言论检测和社交上下文生成等一系列任务。通过对四个开源 MLLM 的十个尺寸变体的详尽评估，我们发现了显着的性能差异，强调了模型社会理解能力进步的必要性。我们的分析表明，在零样本环境中，各种类型的 MLLM 在处理社交媒体任务时通常表现出困难。然而，MLLM 展示了微调后的性能改进，表明了潜在的改进途径。]]></description>
      <guid>https://arxiv.org/abs/2402.14154</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>基于相似性的域排序可以减少意图识别的灾难性遗忘吗？</title>
      <link>https://arxiv.org/abs/2402.14155</link>
      <description><![CDATA[arXiv:2402.14155v1 公告类型：新
摘要：面向任务的对话系统预计能够处理不断扩展的意图和领域，即使它们已被部署以支持越来越多的功能。为了实现这一期望，缓解在意图识别等任务的持续学习 (CL) 设置中发生的灾难性遗忘问题 (CF) 变得至关重要。尽管现有的对话系统研究已经为此探索了基于重放和基于正则化的方法，但领域排序对意图识别模型的 CL 性能的影响仍未得到探索。如果理解得好，域排序有可能成为一种正交技术，可以与经验重放等现有技术一起使用。我们的工作通过比较三种域排序策略（最小和路径、最大和路径、随机）对生成意图识别模型的 CL 性能的影响来填补这一空白。我们的研究结果表明，在 220M T5-Base 模型上进行训练时，最小和路径策略在减少灾难性遗忘方面优于其他策略。然而，随着更大的 770M T5-Large 型号的出现，这一优势会减弱。这些结果强调了领域排序作为一种补充策略的潜力，可以减轻持续学习意图识别模型中的灾难性遗忘，特别是在资源有限的情况下。]]></description>
      <guid>https://arxiv.org/abs/2402.14155</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>FanOutQA：大型语言模型的多跳、多文档问答</title>
      <link>https://arxiv.org/abs/2402.14116</link>
      <description><![CDATA[arXiv:2402.14116v1 公告类型：新
摘要：日常场景中常见的一类问题是“扇出”问题，即复杂的多跳、多文档推理问题，需要查找大量实体的信息。然而，很少有资源来评估大型语言模型中的此类问答能力。为了更全面地评估法学硕士中的复杂推理，我们提出了 FanOutQA，这是一个以英语维基百科为知识库的扇出问答对和人工注释分解的高质量数据集。我们在数据集和基准 7 个 LLM 中制定了三个基准设置，包括 GPT-4、LLaMA 2、Claude-2.1 和 Mixtral-8x7B，发现当代模型仍然有空间改进长上下文中文档间依赖关系的推理。我们提供数据集和开源工具来运行模型，以鼓励在 https://fanoutqa.com 上进行评估]]></description>
      <guid>https://arxiv.org/abs/2402.14116</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>具有动态多奖励权重的强化学习，用于多风格可控生成</title>
      <link>https://arxiv.org/abs/2402.14146</link>
      <description><![CDATA[arXiv:2402.14146v1 公告类型：新
摘要：风格是文本的一个组成部分，它表达多种信息，包括人际动态（例如形式）和作者的情感或态度（例如厌恶）。人类经常同时采用多种风格。一个悬而未决的问题是，如何显式控制大型语言模型，以便它们在生成文本时将目标样式编织在一起：例如，生成负面且无毒的文本。以前的工作研究了单个样式的受控生成，或者样式和其他属性的受控生成。在本文中，我们将其扩展为同时控制多种样式。具体来说，我们研究了用于控制多风格生成的强化学习（RL）方法的多种风格奖励的各种公式。这些奖励公式包括鉴别器的校准输出和鉴别器梯度大小的动态加权。我们发现动态加权通常优于静态加权方法，并且我们探索了其在 2 型和 3 型控制中的有效性，甚至与即插即用模型等强基线相比也是如此。具有多种样式属性的 RL 管道的所有代码和数据都将公开。]]></description>
      <guid>https://arxiv.org/abs/2402.14146</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>LexC-Gen：利用大型语言模型和双语词典为资源极少的语言生成数据</title>
      <link>https://arxiv.org/abs/2402.14086</link>
      <description><![CDATA[arXiv:2402.14086v1 公告类型：新
摘要：可以通过使用双语词典对高资源语言的标记任务数据进行逐字翻译来解决低资源语言的数据稀缺问题。然而，双语词典通常与任务数据的词汇重叠有限，这导致翻译覆盖率和词典利用率较差。我们提出了词典条件数据生成（LexC-Gen），这是一种大规模生成低资源语言分类任务数据的方法。具体来说，LexC-Gen首先使用双语词典中的高资源语言单词生成词典兼容的任务数据，然后通过单词翻译将其翻译为双语词典中的低资源语言。在 17 种资源极少的语言中，LexC-Gen 生成的数据与专家翻译的黄金数据具有竞争力，并且在情感分析和主题分类任务上比现有的基于词典的单词翻译方法平均分别提高了 5.6 和 8.9 个百分点。我们证明双语词典的调节是 LexC-Gen 的关键组成部分。 LexC-Gen 也很实用——它只需要一个 GPU 即可大规模生成数据。它与开放获取的法学硕士配合良好，其成本是基于 GPT4 的多语言数据生成成本的五分之一。]]></description>
      <guid>https://arxiv.org/abs/2402.14086</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>通过少镜头注释器适应进行经济高效的主观任务注释和建模</title>
      <link>https://arxiv.org/abs/2402.14101</link>
      <description><![CDATA[arXiv:2402.14101v1 公告类型：新
摘要：在主观 NLP 任务中，不存在单一的基本事实，因此包含不同的注释者变得至关重要，因为他们独特的视角会显着影响注释。在现实场景中，注释预算通常成为数据和后续建模中包含的视角（即注释者）数量的主要决定因素。我们引入了一种新颖的框架，用于主观任务中的注释收集和建模，旨在最小化注释预算，同时最大化每个注释者的预测性能。我们的框架有两个阶段的设计：首先，我们依靠一小组注释器来构建多任务模型，其次，我们通过策略性地为每个注释器注释一些样本来增强模型以获得新的视角。为了大规模测试我们的框架，我们引入并发布了一个独特的数据集，即道德基础主观语料库，其中包含由 24 名道德情感注释者注释的 2000 篇 Reddit 帖子。我们证明，我们的框架在捕获注释者的个人观点方面超越了之前的 SOTA，而在两个数据集上仅用了原始注释预算的 25%。此外，我们的框架产生了更公平的模型，减少了注释者之间的性能差异。]]></description>
      <guid>https://arxiv.org/abs/2402.14101</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>利用仅编码器预训练语言模型来有效生成关键短语</title>
      <link>https://arxiv.org/abs/2402.14052</link>
      <description><![CDATA[arXiv:2402.14052v1 公告类型：新
摘要：本研究讨论了仅编码器预训练语言模型 (PLM) 在关键短语生成 (KPG) 中的应用，与编码器-解码器模型相比，仅域定制编码器模型的可用性更广泛。我们研究了三个核心问题：(1) KPG 中仅编码器 PLM 的功效，(2) 在 KPG 中采用仅编码器 PLM 的最佳架构决策，以及 (3) 域内仅编码器与编码器之间的性能比较- 跨不同资源设置的 PLM 解码器。我们的研究结果来自两个领域的广泛实验，结果表明，对于仅编码器的 PLM，尽管具有条件随机字段的 KPE 在识别当前关键短语方面略胜一筹，但 KPG 公式可呈现更广泛的关键短语预测。此外，仅编码器 PLM 的前缀 LM 微调成为 KPG 的强大且数据高效的策略，其性能优于通用域 seq2seq PLM。当采用仅编码器 PLM 初始化的编码器-解码器架构时，我们还确定了针对模型深度而不是宽度的有利参数分配。该研究揭示了利用仅编码器的 PLM 来推进 KPG 系统的潜力，并为未来的 KPG 方法奠定了基础。我们的代码和预训练的检查点发布在 https://github.com/uclanlp/DeepKPG。]]></description>
      <guid>https://arxiv.org/abs/2402.14052</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>从屏幕截图提高语言理解</title>
      <link>https://arxiv.org/abs/2402.14073</link>
      <description><![CDATA[arXiv:2402.14073v1 公告类型：新
摘要：新兴的语言模型 (LM) 系列能够在单个视觉视图中处理文本和图像，有望解锁图表理解和 UI 导航等复杂任务。我们将这些模型称为屏幕截图语言模型。尽管它们很有吸引力，但现有的屏幕截图 LM 在语言理解任务上远远落后于纯文本模型。为了弥补这一差距，我们采用了一种简化的设置，其中模型输入是纯文本渲染的屏幕截图，并且我们专注于提高屏幕截图 LM 的文本能力。我们提出了一种新颖的补丁和文本预测（PTP）目标，它可以掩盖并恢复屏幕截图的图像补丁和屏幕截图中的文本。我们还对掩蔽率和补丁大小进行了广泛的消融研究，以及提高训练稳定性的设计。我们的预训练模型在仅采用视觉输入的情况下，在 8 个 GLUE 任务中的 6 个上实现了与 BERT 相当的性能（2% 以内），并且比之前的工作提高了 8%。此外，我们扩展 PTP 来训练自回归屏幕截图 LM 并证明其有效性——我们的模型可以通过利用屏幕截图上下文显着减少困惑。我们希望我们的发现能够激励未来的研究，开发强大的屏幕截图语言模型并将其扩展到更广泛的应用。]]></description>
      <guid>https://arxiv.org/abs/2402.14073</guid>
      <pubDate>Fri, 23 Feb 2024 06:17:30 GMT</pubDate>
    </item>
    </channel>
</rss>