<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Thu, 28 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>语言模型中非事实幻觉的机制</title>
      <link>https://arxiv.org/abs/2403.18167</link>
      <description><![CDATA[arXiv:2403.18167v1 公告类型：新
摘要：最先进的语言模型（LM）有时会产生与世界知识不一致的非事实幻觉。尽管在检测和减轻幻觉方面做出了广泛的努力，但了解其内部机制仍然难以捉摸。我们的研究调查了幻觉的机制原因，特别是非事实幻觉，其中机器学习错误地预测了对象属性以响应主题关系查询。通过因果中介分析和嵌入空间投影，我们确定了不同规模和设计的 LM 之间共有的幻觉的两个一般机制原因：1）下层 MLP 中的主题属性知识不足，2）未能在上层中选择正确的对象属性注意力头和 MLP。这两种机制表现出不同程度的主客关联、预测不确定性和扰动鲁棒性。此外，我们仔细检查了 LM 预训练检查点，揭示了幻觉的两种机械原因的不同学习动态。我们还强调了因果分析中的归因特征如何有效地构建幻觉检测器。我们的工作提出了对 LM 事实错误的机械理解。]]></description>
      <guid>https://arxiv.org/abs/2403.18167</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>作为金融数据注释器的大型语言模型：有效性和效率的研究</title>
      <link>https://arxiv.org/abs/2403.18152</link>
      <description><![CDATA[arXiv:2403.18152v1 公告类型：新
摘要：由于领域专家的稀缺和雇用成本较高，收集金融领域的标记数据集具有挑战性。虽然大型语言模型（LLM）在通用领域数据集的数据注释任务中表现出了卓越的性能，但它们在特定领域数据集上的有效性仍未得到充分探索。为了解决这一差距，我们研究了法学硕士作为提取财务文档中关系的有效数据注释器的潜力。我们将三个法学硕士（GPT-4、PaLM 2 和 MPT Instruct）生成的注释与专家注释者和众包工作者进行比较。我们证明，当前最先进的法学硕士足以替代非专家众包工作者。我们使用各种提示和参数设置来分析模型，发现通过提供属于这些组的特定示例来自定义每个关系组的提示至关重要。此外，我们引入了可靠性指数（LLM-RelIndex），用于识别可能需要专家关注的输出。最后，我们进行了大量的时间、成本和错误分析，并为在特定领域的设置中收集和使用自动注释提供建议。]]></description>
      <guid>https://arxiv.org/abs/2403.18152</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>Juru：来自可靠来源的合法巴西大语言模型</title>
      <link>https://arxiv.org/abs/2403.18140</link>
      <description><![CDATA[arXiv:2403.18140v1 公告类型：新
摘要：与预训练大型语言模型相关的高计算成本限制了他们的研究。为了解决这个问题，出现了两种策略：领域专业化和使用高质量数据进行预训练。为了探索这些策略，我们专门使用了来自巴西著名法律来源的 19 亿个独特代币的 Sabi&#39;a-2 Small 模型，并对法律和常识考试进行了几次评估。我们的模型 Juru 展示了领域专业化和减少预训练数据量的好处。然而，这种专业化是以降低同一语言中其他知识领域的性能为代价的。这项研究提供了越来越多的科学证据，表明预训练数据选择可以提高大型语言模型的性能，从而以较低的成本探索这些模型。]]></description>
      <guid>https://arxiv.org/abs/2403.18140</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型产生被认为具有同理心的响应</title>
      <link>https://arxiv.org/abs/2403.18148</link>
      <description><![CDATA[arXiv:2403.18148v1 公告类型：新
摘要：大型语言模型（LLM）在许多任务上都表现出了令人惊讶的表现，包括编写表现出同理心的支持性信息。在这里，我们让这些模型生成移情信息，以响应描述常见生活经历的帖子，例如工作场所情况、养育子女、人际关系以及其他引起焦虑和愤怒的情况。在两项研究 (N=192, 202) 中，我们向人类评分者展示了由多个模型（GPT4 Turbo、Llama2 和 Mistral）编写的各种回复，并让人们根据这些回复的共情程度进行评分。我们发现，法学硕士生成的回复始终被认为比人类撰写的回复更具同理心。语言分析还表明，这些模型在标点符号、表情符号和某些单词的使用方面以独特的、可预测的“风格”写作。这些结果凸显了在同理心很重要的情况下使用法学硕士来增强人类同伴支持的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.18148</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 角色扮演数据集：用户动机和模型自然度分析</title>
      <link>https://arxiv.org/abs/2403.18121</link>
      <description><![CDATA[arXiv:2403.18121v1 公告类型：新
摘要：像 ChatGPT 这样的交互式大语言模型的最新进展已经彻底改变了各个领域；然而，他们在自然和角色扮演对话环境中的行为仍未得到充分研究。在我们的研究中，我们通过分析 ChatGPT 在正常方式和角色扮演环境下的交互，深入研究 ChatGPT 在不同环境下的对话中的行为，从而解决了这一差距。我们引入了一个包含广泛人类与人工智能对话的新颖数据集，并标注了用户动机和模型自然性，以检查（i）人类如何与对话式人工智能模型互动，以及（ii）人工智能模型响应的自然程度。我们的研究强调了与 ChatGPT 交互时用户动机的多样性和可变的人工智能自然度，不仅展示了人类与人工智能之间自然对话的微妙动态，而且还为提高人类与人工智能通信的有效性提供了新途径。]]></description>
      <guid>https://arxiv.org/abs/2403.18121</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>对于那些不知道（如何）提问的人：为数字新手构建技术问题数据集</title>
      <link>https://arxiv.org/abs/2403.18125</link>
      <description><![CDATA[arXiv:2403.18125v1 公告类型：新
摘要：虽然大型语言模型（LLM）的兴起创造了丰富的学习数字技术的新机会，但许多处于该技术边缘的人由于词汇或概念障碍而无法提出适当的问题，因此难以获得和保持能力。尽管已经做出了很多努力来了解法学硕士创建内容的真实性以及法学硕士回答问题的能力，但尚不清楚不明确或不标准的语言查询如何影响模型输出。我们建议创建一个数据集，利用我们从十年的一对一辅导中收集的数据来捕获数字新手和局外人的问题。在本文中，我们列出了我们计划的工作以及该数据集的一些潜在用途。]]></description>
      <guid>https://arxiv.org/abs/2403.18125</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>GPT 和语言障碍：跨语言法律 QA 考试</title>
      <link>https://arxiv.org/abs/2403.18098</link>
      <description><![CDATA[arXiv:2403.18098v1 公告类型：新
摘要：在本文中，我们使用 COLIEE Task 4 数据集探索了生成式预训练 Transformer (GPT) 在跨语言法律问答 (QA) 系统中的应用。在 COLIEE 任务 4 中，给定一个陈述和一组作为上下文的相关法律文章，目标是确定该陈述是否具有法律效力，即是否可以从提供的上下文文章中推断出该陈述，即也称为蕴含任务。通过对英语和日语提示和数据的四种不同组合进行基准测试，我们为 GPT 在多语言法律 QA 场景中的表现提供了宝贵的见解，有助于在法律领域开发更高效、更准确的跨语言 QA 解决方案。]]></description>
      <guid>https://arxiv.org/abs/2403.18098</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>用于教育的大型语言模型：调查与展望</title>
      <link>https://arxiv.org/abs/2403.18105</link>
      <description><![CDATA[arXiv:2403.18105v1 公告类型：新
摘要：大型语言模型（LLM）的出现为教育领域带来了一个充满可能性的新时代。本调查论文从多方面的角度总结了法学硕士在教育环境中的各种技术，包括学生和教师帮助、适应性学习和商业工具。我们系统地回顾每个角度的技术进步，组织相关数据集和基准，并确定与在教育中部署法学硕士相关的风险和挑战。此外，我们概述了未来的研究机会，强调了潜在的有前途的方向。我们的调查旨在为教育工作者、研究人员和政策制定者提供全面的技术图景，以利用法学硕士的力量彻底改变教育实践并营造更有效的个性化学习环境。]]></description>
      <guid>https://arxiv.org/abs/2403.18105</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>COIG-CQIA：中文教学微调只需要质量</title>
      <link>https://arxiv.org/abs/2403.18058</link>
      <description><![CDATA[arXiv:2403.18058v1 公告类型：新
摘要：最近，大型语言模型（LLM）取得了重大进展，特别是英语。这些进步使这些法学硕士能够以前所未有的准确性和流畅性理解和执行复杂的指令。然而，尽管取得了这些进步，中文指令调优的发展仍然存在明显差距。汉语独特的语言特征和文化深度给教学调整任务带来了挑战。现有的数据集要么源自以英语为中心的法学硕士，要么不适合与现实世界的中国用户的交互模式保持一致。为了弥补这一差距，我们引入了 COIG-CQIA，一个高质量的中文指令调优数据集。我们的目标是建立一个多样化、广泛的指令调整数据集，以更好地使模型行为与人类交互保持一致。为此，我们从中国互联网上的各种来源收集了高质量的人类编写的语料库，包括问答社区、维基百科、考试和现有的 NLP 数据集。该语料库经过严格过滤和仔细处理，形成 COIG-CQIA 数据集。此外，我们在深入评估和分析后，在 CQIA 的不同子集上训练各种规模的模型。我们的实验结果为选择和开发中文指令调整数据集提供了宝贵的见解。我们还发现，在 CQIA-Subset 上训练的模型在人类评估以及知识和安全基准方面取得了有竞争力的结果。数据可在 https://huggingface.co/datasets/m-a-p/COIG-CQIA 获取]]></description>
      <guid>https://arxiv.org/abs/2403.18058</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>增强法律文档检索：采用大型语言模型的多阶段方法</title>
      <link>https://arxiv.org/abs/2403.18093</link>
      <description><![CDATA[arXiv:2403.18093v1 公告类型：新
摘要：具有数十亿参数的大型语言模型，例如 GPT-3.5、GPT-4 和 LLaMA，越来越流行。许多研究探索了有效的激励技术，以利用这些法学硕士的力量来解决各种研究问题。由于法律文章数量庞大、篇幅较长，检索，特别是在法律数据领域，对直接应用提示技术提出了一项具有挑战性的任务。这项研究的重点是通过将提示作为检索系统的最后阶段来最大化提示的潜力，之前有两个阶段的支持：BM25 预排序和基于 BERT 的重新排序。在 COLIEE 2023 数据集上的实验表明，将法学硕士的提示技术集成到检索系统中可以显着提高检索准确性。然而，错误分析揭示了检索系统中存在的几个仍需要解决的问题。]]></description>
      <guid>https://arxiv.org/abs/2403.18093</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>句法和语义邻近性对回译机器翻译的影响</title>
      <link>https://arxiv.org/abs/2403.18031</link>
      <description><![CDATA[arXiv:2403.18031v1 公告类型：新
摘要：无监督即时反向翻译与多语言预训练相结合，是无监督神经机器翻译的主要方法。然而，从理论上讲，该方法一般不应该起作用。因此，我们用人工语言进行受控实验，以确定语言的哪些属性使反向翻译成为有效的训练方法，涵盖词汇、句法和语义属性。我们发现，与普遍的看法相反，（i）平行的词频分布，（ii）部分共享的词汇，以及（iii）跨语言的相似句法结构不足以解释回译的成功。然而，我们表明，即使是粗略的语义信号（跨语言的相似词汇字段）也确实可以通过回译改善两种语言的对齐。我们推测，跨语言并行的丰富语义依赖性是基于反向翻译的无监督方法成功的根源。总体而言，无监督机器翻译的成功远不能从分析上得到保证。相反，它是世界语言具有深刻相似性的另一个证据，我们希望展示如何识别这些相似性中的哪些可以服务于无监督的跨语言工具的开发。]]></description>
      <guid>https://arxiv.org/abs/2403.18031</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>监管即时培训</title>
      <link>https://arxiv.org/abs/2403.18051</link>
      <description><![CDATA[arXiv:2403.18051v1 公告类型：新
摘要：大型语言模型（LLM）的性能在很大程度上依赖于提示的质量，这些提示通常是手动设计的并且特定于任务，这使得它们成本高昂且不可扩展。我们提出了一种新颖的方法，即监督即时培训（SPT）。 SPT 使用双 LLM 系统自动生成高效的提示。在这个系统中，一个法学硕士（生成器）执行一项任务，而另一个法学硕士（校正器）提供反馈并生成改进的提示。与早期的技术相比，生成器和校正器随着时间的推移协作并不断改进其提示。我们还引入了 \textit{影响分数} 的概念来衡量提示的句子级有效性。我们的方法在四个基准上进行了测试，测试了法学硕士的幻觉水平。值得注意的是，我们能够将 GSM8K 上的 GPT-4 准确率从 65.8% 提高到 94.1%（提高了 28.3%）。 SPT 通过完善提示来提高表现和减少幻觉，从而为传统模型微调提供高效且可扩展的替代方案，从而推动法学硕士的发展。]]></description>
      <guid>https://arxiv.org/abs/2403.18051</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>DORE：葡萄牙语定义生成数据集</title>
      <link>https://arxiv.org/abs/2403.18018</link>
      <description><![CDATA[arXiv:2403.18018v1 公告类型：新
摘要：定义建模（DM）是自动生成特定单词的字典定义的任务。具有 DM 能力的计算系统可以有许多应用程序，使广泛的受众受益。由于 DM 被认为是一个有监督的自然语言生成问题，因此这些系统需要大量带注释的数据集来训练机器学习 (ML) 模型。已经发布了英语和其他高资源语言的多个 DM 数据集。虽然葡萄牙语在大多数自然语言处理任务中被认为是中/高资源语言，并且有超过 2 亿的母语使用者使用葡萄牙语，但没有适用于葡萄牙语的 DM 数据集。在本研究中，我们通过引入 DORE 来填补这一空白；第一个 PoRtuguEse 定义建模数据集，包含超过 100,000 个定义。我们还在 DORE 上评估了几种基于深度学习的 DM 模型并报告了结果。本文的数据集和研究结果将促进更广泛背景下的葡萄牙语研究。]]></description>
      <guid>https://arxiv.org/abs/2403.18018</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>使用聚类定义丰富单词使用图</title>
      <link>https://arxiv.org/abs/2403.18024</link>
      <description><![CDATA[arXiv:2403.18024v1 公告类型：新
摘要：我们提出了一个单词使用图（WUG）数据集，其中多种语言的现有 WUG 通过充当语义定义的集群标签进行了丰富。它们是由微调的编码器-解码器语言模型从头开始生成的。进行的人工评估表明，这些定义比两个基线系统从 WordNet 选择的定义更好地匹配 WUG 中的现有集群。同时，该方法使用简单，易于扩展到新语言。由此产生的丰富数据集对于继续进行可解释的语义变化建模非常有帮助。]]></description>
      <guid>https://arxiv.org/abs/2403.18024</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>通过 Mask Specific 损失提高预训练语言模型的敏感性：生物医学 NER 的案例研究</title>
      <link>https://arxiv.org/abs/2403.18025</link>
      <description><![CDATA[arXiv:2403.18025v1 公告类型：新
摘要：使语言模型 (LM) 适应新领域通常是通过在特定领域数据上微调预训练的 LM (PLM) 来实现的。微调将新知识引入 LM，使其能够理解并有效地执行目标领域任务。然而，如果忽略源域和目标域之间的广泛差异（例如词义），微调可能会无意中变得不敏感。例如，诸如“慢性”和“压力”之类的词在社交对话中可能会被轻视，但在临床上，这些词通常是一种担忧的表达。为了解决不敏感的微调问题，我们提出了掩模特定语言建模（MSLM），这是一种通过在微调过程中适当权衡特定领域术语（DS术语）的重要性来有效获取目标领域知识的方法。 MSLM 联合屏蔽 DS 术语和通用单词，然后通过确保 LM 因预测 DS 术语（与通用单词相比）不准确而受到更大的惩罚来学习特定于掩模的损失。我们的分析结果表明，MSLM 提高了 LM 的灵敏度和 DS 项的检测。我们凭经验表明，最佳掩蔽率不仅取决于 LM，还取决于数据集和序列的长度。我们提出的掩蔽策略优于先进的掩蔽策略，例如基于跨度和 PMI 的掩蔽。]]></description>
      <guid>https://arxiv.org/abs/2403.18025</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:25 GMT</pubDate>
    </item>
    </channel>
</rss>