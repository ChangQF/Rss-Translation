<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 13 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>KEBench：大型视觉语言模型知识编辑的基准</title>
      <link>https://arxiv.org/abs/2403.07350</link>
      <description><![CDATA[arXiv:2403.07350v1 公告类型：新
摘要：目前，针对大视觉语言模型（LVLM）的知识编辑的研究还很少。编辑 LVLM 面临着有效整合不同模式（图像和文本）的挑战，同时确保修改的连贯性和上下文相关性。现有的基准具有三个指标（可靠性、局部性和通用性）来衡量 LVLM 的知识编辑。然而，该基准在评估中使用的生成图像的质量方面存在缺陷，并且无法评估模型是否有效地利用与相关内容相关的编辑知识。我们采用不同的数据收集方法构建新的基准$\textbf{KEBench}$，并扩展新的指标（可移植性）进行综合评估。利用多模态知识图，我们的图像数据表现出针对实体的明确方向性。这个方向性可以进一步用于提取实体相关知识和表单编辑数据。我们在五个 LVLM 上进行了不同编辑方法的实验，并深入分析了这些方法对模型的影响。结果揭示了这些方法的优点和缺点，并希望为未来研究的潜在途径提供见解。]]></description>
      <guid>https://arxiv.org/abs/2403.07350</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>GPT 生成的文本检测：基准数据集和基于张量的检测方法</title>
      <link>https://arxiv.org/abs/2403.07321</link>
      <description><![CDATA[arXiv:2403.07321v1 公告类型：新
摘要：随着像 ChatGPT 这样的自然语言模型在应用程序和服务中变得越来越普遍，对稳健且准确的方法来检测其输出的需求变得至关重要。在本文中，我们提出了 GPT Reddit 数据集 (GRiD)，这是一种新颖的生成预训练 Transformer (GPT) 生成的文本检测数据集，旨在评估检测模型在识别 ChatGPT 生成的响应方面的性能。该数据集由基于 Reddit 的不同上下文提示对集合组成，其中包含人工生成和 ChatGPT 生成的响应。我们对数据集的特征进行分析，包括语言多样性、上下文复杂性和响应质量。为了展示该数据集的实用性，我们对几种检测方法进行了基准测试，证明了它们在区分人类和 ChatGPT 生成的响应方面的功效。该数据集可作为在 ChatGPT 背景下评估和推进检测技术的资源，并有助于确保互联网上负责任且值得信赖的人工智能驱动通信的持续努力。最后，我们提出了 GpTen，一种新颖的基于张量的 GPT 文本检测方法，它本质上是半监督的，因为它只能访问人类生成的文本，并且与完全监督的基线性能相当。]]></description>
      <guid>https://arxiv.org/abs/2403.07321</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>重新思考 ASTE：与对比学习一起的极简标签方案</title>
      <link>https://arxiv.org/abs/2403.07342</link>
      <description><![CDATA[arXiv:2403.07342v1 公告类型：新
摘要：方面情感三元组提取（ASTE）是细粒度情感分析的一个新兴子任务，旨在从非结构化文本数据中提取结构化情感三元组。现有的 ASTE 方法通常会因为额外的结构或外部数据而使任务复杂化。在这项研究中，我们提出了一种新颖的标记方案，并采用对比学习方法来缓解这些挑战。与最先进的技术相比，所提出的方法表现出可比或优越的性能，同时具有更紧凑的设计和减少的计算开销。值得注意的是，即使在大型语言模型（LLM）时代，我们的方法在少数学习场景中也表现出比 GPT 3.5 和 GPT 4 更优越的功效。这项研究还为大型语言模型范式内 ASTE 技术的进步提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.07342</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>CKERC：联合大型语言模型与常识知识进行对话中的情绪识别</title>
      <link>https://arxiv.org/abs/2403.07260</link>
      <description><![CDATA[arXiv:2403.07260v1 公告类型：新
摘要：对话中的情绪识别（ERC）是一项预测对话上下文中话语情绪的任务。它紧密依赖于对话上下文、说话者身份信息、多方对话场景等。然而，最先进的方法（instructERC）仅识别说话人，而忽略了对话过程中说话人背后的常识知识（即听众的反应和说话人的意图等），无法深度挖掘说话人信息。为此，我们提出了一种新颖的具有常识知识框架的联合大语言模型，用于对话中的情感识别，即CKERC。我们设计提示，以大语言模型的历史话语为基础生成对话者的常识。我们使用对话者常识识别任务进行 LLM 预训练来微调说话者隐含线索信息。通过解决上述挑战，我们的方法达到了最先进的水平。我们在三个广泛使用的数据集上进行了广泛的实验，即IEMOCAP、MELD、EmoryNLP，展示了我们的方法优势。此外，我们还进行了深入分析，进一步证明了常识知识在大语言模型中 ERC 任务中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.07260</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>可解释知识追踪调查</title>
      <link>https://arxiv.org/abs/2403.07279</link>
      <description><![CDATA[arXiv:2403.07279v1 公告类型：新
摘要：随着高质量教育数据的长期积累，人工智能在知识溯源方面展现出了优异的表现。然而，由于某些算法缺乏可解释性和透明度，这种方法将导致利益相关者信任度降低以及对智能决策的接受度降低。因此，算法需要达到高精度，用户需要了解内部运行机制并为决策提供可靠的解释。本文深入分析了KT算法的可解释性。首先介绍了可解释人工智能和知识追踪的概念和常用方法。接下来，可解释的知识追踪模型分为两类：透明模型和黑盒模型。然后，从事前可解释方法、事后可解释方法和其他维度三个阶段回顾所使用的可解释方法。值得注意的是，目前缺乏可解释知识追踪的评估方法。因此，使用三种XAI方法进行对比和删除实验来解释深度知识追踪模型在ASSISTment2009上的预测结果。此外，本文从教育利益相关者的角度对评估方法提供了一些见解。本文对可解释知识追踪的研究进行了详细而全面的回顾，旨在为对知识追踪的可解释性感兴趣的研究者提供一些依据和启发。]]></description>
      <guid>https://arxiv.org/abs/2403.07279</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>用于链接预测的知识图大语言模型 (KG-LLM)</title>
      <link>https://arxiv.org/abs/2403.07311</link>
      <description><![CDATA[arXiv:2403.07311v1 公告类型：新
摘要：预测知识图谱（KG）中的多个链接的任务是知识图谱分析领域的一个挑战，由于自然语言处理（NLP）和知识图谱嵌入技术的进步，这一挑战越来越容易解决。本文介绍了一种新颖的方法，即知识图大型语言模型框架（KG-LLM），该框架利用关键的 NLP 范式，包括思想链（CoT）提示和上下文学习（ICL）来增强多跳KG 中的链接预测。通过将 KG 转换为 CoT 提示，我们的框架旨在辨别和学习实体的潜在表示及其相互关系。为了展示 KG-LLM 框架的有效性，我们在此框架内微调了三个领先的大型语言模型 (LLM)，采用非 ICL 和 ICL 任务进行综合评估。此外，我们还探讨了该框架为法学硕士提供零样本能力的潜力，以处理以前未见过的提示。我们的实验结果发现，集成 ICL 和 CoT 不仅增强了我们方法的性能，而且还显着提高了模型的泛化能力，从而确保在不熟悉的场景中进行更精确的预测。]]></description>
      <guid>https://arxiv.org/abs/2403.07311</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>从认知动机解析器生成结构启动预测</title>
      <link>https://arxiv.org/abs/2403.07202</link>
      <description><![CDATA[arXiv:2403.07202v1 公告类型：新
摘要：结构启动是一种广泛使用的心理语言学范式，用于研究人类句子表征。在这项工作中，我们提出了一个框架，使用经验启动模式来构建表征人类在处理句子时构建的结构表征的理论。该框架使用新的认知驱动解析器 SPAWN，从理论语法生成定量启动预测，并用经验人类行为评估这些预测。作为一个案例研究，我们应用这个框架来研究英语中简化的关系从句表示。我们使用 SPAWN 从两个理论帐户中生成启动预测，这两个理论帐户对关系从句的结构做出了不同的假设。我们发现，只有其中一种理论（分词阶段）的预测与经验启动模式一致，从而强调了有关关系从句的哪些假设可以更好地捕捉人类句子表征。]]></description>
      <guid>https://arxiv.org/abs/2403.07202</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>Curry-DPO：使用课程学习和排名偏好增强一致性</title>
      <link>https://arxiv.org/abs/2403.07230</link>
      <description><![CDATA[arXiv:2403.07230v1 公告类型：新
摘要：直接偏好优化（DPO）是一种有效的技术，它利用成对偏好数据（通常是每个用户提示选择一个和拒绝的响应对）来使法学硕士与人类偏好保持一致。在实践中，对于给定的提示可以存在多个响应，并且彼此之间的质量不同。由于多个响应的质量评级可用，我们建议利用这些响应为给定的提示创建多个偏好对。我们的工作重点是通过课程学习方法在 DPO 培训中系统地使用构建的多重偏好对。特别是，我们根据各种标准对这些多对偏好数据从易到难（模拟课程培训）进行排序。我们展示了我们提出的方法与标准单对 DPO 设置的详细比较。我们的方法（我们称之为 Curry-DPO）在 MTbench、Vicuna、WizardLM 和 UltraFeedback 测试集上始终显示出性能提升，凸显了其有效性。更具体地说，Curry-DPO 在 MT 基准上取得了 7.43 的分数，Zephy-7B 模型的表现优于大多数具有相似参数大小的现有 LLM。在我们的实验中，Curry-DPO 还在 Vicuna、WizardLM 和 UltraFeedback 测试数据集上实现了最高的调整胜率（分别为 90.7%、87.1% 和 87.9%），与标准 DPO 技术相比，显着提高了高达 7.5%。]]></description>
      <guid>https://arxiv.org/abs/2403.07230</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>大规模监控 AI 修改内容：ChatGPT 对 AI 会议同行评审影响的案例研究</title>
      <link>https://arxiv.org/abs/2403.07183</link>
      <description><![CDATA[arXiv:2403.07183v1 公告类型：新
摘要：我们提出了一种估计大型语料库中文本比例的方法，该语料库可能会被大型语言模型（LLM）大幅修改或生成。我们的最大似然模型利用专家编写和人工智能生成的参考文本，在语料库级别准确有效地检查现实世界的法学硕士使用情况。我们将这种方法应用于 ChatGPT 发布后举行的人工智能会议中科学同行评审的案例研究：ICLR 2024、NeurIPS 2023、CoRL 2023 和 EMNLP 2023。我们的结果表明，6.5% 到 16.9% 的文本提交为法学硕士可以对这些会议的同行评审进行大幅修改，即除了拼写检查或较小的写作更新之外。生成文本发生的情况可以洞察用户行为：在报告置信度较低、提交时间接近截止日期以及不太可能回应作者反驳的审稿人的审稿中，LLM 生成文本的估计比例较高。我们还观察生成文本中的语料库级别趋势，这些趋势可能过于微妙而无法在个人级别上检测到，并讨论这种趋势对同行评审的影响。我们呼吁未来开展跨学科工作来研究法学硕士的使用如何改变我们的信息和知识实践。]]></description>
      <guid>https://arxiv.org/abs/2403.07183</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>CuentosIE：关于“带有消息的故事”的聊天机器人可以帮助教授情商吗？</title>
      <link>https://arxiv.org/abs/2403.07193</link>
      <description><![CDATA[arXiv:2403.07193v1 公告类型：新
摘要：在本文中，我们介绍了 CuentosIE（TalesEI：带有发展情商消息的故事聊天机器人），这是一种关于情感的教育聊天机器人，还为教师和心理学家提供了一种工具，通过由以下机构编制的指标和数据来监控学生/患者： CuentosIE。使用“带有信息的故事”是合理的，因为它们简单且易于理解，这要归功于它们的道德或相关隐喻。 CuentosIE 的主要贡献是对一组高度专业化的故事的选择、收集和分类，以及提供对教育用户情绪有用的工具（搜索、阅读理解、聊天、推荐和分类）。并监测他们的情绪发展。该工具的初步评估取得了令人鼓舞的结果，这为文章标题提出的问题提供了肯定的答案。]]></description>
      <guid>https://arxiv.org/abs/2403.07193</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>用大型语言模型叙述因果图</title>
      <link>https://arxiv.org/abs/2403.07118</link>
      <description><![CDATA[arXiv:2403.07118v1 公告类型：新
摘要：使用生成式人工智能从图形创建文本描述主要集中在知识图，它使用事实连接概念。在这项工作中，我们探索大型预训练语言模型从因果图生成文本的能力，其中显着概念表示为节点，因果关系通过有向、类型化的边表示。这些图表中编码的因果推理可以支持医疗保健或营销等多种应用。使用两个公开可用的因果图数据集，我们实证研究了四种 GPT-3 模型在不同设置下的性能。我们的结果表明，虽然因果文本描述可以通过训练数据得到改善，但与基于事实的图表相比，它们在零样本设置下更难生成。结果进一步表明，生成式人工智能的用户可以更快地部署未来的应用程序，因为与通过大型数据集进行微调相比，仅使用几个示例训练模型可以获得相似的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.07118</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>思维图：生成生物推理的思维过程</title>
      <link>https://arxiv.org/abs/2403.07144</link>
      <description><![CDATA[arXiv:2403.07144v1 公告类型：新
摘要：我们将思维图作为一种支持复杂推理的新颖框架，并以基因集分析为例来揭示生物过程之间的语义关系。我们的框架因其能够提供对基因集更深入的理解而脱颖而出，基于与人类注释的余弦相似性，显着超过 GSEA 40.28%，超过 LLM 基线 5.38%。我们的分析进一步提供了对生物过程命名的未来方向以及对生物信息学和精准医学的影响的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.07144</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>重建 ROME：解决顺序模型编辑期间的模型崩溃问题</title>
      <link>https://arxiv.org/abs/2403.07175</link>
      <description><![CDATA[arXiv:2403.07175v1 公告类型：新
摘要：最近使用排名一模型编辑（ROME）（一种流行的模型编辑方法）进行模型编辑的工作表明，在某些事实下，该算法无法在不破坏模型的情况下进行编辑。此类编辑以前称为禁用编辑。这些禁用编辑会导致模型立即崩溃并限制使用 ROME 进行顺序编辑。在本文中，我们做出了两个主要贡献。首先，我们表明，ROME 的模型崩溃仅在使用 CounterFact 数据集进行编辑时发生，而在使用 zsRE 数据集时不会发生。其次，我们发现禁用编辑是 ROME 原始实现的一个产物。通过本文，我们提供了一个更稳定的实现 ROME，我们将其称为 r-ROME，并表明在使用 ROME 进行大规模顺序编辑时，我们不再观察到模型崩溃。]]></description>
      <guid>https://arxiv.org/abs/2403.07175</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>基于 LSTM 的文本生成：历史数据集的研究</title>
      <link>https://arxiv.org/abs/2403.07087</link>
      <description><![CDATA[arXiv:2403.07087v1 公告类型：新
摘要：本文对文本生成领域的长短期记忆（LSTM）网络进行了探索，重点关注莎士比亚和尼采历史数据集的利用。 LSTM 以其在处理顺序数据方面的有效性而闻名，在这里应用于对历史文本中固有的复杂语言模式和结构进行建模。该研究表明，基于 LSTM 的模型在历史数据集上进行训练时，不仅可以生成语言丰富且上下文相关的文本，还可以深入了解语言模式随时间的演变。该发现提出的模型在预测尼采作品中的文本方面非常准确和高效，且损失值较低，训练时间为 100 次迭代。模型精度为0.9521，精度较高。模型的损失为0.2518，表明其有效性。该模型预测莎士比亚作品文本的准确率为0.9125，表明错误率较低。模型的训练时间为 100，反映了 Nietzsche 数据集的效率。这种效率证明了模型设计和训练方法的有效性，特别是在处理复杂的文学文本时。这项研究展示了 LSTM 网络在文本生成方面的多功能性，并为历史语言学及其他领域的未来探索提供了途径，为自然语言处理领域做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2403.07087</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>SPA：迈向计算友好的云基和设备端协作 Seq2seq 个性化生成</title>
      <link>https://arxiv.org/abs/2403.07088</link>
      <description><![CDATA[arXiv:2403.07088v1 公告类型：新
摘要：大型语言模型（LLM）已在各种任务和问题回答中显示出其卓越的能力。然而，LLM 需要较高的计算成本和较大的内存成本。同时，当训练或预测过程包含敏感信息时，LLM 可能会导致隐私泄露。在本文中，我们提出了 SPA（Side Plugin Adaption），这是一种轻量级架构，用于在严格的设备上计算和内存约束的情况下进行快速设备上推理和隐私保留。与其他设备上的 seq2seq 生成相比，SPA 可以在低资源约束下做出快速稳定的推理，从而获得成本效率。我们的方法在云上预训练的 LLM 和设备上的附加参数之间建立交互，这可以提供有关预训练的 LLM 和私有个人特征的知识。此外，SPA 提供了一个框架来保持基于特征的参数私有保证，但低计算设备同时将包含一般信息的参数保留在高计算设备上。]]></description>
      <guid>https://arxiv.org/abs/2403.07088</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:34 GMT</pubDate>
    </item>
    </channel>
</rss>