<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 20 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>医疗保健人工智能的泛化：临床大语言模型的评估</title>
      <link>https://arxiv.org/abs/2402.10965</link>
      <description><![CDATA[arXiv:2402.10965v1 公告类型：新
摘要：大语言模型 (LLM) 的进步为医疗保健领域提供了新的机会，可以改善患者护理、临床决策以及增强医生和管理人员的工作流程。然而，这些模型的潜力重要地取决于它们在临床环境和人群中有效推广的能力，这是早期开发中经常被低估的挑战。为了更好地了解这些挑战的原因并为缓解方法提供信息，我们评估了 ClinicLLM（一家接受过[医院]临床记录培训的法学硕士），分析了其在 30 天全因再入院预测方面的表现，重点关注医院之间的差异和患者特征。我们发现普遍性较差，特别是在样本较少的医院、有政府保险和未指定保险的患者、老年人和合并症较高的患者中。为了了解缺乏概括性的原因，我们调查了微调的样本量、注释内容（每个注释的字数）、患者特征（合并症水平、年龄、保险类型、行政区）和卫生系统方面（医院、所有医疗机构）。导致 30 天再入院和死亡率）。我们使用描述性统计和监督分类来识别特征。我们发现，除了样本量之外，患者年龄、合并症数量以及注释中的字数都是与泛化相关的重要因素。最后，我们比较了局部微调（特定于医院）、基于实例的增强微调和基于集群的微调，以提高泛化能力。其中，局部微调被证明是最有效的，将 AUC 提高了 0.25% 至 11.74%（在数据有限的情况下最有帮助）。总体而言，这项研究为加强大型语言模型在社会重要的医疗保健领域的部署以及提高其在更广泛人群中的表现提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2402.10965</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:06 GMT</pubDate>
    </item>
    <item>
      <title>SportsMetrics：混合文本和数字数据以理解法学硕士中的信息融合</title>
      <link>https://arxiv.org/abs/2402.10979</link>
      <description><![CDATA[arXiv:2402.10979v1 公告类型：新
摘要：大型语言模型在集成各种数据类型（例如文本文档和数据库记录）以进行高级分析方面具有巨大的潜力。然而，混合文本和数字数据带来了巨大的挑战。法学硕士需要处理和交叉引用实体和数字，处理数据不一致和冗余，并开发规划能力，例如构建用于管理复杂数据查询的工作记忆。在本文中，我们介绍了以体育数据分析为中心的四项新任务，以评估法学硕士的数值推理和信息融合能力。这些任务包括向法学硕士提供详细的、逐个比赛的体育比赛描述，然后用新的比赛规则、更长的持续时间、混乱的叙述等对抗性场景来挑战他们，并分析比赛摘要中的关键统计数据。我们对 NBA 和 NFL 比赛进行了大量实验，以评估法学硕士在这些任务上的表现。我们的基准 SportsMetrics 引入了一种评估法学硕士数字推理和融合技能的新机制。]]></description>
      <guid>https://arxiv.org/abs/2402.10979</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:06 GMT</pubDate>
    </item>
    <item>
      <title>测量和控制语言模型对话框中的角色漂移</title>
      <link>https://arxiv.org/abs/2402.10962</link>
      <description><![CDATA[arXiv:2402.10962v1 公告类型：新
摘要：提示是用于定制语言模型聊天机器人的标准工具，使它们能够呈现特定的“角色”。使用提示的隐含假设是它们是稳定的，因此聊天机器人将在对话期间继续根据规定的角色生成文本。我们提出了一个定量基准来测试这一假设，通过两个个性化聊天机器人之间的自聊天来评估角色稳定性。通过测试 LLaMA2-chat-70B 等流行模型，我们发现在八轮对话中存在显着的角色漂移。对这种现象的实证和理论分析表明，由于长时间交流中的注意力衰减，变压器注意力机制发挥了作用。为了对抗注意力衰退和角色漂移，我们提出了一种称为 split-softmax 的轻量级方法，它与两个强大的基线相比具有优势。]]></description>
      <guid>https://arxiv.org/abs/2402.10962</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:05 GMT</pubDate>
    </item>
    <item>
      <title>GLoRe：何时、何地以及如何通过全球和本地改进改进 LLM 推理</title>
      <link>https://arxiv.org/abs/2402.10963</link>
      <description><![CDATA[arXiv:2402.10963v1 公告类型：新
摘要：最先进的语言模型可以在数学、科学或编码任务上表现出令人印象深刻的推理细化能力。然而，最近的研究表明，即使是最好的模型，在无法获得外部反馈的情况下也很难确定\textit{何时何地进行优化}。基于结果的奖励模型（\textbf{ORMs}）经过训练来预测最终答案的正确性（指示何时进行优化），为决定何时进行优化提供了一种方便的解决方案。基于流程的奖励模型（\textbf{PRMs}）经过训练可以预测中间步骤的正确性，然后可以用来指示需要改进的地方。但它们的训练成本很高，需要大量的人工注释。在本文中，我们提出了逐步 ORM（\textbf{SORMs}），仅在合成数据上进行训练，以近似最优策略或 $V^{\star}$ 的预期未来奖励。更具体地说，SORM 经过训练，可以在对当前策略进行多次采样（而不是像 ORM 那样只采样一次）时预测最终答案的正确性。我们的实验表明，与 ORM 相比，SORM 可以更准确地检测到不正确的推理步骤，从而提高进行细化时的下游准确性。然后，我们训练 \textit{global} 细化模型，该模型仅将问题和草稿解决方案作为输入并预测校正后的解决方案，以及 \textit{local} 细化模型，该模型也将指示第一个推理位置的批评作为输入错误。我们通过重用用于训练 SORM 的数据来综合生成两个模型的训练数据。我们发现，使用 ORM 作为重新排序器，结合全局和局部改进，显着优于其中任何一个单独的改进，以及三个样本基线中的最佳结果。通过这种策略，我们可以将 GSM8K 上的 LLaMA-2 13B 模型（已使用 RL 进行微调）的贪婪采样精度从 53\% 提高到 65\%。]]></description>
      <guid>https://arxiv.org/abs/2402.10963</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:05 GMT</pubDate>
    </item>
    <item>
      <title>DAEDRA：用于预测被动药物警戒报告结果的语言模型</title>
      <link>https://arxiv.org/abs/2402.10951</link>
      <description><![CDATA[arXiv:2402.10951v1 公告类型：新
摘要：近年来，大型语言模型（LLM）的出现引发了特定领域模型的激增，这些模型旨在反映语言上下文和内容的特殊性作为原始领域的相关性。本文详细介绍了 DAEDRA 的概念、设计、培训和评估，DAEDRA 是一个法学硕士，旨在检测通过被动报告 (PR) 引发的不良事件报告中的监管相关结果（死亡率、急诊就诊和住院治疗）。虽然公关是一种从广泛且多样化的受众（通常不仅包括医生和医疗保健提供者，还包括患者、家庭成员和其他非专业利益相关者）获取信息的极具成本效益的方式，但这种多样性使得公关语料库难以分析。通用语言模型可能无法捕获复杂的临床维度，而特定的临床或生物医学模型可能无法在外行报告中表现良好。为了评估子域特定语言模型的实用性，采用了自适应训练方法，其中在语料库的子集上评估基本语言模型候选者，并在整个语料库上训练表现最好的模型。这以相对较低的训练成本和单日训练时间，在 $F_1$ (+1%)、精确度 (+2.5%) 和召回率 (+3.8%) 方面产生了小但显着的改进。在分析高度专业化的语料库时，特定子领域的法学硕士仍然是获得更好结果的可行选择。]]></description>
      <guid>https://arxiv.org/abs/2402.10951</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:04 GMT</pubDate>
    </item>
    <item>
      <title>相对偏好优化：通过对比相同和不同提示的响应来增强 LLM 一致性</title>
      <link>https://arxiv.org/abs/2402.10958</link>
      <description><![CDATA[arXiv:2402.10958v1 公告类型：新
摘要：在大语言模型（LLM）领域，使模型与用户的不同偏好保持一致是一个严峻的挑战。直接偏好优化（DPO）在这一领域发挥了关键作用。它的工作原理是使用源自相同提示的偏好对，并且无需额外的奖励模型即可发挥作用。然而，DPO 并没有完全反映人类学习的复杂本质，人类学习通常涉及理解对相同问题和相似问题的不同反应。为了克服这一不足，我们提出了相对偏好优化（RPO）。 RPO 旨在区分源自相同和相关提示的更受欢迎和更不受欢迎的响应。它引入了对比加权机制，可以使用更广泛的偏好数据（包括配对和不配对的数据集）来调整法学硕士。这种方法扩展了模型的学习能力，使其能够利用来自更多样化提示的见解。通过包括对话和总结任务在内的实证测试以及使用AlpacaEval2.0排行榜的评估，RPO展示了使LLM与用户偏好保持一致并提高其在培训过程中的适应性的卓越能力。重现论文中提出的结果所需的 PyTorch 代码将在 GitHub 上提供以供公众访问。]]></description>
      <guid>https://arxiv.org/abs/2402.10958</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:04 GMT</pubDate>
    </item>
    <item>
      <title>通过纳入心理量表对社交媒体进行零样本可解释的心理健康分析</title>
      <link>https://arxiv.org/abs/2402.10948</link>
      <description><![CDATA[arXiv:2402.10948v1 公告类型：新
摘要：心理健康分析中的传统判别方法以其强大的能力而闻名，但缺乏可解释性，并且需要大规模的注释数据。另一方面，生成方法，例如基于大型语言模型（LLM）的方法，有可能摆脱繁重的注释并提供解释。然而，与判别性方法相比，它们的能力仍然存在不足，并且由于解释的生成是一个黑盒过程，因此它们的解释可能不可靠。受到使用量表评估心理状态的心理评估实践的启发，我们的方法通过法学硕士结合了两个程序。首先，患者填写心理健康问卷，其次，心理学家解释从心理健康问题中收集到的信息并做出明智的决定。实验结果表明，我们的方法优于其他零样本方法。我们的方法可以根据心理问卷的输出生成更严格的解释。]]></description>
      <guid>https://arxiv.org/abs/2402.10948</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:03 GMT</pubDate>
    </item>
    <item>
      <title>偏心自动提示效果不合理</title>
      <link>https://arxiv.org/abs/2402.10949</link>
      <description><![CDATA[arXiv:2402.10949v1 公告类型：新
摘要：大型语言模型（LLM）已经表现出卓越的解决问题和基本数学的能力。然而，它们的功效很大程度上取决于提示的制定。本研究试图量化将“积极思考”纳入提示系统信息的影响，然后将其与系统提示优化进行比较。我们评估了 60 种系统消息片段组合的性能，在有或没有思想链提示的情况下进行了测试，在 GSM8K 数据集上参数范围从 7 到 700 亿的三个模型中进行了测试。我们的研究结果表明，结果并不能普遍推广到各个模型。在大多数情况下，包含“积极思考”会对模型性能产生积极影响。然而值得注意的是，Llama2-70B 在不使用思想链时表现出例外，因为发现最佳系统消息根本没有。考虑到对大型黑盒模型进行手动调整提示的组合复杂性和计算时间，然后我们将最佳“积极思考”提示的性能与系统提示优化的输出进行比较。我们表明，即使在使用较小的开源模型时，使用自动提示优化器也是提高性能的最有效方法。此外，我们的研究结果表明，得分最高、自动优化的提示表现出一定程度的特殊性，远远超出预期。]]></description>
      <guid>https://arxiv.org/abs/2402.10949</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:03 GMT</pubDate>
    </item>
    <item>
      <title>开源阿拉伯文字 OCR 的进步和局限性：案例研究</title>
      <link>https://arxiv.org/abs/2402.10943</link>
      <description><![CDATA[arXiv:2402.10943v1 公告类型：新
摘要：这项工作在领先的阿拉伯学术期刊 al-Abhath 上介绍了开源 OCR 引擎 Kraken 的准确性研究。与其他商用 OCR 引擎相比，Kraken 能够生成高度准确的阿拉伯文字 OCR。该研究还评估了 al-Abhath 数据上特定字体和通用模型的相对准确性，并对“错误实例”和可能导致 OCR 误识别的上下文特征进行了微观分析。基于这一分析，本文认为，阿拉伯文字 OCR 可以通过以下方式得到显着改进：(1) 更系统的训练数据生成方法，以及 (2) 关键技术组件的开发，特别是多语言模型和改进的行分割和布局分析。
  Cet 文章介绍了 ROC 开源的精确性，Krakan，sur la revue acad{\&#39;e}mique arabe de prime rang，al-Abhath。 CONTRAIREMENT {\`a} d&#39;autres moteurs ROC disponibles sur le March{\&#39;e}, Kraken se r{\&#39;e}v{\`e}le {\^e}tre Capable de produire de la ROC extr{ \^e}ment exacte de l&#39;{\&#39;e}阿拉伯文化。 L&#39;{\&#39;e}tude {\&#39;e}value aussi l&#39;exacttituderelative des mod{\`e}les sp{\&#39;e}cifiquement configur{\&#39;e}s {\&#39;a} despolices et celle des mod{\`e}les g{\&#39;e}n{\&#39;e}ralis{\&#39;e}s sur les donn{\&#39;e}es d&#39;al-Abhath 等对“事件”进行微观分析erreurs”，ainsi qu&#39;une microanalysis des {\&#39;e}l{\&#39;e}ments contextuels qui pourraient avoir contribu{\&#39;e} {\`a} la m{\&#39;e}reconnaissance ROC. S&#39;appuyant sur cette analysis, 这篇文章 fait valoir que la ROC de l&#39;{\&#39;e}criture arabe peut {\^e}tre consid{\&#39;e}rablement am{\&#39;e}lior{\&#39;e} e gr{\^a}ce {\`a} (1) une approche plus syst{\&#39;e}matique d&#39;entra{\^i}nement de la Production de donn{\&#39;e}es et (2) gr{\^a}ce au d{\&#39;e}veloppement de composants technologiques foldamentaux, notammentl&#39;am{\&#39;e}lioration des mod{\`e}les multilinguals, de la splitting de ligne et de l&#39;analysis de la mise en page。]]></description>
      <guid>https://arxiv.org/abs/2402.10943</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:02 GMT</pubDate>
    </item>
    <item>
      <title>CultureLLM：将文化差异纳入大型语言模型</title>
      <link>https://arxiv.org/abs/2402.10946</link>
      <description><![CDATA[arXiv:2402.10946v1 公告类型：新
摘要：据报道，由于英语语料库的训练数据占主导地位，大型语言模型（LLM）偏向于某些文化。由于多语言文化数据的收集成本通常很高，因此现有的工作通过及时的工程或针对特定文化的预培训来解决这个问题。然而，他们可能忽视了低资源文化的知识缺陷，需要大量的计算资源。在本文中，我们提出了 CultureLLM，这是一种将文化差异纳入法学硕士的经济有效的解决方案。 CultureLLM 采用世界价值调查（WVS）作为种子数据，并通过所提出的语义数据增强生成语义等效的训练数据。我们仅使用来自 WVS 的 50 个种子样本和增强数据，对特定文化的 LLM 和一个统一模型 (CultureLLM-One) 进行了微调，适用于涵盖丰富和资源匮乏语言的 9 种文化。对 60 个文化相关数据集的大量实验表明，CultureLLM 的性能显着优于 GPT-3.5（8.1%）和 Gemini Pro（9.5%）等各种对应模型，其性能与 GPT-4 相当甚至更好。我们的人类研究表明，生成的样本在语义上与原始样本等效，为 LLM 增强提供了有效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2402.10946</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:02 GMT</pubDate>
    </item>
    <item>
      <title>用于医学诊断和不确定性量化的临床程序代码的神经机器翻译</title>
      <link>https://arxiv.org/abs/2402.10940</link>
      <description><![CDATA[arXiv:2402.10940v1 公告类型：新
摘要：临床决策支持系统（CDSS）旨在通过将系统生成的建议与医学专业知识相结合来增强临床医生的决策。鉴于医疗费用高、劳动力密集且时间敏感，迫切需要高效的决策支持，特别是在复杂的紧急情况下。在这些信息有限的场景中，利用 AI（人工智能）模型有效减少诊断不确定性的先进 CDSS 框架具有实用性。这种具有量化不确定性的人工智能驱动的 CDSS 框架有望在现实世界医疗保健的苛刻环境中实用且有益。在这项研究中，我们引入了医学熵的概念，量化了基于 ICD-9 程序代码的神经机器翻译预测的患者结果的不确定性。我们的实验结果不仅显示了基于简单 ICD-9 代码的程序和诊断序列之间的强相关性，而且还证明了通过数据驱动的方法对住院期间的不确定性趋势进行建模的有前途的能力。]]></description>
      <guid>https://arxiv.org/abs/2402.10940</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:01 GMT</pubDate>
    </item>
    <item>
      <title>Text2Data：具有文本控制的低资源数据生成</title>
      <link>https://arxiv.org/abs/2402.10941</link>
      <description><![CDATA[arXiv:2402.10941v1 公告类型：新
摘要：自然语言是人类与机器无缝交互的常见且直接的控制信号。认识到该接口的重要性，机器学习社区正在投入大量精力来生成在语义上与文本指令一致的数据。虽然在图像编辑、音频合成、视频创建等领域的文本到数据生成方面取得了长足的进步，但资源匮乏的领域通常以昂贵的注释或复杂的数据结构（例如分子、运动动力学和时间序列）为特征。缺乏文字标签。这一缺陷阻碍了监督学习，从而限制了高级生成模型在文本到数据任务中的应用。为了应对资源匮乏场景中的这些挑战，我们提出了 Text2Data，这是一种利用未标记数据通过无监督扩散模型了解底层数据分布的新颖方法。随后，它通过一种新颖的基于约束优化的学习目标进行可控微调，确保可控性并有效抵消灾难性遗忘。综合实验表明，与现有基线相比，Text2Data 能够在各种模式（包括分子、运动和时间序列）的可控性方面实现增强的性能。]]></description>
      <guid>https://arxiv.org/abs/2402.10941</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:01 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士协助危机管理：构建先进的法学硕士平台以实现有效的应急响应和公共合作</title>
      <link>https://arxiv.org/abs/2402.10908</link>
      <description><![CDATA[arXiv:2402.10908v1 公告类型：新
摘要： 紧急情况和重大事件往往迅速发生，需要迅速有效的应对。在这项研究中，我们引入了一种新颖的方法，使用开源大语言模型 LLAMA2 从社交媒体帖子和直接紧急消息中识别和分类紧急情况。目标是利用自然语言处理和机器学习的力量，在全国紧急情况下为公共安全电信人员和大量人群提供帮助。我们的研究重点是开发一种语言模型，可以理解用户在 911 呼叫中描述的情况，使 LLAMA2 能够分析内容并向电信员提供相关指令，同时还创建工作流程以在必要时向政府机构通知呼叫者的信息。该语言模型提供的另一个好处是，当 911 系统不堪重负时，它能够在重大紧急事件中为人们提供帮助，通过简单的指令协助用户并向当局通报他们的位置和紧急信息。]]></description>
      <guid>https://arxiv.org/abs/2402.10908</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:00 GMT</pubDate>
    </item>
    <item>
      <title>新闻来源可信度评估：Reddit 案例研究</title>
      <link>https://arxiv.org/abs/2402.10938</link>
      <description><![CDATA[arXiv:2402.10938v1 公告类型：新
摘要：在社交媒体平台时代，识别在线内容的可信度对于打击错误信息至关重要。我们提出了 CREDiBERT（使用来自 Transformers 的双向编码器表示的可信度评估），这是一种针对 Reddit 提交内容进行微调的源可信度评估模型，重点关注政治话语作为主要贡献。我们利用 Reddit 的社区结构，对 CREDiBERT 采用半监督训练方法。通过使用 CREDiBERT 对提交内容进行编码并将其集成到 Siamese 神经网络中，我们显着提高了提交可信度的二元分类，与现有方法相比，F1 分数提高了 9%。此外，我们在 Reddit 中引入了新版本的 post-to-post 网络，它可以有效地对用户交互进行编码，从而将二元分类任务的 F1 分数提高了近 8%。最后，我们使用 CREDiBERT 来评估 Reddit 子版块对不同主题的敏感性。]]></description>
      <guid>https://arxiv.org/abs/2402.10938</guid>
      <pubDate>Wed, 21 Feb 2024 00:57:00 GMT</pubDate>
    </item>
    <item>
      <title>用于大型语言模型评估的基于分类的清单</title>
      <link>https://arxiv.org/abs/2402.10899</link>
      <description><![CDATA[arXiv:2402.10899v1 公告类型：新
摘要：由于大型语言模型（LLM）已在许多下游任务中使用，内部刻板表示可能会影响输出的公平性。在这项工作中，我们将人类知识引入自然语言干预中，并研究性别偏见背景下预先训练的语言模型（LM）行为。受 CheckList 行为测试的启发，我们提出了一个清单式的任务，旨在通过问答（QA）来探索和量化 LM 的不道德行为。我们设计了三项比较研究，从一致性、偏差倾向、模型偏好和性别偏好转换四个方面评估 LM。我们探讨了一种在 SQuAD-v2 数据集上训练的基于 Transformer 的 QA 模型和一种自回归大型语言模型。我们的结果表明，基于 Transformer 的 QA 模型的偏差趋势与其一致性呈正相关，而 LLM 则显示出相反的关系。我们提出的任务提供了第一个涉及 LLM 偏差评估人类知识的数据集。]]></description>
      <guid>https://arxiv.org/abs/2402.10899</guid>
      <pubDate>Wed, 21 Feb 2024 00:56:59 GMT</pubDate>
    </item>
    </channel>
</rss>