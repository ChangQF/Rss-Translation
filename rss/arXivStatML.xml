<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 01 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>在线和离线稳健多元线性回归</title>
      <link>https://arxiv.org/abs/2404.19496</link>
      <description><![CDATA[arXiv:2404.19496v1 公告类型：交叉
摘要：我们考虑多元高斯线性回归模型参数的稳健估计。为此，我们考虑使用或不使用岭正则化的通常（马哈拉诺比斯）最小二乘准则的稳健版本。我们介绍两种方法，每种方法都考虑对比：（i）在线随机梯度下降算法及其平均版本和（ii）离线定点算法。在弱假设下，我们证明了所得估计的渐近正态性。由于噪声的方差矩阵通常是未知的，因此我们建议在基于 Mahalanobis 的随机梯度下降算法中插入对其的鲁棒估计。我们在合成数据上显示，与经典的最小二乘估计相比，所提出的估计在稳健性方面取得了巨大的进步。我们还将展示所提出算法的在线版本的计算效率。所有提出的算法都在 CRAN 上可用的 R 包 RobRegression 中实现。]]></description>
      <guid>https://arxiv.org/abs/2404.19496</guid>
      <pubDate>Wed, 01 May 2024 06:19:11 GMT</pubDate>
    </item>
    <item>
      <title>半代数函数的不精确次梯度方法</title>
      <link>https://arxiv.org/abs/2404.19517</link>
      <description><![CDATA[arXiv:2404.19517v1 公告类型：交叉
摘要：受近似导数在机器学习和优化中广泛使用的推动，我们研究了具有非零加性误差和步长的不精确次梯度方法。在非凸半代数设置中，在有界假设下，我们证明该方法提供的点最终在与 $\epsilon^\rho$ 成正比的距离处波动接近临界集，其中 $\epsilon$ 是次梯度评估中的误差，$ \rho$ 与问题的几何形状有关。在凸设置中，我们提供平均值的复杂性结果。我们还获得了独立兴趣的副产品，例如非光滑非凸问题的类似下降引理以及微分包含的仿射插值极限的一些结果。]]></description>
      <guid>https://arxiv.org/abs/2404.19517</guid>
      <pubDate>Wed, 01 May 2024 06:19:11 GMT</pubDate>
    </item>
    <item>
      <title>免训练图神经网络和标签作为特征的力量</title>
      <link>https://arxiv.org/abs/2404.19288</link>
      <description><![CDATA[arXiv:2404.19288v1 公告类型：交叉
摘要：我们提出了免训练图神经网络（TFGNN），它可以在没有训练的情况下使用，也可以通过可选的训练进行改进，用于传导节点分类。我们首先提倡将标签作为特征（LaF），这是一种可接受但尚未探索的技术。我们证明 LaF 确实增强了图神经网络的表达能力。我们基于此分析设计了 TFGNN。在实验中，我们确认 TFGNN 在免训练设置中优于现有的 GNN，并且比传统 GNN 的训练迭代次数要少得多。]]></description>
      <guid>https://arxiv.org/abs/2404.19288</guid>
      <pubDate>Wed, 01 May 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>可证明有效的多智能体强化学习信息导向采样算法</title>
      <link>https://arxiv.org/abs/2404.19292</link>
      <description><![CDATA[arXiv:2404.19292v1 公告类型：交叉
摘要：本文基于信息定向采样（IDS）原理设计并分析了一套新颖的多智能体强化学习（MARL）算法。这些算法从信息论的基本概念中汲取灵感，并被证明在 MARL 设置中具有样本效率，例如两人零和马尔可夫游戏 (MG) 和多人一般和 MG。对于情景两人零和 MG，我们提出了三种用于学习纳什均衡的样本有效算法。基本算法称为 MAIDS，采用非对称学习结构，其中最大玩家首先基于联合策略的联合信息比解决极小极大优化问题，然后最小玩家用最大玩家最小化边际信息比。 - 玩家的政策已修复。理论分析表明，它实现了 K 个剧集的 tilde{O}(sqrt{K}) 的贝叶斯遗憾。为了减少 MAIDS 的计算负载，我们开发了一种名为 Reg-MAIDS 的改进算法，该算法具有相同的贝叶斯遗憾界限，同时计算复杂度更低。此外，利用IDS原理在选择学习目标方面的灵活性，我们提出了两种基于率失真理论的压缩环境构建方法，并在此基础上开发了一种以压缩环境为学习目标的算法Compressed-MAIDS。最后，我们将 Reg-MAIDS 扩展到多人广义和 MG，并证明它可以以样本有效的方式学习纳什均衡或粗相关均衡。]]></description>
      <guid>https://arxiv.org/abs/2404.19292</guid>
      <pubDate>Wed, 01 May 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>正交引导：输入不确定性的有效模拟</title>
      <link>https://arxiv.org/abs/2404.19145</link>
      <description><![CDATA[arXiv:2404.19145v1 公告类型：交叉
摘要：Bootstrap 是模拟输入不确定性的流行方法。然而，当样本数量很大时，计算成本可能会很高。我们提出了一种称为 \textbf{Orthogonal Bootstrap} 的新方法，可以减少所需的蒙特卡洛复制次数。我们将被模拟的目标分解为两部分：\textit{非正交部分}，其具有称为Infinitesimal Jackknife的封闭形式结果；和\textit{正交部分}，其更容易被模拟。我们从理论上和数值上表明，正交 Bootstrap 显着降低了 Bootstrap 的计算成本，同时提高了经验精度并保持了构造区间的相同宽度。]]></description>
      <guid>https://arxiv.org/abs/2404.19145</guid>
      <pubDate>Wed, 01 May 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>使用变分自回归网络和量子退火进行统计力学计算</title>
      <link>https://arxiv.org/abs/2404.19274</link>
      <description><![CDATA[arXiv:2404.19274v1 公告类型：交叉 
摘要：在统计力学中，计算配分函数通常很困难。最近提出了一种使用变分自回归网络 (VAN) 的近似方法。这种方法的优点是可以直接计算生成概率，同时获得大量样本。本研究介绍了一种新颖的近似方法，该方法结合使用量子退火机和 VAN 得到的样本，经验上假设这些样本遵循吉布斯-玻尔兹曼分布。当应用于有限尺寸的 Sherrington-Kirkpatrick 模型时，与传统的 VAN 方法和其他近似方法（例如广泛使用的朴素平均场）相比，所提出的方法表现出更高的准确性。]]></description>
      <guid>https://arxiv.org/abs/2404.19274</guid>
      <pubDate>Wed, 01 May 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>隐藏的协同作用：$L_1$ 权重标准化和 1-Path-Norm 正则化</title>
      <link>https://arxiv.org/abs/2404.19112</link>
      <description><![CDATA[arXiv:2404.19112v1 公告类型：交叉
摘要：我们提出了 PSiLON Net，这是一种 MLP 架构，它对每个权重向量使用 $L_1$ 权重归一化，并跨层共享长度参数。 1-路径范数为神经网络的 Lipschitz 常数提供了界限，并反映了其泛化性，我们展示了 PSiLON Net 的设计如何极大地简化了 1-路径范数，同时为高效学习和近似学习提供了归纳偏差。稀疏参数。如果需要，我们提出一种修剪方法，以在训练的最后阶段实现精确的稀疏性。为了利用残差网络的归纳偏差，我们提出了一个简化的残差块，利用串联的 ReLU 激活。对于使用此类块构建的网络，我们证明仅考虑 1 路径范数中可能路径的子集就足以限制 Lipschitz 常数。使用 1-path-norm 和这个改进的界限作为正则化器，我们使用过度参数化的 PSiLON Nets 和 PSiLON ResNets 在小数据范围内进行实验，证明了可靠的优化和强大的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.19112</guid>
      <pubDate>Wed, 01 May 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>一种无模型的分类子数据选择方法</title>
      <link>https://arxiv.org/abs/2404.19127</link>
      <description><![CDATA[arXiv:2404.19127v1 公告类型：交叉
摘要：子数据选择是对从大数据中选择具有代表性的小样本的方法的研究，其分析速度快且统计效率高。现有的子数据选择方法假设可以使用基础模型对大数据进行合理建模，例如用于分类问题的（多项）逻辑回归。当基本建模假设正确时，这些方法非常有效，但否则通常会产生较差的结果。在本文中，我们提出了一种用于分类问题的无模型子数据选择方法，得到的子数据称为PED子数据。 PED 子数据使用决策树来查找数据分区，然后从该分区的每个组件中选择适当的样本。随机森林用于分析选定的子数据。我们的方法可用于响应中的一般数量的类以及分类和连续预测变量。我们分析表明，PED 子数据比统一子数据产生更小的基尼系数。此外，我们通过大量的模拟和真实数据集证明，PED 子数据比其他竞争方法具有更高的分类精度。]]></description>
      <guid>https://arxiv.org/abs/2404.19127</guid>
      <pubDate>Wed, 01 May 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>通过扭曲顺序蒙特卡罗进行语言模型中的概率推理</title>
      <link>https://arxiv.org/abs/2404.17546</link>
      <description><![CDATA[arXiv:2404.17546v1 公告类型：交叉
摘要：大型语言模型 (LLM) 的许多功能和安全技术，包括 RLHF、自动红队、即时工程和填充，都可以被视为来自非标准化目标分布的样本，该目标分布由给定奖励或潜在函数在整个模型中定义。顺序。在这项工作中，我们利用顺序蒙特卡罗（SMC）的丰富工具包来解决这些概率推理问题。特别是，我们使用学习的扭曲函数来估计每个时间步的势的预期未来值，这使我们能够将推理时间计算集中在有希望的部分序列上。我们提出了一种新颖的对比方法来学习扭曲函数，并与软强化学习的丰富文献建立了联系。作为扭曲 SMC 框架的补充应用，我们提出了使用日志分区函数上新颖的双向 SMC 边界来评估语言模型推理技术准确性的方法。这些界限可用于估计两个方向上的推理分布和目标分布之间的 KL 散度。我们应用推理评估技术来表明，扭曲的 SMC 可以有效地从预训练模型（无害训练和自动红队的有用组成部分）中采样不需要的输出，生成具有不同情绪的评论，并执行填充任务。]]></description>
      <guid>https://arxiv.org/abs/2404.17546</guid>
      <pubDate>Wed, 01 May 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>通过标准化流程统一模拟和推理</title>
      <link>https://arxiv.org/abs/2404.18992</link>
      <description><![CDATA[arXiv:2404.18992v1 公告类型：交叉
摘要：深度神经网络在探测器校准中有许多应用，并且越来越多的研究提出深度生成模型作为自动快速探测器模拟器。我们证明，可以通过使用来自能量回归的条件生成模型的最大似然估计（MLE）来统一这两个任务。与直接回归技术不同，MLE 方法与先验无关，并且可以根据最大值附近的似然形状确定非高斯分辨率。使用类似 ATLAS 的热量计模拟，我们在热量计能量校准的背景下演示了这一概念。]]></description>
      <guid>https://arxiv.org/abs/2404.18992</guid>
      <pubDate>Wed, 01 May 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>统计数据和可解释性：富有成效的联盟</title>
      <link>https://arxiv.org/abs/2404.19301</link>
      <description><![CDATA[arXiv:2404.19301v1 公告类型：新
摘要：在本文中，我们提出了标准统计工具作为可解释性文献中常见问题的解决方案。事实上，利用统计估计器可以对解释进行正确的定义，从而提供理论保证和评估指标的制定来定量评估解释的质量。除其他外，这种方法规避了目前文献中普遍存在的主观人类评估。此外，我们认为不确定性量化对于提供稳健且值得信赖的解释至关重要，并且可以通过引导程序等经典统计程序在此框架中实现。然而，值得注意的是，虽然统计数据提供了宝贵的贡献，但它并不是解决所有挑战的灵丹妙药。未来的研究途径可以集中在开放性问题上，例如定义解释的目的或为反事实或对抗性场景建立统计框架。]]></description>
      <guid>https://arxiv.org/abs/2404.19301</guid>
      <pubDate>Wed, 01 May 2024 06:19:06 GMT</pubDate>
    </item>
    <item>
      <title>神经动态数据评估</title>
      <link>https://arxiv.org/abs/2404.19557</link>
      <description><![CDATA[arXiv:2404.19557v1 公告类型：新
摘要：数据构成了数据经济及其市场的基本组成部分。高效、公平的数据评估已成为人们广泛关注的话题。许多基于边际贡献的方法在各种下游任务中显示出了可喜的结果。然而，众所周知，它们的计算成本很高，因为它们需要训练大量的实用函数，这些函数用于评估给定数据集对于特定目的的有用性或价值。因此，人们认为将这些方法应用于涉及大规模数据集的数据市场是不可行的。因此，出现了一个关键问题：如何避免效用函数的重新训练？为了解决这个问题，我们从最优控制的角度提出了一种新颖的数据评估方法，称为神经动态数据评估（NDDV）。我们的方法具有扎实的理论解释，可以通过数据最优控制状态的敏感性准确识别数据评估。此外，我们实施了数据重新加权策略来捕获数据点的独特特征，通过数据点和平均场状态之间的交互来确保公平性。值得注意的是，我们的方法只需要训练一次即可估计所有数据点的值，显着提高了计算效率。我们使用不同的数据集和任务进行全面的实验。结果表明，所提出的 NDDV 方法在准确识别高值或低值数据点方面优于现有最先进的数据评估方法，并且计算效率更高。]]></description>
      <guid>https://arxiv.org/abs/2404.19557</guid>
      <pubDate>Wed, 01 May 2024 06:19:06 GMT</pubDate>
    </item>
    <item>
      <title>深度学习时代的可扩展贝叶斯推理：从高斯过程到深度神经网络</title>
      <link>https://arxiv.org/abs/2404.19157</link>
      <description><![CDATA[arXiv:2404.19157v1 公告类型：新
摘要：在大型数据集上训练的大型神经网络已成为机器学习的主导范式。这些系统依赖于其参数的最大似然点估计，从而阻止它们表达模型的不确定性。这可能会导致过度自信的预测，并阻止使用深度学习模型进行顺序决策。本论文开发了可扩展的方法来为神经网络配备模型不确定性。特别是，我们利用线性拉普拉斯近似为预训练的神经网络配备由切线模型提供的不确定性估计。这将神经网络中的贝叶斯推理问题转变为共轭高斯线性模型中的贝叶斯推理问题之一。遗憾的是，其成本仍然是网络参数数量或观测数量乘以输出维度的三次方。根据假设，两者都不容易处理。我们通过使用随机梯度下降（SGD）（深度学习的主力算法）来解决这个棘手问题，在线性模型及其凸对偶：高斯过程中执行后验采样。这样，我们回到线性化神经网络，发现线性化拉普拉斯近似在用于超参数学习时与现代深度学习实践（即随机优化、早期停止和标准化层）存在许多不兼容性。我们解决了这些问题，并构建了一个基于样本的 EM 算法，用于通过线性化神经网络进行可扩展的超参数学习。我们应用上述方法，使用在 Imagenet（1.2M 观测值和 1000 个输出维度）上训练的 ResNet-50（25M 参数）执行线性化神经网络推理。此外，我们应用我们的方法来估计通过深度图像先验网络获得的 3D 断层摄影重建的不确定性。]]></description>
      <guid>https://arxiv.org/abs/2404.19157</guid>
      <pubDate>Wed, 01 May 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>通过克罗内克乘积分解对矩阵值数据进行回归</title>
      <link>https://arxiv.org/abs/2404.19220</link>
      <description><![CDATA[arXiv:2404.19220v1 公告类型：新
摘要：我们研究矩阵变量回归问题 $Y_i = \sum_{k} \beta_{1k} X_i \beta_{2k}^{\top} + E_i$ for $i=1,2\dots,n$高维状态，其中响应 $Y_i$ 是维度 $p_{1}\times p_{2}$ 超出样本大小 $n$ 和维度 $q_{1}\times q_{2}$ 的矩阵预测变量 $X_i$ 即 $q_{1},q_{2} \ll n \ll p_{1},p_{2}$。我们提出了一种称为 KRO-PRO-FAC 的估计算法，用于估计参数 $\{\beta_{1k}\} \subset \Re^{p_1 \times q_1}$ 和 $\{\beta_{2k}\} \subset \Re^{p_2 \times q_2}$ 利用 Van Loan 和 Pitsianis (1993) 的 Kronecker 乘积分解和重排运算。 KRO-PRO-FAC 算法计算效率高，因为它不需要估计 $\{Y_i\}$ 条目之间的协方差。我们在 $\hat{\beta}_{1k} -\beta_{1k}$ 和 $\hat{\beta}_{2k} - \beta_{2k}$ 之间建立光谱范数的扰动界限，其中$E_i$ 的行或 $E_i$ 的列是独立的亚高斯随机向量。对模拟和真实数据的数值研究表明，与其他现有方法相比，我们的程序在估计误差和预测准确性方面都具有竞争力。]]></description>
      <guid>https://arxiv.org/abs/2404.19220</guid>
      <pubDate>Wed, 01 May 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>从相关数据学习稀疏高维矩阵值图形模型</title>
      <link>https://arxiv.org/abs/2404.19073</link>
      <description><![CDATA[arXiv:2404.19073v1 公告类型：新
摘要：我们考虑推断稀疏、高维、平稳矩阵变量高斯时间序列的条件独立图（CIG）的问题。过去所有关于高维矩阵图模型的工作都假设矩阵变量的独立同分布（i.i.d.）观察是可用的。在这里我们允许相关观察。我们考虑采用克罗内克可分解功率谱密度 (PSD) 的基于稀疏组套索的频域公式，并通过乘数交替方向法 (ADMM) 方法求解该问题。该问题是双凸问题，通过触发器优化来解决。我们为逆 PSD 估计量的 Frobenius 范数局部收敛到真实值提供了充分的条件。这个结果还产生了收敛率。我们使用合成数据和真实数据的数值示例来说明我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.19073</guid>
      <pubDate>Wed, 01 May 2024 06:19:04 GMT</pubDate>
    </item>
    </channel>
</rss>