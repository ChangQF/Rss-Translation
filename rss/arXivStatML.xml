<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 21 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>平滑的 Kolmogorov Arnold 网络支持结构知识表示</title>
      <link>https://arxiv.org/abs/2405.11318</link>
      <description><![CDATA[arXiv:2405.11318v1 公告类型：交叉 
摘要：柯尔莫哥洛夫-阿诺德网络（KAN）由于其有限的网络拓扑，为传统多层感知器（MLP）架构提供了一种高效且可解释的替代方案。然而，根据 Kolmogorov 和 Vitushkin 的结果，使用受限于有限数量截止点的解析函数的 KAN 实现对通用平滑函数的表示不能准确。因此，KAN 在整个训练过程中的收敛性可能会受到限制。本文探讨了 KAN 中平滑性的相关性，提出平滑、结构丰富的 KAN 可以在特定功能类中实现与 MLP 的等价。通过利用固有的结构知识，KAN 可以减少训练所需的数据并降低生成幻觉预测的风险，从而提高计算生物医学中的模型可靠性和性能。]]></description>
      <guid>https://arxiv.org/abs/2405.11318</guid>
      <pubDate>Tue, 21 May 2024 21:13:03 GMT</pubDate>
    </item>
    <item>
      <title>用于加密货币价格预测的深度学习模型回顾：实施和评估</title>
      <link>https://arxiv.org/abs/2405.11431</link>
      <description><![CDATA[arXiv:2405.11431v1 公告类型：交叉 
摘要：投资者和研究人员对准确的加密货币价格预测模型非常感兴趣。深度学习模型是著名的机器学习技术，它已经改变了各个领域，并在金融和经济领域展现出了潜力。尽管人们已经探索了各种深度学习模型来预测加密货币价格，但由于市场波动性较大，尚不清楚哪些模型适合。在本研究中，我们回顾了有关加密货币价格预测的深度学习的文献，并评估了用于加密货币股票价格预测的新型深度学习模型。我们的深度学习模型包括长短期记忆 (LSTM) 循环神经网络的变体、卷积神经网络 (CNN) 的变体和 Transformer 模型。我们评估用于多步提前预测加密货币收盘价的单变量和多变量方法。我们的结果表明，单变量 LSTM 模型变体在加密货币预测方面表现最佳。我们还对四种加密货币进行了波动性分析，显示它们的价格在整个 COVID-19 大流行期间出现了显着波动。此外，我们还研究了由模型的不同训练集识别的两种场景的预测准确性。首先，我们使用 COVID-19 之前的数据集对 COVID-19 早期的加密货币收盘价预测进行建模。其次，我们利用 COVID-19 时期的数据来预测 2023 年至 2024 年的价格。]]></description>
      <guid>https://arxiv.org/abs/2405.11431</guid>
      <pubDate>Tue, 21 May 2024 21:13:03 GMT</pubDate>
    </item>
    <item>
      <title>Deep Ritz方法PGD训练的三层神经网络误差分析</title>
      <link>https://arxiv.org/abs/2405.11451</link>
      <description><![CDATA[arXiv:2405.11451v1 公告类型：交叉 
摘要：机器学习是一个快速发展的领域，在各个领域都有不同的应用。一个突出的研究领域是利用深度学习技术来求解偏微分方程（PDE）。在这项工作中，我们特别关注在深度 Ritz 方法（DRM）框架内采用三层 tanh 神经网络来求解具有三种不同类型边界条件的二阶椭圆方程。我们执行投影梯度下降（PDG）来训练三层网络并建立其全局收敛性。据我们所知，我们是第一个提供使用超参数化网络解决偏微分方程问题的全面误差分析的人，因为我们的分析同时包括近似误差、泛化误差和优化误差的估计。我们以样本大小 $n$ 来表示误差范围，并且我们的工作为如何设置投影梯度下降算法的网络深度、宽度、步长和迭代次数提供了指导。重要的是，我们在这项工作中的假设是经典的，我们不需要对方程的解进行任何额外的假设。这确保了我们的结果的广泛适用性和通用性。]]></description>
      <guid>https://arxiv.org/abs/2405.11451</guid>
      <pubDate>Tue, 21 May 2024 21:13:03 GMT</pubDate>
    </item>
    <item>
      <title>从不完美的人类反馈中学习：腐败与稳健决斗的故事</title>
      <link>https://arxiv.org/abs/2405.11204</link>
      <description><![CDATA[arXiv:2405.11204v1 公告类型：交叉 
摘要：本文研究了从不完美的人类反馈（LIHF）中学习，其动机是人类潜在的非理性或对真实偏好的不完美感知。我们重新审视经典的决斗强盗问题，作为从比较人类反馈中学习的模型，并通过将人类反馈中的缺陷转化为对用户实用程序的不可知腐败来丰富它。我们首先确定 LIHF 的基本限制，并证明 $\Omega(\max\{T^{1/2},C\})$ 的遗憾下限，即使总腐败 $C$ 已知并且当随着时间的推移，损坏会优雅地衰减（即用户反馈变得越来越准确）。然后，我们转向设计适用于任意腐败和未知 $C$ 的现实场景的稳健算法。我们的主要发现是，基于梯度的算法通过改变学习率在腐败情况下可以实现平滑的效率与鲁棒性权衡。具体来说，在一般凹用户效用下，Yue 和 Joachims (2009) 的决斗强盗梯度下降 (DBGD) 可以调整以实现后悔 $O(T^{1-\alpha} + T^{\alpha} C)$任何给定参数 $\alpha \in (0, \frac{1}{4}]$。此外，这个结果使我们能够确定标准 DBGD 的遗憾下限（$\alpha=1/4$ 情况) 首次作为 $\Omega(T^{3/4})$ ，据我们所知，对于强凹用户效用，我们展示了更好的权衡：有一种算法可以实现 $O(T^{ \alpha} + T^{\frac{1}{2}(1-\alpha)}C)$ 对于任何给定的 $\alpha \in [\frac{1}{2},1)$。我们的理论见解得到了对现实世界推荐数据的广泛实验的证实。]]></description>
      <guid>https://arxiv.org/abs/2405.11204</guid>
      <pubDate>Tue, 21 May 2024 21:13:02 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入基于小波的 ANN 的调整后霍尔特混合模型实时监测和预测 COVID 19 病例</title>
      <link>https://arxiv.org/abs/2405.11213</link>
      <description><![CDATA[arXiv:2405.11213v1 公告类型：交叉 
摘要：自 SARS - CoV - 2 (COVID - 19) 新型冠状病毒出现以来，人们投入了大量的时间和精力来估计其轨迹，并可能以合理的准确度进行预测、病例数、治愈率，以及因同样原因造成的死亡。本文提出的模型是朝着同一方向迈出的一步。所讨论的主要模型是嵌入基于小波的 ANN 的混合霍尔特模型。为了测试其预测能力，我们比较了三个单独的模型，第一个是简单的 ARIMA 模型，第二个也是具有基于小波函数的 ARIMA 模型，第三个是所提出的模型。我们还将该模型的预测精度与现代 Vanilla LSTM 循环神经网络模型的预测精度进行了比较。我们已经根据全国以及 6 个热点州的确诊病例数（每日）测试了所提出的模型。除了混合模型之外，我们还提出了一种简单的调整算法，以便可以针对整个国家/地区进行每日和/或每周的预测，以及基于外部的移动窗口绩效指标样本预测。为了采用更全面的方法来分析 COVID-19 动态，还重点关注使用区室流行病学模型 (SIR) 来估计基本繁殖数 $R_0$。最后，我们还非常重视估计所提出模型的保质期。显而易见但值得注意的是，在这方面，准确的模型如何能够确保更好地配置医疗资源，并使政府能够提前采取必要的措施。]]></description>
      <guid>https://arxiv.org/abs/2405.11213</guid>
      <pubDate>Tue, 21 May 2024 21:13:02 GMT</pubDate>
    </item>
    <item>
      <title>通过合成数据生成和机器学习应用推进 fNIRS 神经成像</title>
      <link>https://arxiv.org/abs/2405.11242</link>
      <description><![CDATA[arXiv:2405.11242v1 公告类型：交叉 
摘要：本研究提出了一种通过数据合成和机器学习模型应用来推进功能性近红外光谱（fNIRS）神经成像的综合方法。通过解决高质量神经影像数据集的稀缺问题，这项工作利用蒙特卡罗模拟和参数化头部模型来生成全面的合成数据集，反映广泛的条件。我们开发了一个容器化环境，使用 Docker 和 Xarray 进行标准化和可重复的数据分析，促进不同信号处理模式之间的有意义的比较。此外，还建立了基于云的基础设施，用于可扩展的数据生成和处理，从而提高了神经影像数据的可访问性和质量。合成数据生成与机器学习技术的结合有望提高 fNIRS 断层扫描的准确性、效率和适用性，有可能彻底改变神经系统疾病的诊断和治疗策略。本文开发的方法和基础设施为数据模拟和分析设定了新标准，为神经成像和更广泛的生物医学工程领域的未来研究铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2405.11242</guid>
      <pubDate>Tue, 21 May 2024 21:13:02 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯核心集质量的一般界限</title>
      <link>https://arxiv.org/abs/2405.11780</link>
      <description><![CDATA[arXiv:2405.11780v1 公告类型：新 
摘要：贝叶斯核心集通过基于数据的小加权子集的代理对数似然来近似全数据对数似然函数，从而加速大规模数据体系中的后验推理。但是，虽然贝叶斯核心集和构​​建方法适用于各种模型，但现有的对核心集近似所产生的后验推理误差的理论分析仅适用于限制性设置，即指数族模型或具有强对数凹性和强对数凹性的模型。平滑度假设。这项工作提出了核心集近似的 Kullback-Leibler (KL) 散度的一般上限和下限，反映了贝叶斯核心集的全部适用性。下限仅需要典型的贝叶斯渐近分析的温和模型假设，而上限则要求对数似然函数满足广义次指数标准，该标准弱于早期工作中使用的条件。应用下限来获得核心集近似质量的基本限制，并为先前观察到的基于重要性采样的构造方法的较差经验性能提供理论解释。上限用于分析最近子样本优化方法的性能。该理论的灵活性在涉及多模态、不可识别、重尾贝叶斯后验分布的验证实验中得到了证明。]]></description>
      <guid>https://arxiv.org/abs/2405.11780</guid>
      <pubDate>Tue, 21 May 2024 21:13:01 GMT</pubDate>
    </item>
    <item>
      <title>用于序列建模的交流发电机</title>
      <link>https://arxiv.org/abs/2405.11848</link>
      <description><![CDATA[arXiv:2405.11848v1 公告类型：新 
摘要：本文介绍了交流发电机，这是一种新型的非马尔可夫序列动力学模型。交流发电机具有两个神经网络：观察轨迹网络 (OTN) 和特征轨迹网络 (FTN)。 OTN 和 FTN 协同工作，在一个周期内分别交替输出观察空间和某些特征空间中的样本。 OTN 和 FTN 的参数不依赖于时间，并且通过轨迹上的最小交叉熵准则来学习。交流发电机用途广泛。它们可以用作动态潜变量生成模型或序列到序列的预测器。当交流发电机用作生成模型时，FTN 会生成可解释的低维潜在变量，以捕获控制观测的动态。当交流发电机用作序列到序列预测器时，FTN 学会预测观察到的特征。在这两种情况下，OTN 都会学习生成与数据匹配的序列。交流发电机可以揭示复杂序列数据背后的潜在动态，准确预测和估算缺失数据，并对新轨迹进行采样。我们展示了交流发电机在三种应用中的功能。我们首先使用交流发电机对洛伦兹方程进行建模，该方程通常用于描述混沌行为。然后，我们将交流发电机应用于神经科学，将大脑活动映射到身体活动。最后，我们将交流发电机应用于气候科学，重点关注海面温度预测。在我们所有的实验中，我们发现交流发电机训练稳定、采样快速、生成高质量的生成样本和潜在变量，并且在我们研究的领域中优于强大的基线，例如神经常微分方程和扩散模型。]]></description>
      <guid>https://arxiv.org/abs/2405.11848</guid>
      <pubDate>Tue, 21 May 2024 21:13:01 GMT</pubDate>
    </item>
    <item>
      <title>自验证集成模型 (SVEM) 的随机排列全模型​​测试启发式</title>
      <link>https://arxiv.org/abs/2405.11156</link>
      <description><![CDATA[arXiv:2405.11156v1 公告类型：交叉 
摘要：我们引入了一种启发式方法来测试自验证集成模型（SVEM）对恒定响应的零假设的拟合显着性。 SVEM 模型对模型的 nBoot 拟合的预测进行平均，应用于目标数据集的分数加权引导程序。它利用反相关权重进行训练和验证，对训练数据的验证副本进行调整。所提出的测试计算以响应列均值为中心的 SVEM 预测，并通过整个因子空间中间隔的每个 nPoint 点的集合变异性进行归一化。通过将 SVEM 模型重新拟合到响应列的 nPerm 随机排列并记录 nPoint 点处的相应标准化预测来构建参考分布。应用于中心和缩放的 nPerm x nPoint 参考矩阵的降阶奇异值分解用于计算每个 nPerm 排列结果的马哈拉诺比斯距离以及原始响应列的折刀（保留）马哈拉诺比斯距离。针对实验中的每个响应独立重复该过程，生成联合图形摘要。我们提出了仿真驱动的功耗分析，并讨论了与模型灵活性和设计充分性相关的测试局限性。即使基本 SVEM 模型包含的参数多于观测值，该测试仍保持标称 I 类错误率。]]></description>
      <guid>https://arxiv.org/abs/2405.11156</guid>
      <pubDate>Tue, 21 May 2024 21:13:01 GMT</pubDate>
    </item>
    <item>
      <title>由于贝叶斯误差，神经网络的鲁棒精度认证受到限制</title>
      <link>https://arxiv.org/abs/2405.11547</link>
      <description><![CDATA[arXiv:2405.11547v1 公告类型：新 
摘要：对抗性示例对许多基于神经网络构建的关键系统构成安全威胁。虽然经过认证的培训提高了稳健性，但它也显着降低了准确性。尽管有多种解决此问题的建议，但准确率仍然显着下降。更重要的是，目前尚不清楚在保持准确性的同时实现鲁棒性是否存在某种基本限制。在这项工作中，我们提供了基于贝叶斯错误的新颖视角。通过采用贝叶斯误差进行稳健性分析，我们研究了经过认证的稳健准确性的极限，同时考虑了数据分布的不确定性。我们首先表明，在追求鲁棒性的过程中，由于数据分布发生变化，贝叶斯误差发生了变化，准确性不可避免地会下降。随后，考虑到各个类别的分布及其边界，我们建立了经过认证的稳健准确性的上限。我们的理论结果是在现实世界的数据集上进行经验评估的，并被证明与现有认证训练结果的有限成功一致，\emph{例如}，对于 CIFAR10，我们的分析结果的上限（经过认证的鲁棒精度）为67.49\%，而现有方法只能将其从2017年的53.89\%提高到2023年的62.84\%。]]></description>
      <guid>https://arxiv.org/abs/2405.11547</guid>
      <pubDate>Tue, 21 May 2024 21:13:00 GMT</pubDate>
    </item>
    <item>
      <title>线性注意力上下文学习的渐近理论</title>
      <link>https://arxiv.org/abs/2405.11751</link>
      <description><![CDATA[arXiv:2405.11751v1 公告类型：新 
摘要：Transformers 具有基于输入本身提供的示例来学习和执行任务的卓越能力，无需明确的事先训练。有人认为，这种被称为上下文学习 (ICL) 的能力是 Transformers 成功的基石，但有关成功 ICL 所需的样本复杂性、预训练任务多样性和上下文长度的问题仍未解决。在这里，我们通过线性注意力在线性回归任务的 ICL 精确可解模型中为这些问题提供了精确的答案。我们在现象学丰富的缩放机制中推导出学习曲线的尖锐渐近线，其中令牌维度被取为无穷大；上下文长度和预训练任务多样性与令牌维度成比例；预训练示例的数量呈二次方缩放。我们展示了随着预训练示例的增加而出现的双下降学习曲线，并揭示了低任务多样性机制和高任务多样性机制之间模型行为的相变：在低多样性机制中，模型倾向于记忆训练任务，而在高多样性机制中，模型倾向于记忆训练任务。制度下，它实现了超出预训练任务范围的真正的上下文学习和泛化。这些理论见解通过线性注意力和完全非线性 Transformer 架构的实验得到了实证验证。]]></description>
      <guid>https://arxiv.org/abs/2405.11751</guid>
      <pubDate>Tue, 21 May 2024 21:13:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习进行单变量时间序列预测的滞后选择：实证研究</title>
      <link>https://arxiv.org/abs/2405.11237</link>
      <description><![CDATA[arXiv:2405.11237v1 公告类型：新 
摘要：大多数预测方法使用最近的过去观测值（滞后）来对单变量时间序列的未来值进行建模。选择足够数量的滞后对于训练准确的预测模型非常重要。已经设计了几种方法和启发法来解决此任务。然而，对于什么是最好的方法还没有达成共识。此外，滞后选择程序是基于局部模型和经典预测技术（例如 ARIMA）开发的。我们通过对不同滞后选择方法进行广泛的实证分析来弥补文献中的这一差距。我们专注于以全局方法训练的深度学习方法，即包含多个单变量时间序列的数据集。实验使用三个基准数据库进行，其中总共包含 2411 个单变量时间序列。结果表明，滞后大小是准确预测的相关参数。特别是，过小或过大的滞后大小会对预测性能产生相当大的负面影响。交叉验证方法显示了滞后选择的最佳性能，但该性能与简单的启发式方法相当。]]></description>
      <guid>https://arxiv.org/abs/2405.11237</guid>
      <pubDate>Tue, 21 May 2024 21:12:59 GMT</pubDate>
    </item>
    <item>
      <title>使用低秩张量块风险模型进行因果客户流失分析</title>
      <link>https://arxiv.org/abs/2405.11377</link>
      <description><![CDATA[arXiv:2405.11377v1 公告类型：新 
摘要：本研究引入了一种创新方法，使用潜在结果框架来分析各种干预措施对客户流失的影响。我们提出了一种新的因果模型，即张量化潜在因素块风险模型，它结合了张量完成方法，用于对客户流失进行原则性因果分析。我们方法的一个关键要素是为参数张量制定 1 位张量补全。这可以从客户流失记录中捕获隐藏的客户特征和时间元素，从而有效地解决客户流失数据的二元性质及其时间单调趋势。我们的模型还根据类似的影响对干预措施进行独特的分类，从而提高了实施客户保留策略的准确性和实用性。为了提高计算效率，我们应用了投影梯度下降算法与谱聚类相结合。我们为我们的模型奠定了理论基础，包括其非渐近性质。通过模拟和实际应用的综合实验，进一步验证了我们模型的有效性和优越性。]]></description>
      <guid>https://arxiv.org/abs/2405.11377</guid>
      <pubDate>Tue, 21 May 2024 21:12:59 GMT</pubDate>
    </item>
    <item>
      <title>大数据有多大？</title>
      <link>https://arxiv.org/abs/2405.11404</link>
      <description><![CDATA[arXiv:2405.11404v1 公告类型：新 
摘要：大数据利用机器学习模型迎来了新一波的预测能力。在这项工作中，我们评估了“it big”在典型材料科学机器学习问题中的含义。这不仅涉及数据量，还涉及数据质量和准确性以及基础设施问题。通过选定的示例，我们询问（i）模型如何推广到类似的数据集，（ii）如何从异构来源收集高质量数据集，（iii）模型的特征集和复杂性如何影响表达性，以及（iv） ）创建更大的数据集并在其上训练模型需要哪些基础设施要求。总之，我们发现大数据在不同的方面提出了独特的挑战，这应该有助于激励进一步的工作。]]></description>
      <guid>https://arxiv.org/abs/2405.11404</guid>
      <pubDate>Tue, 21 May 2024 21:12:59 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习模型加速多级马尔可夫链蒙特卡罗</title>
      <link>https://arxiv.org/abs/2405.11179</link>
      <description><![CDATA[arXiv:2405.11179v1 公告类型：新 
摘要：这项工作提出了一种使用低保真机器学习模型加速大规模问题的多级马尔可夫链蒙特卡罗（MCMC）采样的有效方法。虽然大规模贝叶斯推理的传统技术通常用机器学习模型替代计算成本昂贵的高保真模型，从而引入近似误差，但我们的方法通过在分层框架内用低保真模型增强高保真模型，提供了一种计算高效的替代方案。多级方法利用低保真机器学习模型（MLM）对提议的样本进行廉价评估，从而提高高保真模型对样本的接受度。我们的多级算法中的层次结构源自几何多重网格层次结构。我们利用 MLM 来加速粗级采样。最粗级别的训练机器学习模型显着降低了与生成训练数据和训练模型相关的计算成本。我们提出了一种 MCMC 算法，使用 MLM 加速最粗级采样，并考虑引入的近似误差。我们提供了详细平衡的理论证明，并证明我们的多级方法构成了一致的 MCMC 算法。此外，我们得出了机器学习模型准确性的条件，以促进更有效的分层采样。我们的技术在地下水流中的标准基准推理问题上进行了演示，其中我们使用四级 MCMC 算法估计感兴趣数量的概率密度。与使用标准多级算法的采样相比，我们提出的算法将多级采样加速了两倍，同时实现了相似的精度。]]></description>
      <guid>https://arxiv.org/abs/2405.11179</guid>
      <pubDate>Tue, 21 May 2024 21:12:58 GMT</pubDate>
    </item>
    </channel>
</rss>