<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Fri, 07 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>重新加热基于梯度的离散抽样以进行组合优化</title>
      <link>https://arxiv.org/abs/2503.04047</link>
      <description><![CDATA[ARXIV：2503.04047V1公告类型：新 
摘要：最近，基于梯度的离散抽样已成为各种组合优化（CO）问题的高效，通用求解器，实现可与或超过流行数据驱动的方法相当的性能。但是，我们在这些方法中确定了一个关键问题，我们将其称为“在轮廓中徘徊”。这种行为是指很长一段时间以来共享非常相似的目标值的新不同解决方案，从而导致计算效率低下和对潜在解决方案的次优探索。在本文中，我们介绍了一种新型的再加热机制，灵感来自临界温度和物理中特定热量的概念，旨在克服这一限制。从经验上讲，我们的方法表明，在各种CO问题中，与现有基于采样和数据驱动的算法相比。]]></description>
      <guid>https://arxiv.org/abs/2503.04047</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与上限和下限模型的保形预测</title>
      <link>https://arxiv.org/abs/2503.04071</link>
      <description><![CDATA[ARXIV：2503.04071V1公告类型：新 
摘要：本文研究了在目标变量上仅确定性的下限和上限，用于在回归环境中建立预测间隔的共形预测（CP）方法。它提出了一种新的CP机制（CPUL），该机制通过在多个嵌套间隔构造方法上采用模型选择方法来超越后处理。矛盾的是，包括CPUL在内的许多公认的CP方法可能无法在界限紧密的地区提供足够的覆盖范围。为了纠正此限制，本文提出了一种最佳的阈值机制OMLT，该机制可调节具有底层底层的紧密区域的CPUL间隔。在大规模学习任务上验证了组合的CPUL-OMLT，其目标是绑定参数优化问题的最佳值。实验结果表明，各种数据集对基线方法的重大改进。]]></description>
      <guid>https://arxiv.org/abs/2503.04071</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联邦学习中的概括：有条件的相互信息框架</title>
      <link>https://arxiv.org/abs/2503.04091</link>
      <description><![CDATA[ARXIV：2503.04091V1公告类型：新 
摘要：联合学习（FL）是一种广泛采用的隐私性分布式学习框架，但与集中学习相比，其概括性能仍然较少。在FL中，概括错误由两个组成部分组成：样本外差距，该差距衡量参与客户的经验和真实风险之间的差距以及参与差距，从而量化了参与和非参与客户之间的风险差异。在这项工作中，我们通过条件相互信息（CMI）框架应用信息理论分析来研究FL的两级概括。除了传统的基于超级样本的CMI框架之外，我们还引入了超级构造，以适应FL中的两级概括设置。我们得出了多个基于CMI的界限，包括基于假设的CMI界限，说明了FL中的隐私约束如何暗示概括保证。此外，我们提出了快速评估评估的CMI界限，该界限恢复了小经验风险制度中两级FL概括的最著名的收敛速率。对于特定的FL模型汇总策略和结构化损失功能，我们完善了界限以相对于参与客户的数量提高收敛率。经验评估证实，我们评估的CMI界限是非易变的，并且可以准确捕获FL算法的概括行为。]]></description>
      <guid>https://arxiv.org/abs/2503.04091</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过直接效应分析学习因果反应表示</title>
      <link>https://arxiv.org/abs/2503.04358</link>
      <description><![CDATA[ARXIV：2503.04358V1公告类型：新 
摘要：我们提出了一种学习因果反应表示的新方法。我们的方法旨在提取方向，其中多维结果是由治疗变量最直接引起的。通过将有条件的独立性测试与因果表示学习，我们制定了一个优化问题，可以最大程度地提高证据，以防止治疗和结果之间的条件独立性，但给定条件集。该公式采用针对特定应用程序量身定制的灵活回归模型，创建了一个多功能框架。该问题是通过广义特征值分解来解决的。我们表明，在温和的假设下，最大的特征值的分布可以通过已知的$ f $分布来界定，从而实现了可检验的条件独立性。我们还提供理论保证，以最大程度地提高学术表示的最佳性，并最大化Fisher信息。最后，我们证明了我们的方法在模拟和现实实验中的经验有效性。我们的结果强调了该框架在复杂的多元设置中发现直接因果效应的实用性。]]></description>
      <guid>https://arxiv.org/abs/2503.04358</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>随时间变化的因素增强矢量自动进展，分组稀疏自动编码器</title>
      <link>https://arxiv.org/abs/2503.04386</link>
      <description><![CDATA[ARXIV：2503.04386V1公告类型：新 
摘要：最近的经济事件，包括全球金融危机和COVID-19大流行，在线性因子增强媒介自回旋（Favar）模型中揭示了预测和结构分析的局限性。非线性维度技术，尤其是自动编码器，在Favar框架中已成为有前途的替代方案，但是挑战仍然存在于可识别性，可解释性和与传统的非线性时间序列方法的集成中。我们通过两项贡献解决这些挑战。首先，我们介绍了一个分组的稀疏自动编码器，该自动编码器采用了尖峰和剪裁套索的先验，在此先验下的参数在同一经济类别的变量上共享，从而实现了半身份证性并增强了模型可解释性。其次，我们将随时间变化的参数纳入VAR组件，以更好地捕获不断发展的经济动态。我们在美国经济上的经验应用表明，散布的稀疏自动编码器通过其简约的结构产生了更多可解释的因素。它与时变参数的组合在点和密度预测中均显示出卓越的性能。冲动反应分析表明，与扩张期相比，衰退期间的货币政策冲击会产生更中等的反应，不确定性更高。]]></description>
      <guid>https://arxiv.org/abs/2503.04386</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在记忆约束和神经缩放规律下的决定性估计</title>
      <link>https://arxiv.org/abs/2503.04424</link>
      <description><![CDATA[ARXIV：2503.04424V1公告类型：新 
摘要：在许多机器学习任务中，计算或准确估算大型半明确矩阵的对数确定因素至关重要。尽管它的立方计算复杂性已经令人难以置信，但在现代应用中，即使存储矩阵本身也可能构成内存瓶颈。为了解决这个问题，我们根据在内存约束设置中的大规模对数确定计算的LDL分解的块计算得出了一种新颖的层次算法。在矩阵高度不良的极端情况下，准确地计算完整矩阵本身可能是不可行的。当考虑大规模的内核矩阵，包括在大型数据集中训练的神经网络的经验神经切线核（NTK）时，这一点尤其重要。在测试错误中的神经缩放定律的假设下，我们表明伪确定的比例满足了幂律关系，从而使我们得出相应的缩放定律。这可以从一小部分完整数据集中对NTK对数数据进行准确估算；在我们的实验中，这会导致$ \ sim $ 100,000 $ \ times $加速，并且在竞争近似方面的精度提高了。使用这些技术，我们成功地估计了对数确定的极端尺寸的密集矩阵，由于其巨大的规模和计算需求，以前被认为是棘手的和无法访问的。]]></description>
      <guid>https://arxiv.org/abs/2503.04424</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过云计算平台云计算平台跨蛋白质和供应商的固定前扣带回皮层的磁共振光谱的可重复性评估</title>
      <link>https://arxiv.org/abs/2503.04453</link>
      <description><![CDATA[ARXIV：2503.04453V1公告类型：新 
摘要：考虑到需要阐明疾病的基本机制及其治疗方法，以及在不同的磁共振系统供应商之间缺乏收购和后处理方案的协调，这项工作是为了确定从不同的会话，机器，机器模型，甚至可以高度复制的诊断症状的不同供应商中获得的代谢物浓度，是否可以从不同的课程，机器，甚至可以进行何种分析。参与者在一周内两天（每天一次，包括两个质子磁共振光谱（1H-MRS）扫描，在两天内进行了磁共振成像（MRI）扫描，每台扫描之间的间隔不超过5分钟的间隔（无折叠活动））。使用变异系数（CV）和类内相关系数（ICC）分析了内部和间隔之间的可靠性，并使用相关系数分析了整个机器的可重复性。至于会话内和会话之间，所有第一或第二次扫描的组的所有CV值几乎低于20％，代谢物的大多数ICC范围从中度（0.4-0.59）到优秀（0.75-1），表明高数据可靠性。当涉及到三个扫描仪的可重复性时，三台机器的Pearson相关系数均接近1，大多数约为0.9，大多数均显示出统计学意义（p &lt;0.01）。另外，供应商的可重复性大于供应商间供应商。]]></description>
      <guid>https://arxiv.org/abs/2503.04453</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过数据删除和复制中毒贝叶斯推断</title>
      <link>https://arxiv.org/abs/2503.04480</link>
      <description><![CDATA[ARXIV：2503.04480V1公告类型：新 
摘要：对抗机器学习（AML）的研究表明，统计模型容易受到恶意变化的数据。但是，尽管贝叶斯机器学习模型取得了进步，但大多数AML研究仍然集中在经典技术上。因此，我们专注于将白框模型中毒范式扩展到攻击通用的贝叶斯推断，从而突出了其在对抗环境中的脆弱性。开发了一系列攻击，使攻击者可以通过战略删除和真实观察的复制来将贝叶斯后部引导到目标分布，即使只有对后验进行采样。这些算法的分析特性得到了证明，并且在合成和现实世界情景中均可在经验上进行性能。攻击者的努力相对较少，能够实质性地改变贝叶斯的信念，并且通过接受更多的风险，他们可以将这些信念塑造成自己的意志。通过仔细构造对抗性后部，可以实现手术中毒，以便只有针对性的推论被损坏，而其他人则受到最小的干扰。]]></description>
      <guid>https://arxiv.org/abs/2503.04480</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Infosem：一个深层生成模型，具有提供基因调节网络推断的信息的先验</title>
      <link>https://arxiv.org/abs/2503.04483</link>
      <description><![CDATA[ARXIV：2503.04483V1公告类型：新 
摘要：从基因表达数据中推断基因调节网络（GRN）对于理解生物学过程至关重要。据报道，据报道，有监督的模型可以实现此任务的高性能，但它们依靠昂贵的基础真理（GT）标签和风险学习基因特异性偏见，例如GT相互作用的类不平衡，而不是真正的调节机制。为了解决这些问题，我们介绍了Infosem，这是一种无监督的生成模型，它利用文本基因嵌入作为信息的先验，改善GRN推断而没有GT标签。 Infosem还可以将GT标签纳入可用的额外先验，避免偏见并进一步提高性能。此外，我们提出了一个以生物学动机的基准框架，可以更好地反映现实世界中的应用，例如生物标志物发现，并揭示了现有监督方法的偏见。在将标记的数据集成为先验时，INFOSEM在四个数据集中的现有模型在四个数据集中的表现优于38.5％，并进一步将性能提高了11.1％。]]></description>
      <guid>https://arxiv.org/abs/2503.04483</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用先验在多臂匪徒的分配功能上</title>
      <link>https://arxiv.org/abs/2503.04518</link>
      <description><![CDATA[ARXIV：2503.04518V1公告类型：新 
摘要：我们介绍了Dirichlet过程后取样（DPPS），这是一种基于Dirichlet过程（DP）先验的多臂匪徒的贝叶斯非参数算法。像汤普森（Thompson）采样一样，DPPS是一种概率匹配算法，即，它基于其最佳后验证性而扮演的手臂。与其假设一个参数类用于每只手臂的奖励生成分布，然后在参数上进行先验，而是在DPPS中直接使用DP先验对奖励生成分布进行建模。 DPP提供了一种原则性的方法来纳入有关匪徒环境的先前信念，并以DP后代的非信息限制（即贝叶斯自举），我们恢复了非参数汤普森采样（NPTS），一种流行的非参数bastit算法，作为DPPS的特殊情况。我们采用DP先验的破坏性代表，并在具有挑战性的合成和现实世界的强盗环境中表现出DPP的出色经验表现。最后，使用信息理论分析，我们在贝叶斯遗憾设置中显示了DPP的非反应性最优性。]]></description>
      <guid>https://arxiv.org/abs/2503.04518</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于过滤的概率数值求解器传播模型不确定性</title>
      <link>https://arxiv.org/abs/2503.04684</link>
      <description><![CDATA[ARXIV：2503.04684V1公告类型：新 
摘要：用于普通微分方程（ODES）的基于过滤的概率数值求解器，也称为ODE过滤器，已被确定为量化ODE溶液中数值不确定性的有效方法。但是，在实际应用中，潜在的动态系统通常包含不确定的参数，这需要对ODE解决方案的不确定性传播。在本文中，我们证明了ODE过滤器尽管具有概率，但并不能自动解决这种不确定性传播问题。为了解决这一限制，我们提出了一种新颖的方法，该方法将ODE过滤器与数值正交相结合，以正确地将不确定参数边缘化，同时考虑参数不确定性和数值求解器不确定性。跨多个动态系统的实验表明，所得的不确定性估计与参考解决方案紧密匹配。值得注意的是，我们展示了来自ODE求解器的数值不确定性如何帮助防止传播不确定性估计值过度自信，尤其是在使用较大的步骤尺寸时。我们的结果表明，概率数值方法可以有效地量化动态系统中的数值和参数不确定性。]]></description>
      <guid>https://arxiv.org/abs/2503.04684</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>正规化可靠的学习者和实例攻击</title>
      <link>https://arxiv.org/abs/2410.10572</link>
      <description><![CDATA[ARXIV：2410.10572V2公告类型：交叉 
摘要：针对实例的数据中毒攻击，对手损坏了训练设置以引起特定测试点错误的训练，这引起了重大关注。 Balcan等人（2022年）提出了一种解决这一挑战的方法，它通过定义了可靠的学习者的概念，即使在存在数据中毒攻击的情况下，在定义明确的假设下，即使在定义明确的假设下提供正确的正确性保证。然后，他们提供了一种通用的最佳（但计算效率低下）可靠的学习者，以及通过log-conconcave分布的线性分离器的情况下的计算有效算法。
  在这项工作中，我们解决了Balcan等人（2022年）剩下的两个挑战。首先是，在Balcan等人（2022）中，对强烈的假设类别的鲁棒性学习者的定义变得空虚：如果有两个分类器H_0，H_1，H_1 \ in H中的H_1 \ acter h_1均在训练集中零错误，以便H_0（x）\ neq H_1（x）（x），然后是一个强大的启发者，则必须是x abstains obsstain on x on x on x on x on x on x on x on x on x on x on x on x。我们通过定义正规化的鲁棒性学习者的修改概念来解决这个问题，在这种情况下允许进行非平凡的陈述。第二个是Balcan等人（2022）的通用算法需要在每个测试点X上重新运行ERM Oracle（本质上，重新验证分类器），即使可以有效地实现ERM，这通常是不切实际的。为了解决这个问题，我们表明，至少在某些有趣的情况下，我们可以通过使用动态算法设计中的技术来设计算法，这些算法可以在训练时间中及时产生其输出。]]></description>
      <guid>https://arxiv.org/abs/2410.10572</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>积极的未标签扩散模型，用于预防敏感数据生成</title>
      <link>https://arxiv.org/abs/2503.03789</link>
      <description><![CDATA[ARXIV：2503.03789V1公告类型：交叉 
摘要：扩散模型是强大的生成模型，但通常会生成用户不需要的敏感数据，这主要是因为未标记的训练数据经常包含此类敏感数据。由于在大规模未标记的培训数据中标记所有敏感数据是不切实际的，因此我们通过使用少量标记的敏感数据来解决此问题。在本文中，我们提出了阳性未标记的扩散模型，该模型可以防止使用未标记和敏感数据产生敏感数据。我们的方法仅使用未标记和敏感（正）数据近似正常数据的证据（ELBO）。因此，即使没有标记的正常数据，我们也可以最大化ELBO以获得正常数据，并将其最小化以获得标记的敏感数据，从而确保仅生成正常数据。通过在各种数据集和设置上进行的实验，我们证明了我们的方法可以防止敏感图像的产生而不会损害图像质量。]]></description>
      <guid>https://arxiv.org/abs/2503.03789</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>刘易斯（层明智的稀疏） - 一种培训的免费指导模型合并方法</title>
      <link>https://arxiv.org/abs/2503.03874</link>
      <description><![CDATA[ARXIV：2503.03874V1公告类型：交叉 
摘要：随着专业的大语言模型（LLMS）变得越来越普遍，模型合并方法被用来组合它们以创建单个多任务模型，而无需任何其他数据或培训。但是，当合并的目的是在特定特定任务特定的基准上提高下游模型的性能时，这些方法缺乏。在这项工作中，我们提出了Lewis（Layer Wise Spartity），这是一个指导的模型合并框架，它使用基于激活的层重要性来动态调整合并过程所需的层任务 - 矢量稀疏性。刘易斯使用校准数据集在模型合并所需的任务矢量修剪过程中优先考虑关键层。这种方法通过保留基本的层次特定任务知识来指导现有的合并方法，同时确保合并模型在类似于校准数据集的基准下执行最佳基准。我们的实验证明了刘易斯的有效性，其绩效提高了通过模型合并高达4％和11.3％的模型创建的代码指令和数学解决模型，这表现优于无指导的无数据合并模型合并方法，这些方法使用均匀的距离。]]></description>
      <guid>https://arxiv.org/abs/2503.03874</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改进了ERD \ H {O} S-R \'Enyi图的强大估计：稀疏制度和最佳分解点</title>
      <link>https://arxiv.org/abs/2503.03923</link>
      <description><![CDATA[ARXIV：2503.03923V1公告类型：交叉 
摘要：我们研究了强有力估计ERD \ H {O} S-r \&#39;enyi随机图的边缘密度$ g（n，d^\ circ/n）$时，当对手可以任意地添加或删除Eta $ \ eta $ raction nodes的$ \ eta $ raction时。我们为这个问题开发了第一个多项式时间算法，该算法估算$ d^\ circ $ coct to添加错误$ o $ o（[\ sqrt {\ log（n） / n} + \ eta \ eta \ eta \ sqrt {\ log log（1 / \ eta）} \ log（1/\ eta））$。我们的错误保证将信息理论的下限与$ \ log（1/\ eta）$的因素相匹配。此外，我们的估计器适用于所有$ d^\ circ \ geq \ omega（1）$，并实现最佳分解点$ \ eta = 1/2 $。
  先前的算法[AJK+22，CDHS24]，包括效率低下的算法，会显着次优误差。此外，即使承认次优误差保证，只有效率低下的算法才能达到最佳分解点。我们的算法基于平方（SOS）层次结构。一个关键的成分是构建恒定的SOS证书，以$ g（n，d^\ circ/n）$中的小组的边缘数量浓度。至关重要的是，我们表明这些证书也存在于稀疏制度中，当$ d^\ circ = o（\ log n）$时，在这种制度中，以前的算法的性能显着次优。]]></description>
      <guid>https://arxiv.org/abs/2503.03923</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>