<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Fri, 21 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>采取基于扰动的医学AI解释</title>
      <link>https://arxiv.org/abs/2502.14001</link>
      <description><![CDATA[Arxiv：2502.14001V1公告类型：新 
摘要：机器学习算法的最新进步达到了可以配备人工智能（AI）模型的医疗设备，以诊断支持和常规自动化。在医学和医疗保健中，特别需要对AI模型产生的结果充分和客观的解释性。但是，由于AI模型的复杂性通常被视为黑匣子，并且导致其响应的计算过程通常是不透明的。尽管已经提出了几种方法来通过评估每个特征在歧视和预测中的重要性来解释模型的行为，但它们可能会遭受用于培训或测试的数据集的规模和采样方案引起的偏见和不相差。为了克服现有方法的缺点，我们探讨了一种替代方法，以提供可以独立于学习过程定义的AI模型的客观解释，并且不需要其他数据。作为这一研究方向的初步研究，这项工作研究了深度学习模型的雅各布矩阵的数值可用性，该矩阵衡量了对输入中添加的小型扰动的模型响应的稳定性。指示器（如果有）是根据给定目标输入的训练有素的AI模型计算的。这是迈向基于扰动的解释的第一步，该解释将有助于医生在其临床应用中理解和解释AI模型的响应。]]></description>
      <guid>https://arxiv.org/abs/2502.14001</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过发散组成的随机非凸优化的新下限</title>
      <link>https://arxiv.org/abs/2502.14060</link>
      <description><![CDATA[ARXIV：2502.14060V1公告类型：新 
摘要：我们研究了一系列非convex设置中一阶随机优化的基本限制，包括满足类星体 -  cosevexity（QC），二次增长（QG）和受限的SET不等式（RSI）的L-平滑函数（QC）。虽然标准算法的收敛性在确定性方案中得到了充分理解，但更少的结果解决了随机情况，在这种情况下，只有无偏见和嘈杂的梯度可用。我们在噪声梯度查询的数量上建立了新的下限，以最大程度地减少这些函数类别，还表明它们在表征每个类别的所有相关数量中都很紧密（达到对数因素）。我们的方法将优化任务重新制定为功能识别问题，利用差异组成论证来构建一个具有挑战性的子类，从而导致急剧的下限。此外，我们在一维设置中提出了一种专门的算法，该算法达到更快的速度，这表明某些维阈值对于非convex随机优化的复杂性是固有的。]]></description>
      <guid>https://arxiv.org/abs/2502.14060</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在l \'evy-prokhorov分布转移下的共形预测：对本地和全球扰动的鲁棒性</title>
      <link>https://arxiv.org/abs/2502.14105</link>
      <description><![CDATA[ARXIV：2502.14105V1公告类型：新 
摘要：共形预测提供了一个有限样本保证的预测间隔的强大框架，但其稳健性在分配变化下仍然是一个重大挑战。本文通过使用l \&#39;evy-prokhorov（LP）歧义集进行建模分布来解决此限制，从而捕获本地和全局扰动。我们提供了LP歧义集的独立概述及其与诸如Wasserstein和Total Nailiation之类的流行指标的联系。我们表明，共形预测与LP歧义集之间的联系是自然的：通过传播通过评分函数设置的LP歧义，我们将复杂的高维分布转移到可管理的一维分布转移，从而可以准确地量化最差的最差量化。案例分位数和覆盖范围。在此分析的基础上，我们构建了强大的保形预测间隔，这些间隔在分配变化下保持有效，明确将LP参数与间隔宽度和置信度联系在一起。现实世界数据集的实验结果证明了该方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.14105</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于网络黑盒系统的多目标贝叶斯优化：绿色利润和智能设计的途径</title>
      <link>https://arxiv.org/abs/2502.14121</link>
      <description><![CDATA[ARXIV：2502.14121V1公告类型：新 
摘要：设计现代工业系统需要平衡几个相互竞争的目标，例如盈利能力，弹性和可持续性，同时考虑了技术，经济和环境因素之间的复杂互动。多目标优化（MOO）方法通常用于导航这些权衡，但是选择适当的算法来解决这些问题通常不清楚，尤其是当系统表示从完全方程式（White-Box）变化到完全数据驱动的情况（ Black-Box）型号。尽管灰色盒Moo方法试图弥合这一差距，但它们通常对系统结构施加了严格的假设，要求模型符合求解器的基本结构假设，而不是求解器适应感兴趣系统的自然表示。在本章中，我们通过利用网络表示向Grey-Box MOO介绍了一种统一的方法，该方法为将互连系统建模为一系列具有共享各种输入和输出的功能节点提供了一个通用且灵活的框架。具体而言，我们提出了一种新型的贝叶斯优化风格的算法Mobons，可以有效地优化一般功能网络，包括具有循环依赖性的算法，启用反馈回路，循环流和多尺度模拟的建模 - 现有方法无法捕获的功能。此外，Mobons结合了约束，支持并行评估，并保留贝叶斯优化的样本效率，同时利用网络结构以提高可伸缩性。我们通过两个案例研究证明了Mobon的有效性，其中包括与可持续过程设计有关。通过在一般图表下启用高效的MOO，Mobons有可能显着增强更有利可图，弹性和可持续工程系统的设计。]]></description>
      <guid>https://arxiv.org/abs/2502.14121</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测驱动的自适应收缩估计</title>
      <link>https://arxiv.org/abs/2502.14166</link>
      <description><![CDATA[ARXIV：2502.14166V1公告类型：新 
摘要：预测驱动的推理（PPI）是通过将有限的金标准数据与机器学习（ML）预测相结合来增强统计估计的有力框架。虽然先前的工作证明了PPI对单个统计任务的好处，但现代应用需要回答许多并行的统计问题。我们介绍了预测驱动的自适应收缩（PAS），这种方法将PPI与经验贝叶斯收缩融合在一起，以改善多种均值的估计。 PAS DECIAS在每个任务中嘈杂的ML预测，然后通过使用相同的预测作为收缩的参考点来借用跨任务的强度。收缩量是通过最大程度地降低无偏见的风险估计来确定的，我们证明这种调整策略在渐近上是最佳的。在合成数据集和现实世界数据集的实验表明，PA适应了ML预测的可靠性，并且在大规模应用中胜过传统和现代基准。]]></description>
      <guid>https://arxiv.org/abs/2502.14166</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有线性函数近似的分布TD学习的有限样本分析</title>
      <link>https://arxiv.org/abs/2502.14172</link>
      <description><![CDATA[Arxiv：2502.14172V1公告类型：新 
摘要：在本文中，我们研究了分布时间差异（TD）学习的有限样本统计率，并使用线性函数近似。分配TD学习的目的是估算给定策略{\ pi}的折扣马尔可夫决策过程的回报分布。关于分布TD学习的统计分析的先前工作主要集中在表格案例上。相比之下，我们首先考虑线性函数近似设置并得出尖锐的有限样本率。我们的理论结果表明，线性分布TD学习的样本复杂性与经典线性TD学习的样本相匹配。这意味着，通过线性函数近似，使用流数据学习返回的完整分布并不比学习其期望（即值函数）更加困难。为了获得紧密的样本复杂性界限，我们对线性类别钟形方程进行细粒分析，并对随机矩阵的产物采用指数稳定性参数。我们的发现为分配增强学习算法的统计效率提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2502.14172</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自我监督转移学习的分配匹配</title>
      <link>https://arxiv.org/abs/2502.14424</link>
      <description><![CDATA[ARXIV：2502.14424V1公告类型：新 
摘要：在本文中，我们提出了一种称为分配匹配（DM）的新型自我监督的转移学习方法，该方法将表示分布向预定义的参考分布驱动，同时保持增强不变性。 DM的设计产生了一个学识渊博的表示空间，该空间具有直观的结构化，并提供了易于解释的超参数。多个现实世界数据集和评估指标之间的实验结果表明，与现有的自我监督转移学习方法相比，DM在目标分类任务上竞争性能。此外，我们为DM提供了强大的理论保证，包括人群定理和端到端样本定理。人口定理弥合了自我监督的学习任务和目标分类精度之间的差距，而样本定理表明，即使目标域中的样本数量有限，DM也可以提供出色的分类性能，只要未标记的样本量为足够大。]]></description>
      <guid>https://arxiv.org/abs/2502.14424</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>$ f $ -Divergence稳定算法的概括错误通过二元性</title>
      <link>https://arxiv.org/abs/2502.14544</link>
      <description><![CDATA[ARXIV：2502.14544V1公告类型：新 
摘要：使用$ f $ -Divergence正则化（ERM- $ F $ DR）的经验风险最小化解决方案扩展到约束优化问题，确定了解决方案和约束之间的等价条件。引入了ERM- $ F $ DR的双重公式，提供了一种计算有效的方法，以得出ERM-F $ DR解决方案的标准化功能。这种双重方法利用了Legendre-Fenchel变换和隐式函数定理，从而在轻度条件下对一般算法的一般算法进行明确特征，而另一种则可以对ERM-F $ DR Solutions进行明确特征。]]></description>
      <guid>https://arxiv.org/abs/2502.14544</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过顺序可能混合估算置信度</title>
      <link>https://arxiv.org/abs/2502.14689</link>
      <description><![CDATA[ARXIV：2502.14689V1公告类型：新 
摘要：我们提出了一个通用框架，用于基于顺序的似然混合来构建置信集。基于顺序分析的经典结果，我们为最近的几项工作提供了一个统一的观点，并建立了连续混合，贝叶斯推论和在线估计中遗憾不平等之间的基本联系。该框架适用于任何可实现的可能性功能家族，并允许非i.i.d。数据和任何时间有效性。此外，该框架无缝整合了标准的近似推理技术，例如基于变异的推理和基于采样的方法，并扩展到伪造的模型类，同时保留可证明的覆盖范围保证。我们通过在经典设置（包括顺序线性回归和稀疏估计）中得出更紧密的置信序列来说明框架的功能，并提供简化的证明。]]></description>
      <guid>https://arxiv.org/abs/2502.14689</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于约束的因果发现算法的内部不相互分数得分</title>
      <link>https://arxiv.org/abs/2502.14719</link>
      <description><![CDATA[ARXIV：2502.14719V1公告类型：新 
摘要：因果发现旨在从观察性或实验数据中推断出因果图。诸如流行的PC算法之类的方法基于有条件的独立性测试，并利用启用假设（例如忠实性假设）的推论。实际上，这些假设以及从所选条件独立性测试继承的功能假设通常被视为给定，并且没有进一步测试其在数据上的有效性。在这项工作中，我们提出了内部相干性评分，可以在不需要地面真相或进一步统计测试的情况下检测到违反假设和有限样本错误的测试。我们提供了错误结果的完整分类，包括可检测到的错误和无法检测到的错误之间的区别，并证明可以通过我们的分数来测量可检测到的错误结果。我们使用模拟和现实世界数据集说明了在PC算法上的相干性分数，并设想对内部相干性的测试可以成为应用基于约束方法的标准工具，就像一套测试套件一样，用于验证经典的假设。回归分析。]]></description>
      <guid>https://arxiv.org/abs/2502.14719</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过错误分类惩罚进行假设检验的强大信息选择</title>
      <link>https://arxiv.org/abs/2502.14738</link>
      <description><![CDATA[ARXIV：2502.14738V1公告类型：新 
摘要：我们研究了贝叶斯假设测试 /分类任务的强大信息选择问题，其目标是根据所选信息源的观察结果从一组有限的假设中识别世界的真实状态。我们引入了一个新颖的错误分类惩罚框架，该框架可以对不同的错误分类事件进行不均匀的处理。扩展了经典子集选择框架，我们研究了选择一部分来源的问题，这些来源可最大程度地减少预算下错误分类的最大罚款，尽管删除或失败了所选来源的子集。我们表征了目标函数的曲率特性，并提出了具有性能保证的有效贪婪算法。接下来，我们重点介绍了优化最大惩罚度量标准的某些局限性，并提出了一个suppular替代指标，以指导信息集的选择。我们提出了一种贪婪的算法，并提供了优化替代指标的近距离保证。最后，我们从经验上证明了我们提出的算法在信息集选择问题的几个实例中的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.14738</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多目标因果贝叶斯优化</title>
      <link>https://arxiv.org/abs/2502.14755</link>
      <description><![CDATA[ARXIV：2502.14755V1公告类型：新 
摘要：在决策问题中，干预的结果通常取决于系统组件之间的因果关系，并且评估的成本高昂。在这种情况下，因果贝叶斯优化（CBO）可以利用系统变量之间的因果关系，并顺序执行干预措施，以最小的数据接近最佳。将CBO扩展到多结果设置，我们提出了多目标因果贝叶斯优化（MO-CBO），这是一种范式，用于识别已知的多目标因果图中的帕累托 - 最佳干预措施。我们首先得出图形表征，以进行潜在的最佳变量集以进行干预。表明任何MO-CBO问题都可以分解为几个传统的多目标优化任务，然后我们引入了一种算法，该算法使用相对的超vOLUME改进来依次平衡这些任务的探索。所提出的方法将在合成和实际因果图上进行验证，以证明其优于传统的（非毒物）多目标贝叶斯在可有因果信息的设置中优化。]]></description>
      <guid>https://arxiv.org/abs/2502.14755</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>走向表示形式的学习理论</title>
      <link>https://arxiv.org/abs/2502.14047</link>
      <description><![CDATA[ARXIV：2502.14047V1公告类型：交叉 
摘要：最近有人争辩说，随着其规模和性能的提高，AI模型的表示形式变得一致。经验分析旨在支持这一想法，并猜测不同表示形式可能与共享的现实统计模型的一致性。在本文中，我们提出了一种学习理论的观点来对齐。首先，我们根据度量，概率和光谱思想审查并连接不同的对齐方式。然后，我们将重点放在缝线上，这是一种在任务背景下理解不同表示之间相互作用的特殊方法。我们这里的主要贡献是将缝合的特性与基础表示的内核比对有关。我们的结果可以看作是施放表示形式作为学习理论问题的第一步。]]></description>
      <guid>https://arxiv.org/abs/2502.14047</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>测量空间中重中心估计的有限样品边界</title>
      <link>https://arxiv.org/abs/2502.14069</link>
      <description><![CDATA[Arxiv：2502.14069V1公告类型：交叉 
摘要：我们研究了估计给定的分布的重中心的问题。地球空间中的数据。假设在Alexandrov的意义上构成了上层曲率，并具有支持条件，从而确保了Barycenter问题的强大测量凸度，我们在预期和概率很高的情况下建立了有限样本误差界限。我们的结果概括了Hoeffding-和Bernstein型浓度不平等，从欧几里得到地球空间。]]></description>
      <guid>https://arxiv.org/abs/2502.14069</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>零损失保证和明确的最小化器，用于通用过度兼容的深度学习网络</title>
      <link>https://arxiv.org/abs/2502.14114</link>
      <description><![CDATA[ARXIV：2502.14114V1公告类型：交叉 
摘要：我们确定了过多散射深度学习（DL）网络的足够条件，以确保在监督学习的背景下，零损失的可实现性，对于$ \ Mathcal {l}^2 $成本和{\ em emic}培训数据。我们提出了零损耗最小化器的明确结构，而无需调用梯度下降。另一方面，我们指出，使用梯度下降算法，深度的增加可以通过分析训练雅各布的等级损失条件来恶化成本最小化的效率。我们的结果阐明了二分法之间的关键方面，差距差损失范围与过多隔离的DL之间的二分法之间的关键方面。]]></description>
      <guid>https://arxiv.org/abs/2502.14114</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>