<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Thu, 04 Jan 2024 03:14:26 GMT</lastBuildDate>
    <item>
      <title>用于导出（时间均匀）PAC-贝叶斯界限的统一方法。 （arXiv：2302.03421v5 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2302.03421</link>
      <description><![CDATA[我们提出了一个用于推导 PAC-贝叶斯泛化的统一框架
界限。与大多数以前关于这个主题的文献不同，我们的界限是
任何时候有效（即时间一致），这意味着它们在所有停止时都保持不变
次，不仅适用于固定的样本量。我们的方法结合了四种工具
以下顺序： (a) 非负超鞅或逆
submartingales，(b) 混合物法，(c) Donsker-Varadhan 公式
（或其他凸对偶原理），以及 (d) 维尔不等式。我们的主要
结果是 PAC-Bayes 定理，该定理适用于广泛的离散类别
随机过程。我们展示了这个结果如何暗示时间一致的版本
著名的经典 PAC-Bayes 界限，例如 Seeger、McAllester 的界限，
毛雷尔（Maurer）和卡托尼（Catoni），以及最近的许多突破。我们还介绍了几款
小说的界限。我们的框架还使我们能够放宽传统假设；
特别是，我们考虑非平稳损失函数和非独立同分布。数据。在
总而言之，我们统一了过去界限的推导并简化了对未来的搜索
边界：可以简单地检查我们的上鞅条件或下鞅条件
满足，如果满足，则保证有（时间统一的）PAC-贝叶斯界限。
]]></description>
      <guid>http://arxiv.org/abs/2302.03421</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:26 GMT</pubDate>
    </item>
    <item>
      <title>$\ell_p$ 灵敏度采样的界限更清晰。 （arXiv：2306.00732v2 [cs.DS] 已更新）</title>
      <link>http://arxiv.org/abs/2306.00732</link>
      <description><![CDATA[在大规模机器学习中，随机采样是一种流行的方法
通过一小部分具有代表性的示例子集来近似数据集。在
特别是，灵敏度采样是一项经过深入研究的技术，
为近似的质量提供可证明的保证，同时减少
VC 维度 $d$ 与总数的乘积的示例数量
敏感度 $\mathfrak S$ 在非常一般的设置中。然而，保证
超出 $\mathfrak S d$ 的一般界限可能仅在
一种设置，用于 $\ell_2$ 子空间嵌入，尽管进行了大量研究
之前工作中的敏感性采样。在这项工作中，我们展示了第一个界限
$\ell_p$ 子空间嵌入的敏感度采样 $p &gt; 2$ 改善
超过一般的 $\mathfrak S d$ 界限，达到大约 $\mathfrak 的界限
S^{2-2/p}$ 为 $2]]></description>
      <guid>http://arxiv.org/abs/2306.00732</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:26 GMT</pubDate>
    </item>
    <item>
      <title>一般功能空间中的最优传输图估计。 （arXiv：2212.03722v2 [math.ST] 已更新）</title>
      <link>http://arxiv.org/abs/2212.03722</link>
      <description><![CDATA[我们研究在给定独立样本的情况下估计函数 $T$ 的问题
来自分布 $P$ 和前推分布 $T_\sharp P$。
此设置的动机是科学应用，其中 $T$ 代表
物理系统随时间的演变，以及在机器学习中，
例如，$T$ 可能表示深度神经网络学习到的转换
为生成建模任务训练的网络。为了确保可识别性，我们
假设 $T = \nabla \varphi_0$ 是凸函数的梯度，在
这种情况$T$被称为\emph{最优传输图}。之前的工作有
研究了 $T$ 的估计，假设它位于 H\&quot;older 中
类，但缺乏一般理论。我们提出了一个统一的方法论
获得一般函数中最优传输图的估计率
空间。我们的假设明显弱于那些出现在
文献：我们只要求源测度 $P$ 满足庞加莱方程
不等式并且最优映射是平滑凸函数的梯度
它位于一个度量熵可以控制的空间中。作为一个特例，
我们恢复了 H\&quot; 旧传输地图的已知估计率，而且还获得了
在之前的工作未涵盖的许多设置中，结果几乎是清晰的。例如，
当 $P$ 为正态时，我们提供第一个统计估计率
分布和传输图由无限宽度的浅层神经网络给出
网络。
]]></description>
      <guid>http://arxiv.org/abs/2212.03722</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:25 GMT</pubDate>
    </item>
    <item>
      <title>随机系综的贝叶斯后验近似。 （arXiv：2212.08123v3 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2212.08123</link>
      <description><![CDATA[我们引入随机神经网络的集合来近似
贝叶斯后验，结合随机方法，例如 dropout 和 deep
合奏团。随机系综被表述为分布族
并训练以通过变分推理来近似贝叶斯后验。
我们基于蒙特卡罗 dropout、DropConnect 和
一种新颖的非参数版本的 dropout 并在玩具问题上对其进行评估
和 CIFAR 图像分类。对于这两项任务，我们测试了
后验直接针对哈密顿蒙特卡罗模拟。我们的成果
表明随机系综提供的后验估计比
贝叶斯推理的其他流行基线。
]]></description>
      <guid>http://arxiv.org/abs/2212.08123</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:25 GMT</pubDate>
    </item>
    <item>
      <title>正则化 M 估计量的单指数模型中的可观察调整。 （arXiv：2204.06990v3 [math.ST] 已更新）</title>
      <link>http://arxiv.org/abs/2204.06990</link>
      <description><![CDATA[我们考虑来自具有未知链接的单索引模型的观察$(X,y)$
函数、高斯协变量和正则化 M 估计量 $\hat\beta$
由凸损失函数和正则化器构造而成。在政权中
样本大小 $n$ 和维度 $p$ 都在增加，使得 $p/n$ 具有
有限极限，$\hat\beta$ 的经验分布的行为以及
预测值 $X\hat\beta$ 之前已在许多方面进行了表征
模型：已知经验分布会收敛到邻近算子
相关高斯序列模型中的损失和惩罚，捕获
比率 $p/n$、损失、正则化和数据生成之间的相互作用
过程。 $(\hat\beta,X\hat\beta)$ 和相应的之间的这种联系
近端算子需要求解通常涉及的定点方程
不可观察的量，例如索引或链接上的先验分布
功能。

本文提出了一种不同的理论来描述经验分布
$\hat\beta$ 和 $X\hat\beta$ 的近似值：$(\hat\beta,X\hat\beta)$ 的近似值
提供了仅涉及可观察的近端算子项
调整。这些建议的可观察调整是数据驱动的，例如，
不需要索引或链接函数的先验知识。这些新
调整产生指数各个组成部分的置信区间，
以及 $\hat\beta$ 与指数相关性的估计。这
因此，损失、正则化和模型之间的相互作用被捕获在
数据驱动的方式，无需求解中研究的定点方程
以前的作品。结果适用于强凸正则化器和
非正则 M 估计。模拟提供了正方形和
单指数模型中的逻辑损失，包括逻辑回归和 1 位
具有 20\% 损坏位的压缩感知。
]]></description>
      <guid>http://arxiv.org/abs/2204.06990</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:24 GMT</pubDate>
    </item>
    <item>
      <title>使用正则化稀疏自动编码器预测良好的反应坐标和 MD 轨迹的未来演化：一种新颖的深度学习方法。 （arXiv：2208.10962v2 [physical.chem-ph] 已更新）</title>
      <link>http://arxiv.org/abs/2208.10962</link>
      <description><![CDATA[识别反应坐标（RC）是一个活跃的研究领域，考虑到
RC 在决定化学反应进程中发挥着至关重要的作用。
反应坐标的选择通常基于启发式知识。
然而，选择的一个基本标准是坐标应该
明确捕获反应物和产物状态。另外，
坐标应该是最慢的一个，以便所有其他自由度
可以很容易地沿着反应坐标平衡。另外，坐标
应该是最慢的一个，以便所有其他自由度都可以轻松
沿反应坐标平衡。我们使用正则化稀疏
自动编码器，一种基于能量的模型，用于发现一组关键的反应
坐标。除了发现反应坐标之外，我们的模型还
预测分子动力学 (MD) 轨迹的演化。我们展示了
包括稀疏性强制正则化有助于选择一个小但
一组重要的反应坐标。我们使用两个模型系统来演示
我们的方法：丙氨酸二肽系统以及原黄素和 DNA 系统，
在水溶液中表现出原黄素嵌入 DNA 小沟中
环境。我们将 MD 轨迹建模为多元时间序列，并且我们的
潜变量模型执行多步时间序列预测的任务。
这个想法受到流行的稀疏编码方法的启发 - 表示每个
输入样本是取自一组的几个元素的线性组合
代表性图案。
]]></description>
      <guid>http://arxiv.org/abs/2208.10962</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:24 GMT</pubDate>
    </item>
    <item>
      <title>通过差异传播验证复合系统。 （arXiv：2210.12061v2 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2210.12061</link>
      <description><![CDATA[评估现实世界系统在给定质量方面的有效性
由于大量的数据，标准是工业应用中一项常见但成本高昂的任务
所需的实际测试数量。通过以下方式验证此类系统
模拟提供了一种有前途且成本较低的替代方案，但需要
评估模拟精度并因此进行端到端测量。
此外，模拟和实际使用之间的协变量变化可能会导致
估计此类系统的可靠性存在困难。在这项工作中，我们
提出一种传播分布边界的验证方法
通过复合系统测量差异，从而使我们能够得出
真实系统潜在故障概率的上限
不准确的模拟。每个传播步骤都需要一个优化问题，
其中——对于诸如最大平均差异（MMD）之类的衡量标准——我们制定
基于半定规划的紧凸松弛。我们证明
我们的传播方法为复合系统产生有效且有用的界限
呈现出多种逼真的效果。特别是，我们表明
所提出的方法可以成功地解释数据转移
实验设计以及模拟中的模型不准确。
]]></description>
      <guid>http://arxiv.org/abs/2210.12061</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:24 GMT</pubDate>
    </item>
    <item>
      <title>具有未知上下文分布的上下文强盗的最佳交叉学习。 （arXiv：2401.01857v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.01857</link>
      <description><![CDATA[我们考虑设计上下文老虎机算法的问题
Balseiro 等人的“交叉学习”设置，学习者观察
他们在所有可能的情况下所采取的行动而损失，而不仅仅是在
本轮。我们特别考虑选择损失的设置
对抗性地对上下文进行独立同分布采样。来自未知的分布。在
在这个设置中，我们解决了 Balseiro 等人的一个开放问题。通过提供
具有近乎严格（最多对数因子）遗憾的高效算法
$\widetilde{O}(\sqrt{TK})$ 的边界，与上下文的数量无关。作为
结果，我们获得了问题的第一个近乎严格的后悔界限
学习在最高价拍卖中出价（在未知的价值分布下）
以及具有随机动作集的沉睡强盗。

我们算法的核心是一种协调的新技术
在多个时期执行学习算法，以消除
未知分布的估计与行动之间的相关性
由算法播放。这项技术可能会引起独立的兴趣
涉及未知上下文估计的其他学习问题
分配。
]]></description>
      <guid>http://arxiv.org/abs/2401.01857</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:23 GMT</pubDate>
    </item>
    <item>
      <title>关于对称下学习的难度。 （arXiv：2401.01869v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.01869</link>
      <description><![CDATA[我们研究通过梯度学习等变神经网络的问题
血统。将已知的对称性（“等方差”）纳入神经网络
NETs 根据经验改进了领域中学习管道的性能
从生物学到计算机视觉。然而，丰富而独立的产品线
学习理论研究表明，实际上学习是浅层的，
全连接（即非对称）网络的复杂度呈指数级
相关统计查询（CSQ）模型，一个包含梯度的框架
血统。在这项工作中，我们问：已知的问题对称性是否足以
减轻梯度学习神经网络的基本难度
血统？我们对这个问题的回答是否定的。特别是，我们给予较低的
浅图神经网络、卷积网络、不变性的界限
多项式和用于置换子群的帧平均网络，它们都
在相关输入中以超多项式或指数方式缩放
方面。因此，尽管通过传递显着的感应偏置
对称性，实际上学习由 表示的完整函数类
通过梯度下降的等变神经网络仍然很困难。
]]></description>
      <guid>http://arxiv.org/abs/2401.01869</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:23 GMT</pubDate>
    </item>
    <item>
      <title>深度学习线性分数过程的 Hurst 参数并评估其可靠性。 （arXiv：2401.01789v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.01789</link>
      <description><![CDATA[这项研究探讨了深度学习的可靠性，特别是 Long
短期记忆 (LSTM) 网络，用于估计中的 Hurst 参数
分数随机过程。该研究重点关注三种类型的过程：
分数布朗运动 (fBm)、分数奥恩斯坦-乌伦贝克 (fOU) 过程、
和线性分数稳定运动（lfsm）。这项工作涉及快速
为 fBm 和 fOU 生成广泛的数据集，以训练 LSTM 网络
在可行的时间内获取大量数据。研究分析了该方法的准确性
LSTM网络关于各种性能的Hurst参数估计
RMSE、MAE、MRE 以及绝对和相对分位数等度量
错误。研究发现 LSTM 在以下方面优于传统统计方法
fBm 和 fOU 流程的情况；然而，它在 lfsm 上的准确性有限
流程。该研究还深入探讨了训练长度的影响
以及评估序列长度对 LSTM 性能的影响。方法论是
通过估计锂离子电池退化数据中的 Hurst 参数来应用
并获得估计的置信界限。研究结论是
而深度学习方法在分数参数估计方面显示出前景
流程，其有效性取决于流程类型和
训练数据的质量。
]]></description>
      <guid>http://arxiv.org/abs/2401.01789</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>使用均匀分布网格上的分类来有效计算置信集。 （arXiv：2401.01804v1 [econ.EM]）</title>
      <link>http://arxiv.org/abs/2401.01804</link>
      <description><![CDATA[经济模型产生矩不等式，可用于形成检验
的真实参数。导出真实参数的置信集 (CS)
通过反转这些测试。然而，他们往往缺乏分析表达，
需要进行网格搜索以通过保留网格以数字方式获得 CS
通过测试的点。当统计量不是渐近关键时，
为参数空间中的每个网格点构建临界值添加
计算负担。在本文中，我们将计算问题转换为
使用支持向量机 (SVM) 解决分类问题
分类器。其决策功能提供了一种更快、更系统的方法
将参数空间分为两个区域：内部与外部
置信度。我们将 CS 中的那些点标记为 1，将 CS 之外的点标记为 -1。
研究人员可以在大小和用途可管理的网格上训练 SVM 分类器
它来确定较密集网格上的点是否在 CS 中。我们
为网格建立某些条件，以便进行调整
我们在 CS 中渐进地重现测试。这意味着在
极限，当且仅当一个点被分类为属于置信集
它被 SVM 标记为 1。
]]></description>
      <guid>http://arxiv.org/abs/2401.01804</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>用于高维因果推理的深度因果生成模型的模块化学习。 （arXiv：2401.01426v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.01426</link>
      <description><![CDATA[Pearl 的因果层次结构在
观察性问题、干预性问题和反事实问题。研究人员
提出了合理且完整的算法来计算可识别的因果查询
在层次结构的给定级别，使用因果结构和数据
层次结构的较低级别。然而，大多数这些算法都假设我们
可以准确地估计数据的概率分布，即
对于图像等高维变量的不切实际的假设。上
另一方面，现代生成深度学习架构可以经过训练
了解如何从此类高维分布中准确采样。
特别是随着最近图像基础模型的兴起，
希望利用预先训练的模型来回答因果查询
高维数据。为了解决这个问题，我们提出了顺序训练
算法，给定因果结构和预先训练的条件
生成模型，可以训练深度因果生成模型，该模型利用
预先训练的模型，可以证明从可识别的干预和
反事实分布。我们的算法称为 Modular-DCM，使用
对抗性训练来学习网络权重，并尽我们所能
知识，是第一个可以利用预先训练的模型和
在存在潜在特征的情况下，从任何可识别的因果查询中抽取可证明的样本
与高维数据的混淆。我们展示了我们的实用性
使用包含图像的半合成和真实数据集的算法
因果结构中的变量。
]]></description>
      <guid>http://arxiv.org/abs/2401.01426</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>通过深度集线性化最优传输进行点云分类。 （arXiv：2401.01460v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.01460</link>
      <description><![CDATA[我们引入了 Deep Set Linearized Optimal Transport，这是一种专为
将点云有效地同时嵌入到$L^2-$空间中。这
嵌入保留了 Wasserstein 中特定的低维结构
空间，同时构造一个分类器来区分不同类别的
点云。我们的方法的动机是观察到 $L^2-$distances
不同点云的最佳传输图之间，源自
共享固定参考分布，提供近似值
在某些假设下，Wasserstein-2 点云之间的距离。
为了学习这些传输图的近似值，我们采用输入凸神经网络
网络（ICNN）并确定，在特定条件下，欧几里得
这些 ICNN 样本之间的距离与 Wasserstein-2 非常接近
真实分布之间的距离。此外，我们还训练了一个
判别器网络对这些样本赋予权重并创建一个
排列不变分类器来区分不同类别的
点云。我们展示了我们的算法相对于标准算法的优势
通过在流式细胞术数据集上进行实验的深集方法
有限数量的标记点云。
]]></description>
      <guid>http://arxiv.org/abs/2401.01460</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>模型平均和双重机器学习。 （arXiv：2401.01645v1 [econ.EM]）</title>
      <link>http://arxiv.org/abs/2401.01645</link>
      <description><![CDATA[本文讨论了双重/去偏机器学习 (DDML) 与
Stacking，一种组合多个候选学习器的模型平均方法，
估计结构参数。我们引入两种新的堆叠方法
DDML：短堆栈充分利用了 DDML 的交叉拟合步骤
减少计算负担，池化堆叠强制通用堆叠
重量超过交叉拟合折叠。使用校准模拟研究和两个
在估算引用和工资方面的性别差距的应用程序中，我们表明 DDML
与常见的相比，堆叠对于部分未知的功能形式更稳健
基于单个预选学习者的替代方法。我们提供Stata
和 R 软件实施我们的建议。
]]></description>
      <guid>http://arxiv.org/abs/2401.01645</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>次二次时间内的可扩展网络重建。 （arXiv：2401.01404v1 [cs.DS]）</title>
      <link>http://arxiv.org/abs/2401.01404</link>
      <description><![CDATA[网络重建在于确定未观察到的成对
仅给出结果的观测数据的 $N$ 节点之间的耦合
以这些耦合为条件的行为——通常是时间序列或
来自图形模型的独立样本。可扩展性的主要障碍
针对这个问题提出的算法是一个看似不可避免的二次方程
复杂度为$O(N^2)$，对应于每个可能的要求
成对耦合至少被考虑过一次，尽管事实上大多数
感兴趣的网络是稀疏的，具有许多非零耦合，即
只有$O(N)$。在这里，我们提出了一种适用于广泛领域的通用算法
重建问题在次二次时间内实现其结果，其中
数据相关的复杂性松散上限为 $O(N^{3/2}\log N)$，但
更典型的对数线性复杂度为 $O(N\log^2N)$。我们的算法依赖于
随机第二邻域搜索，产生最佳边缘候选
高概率，从而绕过详尽的二次搜索。在实践中，
我们的算法的性能提高了许多数量级
比二次基线更容易并行化，从而使
几十万甚至上百万的网络重构
节点和边。
]]></description>
      <guid>http://arxiv.org/abs/2401.01404</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:20 GMT</pubDate>
    </item>
    </channel>
</rss>