<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 13 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>稀疏上下文特定因果系统的可扩展结构学习</title>
      <link>https://arxiv.org/abs/2402.07762</link>
      <description><![CDATA[已经提出了几种以图形方式表示联合分布的分类变量之间的上下文特定关系的方法以及结构学习算法。虽然现有的基于优化的方法由于存在大量特定于上下文的模型而具有有限的可扩展性，但基于约束的方法甚至比基于约束的 DAG 学习算法更容易出错，因为必须测试更多的关系。我们提出了一种用于学习特定于上下文的模型的混合算法，该算法可扩展到数百个变量，同时测试的约束不比标准 DAG 学习算法多。可扩展学习是通过基于顺序的 MCMC 算法和类似于 DAG 模型通常调用的稀疏假设的组合来实现的。为了实现该方法，我们解决了 Alon 和 Balogh 最近提出的一个开放问题的特殊情况。事实证明，该方法在准确性和可扩展性方面在合成数据和现实世界示例上表现良好。]]></description>
      <guid>https://arxiv.org/abs/2402.07762</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:04 GMT</pubDate>
    </item>
    <item>
      <title>测试风险的随机梯度流动力学及其弱特征精确解</title>
      <link>https://arxiv.org/abs/2402.07626</link>
      <description><![CDATA[我们研究了学习理论中连续时间随机梯度流动力学的测试风险。使用路径积分公式，我们在小学习率的情况下提供了计算纯梯度流和随机梯度流的测试风险曲线之间差异的通用公式。我们将一般理论应用于弱特征的简单模型，该模型显示了双下降现象，并明确计算了动力学中添加的随机项带来的修正，作为时间和模型参数的函数。将分析结果与离散时间随机梯度下降的模拟进行比较，结果显示出良好的一致性。]]></description>
      <guid>https://arxiv.org/abs/2402.07626</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:03 GMT</pubDate>
    </item>
    <item>
      <title>通过分数式福克-普朗克方程的重尾 SDE 的泛化界限</title>
      <link>https://arxiv.org/abs/2402.07723</link>
      <description><![CDATA[在过去的几年里，了解重尾随机优化算法的泛化特性引起了越来越多的关注。虽然通过使用重尾随机微分方程作为代理来阐明随机优化器的有趣方面，但先前的工作要么提供了预期的泛化界限，要么引入了不可计算的信息理论术语。为了解决这些缺点，在这项工作中，我们证明了不包含任何重要信息论术语的重尾 SDE 的高概率泛化界限。为了实现这一目标，我们开发了基于估计与所谓的分数式 Fokker-Planck 方程（控制相应重尾 SDE 分布演化的偏微分方程）相关的熵流的新证明技术。除了获得高概率边界之外，我们还表明与现有技术相比，我们的边界更好地依赖于参数的维度。我们的结果进一步确定了相变现象，这表明重尾可能是有益的，也可能是有害的，具体取决于问题的结构。我们通过在各种环境下进行的实验来支持我们的理论。]]></description>
      <guid>https://arxiv.org/abs/2402.07723</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:03 GMT</pubDate>
    </item>
    <item>
      <title>使用 BAM 进行图结构推理：引入双线性注意力机制</title>
      <link>https://arxiv.org/abs/2402.07735</link>
      <description><![CDATA[在统计学和机器学习中，检测数据集中的依赖性是一个核心挑战。我们提出了一种用于监督图结构学习的新型神经网络模型，即学习观察数据与其底层依赖结构之间的映射的过程。该模型使用可变形状和耦合的模拟输入数据进行训练，并且仅需要通过训练网络进行一次前向传递即可进行推理。通过利用结构方程模型并采用随机生成的多元切比雪夫多项式来模拟训练数据，我们的方法展示了跨线性和各种类型的非线性依赖关系的强大通用性。我们引入了一种新颖的双线性注意机制（BAM），用于显式处理依赖信息，该机制在变换数据的协方差矩阵级别上运行，并尊重对称正定矩阵流形的几何形状。实证评估证明了我们的方法在检测各种依赖性方面的鲁棒性，在无向图估计方面表现出色，并通过一种新颖的两步方法在完整的部分有向无环图估计方面证明了竞争力。]]></description>
      <guid>https://arxiv.org/abs/2402.07735</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:03 GMT</pubDate>
    </item>
    <item>
      <title>多臂老虎机中的可复制性是渐近自由的</title>
      <link>https://arxiv.org/abs/2402.07391</link>
      <description><![CDATA[这项工作的动机是对可重复机器学习不断增长的需求。我们研究随机多臂老虎机问题。特别是，我们考虑一种可复制的算法，该算法以高概率确保算法的操作序列不受数据集中固有的随机性的影响。我们观察到现有算法比不可复制算法需要 $O(1/\rho^2)$ 倍的遗憾，其中 $\rho$ 是不可复制的级别。然而，我们证明，当时间范围 $T$ 对于给定的 $\rho$ 足够大时，只要仔细选择置信界限的大小，这种额外成本是不必要的。我们引入了一种探索然后提交算法，该算法在提交到单个手臂之前统一绘制手臂。此外，我们还研究了一种连续消除算法，该算法在每个阶段结束时消除次优臂。为了确保这些算法的可复制性，我们将随机性纳入其决策过程中。我们还将连续消除法的使用扩展到线性老虎机问题。为了分析这些算法，我们提出了一种限制不复制概率的原则方法。这种方法阐明了现有研究隐含遵循的步骤。此外，我们推导了双臂可复制老虎机问题的第一个下界，这意味着所提出的算法在双臂情况下达到 $\log\log T$ 因子的最优性。]]></description>
      <guid>https://arxiv.org/abs/2402.07391</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:02 GMT</pubDate>
    </item>
    <item>
      <title>与单一对手的顶级 $K$ 排名</title>
      <link>https://arxiv.org/abs/2402.07445</link>
      <description><![CDATA[在本文中，我们解决了单调对手的 top-$K$ 排名问题。我们考虑随机生成比较图并且允许对手添加任意边的场景。然后，统计学家的目标是根据从该半随机比较图得出的成对比较，准确识别 top-$K$ 首选项目。本文的主要贡献是开发了一种加权最大似然估计器 (MLE)，它可以实现接近最优的样本复杂性，最高可达 $\log^2(n)$ 因子，其中 n 表示比较的项目数量。这是通过分析和算法创新的结合实现的。在分析方面，我们提供了加权 MLE 的精细 $\ell_\infty$ 误差分析，它比现有分析更明确、更严格。它将 $\ell_\infty$ 误差与加权比较图的光谱特性联系起来。受此启发，我们的算法创新涉及开发基于 SDP 的方法来重新加权半随机图并满足指定的光谱属性。此外，我们提出了一种基于矩阵乘法权重更新（MMWU）框架的一阶方法。该方法在相对于半随机比较图的大小的近线性时间内有效地求解了所得的 SDP。]]></description>
      <guid>https://arxiv.org/abs/2402.07445</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:02 GMT</pubDate>
    </item>
    <item>
      <title>自洽共形预测</title>
      <link>https://arxiv.org/abs/2402.07307</link>
      <description><![CDATA[在机器学习指导的决策中，决策者经常在具有相同预测结果的背景下采取相同的行动。共形预测有助于决策者量化行动结果的不确定性，从而实现更好的风险管理。受这个观点的启发，我们引入了自洽共形预测，它产生了 Venn-Abers 校准预测和共形预测区间，它们在模型预测提示的行动的条件下有效。我们的程序可以事后应用于任何黑盒预测器，以提供严格的、针对具体行动的决策保证。数值实验表明我们的方法在区间效率和条件有效性之间取得了平衡。]]></description>
      <guid>https://arxiv.org/abs/2402.07307</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>线性强盗的噪声自适应置信集及其在贝叶斯优化中的应用</title>
      <link>https://arxiv.org/abs/2402.07341</link>
      <description><![CDATA[适应先验未知的噪声水平是顺序决策中一个非常重要但具有挑战性的问题，因为有效的探索通常需要了解噪声水平，而噪声水平通常是松散指定的。我们报告在解决线性老虎机问题方面取得了两个方面的重大进展。首先，我们提出了一种新颖的置信集，它对未知的亚高斯参数 $\sigma_*^2$ 具有“半自适应”作用，因为（归一化的）置信宽度随 $\sqrt{d\sigma_*^ 缩放2 + \sigma_0^2}$ 其中 $d$ 是维度，$\sigma_0^2$ 是指定的亚高斯参数（已知），可以比 $\sigma_*^2$ 大得多。与 Abbasi-Yadkori 等人的标准置信集 $\sqrt{d\sigma_0^2}$ 相比，这是一个显着的改进。 (2011)，特别是当 $d$ 很大时。我们证明这会导致线性老虎机的后悔界限得到改善。其次，对于有界奖励，我们提出了一种新颖的方差自适应置信集，其在现有技术的基础上具有大大改进的数值性能。然后，正如我们声称的那样，我们应用这个置信集通过乐观方法开发第一个实用的方差自适应线性老虎机算法，这是由我们新颖的后悔分析技术实现的。我们的两种信心都严重依赖于在线学习的“后悔平等”。我们在贝叶斯优化任务中的实证评估表明，与现有方法相比，我们的算法表现出更好或相当的性能。]]></description>
      <guid>https://arxiv.org/abs/2402.07341</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>用于快速自适应预测区间的回归树</title>
      <link>https://arxiv.org/abs/2402.07357</link>
      <description><![CDATA[预测模型会犯错误。因此，需要量化与其预测相关的不确定性。共形推理已成为围绕点预测创建统计上有效的预测区域的强大工具，但其对回归问题的简单应用会产生非自适应区域。新的共形分数通常依赖于分位数回归器或条件密度估计器，旨在解决这一限制。尽管它们对于创建预测带很有用，但这些分数脱离了量化任意预测模型的不确定性的原始目标。本文提出了一系列与模型无关的新方法，用于校准具有局部覆盖保证的回归问题的预测区间。我们的方法基于追求近似条件覆盖的特征空间的最粗划分。我们通过根据一致性分数训练回归树和随机森林来创建此分区。我们的建议是通用的，因为它适用于各种一致性分数和预测设置，并且与模拟和现实数据集中建立的基线相比，表现出卓越的可扩展性和性能。我们提供了一个 Python 包 locart，它使用标准 scikit-learn 接口来实现我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2402.07357</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>PASOA- 基于粒子的贝叶斯最优自适应设计</title>
      <link>https://arxiv.org/abs/2402.07160</link>
      <description><![CDATA[我们提出了一种名为 PASOA 的新程序，用于贝叶斯实验设计，它通过同时提供参数推断的连续后验分布的准确估计来执行顺序设计优化。顺序设计过程是通过对比估计原理进行的，使用随机优化和顺序蒙特卡罗 (SMC) 采样器来最大化预期信息增益 (EIG)。由于连续后验分布之间的距离越大，获得的信息增益就越大，因此此 EIG 目标可能会恶化经典 SMC 性能。为了解决这个问题，建议通过回火来获得大的信息增益和准确的 SMC 采样，我们证明这对于性能至关重要。这种随机优化和调节 SMC 的新颖组合允许共同处理设计优化和参数推断。我们提供了一个证明，证明所获得的最优设计估计量受益于某些一致性属性。数值实验证实了该方法的潜力，其性能优于其他最新的现有程序。]]></description>
      <guid>https://arxiv.org/abs/2402.07160</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>通过张量随机投影改进 LSH</title>
      <link>https://arxiv.org/abs/2402.07189</link>
      <description><![CDATA[局部敏感哈希 (LSH) 是数据科学家用于近似最近邻搜索问题的基本算法工具包，已广泛用于许多大规模数据处理应用，例如近重复检测、最近邻搜索、聚类等。 ，我们的目标是为张量数据的欧几里德距离和余弦相似度提出更快且空间有效的局部敏感哈希函数。通常，获取张量数据的 LSH 的简单方法包括首先将张量重塑为向量，然后对向量数据 $E2LSH$ 和 $SRP$ 应用现有的 LSH 方法。然而，这种方法对于高阶张量来说变得不切实际，因为重构向量的大小按照张量的阶数呈指数变化。因此，LSH 参数的大小呈指数增长。为了解决这个问题，我们建议两种用于欧氏距离和余弦相似度的 LSH 方法，即 $CP-E2LSH$、$TT-E2LSH$ 和 $CP-SRP$、$TT-SRP$，分别建立在 $CP 的基础上$ 和张量训练 $(TT)$ 分解技术。我们的方法具有空间效率，并且可以有效地应用于低阶 $CP$ 或 $TT$ 张量。我们对我们的提案的正确性和有效性进行了严格的理论分析。]]></description>
      <guid>https://arxiv.org/abs/2402.07189</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>平均场体系中图神经网络的泛化误差</title>
      <link>https://arxiv.org/abs/2402.07025</link>
      <description><![CDATA[这项工作提供了一个理论框架，用于在参数数量超过数据点数量的超参数化状态下通过图神经网络评估图分类任务的泛化误差。我们探索两种广泛使用的图神经网络类型：图卷积神经网络和消息传递图神经网络。在这项研究之前，过度参数化机制中泛化误差的现有界限没有提供任何信息，限制了我们对过度参数化网络性能的理解。我们的新颖方法涉及推导平均场范围内的上限，以评估这些图神经网络的泛化误差。我们建立收敛率为 $O(1/n)$ 的上限，其中 $n$ 是图样本的数量。这些上限为网络在具有挑战性的过度参数化机制中对未见数据的性能提供了理论保证，并总体上有助于我们理解其性能。]]></description>
      <guid>https://arxiv.org/abs/2402.07025</guid>
      <pubDate>Tue, 13 Feb 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>私人统计推断的重采样方法</title>
      <link>https://arxiv.org/abs/2402.07131</link>
      <description><![CDATA[我们考虑构建具有差分隐私的置信区间的任务。我们提出了非参数引导程序的两个私有变体，它们私下计算在数据分区上运行的多个“小”引导程序结果的中位数，并给出结果置信区间的覆盖误差的渐近界限。对于固定的差分隐私参数 $\epsilon$，我们的方法在样本大小 $n$ 的对数因子内具有与非私有引导相同的错误率。我们使用真实数据和合成数据实证验证了均值估计、中值估计和逻辑回归方法的性能。我们的方法实现了与现有方法（和非私有基线）相似的覆盖精度，同时提供比以前的方法明显更短（$\gtrsim 10$倍）的置信区间。]]></description>
      <guid>https://arxiv.org/abs/2402.07131</guid>
      <pubDate>Tue, 13 Feb 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>自监督学习结构冗余的低秩近似</title>
      <link>https://arxiv.org/abs/2402.06884</link>
      <description><![CDATA[我们研究了重构 SSL 的数据生成机制，以阐明其有效性。通过无限量的标记样本，我们为完美的线性逼近提供了充分必要的条件。该条件揭示了保留 Y 标签类别的满秩分量以及冗余分量。受该条件的启发，我们建议通过低秩分解来近似冗余分量，并通过引入新的量 $\epsilon_s$ 来测量近似质量，该新量由因式分解 s 的秩参数化。我们将 $\epsilon_s$ 纳入线性回归和岭回归设置下的超额风险分析中，其中后一种正则化方法是处理学习特征的维度远大于下游任务的标记样本数 n 的情况。我们设计了三个程式化实验来比较 SSL 与不同设置下的监督学习，以支持我们的理论发现。]]></description>
      <guid>https://arxiv.org/abs/2402.06884</guid>
      <pubDate>Tue, 13 Feb 2024 06:17:58 GMT</pubDate>
    </item>
    <item>
      <title>使用加权虚拟观察进行有效的增量信念更新</title>
      <link>https://arxiv.org/abs/2402.06940</link>
      <description><![CDATA[我们提出了一种算法解决方案，解决以概率程序为代表的贝叶斯统计模型中蒙特卡罗推理背景下的增量信念更新问题。给定一个模型和一个样本近似后验，我们的解决方案构建一组加权观察来调节模型，以便推理会产生相同的后验。这个问题出现例如在多级建模、增量推理、存在隐私约束的情况下进行推理。首先，选择一组虚拟观测值，然后通过计算有效的优化过程找到观测权重，使得重建的后验与原始后验一致或非常接近。我们将该解决方案实施并应用于许多教学示例和案例研究，显示了我们方法的效率和稳健性。提供的参考实现与概率编程语言或推理算法无关，并且可以应用于大多数主流概率编程环境。]]></description>
      <guid>https://arxiv.org/abs/2402.06940</guid>
      <pubDate>Tue, 13 Feb 2024 06:17:58 GMT</pubDate>
    </item>
    </channel>
</rss>