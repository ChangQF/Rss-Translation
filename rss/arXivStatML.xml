<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 10 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>组合老虎机的汤普森抽样：多项式遗憾和不匹配抽样悖论</title>
      <link>https://arxiv.org/abs/2410.05441</link>
      <description><![CDATA[arXiv:2410.05441v1 公告类型：新
摘要：我们考虑线性组合半老虎机和亚高斯奖励的汤普森抽样 (TS)。我们提出了第一个已知的 TS，其有限时间遗憾不会随问题的维度呈指数级增长。我们进一步展示了“不匹配的抽样悖论”：了解奖励分布并从正确的后验分布中抽样的学习者的表现可能比不知道奖励并仅从精心选择的高斯后验中抽样的学习者差得多。用于生成实验的代码可在 https://github.com/RaymZhang/CTS-Mismatched-Paradox 获得]]></description>
      <guid>https://arxiv.org/abs/2410.05441</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于综合神经数据分析的元动态状态空间模型</title>
      <link>https://arxiv.org/abs/2410.05454</link>
      <description><![CDATA[arXiv:2410.05454v1 公告类型：新
摘要：学习跨环境的共享结构有助于神经系统的快速学习和自适应行为。这已在机器学习中得到广泛证明和应用，以训练能够推广到新环境的模型。然而，在类似任务中利用神经活动中的共享结构来从神经记录中学习潜在动态的工作有限。现有方法旨在从单个数据集推断动态，无法轻易适应解释记录之间的统计异质性。在这项工作中，我们假设类似的任务允许相应的相关解决方案系列，并提出了一种新方法，用于从受过训练的动物的任务相关神经活动中对这个解决方案空间进行元学习。具体而言，我们在低维流形上捕获跨记录的变异性，从而简明扼要地参数化这个动态系列，从而促进在给定新记录的情况下快速学习潜在动态。我们证明了我们的方法对合成动力系统的少量重建和预测以及在不同手臂伸展任务期间来自运动皮层的神经记录的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.05454</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实验设计中适应性的力量</title>
      <link>https://arxiv.org/abs/2410.05552</link>
      <description><![CDATA[arXiv:2410.05552v1 公告类型：新
摘要：给定 n 个具有潜在异质协变量的实验对象和两种可能的治疗方法，即主动治疗和对照，本文解决了确定估计治疗效果的最佳准确度的基本问题。此外，我们提出了一种接近这种最佳准确度的实验设计，为这个基本但仍未解决的问题提供了（非渐近）答案。方法论贡献如下。首先，我们建立了一个以最小方差为基准的理想化最优估计量，然后证明自适应实验对于实现接近最优的估计精度是必要的。其次，通过将双重稳健方法的概念融入到顺序实验设计中，我们将最优估计问题构建为在线强盗学习问题，连接统计估计和强盗学习两个领域。利用强盗算法设计和自适应统计估计的工具和思想，我们提出了一个通用的低切换自适应实验框架，它可以成为广泛自适应实验设计的通用研究范式。通过信息论下界与贝叶斯风险分析相结合，我们证明了所提实验的最优性。数值结果表明，仅需两到三次策略更新，估计精度即可接近最优值。]]></description>
      <guid>https://arxiv.org/abs/2410.05552</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SMART：使用基于样条的多元自适应回归树进行回归的灵活方法</title>
      <link>https://arxiv.org/abs/2410.05597</link>
      <description><![CDATA[arXiv:2410.05597v1 公告类型：新
摘要：决策树在预测建模方面功能强大，但在对连续关系进行建模时，方差往往很大。虽然多元自适应回归样条 (MARS) 等算法擅长捕捉这种连续关系，但在对不连续性进行建模时，它们的表现不佳。为了解决这两种方法的局限性，我们引入了基于样条的多元自适应回归树 (SMART)，它使用决策树来识别具有不同连续关系的数据子集，然后利用 MARS 独立拟合这些关系。与其他依赖树结构来对交互和高阶项进行建模的方法不同，SMART 利用 MARS 处理这些项的原生能力，使树能够专注于识别关系中的不连续性。我们在各种数据集上测试了 SMART，证明了它在这种情况下比最先进的方法有所改进。此外，我们还提供了我们方法的开源实现，供从业者使用。]]></description>
      <guid>https://arxiv.org/abs/2410.05597</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不规则时间序列的连续状态空间 Feynman-Kac 模型的摊销控制</title>
      <link>https://arxiv.org/abs/2410.05602</link>
      <description><![CDATA[arXiv:2410.05602v1 公告类型：新
摘要：许多现实世界的数据集，例如医疗保健、气候和经济，通常以不规则的时间序列形式收集，这对准确建模提出了挑战。在本文中，我们提出了连续状态空间模型的摊销控制 (ACSSM)，用于对不规则和离散观测的时间序列进行连续动态建模。我们首先提出一个多边际 Doob 的 $h$ 变换来构建一个以这些不规则观测为条件的连续动力系统。随后，我们引入了一种具有严格证据下限 (ELBO) 的变分推理算法，利用随机最优控制 (SOC) 理论来近似难以处理的 Doob 的 $h$ 变换并模拟条件动态。为了提高训练和推理过程中的效率和可扩展性，ACSSM 采用摊销推理将表示学习与潜在动态分离。此外，它还采用了无模拟潜在动力学框架和基于变换器的数据同化方案，从而促进了潜在状态的并行推理和 ELBO 计算。通过对各种真实世界数据集的实证评估，ACSSM 在分类、回归、插值和外推等任务中表现出色，同时保持了计算效率。]]></description>
      <guid>https://arxiv.org/abs/2410.05602</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高斯普适性在高维混合数据分类中的失效</title>
      <link>https://arxiv.org/abs/2410.05609</link>
      <description><![CDATA[arXiv:2410.05609v1 公告类型：新
摘要：高斯或高斯混合数据的假设已在一系列机器学习 (ML) 方法的精确性能分析中得到广泛利用，这些分析针对的是具有相当多样本和特征的大型数据集。为了放宽这一限制性假设，随后人们致力于通过研究高斯普适性的场景来建立“高斯等效原理”，其中当用具有相同均值和协方差的高斯数据替换时，ML 方法对非高斯数据的渐近性能保持不变。在高斯普适性领域之外，关于数据分布如何影响学习性能的确切结果很少。
在本文中，我们为经验风险最小化提供了一个精确的高维表征，用于在扩展高斯混合的线性因子模型的一般混合数据设置下进行分类。高斯普适性在这种设置下会失效，因为渐近学习性能取决于类均值和协方差以外的数据分布。为了阐明高斯普适性在混合数据分类中的局限性并了解其失效的影响，我们指定了高斯普适性的条件并讨论了它们对损失函数选择的影响。]]></description>
      <guid>https://arxiv.org/abs/2410.05609</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论神经切线核理论中随机初始化的影响</title>
      <link>https://arxiv.org/abs/2410.05626</link>
      <description><![CDATA[arXiv:2410.05626v1 公告类型：新
摘要：本文旨在讨论神经正切核 (NTK) 理论中随机初始化对神经网络的影响，NTK 理论中的大多数最新工作都忽略了这一点。众所周知，当网络宽度趋于无穷大时，具有随机初始化的神经网络会收敛到高斯过程 $f^{\mathrm{GP}}$，其取值范围为 $L^{2}(\mathcal{X})$，其中 $\mathcal{X}$ 是数据的域。相比之下，为了采用传统的核回归理论，大多数最新工作引入了一种特殊的镜像架构和镜像（随机）初始化，以确保网络的输出在初始化时始终为零。因此，传统设置和镜像初始化是否会使宽神经网络表现出不同的泛化能力仍是一个问题。在本文中，我们首先证明具有随机初始化的神经网络的梯度流的训练动态均匀收敛到具有随机初始化 $f^{\mathrm{GP}}$ 的相应 NTK 回归的梯度流的训练动态。然后我们证明：对于任何 $s &lt; \frac{3}{d+1}$，$\mathbf{P}(f^{\mathrm{GP}} \in [\mathcal{H}^{\mathrm{NT}}]^{s}) = 1$，且对于任何 $s \geq \frac{3}{d+1}$，$\mathbf{P}(f^{\mathrm{GP}} \in [\mathcal{H}^{\mathrm{NT}}]^{s}) = 0$，其中 $[\mathcal{H}^{\mathrm{NT}}]^{s}$ 是与 NTK 相关的 RKHS $\mathcal{H}^{\mathrm{NT}}$ 的实插值空间。因此，梯度下降训练的宽神经网络的泛化误差为$\Omega(n^{-\frac{3}{d+3}})$，并且仍然受到维数灾难的影响。一方面，结果凸显了镜像初始化的好处。另一方面，这意味着 NTK 理论可能无法完全解释神经网络的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2410.05626</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>长上下文线性系统辨识</title>
      <link>https://arxiv.org/abs/2410.05690</link>
      <description><![CDATA[arXiv:2410.05690v1 公告类型：新
摘要：本文解决了长上下文线性系统识别问题，其中动态系统在时间 $t$ 的状态 $x_t$ 在长度为 $p$ 的固定上下文窗口上线性依赖于先前状态 $x_s$。我们为广泛的系统建立了一个样本复杂度界限，该界限将 i.i.d. 参数速率与对数因子相匹配，扩展了以前仅考虑一阶依赖性的工作。我们的研究结果揭示了一种无混合学习现象，表明学习长上下文线性自回归模型不会受到可能与扩展上下文窗口相关的缓慢混合特性的阻碍。此外，我们将这些结果扩展到 (i) 共享低秩表示，其中秩正则化估计量可提高与维数相关的速率，以及 (ii) 严格稳定系统中错误指定的上下文长度，其中较短的上下文具有统计优势。]]></description>
      <guid>https://arxiv.org/abs/2410.05690</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变分推断中利用控制变量的路径梯度方差减少</title>
      <link>https://arxiv.org/abs/2410.05753</link>
      <description><![CDATA[arXiv:2410.05753v1 公告类型：新
摘要：贝叶斯深度学习中的变分推断通常涉及计算缺乏闭式解的期望的梯度。在这些情况下，路径和得分函数梯度估计器是最常见的方法。与得分函数估计器相比，路径估计器通常具有低得多的方差，而得分函数估计器通常需要方差减少技术。然而，最近的研究表明，即使是路径梯度估计器也可以从方差减少中受益。在这项工作中，我们回顾了现有的基于控制变量的路径梯度估计器的方差减少方法，以评估其有效性。值得注意的是，这些方法通常依赖于被积函数近似，并且仅适用于简单的变分族。为了解决这个限制，我们建议将零方差控制变量应用于路径梯度估计器。这种方法的优点是除了能够从中抽样之外，只需要对变分分布做出最少的假设。]]></description>
      <guid>https://arxiv.org/abs/2410.05753</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯深度学习的温度优化</title>
      <link>https://arxiv.org/abs/2410.05757</link>
      <description><![CDATA[arXiv:2410.05757v1 公告类型：新
摘要：冷后验效应 (CPE) 是贝叶斯深度学习 (BDL) 中的一种现象，将后验调整到低温通常会提高后验预测分布 (PPD) 的预测性能。尽管术语“CPE”表明较低的温度本质上更好，但 BDL 社区越来越认识到情况并非总是如此。尽管如此，除了网格搜索之外，仍然没有系统的方法来找到最佳温度。在这项工作中，我们提出了一种数据驱动的方法来选择最大化测试对数预测密度的温度，将温度视为模型参数并直接从数据中估算它。我们通过经验证明，我们的方法在回归和分类任务中的表现与网格搜索相当，成本仅为其一小部分。最后，我们强调了 BDL 和广义贝叶斯社区对 CPE 的不同观点：前者主要关注 PPD 的预测性能，而后者强调校准的不确定性和对模型错误指定的稳健性；这些不同的目标导致不同的温度偏好。]]></description>
      <guid>https://arxiv.org/abs/2410.05757</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不确定性感知公平自适应分类树</title>
      <link>https://arxiv.org/abs/2410.05810</link>
      <description><![CDATA[arXiv:2410.05810v1 公告类型：新
摘要：在人工智能和机器学习算法对人类生活影响日益增大的时代，开发能够考虑其预测中潜在歧视的模型至关重要。本文通过引入一种新的分类树算法来解决这个问题，该算法使用一种新颖的拆分标准，将公平性调整纳入树构建过程。所提出的方法集成了一种公平意识杂质度量，该度量在受保护群体之间平衡了预测准确性和公平性。通过确保每个拆分节点同时考虑分类误差的增益和公平性，我们的算法鼓励减轻歧视的拆分。重要的是，在惩罚不公平的拆分时，我们利用公平性指标的置信区间而不是依赖其点估计来考虑公平性指标中的不确定性。基准和合成数据集上的实验结果表明，与传统分类树相比，我们的方法有效地减少了歧视性预测，而整体准确性没有显着损失。]]></description>
      <guid>https://arxiv.org/abs/2410.05810</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>平等分配的随机赌博机</title>
      <link>https://arxiv.org/abs/2410.05856</link>
      <description><![CDATA[arXiv:2410.05856v1 公告类型：新
摘要：我们研究 EgalMAB，这是一个在随机多臂老虎机背景下的平等分配问题。在 EgalMAB 中，代理负责将一组用户分配到各个臂。在每个时间步骤中，代理必须为每个用户分配一个臂，以便没有两个用户被分配到同一个臂。随后，每个用户都会从与其分配的臂相关的未知奖励分布中获得奖励。代理的目标是在固定期限内最大化所有用户之间的最小预期累积奖励。这个问题在工作公平性和资源分配等领域都有应用。我们设计和分析了基于 UCB 的策略 EgalUCB，并建立了累积遗憾的上限。作为补充，我们建立了一个几乎匹配的独立于策略的不可能结果。]]></description>
      <guid>https://arxiv.org/abs/2410.05856</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>流形、随机矩阵和谱间隙：生成扩散的几何阶段</title>
      <link>https://arxiv.org/abs/2410.05898</link>
      <description><![CDATA[arXiv:2410.05898v1 公告类型：新
摘要：在本文中，我们研究了流形假设下的生成扩散模型的潜在几何形状。为此，我们分析了得分函数雅可比矩阵的特征值（和奇异值）的谱，其不连续性（间隙）揭示了不同子流形的存在和维数。使用统计物理方法，我们推导出几个分布假设下的谱分布和谱间隙公式，并将这些理论预测与从训练网络估计的谱进行比较。我们的分析揭示了生成过程中存在三个不同的定性阶段：一个平凡阶段；一个流形覆盖阶段，其中扩散过程适合流形内部的分布；一个巩固阶段，其中得分与流形正交，所有粒子都投影在数据支持上。不同时间尺度之间的这种“分工”很好地解释了为什么生成扩散模型不受困扰基于可能性的模型的流形过度拟合现象的影响，因为内部分布和流形几何是在生成过程中的不同时间点产生的。]]></description>
      <guid>https://arxiv.org/abs/2410.05898</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有未知链接函数的广义稀疏加性模型</title>
      <link>https://arxiv.org/abs/2410.06012</link>
      <description><![CDATA[arXiv:2410.06012v1 公告类型：新
摘要：广义加性模型 (GAM) 已成功应用于高维数据分析。然而，大多数现有方法不能同时估计链接函数、组件函数和变量交互。为了缓解这个问题，我们提出了一种新的稀疏加性模型，称为具有未知链接函数的广义稀疏加性模型 (GSAMUL)，其中组件函数由 B 样条基估计，未知链接函数由多层感知器 (MLP) 网络估计。此外，$\ell_{2,1}$-norm 正则化器用于变量选择。所提出的 GSAMUL 可以实现变量选择和隐藏交互。我们将此估计集成到双层优化问题中，其中数据分为训练集和验证集。理论上，我们提供了关于近似程序收敛的保证。在应用中，对合成和真实世界数据集的实验评估一致验证了所提出方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.06012</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于似然的可区分结构学习</title>
      <link>https://arxiv.org/abs/2410.06163</link>
      <description><![CDATA[arXiv:2410.06163v1 公告类型：新
摘要：现有的有向无环图 (DAG) 可微结构学习方法依赖于强可识别性假设，以保证无环约束优化问题的全局最小化器识别真正的 DAG。此外，经验观察发现，优化器可能会利用损失函数中不良的伪影。我们通过研究具有多个全局最小化器的一般似然下可微无环约束程序的行为来解释和解决这些问题。通过仔细正则化似然，即使在没有可识别参数化的情况下，也可以识别马尔可夫等价类中最稀疏的模型。我们首先详细研究高斯情况，展示如何通过适当的似然正则化定义识别最稀疏模型的分数。假设忠实，它还可以恢复马尔可夫等价类。然后将这些结果推广到一般模型和可能性，其中相同的主张成立。这些理论结果通过经验验证，展示了如何使用基于标准梯度的优化器来实现这一点，从而为一般模型和损失下的可微结构学习铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.06163</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>