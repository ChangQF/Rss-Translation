<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Thu, 07 Dec 2023 03:14:15 GMT</lastBuildDate>
    <item>
      <title>神经网络雅可比正则化训练的无限宽度分析。 （arXiv：2312.03386v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.03386</link>
      <description><![CDATA[深度神经网络的最新理论分析
无限宽度限制加深了我们对初始化、特征的理解
学习和培训这些网络，并带来新的实用技术
用于寻找合适的超参数、学习网络权重，以及
进行推理。在本文中，我们通过以下方式拓宽了这一研究方向
表明这种无限宽度分析可以扩展到 a 的雅可比行列式
深度神经网络。我们展示了多层感知器（MLP）及其
初始化时的雅可比行列式联合收敛于高斯过程 (GP)
MLP 隐藏层的宽度趋于无穷大并表征了该 GP。我们
还证明了在无限宽度限制下，MLP的演化
所谓的稳健训练（即使用雅可比行列式的正则化器进行训练）
由线性一阶常微分方程描述，即
由神经正切内核的变体确定。我们通过实验表明
我们的理论主张与广泛的有限网络的相关性，以及
实证分析核回归解的性质以获得
深入了解雅可比正则化。
]]></description>
      <guid>http://arxiv.org/abs/2312.03386</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>分布转移下对比学​​习和自我训练的互补优势。 （arXiv：2312.03318v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.03318</link>
      <description><![CDATA[自我训练和对比学习已成为以下领域的领先技术：
合并未标记的数据，均处于分布变化（无监督
领域适应）以及当它不存在时（半监督学习）。然而，
尽管这些技术很受欢迎且具有兼容性，但它们的功效
组合仍有待探索。在本文中，我们进行了系统的
对这种组合的实证研究，发现 (i) 在域中
适应环境、自我训练和对比学习提供了重要的
互补收益； (ii) 在半监督学习环境中，
令人惊讶的是，这些好处并不具有协同作用。跨八个分布班次
数据集（例如 BREED、WILDS），我们证明组合方法可以获得
比任何一种独立方法的准确度高出 3--8%。那么我们理论上
在分布转移的简化模型中分析这些技术，
演示对比特征产生的场景
学习可以为自我训练提供良好的初始化，以进一步放大
收益并实现最佳性能，即使单独使用任何一种方法都会
失败。
]]></description>
      <guid>http://arxiv.org/abs/2312.03318</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>野外膳食血糖控制的可解释机制表示。 （arXiv：2312.03344v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.03344</link>
      <description><![CDATA[糖尿病涉及血糖控制的复杂情况，各不相同
广泛地存在于个体之间。然而，当前的方法并不能忠实地捕获
膳食水平的这种变化。一方面，专家精心设计的功能
缺乏数据驱动方法的灵活性；另一方面，学到了
表述往往难以解释，这阻碍了临床采用。在
在本文中，我们提出了一种混合变分自动编码器来学习可解释的
CGM 和膳食数据的表示。我们的方法将潜在空间接地
机械微分方程的输入，产生嵌入
反映生理量，如胰岛素敏感性、血糖
有效性和基础血糖水平。此外，我们还介绍了一种新颖的方法
推断葡萄糖出现率，使机械模型稳健
不可靠的膳食记录。基于 CGM 和自我报告膳食的数据集
患有 2 型糖尿病和糖尿病前期的个体，我们在无人监督的情况下
代表发现个体之间的分离与他们的比例成正比
疾病的严重程度。我们的嵌入产生的集群比
天真的、专家、黑匣子和纯粹的机械特征。我们的方法提供了一个
细致入微但可解释的嵌入空间来比较血糖控制
并且跨个体，可以直接从野外数据中学习。
]]></description>
      <guid>http://arxiv.org/abs/2312.03344</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>关于应用于 GPR 数据的 SVM 方法的变体，以对法国路面的粘层特征进行分类：两个实验案例研究。 （arXiv：2312.03351v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.03351</link>
      <description><![CDATA[在常用的无损技术中，探地法
雷达 (GPR) 是当今评估路面最广泛采用的雷达之一
法国的条件。然而，传统雷达系统及其前向
加工方法已显示出其物理和物理上的局限性
非常薄的层（例如粘层）的几何表征。然而，
使用机器学习方法以逆向方法应用于探地雷达
表明可以在数字上识别粘性涂层
尽管由于时频分辨率低而产生掩蔽效应，但仍具有特性
在原始 B 扫描中注明。因此，我们在本文中建议应用逆
基于机器学习的方法，已经在之前的工作中得到验证
不同路面结构的两个实验案例的数值数据。
第一种情况对应于对已知路面结构的验证
古斯塔夫埃菲尔大学（法国南特）及其路面疲劳旋转木马
第二个案例关注 Vend{\&#39;e}e 部门的一条新的真实道路
（法国）。在这两个案例研究中，SVM/SVR 方法的性能表明
监督学习方法对乳液进行分类和估计的效率
粘层中的配比。
]]></description>
      <guid>http://arxiv.org/abs/2312.03351</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>通过混合 Cramer-Wold 距离平衡边际和联合分布学习。 （arXiv：2312.03307v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.03307</link>
      <description><![CDATA[在训练生成模型的过程中，至关重要的是
测量两个高维概率分布之间的差异：
观察到的生成分布和真实分布
数据集。最近，人们对一种涉及的方法越来越感兴趣
切割高维分布，出现 Cramer-Wold 距离
作为一种有前途的方法。然而，我们已经确定 Cramer-Wold
距离主要关注联合分布式学习，而
了解边际分配模式对于有效
合成数据生成。在本文中，我们介绍了一种新颖的测量方法
相异性，混合 Cramer-Wold 距离。这项措施使我们能够
同时捕获边际和联合分布信息，如
它结合了标准基向量上点质量的混合测量。
基于混合 Cramer-Wold 距离，我们提出了一种新的生成式
称为 CWDAE（Cramer-Wold 分布式自动编码器）的模型，它显示
应用于真实数据时，在生成合成数据方面表现出色
表格数据集。此外，我们的模型提供了调整的灵活性
轻松实现数据隐私级别。
]]></description>
      <guid>http://arxiv.org/abs/2312.03307</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:13 GMT</pubDate>
    </item>
    <item>
      <title>关于内核机中预处理的 Nystrom 近似。 （arXiv：2312.03311v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.03311</link>
      <description><![CDATA[核方法是机器中一类流行的非线性预测模型
学习。用于学习内核模型的可扩展算法需要迭代
在自然界中，但由于条件较差，收敛可能会很慢。光谱
预处理是加速此类收敛的重要工具
用于训练核模型的迭代算法。然而计算和存储
光谱预处理器可能很昂贵，这可能会导致大量
计算和存储开销，排除内核的应用
解决大数据集问题的方法。的尼斯特罗姆近似
谱预处理器的计算和存储成本通常较低，并且具有
在实际应用中取得了成功。在本文中我们分析了
使用这种近似预处理器的权衡。具体来说，我们展示
对数大小的样本（作为数据集大小的函数）
使基于 Nystrom 的近似预处理器能够加速梯度
下降几乎与精确的预处理器一样，同时还减少了
计算和存储开销。
]]></description>
      <guid>http://arxiv.org/abs/2312.03311</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:13 GMT</pubDate>
    </item>
    <item>
      <title>通过增强相对论进行低成本高能隶属推理。 （arXiv：2312.03262v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.03262</link>
      <description><![CDATA[我们提出了一种强大的成员推理攻击（RMIA），可以放大
人口数据和任何目标模型的训练数据之间的区别，
通过有效地利用我们的参考模型和参考数据
似然比检验。我们的算法表现出卓越的测试能力
（真阳性率）与以前的方法相比，即使在极低的情况下
假阳性错误率（低至 0）。另外，在计算限制下，
只有有限数量的参考模型（少至 1 个）可用，
与之前的一些攻击不同，我们的方法表现得非常好
在这种情况下随机猜测。我们的方法奠定了基础
具有成本效益、实用且强大且稳健的隐私风险分析
机器学习算法。
]]></description>
      <guid>http://arxiv.org/abs/2312.03262</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:12 GMT</pubDate>
    </item>
    <item>
      <title>经验贝叶斯协方差分解，以及稀疏 PCA 中多重调优问题的解决方案。 （arXiv：2312.03274v1 [stat.ME]）</title>
      <link>http://arxiv.org/abs/2312.03274</link>
      <description><![CDATA[稀疏主成分分析 (PCA) 已被提议作为一种方法
提高 PCA 的可解释性和可靠性。然而，使用稀疏
PCA 在实践中因难以调整倍数而受到阻碍
控制不同 PC 稀疏性的超参数（“多个
调整问题”，MTP）。这里我们提出了一个使用经验的 MTP 解决方案
贝叶斯方法。我们首先介绍一个惩罚 PCA 的一般公式
数据矩阵$\mathbf{X}$，其中包括一些现有的稀疏PCA方法，如
特别案例。我们证明这种表述也会导致惩罚
协方差（或 Gram）矩阵 $\mathbf{X}^T\mathbf{X}$ 的分解。我们
引入这些惩罚问题的经验贝叶斯版本，其中
处罚由先验分布确定，该先验分布是根据
通过最大似然而不是交叉验证来获取数据。所结果的
《经验贝叶斯协方差分解》提供了一种原则性的、高效的
稀疏 PCA 中 MTP 的解决方案，并且可以立即扩展到
纳入其他结构假设（例如非负 PCA）。我们举例说明
该方法在模拟和真实数据示例上的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2312.03274</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:12 GMT</pubDate>
    </item>
    <item>
      <title>引导你自己的方差。 （arXiv：2312.03213v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.03213</link>
      <description><![CDATA[了解模型不确定性对于许多应用程序都很重要。我们
提出 Bootstrap Your Own Variance (BYOV)，结合 Bootstrap Your Own Latent
(BYOL)，一种无负自监督学习 (SSL) 算法，采用贝叶斯
反向传播（BBB），一种用于估计模型后验的贝叶斯方法。我们发现
BYOV 与监督 BBB 模型的学习预测标准得到了很好的捕捉
通过高斯分布，提供初步证据表明学习的
后验参数对于无标签不确定性估计很有用。自带设备
改进了确定性 BYOL 基线（+2.83% 测试 ECE，+1.03% 测试
Brier），并且在使用各种测试时表现出更好的校准和可靠性
增强(例如：+2.4%测试ECE、+1.2%测试Brier for Salt &amp; Pepper噪音)。
]]></description>
      <guid>http://arxiv.org/abs/2312.03213</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:11 GMT</pubDate>
    </item>
    <item>
      <title>具有自适应子空间搜索的加速梯度算法，用于实例更快的优化。 （arXiv：2312.03218v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.03218</link>
      <description><![CDATA[基于梯度的极小极大优化算法极大地提升了
持续优化和机器学习的发展。一部开创性的著作
由于 Yurii Nesterov [Nes83a] 建立了 $\tilde{\mathcal{O}}(\sqrt{L/\mu})$
最小化$L$-平滑$\mu$-强凸的梯度复杂度
客观的。然而，理想的算法应该适应显式的复杂性
特定的目标函数并为更简单的问题带来更快的速度，
引发我们对现有优化模型的两个失败的重新考虑
和分析。 (i) 最坏情况最优性既不是实例最优性
现实中也没有这样的人。 (ii) 传统的$L$-平滑条件可能不适用
现代实际问题的主要抽象/表征。

在本文中，我们开辟了一种基于梯度设计和分析的新方法
直接应用于机器学习的算法，包括线性
回归及超越。我们引入两个因子$(\alpha, \tau_{\alpha})$
细化优化退化条件的描述
基于 Hessian 奇异值经常观察到的问题
急剧下降。我们设计自适应算法来解决更简单的问题，而无需
具有减少梯度或类似的预言机访问的预先已知的知识。这
算法还提高了几个问题的最先进的复杂性
机器学习，从而解决如何更快地设计的开放问题
根据已知的复杂性下限的算法。特别地，与
$\mathcal{O}(1)$-核范数有界，我们达到最优
$\tilde{\mathcal{O}}(\mu^{-1/3})$ (v.s. $\tilde{\mathcal{O}}(\mu^{-1/2})$)
线性回归的梯度复杂度。我们希望这项工作能够唤起
重新思考以理解现代优化问题的难度。
]]></description>
      <guid>http://arxiv.org/abs/2312.03218</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:11 GMT</pubDate>
    </item>
    <item>
      <title>具有强彩票功能的多层和折叠图神经网络。 （arXiv：2312.03236v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.03236</link>
      <description><![CDATA[强彩票假说 (SLTH) 证明了
随机初始化模型中的高性能子网络，可发现
通过修剪没有任何权重的卷积神经网络（CNN）
训练。最近一项名为 Untrained GNNs Tickets (UGT) 的研究扩展了 SLTH
从 CNN 到浅图神经网络 (GNN)。然而，差异
将基线模型与学习的密集权重进行比较时仍然存在。
此外，将 SLTH 应用于更深的 GNN 仍有一个未开发的领域，
尽管通过附加层提供了更高的精度，但仍遭受
内存需求过多。为了应对这些挑战，这项工作利用
多层超级掩模（M-Sup），一种标量修剪掩模方法，并实现它
在 GNN 中，提出了一种自适应设置剪枝阈值的策略。
在深度 GNN 的背景下，这项研究揭示了未经训练的存在
循环网络，其表现与其经过训练的网络相当
前馈对应物。本文还介绍了多级折叠
和 Unshared Masks 方法来扩展搜索空间
架构和参数。通过对各种数据集的评估，
包括开放图谱基准（OGB），这项工作建立了三赢
基于 SLTH 的 GNN 的场景：通过实现高稀疏性、竞争性
性能和高内存效率，降低高达 98.7\%，
展示了节能图形处理的适用性。
]]></description>
      <guid>http://arxiv.org/abs/2312.03236</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:11 GMT</pubDate>
    </item>
    <item>
      <title>带反馈的算法公平性。 (arXiv:2312.03155v1 [econ.TH])</title>
      <link>http://arxiv.org/abs/2312.03155</link>
      <description><![CDATA[算法公平领域在过去15年迅速崛起
随着算法在日常生活中变得无处不在。算法公平性
传统上认为公平算法的统计概念可能
满足基于噪声数据的决策。我们首先证明这些是
理论上与基于福利的公平观念脱节。然后我们
讨论两个基于个人福利的公平概念、无嫉妒和
损害自由，并建立条件，使它们等同于
分别是错误率平衡和预测奇偶性。我们讨论的是
鉴于最近发现的这些发现的影响
算法公平性中的不可能性定理（Kleinberg、Mullainathan 等）
拉加万 (2016)、乔尔德霍娃 (2017))。
]]></description>
      <guid>http://arxiv.org/abs/2312.03155</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:10 GMT</pubDate>
    </item>
    <item>
      <title>部分观察下的约束贝叶斯优化：平衡的改进和可证明的收敛。 （arXiv：2312.03212v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.03212</link>
      <description><![CDATA[部分可观察约束优化问题（POCOP）阻碍
数据驱动的优化技术，因为 POCOP 的不可行解决方案可以
提供的有关目标和限制的信息很少。我们
努力为昂贵的 POCOP 设计一种有效且可证明的方法
约束贝叶斯优化框架。我们的方法包括两个
关键部件。首先，我们提出了收购的改进设计
在优化过程中引入平衡探索的函数。我们
严格研究该设计的收敛特性以证明其
效力。其次，我们提出了嵌入不同的高斯过程
可能性作为部分可观察约束的替代模型。这
相比之下，模型可以更准确地表示可行区域
到传统的基于分类的模型。我们提出的方法是根据经验
研究综合问题和现实问题。结果表明
我们解决 POCOP 的方法的竞争力。
]]></description>
      <guid>http://arxiv.org/abs/2312.03212</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:10 GMT</pubDate>
    </item>
    <item>
      <title>量子机器学习的优势来自一般计算的优势。 (arXiv:2312.03057v1 [quant-ph])</title>
      <link>http://arxiv.org/abs/2312.03057</link>
      <description><![CDATA[量子机器学习 (QML) 的一个重要里程碑是证明
QML 相对于所有可能的经典学习方法的优势
加速以监督为代表的常见类型的学习任务
使用经典数据进行学习。然而，QML 已被证明的优势
迄今为止，监督学习仅针对设计的学习任务
利用特定量子算法的优势，即 Shor 算法
算法。在这里，我们明确构建了一个前所未有的更广泛的家族
使用经典数据进行监督学习任务以提供可证明的优势
基于通用量子计算优势的 QML，进展超越
肖尔的算法。我们的学习任务可以通过执行
可以在多项式时间内有效计算的通用函数类
对于任意量子算法的大部分输入，但不是任何
经典算法。我们证明了完成这项学习任务的难度
任何可能的多项式时间经典学习方法。我们还澄清
用于准备经典数据以演示此学习任务的协议
实验。这些结果开辟了利用各种量子的途径
计算功能的优势用于实验演示
QML 的优势。
]]></description>
      <guid>http://arxiv.org/abs/2312.03057</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:09 GMT</pubDate>
    </item>
    <item>
      <title>高斯图形模型和图形套索的最大似然阈值。 （arXiv：2312.03145v1 [数学.ST]）</title>
      <link>http://arxiv.org/abs/2312.03145</link>
      <description><![CDATA[与每个图 G 相关联的是一个高斯图模型。此类模型是
通常用于高维设置，即相对较少的地方
数据点与变量数量的比较。最大似然
图的阈值是拟合该图所需的最小数据点数量
使用最大似然估计的相应图形模型。图形化
lasso 是一种选择和拟合图形模型的方法。在这个项目中，
我们问：当图形套索用于选择并拟合 n 上的图形模型时
数据点，n 大于或等于最大值的可能性有多大
相应图的似然阈值？我们的结果是一系列
计算实验。
]]></description>
      <guid>http://arxiv.org/abs/2312.03145</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:09 GMT</pubDate>
    </item>
    </channel>
</rss>