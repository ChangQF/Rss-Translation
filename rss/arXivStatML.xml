<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 18 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>湍流游泳中的演员-评论家强化学习中的物理学知情评论家</title>
      <link>https://arxiv.org/abs/2406.10242</link>
      <description><![CDATA[arXiv:2406.10242v1 公告类型：交叉 
摘要：湍流扩散导致相邻的粒子分离。我们研究了保持粒子靠近其被动平流对应物所需的游动努力。我们通过开发和比较一种新的物理信息强化学习 (PIRL) 策略与规定控制 (PC) 和标准物理不可知强化学习策略，探索最佳地平衡这些努力与预期目标。我们的 PIRL 方案，称为 Actor-Physicist，是 Actor-Critic 算法的一种改编，其中神经网络参数化的评论家被分析得出的物理启发式函数 (物理学家) 取代。然后将此策略与从随机最优控制公式和标准物理不可知 Actor-Critic 类型算法得出的分析计算的最佳 PC 策略进行比较。]]></description>
      <guid>https://arxiv.org/abs/2406.10242</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:20 GMT</pubDate>
    </item>
    <item>
      <title>马尔可夫类别中的随机神经网络对称化</title>
      <link>https://arxiv.org/abs/2406.11814</link>
      <description><![CDATA[arXiv:2406.11814v1 公告类型：新
摘要：我们考虑沿群同态对称化神经网络的问题：给定同态 $\varphi : H \to G$，我们想要一个将 $H$-等变神经网络转换为 $G$-等变神经网络的过程。我们用马尔可夫类别来表示这一点，这使我们能够考虑输出可能是随机的但抽象出测度理论细节的神经网络。我们获得了一个灵活、组合和通用的对称化框架，该框架依赖于对群结构和底层神经网络架构的最小假设。我们的方法将现有的确定性对称化方法恢复为特殊情况，并直接扩展为随机对称化提供了一种新方法。除此之外，我们相信我们的研究结果还证明了马尔可夫类别在以概念但数学严谨的方式解决机器学习问题方面的实用性。]]></description>
      <guid>https://arxiv.org/abs/2406.11814</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:19 GMT</pubDate>
    </item>
    <item>
      <title>具有耦合约束的双层优化的原始-对偶辅助惩罚方法</title>
      <link>https://arxiv.org/abs/2406.10148</link>
      <description><![CDATA[arXiv:2406.10148v1 公告类型：交叉 
摘要：近年来，人们对双层优化的兴趣日益浓厚，部分原因是它在解决具有挑战性的机器学习问题方面的应用。最近有几项令人兴奋的研究集中在开发有效的基于梯度的算法上，这些算法可以解决具有可证明保证的双层优化问题。然而，现有文献主要关注没有约束的双层问题，或者只关注简单的约束，这些约束不会在上下层之间耦合变量，排除了一系列复杂的应用。我们的论文研究了这种具有挑战性但探索较少的场景，并开发了一种（完全）一阶算法，我们称之为 BLOCC，以解决具有耦合约束的双层优化问题。我们为所提出的算法建立了严格的收敛理论，并使用来自塞维利亚市的真实数据证明了它在两个众所周知的实际应用上的有效性——支持向量机 (SVM) 中的超参数选择和交通网络中的基础设施规划。]]></description>
      <guid>https://arxiv.org/abs/2406.10148</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:19 GMT</pubDate>
    </item>
    <item>
      <title>统计力学与机器学习理论等效框架中的代数研究回顾与展望</title>
      <link>https://arxiv.org/abs/2406.10234</link>
      <description><![CDATA[arXiv:2406.10234v2 公告类型：交叉 
摘要：自20世纪以来，统计力学和机器学习理论之间的数学等价性就已为人所知，基于这种等价性的研究为理论物理学和统计学习理论提供了新的方法。例如，统计力学中的代数方法（如算子代数）使我们能够从数学上分析相变现象。在本文中，对于对人工智能感兴趣的理论物理学家，我们回顾并展望了机器学习理论中的代数研究。如果学习机器具有层次结构或潜在变量，则随机汉密尔顿量不能用任何二次扰动来表示，因为它具有奇异性。为了研究由这种奇异随机汉密尔顿量定义的平衡态，需要采用代数方法来推导自由能和泛化误差的渐近形式。我们还介绍了最新的进展，事实上，人工智能的协同理论基础正在基于代数学习理论构建。本文旨在纪念统计力学和量子场论中代数研究的先驱荒木教授。]]></description>
      <guid>https://arxiv.org/abs/2406.10234</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:19 GMT</pubDate>
    </item>
    <item>
      <title>分而治之 MCMC 的扩散生成模型</title>
      <link>https://arxiv.org/abs/2406.11664</link>
      <description><![CDATA[arXiv:2406.11664v1 公告类型：新
摘要：分而治之 MCMC 是一种并行化马尔可夫链蒙特卡罗采样的策略，通过在数据集的不相交子集上运行独立采样器并合并它们的输出。文献中一个持续的挑战是有效地执行这种合并，而不对后验施加分布假设。我们建议使用扩散生成模型来将密度近似拟合到后验分布中。这种方法在具有挑战性的合并问题上优于现有方法，同时其计算成本比现有的密度估计方法更有效地扩展到高维问题。]]></description>
      <guid>https://arxiv.org/abs/2406.11664</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:18 GMT</pubDate>
    </item>
    <item>
      <title>一次剪辑之旅：高维梯度剪辑的 SGD 动态</title>
      <link>https://arxiv.org/abs/2406.11733</link>
      <description><![CDATA[arXiv:2406.11733v1 公告类型：新
摘要：现代机器学习的成功部分归功于已经开发的自适应优化方法，这些方法可以解决在复杂数据集上训练大型模型的困难。其中一种方法是梯度裁剪：一种理论基础有限的实用程序。在这项工作中，我们研究了流式 SGD 下最小二乘问题的裁剪。我们对大内在维度极限下的学习动态进行了理论分析 - 一个依赖于模型和数据集的维数概念。在这个极限下，我们找到了一个描述损失演变的确定性方程。我们表明，高斯噪声裁剪不能提高 SGD 性能。然而，在其他嘈杂的环境中，裁剪可以通过调整裁剪阈值来提供好处。在这些情况下，裁剪偏差会以有利于训练的方式更新，而 SGD 在任何时间表下都无法恢复。最后，我们讨论了高维裁剪和神经网络训练之间的联系。]]></description>
      <guid>https://arxiv.org/abs/2406.11733</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:18 GMT</pubDate>
    </item>
    <item>
      <title>多视图数据的联合链接成分分析</title>
      <link>https://arxiv.org/abs/2406.11761</link>
      <description><![CDATA[arXiv:2406.11761v1 公告类型：新
摘要：在这项工作中，我们提出了针对多视图数据的联合链接组件分析 (joint\_LCA)。与以顺序方式提取共享组件的经典方法不同，joint\_LCA 的目标是同时识别特定于视图的加载矩阵和公共潜在子空间的秩。我们制定了一个矩阵分解模型，其中每个数据视图中都存在一个联合结构和一个单独的结构，这使我们能够得到任何一对数据视图之间交叉协方差的干净的 svd 表示。然后提出了一个具有新惩罚项的目标函数来实现同时估计和秩选择。此外，采用重新拟合程序​​作为补救措施，以减少惩罚造成的收缩偏差。]]></description>
      <guid>https://arxiv.org/abs/2406.11761</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:18 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯网络和机器学习用于 COVID-19 严重程度解释和人口统计学症状分类</title>
      <link>https://arxiv.org/abs/2406.10807</link>
      <description><![CDATA[arXiv:2406.10807v2 公告类型：新 
摘要：随着当前抗击 2019 年冠状病毒病 (COVID-19) 大流行的努力，关于其传播、未来影响和复发仍存在一些尚未发现的不确定性。在本文中，我们提出了一种三阶段数据驱动方法来提取有关 COVID-19 的隐藏信息。第一阶段采用贝叶斯网络结构学习方法来识别 COVID-19 症状与其内在人口统计变量之间的因果关系。作为第二阶段，贝叶斯网络结构学习的输出可作为训练无监督机器学习 (ML) 算法的有用指南，该算法通过聚类揭示患者症状的相似性。然后，最后阶段利用从聚类中获得的标签来训练人口统计症状识别 (DSID) 模型，该模型可预测患者的症状类别和相应的人口统计概率分布。我们将我们的方法应用于从美国疾病控制与预防中心 (CDC) 获得的 COVID-19 数据集。实验结果显示，测试准确率为 99.99%，而启发式 ML 方法的准确率为 41.15%。这有力地证明了我们的贝叶斯网络和 ML 方法在理解病毒症状之间的关系以及提供有关患者分层以降低病毒严重程度的见解方面的可行性。]]></description>
      <guid>https://arxiv.org/abs/2406.10807</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:17 GMT</pubDate>
    </item>
    <item>
      <title>连续状态空间中的分布鲁棒随机控制的统计学习</title>
      <link>https://arxiv.org/abs/2406.11281</link>
      <description><![CDATA[arXiv:2406.11281v1 公告类型：新
摘要：我们探索具有潜在连续状态和动作空间的随机系统的控制，其特征是状态动态 $X_{t+1} = f(X_t, A_t, W_t)$。这里，$X$、$A$ 和 $W$ 分别表示状态、动作和外生随机噪声过程，$f$ 表示描述状态转换的已知函数。传统上，噪声过程 $\{W_t, t \geq 0\}$ 被认为是独立且相同分布的，其分布要么完全已知，要么可以一致估计。然而，在工程环境中常见的分布偏移的发生需要考虑策略的稳健性。本文介绍了一种分布稳健的随机控制范式，该范式可在规定的模糊集内适应对噪声分布的可能自适应对抗扰动。我们研究了两种对手模型：当前动作感知和当前动作不感知，从而得出不同的动态规划方程。此外，考虑到由 $f_k$ 散度和 Wasserstein 距离定义的模糊集，我们描述了在两种对手类型下实现连续状态下稳健值函数统一学习的最佳有限样本极小最大率。最后，我们展示了我们的框架在各种现实环境中的适用性。]]></description>
      <guid>https://arxiv.org/abs/2406.11281</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:17 GMT</pubDate>
    </item>
    <item>
      <title>改进情境动态定价算法</title>
      <link>https://arxiv.org/abs/2406.11316</link>
      <description><![CDATA[arXiv:2406.11316v1 公告类型：新
摘要：在情境动态定价中，卖方根据情境信息按顺序对商品进行定价。只有当价格低于其估值时，买方才会购买产品。卖方的目标是设计一种定价策略，以收集尽可能多的收入。我们关注两种不同的估值模型。第一个假设估值线性依赖于上下文，并进一步受到噪声的扭曲。在次要规律性假设下，我们的算法实现了最佳遗憾界限$\tilde{\mathcal{O}}(T^{2/3})$，从而改进了现有结果。第二个模型消除了线性假设，仅要求预期买方估值在上下文中为$\beta$-H\&quot;older。对于这个模型，我们的算法获得遗憾$\tilde{\mathcal{O}}(T^{d+2\beta/d+3\beta})$，其中$d$是上下文空间的维度。]]></description>
      <guid>https://arxiv.org/abs/2406.11316</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:17 GMT</pubDate>
    </item>
    <item>
      <title>带有老虎机反馈的主动聚类</title>
      <link>https://arxiv.org/abs/2406.11485</link>
      <description><![CDATA[arXiv:2406.11485v1 公告类型：新
摘要：我们研究主动聚类问题 (ACP)。学习者与具有 $d$ 维亚高斯反馈的 $N$ 臂随机老虎机进行交互。存在将臂划分为 $K$ 组的隐藏分区，使得同一组内的臂共享相同的均值向量。学习者的任务是发现这个具有最小预算（即观察次数最少）且误差概率小于规定常数 $\delta$ 的隐藏分区。在本文中，(i) 我们推导出预算的非渐近下限，(ii) 我们引入了计算效率高的 ACB 算法，其预算在大多数情况下都与下限相匹配。我们改进了均匀采样策略的性能。重要的是，与批量设置相反，我们确定主动设置中没有计算信息差距。]]></description>
      <guid>https://arxiv.org/abs/2406.11485</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:17 GMT</pubDate>
    </item>
    <item>
      <title>主动且随时有效的风险控制预测集</title>
      <link>https://arxiv.org/abs/2406.10490</link>
      <description><![CDATA[arXiv:2406.10490v1 公告类型：新
摘要：严格建立有关关键风险指标的黑盒机器学习模型的安全性对于提供有关模型行为的保证非常重要。最近，Bates 等人 (JACM &#39;24) 引入了风险控制预测集 (RCPS) 的概念，用于生成机器学习模型中统计上保证低风险的预测集。我们的方法将这一概念扩展到顺序设置，在这种情况下，即使数据是自适应收集的，我们也提供保证，并确保风险保证随时有效，即同时在所有时间步骤中成立。此外，我们提出了一个构建 RCPS 进行主动标记的框架，即允许使用标记策略来选择是否查询每个接收数据点的真实标签，并确保查询标签的数据点的预期比例低于预定的标签预算。我们还描述了如何使用预测因子（即我们为其提供风险控制保证的机器学习模型）通过估计以协变量为条件的预期风险来进一步提高 RCPS 的效用。我们描述了固定标签预算下标签策略和预测因子的最佳选择，并展示了一个遗憾结果，该结果将最佳标签策略和预测因子的估计误差与 RCPS 所依赖的财富过程联系起来。最后，我们介绍了制定标签策略的实用方法，并通过经验证明，与简单的基线标签策略（例如，标记所有点、随机标记点）相比，我们的标签策略使用更少的标签来实现更高的效用，无论是在模拟还是真实数据上。]]></description>
      <guid>https://arxiv.org/abs/2406.10490</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:16 GMT</pubDate>
    </item>
    <item>
      <title>Adam 对可分离数据的隐性偏见</title>
      <link>https://arxiv.org/abs/2406.10650</link>
      <description><![CDATA[arXiv:2406.10650v1 公告类型：新
摘要：Adam 已成为深度学习问题中最受青睐的优化器之一。尽管它在实践中取得了成功，但关于其理论理解仍存在许多谜团。在本文中，我们研究了 Adam 在线性逻辑回归中的隐性偏差。具体而言，我们表明，当训练数据是线性可分的时，Adam 会收敛到实现最大 $\ell_\infty$-margin 的线性分类器。值得注意的是，对于一般的学习率递减类，这种收敛发生在多项式时间内。我们的结果从理论角度阐明了 Adam 和（随机）梯度下降之间的区别。]]></description>
      <guid>https://arxiv.org/abs/2406.10650</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:16 GMT</pubDate>
    </item>
    <item>
      <title>通过预测问题中的最优收缩校准神经网络参数</title>
      <link>https://arxiv.org/abs/2406.10703</link>
      <description><![CDATA[arXiv:2406.10703v1 公告类型：新
摘要：本研究介绍了一种确保神经网络中最优参数存在性和唯一性的新方法。本文详细介绍了如何在参数为线性的域中将循环神经网络 (RNN) 转换为收缩。然后，它证明了通过 RNN 建模的预测问题，在损失函数中具有特定的正则化项，可以以解析方式表达其一阶条件。该方程组简化为两个涉及西尔维斯特方程的矩阵方程，可以部分求解。我们确定，如果满足某些条件，则存在最优参数，这些参数是唯一的，并且可以通过简单的算法以任何所需的精度找到。此外，随着神经元数量的增加，收敛条件变得更容易满足。还通过对参数进行线性约束来探索前馈神经网络 (FNN)。根据我们的模型，合并循环（具有固定或可变权重）将产生更容易训练的损失函数，因为它确保了迭代方法收敛的区域的存在。]]></description>
      <guid>https://arxiv.org/abs/2406.10703</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:16 GMT</pubDate>
    </item>
    <item>
      <title>通过随机矩阵理论分析多任务回归并应用于时间序列预测</title>
      <link>https://arxiv.org/abs/2406.10327</link>
      <description><![CDATA[arXiv:2406.10327v1 公告类型：新
摘要：在本文中，我们介绍了一种新的多任务回归理论框架，应用随机矩阵理论在高维非高斯数据分布下提供精确的性能估计。我们将多任务优化问题制定为正则化技术，以使单任务模型能够利用多任务学习信息。我们在线性模型的背景下推导出多任务优化的闭式解。我们的分析通过将多任务学习性能与各种模型统计数据（例如原始数据协方差、信号生成超平面、噪声水平以及数据集的大小和数量）联系起来，提供了有价值的见解。我们最终提出了一种一致的训练和测试误差估计，从而为多任务回归场景中的超参数优化提供了坚实的基础。在回归和多元时间序列预测中对合成和真实数据集的实验验证表明单变量模型有所改进，将我们的方法纳入训练损失中，从而利用多变量信息。]]></description>
      <guid>https://arxiv.org/abs/2406.10327</guid>
      <pubDate>Wed, 19 Jun 2024 03:16:15 GMT</pubDate>
    </item>
    </channel>
</rss>