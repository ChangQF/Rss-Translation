<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 19 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>预测不确定性的模型无关变量重要性：基于熵的方法</title>
      <link>https://arxiv.org/abs/2310.12842</link>
      <description><![CDATA[arXiv:2310.12842v3 公告类型：替换 
摘要：为了信任机器学习算法的预测，有必要了解导致这些预测的因素。对于概率和不确定性感知模型，不仅需要了解预测本身的原因，还需要了解模型对这些预测的信心水平的原因。在本文中，我们展示了如何将现有的可解释性方法扩展到不确定性感知模型，以及如何使用此类扩展来了解模型预测分布中不确定性的来源。特别是，通过调整排列特征重要性、部分依赖图和个体条件期望图，我们证明可以获得对模型行为的新见解，并且这些方法可用于测量特征对预测分布的熵和该分布下地面真实标签的对数似然的影响。通过使用合成数据和真实数据进行实验，我们证明了这些方法的实用性，可以了解不确定性的来源及其对模型性能的影响。]]></description>
      <guid>https://arxiv.org/abs/2310.12842</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:43 GMT</pubDate>
    </item>
    <item>
      <title>二元分类中的最佳对称性</title>
      <link>https://arxiv.org/abs/2408.08823</link>
      <description><![CDATA[arXiv:2408.08823v1 公告类型：交叉 
摘要：我们探索了群对称性在二元分类任务中的作用，提出了一个利用 Neyman-Pearson 最优性原理的新框架。与更大的对称组会导致分类性能提高的普遍直觉相反，我们的研究结果表明，选择合适的组对称性对于优化泛化和样本效率至关重要。我们为设计组等变神经网络建立了理论基础，将对称性的选择与数据的底层概率分布保持一致。我们的方法通过仔细调整对称组以适应问题的具体特征，为提高广泛应用的分类准确性提供了一种统一的方法。理论分析和实验结果表明，最佳分类性能并不总是与领域中可能的最大等变组相关，即使似然比在其适当子组之一下不变，而是与这些子组本身相关。这项工作为在不同的机器学习环境中构建更有效的组等变架构提供了见解和实用指南。]]></description>
      <guid>https://arxiv.org/abs/2408.08823</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:42 GMT</pubDate>
    </item>
    <item>
      <title>针对高斯过程的弱监督主动学习</title>
      <link>https://arxiv.org/abs/2204.08335</link>
      <description><![CDATA[arXiv:2204.08335v3 公告类型：替换 
摘要：为监督学习注释数据可能成本高昂。当注释预算有限时，可以使用主动学习来选择和注释那些可能为模型性能带来最大收益的观察结果。我们提出了一种主动学习算法，除了选择要注释的观察结果外，还可以选择获取的注释的精度。假设精度较低的注释更便宜，这允许模型以相同的注释预算探索输入空间的更大部分。我们在之前提出的高斯过程 BALD 目标上构建了我们的获取函数，并通过经验证明了能够在主动学习循环中调整注释精度的收益。]]></description>
      <guid>https://arxiv.org/abs/2204.08335</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:42 GMT</pubDate>
    </item>
    <item>
      <title>去中心化双边匹配市场的探索-承诺算法</title>
      <link>https://arxiv.org/abs/2408.08690</link>
      <description><![CDATA[arXiv:2408.08690v1 公告类型：交叉 
摘要：在去中心化的双边匹配市场中，需求方（玩家）与供应方（臂）竞争匹配，在线学习引起了广泛关注，因为它抽象出了匹配平台（例如 UpWork、TaskRabbit）中的复杂交互。然而，过去的研究假设每个臂都知道他们对玩家的偏好排名（单边学习），并且每个玩家都旨在通过连续的交互来学习对臂的偏好。此外，为了理论上的可处理性，通常会对问题做出一些（不切实际的）假设，例如广播玩家臂匹配 Liu 等人（2020；2021）；Kong &amp; Li (2023) 或连续独裁 Sankararaman 等人（2021）；Basu 等人（2021）；Ghosh 等人（2022）。在本文中，我们研究了一个去中心化的双边匹配市场，其中我们不假设玩家的偏好排名为各支队伍所预先知道。此外，我们对这个问题没有任何结构性假设。我们针对这个问题提出了一种多阶段探索然后提交类型的算法，即基于 epoch 的 CA-ETC（碰撞避免探索然后提交）（简称 \texttt{CA-ETC}），它不需要代理（玩家和支队伍）之间的任何通信，因此是去中心化的。我们表明，对于初始 epoch 长度 $T_{\circ}$ 和后续 epoch 长度 $2^{l/\gamma} T_{\circ}$（对于第 $l-$ 个 epoch，$\gamma \in (0,1)$ 作为算法的输入参数），\texttt{CA-ETC} 为第 $i$ 个玩家产生了玩家最佳预期遗憾 $\mathcal{O}\left(T_{\circ} (\frac{K \log T}{T_{\circ} \Delta^2})^{1/\gamma} + T_{\circ} (\frac{T}{T_{\circ}})^\gamma\right)$，其中 $T$ 是学习范围，$K$ 是 arm 的数量，$\Delta$ 是适当定义的问题差距。此外，我们提出了一种基于黑板通信的基线，在 $T$ 中实现对数遗憾。]]></description>
      <guid>https://arxiv.org/abs/2408.08690</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:41 GMT</pubDate>
    </item>
    <item>
      <title>渔夫在继承模型网络中收获并行学习</title>
      <link>https://arxiv.org/abs/2408.08493</link>
      <description><![CDATA[arXiv:2408.08493v1 公告类型：交叉 
摘要：随着表现出复杂继承关系的模型的不断增长和更新，在各种学习框架中进行反学习仍然具有挑战性。本文提出了一种新颖的反学习框架，该框架可以在表现出继承关系的模型之间实现完全并行的反学习。一个关键推动因素是新的统一模型继承图 (UMIG)，它使用有向无环图 (DAG) 捕获继承。我们框架的核心是新的 Fisher 继承反学习 (FIUn) 算法，它利用初始反学习模型中的 Fisher 信息矩阵 (FIM) 来精确定位继承模型中受影响的参数。通过使用 FIM，FIUn 方法打破了模型之间的顺序依赖关系，促进了同时进行反学习并减少了计算开销。我们进一步设计将不同的 FIM 合并为一个矩阵，在继承的模型之间同步更新。实验证实了我们的反学习框架的有效性。对于单类任务，它实现了完全的反学习，未学习标签的准确率为 0\%，而保留标签的准确率平均为 94.53\%。对于多类任务，未学习标签的准确率为 1.07\%，保留标签的准确率为 84.77\%。与其他方法相比，我们的框架将反学习速度提高了 99\%。]]></description>
      <guid>https://arxiv.org/abs/2408.08493</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:40 GMT</pubDate>
    </item>
    <item>
      <title>S$^3$Attention：通过平滑骨架草图提高长序列注意力</title>
      <link>https://arxiv.org/abs/2408.08567</link>
      <description><![CDATA[arXiv:2408.08567v1 公告类型：交叉 
摘要：基于注意力的模型在众多应用中取得了许多显著的突破。然而，注意力的二次复杂度使得普通的基于注意力的模型很难应用于长序列任务。提出了各种改进的注意力结构，通过引入低秩和用子序列近似整个序列来降低计算成本。这些方法最具挑战性的部分是在信息保存和计算减少之间保持适当的平衡：使用的子序列越长，保存的信息越好，但代价是引入更多的噪音和计算成本。在本文中，我们提出了一种基于平滑骨架草图的注意力结构，称为 S$^3$Attention，它比以前在协商这种权衡方面的尝试有了显著的改进。 S$^3$Attention 有两种机制可以有效地最小化噪声的影响，同时保持序列长度的线性复杂度：一种平滑块，用于混合长序列上的信息；一种矩阵草图方法，用于同时从输入矩阵中选择列和行。我们从理论和经验上验证了 S$^3$Attention 的有效性。对长距离竞技场 (LRA) 数据集和六个时间序列预测的广泛研究表明，S$^3$Attention 的表现明显优于 vanilla Attention 和其他最先进的 Attention 结构变体。]]></description>
      <guid>https://arxiv.org/abs/2408.08567</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:40 GMT</pubDate>
    </item>
    <item>
      <title>通过图像诱导的重要性权重增强价格趋势交易策略</title>
      <link>https://arxiv.org/abs/2408.08483</link>
      <description><![CDATA[arXiv:2408.08483v1 公告类型：交叉
摘要：我们打开“黑匣子”，通过深度学习图像分析技术识别价格图表图像中的预测性一般价格模式。我们识别的价格模式导致构建图像诱导重要性（三重-I）权重，这些权重根据现有价格趋势交易信号在预测价格变动中的重要性水平应用于加权移动平均。通过对中国股市的广泛实证分析，我们表明三重-I加权方案可以显著增强用于提出投资组合的价格趋势交易信号，并在网络规格、图像结构和股票规模方面进行了深思熟虑的稳健性研究。此外，我们证明三重-I加权方案能够从时间尺度迁移学习中提出长期投资组合，通过非技术迁移学习增强基于新闻的交易策略，并提高投资组合选择的众多交易规则的整体强度。]]></description>
      <guid>https://arxiv.org/abs/2408.08483</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:39 GMT</pubDate>
    </item>
    <item>
      <title>预处理和压缩：通过内在维度理解跨成像域的隐藏表示细化</title>
      <link>https://arxiv.org/abs/2408.08381</link>
      <description><![CDATA[arXiv:2408.08381v1 公告类型：交叉 
摘要：近年来，人们对神经网络隐藏表示的几何属性（例如内在维度 (ID)）如何在其层中演变，以及这些属性如何预测重要的模型行为（例如泛化能力）产生了兴趣。然而，有证据表明，这种行为可能会根据网络训练数据的领域（例如自然图像与医学图像）而发生显着变化。在这里，我们通过探索网络学习到的表示的 ID 如何在其层中演变来进一步探究，本质上是描述网络如何连续细化用于预测的输入数据的信息内容。通过分析六种网络架构中的 11 个自然和医学图像数据集，我们发现自然图像模型和医学图像模型之间的 ID 演化曲线形状明显不同：医学图像模型在网络中的表示 ID 中更早达到峰值，这意味着通常用于这些领域下游任务的图像特征及其抽象性存在差异。此外，我们发现峰值表示 ID 与其输入空间中数据的 ID 之间存在很强的相关性，这意味着模型学习到的表示的内在信息内容受其训练数据的信息内容引导。总体而言，我们的研究结果强调了自然和非自然成像领域在隐藏表示信息内容方面的网络行为存在显著差异，并进一步深入了解了网络学习到的特征如何由其训练数据塑造。]]></description>
      <guid>https://arxiv.org/abs/2408.08381</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:38 GMT</pubDate>
    </item>
    <item>
      <title>Oja 的可塑性规则克服了在生物约束下训练神经网络的若干挑战</title>
      <link>https://arxiv.org/abs/2408.08408</link>
      <description><![CDATA[arXiv:2408.08408v1 公告类型：交叉 
摘要：关于生物神经回路和深度人工神经网络 (DNN) 之间的相似点和不同点的文献很多。然而，现代 DNN 训练依赖于多种工程技巧，例如数据批处理、规范化、自适应优化器和精确权重初始化。尽管这些工程技巧在训练 DNN 中起着关键作用，但在比较生物和人工网络时，它们常常被忽视，这可能是因为缺乏直接生物学实现的证据。在这项研究中，我们表明 Oja 的可塑性规则部分克服了一些工程技巧的需要。具体而言，在困难但生物学上现实的学习场景下，例如在线学习、深度架构和次优权重初始化，Oja 规则可以显着提高纯反向传播的性能。我们的结果表明，简单的突触可塑性规则可以克服学习挑战，而这些挑战通常在训练 DNN 时使用生物学上不太合理的方法克服。]]></description>
      <guid>https://arxiv.org/abs/2408.08408</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:38 GMT</pubDate>
    </item>
    <item>
      <title>通过凸化损失实现 PAC-Bayesian 分类的错误分类超额风险界限</title>
      <link>https://arxiv.org/abs/2408.08675</link>
      <description><![CDATA[arXiv:2408.08675v1 公告类型：新
摘要：PAC-Bayesian 界限已被证明是推导泛化界限和设计机器学习中新学习算法的宝贵工具。然而，它通常侧重于提供相对于所选损失函数的泛化界限。在分类任务中，由于 0-1 损失的非凸性质，通常使用凸替代损失，因此当前的 PAC-Bayesian 界限主要针对此凸替代指定。这项工作将重点转移到在使用凸替代损失时为 PAC-Bayesian 分类提供错误分类超额风险界限。我们这里的关键因素是利用期望中的 PAC-Bayesian 相对界限，而不是依赖概率中的 PAC-Bayesian 界限。我们在几个重要的应用中展示了我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2408.08675</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:37 GMT</pubDate>
    </item>
    <item>
      <title>强模型的 Shapley 边际盈余</title>
      <link>https://arxiv.org/abs/2408.08845</link>
      <description><![CDATA[arXiv:2408.08845v1 公告类型：新
摘要：Shapley 值已广泛用于机器学习，作为解释模型预测和估计协变量重要性的一种方式。准确解释模型对于现实世界模型至关重要，既有助于决策，又能推断出真实数据生成过程 (DGP) 的属性。在本文中，我们证明，虽然基于模型的 Shapley 值可能是模型预测的准确解释者，但机器学习模型本身通常不能很好地解释 DGP，即使该模型非常准确。特别是在存在相互关联或噪声变量的情况下，高度预测模型的输出可能无法解释这些关系。这意味着对训练模型行为的解释可能无法提供对 DGP 的有意义的见解。在本文中，我们介绍了一种新的变量重要性算法，即强模型的 Shapley 边际盈余，该算法对可能的模型空间进行采样，以得出特征重要性的推理度量。我们将此方法与其他流行的特征重要性方法（基于 Shapley 和非基于 Shapley 的方法）进行了比较，并证明了相对于其他方法，此方法在推理能力方面具有显著的优越性。]]></description>
      <guid>https://arxiv.org/abs/2408.08845</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:37 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中潜变量的线性组合：插值及其他</title>
      <link>https://arxiv.org/abs/2408.08558</link>
      <description><![CDATA[arXiv:2408.08558v1 公告类型：新
摘要：生成模型对于数据合成和增强等应用至关重要。扩散、流匹配和连续正则化流已在各种模态中显示出有效性，并依赖于高斯隐变量进行生成。由于任何生成的对象都与特定的潜在变量直接相关，我们可以操纵变量来控制生成过程。然而，组合潜在变量的标准方法，如球面插值，只适用于或适用于特殊情况。此外，当前用于获取数据低维表示的方法（例如，对于搜索和创意应用的替代模型很重要）是网络和数据模态特定的。在这项工作中，我们表明组合变量的标准方法不会产生遵循模型训练预期分布的中间体。我们提出了高斯变量组合 (COG)，这是一种解决此问题的新型插值方法，易于实现，但与当前方法相匹配或改进。 COG 通常处理线性组合，并且如我们所展示的，它还支持其他操作，包括例如定义潜在空间的子空间，使用基于高斯潜在的生成模型简化高维对象的富有表现力的低维空间的创建。]]></description>
      <guid>https://arxiv.org/abs/2408.08558</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:36 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯操作模态分析的新视角</title>
      <link>https://arxiv.org/abs/2408.08664</link>
      <description><![CDATA[arXiv:2408.08664v1 公告类型：新
摘要：在运行模态分析 (OMA) 领域，获得的模态信息经常用于评估航空航天、机械、海上和土木结构的当前状态。然而，操作系统的随机性和缺乏强制信息可能导致结果不一致。因此，通过 OMA 量化恢复的模态参数的不确定性具有重要价值。在本文中，提出了一种关于贝叶斯 OMA 的新视角：贝叶斯随机子空间识别 (SSI) 算法。与现有的贝叶斯 OMA 方法不同，分层概率模型嵌入在协方差驱动的 SSI 的核心中。通过用贝叶斯等效方法替代典型相关分析，获得了模态特性的后验分布。针对所提出的贝叶斯公式提出了两种推理方案：马尔可夫链蒙特卡罗和变分贝叶斯。然后探讨了两个案例研究。第一项是使用模拟多自由度线性系统的数据进行的基准研究。应用贝叶斯 SSI 后，结果表明，两种推理方案都针对并恢复了相同的后验，后验均值与传统 SSI 结果之间具有良好的一致性。第二项研究将变分形式应用于从在用结构 Z24 桥梁获得的数据。本研究的结果以单一模型阶数呈现，然后使用稳定图。呈现了恢复的后验不确定性，并将其与经典 SSI 结果进行比较。观察到，平均值与固有频率一致的后验分布比远离固有频率的值表现出较低的方差。]]></description>
      <guid>https://arxiv.org/abs/2408.08664</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:36 GMT</pubDate>
    </item>
    <item>
      <title>通过对抗对比训练进行无监督迁移学习</title>
      <link>https://arxiv.org/abs/2408.08533</link>
      <description><![CDATA[arXiv:2408.08533v1 公告类型：新
摘要：在无标记场景下学习下游监督学习任务的数据表示既重要又具有挑战性。在本文中，我们提出了一种使用对抗性对比训练（ACT）的新型无监督迁移学习方法。我们的实验结果表明，在各种数据集上使用微调线性探测和 K-NN 协议均具有出色的分类准确率，与现有的最先进的自监督学习方法具有竞争力。此外，我们为错误指定、过度参数化的设置中的下游分类任务提供了端到端的理论保证，强调了大量未标记数据如何有助于预测准确性。我们的理论发现表明，当未标记样本量足够大时，下游任务的测试误差仅取决于 ACT 中使用的数据增强的效率。这为使用小样本量学习下游任务提供了理论理解。]]></description>
      <guid>https://arxiv.org/abs/2408.08533</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:35 GMT</pubDate>
    </item>
    <item>
      <title>利用可解释特征对谱域高维时间序列进行分类</title>
      <link>https://arxiv.org/abs/2408.08388</link>
      <description><![CDATA[arXiv:2408.08388v1 公告类型：新
摘要：时间序列的可解释分类在高维中提出了重大挑战。频域中的传统特征选择方法通常假设谱密度矩阵 (SDM) 或其逆中的稀疏性，这可能会限制实际应用。在本文中，我们提出了一种基于模型的方法，通过假设逆 SDM 之间的差异稀疏性来对高维平稳时间序列进行分类。我们的方法强调模型参数的可解释性，使其特别适用于神经科学等领域，在这些领域，了解不同状态下大脑网络连接的差异至关重要。模型参数的估计量在适当的条件下表现出一致性。我们进一步建议使用标准深度学习优化器进行参数估计，采用小批量和学习率调度等技术。此外，我们介绍了一种筛选最具鉴别力的频率进行分类的方法，该方法在一般条件下表现出可靠的筛选特性。所提模型的灵活性使得协变量的重要性可以随频率变化，从而实现细致入微的推断和对潜在问题的更深入洞察。我们方法的新颖之处在于模型参数的可解释性，满足了神经科学的关键需求。所提出的方法已在模拟示例和“Alert-vs-Drowsy”EEG 数据集上进行了评估。]]></description>
      <guid>https://arxiv.org/abs/2408.08388</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:34 GMT</pubDate>
    </item>
    </channel>
</rss>