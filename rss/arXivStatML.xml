<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 16 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>稀疏渐近 PCA：识别跨时间范围的稀疏潜在因子</title>
      <link>https://arxiv.org/abs/2407.09738</link>
      <description><![CDATA[arXiv:2407.09738v1 公告类型：交叉 
摘要：本文提出了一种使用新的稀疏渐近主成分分析 (APCA) 进行稀疏潜在因子建模的新方法。该方法在一般近似因子模型框架内分析大维面板数据系统在时间范围内的共同变动。与现有的基于稀疏 PCA 的稀疏因子建模方法不同，这些方法假设稀疏载荷矩阵，而我们的稀疏 APCA 假设因子过程在时间范围内是稀疏的，而相应的载荷矩阵不一定是稀疏的。这一发展的动机是观察到稀疏载荷的假设可能不适用于金融回报，因为市场因子的暴露通常是普遍的和非稀疏的。我们提出了一种截断幂法来估计第一个稀疏因子过程，并提出了一种用于多因子情况的顺序缩减方法。此外，我们开发了一种数据驱动的方法，使用一种新颖的横截面交叉验证方法识别时间范围内风险因素的稀疏性。从理论上讲，我们确定我们的估计量在温和条件下是一致的。蒙特卡罗模拟表明，所提出的方法在有限样本中表现良好。从实证上讲，我们分析了 2004 年 1 月至 2016 年 12 月标准普尔 500 指数股票平衡面板的每日股票收益。通过文本分析，我们研究与已识别的稀疏因素相关的特定事件，这些因素系统地影响股市。我们的方法为经济学家提供了一种新途径来研究和理解经济和金融体系随时间推移的系统性风险。]]></description>
      <guid>https://arxiv.org/abs/2407.09738</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:28 GMT</pubDate>
    </item>
    <item>
      <title>基于高斯过程的导数全局灵敏度分析的主动学习</title>
      <link>https://arxiv.org/abs/2407.09739</link>
      <description><![CDATA[arXiv:2407.09739v1 公告类型：交叉 
摘要：我们考虑了昂贵黑盒函数全局敏感性分析的主动学习问题。我们的目标是有效地学习不同输入变量的重要性，例如，在车辆安全实验中，我们研究各种部件厚度对安全目标的影响。由于函数评估成本高昂，我们使用主动学习来优先考虑产生最大价值的实验资源。我们提出了新的主动学习获取函数，直接针对高斯过程代理模型下基于导数的全局敏感性测量 (DGSM) 的关键数量。我们展示了主动学习直接应用于 DGSM 的第一个应用，并为这些测量开发了可处理的不确定性减少和信息增益获取函数。通过对合成和现实问题的全面评估，我们的研究证明了这些主动学习获取策略如何显着提高 DGSM 估计的样本效率，特别是在有限的评估预算下。我们的工作为各种科学和工程应用中更高效、更准确的敏感性分析铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2407.09739</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:28 GMT</pubDate>
    </item>
    <item>
      <title>TrIM：用于基于梯度的降维和高维回归的变换迭代蒙德里安森林</title>
      <link>https://arxiv.org/abs/2407.09964</link>
      <description><![CDATA[arXiv:2407.09964v1 公告类型：交叉 
摘要：我们提出了一种基于梯度的线性降维和高维回归的计算效率高的算法。该算法首先计算一个蒙德里安森林，并使用该估计量从回归函数的预期梯度外积 (EGOP) 估计中识别输入的相关特征子空间。此外，我们引入了一种称为变换迭代蒙德里安 (TrIM) 森林的迭代方法，通过使用 EGOP 估计来更新蒙德里安分区机制使用的特征和权重集，从而改进蒙德里安森林估计量。我们获得了从 TrIM 算法的一次迭代中获得的 EGOP 矩阵估计和随机森林估计量的一致性保证和收敛速度。最后，我们证明了我们提出的算法在各种设置中使用模拟数据和真实数据学习相关特征子空间的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.09964</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:28 GMT</pubDate>
    </item>
    <item>
      <title>UQE：非结构化数据库的查询引擎</title>
      <link>https://arxiv.org/abs/2407.09522</link>
      <description><![CDATA[arXiv:2407.09522v1 公告类型：交叉 
摘要：结构化数据分析是一个成熟的领域，有许多成功的方法。然而，大多数现实世界数据都以非结构化形式存在，例如图像和对话。我们研究了大型语言模型 (LLM) 在非结构化数据分析方面的潜力。特别是，我们提出了一种新的通用查询引擎 (UQE)，它直接查询非结构化数据集合并从中得出见解。该引擎接受通用查询语言 (UQL) 中的查询，UQL 是 SQL 的一种方言，在指定条件和运算符方面提供了完全的自然语言灵活性。新引擎利用 LLM 对非结构化数据进行分析的能力，同时还允许我们利用采样和优化技术的进步来实现高效和准确的查询执行。此外，我们借鉴了经典编译器理论中的技术来更好地协调采样方法和基础模型调用之间的工作流程。我们展示了 UQE 在不同模式（包括图像、对话和评论）以及一系列有用的查询类型（包括条件聚合、语义检索和抽象聚合）的数据分析中的效率。]]></description>
      <guid>https://arxiv.org/abs/2407.09522</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:27 GMT</pubDate>
    </item>
    <item>
      <title>正面和未标记数据：模型、估计、推理和分类</title>
      <link>https://arxiv.org/abs/2407.09735</link>
      <description><![CDATA[arXiv:2407.09735v1 公告类型：交叉 
摘要：本研究通过双指数倾斜模型 (DETM) 介绍了一种处理正和未标记 (PU) 数据的新方法。传统方法往往存在不足，因为它们仅适用于完全随机选择 (SCAR) PU 数据，其中标记的正和未标记的正数据被假定来自同一分布。相比之下，我们的 DETM 的双重结构有效地适应了更复杂和未被充分探索的随机选择的 PU 数据，其中标记和未标记的正数据可能来自不同的分布。我们严格建立了 DETM 的理论基础，包括可识别性、参数估计和渐近性质。此外，我们通过为 SCAR 条件开发拟合优度检验并为目标域中正实例的比例构建置信区间，向前迈进了统计推断。我们利用近似贝叶斯分类器进行分类任务，展示了 DETM 在预测方面的稳健性能。通过理论见解和实际应用，本研究强调了 DETM 是解决 PU 数据挑战的综合框架。]]></description>
      <guid>https://arxiv.org/abs/2407.09735</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:27 GMT</pubDate>
    </item>
    <item>
      <title>使用步长递减的 ROOT-SGD 增强随机优化的统计效率</title>
      <link>https://arxiv.org/abs/2407.10955</link>
      <description><![CDATA[arXiv:2407.10955v2 公告类型：新
摘要：在本文中，我们重新审视 \textsf{ROOT-SGD}，这是一种用于随机优化的创新方法，旨在弥合随机优化与统计效率之间的差距。所提出的方法通过集成精心设计的 \emph{递减步长策略} 来提高 \textsf{ROOT-SGD} 的性能和可靠性。这种方法解决了优化中的关键挑战，提供了强大的理论保证和实际好处。我们的分析表明，递减的 \textsf{ROOT-SGD} 在保持计算效率的同时实现了最佳收敛速度。通过动态调整学习率，\textsf{ROOT-SGD} 可确保在整个优化过程中提高稳定性和精度。这项研究的结果为开发既高效又具有统计鲁棒性的高级优化算法提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2407.10955</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:26 GMT</pubDate>
    </item>
    <item>
      <title>具有精选数据的自消费生成模型可证明优化人类偏好</title>
      <link>https://arxiv.org/abs/2407.09499</link>
      <description><![CDATA[arXiv:2407.09499v1 公告类型：交叉 
摘要：生成模型的快速发展带来了生成质量的显著飞跃，模糊了合成数据和真实数据之间的界限。网络规模的数据集现在很容易受到合成数据的不可避免污染，直接影响未来生成模型的训练。目前，文献中已经出现了一些关于自耗生成模型（又称迭代再训练）的理论结果，表明模型崩溃或稳定可能是可能的，这取决于每次再训练步骤中使用的生成数据的比例。然而，在实践中，合成数据在使用和上传到网上之前，通常会受到人工反馈和用户策划。例如，许多流行的文本到图像生成模型的界面，如 Stable Diffusion 或 Midjourney，会为给定的查询生成图像的几种变体，最终可以由用户策划。在本文中，我们从理论上研究了数据管理对生成模型迭代再训练的影响，并表明它可以看作是一种 \emph{隐式偏好优化机制}。然而，与标准偏好优化不同，生成模型无法访问成对比较所需的奖励函数或负样本。此外，我们的研究不需要访问密度函数，只需要访问样本。我们证明，如果根据奖励模型管理数据，则迭代再训练过程的预期奖励将最大化。我们进一步提供了在每个步骤中使用正比例真实数据时再训练循环稳定性的理论结果。最后，我们对合成数据集和 CIFAR10 进行了说明性实验，表明这种程序会放大奖励模型的偏差。]]></description>
      <guid>https://arxiv.org/abs/2407.09499</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:26 GMT</pubDate>
    </item>
    <item>
      <title>流扰动加速波尔兹曼分布的无偏采样</title>
      <link>https://arxiv.org/abs/2407.10666</link>
      <description><![CDATA[arXiv:2407.10666v1 公告类型：新
摘要：基于流的生成模型已用于对玻尔兹曼分布进行采样，但它们在高维系统中的应用受到获取流的雅可比矩阵的大量计算成本的阻碍。为了克服这一挑战，我们引入了流扰动方法，该方法将优化的随机扰动合并到流中。通过重新加权扰动流产生的轨迹，我们的方法实现了对玻尔兹曼分布的无偏采样，与强力雅可比计算和哈钦森估计量相比，速度提高了几个数量级。值得注意的是，它准确地采样了 Chignolin 蛋白，并明确表示了所有原子笛卡尔坐标，据我们所知，这是有史以来使用生成模型如此详细地采样的最大的分子。]]></description>
      <guid>https://arxiv.org/abs/2407.10666</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:25 GMT</pubDate>
    </item>
    <item>
      <title>从不完整、有限和嘈杂的数据中进行 PDE 的主成分流图学习</title>
      <link>https://arxiv.org/abs/2407.10854</link>
      <description><![CDATA[arXiv:2407.10854v1 公告类型：新
摘要：我们提出了一种在简化基础上对动态系统演化进行建模的计算技术，重点关注在高维非均匀网格上对部分观测偏微分方程 (PDE) 进行建模的挑战性问题。我们解决了数据驱动流程图学习的先前工作的局限性，因为我们专注于嘈杂和有限的数据，以转向实际应用中的数据收集场景。利用最近在模态和节点空间中对 PDE 进行建模的工作，我们提出了一种神经网络结构，该结构适用于仅在状态变量或计算域的子集上可用的嘈杂和有限数据的 PDE 建模。具体而言，使用学习的线性变换来减少空间网格点测量，然后在这个简化的基础上学习动态，然后再转换回节点空间。与以前的节点空间学习流程图模型相比，这种方法大大减少了神经网络的参数化。这主要允许使用较小的训练数据集，但也可以减少训练时间。]]></description>
      <guid>https://arxiv.org/abs/2407.10854</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:25 GMT</pubDate>
    </item>
    <item>
      <title>在选择偏差下对未标记正样本数据的真实类别进行增强预测</title>
      <link>https://arxiv.org/abs/2407.10309</link>
      <description><![CDATA[arXiv:2407.10309v1 公告类型：新
摘要：我们为正未标记 (PU) 数据引入了一种新的观察设置，其中预测时的观察结果也被标记。这在实践中很常见——我们认为附加信息对于预测很重要，并将此任务称为“增强 PU 预测”。我们允许标记依赖于特征。在这种情况下，建立贝叶斯分类器及其风险，并将其与仅基于预测器的未标记数据分类器的风险进行比较。我们在这种情况下引入了经验贝叶斯规则的几种变体并研究它们的性能。我们强调在增强 PU 场景中应用经典分类规则的危险（和易用性）——由于没有预先存在的研究，不知情的研究人员很容易歪曲获得的预测。我们得出结论，基于最近提出的为 PU 场景设计的变分自动编码器的变体与其他考虑的变体一样好或更好，并且在未标记样本的准确性方面比仅基于特征的方法具有优势。]]></description>
      <guid>https://arxiv.org/abs/2407.10309</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:24 GMT</pubDate>
    </item>
    <item>
      <title>适当的损失至少会令 1/2 阶感到遗憾</title>
      <link>https://arxiv.org/abs/2407.10417</link>
      <description><![CDATA[arXiv:2407.10417v1 公告类型：新
摘要：机器学习中的一个基本挑战是损失的选择，因为它表征了我们的学习任务，在训练阶段被最小化，并作为估计量的评估标准。通常会选择适当的损失，确保全风险的最小化器与真实概率向量相匹配。从适当损失中得出的估计量被广泛用于构建下游任务（如分类和排名）的预测器。在此过程中，基于获得的估计量的预测器如何在给定的下游任务下表现良好？这个问题与估计量更新时估计概率向量和真实概率向量之间的 $p$ 范数的行为实质上相关。在适当的损失框架中，估计概率向量与真实概率向量的次优性由替代遗憾来衡量。首先，我们分析了替代遗憾，并表明损失的严格适当性是建立非空虚替代遗憾界限的必要和充分条件。其次，我们解决了一个重要的未决问题，即对于一类严格适当的损失，p 范数的收敛阶不能比替代遗憾的 $1/2$ 阶更快。这意味着严格适当的损失需要最佳收敛速度。]]></description>
      <guid>https://arxiv.org/abs/2407.10417</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:24 GMT</pubDate>
    </item>
    <item>
      <title>理解双层线性神经网络中的逐次双下降</title>
      <link>https://arxiv.org/abs/2407.09845</link>
      <description><![CDATA[arXiv:2407.09845v1 公告类型：新
摘要：逐次双下降是一种现象，泛化性能在过度拟合点之外得到改善，导致在学习过程中泛化曲线出现两次下降。了解驱动这种行为的机制不仅对于理解机器学习模型的泛化行为至关重要，而且对于采用传统的选择方法（例如使用早期停止来减轻过度拟合）也至关重要。虽然我们最终想要得出更复杂模型（例如深度神经网络）的结论，但关于逐次双下降根本原因的大多数理论结论都是基于简单模型（例如标准线性回归）。为了开始弥合这一差距，我们研究了两层线性神经网络中的逐次双下降。首先，我们推导出线性两层模型的梯度流，该梯度流连接了标准线性回归模型的学习动态和具有二次权重的线性两层对角网络。其次，我们通过推导泛化误差遵循双下降模式的必要条件，确定了在额外模型层中出现的 epoch-wise 双下降的其他因素。虽然线性回归中的 epoch-wise 双下降归因于输入方差的差异，但在两层模型中，输入输出协方差矩阵的奇异值也起着重要作用。这引出了关于真正深度模型的 epoch-wise 双下降的未识别因素的进一步问题。]]></description>
      <guid>https://arxiv.org/abs/2407.09845</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:23 GMT</pubDate>
    </item>
    <item>
      <title>分类的符合性评分的加权聚合</title>
      <link>https://arxiv.org/abs/2407.10230</link>
      <description><![CDATA[arXiv:2407.10230v1 公告类型：新
摘要：共形预测是一种强大的框架，用于在多类分类中构建具有有效覆盖保证的预测集。然而，现有的方法通常依赖于单一的得分函数，这会限制它们的效率和信息量。我们提出了一种新方法，该方法结合了多个得分函数，通过确定最小化预测集大小的最佳权重来提高共形预测器的性能。我们的理论分析建立了加权得分函数和 Vapnik-Chervonenkis 理论中研究的函数子图类之间的联系，为理解所提出方法的有效性提供了严格的数学基础。实验表明，我们的方法在保持有效覆盖率的同时始终优于单得分共形预测器，提供了一种原则性和数据驱动的方法来提高共形预测在分类任务中的效率和实用性。]]></description>
      <guid>https://arxiv.org/abs/2407.10230</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:23 GMT</pubDate>
    </item>
    <item>
      <title>基于黎曼流形学习的广义低秩矩阵感知参数估计</title>
      <link>https://arxiv.org/abs/2407.10238</link>
      <description><![CDATA[arXiv:2407.10238v1 公告类型：新
摘要：我们证明了广义低秩矩阵感知的收敛保证——即矩阵感知中观测值可能通过一些非线性链接函数。我们专注于最优估计量的局部收敛，忽略优化问题。具体来说，假设经验损失 $\theta^0$ 的最小化器位于真实参数 $\theta^*$ 周围的恒定大小球中，我们证明 $d(\theta^0,\theta^*)=\tilde{O}(\sqrt{dk^2/n})$。我们的分析依赖于黎曼几何中的工具来处理参数空间中的旋转对称性。]]></description>
      <guid>https://arxiv.org/abs/2407.10238</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:23 GMT</pubDate>
    </item>
    <item>
      <title>极端情况下的格兰杰因果关系</title>
      <link>https://arxiv.org/abs/2407.09632</link>
      <description><![CDATA[arXiv:2407.09632v1 公告类型：新
摘要：我们引入了一个严格的格兰杰因果关系数学框架，旨在识别时间序列中极端事件的因果关系。格兰杰因果关系在揭示时变变量之间的方向关系方面起着关键作用。虽然这一概念在极端和高度不稳定的时期变得更加重要，但最先进的方法主要关注分布主体内的因果关系，往往忽略了仅在极端事件期间表现出来的因果机制。我们的框架旨在通过利用因果尾部系数来推断极端事件中的因果关系。我们建立了极端因果关系与其他因果概念之间的等价关系，包括（经典）格兰杰因果关系、Sims 因果关系和结构因果关系。我们证明了格兰杰因果关系在极端情况下的其他关键属性，并表明该框架在存在隐藏混杂因素的情况下特别有用。我们还提出了一种新颖的推理方法，用于从数据中检测极端情况下格兰杰因果关系的存在。我们的方法是无模型的，可以处理非线性和高维时间序列，在所有考虑的设置中，无论是在性能还是速度上，都优于当前最先进的方法，并且发现在应用于金融和极端天气观测时可以发现一致的效果。]]></description>
      <guid>https://arxiv.org/abs/2407.09632</guid>
      <pubDate>Wed, 17 Jul 2024 03:17:22 GMT</pubDate>
    </item>
    </channel>
</rss>