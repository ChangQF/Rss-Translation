<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Tue, 09 Jan 2024 06:17:57 GMT</lastBuildDate>
    <item>
      <title>非线性两时间尺度随机逼近中的有限时间解耦收敛。 （arXiv：2401.03893v1 [数学.OC]）</title>
      <link>http://arxiv.org/abs/2401.03893</link>
      <description><![CDATA[在双时间尺度随机逼近 (SA) 中，两次迭代更新为
使用不同的步长改变速度，每次更新都会影响
其他。先前对线性二次尺度 SA 的研究发现
这些更新的均方误差的收敛速度是相关的
仅取决于它们各自的步长，导致所谓的
解耦收敛。然而，实现这种解耦的可能性
非线性 SA 的收敛性仍然知之甚少。我们的研究探索了
非线性两时间尺度 SA 中有限时间解耦收敛的潜力。
我们发现，在较弱的 Lipschitz 条件下，传统分析是
不足以实现解耦收敛。这一发现进一步
有反例在数值上支持。但通过引入一个额外的
嵌套局部线性条件下，我们证明解耦收敛为
仍然可行，具体取决于相关步长的适当选择
具有平滑度参数。我们的分析取决于精细的表征
两次迭代之间的矩阵交叉项并利用四阶
控制由局部引起的高阶近似误差的矩
线性假设。
]]></description>
      <guid>http://arxiv.org/abs/2401.03893</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>基于贝蒂数的损耗面的拓扑描述。 （arXiv：2401.03824v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03824</link>
      <description><![CDATA[在深度学习模型的背景下，最近受到关注
研究损失函数的表面以便更好地理解
使用基于梯度下降的方法进行训练。此次寻找合适的
分析和拓扑的描述导致了许多努力
识别虚假最小值并表征梯度动态。我们的工作旨在
通过提供拓扑测量来评估损失，为该领域做出贡献
多层神经网络的复杂性。我们比较深入和
通过推导具有常见 sigmoidal 激活函数的浅层架构
损失函数复杂性的上限和下限并揭示
隐藏单元的数量、训练对复杂性有何影响
模型，以及使用的激活函数。此外，我们发现某些
损失函数或模型架构的变化，例如添加
$\ell_2$ 正则化项或在前馈中实现跳过连接
网络，不影响特定情况下的损耗拓扑。
]]></description>
      <guid>http://arxiv.org/abs/2401.03824</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>使用核 Fisher-Rao 流进行单位时间采样。 （arXiv：2401.03892v1 [stat.CO]）</title>
      <link>http://arxiv.org/abs/2401.03892</link>
      <description><![CDATA[我们引入了一种新的平均场常微分方程和相应的相互作用粒子
用于从非标准化目标密度或贝叶斯后验采样的系统。
相互作用的粒子系统是无梯度的，以封闭形式提供，
并且只需要能够从参考密度中采样并计算
（未归一化的）目标与参考密度之比。平均场 ODE 为
通过求解传输速度场的泊松方程获得
沿着两种密度的几何混合的样本，这是路径
特定的 Fisher-Rao 梯度流。我们采用复制核希尔伯特
速度场的空间模拟，这使得泊松方程易于处理
并使我们能够在有限样本上离散化所得平均场 ODE，
作为一个简单的相互作用的粒子系统。平均场 ODE 还可以表示为
从离散时间的角度导出作为连续的极限
Monge-Amp\`ere 方程在称为
样品驱动的最佳运输。我们凭经验证明我们的
相互作用的粒子系统可以产生高质量的样品
具有不同特征的分布。
]]></description>
      <guid>http://arxiv.org/abs/2401.03892</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>上下文固定预算最佳臂识别：具有策略学习的自适应实验设计。 （arXiv：2401.03756v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03756</link>
      <description><![CDATA[个体化治疗建议是循证医学中的一项关键任务
决策。在本研究中，我们将此任务制定为固定预算最佳任务
具有上下文信息的手臂识别（BAI）问题。在这个设定下，
我们考虑进行多个治疗组的适应性实验。在每一个
在这一轮中，决策者观察到表征某个事物的背景（协变量）
实验单元，并将该单元分配给其中一个治疗组。在最后
在实验中，决策者推荐的治疗组估计为
根据具体情况产生最高的预期结果（最佳治疗
手臂）。该决策的有效性是根据最坏情况来衡量的
预期简单遗憾（政策遗憾），代表最大的差异
最佳治疗和推荐治疗的有条件预期结果之间
给定上下文的武器。我们的第一步是推导出渐进下界
最坏的情况预期只是后悔，这也意味着理想的治疗
分配规则。遵循下限，我们提出自适应采样
(AS)-策略学习推荐(PL)策略。在这个策略下，我们
随机分配一个治疗组，其目标分配比率为
每轮。在实验结束时，我们训练一个策略，一个函数
通过最大化反事实，在给定背景的情况下推荐治疗组
经验政策价值。我们的结果表明 AS-PL 策略是
渐进极小极大最优，其主导因子为预期简单
遗憾的是与我们既定的最坏情况下限一致。这项研究
在各个领域具有广泛的影响，并且根据现有文献，
我们的方法可以被视为一种自适应实验设计
政策学习、政策学习或适应性福利最大化。
]]></description>
      <guid>http://arxiv.org/abs/2401.03756</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>最优差分私有 PCA 和尖峰协方差矩阵的估计。 （arXiv：2401.03820v1 [数学.ST]）</title>
      <link>http://arxiv.org/abs/2401.03820</link>
      <description><![CDATA[估计协方差矩阵及其相关主成分是
当代统计学的基本问题。虽然最优估计
程序已经开发出具有易于理解的特性，越来越多的
对隐私保护的需求给这个经典的问题带来了新的复杂性
问题。在本文中，我们研究最优差分私人委托人
尖峰协方差内的成分分析 (PCA) 和协方差估计
模型。

我们精确表征特征值和特征向量的敏感性
在此模型下并建立估计的最小最大收敛率
主成分和协方差矩阵。这些利率可维持至
对数因子并包含一般 Schatten 范数，包括频谱
范数、弗罗贝尼乌斯范数和核范数作为特例。

我们引入了计算效率高的差分私有估计器，并且
证明它们的极小极大最优性，直至对数因子。此外，
建立匹配的极小极大下界。值得注意的是，与
现有的文献，我们的结果适应了不同的排名，不需要
不同主成分之间的特征间隙条件，甚至仍然有效
如果样本量远小于尺寸。
]]></description>
      <guid>http://arxiv.org/abs/2401.03820</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络认知不确定性的准确且可扩展的估计。 （arXiv：2401.03350v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03350</link>
      <description><![CDATA[虽然图神经网络（GNN）广泛用于节点和图
表示学习任务，GNN 不确定性估计的可靠性
分配转移的研究相对较少。确实，虽然
事后校准策略可用于改善分布
校准，他们也不需要改进分布偏移下的校准。
然而，产生具有更好内在不确定性的 GNN 的技术
估计值特别有价值，因为它们总是可以与
稍后制定事后策略。因此，在这项工作中，我们提出 G-$\Delta$UQ，
旨在改善 GNN 内在不确定性的新颖训练框架
估计。我们的框架采用随机数据中心原则
通过新颖的图锚定策略来绘制数据图，并且能够支持
部分随机 GNN。然而，普遍的观点是完全随机的
网络对于获得可靠的估计是必要的，我们发现
采样时我们的锚定策略引起的功能多样性
假设使这变得不必要，并允许我们支持 G-$\Delta$UQ
预训练模型。事实上，通过协变量下的广泛评估，
概念和图形大小的变化，我们表明 G-$\Delta$UQ 会带来更好的结果
用于节点和图分类的校准 GNN。此外，它还改善了
基于不确定性的分布外检测任务的性能
泛化差距估计。总的来说，我们的工作提供了以下方面的见解：
GNN 的不确定性估计，并演示了 G-$\Delta$UQ 的实用性
以获得可靠的估计。
]]></description>
      <guid>http://arxiv.org/abs/2401.03350</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>临床试验结果预测的不确定性量化。 （arXiv：2401.03482v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03482</link>
      <description><![CDATA[不确定性量化的重要性日益得到人们的认可
机器学习的多元化领域。准确评估模型预测
不确定性有助于加深理解并增强信心
研究人员和实践者。这在医学诊断中尤其重要
和药物发现领域，可靠的预测直接影响研究
质量和患者健康。

在本文中，我们建议将不确定性量化纳入
临床试验结果预测。我们的主要目标是增强模型的
辨别细微差别的能力，从而显着提高
整体表现。

我们采用了选择性分类方法来实现我们的目标，
将其与分层交互网络（HINT）无缝集成，
这是临床试验预测模型的前沿。可选择的
分类，涵盖一系列不确定性方法
量化，使模型能够在面对
标记有模糊性或低置信度的样本，从而提高准确性
对它选择分类的实例的预测。一系列
综合实验表明，结合选择性
临床试验预测的分类显着增强了模型的
绩效，关键指标的显着上升证明了这一点，例如
PR-AUC、F1、ROC-AUC 和总体准确度。

具体来说，所提出的方法达到了 32.37\%、21.43\% 和 13.27\%
在第一阶段、第二阶段和第二阶段中，PR-AUC 相对于基础模型 (HINT) 的相对改进
三、试验结果分别预测。当预测第三阶段时，我们的
方法达到 0.9022 PR-AUC 分数。

这些发现说明了该方法的稳健性和预期效用
临床试验预测领域的策略，可能会设定一个
领域新标杆。
]]></description>
      <guid>http://arxiv.org/abs/2401.03482</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>现实主义行动：使用 YOLOv8 和 DeiT 从医学图像中对脑肿瘤进行异常感知诊断。 (arXiv:2401.03302v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2401.03302</link>
      <description><![CDATA[在医学领域，可靠的检测和分类
由于图像的稀有性，从图像中识别脑肿瘤仍然是一个艰巨的挑战
患者群体中的肿瘤。因此，检测能力
异常情况下的肿瘤对于确保及时干预和预防至关重要
改善患者治疗效果。本研究通过利用深度学习来解决这个问题
学习（DL）技术来检测和分类具有挑战性的脑肿瘤
情况。来自国家脑图实验室 (NBML) 的精选数据集
共有81名患者，其中肿瘤病例30例，正常病例51例。这
检测和分类管道分为两个连续的
任务。检测阶段涉及全面的数据分析和
预处理修改图像样本数量和患者数量
每个类别的异常分布（每 1 个肿瘤 9 个正常值）符合
现实世界的场景。接下来，除了通用的评估指标之外
测试中，我们采用了一种名为“Patient to”的新颖性能评估方法
患者（PTP），注重模型的现实评估。在里面
检测阶段，我们微调了YOLOv8n检测模型来检测肿瘤
地区。随后的测试和评估产生了具有竞争力的性能
通用评估指标和 PTP 指标。此外，使用数据
高效图像变换器（DeiT）模块，我们提炼出视觉变换器
来自微调 ResNet152 的 (ViT) 模型作为分类中的教师
阶段。这种方法在可靠的肿瘤检测方面展示了有希望的进步
和分类，为肿瘤诊断提供潜在的进步
真实世界的医学成像场景。
]]></description>
      <guid>http://arxiv.org/abs/2401.03302</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>时间序列异常检测中的弱增强变分自编码器。 （arXiv：2401.03341v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03341</link>
      <description><![CDATA[由于他们的无监督训练和不确定性估计，深度
变分自动编码器（VAE）已成为强大的工具
基于重建的时间序列异常检测（TSAD）。现有基于 VAE 的
TSAD 方法，无论是统计方法还是深度方法，都会调整元先验来估计
有效捕获时空依赖性的似然概率
数据。然而，这些方法面临着固有数据的挑战
稀缺性，这在异常检测任务中经常出现。如此稀缺
容易导致潜在空洞，潜在空间中的不连续区域，从而导致
在这些不连续空间的非鲁棒重建中。我们提议写一本小说
将 VAE 与自我监督学习（SSL）相结合的生成框架
解决这个问题。
]]></description>
      <guid>http://arxiv.org/abs/2401.03341</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>神经元时间滤波器作为正常模式提取器。 （arXiv：2401.03248v1 [q-bio.NC]）</title>
      <link>http://arxiv.org/abs/2401.03248</link>
      <description><![CDATA[为了在生理延迟的情况下产生行动，大脑必须
预测未来。在这里，我们探讨预测如何成为大脑的核心
通过考虑神经元预测标量时间序列的未来来实现函数
输入。假设滞后向量（由以下组成的向量）的动态
时间序列的几个连续元素）是局部线性的，正态
模式分解将动态分解为独立演化
（特征）模式允许直接预测。我们建议一个神经元
学习顶部模式并将其输入投影到相关的子空间上。在下面
根据这种解释，神经元的时间滤波器对应于左侧
广义特征值问题的特征向量。我们通过数学分析
这种算法对合成数据的噪声观测的操作
由线性系统产生。有趣的是，时间滤波器的形状
随信噪比 (SNR) 变化：噪声输入产生单相
滤波器和不断增长的信噪比导致多相滤波器逐渐
更多的相数。时间滤波器随输入 SNR 的变化
类似于在生物神经元中实验观察到的情况。
]]></description>
      <guid>http://arxiv.org/abs/2401.03248</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>TeLeS：用于估计端到端 ASR 置信度的时间词素相似性评分。 （arXiv：2401.03251v1 [eess.AS]）</title>
      <link>http://arxiv.org/abs/2401.03251</link>
      <description><![CDATA[端到端 (E2E) 自动预测的置信度估计
语音识别 (ASR) 模型有利于 ASR 的下游和上游任务。
基于类别概率的置信度分数并不能准确地代表
过度自信的 ASR 预测的质量。辅助置信度估计
模型 (CEM) 校准预测。使用最先进的 (SOTA) 解决方案
CEM 培训的二元目标分数。然而，二进制标签并没有透露
预测单词的粒度信息，例如之间的时间对齐
参考和假设以及预测的单词是否完全错误
或包含拼写错误。针对这个问题，我们提出了一部小说
用于训练 CEM 的时域相似性 (TeLeS) 置信度得分。讲话
训练CEM时目标分数的数据不平衡，我们使用收缩损失
专注于难以学习的数据点，并尽量减少容易学习的数据点的影响
数据点。我们用三种语言训练的 ASR 模型进行实验，
即印地语、泰米尔语和卡纳达语，具有不同的训练数据大小。实验
表明 TeLeS 可以很好地跨领域推广。为了演示
为了验证所提出方法的适用性，我们制定了基于 TeLeS 的采集
(TeLeS-A) 用于对主动学习中的不确定性进行采样的函数。我们观察到一个
与 SOTA 方法相比，字错误率 (WER) 显着降低。
]]></description>
      <guid>http://arxiv.org/abs/2401.03251</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>可以利用先验信息实现更快收敛的罗宾斯-门罗序列。 （arXiv：2401.03206v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03206</link>
      <description><![CDATA[我们提出了一种新方法来提高 Robbins-Monro 的收敛速度
算法通过将目标点的先验信息引入到
罗宾斯-门罗迭代。我们实现了先验信息的合并
不需要——可能是错误的——回归模型，这将
还带来额外的限制。我们证明这个先验信息
Robbins-Monro 序列对于各种先验分布都是收敛的，
甚至是错误的，例如高斯分布、高斯分布的加权和，例如在内核中
密度估计，以及有界任意分布函数更大
比零。我们进一步对序列进行数值分析以了解其
性能和参数的影响。结果表明
先验信息 Robbins-Monro 序列收敛速度快于标准
一，特别是在第一步，这对于
功能测量数量有限的应用，以及当
观察底层函数的噪声很大。我们最终提出一个规则
选择序列的参数。
]]></description>
      <guid>http://arxiv.org/abs/2401.03206</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>用于约束生成建模的反射 Schr\"odinger 桥。(arXiv:2401.03228v1 [stat.ML])</title>
      <link>http://arxiv.org/abs/2401.03228</link>
      <description><![CDATA[扩散模型已成为大规模生成的首选方法
实际应用中的模型。这些应用往往涉及到数据
分布仅限于有界域内，通常需要临时
边界执行的阈值技术。反射扩散模型
(Lou23) 旨在通过生成数据分布来增强泛化性
通过由反射布朗运动控制的向后过程。然而，
如果没有
正确微分同胚映射的推导，但不保证最优
运输属性。为了克服这些限制，我们引入了反射
薛定谔桥算法：熵正则化最优传输方法
专为在不同的有界域内生成数据而定制。我们衍生出优雅
反映了诺伊曼的前向-后向随机微分方程和
Robin 边界条件，将基于散度的似然训练扩展到
有界域，并探索与熵最优传输的自然联系
用于近似线性收敛的研究 - 一个有价值的见解
实践培训。我们的算法可以在不同的领域产生稳健的生成模型
域，其可扩展性在现实世界的约束中得到了证明
通过标准图像基准生成建模。
]]></description>
      <guid>http://arxiv.org/abs/2401.03228</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>Krylov 三次正则化牛顿：具有无量纲收敛率的子空间二阶方法。 （arXiv：2401.03058v1 [数学.OC]）</title>
      <link>http://arxiv.org/abs/2401.03058</link>
      <description><![CDATA[二阶优化方法，例如三次正则牛顿法，
以其快速收敛速度而闻名；尽管如此，他们还是成为
由于其大量的内存，在高维问题中不切实际
要求和计算成本。一种有希望的方法是执行
低维子空间内的二阶更新，从而产生
子空间二阶方法。然而，大多数现有的子空间
二阶方法随机选择子空间，从而导致
收敛速度较慢，具体取决于问题的维度 $d$。在这个
论文中，我们介绍了一种新颖的子空间三次正则化牛顿方法
实现了与维度无关的全局收敛速度
${O}\left(\frac{1}{mk}+\frac{1}{k^2}\right)$ 用于求解凸优化
问题。这里，$m$表示子空间维度，可以是
明显小于 $d$。我们没有采用随机子空间，
主要创新涉及执行三次正则牛顿更新
在与 Hessian 相关的 Krylov 子空间内以及
目标函数。这一结果标志着第一个实例
子空间二阶方法的与维数无关的收敛速度。
此外，当满足 Hessian 的特定光谱条件时，我们的
方法恢复全维三次正则化的收敛速度
牛顿法。数值实验表明我们的方法收敛速度比
现有的随机子空间方法，特别是对于高维问题。
]]></description>
      <guid>http://arxiv.org/abs/2401.03058</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>SPQR：使用强化学习的尖峰随机模型控制 Q 集成独立性。 （arXiv：2401.03137v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03137</link>
      <description><![CDATA[减轻高估偏差是深度学习面临的一项关键挑战
强化学习以在更复杂的任务上取得成功
或包含分布外数据的离线数据集。为了克服
高估偏差，Q-学习的集成方法已经被研究
利用多个 Q 函数的多样性。由于网络初始化有
是促进 Q 函数多样性的主要方法，
启发式设计的多样性注入方法已在
文学。然而，之前的研究并没有试图接近有保证的
从理论角度来看，独立于系综。通过引入一个
基于随机矩阵的 Q 系综独立性的新型正则化损失
理论中，我们提出了尖峰Wishart Q-系综独立正则化（SPQR）
用于强化学习。具体来说，我们修改了棘手的假设
Q-系综独立性到易处理 KL 的测试标准
Q 系综和目标的频谱分布之间的分歧
维格纳半圆分布。我们在多个在线和
离线集成 Q 学习算法。在实验中，SPQR 优于
在线和离线 RL 基准测试中的基线算法。
]]></description>
      <guid>http://arxiv.org/abs/2401.03137</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:50 GMT</pubDate>
    </item>
    </channel>
</rss>