<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 13 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>哪个LLM值得玩？具有时间增加强盗的收敛感知在线模型选择</title>
      <link>https://arxiv.org/abs/2403.07213</link>
      <description><![CDATA[arXiv:2403.07213v1 公告类型：交叉
摘要：随着最近法学硕士的采用激增，聊天机器人、搜索引擎和新闻推荐等基于 Web 的应用程序的规模和复杂性不断增长。由于需要在不同的集合中选择最佳模型，同时平衡任务奖励和探索成本，在线模型选择因此引起了越来越多的关注。组织面临着诸如是否采用昂贵的基于 API 的法学硕士或本地微调的小型法学硕士等决策，权衡成本与性能。传统的选择方法通常会在选择一个候选模型之前评估每个候选模型，鉴于培训和微调法学硕士的成本不断上升，这种方法变得不切实际。此外，分配过多的资源来探索表现不佳的模型也是不可取的。虽然最近的一些工作利用在线老虎机算法来管理模型选择中的探索-利用权衡，但它们往往忽视了模型性能随着模型迭代微调而增加然后收敛的趋势，导致预测不太准确和模型次优选择。
  在本文中，我们提出了一种时增老虎机算法TI-UCB，该算法有效地预测了由于微调而导致的模型性能的提高，并有效地平衡了模型选择中的探索和利用。为了进一步捕获模型的收敛点，我们通过比较连续增长预测来开发变化检测机制。我们从理论上证明，我们的算法在典型的递增老虎机设置中实现了对数后悔上限，这意味着快速的收敛速度。我们的方法的优势也通过分类模型选择和法学硕士在线选择的大量实验得到了实证验证。我们的结果强调了在法学硕士部署中利用先增加后收敛模式进行更高效、更经济的模型选择的重要性。]]></description>
      <guid>https://arxiv.org/abs/2403.07213</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>随机重组的随机外梯度：改进变分不等式的收敛性</title>
      <link>https://arxiv.org/abs/2403.07148</link>
      <description><![CDATA[arXiv:2403.07148v1 公告类型：交叉
摘要：随机外梯度（SEG）方法是解决各种机器学习任务中出现的有限和最小最大优化和变分不等式问题（VIP）的最流行算法之一。然而，现有的SEG收敛分析主要集中在其替换变体上，而该方法的实际实现是随机重新排列组件并顺序使用它们。与经过充分研究的替换变体不同，随机重组 SEG (SEG-RR) 缺乏既定的理论保证。在这项工作中，我们为三类 VIP 提供了 SEG-RR 的收敛分析：(i) 强单调、(ii) 仿射和 (iii) 单调。我们推导出 SEG-RR 比均匀替换采样 SEG 实现更快收敛速度​​的条件。在单调设置中，我们对 SEG-RR 的分析保证了在没有大批量大小的情况下收敛到任意精度，这是经典的替换 SEG 中所需的强烈要求。作为我们结果的副产品，我们为 Shuffle Once SEG（仅在算法开始时对数据进行洗牌）和 Incremental Extragradient（不对数据进行洗牌）提供收敛保证。我们通过实验来补充我们的分析，这些实验验证了 SEG-RR 相对于经典的替换采样 SEG 的优越性能。]]></description>
      <guid>https://arxiv.org/abs/2403.07148</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络的不确定性：一项调查</title>
      <link>https://arxiv.org/abs/2403.07185</link>
      <description><![CDATA[arXiv:2403.07185v1 公告类型：交叉
摘要：图神经网络（GNN）已广泛应用于各种实际应用中。然而，GNN 的预测不确定性源于多种来源，例如数据固有的随机性和模型训练误差，可能会导致不稳定和错误的预测。因此，识别、量化和利用不确定性对于提高下游任务模型的性能以及 GNN 预测的可靠性至关重要。本次调查旨在从不确定性的角度对 GNN 进行全面的概述，重点是其在图学习中的集成。我们比较和总结现有的图不确定性理论和方法，以及相应的下游任务。因此，我们弥合了理论与实践之间的差距，同时连接了不同的 GNN 社区。此外，我们的工作为该领域有希望的方向提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.07185</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>一些凸消息传递算法收敛到不动点</title>
      <link>https://arxiv.org/abs/2403.07004</link>
      <description><![CDATA[arXiv:2403.07004v1 公告类型：交叉
摘要：图模型中 MAP 推理问题的一种流行方法是通过（块）坐标下降来最小化从对偶线性规划或拉格朗日松弛获得的上限。此类算法的示例包括最大和扩散和顺序树重加权消息传递。目前尚未完全了解这些方法的收敛特性。已证明它们收敛于以主动约束的局部一致性为特征的集合，且收敛速度未知；然而，尚不清楚迭代是否完全收敛（到任何单个点）。我们证明了一个更强的结果（之前推测但从未证明）：迭代收敛到算法的固定点。此外，我们表明它们在 $\mathcal{O}(1/\varepsilon)$ 迭代中实现了精度 $\varepsilon&gt;0$。
  我们首先使用一种新颖的证明技术证明了应用于一般分段仿射凸目标的坐标下降版本。然后，我们通过减少一些流行的坐标下降算法来解决这个问题，从而证明了这种方法的通用性。最后，我们表明，与我们的主要结果相反，应用于约束优化问题的类似版本的坐标下降不需要收敛。]]></description>
      <guid>https://arxiv.org/abs/2403.07004</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>高效同步学习与评估的补习法</title>
      <link>https://arxiv.org/abs/2403.07031</link>
      <description><![CDATA[arXiv:2403.07031v1 公告类型：交叉
摘要：我们介绍了“cram”方法，这是一种使用通用机器学习（ML）算法进行同步学习和评估的通用且有效的方法。在批量数据的单次传递中，所提出的方法重复训练机器学习算法并测试其经验性能。因为它利用整个样本来进行学习和评估，所以临时抱佛脚比样本分割的数据效率要高得多。补习方法也自然地适应了在线学习算法，使其实现计算效率高。为了证明临时抱佛脚方法的威力，我们考虑了标准的策略学习设置，其中临时抱佛脚应用于相同的数据，以制定个性化治疗规则（ITR）并估计部署学习的 ITR 时会产生的平均结果。我们证明，在最小的假设集下，所得的填充评估估计量是一致的且渐近正态的。虽然我们的渐近结果需要 ML 算法相对较弱的稳定条件，但我们开发了一种简单、通用的方法，可以与任何策略学习算法一起使用来满足此条件。我们广泛的模拟研究表明，与样本分割相比，临时抱佛脚将评估标准误差降低了 40% 以上，同时提高了学习策略的性能。我们还将补习方法应用于随机临床试验，以证明其对现实问题的适用性。最后，我们简要讨论了临时补习方法在其他学习和评估环境中的未来扩展。]]></description>
      <guid>https://arxiv.org/abs/2403.07031</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>论价值函数的有限表征力及其与统计（内）效率的联系</title>
      <link>https://arxiv.org/abs/2403.07136</link>
      <description><![CDATA[arXiv:2403.07136v1 公告类型：交叉
摘要：确定基于模型和无模型方法之间的权衡是强化学习的核心问题。基于值的方法提供了巨大的计算优势，有时与基于模型的方法在统计上同样有效。然而，关注政策评估的核心问题，我们发现有关转型动态的信息可能无法在价值函数空间中表示。我们通过一系列针对许多重要问题中出现的结构的案例研究来探讨这一点。在某些情况下，不存在信息丢失，并且基于价值的方法与基于模型的方法在统计上一样有效。在其他密切相关的示例中，信息丢失很严重，并且基于价值的方法的性能严重落后。更深入的调查指出，代表性能力的局限性是低效率的驱动因素，而不是算法设计的失败。]]></description>
      <guid>https://arxiv.org/abs/2403.07136</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>CAS：一种具有 FCR 控制的在线选择性共形预测通用算法</title>
      <link>https://arxiv.org/abs/2403.07728</link>
      <description><![CDATA[arXiv:2403.07728v1 公告类型：新
摘要：我们以在线方式研究选择后预测推理问题。为了避免将资源投入到不重要的单位，在报告其预测区间之前对当前个体进行初步选择在在线预测任务中是常见且有意义的。由于在线选择会导致所选预测区间的时间多重性，因此控制实时错误覆盖率（FCR）以测量平均错误覆盖误差非常重要。我们开发了一个名为 CAS（自适应选择后校准）的通用框架，它可以包装任何预测模型和在线选择规则以输出选择后预测间隔。如果选择了当前个体，我们首先对历史数据进行自适应选择以构建校准集，然后为未观察到的标签输出共形预测区间。我们为流行的在线选择规则的校准集提供易于处理的结构。我们证明了 CAS 可以在有限样本和无分布的情况下实现精确的选择条件覆盖保证。对于决策驱动的选择规则，包括大多数在线多重测试程序，CAS 可以精确地将实时 FCR 控制在目标水平以下，而无需任何分布假设。对于具有对称阈值的在线选择，我们在温和的分布假设下建立了 FCR 控制间隙的误差界限。为了解释在线数据的分布变化，我们还将 CAS 嵌入到一些最近的动态保角预测方法中，并检查长期 FCR 控制。合成数据和真实数据的数值结果证实，CAS 可以有效地将 FCR 控制在目标水平附近，并在各种设置下的现有基线上产生更窄的预测区间。]]></description>
      <guid>https://arxiv.org/abs/2403.07728</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>概率简单变分因果效应</title>
      <link>https://arxiv.org/abs/2403.07745</link>
      <description><![CDATA[arXiv:2403.07745v1 公告类型：新
摘要：设$X$和$Z$为随机向量，且$Y=g(X,Z)$。在本文中，一方面，对于$X$和$Z$连续的情况，利用总变差和$g$通量的思想，我们提出了一种因果推理的观点，能够处理广泛的因果问题。事实上，我们关注的是一个称为概率简单变分因果效应（PEACE）的函数，它可以衡量 $X$ 对 $Y$ 的直接因果效应，即连续地、干预性地改变 $X$ 的值，同时保持该值$Z$ 常数。 PEACE 是 $d\ge 0$ 的函数，它是管理概率密度值 $f(x|z)$ 强度的程度。另一方面，我们将上述思想推广到离散情况，并表明其与连续情况的兼容性。此外，我们使用测量理论概念研究了 PEACE 的一些属性。此外，我们提供了一些可识别性标准和几个例子来展示 PEACE 的通用能力。我们注意到，PEACE 可以处理输入变量值的微观层面或宏观层面的变化很重要的因果问题。最后，在 $\partial g_{in}/\partial x$ 以及 $X$ 和 $Z$ 的联合分布发生微小变化的情况下，PEACE 是稳定的，其中 $g_{in}$ 是通过删除所有 $g$ 得到的定义$X$和$Z$的函数关系。]]></description>
      <guid>https://arxiv.org/abs/2403.07745</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>FairRR：通过随机响应进行群体公平性预处理</title>
      <link>https://arxiv.org/abs/2403.07780</link>
      <description><![CDATA[arXiv:2403.07780v1 公告类型：新
摘要：机器学习模型在后续决策过程中越来越多的使用激发了对这些系统公平性的研究。尽管在处理过程中和处理后设置中的群体公平性研究方面已经做了大量工作，但从理论上将这些结果与预处理领域联系起来却很少。本文提出，在下游模型中实现群体公平可以表述为寻找最优设计矩阵，在随机响应框架中修改响应变量。我们证明了可以通过最佳模型效用直接控制群体公平性的度量，并提出了一种称为 FairRR 的预处理算法，该算法产生出色的下游模型效用和公平性。]]></description>
      <guid>https://arxiv.org/abs/2403.07780</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>跨多个主成分分析研究的知识转移</title>
      <link>https://arxiv.org/abs/2403.07431</link>
      <description><![CDATA[arXiv:2403.07431v1 公告类型：新
摘要：迁移学习引起了统计界的极大兴趣。在本文中，我们重点关注与文献中的监督学习任务相比的无监督学习任务的知识迁移。考虑到可迁移的源群体，我们提出了一种两步迁移学习算法，从多个源主成分分析（PCA）研究中提取有用的信息，从而提高目标 PCA 任务的估计准确性。第一步，我们通过一种名为 Grassmannian barycenter 的方法整合多个研究中的共享子空间信息，而不是直接对池数据集执行 PCA。所提出的格拉斯曼重心方法在更一般的情况下具有鲁棒性和计算优势。然后，进一步利用第一步得到的共享子空间估计器来估计第二步中的目标私有子空间。我们的理论分析将 PCA 研究之间的知识迁移归功于扩大的特征值差距，这与稀疏性起核心作用的现有监督迁移学习任务不同。此外，我们证明了经验光谱投影仪的双线性形式在知识转移后在较弱的特征值间隙条件下具有渐近正态性。当信息源集未知时，我们通过解决格拉斯曼流形上的修正优化问题，赋予我们的算法选择有用数据集的能力，这反过来又导致计算友好的修正格拉斯曼 K 均值过程。最后，报告了广泛的数值模拟结果和有关活动识别的真实数据案例，以支持我们的理论主张并说明所提出的迁移学习方法的经验有用性。]]></description>
      <guid>https://arxiv.org/abs/2403.07431</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>使用高斯局部线性映射进行快速、准确和轻量级的基于顺序模拟的推理</title>
      <link>https://arxiv.org/abs/2403.07454</link>
      <description><![CDATA[arXiv:2403.07454v1 公告类型：新
摘要：可以使用对计算机模拟器执行多次调用的算法来解决具有棘手可能性的复杂模型的贝叶斯推理。这些方法统称为“基于模拟的推理”（SBI）。最近的 SBI 方法利用神经网络 (NN) 为不可用的似然函数和后验分布提供近似但富有表现力的构造。然而，它们通常无法实现准确性和计算需求之间的最佳权衡。在这项工作中，我们提出了一种替代方案，使用概率分布的结构化混合来提供似然分布和后验分布的近似值。与最先进的基于神经网络的 SBI 方法相比，我们的方法可以产生准确的后验推理，同时计算量要小得多。我们在 SBI 文献中的几个基准模型上展示了我们的结果。]]></description>
      <guid>https://arxiv.org/abs/2403.07454</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>关于机器学习中一些前推约束的非凸性及其后果</title>
      <link>https://arxiv.org/abs/2403.07471</link>
      <description><![CDATA[arXiv:2403.07471v1 公告类型：新
摘要：前推操作使人们能够通过确定性映射重新分配概率度量。它在统计和优化中发挥着关键作用：许多学习问题（特别是来自最优传输、生成建模和算法公平性）包括作为模型的前推条件的约束或惩罚。然而，文献缺乏对此类约束的（非）凸性及其对相关学习问题的影响的一般理论见解。本文旨在填补这一空白。在第一部分中，我们为两组函数的（非）凸性提供了一系列充分必要条件：将一个概率度量传输到另一个概率度量的映射；这些地图在不同的概率测量中产生相等的输出分布。这凸显了对于大多数概率度量，这些前推约束不是凸的。第二次，我们展示了这个结果如何暗示学习生成模型或群体公平预测器的凸优化问题设计的关键限制。这项工作有望帮助研究人员和实践者更好地理解前推条件对凸性的关键影响。]]></description>
      <guid>https://arxiv.org/abs/2403.07471</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>近插值器：快速规范增长以及插值与泛化之间的权衡</title>
      <link>https://arxiv.org/abs/2403.07264</link>
      <description><![CDATA[arXiv:2403.07264v1 公告类型：新
摘要：我们研究了近插值线性回归器的泛化能力：$\boldsymbol{\beta}$，其训练误差 $\tau$ 为正但很小，即低于本底噪声。在数据分布的随机矩阵理论假设和数据协方差矩阵 $\boldsymbol{\Sigma}$ 的特征衰减假设下，我们证明任何近插值器都表现出快速的范数增长：对于 $\tau$ 固定，$\boldsymbol {\beta}$ 已平方 $\ell_2$-范数 $\mathbb{E}[\|{\boldsymbol{\beta}}\|_{2}^{2}] = \Omega(n^{\alpha })$ 其中 $n$ 是样本数，$\alpha &gt;1$ 是特征衰减的指数，即 $\lambda_i(\boldsymbol{\Sigma}) \sim i^{-\alpha}$。这意味着现有的与数据无关的基于规范的界限必然是宽松的。另一方面，在同一体系中，我们精确地描述了插值和泛化之间的渐近权衡。我们的表征表明，较大的范数缩放指数 $\alpha$ 对应于插值和泛化之间更差的权衡。我们凭经验验证，类似的现象也适用于近插值浅层神经网络。]]></description>
      <guid>https://arxiv.org/abs/2403.07264</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>提升少数派比例如何影响泛化？单隐层神经网络解决群体不平衡问题的理论研究</title>
      <link>https://arxiv.org/abs/2403.07310</link>
      <description><![CDATA[arXiv:2403.07310v1 公告类型：新
摘要：群体不平衡一直是经验风险最小化（ERM）中的一个已知问题，其中实现的高平均准确率伴随着少数群体的低准确率。尽管算法努力提高少数群体的准确性，但 ERM 对各个群体的理论概括分析仍然难以实现。通过用高斯混合模型来表述群体不平衡问题，本文量化了各个群体对样本复杂度、收敛速度以及平均和群体水平测试性能的影响。尽管我们的理论框架以使用单隐藏层神经网络的二元分类为中心，但据我们所知，除了普遍研究的平均泛化性能之外，我们还首次提供了 ERM 组级泛化的理论分析。我们的理论结果的样本见解包括，当所有组级协方差都处于中等状态且所有均值接近于零时，从样本复杂度小、训练速率快和较高的平均和团体水平测试精度。此外，我们表明，增加训练数据中少数群体的比例并不一定会提高少数群体的泛化性能。我们的理论结果在合成数据集和经验数据集上得到了验证，例如图像分类中的 CelebA 和 CIFAR-10。]]></description>
      <guid>https://arxiv.org/abs/2403.07310</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>使用理论上最佳滑动窗口方法跟踪动态高斯密度</title>
      <link>https://arxiv.org/abs/2403.07207</link>
      <description><![CDATA[arXiv:2403.07207v1 公告类型：新
摘要：动态密度估计在许多应用中普遍存在，包括计算机视觉和信号处理。解决这个问题的一种流行方法是“滑动窗口”核密度估计器。该方法存在各种使用启发式定义的权重序列来观察数据的实现。然而，权重序列是估计器的一个关键方面，显着影响跟踪性能。在这项工作中，我们研究了用于演化高斯密度的“滑动窗口”高斯核密度估计器的精确平均积分平方误差（MISE）。我们通过理论上描述精确的 MISE 来提供选择最佳权重序列的原则性指南，该 MISE 可以表示为约束二次规划。我们通过合成数据集提供了经验证据，以表明与启发式方法相比，我们的加权方案确实提高了跟踪性能。]]></description>
      <guid>https://arxiv.org/abs/2403.07207</guid>
      <pubDate>Wed, 13 Mar 2024 06:16:59 GMT</pubDate>
    </item>
    </channel>
</rss>