<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Tue, 28 Nov 2023 03:14:06 GMT</lastBuildDate>
    <item>
      <title>通过深度学习中几何适应的梯度下降，确定性地实现全局 $\mathcal{L}^2$ 最小化。 （arXiv：2311.15487v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.15487</link>
      <description><![CDATA[我们认为梯度下降流广泛用于最小化
深度学习网络中的$\mathcal{L}^2$成本函数，并引入两个
修改版本；一个适用于过参数化设置，另一个适用于
对于参数不足的设置。两者都有明确且自然的不变量
几何意义，考虑回拉向量丛结构
过参数化和前推向量束结构
参数不足的设置。在过度参数化的情况下，我们证明，
假设等级条件成立，则修改梯度的所有轨道
下降将 $\mathcal{L}^2$ 成本以统一的方式驱动至全局最小值
指数收敛速度。我们指出后者与
亚黎曼几何。
]]></description>
      <guid>http://arxiv.org/abs/2311.15487</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:06 GMT</pubDate>
    </item>
    <item>
      <title>用于半约束聚类的 ConstraintMatch。 （arXiv：2311.15395v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.15395</link>
      <description><![CDATA[约束聚类允许使用以下方法训练分类模型
仅成对约束，其较弱并且相对容易挖掘，而
仍然产生全监督级别的模型性能。当他们表演时
即使没有真正的底层类标签，约束
聚类模型仍然需要大量的二元约束注释
为了训练。在本文中，我们提出了一种半监督环境，其中
大量的 \textit{unconstrained} 数据与较小的数据一起可用
一组约束，并建议 \textit{ConstraintMatch} 来利用此类
无约束数据。虽然已经取得了很大进展
使用全标签的半监督学习，存在很多挑战
防止在
基于约束的标签设置。因此，我们对这些问题进行推理和分析
挑战，特别是 1）提出 \textit{pseudo-constraining} 机制
克服确认偏差，这是伪标签的一个主要弱点，2)
开发新的伪标记方法以选择
\textit{信息丰富} 无约束样本，3) 表明这也允许
使用成对损失函数来计算初始损失和辅助损失
促进半约束模型训练。在大量的实验中，我们
证明 ConstraintMatch 在相关基线上的有效性
五个具有挑战性的常规聚类和过度聚类场景
基准并提供其几个组成部分的分析。
]]></description>
      <guid>http://arxiv.org/abs/2311.15395</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:05 GMT</pubDate>
    </item>
    <item>
      <title>将统计学习理论应用于深度学习。 （arXiv：2311.15404v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.15404</link>
      <description><![CDATA[虽然统计学习理论提供了一个强大的框架
了解监督学习、深度学习的许多理论方面
仍不清楚，特别是不同的架构如何导致感应
使用基于梯度的方法训练时出现偏差。这些讲座的目标是
概述尝试时出现的一些主要问题
从学习理论的角度理解深度学习。简短的介绍后
关于统计学习理论和随机优化的提醒，我们讨论
良性过度拟合背景下的隐性偏差。然后我们转向一般
镜像下降算法的描述，展示了我们如何返回并
在参数空间和相应的函数空间之间来回移动
给定的学习问题，以及学习问题的几何形状如何
由度量张量表示。在此框架的基础上，我们提供了
线性对角线上梯度下降隐式偏差的详细研究
用于各种回归任务的网络，显示损失函数、规模
网络初始化和深度时的参数可能会导致各种形式
隐式偏差，特别是内核或特征之间的转换
学习。
]]></description>
      <guid>http://arxiv.org/abs/2311.15404</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:05 GMT</pubDate>
    </item>
    <item>
      <title>一种近乎最优的低切换算法，用于具有通用函数逼近的强化学习。 （arXiv：2311.15238v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.15238</link>
      <description><![CDATA[探索-利用困境一直是一个核心挑战
具有复杂模型类的强化学习（RL）。在本文中，我们
提出一种新算法，Monotonic Q-Learning with Upper Confidence Bound
(MQL-UCB) 用于具有一般函数逼近的 RL。我们的关键算法
设计包括（1）一个通用的确定性策略切换策略，
实现低切换成本，（2）单调值函数结构
仔细控制函数类复杂性，以及（3）方差加权
利用高数据历史轨迹的回归方案
效率。 MQL-UCB 实现 $\tilde{O}(d\sqrt{HK})$ 的最小最大最优后悔
当 $K$ 足够大并且接近最优的策略转换成本时
$\tilde{O}(dH)$，其中$d$是函数类的逃避维数，$H$
是计划范围，$K$ 是集数。

我们的工作揭示了设计可证明样本效率和
具有非线性函数逼近的部署高效 Q 学习。
]]></description>
      <guid>http://arxiv.org/abs/2311.15238</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:04 GMT</pubDate>
    </item>
    <item>
      <title>高维偏微分方程随机平滑的物理信息神经网络中的偏差-方差权衡。 （arXiv：2311.15283v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.15283</link>
      <description><![CDATA[虽然物理信息神经网络 (PINN) 已被证明对于
低维偏微分方程（PDE），计算成本
在高维场景中仍然是一个障碍。这个特别明显
当计算高阶和高维导数时
物理信息损失。随机平滑 PINN (RS-PINN) 引入高斯
原始神经网络模型的随机平滑噪声，使蒙特
用于导数近似的卡洛方法，无需昂贵的
自动分化。尽管它在高维上的计算效率很高，
RS-PINN 在损失和梯度方面引入了偏差，产生了负面影响
收敛，尤其是与随机梯度下降（SGD）结合使用时。我们
对 RS-PINN 中的偏差进行了全面分析，将其归因于
均方误差 (MSE) 损失的非线性和 PDE 非线性。我们
提出基于偏微分方程阶数的定制偏差校正技术
非线性。无偏见的 RS-PINN 允许对其进行详细检查
与有偏见的版本相比的优点和缺点。具体来说，有偏见的版本
与无偏版本相比，方差更低，运行速度更快，但也更少
由于偏差而准确。为了优化偏差-方差权衡，我们结合
混合方法中的两种方法平衡了快速收敛
有偏差版本具有无偏差版本的高精度。此外，
我们提出了 RS-PINN 的增强实现。广泛的实验
各种高维偏微分方程，包括 Fokker-Planck、HJB、viscosous Burgers&#39;、
Allen-Cahn 和 Sine-Gordon 方程说明了偏差与方差的权衡
并强调混合 RS-PINN 的有效性。经验指导方针是
提供用于选择有偏、无偏或混合版本，具体取决于
特定偏微分方程问题的维数和非线性。
]]></description>
      <guid>http://arxiv.org/abs/2311.15283</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:04 GMT</pubDate>
    </item>
    <item>
      <title>鲁棒且自动的数据聚类：狄利克雷过程满足均值中值。 （arXiv：2311.15384v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2311.15384</link>
      <description><![CDATA[集群是领域内最突出的挑战之一
无监督机器学习。基于质心的聚类数组之中
算法，经典的 $k$-means 算法，植根于劳埃德启发式，采用
成为文学中广泛采用的技术之一。
尽管如此，$k$-means 及其变体都面临着值得注意的问题
限制。这些包括对初始簇质心的严重依赖，
收敛到目标函数局部最小值的敏感性，以及
对数据中的异常值和噪声的敏感性。当面对数据时
包含噪声或异常值的观测值，均值中位数 (MoM)
估计器成为任何基于质心的聚类的稳定力量
框架。另一方面，现有的一个普遍的限制
聚类方法取决于对数量的先决知识
分析之前的聚类。利用基于模型的方法，例如
贝叶斯非参数模型，提供无限混合模型的优点，
从而规避了此类要求的需要。受这些事实的推动，
在本文中，我们提出了一种高效且自动的聚类技术
整合基于模型和基于质心的方法的原理
减轻噪声对聚类质量的影响，同时确保
不需要提前指定簇的数量。统计保证
聚类误差的上限，并通过严格评估
模拟和真实数据集表明我们提出的方法相对于
现有最先进的聚类算法。
]]></description>
      <guid>http://arxiv.org/abs/2311.15384</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:04 GMT</pubDate>
    </item>
    <item>
      <title>随机黑盒模拟器的多保真度约束优化。 （arXiv：2311.15137v1 [数学.OC]）</title>
      <link>http://arxiv.org/abs/2311.15137</link>
      <description><![CDATA[模拟器参数的约束优化至关重要
在设计过程中的作用。当模拟器
是随机的，计算量大，参数空间为
高维。只需利用
相对于参数的梯度，但这些梯度是
在许多遗留的黑盒代码中不可用。我们介绍一下算法
Scout-Nd（N 维随机约束优化）来解决
通过有效估计梯度来解决前面提到的问题，减少
梯度估计器的噪声，并应用多保真度方案进一步
减少计算工作量。我们在标准基准上验证我们的方法，
展示其在优化参数方面的有效性，更好地突出显示
与现有方法相比的性能。
]]></description>
      <guid>http://arxiv.org/abs/2311.15137</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:03 GMT</pubDate>
    </item>
    <item>
      <title>有限样本下相位检索的局部景观。 （arXiv：2311.15221v1 [cs.IT]）</title>
      <link>http://arxiv.org/abs/2311.15221</link>
      <description><![CDATA[在本文中，我们对当地的景观进行了细粒度的分析。
有限样本条件下的相位检索。我们的目标是确定
保证良性当地景观所需的最小样本量
围绕高维度的全局最小值。让 $n$ 和 $d$ 表示样本
分别是尺寸和输入尺寸。我们首先探索局部凸性
并确定当 $n=o(d\log d)$ 时，对于
局部球，只要 $d$ 为，Hessian 矩阵就必须具有负特征值
足够大。因此，局部景观是高度非凸的。我们
接下来考虑一点强凸性并证明只要
$n=\omega(d)$，景观有很大概率是单点强
局部环面凸：$\{w\in\mathbb{R}^d: o_d(1)\leqslant
\|w-w^*\|\leqslant c\}$，其中 $w^*$ 是基本事实，$c$ 是绝对值
持续的。这意味着梯度下降从该点中的任何点初始化
域可以以指数速度收敛到 $o_d(1)$-loss 解。
此外，我们证明当 $n=o(d\log d)$ 时，半径为
$\widetilde\Theta\left(\sqrt{1/d}\right)$ 使得单点凸性破裂
在相应的较小的局部球中。这表明不可能
在有限的条件下建立精确的 $w^*$ 梯度下降收敛
仅依靠单点凸性进行采样。
]]></description>
      <guid>http://arxiv.org/abs/2311.15221</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:03 GMT</pubDate>
    </item>
    <item>
      <title>图上非线性耦合振荡器的潜在线性模型。 （arXiv：2311.14910v1 [数学.DS]）</title>
      <link>http://arxiv.org/abs/2311.14910</link>
      <description><![CDATA[任意图上的耦合振荡器系统由以下项局部驱动
附近振荡器之间相互同步的趋势，但可以和
通常在整个图上表现出非线性行为。了解这样的
非线性行为一直是预测是否所有
这种系统中的振荡器最终将同步。在本文中，我们
令人惊讶的是，证明了耦合振荡器的这种非线性行为
可以在某些潜在的动态空间中有效地线性化。关键洞察
是存在少量的“潜在动态过滤器”，每个过滤器都有一个
与同步和非同步动态的特定关联
子图，以便子图上任何观察到的动态都可以近似为
这种基本动态模式的适当线性组合。采取
子图级预测的集合提供了一个可解释的预测器
整个图上的系统是否达到全局同步。我们
提出基于监督矩阵分解的算法来学习这样的
潜在的动态过滤器。我们证明我们的方法具有竞争力
在针对基线和黑盒的同步预测任务中
分类算法，尽管其架构简单且可解释。
]]></description>
      <guid>http://arxiv.org/abs/2311.14910</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:02 GMT</pubDate>
    </item>
    <item>
      <title>通过循环神经网络进行变点检测的选择性推理。 （arXiv：2311.14964v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2311.14964</link>
      <description><![CDATA[在这项研究中，我们调查了统计数据的量化
使用循环检测时间序列中检测到的变化点 (CP) 的可靠性
神经网络（RNN）。由于其灵活性，RNN 有潜力
有效地识别具有复杂动态特征的时间序列中的CP。
然而，错误检测随机噪声的风险增加
作为 CP 的波动。本研究的主要目的是严格控制
通过向
RNN 检测到的 CP。为了实现这一目标，我们引入了一种基于
选择性推理（SI）的框架。 SI 通过以下方式实现有效推论
以假设选择事件为条件，从而减轻选择
偏见。在本研究中，我们将 SI 框架应用于基于 RNN 的 CP 检测，其中
表征RNN选择CP的复杂过程是我们的主要技术
挑战。我们证明了所提出方法的有效性和有效性
通过人工和真实数据实验。
]]></description>
      <guid>http://arxiv.org/abs/2311.14964</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:02 GMT</pubDate>
    </item>
    <item>
      <title>带热身的动量梯度下降中的大型弹射器：实证研究。 （arXiv：2311.15051v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.15051</link>
      <description><![CDATA[虽然动量梯度下降在现代深度学习中被广泛使用
学习，具体了解其对训练轨迹的影响
仍然难以捉摸。在这项工作中，我们凭经验证明动量梯度
具有较大学习率的下降和学习率预热显示较大
弹射器，将迭代推向比发现的更平坦的最小值
梯度下降。然后我们提供经验证据和理论直觉
大型弹射器是由动量“放大”引起的
自稳定效应（Damian 等人，2023）。
]]></description>
      <guid>http://arxiv.org/abs/2311.15051</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:02 GMT</pubDate>
    </item>
    <item>
      <title>深度潜在力模型：用于贝叶斯深度学习的基于 ODE 的过程卷积。 （arXiv：2311.14828v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2311.14828</link>
      <description><![CDATA[对高度非线性动力系统中存在的现象进行有效建模
同时准确量化不确定性也是一项具有挑战性的任务，
通常需要针对特定​​问题的技术。我们概述了深层的潜在力量
模型（DLFM），一种解决这个问题的与领域无关的方法，
由深度高斯过程架构组成，其中每层的内核
使用以下框架从常微分方程导出
处理卷积。提出了两种不同的 DLFM 公式：
利用权重空间和基于变分诱导点的高斯过程
近似值，两者都适用于双随机变分
推理。我们提供的证据表明我们的模型能够高度捕获
现实世界多元时间序列数据中的非线性行为。此外，
我们发现我们的方法取得了与许多其他方法相当的性能
基准回归任务的概率模型。我们还根据经验评估
诱导点框架对外推法的负面影响
基于 LFM 的模型的功能。
]]></description>
      <guid>http://arxiv.org/abs/2311.14828</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:01 GMT</pubDate>
    </item>
    <item>
      <title>通过局部曲率轮廓进行有效的结构编码。 （arXiv：2311.14864v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.14864</link>
      <description><![CDATA[结构和位置编码可以显着提高性能
图神经网络在下游任务中的应用。最近的文献已经开始
系统地研究这些结构特性的差异
方法编码，以及它们之间的性能权衡。但是，那
哪些结构特性产生最有效的编码的问题
保持开放。在本文中，我们从几何角度研究这个问题
看法。我们提出了一种基于离散 Ricci 的新型结构编码
曲率（局部曲率剖面，短 LCP）并表明它显着
优于现有的编码方法。我们进一步表明，结合本地
具有全局位置编码的结构编码（例如 LCP）得到了改进
下游性能，表明它们捕获了互补的几何
信息。最后，我们比较不同的编码类型
（基于曲率的）重新布线技术。最近重新布线激增
由于它能够提高图神经网络的性能而受到关注
通过减轻过度平滑和过度挤压效应来建立网络。我们的成果
建议利用曲率信息进行结构编码
与重新布线相比，性能提升显着更大。
]]></description>
      <guid>http://arxiv.org/abs/2311.14864</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:01 GMT</pubDate>
    </item>
    <item>
      <title>差异隐私中特定于实例的非对称敏感性。 （arXiv：2311.14681v1 [cs.DS]）</title>
      <link>http://arxiv.org/abs/2311.14681</link>
      <description><![CDATA[我们为差分隐私估计提供了一个新的算法框架
适应底层数据集硬度的通用函数。我们
建立在以前的工作的基础上，该工作提供了通过以下方式选择输出的范例
基于逆向底层的接近度的指数机制
数据集，称为逆敏感性机制。我们的框架会稍微
修改紧密度度量并提供一个简单高效的应用程序
稀疏向量技术。而逆敏感性机制是
被证明是实例最优的，它只是相对于一类无偏的
使最可能的结果与基础数据相匹配的机制。我们
打破这个假设以便更自然地驾驭偏差方差
权衡，这也将至关重要地允许将我们的方法扩展到
无界数据。考虑到这种权衡，我们提供了强烈的直觉
经验验证我们的技术在以下情况下将特别有效
到基础数据集的距离是不对称的。这种不对称性是
一系列重要问题所固有的，包括基本统计数据，例如
作为方差，以及常用的机器学习性能指标
分类和回归任务。我们有效地实例化我们的方法
在 $O(n)$ 时间内解决这些问题并根据经验表明我们的技术将
给出显着改进的差分私人估计。
]]></description>
      <guid>http://arxiv.org/abs/2311.14681</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习预测加密货币价格：集成金融、区块链和文本数据。 （arXiv：2311.14759v1 [q-fin.ST]）</title>
      <link>http://arxiv.org/abs/2311.14759</link>
      <description><![CDATA[本文探讨了机器学习（ML）和自然的应用
加密货币价格预测中的语言处理（NLP）技术，
特别是比特币（BTC）和以太坊（ETH）。专注于新闻和社交
媒体数据，主要来自 Twitter 和 Reddit，我们分析了
使用高级深度学习 NLP 评估公众对加密货币估值的看法
方法。除了传统的价格回归之外，我们还处理加密货币价格
预测作为一个分类问题。这包括预测
价格变动（向上或向下）和局部极值的识别。我们
比较各种 ML 模型（有或没有 NLP 数据）的性能
一体化。我们的研究结果表明，结合 NLP 数据可以显着
增强我们模型的预测性能。我们发现
预训练模型，例如 Twitter-RoBERTa 和 BART MNLI，非常有效
捕捉市场情绪，并对大型语言模型进行微调
（法学硕士）也带来了显着的预测改进。值得注意的是，BART MNLI
零样本分类模型在提取方面表现出相当高的熟练度
来自文本数据的看涨和看跌信号。我们所有的型号都一致
在不同的验证场景中产生利润，没有观察到下降
随着时间的推移，利润或 NLP 数据的影响会减少。研究
强调文本分析在改善财务预测和
展示了各种 NLP 技术在捕捉细微差别方面的有效性
市场情绪。
]]></description>
      <guid>http://arxiv.org/abs/2311.14759</guid>
      <pubDate>Tue, 28 Nov 2023 03:14:00 GMT</pubDate>
    </item>
    </channel>
</rss>