<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 12 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>高斯混合块模型中的谱聚类</title>
      <link>https://arxiv.org/abs/2305.00979</link>
      <description><![CDATA[arXiv:2305.00979v3 公告类型：替换
摘要：高斯混合块模型是图上的分布，致力于对现代网络进行建模：为了从这样的模型生成图，我们将每个顶点 $i$ 与潜在特征向量 $u_i \in \mathbb{R}^d$ 相关联从高斯混合中采样，当且仅当特征向量足够相似时，我们添加边缘 $(i,j)$，其中 $\langle u_i,u_j \rangle \ge \tau$ 对于预先指定的阈值$\tau$。高斯混合的不同分量代表了这样一个事实：可能存在具有不同特征分布的不同类型的节点——例如，在社交网络中，每个分量代表不同社区的不同属性。与这些网络相关的自然算法任务是嵌入（恢复潜在特征向量）和聚类（按混合分量对节点进行分组）。
  在本文中，我们发起了对从高维高斯混合块模型采样的聚类和嵌入图的研究，其中潜在特征向量$d\to\infty$的维度作为网络$n\to\infty$的大小。这种高维设置最适合现代网络的背景，在现代网络中，我们认为潜在特征空间是高维的。我们分析了在 2 分量球形高斯混合的情况下此类图的规范谱聚类和嵌入算法的性能，并开始勾勒出这些模型中聚类和嵌入的信息计算景观。]]></description>
      <guid>https://arxiv.org/abs/2305.00979</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>Grokking 作为从懒惰到丰富训练动态的过渡</title>
      <link>https://arxiv.org/abs/2310.06110</link>
      <description><![CDATA[arXiv:2310.06110v3 公告类型：替换
摘要：我们提出，神经网络的训练损失比测试损失早得多减少的“grokking”现象可能是由于神经网络从惰性训练动态过渡到丰富的特征学习机制而出现的。为了说明这种机制，我们研究了两层神经网络多项式回归问题上普通梯度下降的简单设置，该网络在没有正则化的情况下以现有理论无法解释的方式表现出grokking。我们为此类网络的测试损失确定了足够的统计数据，并且跟踪这些过度训练表明，当网络首先尝试用其初始特征拟合内核回归解决方案，然后进行后期特征学习时，在这种设置中就会出现 grokking 。在列车损失已经很低之后，就确定了泛化解决方案。我们发现，grokking 的关键决定因素是特征学习的速率（可以通过缩放网络输出的参数精确控制）以及初始特征与目标函数 $y(x)$ 的对齐。我们认为，当 (1) 初始神经正切核的顶部特征向量和任务标签 $y(x)$ 未对齐，但 (2) 数据集大小足够大，使得网络可以进行时，就会出现这种延迟泛化最终进行概括，但不要太大，以至于训练损失完美地跟踪所有时期的测试损失，并且（3）网络开始在惰性状态下进行训练，因此不会立即学习特征。我们得出的结论是，从惰性（线性模型）到丰富训练（特征学习）的转变可以在更一般的环境中控制 grokking，例如 MNIST、单层 Transformer 和学生-教师网络。]]></description>
      <guid>https://arxiv.org/abs/2310.06110</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>二次预测误差方法的速率最优非渐进</title>
      <link>https://arxiv.org/abs/2404.07937</link>
      <description><![CDATA[arXiv:2404.07937v1 公告类型：交叉
摘要：我们研究了满足特定可识别性条件的一类时变参数预测模型的二次预测误差方法，即非线性最小二乘法。虽然已知该方法可以渐近地实现各种问题的最优速率，但在选定的少数（通常是线性）模型类之外，还没有与这些最优速率相匹配的非渐近结果。通过利用依赖数据学习的现代工具，我们为非线性参数化模型类的更一般设置提供了该方法的第一个速率最优非渐近分析。此外，我们表明我们的结果可以应用于特定类别的可识别自回归移动平均（ARMA）模型，从而产生用于识别 ARMA 模型的第一个最佳非渐近率。]]></description>
      <guid>https://arxiv.org/abs/2404.07937</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>用于时间固定和时间相关预测变量的随机森林：DynForest R 包</title>
      <link>https://arxiv.org/abs/2302.02670</link>
      <description><![CDATA[arXiv:2302.02670v2 公告类型：替换
摘要：R 包 DynForest 实现了随机森林，用于基于时间固定和时间相关的预测因子来预测连续、分类或（多原因）事件时间结果。 DynForest 的主要独创性在于它处理时间相关的预测变量，这些预测变量可以是内生的（即受结果过程的影响）、带有误差的测量并在特定主题的时间进行测量。在树构建过程的每个递归步骤中，与时间相关的预测变量在内部被总结为可以进行分割的单独特征。这是通过使用灵活的线性混合模型（得益于 R 包 lcmm）来实现的，该模型的规格由用户预先指定。 DynForest 返回连续结果的平均值、对分类结果进行多数投票的类别或随时间推移的生存结果的累积发生率函数。 DynForest 还计算变量重要性和最小深度，以告知最具预测性的变量或变量组。本文旨在通过分步示例指导用户使用 DynForest 拟合随机森林。]]></description>
      <guid>https://arxiv.org/abs/2302.02670</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>表演是不够的：罗生门四重奏讲述的故事</title>
      <link>https://arxiv.org/abs/2302.13356</link>
      <description><![CDATA[arXiv:2302.13356v4 公告类型：替换
摘要：监督学习的通常目标是找到最佳模型，即优化特定性能指标的模型。然而，如果该模型提供的解释与另一个模型完全不同，并且与另一个模型再次不同，尽管所有模型都具有相似的良好拟合统计量，该怎么办？同样有效的模型是否有可能将焦点放在数据中的不同关系上？受 Anscombe 四重奏的启发，本文引入了 Rashomon 四重奏，即基于合成数据集构建的一组四个模型，这些模型具有几乎相同的预测性能。然而，视觉探索揭示了对数据中关系的不同解释。这个说明性示例旨在鼓励使用模型可视化方法来比较预测模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2302.13356</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>使用多项分布对样本分区进行质量检查</title>
      <link>https://arxiv.org/abs/2404.07778</link>
      <description><![CDATA[arXiv:2404.07778v1 公告类型：交叉
摘要：在本文中，我们提出了一种新颖的方法，用于检查将样本划分为几个不同类别的聚类质量，从而确定所提供数据集的真实聚类数量的未知值。我们的目标引导我们开发一种方法，通过将多项分布应用于聚集在一个组中的数据成员与其各自的集群代表的距离。该过程是针对每个集群独立执行的，并将相关统计数据组合在一起以设计我们的有针对性的措施。各个簇分别拥有对应于簇中其成员相对于典型成员的不同位置的类别概率，以簇质心、中心点或众数的形式，称为相应的簇代表。我们的方法是稳健的，因为它是无分布的，因为它的设计与基础样本的父分布无关。它满足了现有聚类准确性度量中罕见的令人垂涎的品质之一，即能够调查分配的样本是否拥有除所有成员组成的单个组之外的任何固有聚类。我们的测量方法概念简单，算法简单，运行时间快，性能好，用途广泛，通过广泛的模拟和多样化的案例研究证明了这一点，使其具有吸引力。]]></description>
      <guid>https://arxiv.org/abs/2404.07778</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>事后逆转：我们是否过早选择模型？</title>
      <link>https://arxiv.org/abs/2404.07815</link>
      <description><![CDATA[arXiv:2404.07815v1 公告类型：交叉
摘要：经过训练的模型通常由事后变换组成，例如温度缩放（TS）、集成和随机权重平均（SWA），以提高性能、鲁棒性、不确定性估计等。然而，此类变换通常仅在基础模型之后应用模型已经通过标准方式最终确定。在本文中，我们通过广泛的实证研究来挑战这种做法。特别是，我们展示了一种称为事后逆转的现象，即在应用这些事后变换后性能趋势发生逆转。这种现象在高噪声环境下尤为突出。例如，虽然基础模型在训练早期严重过度拟合，但传统集成和 SWA 都倾向于训练更多 epoch 的基础模型。事后逆转还可以抑制双重下降的出现，并减轻基础模型中测试损失和测试误差之间的不匹配。根据我们的发现，我们提出了事后选择，这是一种简单的技术，事后指标可以为模型开发决策提供信息，例如早期停止、检查点和更广泛的超参数选择。我们的实验分析涵盖卫星成像、语言建模、人口普查预测和社交网络分析等领域的现实世界视觉、语言、表格和图形数据集。在 LLM 指令调优数据集上，与朴素选择相比，事后选择可带来 &gt; 1.5 倍的 MMLU 改进。代码可在 https://github.com/rishabh-ranjan/post-hoc-reversal 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.07815</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>在有限的时间间隔内应用指导可以提高扩散模型中的样本和分布质量</title>
      <link>https://arxiv.org/abs/2404.07724</link>
      <description><![CDATA[arXiv:2404.07724v1 公告类型：交叉
摘要：引导是从图像生成扩散模型中提取最佳性能的关键技术。传统上，在图像的整个采样链中应用恒定的引导权重。我们表明，指导显然对链的开头（高噪音水平）有害，对末端（低噪音水平）基本上没有必要，并且只对中间有利。因此，我们将其限制在特定的噪声水平范围内，从而提高推理速度和结果质量。这种有限的指导区间显着提高了 ImageNet-512 中的记录 FID，从 1.81 提高到 1.40。我们证明，它在不同的采样器参数、网络架构和数据集（包括稳定扩散 XL 的大规模设置）中在数量和质量上都是有益的。因此，我们建议将指导间隔作为所有使用指导的扩散模型中的超参数。]]></description>
      <guid>https://arxiv.org/abs/2404.07724</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型概述：应用、引导生成、统计率和优化</title>
      <link>https://arxiv.org/abs/2404.07771</link>
      <description><![CDATA[arXiv:2404.07771v1 公告类型：交叉
摘要：扩散模型是一种强大且通用的生成人工智能技术，在计算机视觉、音频、强化学习和计算生物学领域取得了巨大成功。在这些应用中，扩散模型提供灵活的高维数据建模，并充当采样器，用于在任务所需属性的主动指导下生成新样本。尽管取得了显着的实证成功，但扩散模型的理论非常有限，可能会减慢进一步利用和改进扩散模型的原则性方法创新。在本文中，我们回顾了扩散模型的新兴应用，了解它们在各种控制下的样本生成。接下来，我们概述现有的扩散模型理论，涵盖其统计特性和采样能力。我们采用渐进式的例程，从无条件扩散模型开始，然后连接到有条件的对应模型。此外，我们回顾了通过条件扩散模型进行高维结构化优化的新途径，其中将搜索解决方案重新表述为条件采样问题并通过扩散模型来解决。最后，我们讨论扩散模型的未来方向。本文的目的是为激发扩散模型的前瞻性理论和方法提供全面的理论展示。]]></description>
      <guid>https://arxiv.org/abs/2404.07771</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>通过近似消息传递推断高维线性回归中的变化点</title>
      <link>https://arxiv.org/abs/2404.07864</link>
      <description><![CDATA[arXiv:2404.07864v1 公告类型：新
摘要：我们考虑在高维线性回归中定位变化点的问题。我们提出了一种近似消息传递（AMP）算法来估计信号和变化点位置。假设高斯协变量，我们在样本数量与信号维度成比例增长的极限内给出其估计性能的精确渐近特征。我们的算法可以定制以利用有关信号、噪声和变化点的任何先验信息。它还能够以有效可计算的近似后验分布的形式实现不确定性量化，我们精确地描述了其渐近形式。我们通过数值实验验证了我们的理论，并证明了我们的估计器在合成数据和图像上的良好性能。]]></description>
      <guid>https://arxiv.org/abs/2404.07864</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>von Mises-Fisher 分布的平均参数化解决方案</title>
      <link>https://arxiv.org/abs/2404.07358</link>
      <description><![CDATA[arXiv:2404.07358v1 公告类型：交叉
摘要：von Mises-Fisher 分布作为一个指数族，可以用其自然参数或平均参数来表示。然而不幸的是，根据其平均参数的分布的归一化函数不能以封闭形式获得，这限制了平均参数化的实用性并使最大似然估计更普遍地复杂化。我们推导出一个二阶常微分方程，其解产生平均参数归一化器及其前两个导数，以及族的方差函数。我们还提供微分方程解的封闭形式近似。这允许根据平均参数快速评估密度和自然参数。我们展示了使用 Bregman 聚类的混合 von Mises-Fisher 分布的主题建模应用。]]></description>
      <guid>https://arxiv.org/abs/2404.07358</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>具有自我对弈的差分隐私强化学习</title>
      <link>https://arxiv.org/abs/2404.07559</link>
      <description><![CDATA[arXiv:2404.07559v1 公告类型：交叉
摘要：我们研究了具有差分隐私（DP）约束的多智能体强化学习（多智能体 RL）问题。这是由涉及敏感数据的各种现实应用程序推动的，在这些应用程序中保护用户的私人信息至关重要。我们首先将联合DP（JDP）和本地DP（LDP）的定义扩展到两人零和情景马尔可夫博弈，这两个定义都确保了轨迹方面的隐私保护。然后，我们设计了一种基于乐观纳什值迭代和伯恩斯坦型奖金私有化的可证明有效的算法。当使用适当的隐私机制实例化时，该算法能够满足 JDP 和 LDP 要求。此外，对于 DP 的两种概念，我们的遗憾界限概括了单智能体 RL 情况下的最佳已知结果，而我们的遗憾也可以在没有隐私约束的情况下减少为多智能体 RL 的最佳已知结果。据我们所知，这些是理解多智能体强化学习中轨迹式隐私保护的第一批结果。]]></description>
      <guid>https://arxiv.org/abs/2404.07559</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>针对不平衡分类问题的稳健性能指标</title>
      <link>https://arxiv.org/abs/2404.07661</link>
      <description><![CDATA[arXiv:2404.07661v1 公告类型：新
摘要：我们表明，二元分类中既定的性能指标，例如 F 分数、杰卡德相似系数或马修斯相关系数（MCC），对于类别不平衡并不稳健，因为如果少数类别的比例倾向于到 $0$，这些指标下贝叶斯分类器的真阳性率 (TPR) 也趋于 $0$。因此，在不平衡的分类问题中，这些指标有利于忽略少数类的分类器。为了缓解这个问题，我们对 F 分数和 MCC 进行了稳健的修改，即使在严重不平衡的情况下，TPR 也远离 0$。我们以数字方式说明了模拟中以及信用违约数据集上各种绩效指标的行为。我们还讨论了 ROC 和精确召回曲线的联系，并就如何将它们的使用与性能指标结合起来提供建议。]]></description>
      <guid>https://arxiv.org/abs/2404.07661</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>超参数化多重线性回归作为超曲线拟合</title>
      <link>https://arxiv.org/abs/2404.07849</link>
      <description><![CDATA[arXiv:2404.07849v1 公告类型：新
摘要：论文表明，将固定效应多元线性回归模型应用于超参数化数据集相当于用单个标量参数参数化的超曲线来拟合数据。这种等价性允许采用以预测器为中心的方法，其中每个预测器都由所选参数的函数来描述。事实证明，即使存在违反模型假设的非线性依赖性，线性模型也能产生准确的预测。预测函数空间中的因变量和单项式基的参数化在这里应用于合成数据和实验数据。超曲线方法特别适合预测变量中存在噪声的问题的正则化，并且可用于从模型中删除噪声和“不正确”的预测变量。]]></description>
      <guid>https://arxiv.org/abs/2404.07849</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>用于高数据设置中基于模拟的推理的扩散后验采样</title>
      <link>https://arxiv.org/abs/2404.07593</link>
      <description><![CDATA[arXiv:2404.07593v1 公告类型：新
摘要：确定非线性模型的哪些参数可以最好地描述一组实验数据是科学中的一个基本问题，并且随着复杂的大规模模拟器（又称黑盒模拟器）的兴起，它最近获得了很大的关注。此类模型的可能性通常很棘手，这就是不能使用经典 MCMC 方法的原因。基于模拟的推理 (SBI) 在这种情况下脱颖而出，因为它只需要模拟数据集来训练能够逼近将输入参数与给定观察相关联的后验分布的深度生成模型。在这项工作中，我们考虑一种高数据扩展，其中可以使用多个观察值，并且希望利用它们的共享信息来更好地推断模型的参数。我们提出的方法是建立在蓬勃发展的基于分数的扩散文献的最新发展基础上的，使我们能够简单地使用来自根据个体观察训练的分数网络的信息来估计高数据后验分布。我们将我们的方法与最近提出的各种数值实验的竞争方法进行比较，并证明其在数值稳定性和计算成本方面的优越性。]]></description>
      <guid>https://arxiv.org/abs/2404.07593</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:23 GMT</pubDate>
    </item>
    </channel>
</rss>