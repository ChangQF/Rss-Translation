<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Fri, 11 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>SGD可以选择好渔民吗？自选择性偏见和以后的本地融合</title>
      <link>https://arxiv.org/abs/2504.07133</link>
      <description><![CDATA[ARXIV：2504.07133V1公告类型：新 
摘要：我们重新审查了$ k $ k $线性回归器具有自选择性偏置的$ d $尺寸，并具有最大选择标准，如Cherapanamjeri，daskalakis，iylyas和Zampetakis [cdiz23，stoc&#39;23]。我们的主要结果是$ \ operatorname {poly}（d，k，1/\ varepsilon） + {k}^{o（k）} $ time算法的算法，从而改善了[cdiz23]和[cdiz23]和[gm24，arxiv]的运行时间。我们通过提供第一种自我选择的局部收敛算法来实现这一目标，从而解决[CDIZ23]的主要开放问题。
  为了获得该算法，我们将自我选择减少到一个看似无关的统计问题，称为变形。当一个人不观察样品的确切值，而只有某些包含确切值的设置（样品空间的子集）时，就会发生变形。由于人类和算法的圆形，仪器的精度有限，并且在多代理系统中，因此在各种现实世界应用中的推论是在各种现实世界应用中产生的。
  我们减少对更高的水平是直观的，并且依赖于自选择性问题的几何形状，这使我们能够绕过先前的分析方法的局限性。为了证明其适用性，我们在另一个自选择标准下为线性回归提供了局部收敛算法，该算法与第二价格拍卖数据有关。此外，我们给出了第一个多项式时间局部收敛算法，用于从凸形分区产生的样品的粗高斯平均值估计。以前，由于Fotakis，Kalavasis，Kontonis和Tzamos [FKKT21，Colt&#39;21]，仅知道样品效率算法。]]></description>
      <guid>https://arxiv.org/abs/2504.07133</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM推理和AI代理的吞吐量 - 最佳调度算法</title>
      <link>https://arxiv.org/abs/2504.07347</link>
      <description><![CDATA[ARXIV：2504.07347V1公告类型：新 
摘要：随着对大语言模型（LLM）和AI代理的需求迅速增长，为有效的LLM推理进行优化的系统变得至关重要。尽管重大努力针对系统级工程，但通过数学建模和排队的角度探索了很少的努力。
  在本文中，我们旨在开发LLM推论的排队基础，弥合排队和LLM系统社区之间的差距。特别是，我们研究了LLM推理系统中的吞吐量方面。我们证明，大量的“支持工作”调度算法可以为单个请求和AI代理工作负载实现最大的吞吐量，从而强调“工作支持”作为实践中的关键设计原理。对现实世界系统的评估表明，Orca和Sarathi-Serve是最佳的，令人放心的从业者，而FastTransformer和Vanilla Vllm并不是最大的稳定，应谨慎使用。
  我们的结果强调了排队社区可以提供的重大好处在改善LLM推理系统并呼吁进行更多跨学科发展。]]></description>
      <guid>https://arxiv.org/abs/2504.07347</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于梯度的样品选择，以更快的贝叶斯优化</title>
      <link>https://arxiv.org/abs/2504.07742</link>
      <description><![CDATA[ARXIV：2504.07742V1公告类型：新 
摘要：贝叶斯优化（BO）是用于黑盒优化的有效技术。但是，由于计算高斯过程（GP）替代模型的立方复杂性，其适用性通常仅限于中等预算问题。在大型预算方案中，直接采用标准GP模型在计算时间和资源需求中面临重大挑战。在本文中，我们提出了一种新型方法，基于梯度的样品选择贝叶斯优化（GSSBO），以提高BO的计算效率。 GP模型是在选定的样本集而不是整个数据集上构建的。通过利用梯度信息来维持多样性和表示，选择这些样本。我们提供了基于梯度的样本选择策略的理论分析，并为我们提出的框架获得明确的sublitear后悔界限。关于合成和现实世界任务的广泛实验表明，我们的方法显着降低了BO中GP拟合的计算成本，同时保持优化性能与基线方法相当。]]></description>
      <guid>https://arxiv.org/abs/2504.07742</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在不完整数据上的等级一张量近似的性能</title>
      <link>https://arxiv.org/abs/2504.07818</link>
      <description><![CDATA[ARXIV：2504.07818V1公告类型：新 
摘要：当只有一部分$ \ varepsilon $的噪声观察可用时，我们对排名一张量的信号的估计感兴趣。我们表明，对此问题的研究可以简化为随机矩阵模型，该模型的光谱分析可访问重建性能。这些结果阐明了并指定通过删除其条目的随机部分的人工降低张量的记忆成本而引起的性能丧失。]]></description>
      <guid>https://arxiv.org/abs/2504.07818</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于MMD的平滑距离内核和在Wasserstein梯度流中的应用</title>
      <link>https://arxiv.org/abs/2504.07820</link>
      <description><![CDATA[ARXIV：2504.07820V1公告类型：新 
摘要：负距离内核$ k（x，y）：=  -  \ | x -y \ | $用于定义统计信息中最大平均差异（MMD），并在各种应用中导致有利的数值结果。特别是，用于处理高维内核总和从距离内核的简单无参数结构中获利的所谓切片技术。但是，由于其在$ x = y $中的非平滑度，大多数经典的理论结果，例如相应的MMD功能的Wasserstein梯度流不变。在本文中，我们提出了一个新的内核，该内核保持负距离内核的有利特性是有条件的正定确定订单确定性，其对无穷大和简单的切片结构几乎线性增加，但现在是Lipschitz可区分的。我们的构建基于绝对值函数的简单一维平滑过程，然后是Riemann-Liouville分数积分变换。数值结果表明，新内核的性能与梯度下降方法中的负距离内核相似，但现在具有理论保证。]]></description>
      <guid>https://arxiv.org/abs/2504.07820</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将可靠性验证限制嵌入一代扩展计划中</title>
      <link>https://arxiv.org/abs/2504.07131</link>
      <description><![CDATA[ARXIV：2504.07131V1公告类型：交叉 
摘要：生成计划方法在管理可靠性评估和发电计划的优化模型之间管理不兼容的数学结构方面面临挑战，这阻碍了可靠性约束的整合。这项研究提出了一种通过利用加权倾斜决策树（WODT）技术将可靠性验证约束嵌入到生成扩展计划中的方法。在每个计划年度中，都会生成带有可靠性评估模拟的一代混合数据集。使用此数据集对WODT模型进行了训练。可靠性可行的区域是通过深度优先搜索技术提取的，并作为析取约束。然后，使用凸形船体建模技术将这些约束转换为混合成员线性形式，并嵌入到单位承诺集成的生成扩展计划模型中。提出的方法通过为德克萨斯州电力可靠性委员会（ERCOT）地区的长期生成计划案例研究进行了验证，并证明了其在实现可靠和最佳计划解决方案方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2504.07131</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跟随扰动的领导者在M-stem-bandit问题上实现最佳世界世界</title>
      <link>https://arxiv.org/abs/2504.07307</link>
      <description><![CDATA[ARXIV：2504.07307V1公告类型：交叉 
摘要：我们考虑了组合半伴侣问题的常见情况，即$ M $ seet半狂人，其中学习者准确地从总$ d $臂中选择了$ m $ and。在对抗性环境中，最佳的遗憾是$ \ Mathcal {o}（\ sqrt {nmd}）$在时间范围内$ n $，是通过众所周知的遵循规范化的领导者（FTRL）策略来实现的，但是，该策略需要在各个方面进行概率，以示例概率在每个范围内取得了示例，以确定该概率和示例性问题，并在各个方面进行了示例，并在每个方面都在求解时间均达到了时间，并需要达到时间范围的问题。可以通过以下扰动领导者（FTPL）策略避免此问题，该策略只是将$ m $ harm列为$ m $ $ m $（估计）损失的损失，并随机扰动。在本文中，我们表明，FTPL带有fr \&#39;echet扰动也享受了最佳的遗憾，在对抗性环境中，$ \ nmcal {o}（\ sqrt {nmd}）$在对抗性环境中，并实现了最佳的遗憾界限，即为遗憾的是，遗憾的是遗憾。]]></description>
      <guid>https://arxiv.org/abs/2504.07307</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过PDE统一和扩展扩散模型解决反问题</title>
      <link>https://arxiv.org/abs/2504.07437</link>
      <description><![CDATA[ARXIV：2504.07437V1公告类型：交叉 
摘要：扩散模型已成为具有计算机视觉和科学机器学习（SCIML）应用的强大生成工具，在该工具中已被用来解决大规模的概率逆问题。传统上，这些模型是使用变异推断，降解，统计信号处理和随机微分方程的原理得出的。与常规介绍相反，在这项研究中，我们使用线性偏微分方程中的思想得出了扩散模型，并证明该方法具有多种好处，其中包括对正向和反向过程的建设性推导，统一的多种公式和采样策略的统一推导，以及对新模型的发现。我们还将这些模型的条件版本应用于解决规范的条件密度估计问题和具有挑战性的反问题。这些问题有助于建立基准，以系统地量化本研究中不同配方和采样策略的性能以及未来的研究。最后，我们确定并实施了一种机制，可以将单个扩散模型应用于从多个测量运算符获得的测量值中。综上所述，本手稿的内容为扩散模型应用于解决基于物理的逆问题的应用提供了新的理解和几个新方向。]]></description>
      <guid>https://arxiv.org/abs/2504.07437</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT随身携带：定制培训基金会模型可能是简单，可扩展的和负担得起的</title>
      <link>https://arxiv.org/abs/2504.07513</link>
      <description><![CDATA[ARXIV：2504.07513V1公告类型：交叉 
摘要：现代大型语言基础模型（LLM）现在已经进入了数百万用户的日常生活。我们问一个自然的问题，是否可以为每个用户或每个任务自定义LLM。从系统和工业经济的考虑中，一般的持续培训或微调仍需要大量计算和培训GPU节点的记忆，而部署的大多数推理节点（可能具有下端GPU）被配置为使前进的通行证最快。我们提出了一个框架，以完全利用现有的LLM和在线服务系统。我们在预验证的LLM的最终层嵌入底层嵌入（是基础）上训练了一个额外的变压器块的分支，然后将随身携带的模块合并以组成定制的LLM。我们可以混合多个层或多个专门从事不同领域的LLM，例如聊天，编码，数学，以形成最适合新任务的LLM的新混合物。由于基本模型不需要更新参数，因此我们能够将大多数在推理节点上的培训工作计算外包，并且仅在培训节点上训练轻巧的随身携带，在该节点上，我们消耗了小于1GB的GPU内存来训练30B LLM上的100m随身携带层。我们测试了QWEN和DEEPSEEK开放式模型，以持续进行预处理，并获得了更快的损失收敛。我们使用它来改善使用极小的计算和模型大小的求解数学问题，并使用1000个数据链数据样本，以及两个层层随身携带的1 MB参数，结果是有希望的。]]></description>
      <guid>https://arxiv.org/abs/2504.07513</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工深神经网络中吸收相变的通用缩放定律</title>
      <link>https://arxiv.org/abs/2307.02284</link>
      <description><![CDATA[ARXIV：2307.02284V3公告类型：替换 
摘要：我们证明，在信号传播动力学的相位边界附近运行的常规人工深神经网络（也称为混乱的边缘）在非平衡统计力学中表现出吸收相变的普遍缩放定律。我们利用传播动力学的完全确定性的性质来阐明神经网络中的信号崩溃与吸收状态之间的类比（系统可以输入但无法从中逃脱）。我们的数值结果表明，多层感知器和卷积神经网络分别属于平均场和定向的渗透普遍性类别。同样，有限尺寸的缩放是成功应用的，这表明与深度学习的深度宽度折衷有潜在的联系。此外，我们对梯度下降下训练动力学的分析表明，对相边界的高参数调整是必要的，但不足以实现深网中的最佳概括。值得注意的是，与缩放定律相关的非额度度量因素在凝结上述观察结果中起着重要作用。这些发现突出了批判性概念在分析人造深层神经网络的行为上的有用性，并为统一理解批判性与智力之间的基本关系提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2307.02284</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在两层神经网络中具有一个梯度步骤的非线性特征学习理论</title>
      <link>https://arxiv.org/abs/2310.07891</link>
      <description><![CDATA[ARXIV：2310.07891V4公告类型：替换 
摘要：被认为是深层神经网络成功的基本原因之一。众所周知，在某些条件下，在两层完全连接的神经网络中，第一层梯度下降的一步可以导致特征学习。特征在于特征矩阵的范围中的分离级别一个组件-Spike的外观。但是，在恒定的梯度下降步骤大小的情况下，该尖峰仅从目标函数的线性组件中传递信息，因此学习非线性组件是不可能的。我们表明，随着学习率随样本量增长的学习率，这种训练实际上引入了多个等级的组件，每个组件都与特定的多项式特征相对应。我们进一步证明，这些尖峰的限制性大量和大型样本训练以及更新的神经网络的测试错误是完全表征的。通过精确分析培训和测试错误的改善，我们证明了这些非线性特征可以增强学习。]]></description>
      <guid>https://arxiv.org/abs/2310.07891</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DCSI-基于分离和连接性的簇可分离性的改进度量</title>
      <link>https://arxiv.org/abs/2310.12806</link>
      <description><![CDATA[ARXIV：2310.12806V4公告类型：替换 
摘要：给定数据集中的类标签是否对应于有意义的群集对使用现实世界数据集评估聚类算法至关重要。该特性可以通过可分离性度量来量化。基于密度的聚类的可分离性的主要方面是类别间分离和类内连接性，基于分类的复杂度度量或群集有效性指数（CVIS）都无法充分合并它们。新开发的度量（密度簇可分离性指数，DCSI）旨在量化这两个特征，也可以用作CVI。关于合成数据的广泛实验表明，DCSI与通过调整后的RAND指数（ARI）测得的DBSCAN的性能密切相关，但在多级数据集的重叠类中，对于基于密度的硬聚类的重叠类别而言，缺乏鲁棒性。对经常使用的现实世界数据集的详细评估表明，DCSI可以正确识别与基于有意义的密度群集不相对应的触摸或重叠类。]]></description>
      <guid>https://arxiv.org/abs/2310.12806</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过结构化的牛顿下降加速不良条件的汉克尔矩阵恢复</title>
      <link>https://arxiv.org/abs/2406.07409</link>
      <description><![CDATA[ARXIV：2406.07409V2公告类型：替换 
摘要：本文研究了强大的Hankel恢复问题，该问题同时消除了稀疏的异常值并完成了部分观察中缺失的条目。我们提出了一种新型的非凸算法，即汉克尔结构化的牛顿般的下降（HSNLD），以解决强大的Hankel恢复问题。 HSNLD具有线性收敛的高效，其收敛速率与基础Hankel基质的条件数无关。恢复保证已在某些轻度条件下建立。合成数据集和真实数据集的数值实验表明，HSNLD与最新算法的出色性能。]]></description>
      <guid>https://arxiv.org/abs/2406.07409</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>未经调整的Langevin算法的性能没有平稳性假设</title>
      <link>https://arxiv.org/abs/2502.03458</link>
      <description><![CDATA[ARXIV：2502.03458V2公告类型：替换 
摘要：在本文中，我们研究了从密度不一定光滑或登录concave的分布中抽样的问题。我们提出了一种简单的基于Langevin的算法，该算法不依赖于流行，而是计算挑战性的技术，例如Moreau Yosida Invelope或Gaussian平滑。我们得出了算法与Wasserstein距离算法分布的收敛性的非反应保证。还为算法作为优化器的性能提供了非渐近界限，特别是用于解决相关的多余风险优化问题的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.03458</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通用架构用于学习多面体规范和凸正则化器</title>
      <link>https://arxiv.org/abs/2503.19190</link>
      <description><![CDATA[ARXIV：2503.19190V2公告类型：替换 
摘要：本文介绍了学习凸正规化器的任务，以指导来自有限数据的图像重建。通过强加重建是振幅等值的，我们将可允许的功能范围缩小到可以表达为seminorm的力量的功能。然后，我们证明可以在多面体规范的帮助下将此类功能近似为任意精度。特别是，我们确定了此类系统的两个双重参数化：（i）具有$ \ ell_1 $ -penalty的合成形式，其中涉及一些可学习的词典； （ii）带有$ \ ell_ \ infty $ -penalty的分析表，涉及可训练的正则化操作员。在提供了几何见解并证明了两种形式是通用的之后，我们提出了一个依赖特定体系结构（具有加权$ \ ell_1 $罚款的紧身框架）的实现，很容易训练。我们说明了它用于降解和重建生物医学图像的用途。我们发现，所提出的框架的表现优于基于稀疏性的压缩传感方法，而基本上提供了相同的收敛性和鲁棒性保证。]]></description>
      <guid>https://arxiv.org/abs/2503.19190</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>