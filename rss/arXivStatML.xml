<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 26 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>登上国际空间站：不平衡的自我监督：发现混合表格数据集的缩放自动编码器</title>
      <link>https://arxiv.org/abs/2403.15790</link>
      <description><![CDATA[arXiv:2403.15790v1 公告类型：交叉
摘要：不平衡自监督学习领域，特别是在表格数据背景下，尚未得到广泛研究。现有的研究主要集中在图像数据集上。本文旨在通过研究表格数据领域自监督学习中数据不平衡带来的具体挑战来填补这一空白，主要关注自动编码器。自动编码器广泛用于学习和构建数据集的新表示，特别是降维。它们也经常用于生成模型学习，如变分自动编码器中所示。在处理混合表格数据时，定性变量通常使用具有标准损失函数（MSE 或交叉熵）的 one-hot 编码器进行编码。在本文中，我们分析了这种方法的缺点，特别是当分类变量不平衡时。我们提出了一种平衡学习的新指标：多监督平衡 MSE。该方法通过平衡变量的影响来减少重建误差。最后，我们凭经验证明，与标准 MSE 相比，这个新指标：i）在数据集不平衡时表现出色，尤其是当学习过程不充分时，ii）在相反的情况下提供类似的结果。]]></description>
      <guid>https://arxiv.org/abs/2403.15790</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>预测人类句子理解的计算句子级指标</title>
      <link>https://arxiv.org/abs/2403.15822</link>
      <description><![CDATA[arXiv:2403.15822v1 公告类型：交叉
摘要：计算心理语言学的大部分研究都集中在单词的处理上。本研究介绍了使用多语言大语言模型计算句子级度量的创新方法。这些指标开发了句子惊讶度和句子相关性，然后进行测试和比较，以验证它们是否可以预测人类如何跨语言理解整个句子。这些指标提供了显着的可解释性，并在预测人类句子阅读速度方面实现了高精度。我们的结果表明，这些计算句子级指标在预测和阐明读者在理解各种语言的整个句子时遇到的处理困难方面非常有效。他们令人印象深刻的表现和泛化能力为未来整合法学硕士和认知科学的研究提供了一个有前途的途径。]]></description>
      <guid>https://arxiv.org/abs/2403.15822</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>综合路径稳定性选择</title>
      <link>https://arxiv.org/abs/2403.15877</link>
      <description><![CDATA[arXiv:2403.15877v1 公告类型：交叉
摘要：稳定性选择是一种广泛使用的提高特征选择算法性能的方法。然而，稳定性选择被发现是高度保守的，导致灵敏度低。此外，预期误报数量 E(FP) 的理论界限相对宽松，因此很难知道实际中会出现多少误报。在本文中，我们介绍了一种基于整合稳定性路径而不是最大化稳定性路径的新方法。这对 E(FP) 产生了更严格的限制，从而产生了在实践中具有更高灵敏度的特征选择标准，并且在匹配目标 E(FP) 方面得到了更好的校准。我们提出的方法需要与原始稳定性选择算法相同的计算量，并且只需要用户指定一个输入参数，即 E(FP) 的目标值。我们提供了性能的理论界限，并通过癌症基因表达研究的模拟和真实数据演示了该方法。]]></description>
      <guid>https://arxiv.org/abs/2403.15877</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>局部性和权重共享在基于图像的任务中的作用：CNN、LCN 和 FCN 之间的样本复杂度分离</title>
      <link>https://arxiv.org/abs/2403.15707</link>
      <description><![CDATA[arXiv:2403.15707v1 公告类型：交叉
摘要：视觉任务具有局部性和平移不变性的特点。卷积神经网络（CNN）在这些任务上的卓越性能被广泛归因于其架构中的局部性和权重共享的归纳偏差。现有的尝试量化 CNN 相对于局部连接的卷积神经网络 (LCN) 和完全连接的神经网络 (FCN) 中这些偏差的统计优势，属于以下类别之一：要么忽略优化器，仅提供统一收敛上限没有分离的下界，或者他们考虑的简单任务并不能真正反映现实世界视觉任务中的局部性和平移不变性。为了解决这些缺陷，我们引入了动态信号分布（DSD）分类任务，该任务将图像建模为由 $k$ 个补丁组成，每个补丁的维度为 $d$，并且标签由 $d$ 稀疏信号向量确定，可以自由出现在 $k$ 补丁中的任何一个中。在此任务中，对于任何正交等变算法（例如梯度下降），我们证明 CNN 需要 $\tilde{O}(k+d)$ 样本，而 LCN 需要 $\Omega(kd)$ 样本，从而建立了权重的统计优势共享翻译不变任务。此外，与 FCN 的 $\Omega(k^2d)$ 样本相比，LCN 需要 $\tilde{O}(k(k+d))$ 样本，这展示了本地任务中局部性的好处。此外，我们还开发了用于分析随机算法的信息论工具，这可能对统计研究感兴趣。]]></description>
      <guid>https://arxiv.org/abs/2403.15707</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>可识别的潜在神经因果模型</title>
      <link>https://arxiv.org/abs/2403.15711</link>
      <description><![CDATA[arXiv:2403.15711v1 公告类型：交叉
摘要：因果表示学习旨在从低级观察数据中揭示潜在的高级因果表示。它特别擅长在看不见的分布变化下进行预测，因为这些变化通常可以解释为干预的后果。因此，利用{已见}的分布变化成为帮助识别因果表示的自然策略，这反过来又有利于对先前{未见}的分布进行预测。确定有助于因果表征可识别性的分布变化的类型（或条件）至关重要。这项工作建立了一个{充分}和{必要}条件来表征潜在加性噪声模型背景下可识别性的分布变化类型。此外，当只有一部分分布变化满足条件时，我们给出了部分可识别性结果。此外，我们将我们的发现扩展到潜在的后非线性因果模型。我们将我们的发现转化为实用的算法，从而获得可靠的潜在因果表示。我们的算法在基础理论的指导下，在各种合成和现实数据集上表现出了出色的性能。实证观察与理论发现密切相关，证实了我们方法的稳健性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.15711</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>通过不同功能表示集合的监督学习：功能投票分类器</title>
      <link>https://arxiv.org/abs/2403.15778</link>
      <description><![CDATA[arXiv:2403.15778v1 公告类型：交叉
摘要：许多传统的统计和机器学习方法在直接应用于高维时间观测时面临挑战。近几十年来，函数数据分析 (FDA) 作为一种对数据进行建模和分析的框架得到了广泛的欢迎，这些数据本质上是在时间域中起作用的。尽管近几十年来 FDA 文献中已经广泛探讨了监督分类，但功能分类器的集成学习直到最近才成为人们感兴趣的话题。因此，后一个主题从各种统计角度呈现了未探索的方面和挑战。本文的重点在于功能数据的集成学习领域，旨在展示如何使用不同的功能数据表示来训练集成成员以及如何通过多数投票来组合基本模型预测。提出所谓的功能投票分类器（FVC）是为了演示导致增强多样性的不同功能表示如何提高预测准确性。来自多个领域的许多现实世界数据集用于表明，与单个模型相比，FVC 可以显着提高性能。所提出的框架为具有功能数据的投票集成提供了基础，并且可以刺激 FDA 背景下的一系列非常令人鼓舞的研究。]]></description>
      <guid>https://arxiv.org/abs/2403.15778</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>关于有限矩损失的泛化界限的注释</title>
      <link>https://arxiv.org/abs/2403.16681</link>
      <description><![CDATA[arXiv:2403.16681v1 公告类型：新
摘要：本文研究了 Alquier [1] 的截断方法，以导出重尾无界损失的高概率 PAC-Bayes 界限。假设第 $p$ 个时刻是有界的，则结果边界在 $p=2$ 时的慢速率 $1 / \sqrt{n}$ 和 $p \to \infty 时的快速率 $1 / n$ 之间插值$ 并且损失基本上是有限的。此外，本文还推导了一个高概率 PAC-Bayes，其损失范围具有有限方差。与文献中先前的界限相比，该界限对置信参数和依赖性度量的依赖性要好得多。最后，本文将所有结果扩展到期望和单抽 PAC-Bayes 中的保证。为此，它在这些设置中从 [2] 中获得了 PAC-Bayes 快速速率界限的类似物，以实现有界损失。]]></description>
      <guid>https://arxiv.org/abs/2403.16681</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>具有无限维输入的序列到序列函数的变压器的逼近和估计能力</title>
      <link>https://arxiv.org/abs/2305.18699</link>
      <description><![CDATA[arXiv:2305.18699v1 公告类型：交叉
摘要：尽管 Transformer 网络在自然语言处理和计算机视觉等各种应用中取得了巨大成功，但其理论方面尚不清楚。在本文中，我们研究了 Transformer 作为具有无限维输入的序列到序列函数的近似和估计能力。尽管输入和输出都是无限维的，但我们表明，当目标函数具有各向异性平滑度时，Transformers 由于其特征提取能力和参数共享特性，可以避免维数灾难。此外，我们还表明，即使平滑度根据每个输入而变化，Transformers 也可以估计每个输入特征的重要性并动态提取重要特征。然后，我们证明 Transformer 可以达到与固定平滑度情况下相似的收敛速度。我们的理论结果支持 Transformers 在高维数据方面的实际成功。]]></description>
      <guid>https://arxiv.org/abs/2305.18699</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>核视角下的两层神经网络平均场分析</title>
      <link>https://arxiv.org/abs/2403.14917</link>
      <description><![CDATA[arXiv:2403.14917v1 公告类型：交叉
摘要：在本文中，我们通过核方法研究了平均场体系中两层神经网络的特征学习能力。为了关注第一层引起的内核动态，我们利用双时间尺度限制，其中第二层的移动速度比第一层快得多。在这个限制下，学习问题被简化为内在内核上的最小化问题。然后，我们展示了平均场 Langevin 动力学的全局收敛性，并推导了时间和粒子离散化误差。我们还证明，两层神经网络可以比任何核方法更有效地学习多个再生核希尔伯特空间的并集，并且神经网络获取与目标函数对齐的数据相关核。此外，我们开发了一个标签噪声程序，它收敛到全局最优值，并表明自由度表现为隐式正则化。]]></description>
      <guid>https://arxiv.org/abs/2403.14917</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>多环境场景下的预测推理</title>
      <link>https://arxiv.org/abs/2403.16336</link>
      <description><![CDATA[arXiv:2403.16336v1 公告类型：新
摘要：我们解决了跨多个环境的预测问题中构建有效置信区间和集合的挑战。我们研究了适合这些问题的两种类型的覆盖范围，扩展了折刀法和分割保形方法，以展示如何在这种非传统的分层数据生成场景中获得无分布的覆盖范围。我们的贡献还包括对非实值响应设置的扩展以及这些一般问题中预测推理的一致性理论。我们展示了一种新颖的调整大小方法来适应问题的难度，该方法既适用于现有的分层数据预测推理方法，也适用于我们开发的方法；这使用来自测试环境的有限信息减少了预测集的大小，这是该方法实际性能的关键，我们通过神经化学传感和物种分类数据集对其进行评估。]]></description>
      <guid>https://arxiv.org/abs/2403.16336</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>使用高阶累积量和路径分析从泊松分支结构因果模型发现因果关系</title>
      <link>https://arxiv.org/abs/2403.16523</link>
      <description><![CDATA[arXiv:2403.16523v1 公告类型：新
摘要：计数数据自然出现在金融、神经科学和流行病学等许多领域，发现计数数据之间的因果结构是各种科学和工业场景中的关键任务。计数数据最常见的特征之一是由二项式细化算子和捕获分支和噪声的独立泊松分布描述的固有分支结构。例如，在人口计数场景中，死亡率和移民对计数有贡献，其中生存遵循伯努利分布，移民遵循泊松分布。然而，由于不可识别性问题，从此类数据中发现因果关系具有挑战性：单个因果对是马尔可夫等价的，即 $X\rightarrow Y$ 和 $Y\rightarrow X$ 是分布等价的。幸运的是，在这项工作中，我们发现如果 $X$ 是根顶点并且至少有两条到 $Y$ 或 $X 的祖先的有向路径，则从 $X$ 到其子 $Y$ 的因果顺序是可识别的具有到 $X$ 的最有向路径的 $ 具有到 $Y$ 的有向路径，而不传递 $X$。具体来说，我们提出了泊松分支结构因果模型（PB-SCM），并使用高阶累积量对 PB-SCM 进行路径分析。理论结果建立了路径与累积量之间的联系，并证明可以从累积量中获得路径信息。利用路径信息，在某些图形条件下可以识别因果顺序。提出了一种PB-SCM下学习因果结构的实用算法，并通过实验证明和验证了该方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.16523</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>具有保证私有初始化的近乎最优差分私有低秩跟踪回归</title>
      <link>https://arxiv.org/abs/2403.15999</link>
      <description><![CDATA[arXiv:2403.15999v1 公告类型：新
摘要：我们研究了在高斯测量矩阵的迹回归模型下对秩 $r$ 矩阵 $M \in \RR^{d_1\times d_2}$ 的差分隐私（DP）估计。理论上，精确表征了非私有谱初始化的敏感性，并建立了 Schatten-$q$ 范数下估计 $M$ 的差分隐私约束极小极大下界。在方法上，本文引入了一种计算高效的 DP 初始化算法，样本大小为 $n \geq \wt O (r^2 (d_1\vee d_2))$。在某些规律性条件下，DP 初始化落在 $M$ 周围的局部球内。我们还提出了一种基于黎曼优化 (DP-RGrad) 的差分隐私算法来估计 $M$，该算法在 DP 初始化和 $n \geq \wt O(r (d_1 + d_2))$。最后，本文讨论了迹回归模型下低秩矩阵估计的极小极大下界和上限之间的非平凡差距。结果表明，DP-RGrad 给出的估计器在较弱的差分隐私概念下获得了最佳收敛速度。我们用于分析初始化敏感性的强大技术不需要 $r$ 非零奇异值之间的特征间隙条件。]]></description>
      <guid>https://arxiv.org/abs/2403.15999</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>从偏序学习有向无环图</title>
      <link>https://arxiv.org/abs/2403.16031</link>
      <description><![CDATA[arXiv:2403.16031v1 公告类型：新
摘要：有向无环图（DAG）通常用于建模随机变量之间的因果关系。一般来说，学习 DAG 结构在计算和统计上都具有挑战性。此外，如果没有附加信息，边缘的方向可能无法从观测数据估计。相反，给定变量的完整因果排序，即使在高维度上，也可以有效地解决问题。在本文中，我们考虑当变量的部分因果排序可用时学习 DAG 的中间问题。我们提出了一个利用偏序的通用估计框架，并针对低维和高维问题提出了有效的估计算法。通过数值研究说明了所提出框架的优点。]]></description>
      <guid>https://arxiv.org/abs/2403.16031</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>基于改进扩散图的流形正则化分类模型</title>
      <link>https://arxiv.org/abs/2403.16059</link>
      <description><![CDATA[arXiv:2403.16059v1 公告类型：新
摘要：流形正则化模型是一种半监督学习模型，利用数据集的几何结构（包括少量标记样本和大量未标记样本）来生成分类器。然而，原始流形范数将模型的性能限制在局部区域。为了解决这个限制，本文提出了一种基于标签传播模型来改进流形正则化的方法。我们首先增强了扩散图算法的概率转移矩阵，该矩阵可用于估计诺伊曼热核，使其能够准确地描述流形上的标签传播过程。使用这个矩阵，我们在数据集上建立标签传播函数来描述不同时间步长的标签分布。随后，我们将标签传播函数扩展到整个数据流形。我们证明扩展的标签传播函数在足够长的时间后收敛到稳定的分布，并且可以被视为分类器。基于这个概念，我们提出了对流形正则化模型的可行改进，并通过实验验证了其优越性。]]></description>
      <guid>https://arxiv.org/abs/2403.16059</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>共形在线模型聚合</title>
      <link>https://arxiv.org/abs/2403.15527</link>
      <description><![CDATA[arXiv:2403.15527v1 公告类型：新
摘要：保形预测为机器学习模型配备了合理的不确定性量化概念，而无需做出强分布假设。它包含任何黑盒预测模型，并将点预测转换为具有预定义边际覆盖保证的集合预测。然而，只有当我们提前修复底层机器学习模型时，保形预测才有效。保形预测中一个相对未解决的问题是模型选择和/或聚合：对于给定的问题，我们应该对众多预测方法（随机森林、神经网络、正则化线性模型等）中的哪一个进行保形？本文提出了一种在在线设置中进行共形模型聚合的新方法，该方法基于通过投票组合来自多种算法的预测集，其中模型的权重根据过去的表现随时间进行调整。]]></description>
      <guid>https://arxiv.org/abs/2403.15527</guid>
      <pubDate>Tue, 26 Mar 2024 06:17:16 GMT</pubDate>
    </item>
    </channel>
</rss>