<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>具有抗对抗攻击能力的异构多人多臂老虎机</title>
      <link>https://arxiv.org/abs/2501.17882</link>
      <description><![CDATA[arXiv:2501.17882v1 公告类型：新
摘要：我们考虑一个多人多臂老虎机设置，其中存在试图对系统中玩家获得的奖励产生负面影响的对手。任何给定臂的奖励分布在玩家之间都是不同的。如果发生碰撞（多个玩家选择同一臂），所有碰撞用户都将获得零奖励。对手使用碰撞来影响玩家获得的奖励，即，如果对手攻击一个臂，任何选择该臂的玩家都将获得零奖励。在任何时间步骤，对手都可能攻击多个臂。假设系统中的玩家不会偏离所有玩家使用的预定策略，并且每个时间步骤中没有一个臂面临对抗性攻击的概率都是严格正的。为了对抗对抗性攻击，玩家可以使用单个比特进行 $O(\log T)$ 个时间单位的通信，其中 $T$ 是时间范围，并且每个玩家只能在所有时间步骤中观察自己的行动和奖励。我们提出了一种{所有玩家都使用的策略，该策略}实现了接近 $O(\log^{1+\delta}T + W)$ 阶的最优遗憾，其中 $W$ 是至少有一个分支受到对抗性攻击的时间单位总数。]]></description>
      <guid>https://arxiv.org/abs/2501.17882</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Knoop：通过过度参数化对变量选择进行实用增强</title>
      <link>https://arxiv.org/abs/2501.17889</link>
      <description><![CDATA[arXiv:2501.17889v1 公告类型：新
摘要：变量选择在提高不同领域的建模效率方面起着至关重要的作用，解决了相关变量高维数据集带来的挑战。这项工作引入了一种新方法，即过度参数化的 Knockoff（Knoop），以增强用于变量选择的 Knockoff 过滤器。具体来说，Knoop 首先为每个原始变量生成多个 knockoff 变量，并将它们与原始变量集成到过度参数化的 Ridgeless 回归模型中。对于每个原始变量，Knoop 评估其 knockoff 的系数分布，并将其与原始系数进行比较以进行基于异常的显着性检验，确保稳健的变量选择。大量实验表明，与模拟和真实世界数据集中的现有方法相比，该方法具有更优异的性能。 Knoop 实现了显著更高的接收者操作特征 (ROC) 曲线下面积 (AUC)，可通过受控模拟有效地识别与基本事实相关的变量，同时在各种回归和分类任务中展现出增强的预测准确性。分析结果进一步支持了我们的观察结果。]]></description>
      <guid>https://arxiv.org/abs/2501.17889</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>U-aggregation：多种学习算法的无监督聚合</title>
      <link>https://arxiv.org/abs/2501.18084</link>
      <description><![CDATA[arXiv:2501.18084v1 公告类型：新
摘要：在各个领域，对开放科学和开源机器学习的日益倡导使得越来越多的模型公开可用。这些模型允许从业者将它们集成到自己的环境中，从而减少了对大量数据标记、训练和校准的需求。然而，由于可转移性有限、数据异质性以及在现实环境中难以获得真实标签或结果等问题，为特定目标人群选择最佳模型仍然具有挑战性。在本文中，我们提出了一种无监督模型聚合方法 U-aggregation，旨在整合多个预训练模型，以在新人群中增强和稳健地表现。与现有的监督模型聚合或超级学习者方法不同，U-aggregation 假设目标人群中没有观察到的标签或结果。我们的方法通过适应更现实的设置（包括模型和个体层面的异方差以及对抗模型的存在）解决了现有无监督模型聚合技术的局限性。借鉴随机矩阵理论的见解，U 聚合结合了方差稳定步骤和迭代稀疏信号恢复过程。这些步骤改善了对目标人群中个人真实潜在风险的估计，并评估了候选模型的相对性能。我们提供了理论研究和系统数值实验来阐明 U 聚合的属性。我们利用 PGS 目录中公开可用的模型，通过使用 U 聚合来增强复杂性状的遗传风险预测，展示了其潜在的现实应用。]]></description>
      <guid>https://arxiv.org/abs/2501.18084</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>私人均值估计的最优调查设计</title>
      <link>https://arxiv.org/abs/2501.18121</link>
      <description><![CDATA[arXiv:2501.18121v1 公告类型：新 
摘要：这项工作确定了第一个隐私感知分层抽样方案，该方案在差分隐私 (DP) 框架内最小化拉普拉斯、离散拉普拉斯 (DLap) 和截断均匀拉普拉斯 (TuLap) 机制下的一般隐私均值估计的方差。我们将分层抽样视为子抽样操作，它放大了隐私保证；但是，为了对每个组具有相同的最终隐私保证，需要根据子抽样率使用不同的名义隐私预算。忽略 DP 的影响，传统的分层抽样策略可能会出现显着的方差膨胀。我们将最佳调查设计表述为优化问题，其中我们确定每个组的最佳子抽样大小，目标是最小化结果估计量的方差。我们建立了方差目标的强凸性，提出了一种有效的算法来识别整数最优设计，并对最优设计的结构提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2501.18121</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>随机特征表示提升</title>
      <link>https://arxiv.org/abs/2501.18283</link>
      <description><![CDATA[arXiv:2501.18283v1 公告类型：新
摘要：我们引入了随机特征表示提升 (RFRBoost)，这是一种使用提升理论构建深度残差随机特征神经网络 (RFNN) 的新方法。RFRBoost 在每一层使用随机特征来学习网络表示的功能梯度，从而提高性能，同时保留 RFNN 的凸优化优势。在 MSE 损失的情况下，我们获得了具有随机特征的贪婪逐层提升的闭式解。对于一般损失函数，我们表明拟合随机特征残差块可以简化为求解二次约束最小二乘问题。我们通过对 91 个表格数据集进行回归和分类的数值实验证明，RFRBoost 明显优于传统 RFNN 和端到端训练的 MLP ResNet，同时提供了源自提升​​理论的显着计算优势和理论保证。]]></description>
      <guid>https://arxiv.org/abs/2501.18283</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果关系二元三元组有向无环图中的不真实概率分布</title>
      <link>https://arxiv.org/abs/2501.18337</link>
      <description><![CDATA[arXiv:2501.18337v1 公告类型：新
摘要：忠实性是因果发现和因果推理中概率分布和图的基础。本文在三顶点二元因果有向无环图（DAG）结构中构造了几个不忠实的概率分布示例，这些示例不忠实于 J.M.,Robins,et al. Uniform consistent in causal inference. Biometrika (2003),90(3): 491--515 中描述的因果 DAG。并给出了二元三重因果 DAG 中具有多重独立性和条件独立的一般不忠实概率分布。]]></description>
      <guid>https://arxiv.org/abs/2501.18337</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用无限维函数回归进行情境在线决策</title>
      <link>https://arxiv.org/abs/2501.18359</link>
      <description><![CDATA[arXiv:2501.18359v1 公告类型：新
摘要：上下文顺序决策问题在机器学习中起着至关重要的作用，涵盖了广泛的下游应用，例如强盗、顺序假设检验和在线风险控制。这些应用通常需要不同的统计度量，包括期望、方差和分位数。在本文中，我们提供了一个通用的可接受算法框架，用于处理各种上下文在线决策问题，该框架直接学习整个底层未知分布，而不是关注单个统计数据。这要困难得多，因为回归的维度是不可数的无限的，任何现有的线性上下文强盗算法都会导致无限的遗憾。为了解决这个问题，我们提出了一种有效的无限维函数回归预言机，用于上下文累积分布函数 (CDF)，其中每个数据点都被建模为上下文相关的 CDF 基函数的组合。我们的分析表明，设计积分算子的特征值序列的衰减率决定了回归误差率，从而决定了效用遗憾率。具体而言，当特征值序列表现出 $\frac{1}{\gamma}\ge 1$ 阶多项式衰减时，效用遗憾值由 $\tilde{\mathcal{O}}\Big(T^{\frac{3\gamma+2}{2(\gamma+2)}}\Big)$ 界定。通过设置 $\gamma=0$，这恢复了具有有限维回归的上下文老虎机的现有最佳遗憾率，并且在更强的指数衰减假设下是最佳的。此外，我们提供了一种数值方法来计算积分算子的特征值序列，从而使我们的框架能够实际实现。]]></description>
      <guid>https://arxiv.org/abs/2501.18359</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越先前的限制：解决粒子滤波中的分布错位问题</title>
      <link>https://arxiv.org/abs/2501.18501</link>
      <description><![CDATA[arXiv:2501.18501v1 公告类型：新
摘要：粒子过滤是一种贝叶斯推理方法，也是动态系统状态估计的基本工具，但其有效性通常受到初始先验分布约束的限制，我们将这种现象定义为先验边界现象。当目标状态超出先验支持范围时，就会出现这种挑战，导致传统粒子过滤方法无法进行准确估计。尽管已经提出了无界先验和更大粒子集等技术，但它们在计算上仍然过于昂贵，并且在动态场景中缺乏适应性。为了系统地克服这些限制，我们提出了扩散增强粒子过滤框架，该框架引入了三个关键创新：通过探索性粒子进行自适应扩散、熵驱动的正则化以防止权重崩溃以及基于内核的扰动以进行动态支持扩展。这些机制共同使粒子过滤能够探索先验边界之外，确保对边界外目标进行稳健的状态估计。理论分析和大量实验验证了框架的有效性，表明在高维和非凸场景中的成功率和估计精度有显著提高。]]></description>
      <guid>https://arxiv.org/abs/2501.18501</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>插值附近广义浅层神经网络的最佳泛化和学习转变</title>
      <link>https://arxiv.org/abs/2501.18530</link>
      <description><![CDATA[arXiv:2501.18530v1 公告类型：新
摘要：我们考虑一个监督学习的师生模型，该模型具有一个经过充分训练的 2 层神经网络，其宽度 $k$ 和输入维度 $d$ 很大且成比例。我们计算网络对任何激活函数的贝叶斯最优泛化误差，其中训练数据的数量 $n$ 与输入维度成二次方关系，即在插值阈值附近，其中可训练参数的数量 $kd+k$ 和数据点的数量 $n$ 是可比的。我们的分析解决了一般权重分布。专注于二元权重，我们发现了一个不连续的相变，将“通用”阶段与“专业化”阶段分开。在第一个阶段，泛化误差与权重分布无关，并且随着采样率 $n/d^2$ 缓慢衰减，学生只学习教师权重的一些非线性组合。在后者中，误差取决于权重分布，并且由于学生网络与教师网络的对齐而衰减得更快。因此，我们揭示了插值附近存在一个高度预测的解决方案，但这可能很难找到。]]></description>
      <guid>https://arxiv.org/abs/2501.18530</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度集成秘密执行经验贝叶斯</title>
      <link>https://arxiv.org/abs/2501.17917</link>
      <description><![CDATA[arXiv:2501.17917v1 公告类型：交叉 
摘要：量化神经网络中的不确定性是一个高度相关的问题，对许多应用至关重要。解决此任务的两个主要范例是贝叶斯神经网络 (BNN) 和深度集成。尽管这两种方法之间存在一些相似之处，但通常推测它们缺乏正式联系，因此被理解为根本不同。由于依赖贝叶斯范式，BNN 通常被吹捧为更具原则性，而集成则被认为更具临时性；然而，深度集成往往在经验上优于 BNN，但对于为什么会这样没有令人满意的解释。在这项工作中，我们通过展示深度集成执行精确的贝叶斯平均来弥合这一差距，其后验是通过隐式学习的数据相关先验获得的。换句话说，深度集成是贝叶斯的，或者更具体地说，它们实现了经验贝叶斯程序，其中先验是从数据中学习的。这种观点有两个主要好处：（i）它从理论上证明了深度集成的合理性，从而解释了它们强大的经验性能；（ii）对学习到的先验的检查表明它是由点质量的混合给出的——使用如此强大的先验有助于阐明观察到的集成现象。总的来说，我们的工作提供了对深度集成的新认识，这不仅本身很有趣，而且还可能产生推动这些模型经验改进的未来见解。]]></description>
      <guid>https://arxiv.org/abs/2501.17917</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>双曲空间中贝叶斯系统发育的变分组合序贯蒙特卡罗</title>
      <link>https://arxiv.org/abs/2501.17965</link>
      <description><![CDATA[arXiv:2501.17965v1 公告类型：交叉 
摘要：双曲空间自然编码层次结构，例如系统发育（二叉树），其中向内弯曲的测地线反映了通过最小共同祖先的路径，而邻域的指数增长反映了拓扑的超指数扩展。这种扩展挑战限制了基于欧几里得的近似推理方法的效率。受树和双曲空间之间几何连接的启发，我们开发了两种顺序搜索算法的新型双曲扩展：组合和嵌套组合顺序蒙特卡罗（\textsc{Csmc} 和 \textsc{Ncsmc}）。我们的方法引入了一致和无偏估计量，以及变分推理方法（\textsc{H-Vcsmc} 和 \textsc{H-Vncsmc}），它们的表现优于欧几里得方法。实证结果表明，高维系统发育推断任务的速度、可扩展性和性能有所提高。]]></description>
      <guid>https://arxiv.org/abs/2501.17965</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联合定价和资源分配：一种最优在线学习方法</title>
      <link>https://arxiv.org/abs/2501.18049</link>
      <description><![CDATA[arXiv:2501.18049v1 公告类型：交叉 
摘要：我们研究动态定价和资源分配的在线学习问题，我们做出联合定价和库存决策以最大化整体净利润。我们考虑需求对价格的随机依赖性，这使资源分配过程复杂化，并给问题带来了显着的非凸性和不平滑性。为了解决这个问题，我们开发了一种有效的算法，该算法利用多个 OCO 代理的“下置信边界 (LCB)”元策略。我们的算法实现了 $\tilde{O}(\sqrt{Tmn})$ 遗憾（对于 $m$ 个供应商和 $n$ 个消费者），这对于时间范围 $T$ 是最优的。我们的结果表明统计学习方法与复杂运筹学问题的有效结合。]]></description>
      <guid>https://arxiv.org/abs/2501.18049</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有边缘覆盖的噪声自适应共形分类</title>
      <link>https://arxiv.org/abs/2501.18060</link>
      <description><![CDATA[arXiv:2501.18060v1 公告类型：交叉 
摘要：共形推理为机器学习中的不确定性量化提供了严格的统计框架，使任何分类模型都能获得具有精确覆盖保证的经过良好校准的预测集。然而，它依赖于完美数据可交换性的理想化假设，这限制了它在现实世界复杂情况下的有效性，例如低质量标签——这是现代大规模数据集中普遍存在的问题。这项工作通过引入一种自适应共形推理方法解决了这个悬而未决的问题，该方法能够有效地处理由随机标签噪声引起的可交换性偏差，从而产生具有严格边际覆盖保证的信息预测集，即使在那些具有挑战性的情况下也是如此。我们通过大量数值实验验证了我们的方法，证明了它在合成和真实数据集上的有效性，包括 CIFAR-10H 和 BigEarthNet。]]></description>
      <guid>https://arxiv.org/abs/2501.18060</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习进行髓鞘水估计的输入层正则化和自动正则化超参数调整</title>
      <link>https://arxiv.org/abs/2501.18074</link>
      <description><![CDATA[arXiv:2501.18074v1 公告类型：交叉 
摘要：我们提出了一种新颖的深度学习方法，该方法将经典正则化与数据增强相结合，通过双指数分析估计大脑中的髓鞘水分数 (MWF)。我们的目标是设计一种精确的深度学习技术来分析磁共振松弛测量中出现的信号。特别是，我们研究了双指数模型，这是用于 MWF 估计的信号模型之一。我们在几个方面大大扩展了我们之前在 \emph{输入层正则化 (ILR)} 方面的工作。我们现在通过专用神经网络或广义交叉验证 (GCV) 逐个信号或逐个像素地结合最佳正则化参数选择来形成增强输入信号，并且现在将 MWF 的估计（而不仅仅是指数时间常数）纳入分析中。在合成生成的数据上，我们提出的深度学习架构优于经典方法和传统的多层感知器。在活体脑数据上，我们的架构再次优于其他比较方法，事实证明 GCV 在正则化参数选择方面略优于 NN。因此，ILR 改进了双指数模型中 MWF 的估计。此外，GCV 等经典方法可以与深度学习相结合，以优化人脑中的 MWF 成像。]]></description>
      <guid>https://arxiv.org/abs/2501.18074</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种用于中高维赫斯特分布一致性估计的谱聚类算法</title>
      <link>https://arxiv.org/abs/2501.18115</link>
      <description><![CDATA[arXiv:2501.18115v1 公告类型：交叉 
摘要：尺度不变性（分形性）是许多随机系统大规模行为的一个显著特征。在这项工作中，我们构建了一种算法，用于统计识别高维分形系统中的赫斯特分布（特别是尺度指数）。该算法基于小波随机矩阵、改进的谱聚类和用于选择聚类精度超参数值的模型选择步骤。在维度、样本大小和尺度趋于无穷大的中等高维状态下，我们表明该算法可以一致地估计赫斯特分布。蒙特卡罗模拟表明，所提出的方法对于实际样本量是有效的，并且优于另一种基于混合高斯建模的流行聚类方法。我们将该算法应用于现实世界宏观经济时间序列的分析，以揭示协整的证据。]]></description>
      <guid>https://arxiv.org/abs/2501.18115</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>