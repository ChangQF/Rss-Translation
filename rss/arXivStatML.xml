<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 19 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>排序与选择中改进有限预算分配的正确选择概率的级数展开</title>
      <link>https://arxiv.org/abs/2411.10695</link>
      <description><![CDATA[arXiv:2411.10695v1 公告类型：新
摘要：本文通过开发正确选择概率 (PCS) 的 Bahadur-Rao 型扩展来解决提高排名和选择中有限样本性能的挑战。虽然传统的大偏差近似值可以捕捉渐近状态下的 PCS 行为，但它们在有限样本设置中可能缺乏精度。我们的方法增强了有限模拟预算下的 PCS 近似，提供了更准确的最佳采样率和依赖于预算的最优条件的表征。在算法上，我们提出了一种新颖的有限预算分配 (FCBA) 策略，该策略按顺序估计最优条件并相应地平衡采样率。我们在小样本上用数字说明我们的 FCBA 策略与经过测试的传统方法相比实现了卓越的 PCS 性能。作为扩展，我们注意到文献中描述的低置信度场景的非单调 PCS 行为可归因于 PCS 近似中同时进行的不正确二进制比较的疏忽。我们提供了改进的扩展和定制的分配策略来处理低置信度场景，解决了非单调性问题。]]></description>
      <guid>https://arxiv.org/abs/2411.10695</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可分解动作空间中的离线强化学习调查</title>
      <link>https://arxiv.org/abs/2411.11088</link>
      <description><![CDATA[arXiv:2411.11088v1 公告类型：新
摘要：将强化学习 (RL) 扩展到离线领域会产生良好的前景，特别是在数据收集带来巨大挑战或风险的领域。成功将 RL 转移到离线的关键是减轻数据中缺失的状态-动作对的价值估计中的高估偏差。虽然近年来提出了许多方法，但这些方法往往主要集中在连续或小规模的离散动作空间上。另一方面，尽管许多现实世界的问题自然具有可分解的动作，但分解的离散动作空间却受到的关注相对较少。在这项工作中，我们对可分解动作空间中的离线强化学习进行了形成性调查。以 DecQN 中制定的价值分解为基础，我们提出了分解方法的案例，并对适应分解设置的几种离线技术进行了广泛的实证评估。在没有既定基准的情况下，我们引入了一套我们自己的数据集，其中包括不同质量和任务复杂度的数据集。我们提倡可重复的研究和创新，将所有数据集与我们的代码库一起开放给公众使用。]]></description>
      <guid>https://arxiv.org/abs/2411.11088</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有收缩的变分贝叶斯领结神经网络</title>
      <link>https://arxiv.org/abs/2411.11132</link>
      <description><![CDATA[arXiv:2411.11132v1 公告类型：新
摘要：尽管深度模型在机器学习中占据主导地位，但其局限性仍然存在，包括过度自信的预测、易受对抗性攻击以及低估预测的可变性。贝叶斯范式提供了一个自然的框架来克服这些问题，并已成为深度模型不确定性估计的黄金标准，同时还提供了更高的准确性和调整关键超参数的框架。然而，精确的贝叶斯推理具有挑战性，通常涉及施加强独立性和分布假设的变分算法。此外，现有方法对网络的架构选择很敏感。我们通过构建标准前馈整流神经网络的宽松版本，并采用 Polya-Gamma 数据增强技巧来呈现条件线性和高斯模型来解决这些问题。此外，我们在神经网络权重上使用稀疏性促进先验来进行数据驱动的架构设计。为了近似后验，我们推导出一个变分推理算法，该算法避免了分布假设和跨层的独立性，并且是通常的马尔可夫链蒙特卡罗方案的更快替代方法。]]></description>
      <guid>https://arxiv.org/abs/2411.11132</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过最大耦合消除大型语言模型的水印</title>
      <link>https://arxiv.org/abs/2411.11203</link>
      <description><![CDATA[arXiv:2411.11203v1 公告类型：新
摘要：对语言模型进行水印处理对于区分人类和机器生成的文本，从而保持数字通信的完整性和可信度至关重要。我们提出了一种新颖的绿色/红色列表水印方法，将标记集划分为“绿色”和“红色”列表，巧妙地增加了绿色标记的生成概率。为了纠正标记分布偏差，我们的方法采用最大耦合，使用均匀的硬币翻转来决定是否应用偏差校正，并将结果嵌入为伪随机水印信号。理论分析证实了这种方法的无偏性和强大的检测能力。实验结果表明，它在保持高可检测性的同时，通过保持文本质量，优于现有技术，并且它表现出对旨在提高文本质量的有针对性修改的弹性。这项研究为语言模型提供了一种有前途的水印解决方案，在有效检测和对文本质量的最小影响之间取得平衡。]]></description>
      <guid>https://arxiv.org/abs/2411.11203</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>加速大规模稀疏文档数据的球面 K 均值聚类</title>
      <link>https://arxiv.org/abs/2411.11300</link>
      <description><![CDATA[arXiv:2411.11300v1 公告类型：新
摘要：本文提出了一种针对大规模高维稀疏文档数据集的加速球面 K 均值聚类算法。我们设计了一种以架构友好的方式工作的算法 (AFM)，这是一种抑制性能下降因素的过程，例如现代计算机系统 CPU 中的指令数量、分支预测错误和缓存未命中。对于 AFM 操作，我们利用数据对象和聚类均值集的独特通用特征 (UC)，它们是数据关系上的倾斜分布，例如 Zipf 定律和特征值集中现象。UC 表明，相似度计算的大部分乘法次数是针对具有高文档频率 (df) 的术语执行的，并且对象和平均特征向量之间的大部分相似度是通过对少数高平均特征值的乘法获得的。我们提出的算法将倒排索引数据结构应用于均值集，通过新引入的两个结构参数提取均值倒排索引中具有高自由度项和高均值特征值的特定区域，并利用将索引分为三部分进行高效修剪。该算法通过最小化与指令相关的乘法近似次数来确定两个结构参数，通过与所有对象共享包含两个参数的索引结构来减少分支错误预测，并通过在缓存中保留上述特定区域中的常用数据来抑制缓存未命中，从而在 AFM 中工作。我们通过实验证明，与使用最先进技术的算法相比，我们的算法在大规模文档中有效地实现了卓越的速度性能。]]></description>
      <guid>https://arxiv.org/abs/2411.11300</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有隐藏混杂因素的线性循环系统的稳健因果分析</title>
      <link>https://arxiv.org/abs/2411.11590</link>
      <description><![CDATA[arXiv:2411.11590v1 公告类型：新
摘要：我们生活在一个充满复杂系统的世界，我们需要提高对它们的理解。为了实现这一点，纯粹的概率调查往往是不够的。它们只是第一步，必须接着学习系统的底层机制。这就是因果关系学科所关注的。许多复杂系统都包含反馈回路，这意味着我们的方法必须允许循环因果关系。此外，系统很少被充分隔离，这意味着通常存在隐藏的混杂因素，即每个未测量的变量都会对多个测量变量产生因果影响。最后，数据经常被污染过程扭曲，我们需要应用对这种扭曲具有鲁棒性的方法。这就是为什么我们考虑 LLC 的鲁棒性，参见 \cite{llc}，它是少数可以处理具有隐藏混杂因素的循环模型的因果分析方法之一。在对 LLC 的鲁棒性进行理论分析之后，我们还提供了 LLC 的鲁棒扩展。为了便于重现和进一步研究，我们将源代码公开。]]></description>
      <guid>https://arxiv.org/abs/2411.11590</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习结构化预测的可区分替代损失</title>
      <link>https://arxiv.org/abs/2411.11682</link>
      <description><![CDATA[arXiv:2411.11682v1 公告类型：新
摘要：结构化预测涉及学习预测复杂结构而不是简单的标量值。主要挑战来自输出空间的非欧几里得性质，这通常需要放宽问题公式。代理方法建立在核诱导损失或更一般地承认隐式损失嵌入的损失函数的基础上，并将原始问题转换为回归任务，然后进行解码步骤。然而，为具有复杂结构的对象设计有效的损失带来了巨大的挑战，通常需要特定领域的专业知识。在这项工作中，我们引入了一个新颖的框架，其中通过对比学习直接从输出训练数据中学习由神经网络参数化的结构化损失函数，然后再解决监督代理回归问题。因此，可微分损失不仅能够由于代理空间的有限维度而进行神经网络的学习，而且还允许通过基于梯度下降的解码策略预测输出数据的新结构。对监督图预测问题的数值实验表明，我们的方法与基于预定义核的方法实现了相似甚至更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.11682</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>根 N 一致条件均值估计的去偏回归</title>
      <link>https://arxiv.org/abs/2411.11748</link>
      <description><![CDATA[arXiv:2411.11748v1 公告类型：新
摘要：本研究介绍了一种用于回归估计量的去偏方法，包括高维和非参数回归估计量。例如，非参数回归方法允许以数据驱动的方式估计回归函数，并且假设最少；然而，这些方法通常无法实现收敛速度的 $\sqrt{n}$ 一致性，并且许多方法（包括机器学习中的方法）无法保证其估计量渐近遵循正态分布。为了应对这些挑战，我们提出了一种非参数估计量的去偏技术，即在原始估计量中添加偏差校正项，扩展了半参数分析中使用的传统一步估计量。具体来说，对于每个数据点，我们估计原始非参数估计量的条件预期残差，例如，可以使用核（Nadaraya-Watson）回归计算，并将其作为偏差减少项。我们的理论分析表明，对于原始非参数估计量和条件预期残差估计量，所提出的估计量在温和的收敛率条件下实现了 $\sqrt{n}$ 一致性和渐近正态性。值得注意的是，只要原始估计量和条件预期残差估计量满足收敛率条件，这种方法就保持无模型性。所提出的方法具有几个优点，包括提高估计精度和简化置信区间的构造。]]></description>
      <guid>https://arxiv.org/abs/2411.11748</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>并行调节生成对抗网络</title>
      <link>https://arxiv.org/abs/2411.11786</link>
      <description><![CDATA[arXiv:2411.11786v1 公告类型：新
摘要：生成对抗网络 (GAN) 因其在捕获复杂数据生成过程方面的强大性能而成为生成人工智能 (AI) 中的代表性骨干模型。然而，GAN 训练以其臭名昭著的训练不稳定性而闻名，通常以模式崩溃的发生为特征。通过梯度方差的视角，这项工作特别分析了在模式崩溃的情况下训练的不稳定性和低效率，并将其与目标分布中的多模态联系起来。为了缓解严重的多模态性引起的训练问题，我们引入了一个新颖的 GAN 训练框架，该框架利用了一系列通过凸插值产生的调节分布。借助我们新开发的 GAN 目标函数，生成器可以同时学习所有调节分布，在概念上与统计学中的并行调节产生共鸣。我们的模拟研究表明，我们的方法优于现有的流行训练策略，无论是在图像还是表格数据合成方面。我们从理论上分析，通过使用缓和分布来减少梯度估计的方差可以实现这种显著的改进。最后，我们进一步开发了所提框架的一个变体，旨在生成公平的合成数据，这是可信 AI 领域日益增长的兴趣之一。]]></description>
      <guid>https://arxiv.org/abs/2411.11786</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于波动率预测的成对马尔可夫链</title>
      <link>https://arxiv.org/abs/2411.11838</link>
      <description><![CDATA[arXiv:2411.11838v1 公告类型：新
摘要：成对马尔可夫链 (PMC) 是一种概率图模型，扩展了众所周知的隐马尔可夫模型。尽管该模型对许多任务都非常有效，但很少用于连续值预测。这主要是由于生成概率模型固有的建模观察问题。在本文中，我们介绍了一种使用 PMC 进行预测的新算法。一方面，该算法可以规避特征问题，从而充分利用 PMC 的功能。另一方面，它使 PMC 能够通过引入隐藏状态（在每个时间步骤更新）来扩展任何预测模型，并允许为任何模型引入非平稳性。我们将 PMC 及其新算法应用于波动性预测，我们将其与众多对中非常流行的 GARCH(1,1) 和前馈神经模型进行了比较。考虑到我们可以观察到的波动性状态变化，这一点尤其重要。对于每种场景，我们的算法都增强了扩展模型的性能，证明了我们方法的价值。]]></description>
      <guid>https://arxiv.org/abs/2411.11838</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过潜在耦合因子松弛实现低秩最优传输</title>
      <link>https://arxiv.org/abs/2411.10555</link>
      <description><![CDATA[arXiv:2411.10555v1 公告类型：交叉 
摘要：最优传输 (OT) 是寻找概率分布之间最小成本传输计划或耦合的通用框架，在机器学习中有许多应用。将 OT 应用于海量数据集的一个关键挑战是耦合矩阵随数据集大小的二次缩放。[Forrow 等人，2019] 为 k-Wasserstein 重心问题引入了一种因子耦合，[Scetbon 等人，2021] 对其进行了调整，以解决原始低秩 OT 问题。我们基于先前由 [Lin 等人，2021] 推广 [Forrow 等人，2019] 引入的 $\textit{latent couple}$ (LC) 因子分解，推导出低秩问题的另一种参数化。LC 分解对低秩 OT 具有多种优势，包括将问题分解为三个 OT 问题以及更大的灵活性和可解释性。我们利用这些优势推导出一种新算法 $\textit{带潜在耦合的因子松弛}$ (FRLC)，该算法使用 $\textit{坐标}$ 镜像下降来计算 LC 因式分解。FRLC 以线性空间复杂度处理多个 OT 目标（Wasserstein、Gromov-Wasserstein、融合 Gromov-Wasserstein）和边际约束（平衡、不平衡和半松弛）。我们提供了 FRLC 的理论结果，并在各种应用（包括图形聚类和空间转录组学）上展示了卓越的性能，同时展示了其可解释性。]]></description>
      <guid>https://arxiv.org/abs/2411.10555</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>头部方向系统的简约表示模型</title>
      <link>https://arxiv.org/abs/2411.10596</link>
      <description><![CDATA[arXiv:2411.10596v1 公告类型：交叉 
摘要：我们提出了一种用于头部方向 (HD) 系统的简约表示模型，旨在学习一种能够捕捉 HD 细胞基本特性的头部方向高维表示。我们的模型是旋转群 $U(1)$ 的表示，我们研究了全连接版本和卷积版本。我们展示了高斯类调谐轮廓和 2D 圆几何在两个版本的模型中的出现。我们还证明了学习到的模型能够进行准确的路径集成。]]></description>
      <guid>https://arxiv.org/abs/2411.10596</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>吸引-排斥群集：通过力归一化和可调相互作用实现的 t-SNE 通用框架</title>
      <link>https://arxiv.org/abs/2411.10617</link>
      <description><![CDATA[arXiv:2411.10617v1 公告类型：交叉 
摘要：我们提出了一种基于吸引力-排斥力群集 (ARS) 动力学的新数据可视化方法，我们称之为 ARS 可视化。ARS 是一个通用框架，它基于将 t 分布随机邻居嵌入 (t-SNE) 可视化技术视为由吸引力和排斥力驱动的一群相互作用的代理。受群集最新发展的启发，我们修改了 t-SNE 动力学以包括 \emph{total influence} 的规范化，从而产生了更好的定态动力学，我们可以使用与数据大小无关的时间步长（$h=1$）和简单的迭代，而无需使用 t-SNE 中使用的一系列优化技巧。ARS 还包括单独调整吸引力和排斥力内核的能力，这使用户可以控制可视化中簇内的紧密度和簇之间的间距。
与 t-SNE 相比，我们提出的 ARS 数据可视化方法不是 Kullback-Leibler 散度上的梯度下降，而可以仅视为由吸引力和排斥力驱动的相互作用粒子系统。我们提供理论结果来说明相互作用核的选择如何影响动态，并提供实验结果来验证我们的方法并与 MNIST 和 Cifar-10 数据集上的 t-SNE 进行比较。]]></description>
      <guid>https://arxiv.org/abs/2411.10617</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从 KAT 到 KAN：Kolmogorov-Arnold 网络的回顾和神经网络的飞跃</title>
      <link>https://arxiv.org/abs/2411.10622</link>
      <description><![CDATA[arXiv:2411.10622v1 公告类型：交叉 
摘要：维数灾难对现代多层感知器架构构成了重大挑战，经常导致性能停滞和可扩展性问题。解决这一限制通常需要大量数据。相比之下，Kolmogorov-Arnold 网络因其大胆宣称不受维数灾难的影响而引起了机器学习界的关注。本文探讨了 Kolmogorov-Arnold 表示定理和 Kolmogorov-Arnold 网络背后的数学原理，这些原理使其在高维空间中具有可扩展性和高性能。我们首先介绍理解 Kolmogorov-Arnold 网络所必需的基础概念，包括插值方法和基样条，它们构成了它们的数学支柱。接下来是感知器架构和通用近似定理的概述，这是指导现代机器学习的关键原理。接下来，我们将概述 Kolmogorov-Arnold 表示定理，包括其数学公式和克服维数挑战的含义。接下来，我们将回顾 Kolmogorov-Arnold 网络的架构和误差缩放属性，展示这些网络如何真正摆脱维数灾难。最后，我们将讨论 Kolmogorov-Arnold 网络的实际可行性，重点介绍其独特功能使其在实际应用中脱颖而出的场景。本评论旨在深入了解 Kolmogorov-Arnold 网络在高维学习任务中重新定义可扩展性和性能的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.10622</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>抗漂移 TabPFN：基于上下文学习表格数据的时间分布变化</title>
      <link>https://arxiv.org/abs/2411.10634</link>
      <description><![CDATA[arXiv:2411.10634v1 公告类型：交叉 
摘要：虽然大多数 ML 模型都期望数据独立且分布相同，但由于分布变化，这一假设在现实世界中经常被违反，从而导致机器学习模型性能下降。到目前为止，没有一种表格方法能够始终优于忽略这些变化的传统监督学习。为了解决时间分布变化问题，我们提出了抗漂移 TabPFN，这是一种基于上下文学习的新方法，使用先验数据拟合网络来学习学习算法本身：它接受整个训练数据集作为输入，并在一次前向传递中对测试集进行预测。具体来说，它学习在从指定模型归纳偏差的先验中提取的合成数据集上近似贝叶斯推理。这个先验基于结构因果模型 (SCM)，它会随着时间的推移逐渐发生变化。为了模拟这些因果模型的变化，我们使用了辅助 SCM，它指定了主要模型参数的变化。由此产生的抗漂移 TabPFN 可应用于未见过的数据，在小型到中等规模的数据集上只需几秒即可运行，并且无需进行超参数调整。对 18 个合成数据集和真实数据集的综合评估表明，在广泛的基线（例如 XGB、CatBoost、TabPFN 和 Wild-Time 基准测试中的适用方法）上，性能得到了大幅提升。与最强的基线相比，它的准确率从 0.688 提高到 0.744，ROC AUC 从 0.786 提高到 0.832，同时保持了更强的校准性。这种方法可以为进一步研究分布外预测奠定重要基础。]]></description>
      <guid>https://arxiv.org/abs/2411.10634</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>