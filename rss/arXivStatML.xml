<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 30 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>全预测的近似最优算法</title>
      <link>https://arxiv.org/abs/2501.17205</link>
      <description><![CDATA[arXiv:2501.17205v2 公告类型：新
摘要：Omnipredictors 是简单的预测函数，它同时对假设类 $\mathcal{H}$ 中的每个损失函数编码损失最小化预测。在这项工作中，我们给出了在线和离线设置中全向预测的近乎最优的学习算法。首先，我们给出了一个 oracle 高效的在线学习算法，该算法实现了 $(\mathcal{L},\mathcal{H})$-全向预测，对于任何类 Lipschitz 损失函数 $\mathcal{L} \subseteq \mathcal{L}_\mathrm{Lip}$，遗憾值为 $\tilde{O}(\sqrt{T \log |\mathcal{H}|})$。令人惊讶的是，这个遗憾界限与 \emph{最小化单个损失函数} 的最佳遗憾相匹配（最高可达 $\sqrt{\log(T)}$ 因子）。鉴于这种在线算法，我们开发了一种在线到离线转换，可在多个指标上实现近乎最佳的复杂性。具体而言，对于有界变差损失 $\mathcal{L}_\mathrm{BV}$ 类中的所有有界损失函数（包括所有凸损失、所有 Lipschitz 损失和所有适当损失）和任何（可能为无限的）$\mathcal{H}$，我们获得一个离线学习算法，该算法利用（离线）ERM 预言机和来自 $\mathcal{D}$ 的 $m$ 个样本，返回一个有效的 $(\mathcal{L}_{\mathrm{BV}},\mathcal{H},\varepsilon(m))$-omnipredictor，对于 $\varepsilon(m)$，在 Rademacher 复杂度为 $\mathrm{Th} \circ \mathcal{H}$ 中近线性缩放。]]></description>
      <guid>https://arxiv.org/abs/2501.17205</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用生成神经网络测试条件均值独立性</title>
      <link>https://arxiv.org/abs/2501.17345</link>
      <description><![CDATA[arXiv:2501.17345v1 公告类型：新
摘要：条件均值独立性 (CMI) 测试对于统计任务至关重要，包括模型确定和变量重要性评估。在这项工作中，我们引入了一种新颖的总体 CMI 测量和一种基于引导的测试程序，该程序利用深度生成神经网络来估计总体测量中涉及的条件均值函数。测试统计量经过深思熟虑的构建，以确保即使缓慢衰减的非参数估计误差也不会影响测试的渐近精度。我们的方法在具有高维协变量和响应变量的场景中表现出强大的经验性能，可以处理多变量响应，并在零假设的 $n^{-1/2}$ 邻域之外保持对局部替代方案的非平凡能力。我们还使用数值模拟和真实世界图像数据应用程序来强调我们的测试程序的有效性和多功能性。]]></description>
      <guid>https://arxiv.org/abs/2501.17345</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于集群的联邦学习综述</title>
      <link>https://arxiv.org/abs/2501.17512</link>
      <description><![CDATA[arXiv:2501.17512v1 公告类型：新
摘要：随着联邦学习 (FL) 的工业和商业用途的扩大，对优化算法的需求也在不断增长。
在 FL 客户端的数据非独立同分布 (non-IID) 且分布高度异构的环境中，基线 FL 方法似乎不足。为了解决这个问题，最近的研究调查了个性化 FL (PFL)，它放宽了隐式单模型约束并允许从数据或本地模型中学习多个假设。在个性化 FL 方法中，基于集群的解决方案 (CFL) 特别有趣，只要通过领域知识可以清楚地将客户端分成几组。
在本文中，我们研究了最近关于 CFL 的作品，提出：i) 对个性化 CFL 解决方案进行分类；ii) 结构化文献综述 iii) 对 CFL 替代用例的回顾。CCS 概念：$\bullet$ 一般和参考 $\rightarrow$ 调查和概述； $\bullet$ 计算方法 $\rightarrow$ 机器学习；$\bullet$ 信息系统 $\rightarrow$ 聚类；$\bullet$ 安全和隐私 $\rightarrow$ 隐私保护协议。]]></description>
      <guid>https://arxiv.org/abs/2501.17512</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多目标赌博机的帕累托前沿顺序学习</title>
      <link>https://arxiv.org/abs/2501.17513</link>
      <description><![CDATA[arXiv:2501.17513v1 公告类型：新
摘要：我们研究多目标多臂老虎机中帕累托前沿的顺序学习问题。代理面临 K 个可能的臂。每次她都会选择一个，并获得一个向量值奖励。当她认为自己有足够的信息来识别不同臂均值的帕累托前沿时，她会停止游戏并给出答案。我们感兴趣的是设计算法，使得给出的答案至少以 1-$\delta$ 的概率正确。我们的主要贡献是高效实现一种算法，当风险 $\delta$ 较小时，该算法可实现最佳样本复杂度。如果 d 维中有 K 个臂，其中 p 在帕累托集中，则该算法每轮运行时间为 O(Kp^d)。]]></description>
      <guid>https://arxiv.org/abs/2501.17513</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>指数族分布的{\epsilon}-安全决策区域的精确表征和多成本 SVM 近似</title>
      <link>https://arxiv.org/abs/2501.17731</link>
      <description><![CDATA[arXiv:2501.17731v1 公告类型：新
摘要：数据驱动分类器的预测的概率保证对于定义可视为可靠的模型是必要的。这是现代机器学习的一项关键要求，其中系统的优劣以可信度来衡量，明确划分安全与不安全。本文的精神正是朝着这个方向发展。首先，我们引入了{\epsilon}-安全决策区域的正式定义，它是输入空间的一个子集，其中目标（安全）类的预测是概率保证的。其次，我们证明，当数据来自指数族分布时，这种区域的形式由设计参数（即对目标类进行采样的概率和对预测的置信度）通过分析确定和控制。但是，拥有指数数据的要求并不总是可能的。受此限制的启发，我们开发了多成本 SVM，这是一种基于 SVM 的算法，可以近似安全区域，并且还能够处理不平衡数据。该研究通过实验和代码进行补充，以提高可重复性。]]></description>
      <guid>https://arxiv.org/abs/2501.17731</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索非凸离散能量景观：具有副本交换的朗之万类采样器</title>
      <link>https://arxiv.org/abs/2501.17323</link>
      <description><![CDATA[arXiv:2501.17323v1 公告类型：交叉 
摘要：基于梯度的离散采样器 (GDS) 可有效采样离散能量景观。然而，它们在复杂的非凸设置中经常停滞不前。为了改进探索，我们引入了离散副本交换朗之万 (DREXEL) 采样器及其带有调整大都市 (DREAM) 的变体。这些采样器使用两个不同温度和步长大小的 GDS：一个专注于局部开发，而另一个探索更广泛的能量景观。当能量差异很大时，会发生样本交换，这由为离散采样量身定制的机制决定，以确保细节平衡。从理论上讲，我们证明 DREXEL 和 DREAM 都渐近收敛到目标能量，并且比单个 GDS 表现出更快的混合速度。实验进一步证实了它们在探索非凸离散能量景观方面的效率。]]></description>
      <guid>https://arxiv.org/abs/2501.17323</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CardiCat：用于高基数表格数据的变分自动编码器</title>
      <link>https://arxiv.org/abs/2501.17324</link>
      <description><![CDATA[arXiv:2501.17324v1 公告类型：交叉 
摘要：高基数分类特征是混合类型表格数据集的共同特征。现有的生成模型架构难以大规模学习此类数据的复杂性，主要是因为难以参数化分类特征。在本文中，我们提出了一种通用变分自动编码器模型 CardiCat，它可以准确地拟合不平衡的高基数和异构表格数据。我们的方法用联合学习的正则化双编码器-解码器嵌入层代替独热编码。这种方法使我们能够使用也依赖于其他协变量的嵌入，从而实现紧凑且同质化的分类特征参数化。我们的模型采用的可训练参数空间比竞争方法小得多，从而能够大规模学习。与竞争 VAE 模型相比，CardiCat 可以生成高质量的合成数据，更好地表示高基数和不平衡特征，适用于多个真实和模拟数据集。]]></description>
      <guid>https://arxiv.org/abs/2501.17324</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将联邦 ADMM 连接至贝叶斯</title>
      <link>https://arxiv.org/abs/2501.17325</link>
      <description><![CDATA[arXiv:2501.17325v1 公告类型：交叉 
摘要：我们基于 (i) ADMM 和 (ii) 变分贝叶斯 (VB) 为两种不同的联邦学习方法提供了新的联系，并通过结合它们的互补优势提出了新的变体。具体而言，我们表明 ADMM 中的对偶变量通过 VB 中使用的具有各向同性高斯协方差的“站点”参数自然出现。利用这一点，我们从 VB 中推导出两个版本的 ADMM，分别使用灵活的协方差和函数正则化。通过数值实验，我们验证了性能上的改进。这项工作展示了两个被认为根本不同的领域之间的联系，并将它们结合起来以改进联邦学习。]]></description>
      <guid>https://arxiv.org/abs/2501.17325</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>追求不变因果预测和不变引导正则化的基本计算极限</title>
      <link>https://arxiv.org/abs/2501.17354</link>
      <description><![CDATA[arXiv:2501.17354v1 公告类型：交叉 
摘要：从异构环境中寻求不变预测为以纯数据驱动的方式学习因果关系打开了大门，并且在因果发现和稳健迁移学习中有许多应用。然而，现有的可以实现样本高效估计的方法，如 ICP [Peters et al., 2016] 和 EILLS [Fan et al., 2024]，都是基于指数时间算法。在本文中，我们表明，这样的问题本质上在计算上很难：决策问题，即测试两个环境中是否存在非平凡的预测不变解，即使对于线性因果关系也是 NP 难的。在 P$\neq$NP 的世界中，我们的结果意味着使用任何计算效率高的算法，估计误差率都可以任意慢。这表明，在没有预先假设的情况下，追寻因果关系从根本上比检测关联更难。
鉴于在最坏情况下几乎没有希望实现计算改进，本文提出了一种能够在附加条件下实现计算和统计上高效估计的方法。此外，我们的估计量是一个分布稳健的估计量，具有椭圆形不确定集，其中更多的不确定性放在伪方向上而不是不变方向上，通过改变不变超参数，在最具预测性的解和因果解之间实现平滑插值。非渐近结果和实证应用支持这一说法。]]></description>
      <guid>https://arxiv.org/abs/2501.17354</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>si4onnx：用于深度学习模型中选择性推理的 Python 包</title>
      <link>https://arxiv.org/abs/2501.17415</link>
      <description><![CDATA[arXiv:2501.17415v1 公告类型：交叉 
摘要：在本文中，我们介绍了 si4onnx，这是一个用于对深度学习模型执行选择性推理的包。XAI 中的 CAM 和使用 VAE 的基于重建的异常检测等技术可以解释为识别输入图像中重要区域的方法。然而，所识别的区域可能并不总是具有有意义的意义。因此，评估这些区域的统计意义是建立 AI 系统可靠性的关键挑战。si4onnx 是一个 Python 包，它可以通过选择性推理直接实现具有受控 I 型错误率的假设检验。它与使用 PyTorch 和 TensorFlow 等常见框架构建的深度学习模型兼容。]]></description>
      <guid>https://arxiv.org/abs/2501.17415</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过神经映射缩小合成时间序列分布与地面真实时间序列分布之间的差距</title>
      <link>https://arxiv.org/abs/2501.17553</link>
      <description><![CDATA[arXiv:2501.17553v1 公告类型：交叉 
摘要：在本文中，我们介绍了用于矢量量化时间序列生成器的神经映射器 (NM-VQTSG)，这是一种旨在解决矢量量化 (VQ) 时间序列生成中的保真度挑战的新方法。基于 VQ 的方法（例如 TimeVQVAE）已证明在生成时间序列方面取得了成功，但受到两个关键瓶颈的阻碍：压缩到离散潜在空间期间的信息丢失以及学习到的先验分布与地面真实分布的偏差。这些挑战导致合成时间序列的保真度和分布准确性受损。为了克服这些限制，NM-VQTSG 利用基于 U-Net 的神经映射模型来弥合合成和地面真实时间序列之间的分布差距。更具体地说，该模型通过解决生成过程中引入的伪影来细化合成数据，从而有效地调整合成数据和真实数据的分布。重要的是，NM-VQTSG 可用于任何基于 VQ 的生成方法生成的合成时间序列。我们在 UCR 时间序列分类档案中的各种数据集上评估了 NM-VQTSG，证明了其在无条件和条件生成任务中持续提高保真度的能力。FID、IS 和条件 FID 的显著改进证明了这些改进，此外，数据空间和潜在空间中的视觉检查也支持了这些改进。我们的研究结果确立了 NM-VQTSG 是一种提高合成时间序列质量的新方法。我们的实现可在 \url{https://github.com/ML4ITS/TimeVQVAE} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2501.17553</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分布式医疗数据库中的联邦学习：大规模皮层下脑数据的元分析</title>
      <link>https://arxiv.org/abs/1810.08553</link>
      <description><![CDATA[arXiv:1810.08553v4 公告类型：替换 
摘要：目前，全球数据库中包含的大脑图像数量之多前所未有。结合数据科学的发展，这些海量数据为更好地了解脑部疾病的遗传基础提供了潜力。然而，由于隐私和法律问题，存储在不同机构的不同数据集不能总是直接共享，从而限制了大数据在脑部疾病研究中的充分利用。在这里，我们提出了一个联合学习框架，用于安全地访问和荟萃分析任何生物医学数据，而无需共享个人信息。我们通过研究疾病和临床队列之间的大脑结构关系来说明我们的框架。该框架首先在合成数据上进行测试，然后应用于多中心、多数据库研究，包括 ADNI、PPMI、MIRIAD 和英国生物库，展示了该方法在多中心队列分布式分析中进一步应用的潜力]]></description>
      <guid>https://arxiv.org/abs/1810.08553</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用均值中位数估计量的基于狄利克雷过程的稳健聚类</title>
      <link>https://arxiv.org/abs/2311.15384</link>
      <description><![CDATA[arXiv:2311.15384v2 公告类型：替换 
摘要：聚类是无监督机器学习中最突出的挑战之一。在基于质心的方法中，基于 Lloyd 启发式的经典 $k$-means 算法被广泛使用。尽管如此，众所周知，$k$-means 及其变体面临着几个挑战，包括严重依赖初始聚类质心、容易收敛到目标函数的局部最小值以及对数据中的异常值和噪声的敏感性。当数据包含噪声或异常值时，中位数 (MoM) 估计量为稳定基于质心的方法提供了一种强大的替代方案。另一方面，许多常用聚类方法的另一个限制是需要事先指定聚类的数量。基于模型的方法，例如贝叶斯非参数模型，通过结合无限混合模型来解决此问题，从而消除了对预定义聚类计数的要求。受这些事实的启发，我们在本文中提出了一种高效且自动化的聚类技术，该技术结合了基于模型和基于质心的方法的优势。我们的方法减轻了噪声对聚类质量的影响；同时，还估算了聚类的数量。对聚类误差上限的统计保证以及通过模拟和真实数据集进行的严格评估表明，我们提出的方法比现有的最先进的聚类算法更具优势。]]></description>
      <guid>https://arxiv.org/abs/2311.15384</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>特征重要性排名的统计意义</title>
      <link>https://arxiv.org/abs/2401.15800</link>
      <description><![CDATA[arXiv:2401.15800v3 公告类型：替换 
摘要：特征重要性得分是理解机器学习模型预测的普遍工具。然而，许多流行的归因方法由于随机抽样而存在高度不稳定性。利用假设检验的新思想，我们设计出确保最重要的特征以高概率保证正确的技术。这些评估了 $K$ 个排名靠前的特征集及其元素的顺序。给定一组局部或全局重要性分数，我们演示了如何回顾性地验证最高排名的稳定性。然后，我们介绍了两种有效的抽样算法，这些算法可以按顺序识别 $K$ 个最重要的特征，概率超过 $1-\alpha$。这些程序的理论依据在 SHAP 和 LIME 上得到了实证验证。]]></description>
      <guid>https://arxiv.org/abs/2401.15800</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 SPDE 先验进行不确定性量化的神经变分数据同化</title>
      <link>https://arxiv.org/abs/2402.01855</link>
      <description><![CDATA[arXiv:2402.01855v3 公告类型：替换 
摘要：大型地球物理数据集的时空插值历来由最佳插值 (OI) 和更复杂的基于方程或数据驱动的数据同化 (DA) 技术解决。深度学习社区的最新进展使得能够通过结合变分数据同化框架的神经架构来解决插值问题。重建任务被视为涉及变分内部成本的先验的联合学习问题，被视为状态的投影算子，以及后者的基于梯度的最小化。先验模型和求解器都被表述为具有自动微分的神经网络，可以通过最小化损失函数来训练，通常是某些地面实况和重建之间的均方误差。这种策略对于改进平均状态估计非常有效，但仍需要补充发展来量化其相关的不确定性。在这项工作中，我们使用随机偏微分方程 (SPDE) 和高斯过程 (GP) 理论来估计状态的空间和时间变化协方差。我们的神经变分方案经过修改，嵌入了增强状态公式，同时使用状态和 SPDE 参数化进行估计。我们展示了所提出的框架在由基于扩散的各向异性驱动的时空 GP 和真实的海面高度 (SSH) 数据集上的潜力。我们展示了我们的解决方案如何在高斯情况下达到 OI 基线。对于非线性动力学，正如 DA 中几乎总是提到的那样，我们的解决方案优于 OI，同时允许快速且可解释的在线参数估计。]]></description>
      <guid>https://arxiv.org/abs/2402.01855</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>