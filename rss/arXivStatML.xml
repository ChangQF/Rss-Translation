<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 09 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>学习非齐次时间泊松过程的泛化和正则化</title>
      <link>https://arxiv.org/abs/2402.12808</link>
      <description><![CDATA[arXiv:2402.12808v2 公告类型：replace-cross 
摘要：泊松过程，尤其是非齐次泊松过程 (NHPP)，是一种非常重要的计数过程，具有众多实际应用。到目前为止，文献中几乎所有的研究都是使用非数据驱动的分箱方法对无限数据的 NHPP 进行估计。在本文中，我们将从有限和有限数据中估计 NHPP 的问题表述为学习泛化问题。我们用数学方法表明，虽然分箱方法对于估计 NHPP 至关重要，但当数据量有限时，它们会带来过度拟合的威胁。我们提出了一个 NHPP 正则化学习框架，该框架采用了两种新的自适应和数据驱动的分箱方法，有助于消除分箱参数的临时调整。我们的方法在合成和真实世界的数据集上进行了实验测试，结果表明了它们的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.12808</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:32 GMT</pubDate>
    </item>
    <item>
      <title>稀缺之路</title>
      <link>https://arxiv.org/abs/2405.15682</link>
      <description><![CDATA[arXiv:2405.15682v3 公告类型：replace-cross 
摘要：现有的学习率计划不需要指定优化停止步骤 T，而依赖于 T 的学习率计划的表现则远远优于后者。我们提出了一种方法，通过完全避免使用计划来避免这种停止时间的需要，同时与从凸问题到大规模深度学习问题的广泛问题系列中的计划相比，表现出最先进的性能。与具有动量的标准优化器相比，我们的无计划方法不会引入额外的超参数。我们的方法是我们开发的一种统一调度和迭代平均的新理论的直接结果。我们方法的开源实现可用（https://github.com/facebookresearch/schedule_free）。]]></description>
      <guid>https://arxiv.org/abs/2405.15682</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:32 GMT</pubDate>
    </item>
    <item>
      <title>具有因果关系约束和结构信息的分布稳健风险评估</title>
      <link>https://arxiv.org/abs/2203.10571</link>
      <description><![CDATA[arXiv:2203.10571v4 公告类型：replace-cross 
摘要：本研究研究了时间数据上期望值的分布稳健评估。一组替代度量以因果最优传输为特征。我们证明了强对偶性，并将因果约束重铸为无限维测试函数空间上的最小化。我们通过神经网络近似测试函数，并证明样本复杂度具有 Rademacher 复杂度。给出了一个例子来验证技术假设的可行性。此外，当结构信息可用于进一步限制模糊集时，我们证明了对偶公式并提供了有效的优化方法。我们的框架在分布稳健的投资组合选择问题中优于经典框架。我们还通过数值研究了与朴素策略的联系。]]></description>
      <guid>https://arxiv.org/abs/2203.10571</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:31 GMT</pubDate>
    </item>
    <item>
      <title>连接置换等变神经网络和分区图</title>
      <link>https://arxiv.org/abs/2212.08648</link>
      <description><![CDATA[arXiv:2212.08648v3 公告类型：replace-cross 
摘要：置换等变神经网络通常使用 $\mathbb{R}^{n}$ 的张量幂作为其层空间来构建。我们表明，这些神经网络中出现的所有权重矩阵都可以从对称群和分区代数之间的 Schur-Weyl 对偶中获得。特别是，我们采用 Schur-Weyl 对偶来推导出一种简单的图解方法来计算权重矩阵本身。]]></description>
      <guid>https://arxiv.org/abs/2212.08648</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:31 GMT</pubDate>
    </item>
    <item>
      <title>随机森林中的预测误差估计</title>
      <link>https://arxiv.org/abs/2309.00736</link>
      <description><![CDATA[arXiv:2309.00736v4 公告类型：替换 
摘要：本文定量评估了分类随机森林的误差估计。基于 Bates 等人 (2023) 建立的初始理论框架，在随机森林常见的各种误差估计方法的背景下，对真实错误率和预期错误率进行了理论和实证研究。我们表明，在分类情况下，随机森林的预测误差估计平均更接近真实错误率，而不是平均预测误差。这与 Bates 等人 (2023) 针对逻辑回归的发现相反。我们进一步表明，我们的结果适用于不同的误差估计策略，例如交叉验证、装袋和数据拆分。]]></description>
      <guid>https://arxiv.org/abs/2309.00736</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:30 GMT</pubDate>
    </item>
    <item>
      <title>通过凸松弛到单纯形进行图匹配</title>
      <link>https://arxiv.org/abs/2310.20609</link>
      <description><![CDATA[arXiv:2310.20609v2 公告类型：替换 
摘要：本文讨论了图匹配问题，该问题包括寻找两个输入图之间的最佳对齐方式，在计算机视觉、网络去匿名化和蛋白质对齐方面有许多应用。解决这个问题的常用方法是通过 NP-hard \emph{二次分配问题} (QAP) 的凸松弛。
在这里，我们在单位单纯形上引入了一种新的凸松弛，并开发了一种有效的镜像下降方案，该方案具有闭式迭代来解决这个问题。在相关高斯维格纳模型下，我们表明单纯形松弛以高概率允许唯一解。在无噪声情况下，这表明可以精确恢复基本事实排列。此外，我们在标准贪婪舍入方法中为输入矩阵建立了一个新的充分性条件，该条件比常用的“对角优势”条件限制更少。我们利用此条件在无噪声环境下通过镜像下降方案精确地一步恢复基本事实（几乎肯定成立）。我们还利用此条件在无噪声环境下显著改善了 GRAMPA 算法 [Fan et al. 2019] 的条件。]]></description>
      <guid>https://arxiv.org/abs/2310.20609</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:30 GMT</pubDate>
    </item>
    <item>
      <title>估计最大均值的置信上限方法</title>
      <link>https://arxiv.org/abs/2408.04179</link>
      <description><![CDATA[arXiv:2408.04179v1 公告类型：交叉 
摘要：估计最大均值在实践中有多种应用。在本文中，我们研究使用置信上限 (UCB) 方法估计最大均值，其中采样预算自适应地分配给其中一个系统。我们深入研究了现有的总平均值 (GA) 估计量，并提出了一种新的最大均值 (LSA) 估计量。具体而言，我们为这两个估计量建立了统计保证，包括强一致性、渐近均方误差和中心极限定理 (CLT)，这些对于文献来说都是新的。我们表明 LSA 优于 GA，因为当样本量增加时，前者的偏差衰减速度比后者快得多。通过使用 CLT，我们进一步为最大均值构建渐近有效的置信区间，并提出了一种用于临床试验的多重比较问题的单一假设检验。通过数值例子证明了所得点和区间估计以及提出的单一假设检验的统计效率。]]></description>
      <guid>https://arxiv.org/abs/2408.04179</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:29 GMT</pubDate>
    </item>
    <item>
      <title>多项式神经网络的激活阈值和表达能力</title>
      <link>https://arxiv.org/abs/2408.04569</link>
      <description><![CDATA[arXiv:2408.04569v1 公告类型：交叉 
摘要：多项式神经网络已在一系列应用中实现，并为理论机器学习提供了一个有利的框架。具有固定架构和激活度的多项式神经网络给出了从网络权重到一组多项式的代数映射。此映射的图像是网络可表示的函数空间。它的 Zariski 闭包是一种称为神经变体的仿射变体。多项式神经网络神经变体的维度提供了其表达能力的度量。在这项工作中，我们引入了网络架构激活阈值的概念，该阈值表示神经变体的维度何时达到其理论最大值。此外，我们证明了具有等宽架构的多项式神经网络的表达能力结果。]]></description>
      <guid>https://arxiv.org/abs/2408.04569</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:29 GMT</pubDate>
    </item>
    <item>
      <title>动态拉普拉斯算子教程</title>
      <link>https://arxiv.org/abs/2408.04149</link>
      <description><![CDATA[arXiv:2408.04149v1 公告类型：交叉 
摘要：谱技术是流行且可靠的数据分析方法。一个突出的例子是使用由数据亲和性构建的拉普拉斯算子的特征向量来识别自然数据分组或聚类，或生成位于流形上的数据的简化表示。本教程涉及动态拉普拉斯算子，它是拉普拉斯算子的自然泛化，用于处理具有时间分量并位于随时间演化的流形上的数据。在这种动态设置中，聚类对应于长寿命的“连贯”集合。在描述动态泛化之前，我们首先对谱几何进行简单回顾。我们还讨论了计算方法以及通过 SEBA 算法自动分离许多不同特征。本教程的目的是将动态拉普拉斯算子文献中的许多结果汇总成一个简短的文档，以易于理解的风格编写。]]></description>
      <guid>https://arxiv.org/abs/2408.04149</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:28 GMT</pubDate>
    </item>
    <item>
      <title>数据添加难题</title>
      <link>https://arxiv.org/abs/2408.04154</link>
      <description><![CDATA[arXiv:2408.04154v1 公告类型：交叉 
摘要：在许多用于医疗保健任务的机器学习中，标准数据集是通过收集许多通常根本不相似的来源的数据来构建的。但是，在现实环境中，添加更多数据何时有帮助，何时会阻碍期望的模型结果的进展？我们将这种情况定义为 \textit{数据添加困境}，表明在这种多源扩展环境中添加训练数据有时会导致整体准确性降低、公平性结果不确定以及最差子组性能下降。我们发现，这可能是由于数据扩展导致的模型性能改进与分布偏移导致的模型性能下降之间的经验观察到的权衡。因此，我们建立了解决这一困境的基线策略，引入分布偏移启发式方法来指导决策在数据扩展中添加哪些数据源，以产生预期的模型性能改进。最后，我们讨论了数据收集需要考虑的事项，并提出了在模型日益庞大的时代研究数据组成和规模的建议。]]></description>
      <guid>https://arxiv.org/abs/2408.04154</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:28 GMT</pubDate>
    </item>
    <item>
      <title>使用置信上限算法进行推理</title>
      <link>https://arxiv.org/abs/2408.04595</link>
      <description><![CDATA[arXiv:2408.04595v1 公告类型：新
摘要：在本文中，我们讨论了多臂老虎机问题中上置信界 (UCB) 算法的渐近行为，并讨论了其在下游推理任务中的含义。虽然当以顺序方式收集数据时，推理任务变得具有挑战性，但我们认为，当手头的顺序算法满足某些稳定性属性时，可以缓解此问题。这种稳定性概念源自 Lai 和 Wei (1982) 的开创性工作。我们的第一个主要结果表明，UCB 算法始终满足这种稳定性属性，因此每个臂的样本均值都是渐近正态的。接下来，当允许臂数 $K$ 随着臂拉动次数 $T$ 增加时，我们检查 UCB 算法的稳定性。我们表明，在这种情况下，当 $\frac{\log K}{\log T} \rightarrow 0$ 时，臂是稳定的，并且接近最优臂的数量很大。]]></description>
      <guid>https://arxiv.org/abs/2408.04595</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:27 GMT</pubDate>
    </item>
    <item>
      <title>相关样本岭回归中的风险与交叉验证</title>
      <link>https://arxiv.org/abs/2408.04607</link>
      <description><![CDATA[arXiv:2408.04607v1 公告类型：新
摘要：近年来，我们对高维岭回归的理解取得了长足的进步，但现有理论假设训练示例是独立的。通过利用随机矩阵理论和自由概率的最新技术，当数据点具有任意相关性时，我们为岭回归的样本内和样本外风险提供了尖锐的渐近线。我们证明，在这种情况下，广义交叉验证估计量 (GCV) 无法正确预测样本外风险。然而，在噪声残差与数据点具有相同相关性的情况下，可以修改 GCV 以产生一个高效可计算的无偏估计量，该估计量集中在高维极限中，我们将其称为 CorrGCV。我们进一步将渐近分析扩展到测试点与训练集具有非平凡相关性的情况，这是时间序列预测中经常遇到的情况。假设了解时间序列的相关结构，这又会扩展 GCV 估计量，并明确描述此类测试点对长期风险的过度乐观预测程度。我们通过各种高维数据验证了我们理论的预测。]]></description>
      <guid>https://arxiv.org/abs/2408.04607</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:27 GMT</pubDate>
    </item>
    <item>
      <title>混合强化学习打破了线性 MDP 中的样本大小障碍</title>
      <link>https://arxiv.org/abs/2408.04526</link>
      <description><![CDATA[arXiv:2408.04526v1 公告类型：新
摘要：混合强化学习 (RL)，即代理从未知环境中的离线数据集和在线探索中学习，最近引起了广泛关注。Xie 等人 (2022) 提出的一个关键问题是，混合 RL 是否可以在不依赖单策略集中性假设的情况下改进纯离线和纯在线 RL 中建立的现有下限。虽然 Li 等人 (2023) 在表格 PAC RL 案例中对这个问题给出了肯定的答案，但对于遗憾最小化 RL 案例和非表格案例，这个问题仍未解决。
在这项工作中，基于离线 RL 和奖励不可知探索的最新进展，我们为 PAC 和遗憾最小化 RL 开发了计算效率高的算法，具有线性函数近似，没有单策略集中性。我们证明，这些算法实现了更精确的错误或遗憾界限，这些界限不比线性马尔可夫决策过程 (MDP) 中的离线 RL（第一种算法，用于 PAC RL）和在线 RL（第二种算法，用于遗憾最小化 RL）中的最佳样本复杂度差，并且可以改进，无论行为策略的质量如何。据我们所知，这项工作为线性 MDP 中的混合 RL 建立了目前最严格的理论保证。]]></description>
      <guid>https://arxiv.org/abs/2408.04526</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:26 GMT</pubDate>
    </item>
    <item>
      <title>为每个用户提供多个样本，实现更好的局部隐私稀疏估计</title>
      <link>https://arxiv.org/abs/2408.04313</link>
      <description><![CDATA[arXiv:2408.04313v1 公告类型：新
摘要：先前的研究对于具有 $s^*$ 稀疏性假设的项目级局部差分隐私线性回归产生了令人沮丧的结果，其中 $nm$ 个样本的极小最大率为 $\mathcal{O}(s^{*}d / nm\varepsilon^2)$。这对于高维数据来说可能具有挑战性，因为维度 $d$ 非常大。在这项工作中，我们研究了用户级局部差分隐私稀疏线性回归。我们表明，当 $n$ 个用户各自贡献 $m$ 个样本时，可以消除维度 $d$ 的线性依赖性，从而产生 $\mathcal{O}(s^{*2} / nm\varepsilon^2)$ 的误差上界。我们提出了一个框架，首先选择候选变量，然后在缩小的低维空间中进行估计，该框架可扩展到具有严格误差界限的一般稀疏估计问题。在合成数据集和真实数据集上的实验证明了所提方法的优越性。理论和实证结果均表明，在样本数量相同的情况下，当每个用户有多个样本可用时，局部隐私稀疏估计的效果会更好。]]></description>
      <guid>https://arxiv.org/abs/2408.04313</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:25 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型评估质量指标的稳健性调查</title>
      <link>https://arxiv.org/abs/2408.04391</link>
      <description><![CDATA[arXiv:2408.04391v1 公告类型：新
摘要：本文研究了用于评估机器学习模型的质量度量的准确性和稳健性。基于交叉验证方法独立于模型地评估机器学习模型的预测质量，其中估计未知数据的近似误差。所提出的度量量化了模型预测中解释的变化量。通过几个数值示例评估这些度量的可靠性，其中提供了用于验证估计预测误差的附加数据集。此外，估计了所提出的质量度量的置信界限，并从交叉验证方法获得的预测残差中得出局部质量度量。]]></description>
      <guid>https://arxiv.org/abs/2408.04391</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:25 GMT</pubDate>
    </item>
    </channel>
</rss>