<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 15 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过可微分扩散桥重要性抽样进行参数推断</title>
      <link>https://arxiv.org/abs/2411.08993</link>
      <description><![CDATA[arXiv:2411.08993v1 公告类型：新
摘要：我们介绍了一种在高维非线性扩散过程中执行参数推断的方法。我们说明了它在了解物种进化和物种间关系（包括祖先状态重建）方面的适用性。估计是通过利用分数匹配来近似扩散桥进行的，随后在重要性采样器中使用这些扩散桥来估计对数似然。整个设置是可微的，允许在近似对数似然上进行梯度上升。这允许参数推断和扩散均值估计。这种新颖的、数值稳定的、基于分数匹配的参数推断框架在生物二维和三维形态测量数据上进行了展示和演示。]]></description>
      <guid>https://arxiv.org/abs/2411.08993</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>战略预测的微观基础推断</title>
      <link>https://arxiv.org/abs/2411.08998</link>
      <description><![CDATA[arXiv:2411.08998v1 公告类型：新
摘要：在预测任务中，预测模型本身通常会影响目标变量的分布，这种现象称为性能预测。通常，这种影响源于对预测模型有既得利益的利益相关者采取的战略行动。阻碍性能预测在机器学习中广泛应用的一个关键挑战是，从业者通常不知道他们的预测的社会影响。为了解决这一差距，我们提出了一种学习分布图的方法，该方法涵盖了预测模型对人口的长期影响。具体而言，我们将代理的响应建模为成本调整后的效用最大化问题，并提出该成本的估计值。我们的方法利用最佳传输来对齐模型前暴露（事前）和模型后暴露（事后）分布。我们为该建议估计提供了收敛率，并通过对信用评分数据集的实证演示来评估其质量。]]></description>
      <guid>https://arxiv.org/abs/2411.08998</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>局部差分隐私下的极小极大最优双样本测试</title>
      <link>https://arxiv.org/abs/2411.09064</link>
      <description><![CDATA[arXiv:2411.09064v1 公告类型：新
摘要：我们探索在局部差分隐私 (LDP) 下针对多项式和连续数据的隐私双样本测试中隐私和统计效用之间的权衡。我们首先解决多项式的情况，其中我们使用实用的隐私机制（例如拉普拉斯、离散拉普拉斯和 Google 的 RAPPOR）引入隐私置换测试。然后，我们通过分箱将多项式方法扩展到连续数据，并研究其在 LDP 下对 H\&quot;older 和 Besov 平滑类的均匀分离率。针对离散和连续情况的所提出的测试严格控制任何有限样本大小的 I 型错误，严格遵守 LDP 约束，并在 LDP 下实现极小最大分离率。所达到的极小最大率揭示了私人测试中不可避免的固有隐私效用权衡。为了解决密度测试中平滑度参数未知的情况，我们提出了一种基于 Bonferroni 型方法的自适应测试，该方法可在不事先了解平滑度参数的情况下确保稳健的性能。我们通过大量数值实验验证了我们的理论发现，并证明了我们提出的方法的实际相关性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.09064</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合深度加性神经网络</title>
      <link>https://arxiv.org/abs/2411.09175</link>
      <description><![CDATA[arXiv:2411.09175v1 公告类型：新
摘要：传统神经网络（多层感知器）因其在广泛任务中的成功而成为数据科学中的重要工具。然而，它们的性能有时并不令人满意，而且它们通常需要大量参数，这主要是因为它们依赖于线性组合结构。同时，加法回归一直是统计学中线性回归的流行替代方案。在这项工作中，我们引入了结合加法回归思想的新型深度神经网络。我们的神经网络与 Kolmogorov-Arnold 网络具有架构相似性，但基于更简单但灵活的激活和基函数。此外，我们引入了几种将这种架构与传统神经网络相结合的混合神经网络。我们推导出它们的通用近似性质，并通过模拟研究和实际数据应用证明了它们的有效性。数值结果表明，我们的神经网络在使用更少参数的情况下通常比传统神经网络实现更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.09175</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>压缩感知的稀疏贝叶斯生成模型</title>
      <link>https://arxiv.org/abs/2411.09483</link>
      <description><![CDATA[arXiv:2411.09483v1 公告类型：新
摘要：这项工作通过引入一种新型的正则化生成先验来解决压缩感知 (CS) 中的基本线性逆问题。我们提出的方法利用了经典的基于字典的 CS 的思想，特别是稀疏贝叶斯学习 (SBL)，将强正则化集成到稀疏解中。同时，通过利用条件高斯性的概念，它还结合了生成模型对训练数据的适应性。然而，与大多数最先进的生成模型不同，它能够从一些压缩和嘈杂的数据样本中学习，并且不需要优化算法来解决逆问题。此外，与狄利克雷先验网络类似，我们的模型参数化了共轭先验，使其能够应用于不确定性量化。我们通过变分推理的概念在理论上支持我们的方法，并使用不同类型的可压缩信号对其进行实证验证。]]></description>
      <guid>https://arxiv.org/abs/2411.09483</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>治疗前后重复测量随机对照试验疗效事实估计的反事实不确定性量化</title>
      <link>https://arxiv.org/abs/2411.09635</link>
      <description><![CDATA[arXiv:2411.09635v1 公告类型：新
摘要：比较新治疗 $Rx$ 与对照 $C$ 的理想估计量是 $\textit{反事实}$ 疗效 $Rx:C$，即如果每位患者均接受 $\textit{both}$ 治疗，则 $Rx$ 和 $C$ 之间的预期差异结果。虽然已经可以从 $\textit{factual}$ 随机对照试验 (RCT) 中获得反事实 $\textit{点估计}$，但本文表明，在反事实设置中量化事实点估计的不确定性的 $\textit{反事实}$ 不确定性量化 (CUQ) 令人惊讶地可以实现。我们通过创建一种新的统计建模原理 ETZ 实现了 CUQ，其变异性通常小于事实 UQ，该原理适用于具有 $\textit{前后}$ 治疗重复测量的 RCT，这在许多治疗领域很常见。
我们敦促谨慎估计治疗前患者不可观察的真实状况是否存在测量误差，因为违反标准回归假设会导致治疗效果估计的衰减。幸运的是，我们证明，对于一般的传统医学以及将疗效定义为人群平均的靶向治疗，反事实点估计是无偏的。然而，对于靶向治疗，真实人类和数字孪生方法都应该尊重这一限制，以免预测的 $\textit{子组}$ 治疗效果出现偏差。]]></description>
      <guid>https://arxiv.org/abs/2411.09635</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非线性单变量模型的条件回归</title>
      <link>https://arxiv.org/abs/2411.09686</link>
      <description><![CDATA[arXiv:2411.09686v1 公告类型：新
摘要：存在几种统计模型，用于对 $\mathbb{R}^d$ 上的函数 $F$ 进行回归，而不存在统计和计算维数灾难，例如通过对数据分布施加和利用几何假设（例如，其支持是低维的），或对 $F$ 进行强平滑性假设，或特殊结构 $F$。在后者中，已经研究了组合模型，假设 $F=f\circ g$，其中 $g$ 映射到 $\mathbb{R}^r$，其中 $r\ll d$，包括经典的单指标和多指标模型以及最近的神经网络研究。虽然 $g$ 为线性的情况相当容易理解，但当 $g$ 为非线性时，人们对此了解甚少，尤其是当 $g$ 为非线性时，在估计 $F$ 或 $f$ 和 $g$ 时，维数灾难可以被规避。在本文中，我们考虑一个模型 $F(X):=f(\Pi_\gamma X) $，其中 $\Pi_\gamma:\mathbb{R}^d\to[0,\rm{len}_\gamma]$ 是正则曲线 $\gamma: [0,\rm{len}_\gamma]\to\mathbb{R}^d$ 和 $f:[0,\rm{len}_\gamma]\to\mathbb{R}^1$ 的参数上的最近点投影。输入数据 $X$ 不是低维的，远非 $\gamma$，条件是 $\Pi_\gamma(X)$ 定义明确。数据分布、$\gamma$ 和 $f$ 是未知的。该模型是单指标模型的自然非线性推广，对应于 $\gamma$ 为一条直线。我们提出了一个基于条件回归的非参数估计量，并表明在适当的假设下，其中最强的假设是 $f$ 是粗单调的，它可以实现非参数回归的 $一维$ 最优最小-最大速率，直至观测中的噪声水平，并且可以在 $\mathcal{O}(d^2n\log n)$ 时间内构建。学习界限内、保持界限所需的最少样本数内以及计算复杂度内的所有常数最多是 $d$ 中的低阶多项式。]]></description>
      <guid>https://arxiv.org/abs/2411.09686</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>键相关近场动力学材料对应公式的消息传递神经网络替代模型</title>
      <link>https://arxiv.org/abs/2411.08911</link>
      <description><![CDATA[arXiv:2411.08911v1 公告类型：交叉 
摘要：近场动力学是一种非局部连续力学理论，在涉及不连续性和复杂变形的建模问题方面具有独特的优势。在近场动力学框架内，存在各种公式，其中材料对应公式因其能够直接结合传统的连续材料模型而脱颖而出，使其高度适用于一系列工程挑战。该领域的一个显着进步是键相关对应模型，它不仅解决了材料不稳定性问题，而且还实现了高计算精度。然而，键相关模型通常需要比 FEA 更高的计算成本，这可能会限制其实际应用。为了解决这一计算挑战，我们提出了一种基于消息传递神经网络 (MPNN) 的新型替代模型，该模型专门为键相关近场动力学材料对应公式设计。利用图结构与近场动力学固有的邻域连通性之间的相似性，我们构建了一个 MPNN，它可以将近场动力学领域的知识转移到计算图中，并通过 GPU 加速缩短计算时间。与专注于节点特征的传统图神经网络不同，我们的模型强调基于边缘的特征，在公式中捕捉必要的物质点相互作用。这种神经网络方法的一个关键优势是它的灵活性：它不需要固定的邻域连通性，使其能够适应不同的配置并可扩展到复杂系统。此外，该模型本身具有平移和旋转不变性，使其能够保持物理客观性：这是精确机械建模的关键要求。]]></description>
      <guid>https://arxiv.org/abs/2411.08911</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非欧几里得高阶光滑凸优化</title>
      <link>https://arxiv.org/abs/2411.08987</link>
      <description><![CDATA[arXiv:2411.08987v1 公告类型：交叉 
摘要：我们使用 $q$ 阶 oracle 开发了针对 $p$ 范数具有 H\&quot;older 连续 $q$ 阶导数的凸目标优化算法，其中 $p, q \geq 1$。我们还可以优化其他结构化函数。我们通过开发一种非欧几里得不精确加速近点法来实现这一点，该方法利用了不精确的均匀凸正则化器。我们还为通过本地 oracle 与函数交互的任何确定性算法提供了几乎匹配的下限。]]></description>
      <guid>https://arxiv.org/abs/2411.08987</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稳定性选择的选择稳定性及其应用</title>
      <link>https://arxiv.org/abs/2411.09097</link>
      <description><![CDATA[arXiv:2411.09097v1 公告类型：交叉 
摘要：稳定性选择是一种广泛采用的基于重采样的高维结构估计和变量选择框架。然而，“稳定性”的概念通常被狭义地处理，主要通过检查选择频率或“稳定路径”来实现。本文旨在扩大已建立的稳定性估计量的使用范围，以评估稳定性选择框架的整体稳定性，超越单变量分析。我们认为稳定性估计量有两个优点：它可以作为参考来反映所获得结果的稳健性，并有助于确定最佳正则化值以提高稳定性。通过确定该值，我们旨在在既定的理论范围内校准关键的稳定性选择参数，即决策阈值和错误选择的变量的预期数量。此外，我们探索了一种基于此正则化值的新型选择标准。通过先前建立的稳定性估计量的渐近分布，可以确保收敛到真正的稳定性，使我们能够观察连续子样本的稳定性趋势。这种方法揭示了所需的子样本数量，解决了先前研究中的一个显著差距。开发了“stabplot”包以方便使用本文中的图表，支持将它们集成到进一步的统计分析和研究工作流程中。]]></description>
      <guid>https://arxiv.org/abs/2411.09097</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于数据的初始化高效学习和采样多峰分布</title>
      <link>https://arxiv.org/abs/2411.09117</link>
      <description><![CDATA[arXiv:2411.09117v1 公告类型：交叉 
摘要：我们考虑使用马尔可夫链对多峰分布进行采样的问题，给定少量来自平稳测量的样本。虽然混合可能任意慢，但我们表明，如果马尔可夫链具有 $k$ 阶谱间隙，则从来自平稳分布的一组 $\tilde O(k/\varepsilon^2)$ 样本进行初始化将以高概率有效地生成一个样本，其条件定律在 TV 距离上与平稳测量接近 $\varepsilon$。特别是，这适用于满足庞加莱不等式的 $k$ 分布混合，当它们满足对数索伯列夫不等式时，收敛速度更快。我们的边界对于马尔可夫链的扰动是稳定的，特别是对于具有分数估计误差的 $\mathbb R^d$ 上的朗之万扩散，以及与伪似然估计的近似误差相结合的 Glauber 动力学。这证明了基于数据的初始化对于分数匹配方法的成功，尽管数据分布的混合速度很慢，并且改进和推广了 Koehler 和 Vuong (2023) 的结果，使其具有对 $k$ 的线性依赖性，而不是指数依赖性，并适用于任意半群。作为我们结果的结果，我们首次表明可以从样本中有效地学习一类自然的低复杂度 Ising 测度。]]></description>
      <guid>https://arxiv.org/abs/2411.09117</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>夏普矩阵经验伯恩斯坦不等式</title>
      <link>https://arxiv.org/abs/2411.09516</link>
      <description><![CDATA[arXiv:2411.09516v1 公告类型：交叉 
摘要：我们提出了两个尖锐的经验伯恩斯坦不等式，用于具有有界特征值的对称随机矩阵。尖锐的意思是，这两个不等式都以紧密的方式适应未知方差：一阶 $1/\sqrt{n}$ 项捕获的偏差渐近地与矩阵伯恩斯坦不等式完全匹配，包括常数，后者需要知道方差。我们的第一个不等式适用于独立矩阵的样本均值，我们的第二个不等式适用于停止时间下鞅依赖下的均值估计量。]]></description>
      <guid>https://arxiv.org/abs/2411.09516</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论语言生成的极限：幻觉与模式崩溃之间的权衡</title>
      <link>https://arxiv.org/abs/2411.09642</link>
      <description><![CDATA[arXiv:2411.09642v1 公告类型：交叉
摘要：指定语言模型的所有理想属性具有挑战性，但某些要求似乎是必不可少的。给定来自未知语言的样本，训练后的模型应该生成训练中未见过的有效字符串，并且具有足够的表达能力以捕捉语言的全部丰富性。否则，输出无效字符串构成“幻觉”，而无法捕获全部范围会导致“模式崩溃”。我们询问语言模型是否可以满足这两个要求。
我们在基于 Gold 和 Angluin 的统计语言生成设置中对此进行了调查。在这里，该模型从未知语言 K 的分布中接收随机样本，该语言 K 属于可能无限的语言集合。目标是从 K 生成看不见的字符串。如果随着训练规模的增加，其输出收敛到 K 中所有看不见的字符串，我们说该模型从 K 生成具有一致性和广度。
Kleinberg 和 Mullainathan [KM24] 询问语言生成的一致性和广度是否可能。我们对此给出了否定的回答：对于一大类语言模型，包括下一个标记预测模型，对于大多数候选语言集合来说，这是不可能的。这与 [KM24] 的结果形成了鲜明对比，表明对于任何可数的语言集合，一致生成而不具有广度都是可能的。我们的发现强调了具有广度的生成与没有广度的生成有着根本的不同。
作为副产品，我们对有广度或无广度生成所需的样本数量建立了近乎严格的界限。
最后，我们的结果带来了希望：当负面示例（K 之外的字符串）与正面示例同时可用时，对于任何可数的语言集合，一致生成具有广度都是可以实现的。这表明，编码负面示例的训练后反馈对于减少幻觉同时限制模式崩溃至关重要。]]></description>
      <guid>https://arxiv.org/abs/2411.09642</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扰动余弦路由器在混合专家中的统计优势</title>
      <link>https://arxiv.org/abs/2405.14131</link>
      <description><![CDATA[arXiv:2405.14131v2 公告类型：替换 
摘要：混合专家 (MoE) 中的余弦路由器最近成为传统线性路由器的一种有吸引力的替代品。事实上，余弦路由器在图像和语言任务中表现出良好的性能，并且表现出更好的缓解表示崩溃问题的能力，这通常会导致参数冗余和有限的表示潜力。尽管它在经验上取得了成功，但对 MoE 中的余弦路由器的全面分析仍然缺乏。考虑到余弦路由 MoE 的最小二乘估计，我们证明由于余弦路由器中模型参数通过一些偏微分方程的内在相互作用，无论专家的结构如何，专家和模型参数的估计速度都可以慢到 $\mathcal{O}(1/\log^{\tau}(n))$，其中 $\tau &gt; 0$ 是某个常数，$n$ 是样本大小。令人惊讶的是，这些悲观的非多项式收敛速度可以通过实践中广泛使用的技术来稳定余弦路由器——只需在余弦路由器的 $L^2$ 范数中添加噪声，我们将其称为 \textit{扰动余弦路由器}。在专家函数的强可识别设置下，我们证明扰动余弦路由 MoE 下专家和模型参数的估计率都显著提高到多项式速率。最后，我们在合成和真实数据设置中进行了广泛的模拟研究，以实证验证我们的理论结果。]]></description>
      <guid>https://arxiv.org/abs/2405.14131</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协变量偏移下的分布稳健安全样本消除</title>
      <link>https://arxiv.org/abs/2406.05964</link>
      <description><![CDATA[arXiv:2406.05964v2 公告类型：替换 
摘要：我们考虑一种机器学习设置，其中一个训练数据集用于在略有不同的数据分布上训练多个模型。当需要为各种部署环境定制模型时，就会发生这种情况。为了降低存储和训练成本，我们提出了 DRSSS 方法，该方法结合了分布稳健 (DR) 优化和安全样本筛选 (SSS)。该方法的主要优点是，在所有可能的不同环境下，在精简数据集上训练的模型将与在完整数据集上训练的模型表现相同。在本文中，我们重点关注协变量偏移作为一种数据分布变化，并通过实验证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.05964</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>