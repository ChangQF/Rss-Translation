<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 30 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>可分解的 Transformer 点流程</title>
      <link>https://arxiv.org/abs/2409.18158</link>
      <description><![CDATA[arXiv:2409.18158v1 公告类型：新
摘要：对标记点过程进行建模的标准范例是使用基于注意的（Transformer 风格）架构参数化强度函数。尽管这些方法具有灵活性，但它们的推理基于计算密集型细化算法。在这项工作中，我们提出了一个框架，该框架保留了基于注意的架构的优势，并规避了细化算法的局限性。该框架依赖于使用满足马尔可夫性质的对数正态分布和基于 Transformer 的架构的标记条件概率质量函数的混合来建模事件间时间的条件分布。所提出的方法在根据历史预测序列的下一个事件方面达到了最先进的性能。实验还揭示了在推理过程中不依赖细化算法的方法比依赖细化算法的方法更有效。最后，我们在具有挑战性的长期预测任务上测试了我们的方法，发现它优于专门为解决此任务开发的基线；重要的是，与基于细化的基线相比，推理只需要一小部分时间。]]></description>
      <guid>https://arxiv.org/abs/2409.18158</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过噪声对比估计学习非正则化分布的统一观点</title>
      <link>https://arxiv.org/abs/2409.18209</link>
      <description><![CDATA[arXiv:2409.18209v1 公告类型：新
摘要：本文研究了基于噪声对比估计 (NCE) 的用于学习非正态分布的估计量系列。这项工作的主要贡献是通过 NCE 的视角，为学习非正态分布的各种方法提供统一的视角，这些方法已在不同的研究社区中独立提出和研究。这种统一的观点为现有的估计量提供了新的见解。具体而言，对于指数族，我们在一组规律性假设下建立了所提出的估计量的有限样本收敛率，其中大多数是新的。]]></description>
      <guid>https://arxiv.org/abs/2409.18209</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>局部预测推理</title>
      <link>https://arxiv.org/abs/2409.18321</link>
      <description><![CDATA[arXiv:2409.18321v1 公告类型：新
摘要：为了推断特定点 $x$ 上的函数值，必须为更接近 $x$ 的点分配更高的权重，这称为局部多项式/多变量回归。在许多实际情况下，有限的样本量可能会破坏这种方法，但这种情况可以通过预测驱动推理 (PPI) 技术得到改善。本文介绍了一种使用 PPI 进行局部多变量回归的具体算法，该算法可以显著降低估计的方差而不扩大误差。分析了置信区间、偏差校正和覆盖概率，证明了我们算法的正确性和优越性。数值模拟和真实数据实验证明了这些结论。与 PPI 相比，另一个贡献是通过考虑因变量的​​依赖性来提高理论计算效率和可解释性。]]></description>
      <guid>https://arxiv.org/abs/2409.18321</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有分布外泛化的可压缩欧拉方程的模型约束不连续 Galerkin 网络 (DGNet)</title>
      <link>https://arxiv.org/abs/2409.18371</link>
      <description><![CDATA[arXiv:2409.18371v1 公告类型：新 
摘要：在实际工程和科学应用中，特别是在数字孪生环境中，控制、优化、不确定性量化和决策迫切需要大规模复杂动力系统的实时精确解决方案。在这项工作中，我们开发了一种模型约束不连续 Galerkin 网络 (DGNet) 方法，这是我们之前的工作 [动态系统的模型约束切线斜率学习方法] 的扩展，用于具有分布外泛化的可压缩欧拉方程。DGNet 的核心是几种关键策略的协同作用：(i) 利用时间积分方案来捕捉时间相关性并利用神经网络速度来减少计算时间；(ii) 采用模型约束方法确保学习到的切线斜率满足控制方程； (iii) 利用受 GNN 启发的架构，其中边表示黎曼求解器代理模型，节点表示体积积分校正代理模型，从而能够捕获不连续性能力、减少混叠误差和网格离散化泛化能力；(iv) 实现输入规范化技术，使代理模型能够在不同的初始条件、边界条件和解阶之间进行泛化；(v) 结合数据随机化技术，该技术不仅可以隐式地促进代理模型与真实数值模型之间的一致性（直至二阶导数），确保长期稳定性和预测能力，而且还可以在训练期间充当数据生成引擎，从而增强对看不见的数据的泛化能力。为了验证我们新颖的 DGNet 方法的有效性、稳定性和泛化能力，我们为一维和二维可压缩欧拉方程问题提供了全面的数值结果。]]></description>
      <guid>https://arxiv.org/abs/2409.18371</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Wasserstein 生成对抗网络潜在空间的自适应学习</title>
      <link>https://arxiv.org/abs/2409.18374</link>
      <description><![CDATA[arXiv:2409.18374v1 公告类型：新
摘要：基于潜在变量的生成模型，例如生成对抗网络 (GAN) 和变分自动编码器 (VAE)，由于其在许多领域的出色表现而引起了广泛关注。然而，许多数据（例如自然图像）通常不会填充环境欧几里得空间，而是驻留在低维流形中。因此，潜在维度的选择不合适无法揭示数据的结构，可能导致潜在表示不匹配和生成质量差。为了解决这些问题，我们提出了一种称为潜在 Wasserstein GAN (LWGAN) 的新框架，该框架融合了 Wasserstein 自动编码器和 Wasserstein GAN，以便可以通过修改的信息潜在分布自适应地学习数据流形的固有维度。我们证明存在一个编码器网络和一个生成器网络，使得学习到的编码分布的固有维度等于数据流形的维度。我们从理论上确定了我们估计的固有维度是数据流形真实维度的一致估计。同时，我们给出了 LWGAN 泛化误差的上限，这意味着我们强制合成数据分布从群体角度与真实数据分布相似。全面的实证实验验证了我们的框架，并表明 LWGAN 能够在多种情况下识别正确的固有维度，并通过从学习到的潜在分布中采样同时生成高质量的合成数据。]]></description>
      <guid>https://arxiv.org/abs/2409.18374</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WHOMP：通过 Wasserstein 同质性优化随机对照试验</title>
      <link>https://arxiv.org/abs/2409.18504</link>
      <description><![CDATA[arXiv:2409.18504v1 公告类型：新
摘要：我们研究将数据集划分为子组的方法，以最大化每个子组内的多样性，同时最小化子组之间的差异。我们引入了一种称为 $\textit{Wasserstein 同质性划分}$ (WHOMP) 的新型划分方法，该方法可以最佳地最小化 I 类和 II 类错误，这些错误通常由不平衡的组划分或划分（通常称为意外偏差）在比较和对照试验中引起。我们对 WHOMP 与现有划分方法（例如随机子抽样、协变量自适应随机化、重新随机化和反聚类）进行了分析比较，展示了其优势。此外，我们描述了 WHOMP 问题的最优解，并揭示了这些解中子组均值的稳定性和方差之间的固有权衡。基于我们的理论见解，我们设计了算法，不仅可以获得这些最优解决方案，还可以为实践者提供选择所需权衡的工具。最后，我们通过数值实验验证了 WHOMP 的有效性，突出了它相对于传统方法的优势。]]></description>
      <guid>https://arxiv.org/abs/2409.18504</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高维流形假设下的扩散模型的收敛性</title>
      <link>https://arxiv.org/abs/2409.18804</link>
      <description><![CDATA[arXiv:2409.18804v1 公告类型：新
摘要：去噪扩散概率模型 (DDPM) 是一种强大的先进方法，用于从高维数据分布生成合成数据，并广泛用于图像、音频和视频生成以及科学和其他领域的许多其他应用。流形假设指出，高维数据通常位于环境空间内的低维流形上，并且被广泛认为在提供的示例中成立。虽然最近的结果为扩散模型如何适应流形假设提供了宝贵的见解，但它们并没有捕捉到这些模型的巨大经验成功，这使得这成为一个非常富有成果的研究方向。
在这项工作中，我们研究了流形假设下的 DDPM，并证明它们在学习分数方面实现了与环境维度无关的速率。在采样方面，我们获得了与环境维度无关的速率。 Kullback-Leibler 散度，以及 $O(\sqrt{D})$ w.r.t. Wasserstein 距离。我们通过开发一个新框架来实现这一点，该框架将扩散模型与高斯过程极值理论联系起来。]]></description>
      <guid>https://arxiv.org/abs/2409.18804</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>构建泛化误差的置信区间——一项全面的基准研究</title>
      <link>https://arxiv.org/abs/2409.18836</link>
      <description><![CDATA[arXiv:2409.18836v1 公告类型：新
摘要：在评估机器学习中预测模型的质量时，衡量预测性能的泛化误差的置信区间 (CI) 是一个关键工具。幸运的是，存在许多计算此类 CI 的方法，并且不断提出新的有前途的方法。通常，这些方法结合了各种重采样程序（其中最流行的是交叉验证和引导）和不同的方差估计技术。然而，不幸的是，目前尚无关于何时可以最可靠地使用这些组合以及它们通常如何比较的共识。在这项工作中，我们进行了第一项大规模研究，比较泛化误差的 CI - 使用四种不同的诱导剂和总共八个损失函数，对总共 18 个表格回归和分类问题实证评估了 13 种不同的方法。我们概述了构建泛化误差 CI 的方法基础和固有挑战，并在统一框架中对所有 13 种方法进行了简要回顾。最后，根据 CI 方法的相对覆盖频率、宽度和运行时间对其进行评估。基于这些发现，我们能够确定我们推荐的方法子集。我们还将数据集作为基准测试套件发布在 OpenML 上，并将我们的代码发布在 GitHub 上，作为进一步研究的基础。]]></description>
      <guid>https://arxiv.org/abs/2409.18836</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经典统计（样本内）直觉不能很好地概括：关于偏差-方差权衡、过度拟合和从固定设计转向随机设计的注释</title>
      <link>https://arxiv.org/abs/2409.18842</link>
      <description><![CDATA[arXiv:2409.18842v1 公告类型：新
摘要：现代机器学习 (ML) 现象（如双下降和良性过度拟合）的突然出现可能会让许多受过传统训练的统计学家感到不安——这些现象似乎违背了任何关于从数据中学习的入门课程中传达的统计直觉的核心。历史上缺乏对此类现象的早期观察通常归因于当今对更复杂的 ML 方法、过度参数化、插值和/或更高数据维度的依赖。在本文中，我们表明，我们今天观察到的行为与传统统计学教科书中教授的直觉不一致还有另一个原因，这更容易理解，但很少明确讨论。具体来说，许多直觉源自固定设计设置，其中样本内预测误差（在噪声结果重采样的情况下）是令人感兴趣的，而现代 ML 则根据泛化误差（即随机设计中的样本外预测误差）来评估其预测。在这里，我们强调，从固定设计到随机设计的这一简单转变对与偏差-方差权衡有关的教科书直觉产生了（也许令人惊讶的）深远影响，并评论了由此导致的在固定设计与随机设计中观察到双下降和良性过拟合的（不）可能性。]]></description>
      <guid>https://arxiv.org/abs/2409.18842</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于地理数据的位置编码器图分位数神经网络</title>
      <link>https://arxiv.org/abs/2409.18865</link>
      <description><![CDATA[arXiv:2409.18865v1 公告类型：新
摘要：位置编码器图神经网络 (PE-GNN) 是建模连续空间数据的主要方法。然而，它们往往无法产生校准的预测分布，从而限制了它们对不确定性量化的有效性。我们引入了位置编码器图分位数神经网络 (PE-GQNN)，这是一种将 PE-GNN、分位数神经网络和重新校准技术集成到一个完全非参数框架中的新方法，只需要对预测分布做出最少的假设。我们提出了一种新的网络架构，当与基于分位数的损失函数相结合时，可以在不增加计算复杂度的情况下产生准确可靠的概率模型。我们的方法为条件密度估计提供了一个灵活、稳健的框架，适用于空间数据环境之外。我们进一步介绍了一种结构化方法，用于将 KNN 预测器合并到模型中，同时避免通过 GNN 层操作进行数据泄漏。在基准数据集上的实验表明，PE-GQNN 在预测准确性和不确定性量化方面都明显优于现有的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2409.18865</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>最具影响力的子集选择：挑战、前景及未来</title>
      <link>https://arxiv.org/abs/2409.18153</link>
      <description><![CDATA[arXiv:2409.18153v1 公告类型：交叉 
摘要：我们如何将机器学习模型的行为归因于其训练数据？虽然经典的影响函数可以揭示单个样本的影响，但它往往无法捕捉一组样本更复杂、更明显的集体影响。为了应对这一挑战，我们研究了最具影响力的子集选择 (MISS) 问题，该问题旨在识别具有最大集体影响力的训练样本子集。我们对 MISS 中的主流方法进行了全面分析，阐明了它们的优点和缺点。我们的研究结果表明，基于影响的贪婪启发式算法（MISS 中的一类主要算法）即使在线性回归中也可能失败。我们描述了失败模式，包括影响函数的误差和集体影响的非加性结构。相反，我们证明了这些启发式算法的自适应版本可以迭代应用它们，可以有效地捕捉样本之间的相互作用，从而部分解决问题。在真实数据集上进行的实验证实了这些理论发现，并进一步证明了自适应性的优点可以扩展到更复杂的场景，例如分类任务和非线性神经网络。我们在分析的最后强调了性能和计算效率之间的固有权衡，质疑了线性数据建模分数等附加指标的使用，并提供了一系列讨论。]]></description>
      <guid>https://arxiv.org/abs/2409.18153</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Shapley 值对大型多维时间序列数据的新应用：将可解释的人工智能应用于 DNA 图谱分类神经网络</title>
      <link>https://arxiv.org/abs/2409.18156</link>
      <description><![CDATA[arXiv:2409.18156v1 公告类型：交叉 
摘要：将 Shapley 值应用于高维时间序列数据在计算上具有挑战性 - 有时是不可能的。对于 $N$ 个输入，问题难度为 $2^N$。在图像处理中，像素簇（称为超像素）用于简化计算。这项研究为时间序列数据提供了一种有效的解决方案，该解决方案采用了超像素的思想来进行 Shapley 值计算。受法医 DNA 分类示例的启发，该方法应用于多变量时间序列数据，其特征已由卷积神经网络 (CNN) 分类。在 DNA 处理中，从 DNA 提取和处理产生的背景噪声中识别等位基因非常重要。单个 DNA 图谱有 $31,200$ 个扫描点需要分类，并且分类决策必须在法庭上站得住脚。这意味着分类通常由人类读者执行 - 这是一个巨大而耗时的过程。使用 CNN 快速计算有意义的 Shapley 值，为分类提供了一种潜在的替代方案。这项研究证明了 Shapley 值在这项大规模任务中的实际、准确和快速计算]]></description>
      <guid>https://arxiv.org/abs/2409.18156</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>桥接 OOD 检测和泛化：图论视角</title>
      <link>https://arxiv.org/abs/2409.18205</link>
      <description><![CDATA[arXiv:2409.18205v1 公告类型：交叉 
摘要：在现代机器学习的背景下，在现实场景中部署的模型经常会遇到各种数据变化，如协变量和语义变化，从而导致分布外 (OOD) 泛化和检测方面的挑战。尽管对这些问题分别给予了相当大的关注，但缺乏统一的理论理解和实际使用的框架。为了弥合这一差距，我们引入了一个图论框架来共同解决 OOD 泛化和检测问题。通过利用图形公式，可以通过图的邻接矩阵的分解获得数据表示，使我们能够得出可证明的误差量化 OOD 泛化和检测性能。与现有方法相比，实证结果展示了具有竞争力的性能，从而验证了我们的理论基础。代码可在 https://github.com/deeplearning-wisc/graph-spectral-ood 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2409.18205</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>核爆炸的贝叶斯事件分类矩阵方法</title>
      <link>https://arxiv.org/abs/2409.18227</link>
      <description><![CDATA[arXiv:2409.18227v1 公告类型：交叉 
摘要：当前，人们致力于利用地面和太空收集的判别式检测核爆炸并正确对爆炸源进行分类，但这些挑战仍未得到事件分类矩阵 (ECM) 模型的解决。较小的事件（当量较低的爆炸）通常仅包括少数模态中的稀疏观测，因此可能缺乏完整的判别式。协方差结构在事件（源类型）类别的此类观测之间也可能存在很大差异。这两个障碍对于“经典”ECM 来说都是有问题的。我们的工作解决了这一差距，并提出了对以前的 ECM 模型的贝叶斯更新，称为 B-ECM，该模型可以在部分观测上进行训练，并且不依赖于池化协方差结构。我们进一步用贝叶斯决策理论增强 ECM，以便可以直观地降低事件分类的假阴性或假阳性率。为了证明 B-ECM 的分类率有所提高，我们利用蒙特卡罗实验的多个性能指标比较了一系列 B-ECM 和经典 ECM 模型。我们使用合成数据和真实数据。与经典 ECM 模型相比，我们的 B-ECM 模型在整体准确率方面表现出持续的提升，并且假阴性率更低。我们提出了未来改进 B-ECM 的途径，以扩展其决策和预测能力。]]></description>
      <guid>https://arxiv.org/abs/2409.18227</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用动态损失加权来提高预测稳定性</title>
      <link>https://arxiv.org/abs/2409.18267</link>
      <description><![CDATA[arXiv:2409.18267v1 公告类型：交叉 
摘要：滚动原点预测不稳定性是指在有新数据点可用时更新预测导致特定时期的预测变化。最近，提出了对单变量时间序列点预测的 N-BEATS 模型的扩展，将预测稳定性作为除准确性之外的额外优化目标。结果表明，通过最小化包含预测误差和预测不稳定性成分的复合损失函数，并使用静态超参数控制稳定性的影响，可以在不损害准确性的情况下获得更稳定的预测。在本文中，我们通过实证研究是否可以在不影响准确性的情况下通过应用动态损失加权算法（在训练期间改变损失权重）来进一步提高稳定性。我们表明一些现有的动态损失加权方法实现了这一目标。然而，我们提出的随机加权方法的扩展——任务感知随机加权——表现出最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2409.18267</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>