<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 21 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>对抗性训练下的鲁棒 NAS：基准、理论及其他</title>
      <link>https://arxiv.org/abs/2403.13134</link>
      <description><![CDATA[arXiv:2403.13134v1 公告类型：交叉
摘要：神经架构搜索（NAS）的最新发展强调了考虑针对恶意数据的鲁棒架构的重要性。然而，搜索这些鲁棒架构的基准评估和理论保证明显缺乏，特别是在考虑对抗性训练时。在这项工作中，我们的目标是解决这两个挑战，做出双重贡献。首先，我们发布了一个全面的数据集，其中包含图像数据集上 NAS-Bench-201 搜索空间中大量经过对抗训练的网络的干净准确性和鲁棒准确性。然后，利用深度学习理论中的神经正切核（NTK）工具，我们建立了一种在多目标对抗训练下在清洁精度和鲁棒精度方面搜索架构的泛化理论。我们坚信，我们的基准测试和理论见解将通过可靠的可重复性、高效的评估和理论基础，使 NAS 社区受益匪浅，特别是在追求稳健的架构方面。]]></description>
      <guid>https://arxiv.org/abs/2403.13134</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>使用评分规则训练生存模型</title>
      <link>https://arxiv.org/abs/2403.13150</link>
      <description><![CDATA[arXiv:2403.13150v1 公告类型：交叉
摘要：生存分析为各个领域中部分不完整的事件时间数据提供了重要的见解。这也是概率机器学习的一个重要例子。可以通过在模型拟合过程中使用（适当的）评分规则而不是基于可能性的优化来利用预测的概率性质。我们的建议以通用方式实现这一点，并且可用于各种模型类。我们建立了不同的参数化和非参数化子框架，以实现不同程度的灵活性。结合到神经网络中，它可以产生计算效率高且可扩展的优化例程，从而产生最先进的预测性能。最后，我们表明，使用我们的框架，我们可以恢复各种参数模型，并证明与基于可能性的方法相比，优化同样有效。]]></description>
      <guid>https://arxiv.org/abs/2403.13150</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>结构化领域的预测性、可扩展性和可解释性知识追踪</title>
      <link>https://arxiv.org/abs/2403.13179</link>
      <description><![CDATA[arXiv:2403.13179v1 公告类型：交叉
摘要：智能辅导系统优化学习材料的选择和时间安排，以增强理解和长期保留。这需要估计学习者的进度（“知识追踪”；KT）和学习领域的先决条件结构（“知识映射”）。虽然最近的深度学习模型实现了较高的 KT 准确性，但它们是以牺牲心理启发模型的可解释性为代价的。在这项工作中，我们提出了这种权衡的解决方案。 PSI-KT 是一种分层生成方法，它明确地模拟个体认知特征和知识的先决结构如何影响学习动态，从而通过设计实现可解释性。此外，通过使用可扩展的贝叶斯推理，PSI-KT 能够满足现实世界对高效个性化的需求，即使学习者群体和学习历史不断增长。通过对在线学习平台的三个数据集进行评估，PSI-KT 在持续学习环境中实现了卓越的多步骤预测准确性和可扩展推理，同时提供学习者特定特征的可解释表示以及因果支持学习的知识先决结构。总之，具有可靠知识图谱的预测性、可扩展性和可解释性知识追踪为有效的个性化学习奠定了关键基础，使全球广大受众能够接受教育。]]></description>
      <guid>https://arxiv.org/abs/2403.13179</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>更好地理解水印法学硕士的统计</title>
      <link>https://arxiv.org/abs/2403.13027</link>
      <description><![CDATA[arXiv:2403.13027v1 公告类型：交叉
摘要：在本文中，我们研究了大语言模型（LLM）的水印问题。我们考虑模型失真和检测能力之间的权衡，并将其表示为基于 Kirchenbauer 等人的绿红算法的约束优化问题。 （2023a）。我们表明，优化问题的最优解具有良好的分析特性，可以更好地理解并启发水印过程的算法设计。我们根据该优化公式开发了一种在线双梯度上升水印算法，并证明了其模型失真和检测能力之间的渐近帕累托最优性。这样的结果明确地保证了平均增加的绿名单概率和今后的检测能力（与之前的结果相比）。此外，我们对水印问题的模型失真度量的选择进行了系统的讨论。我们证明了 KL 散度选择的合理性，并提出了现有“无失真”和困惑度标准的问题。最后，我们根据基准算法在广泛的数据集上根据经验评估我们的算法。]]></description>
      <guid>https://arxiv.org/abs/2403.13027</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:38 GMT</pubDate>
    </item>
    <item>
      <title>通过非隐私预处理可证明隐私</title>
      <link>https://arxiv.org/abs/2403.13041</link>
      <description><![CDATA[arXiv:2403.13041v1 公告类型：交叉
摘要：在分析差分隐私（DP）机器学习管道时，隐私核算中经常忽视数据相关预处理的潜在隐私成本。在这项工作中，我们提出了一个通用框架来评估非私有数据依赖的预处理算法所产生的额外隐私成本。我们的框架通过利用两个新技术概念建立了整体隐私保证的上限：称为平滑 DP 的 DP 变体和预处理算法的有限敏感度。除了通用框架之外，当与多种 DP 算法结合使用时，我们还为多种依赖于数据的预处理算法提供明确的整体隐私保证，例如数据插补、量化、重复数据删除和 PCA。值得注意的是，该框架也易于实现，允许直接集成到现有的 DP 管道中。]]></description>
      <guid>https://arxiv.org/abs/2403.13041</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:38 GMT</pubDate>
    </item>
    <item>
      <title>通过多元高斯过程回归进行时空数据的模态分析</title>
      <link>https://arxiv.org/abs/2403.13118</link>
      <description><![CDATA[arXiv:2403.13118v1 公告类型：交叉
摘要：模态分析已成为理解复杂流的相干结构的重要工具。经典模态分析方法，例如动态模态分解（DMD）和谱本征正交分解（SPOD），依赖于及时定期采样的足够量的数据。然而，通常需要处理稀疏的时间不规则数据，例如，由于实验测量和模拟算法。为了克服数据稀缺和不规则采样的限制，我们提出了一种使用多元高斯过程回归（MVGPR）的新型模态分析技术。我们首先从线性系统辨识的角度建立 MVGPR 与现有模态分析技术 DMD 和 SPOD 之间的联系。接下来，利用这种联系，我们开发了一种基于 MVGPR 的模态分析技术来解决上述限制。 MVGPR 的能力得益于其精心设计的相关函数内核结构，该函数源自假设的线性动力学。随后，所提出的 MVGPR 方法在一系列示例（从学术数据和合成数据到非定常翼型空气动力学）上与 DMD 和 SPOD 进行基准测试。结果表明 MVGPR 作为经典模态分析方法的一种有前途的替代方法，特别是在数据稀缺和时间不规则的情况下。]]></description>
      <guid>https://arxiv.org/abs/2403.13118</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:38 GMT</pubDate>
    </item>
    <item>
      <title>因式分解高斯近似的变分推理的散度排序</title>
      <link>https://arxiv.org/abs/2403.13748</link>
      <description><![CDATA[arXiv:2403.13748v1 公告类型：新
摘要：给定一个难以处理的分布 $p$，变分推理 (VI) 问题是从一些更容易处理的族 $\mathcal{Q}$ 中计算最佳近似值 $q$。最常见的是通过最小化 Kullback-Leibler (KL) 散度来找到近似值。然而，还存在其他有效的分歧选择，并且当 $\mathcal{Q}$ 不包含 ~$p$ 时，每个分歧都支持不同的解决方案。我们分析当具有稠密协方差矩阵的高斯函数被具有对角协方差矩阵的高斯函数近似时，散度的选择如何影响 VI 的结果。在这种情况下，我们表明不同的散度可以通过它们的变分近似错误估计各种不确定性度量（例如方差、精度和熵）的量进行 \textit{ordered}。我们还推导出一个不可能定理，表明这些度量中没有两个可以同时通过因式分解近似匹配；因此，分歧的选择决定了正确估计哪种度量（如果有）。我们的分析涵盖 KL 散度、R\&#39;enyi 散度以及比较 $\nabla\log p$ 和 $\nabla\log q$ 的基于分数的散度。我们凭经验评估当使用 VI 来近似非高斯分布时这些排序是否成立。]]></description>
      <guid>https://arxiv.org/abs/2403.13748</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:37 GMT</pubDate>
    </item>
    <item>
      <title>使用梯度下降训练形态神经网络：一些理论见解</title>
      <link>https://arxiv.org/abs/2403.12975</link>
      <description><![CDATA[arXiv:2403.12975v1 公告类型：交叉
摘要：形态神经网络或层可以成为促进数学形态学进步的强大工具，无论是在完整格算子的表示等理论方面，还是在图像处理管道的开发方面。然而，当这些架构计数超过几个形态层时，它们就很难训练，至少在使用基于梯度下降的优化算法的流行机器学习框架内是这样。在本文中，我们根据 Bouligand 导数的非光滑优化概念，研究了基于微分的方法和反向传播应用于形态网络的潜力和局限性。我们提供见解和第一理论指导，特别是关于初始化和学习率。]]></description>
      <guid>https://arxiv.org/abs/2403.12975</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:37 GMT</pubDate>
    </item>
    <item>
      <title>当 SMILES 具有语言时：在药物 SMILES 字符串上使用文本分类方法进行药物分类</title>
      <link>https://arxiv.org/abs/2403.12984</link>
      <description><![CDATA[arXiv:2403.12984v1 公告类型：交叉
摘要：复杂的化学结构（如药物）通常由 SMILES 字符串定义为分子和键的序列。这些 SMILES 字符串用于不同的复杂的基于机器学习的药物相关研究和表示工作。为了摆脱复杂的表征，在这项工作中，我们提出了一个问题：如果我们将药物 SMILES 视为常规句子并进行文本分类以进行药物分类会怎么样？我们的实验以极具竞争力的分数证实了这种可能性。该研究探索了将每个原子和键视为句子成分的概念，采用基本的 NLP 方法对药物类型进行分类，证明复杂的问题也可以用更简单的视角来解决。数据和代码可在此处获取：https://github.com/azminewasi/Drug-Classification-NLP。]]></description>
      <guid>https://arxiv.org/abs/2403.12984</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:37 GMT</pubDate>
    </item>
    <item>
      <title>内核多重网格：通过稀疏高斯过程回归加速后拟合</title>
      <link>https://arxiv.org/abs/2403.13300</link>
      <description><![CDATA[arXiv:2403.13300v1 公告类型：新
摘要：加性高斯过程（GP）是非参数特征选择的流行方法。这些模型的常见训练方法是贝叶斯后拟合。然而，训练加法 GP 时的反向拟合收敛速度仍然是一个悬而未决的问题。通过利用一种称为核包（KP）的技术，我们证明了后拟合的收敛速度不会比 $(1-\mathcal{O}(\frac{1}{n}))^t$ 快，其中$n$和$t$分别表示数据大小和迭代次数。因此，后拟合需要最少 $\mathcal{O}(n\log n)$ 次迭代才能实现收敛。基于KP，我们进一步提出了一种称为内核多重网格（KMG）的算法。该算法通过结合稀疏高斯过程回归 (GPR) 来处理每次后拟合迭代后的残差，从而增强后拟合。它适用于具有结构化数据和分散数据的附加 GP。理论上，我们证明 KMG 将所需的迭代次数减少到 $\mathcal{O}(\log n)$，同时保留 $\mathcal{O}(n\log n)$ 和 $\mathcal{O 的时间和空间复杂度}(n)$ 每次迭代分别。在数值上，通过采用仅具有 10 个诱导点的稀疏探地雷达，KMG 可以在 5 次迭代内产生高维目标的精确近似。]]></description>
      <guid>https://arxiv.org/abs/2403.13300</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:36 GMT</pubDate>
    </item>
    <item>
      <title>AdaTrans：用于高维回归的特征和样本自适应迁移学习</title>
      <link>https://arxiv.org/abs/2403.13565</link>
      <description><![CDATA[arXiv:2403.13565v1 公告类型：新
摘要：我们考虑高维设置中的迁移学习问题，其中特征维度大于样本大小。为了学习可能因特征或源样本而异的可转移信息，我们提出了一种自适应转移学习方法，可以检测和聚合特征方式（F-AdaTrans）或样本方式（S-AdaTrans）可转移结构。我们通过采用一种新颖的融合惩罚，再加上可以根据可转移结构进行调整的权重来实现这一点。为了选择权重，我们提出了一种理论上知情的数据驱动程序，使 F-AdaTrans 能够选择性地将可传输信号与目标融合，同时滤除不可传输信号，并使 S-AdaTrans 获得从目标传输的信息的最佳组合。每个源样本。建立非渐近速率，在特殊情况下恢复现有的近极小极大最优速率。使用合成数据和真实数据验证了所提出方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.13565</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:36 GMT</pubDate>
    </item>
    <item>
      <title>深度强化学习的快速价值跟踪</title>
      <link>https://arxiv.org/abs/2403.13178</link>
      <description><![CDATA[arXiv:2403.13178v1 公告类型：新
摘要：强化学习（RL）通过创建与其环境交互的代理来解决顺序决策问题。然而，现有算法通常将这些问题视为静态问题，重点关注模型参数的点估计以最大化预期奖励，而忽略了智能体与环境交互的随机动态以及不确定性量化的关键作用。我们的研究利用卡尔曼滤波范式引入了一种新颖且可扩展的采样算法，称为 Langevinized Kalman Temporal-Difference (LKTD)，用于深度强化学习。该算法以随机梯度马尔可夫链蒙特卡罗 (SGMCMC) 为基础，可有效地从深度神经网络参数的后验分布中抽取样本。在温和的条件下，我们证明了LKTD算法生成的后验样本收敛于平稳分布。这种收敛不仅使我们能够量化与价值函数和模型参数相关的不确定性，而且还使我们能够在整个训练阶段的策略更新期间监控这些不确定性。 LKTD 算法为更强大、适应性更强的强化学习方法铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2403.13178</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:35 GMT</pubDate>
    </item>
    <item>
      <title>大型属性图假设检验的基于采样的框架</title>
      <link>https://arxiv.org/abs/2403.13286</link>
      <description><![CDATA[arXiv:2403.13286v1 公告类型：新
摘要：假设检验是一种统计方法，用于从样本数据中得出有关总体的结论，通常以表格形式表示。随着图形表示在现实生活应用中的流行，图形中的假设检验变得越来越重要。在这项工作中，我们在属性图中形式化了节点、边和路径假设。我们开发了一个基于抽样的假设检验框架，它可以适应现有的假设不可知图抽样方法。为了实现准确有效的采样，我们提出了一种路径假设感知采样，PHASE，一种 m 维随机游走，用于解释假设中指定的路径。我们进一步优化其时间效率，提出PHASEopt。对真实数据集的实验证明了我们的框架利用常见图采样方法进行假设检验的能力，以及假设感知采样在准确性和时间效率方面的优越性。]]></description>
      <guid>https://arxiv.org/abs/2403.13286</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:35 GMT</pubDate>
    </item>
    <item>
      <title>最优流量匹配：一步学习直线轨迹</title>
      <link>https://arxiv.org/abs/2403.13117</link>
      <description><![CDATA[arXiv:2403.13117v1 公告类型：新
摘要：近年来，用于生成建模的流匹配方法的发展蓬勃发展。社区追求的一项有趣的特性是能够学习具有直线轨迹的流动，从而实现最佳运输（OT）位移。直线度对于快速整合学习流路径至关重要。不幸的是，大多数现有的流矫直方法都基于不平凡的迭代过程，这些迭代过程会在训练期间累积误差或利用启发式小批量 OT 近似。为了解决这个问题，我们开发了一种新颖的最佳流量匹配方法，只需一个流量匹配步骤即可恢复二次成本的直接 OT 位移。]]></description>
      <guid>https://arxiv.org/abs/2403.13117</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>函数树：透明的机器学习</title>
      <link>https://arxiv.org/abs/2403.13141</link>
      <description><![CDATA[arXiv:2403.13141v1 公告类型：新
摘要：机器学习算法的输出通常可以用其输入变量的一个或多个多元函数来表示。了解此类函数的全局属性可以帮助理解生成数据的系统以及解释和解释相应的模型预测。提出了一种将一般多元函数表示为更简单函数树的方法。该树通过揭示和描述其输入变量子集的组合联合影响来揭示函数的全局内部结构。给定输入和相应的函数值，构建函数树，可用于快速识别和计算函数的所有主要效果和交互效果直至高阶。涉及最多四个变量的交互效应以图形方式可视化。]]></description>
      <guid>https://arxiv.org/abs/2403.13141</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:34 GMT</pubDate>
    </item>
    </channel>
</rss>