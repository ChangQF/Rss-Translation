<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 16 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>复杂系统中高阶因果关系的定义</title>
      <link>https://arxiv.org/abs/2409.08295</link>
      <description><![CDATA[arXiv:2409.08295v1 公告类型：新
摘要：复杂系统动力学的描述，特别是系统元素之间相互作用结构和因果关系的捕捉，是跨学科研究的核心问题之一。虽然成对因果相互作用的表征是一个相对成熟的领域，具有成熟的理论概念，目前的重点是其有效估计的技术问题，但事实证明，格兰杰因果关系或转移熵等标准概念可能无法忠实地反映可能的协同作用或高阶相互作用，这些现象与许多现实世界的复杂系统高度相关。在本文中，我们提出了对因果推理的信息理论方法的概括和细化，从而能够描述真正的多变量，而不是多个成对的因果相互作用，从而从因果网络转向因果超网络。具体而言，在保持控制中介变量或共同原因的能力的同时，在纯协同相互作用（如排他性分离）的情况下，它将因果作用归因于多变量因果集，但 \emph{不是} 归因于单个输入，从而将其与例如两个附加单变量原因的情况区分开来。我们通过应用于说明性理论示例以及最近报道的采用协同计算的生物神经元动力学的生物物理现实模拟来证明这一概念。]]></description>
      <guid>https://arxiv.org/abs/2409.08295</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散流匹配的 KL 理论保证</title>
      <link>https://arxiv.org/abs/2409.08311</link>
      <description><![CDATA[arXiv:2409.08311v1 公告类型：新
摘要：流匹配 (FM)（也称为随机插值或整流）是一类生成模型，旨在利用固定耦合 $\nu^\star$ 和辅助分布 $\mu$ 在有限的时间内桥接目标分布 $\nu^\star$ 和辅助分布 $\mu$，利用固定耦合 $\pi$ 和确定性或随机性的桥接。这两个成分定义了一个路径度量，然后可以通过学习其马尔可夫投影的漂移来近似。本文的主要贡献是对 $\nu^\star$、$\mu$ 和 $\pi$ 提供相对温和的假设，以获得扩散流匹配 (DFM) 模型的非渐近保证，使用与布朗运动相关的条件分布作为桥梁。更准确地说，我们在 $\nu^\star$、$\mu$ 和 $\pi$ 的分数的矩条件下，以及标准的 $L^2$ 漂移近似误差假设下，建立了目标分布与此类 DFM 模型生成的分布之间的 Kullback-Leibler 散度的界限。]]></description>
      <guid>https://arxiv.org/abs/2409.08311</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联合一次性集成聚类</title>
      <link>https://arxiv.org/abs/2409.08396</link>
      <description><![CDATA[arXiv:2409.08396v1 公告类型：新
摘要：由于数据共享限制，跨多个机构的聚类分析带来了重大挑战。为了克服这些限制，我们引入了联合一次性集成聚类 (FONT) 算法，这是一种针对此类约束下的多站点分析量身定制的新型解决方案。FONT 只需要站点之间的一轮通信，并通过仅交换拟合的模型参数和类标签来确保隐私。该算法将局部拟合的聚类模型组合成一个数据自适应集成，使其广泛适用于各种聚类技术，并且对站点间聚类比例差异具有鲁棒性。我们的理论分析验证了 FONT 学习的数据自适应权重的有效性，模拟研究表明其性能优于现有的基准方法。我们应用 FONT 来识别两个医疗系统中的类风湿性关节炎患者亚组，发现跨站点患者聚类的一致性有所提高，而局部拟合的聚类被证明不太可转移。 FONT 特别适合具有严格通信和隐私限制的实际应用，为多站点集群提供了可扩展且实用的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2409.08396</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于最优分类的神经网络异常检测：理论与实践</title>
      <link>https://arxiv.org/abs/2409.08521</link>
      <description><![CDATA[arXiv:2409.08521v1 公告类型：新
摘要：异常检测是许多应用领域（例如网络安全）中的一个重要问题。许多用于无监督异常检测的深度学习方法产生了良好的经验性能，但缺乏理论保证。通过将异常检测转化为二元分类问题，我们建立了对合成异常进行训练的整流线性单元 (ReLU) 神经网络的非渐近上限和超额风险收敛速度。我们对超额风险的收敛速度与文献中的极小最大最优速率相匹配。此外，我们提供了可以达到这种最优性的合成异常数量的下限和上限。对于实际实施，我们放宽了一些条件以改进对经验风险最小化器的搜索，从而使其性能与其他基于分类的异常检测方法具有竞争力。总的来说，我们的工作为基于无监督神经网络的异常检测器提供了第一个理论保证，并提供了如何设计好它们的经验见解。]]></description>
      <guid>https://arxiv.org/abs/2409.08521</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>三思而后行：利用 MCMC 改进逆问题求解</title>
      <link>https://arxiv.org/abs/2409.08551</link>
      <description><![CDATA[arXiv:2409.08551v1 公告类型：新
摘要：最近的研究表明，扩散模型可以作为解决逆问题的强大先验。一个突出的例子是扩散后验采样 (DPS)，它使用 Tweedie 公式近似给定测量值的数据的后验分布。尽管 DPS 具有无需重新训练即可解决各种逆问题的优点，但这种后验近似可能不准确，尤其是在高噪声水平下，这阻碍了 DPS 的性能。因此，我们提出了 \textbf{D}iffusion \textbf{P}osterior \textbf{MC}MC (\textbf{DPMC})，这是一种基于退火 MCMC 的新型推理算法，用于使用预训练扩散模型解决逆问题。我们定义了一系列中间分布，这些分布受到 DPS 使用的近似条件分布的启发。通过退火 MCMC 采样，我们鼓励样本在移动到噪声水平较低的下一个分布之前更紧密地遵循每个中间分布，从而减少沿路径的累积误差。我们在各种逆问题中测试了我们的算法，包括超分辨率、高斯去模糊、运动去模糊、修复和相位恢复。我们的算法在几乎所有任务中都以更少的评估次数胜过 DPS，并且在现有方法中具有竞争力。]]></description>
      <guid>https://arxiv.org/abs/2409.08551</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多森林：多类别结果的重要性各不相同</title>
      <link>https://arxiv.org/abs/2409.08925</link>
      <description><![CDATA[arXiv:2409.08925v1 公告类型：新
摘要：在具有多类结果的预测任务中，识别与一个或多个结果类别特别相关的协变量可能很重要。随机森林 (RF) 中的传统变量重要性度量 (VIM)，如置换和基尼重要性，侧重于整体预测性能或节点纯度，而不区分类别。因此，可以预期它们无法区分与类别相关的协变量和仅区分类别组的协变量。我们引入了一种称为多类 VIM 的 VIM，它专门用于识别与类别相关的协变量，通过一种称为多森林 (MuF) 的新型 RF 变体。MuF 中的树使用多路和二元分割。多路分割为每个类生成子节点，使用分割标准来评估这些节点代表各自类别的程度。此设置构成了多类 VIM 的基础，它衡量根据此分割标准在各个协变量中执行的分割的判别能力。除了多类 VIM，我们还引入了第二个 VIM，即判别性 VIM。此度量基于二元分割，评估协变量的总体影响强度，而不管它们的类关联性如何。模拟研究表明，多类 VIM 专门对与类相关的协变量进行高度排名，而不像传统 VIM 也将其他类型的协变量排在高度位置。对 121 个数据集的分析表明，与传统 RF 相比，MuF 的预测性能通常略低。然而，考虑到该算法的主要目的是计算多类 VIM，这并不是一个限制因素。]]></description>
      <guid>https://arxiv.org/abs/2409.08925</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过适当的贝叶斯引导进行贝叶斯聚类的方法：贝叶斯袋装聚类 (BBC) 算法</title>
      <link>https://arxiv.org/abs/2409.08954</link>
      <description><![CDATA[arXiv:2409.08954v1 公告类型：新
摘要：本文介绍了一种用于聚类领域的无监督技术的新方法。提出了一种新方法，使用适当的贝叶斯引导来增强现有的文献模型，以提高结果的鲁棒性和可解释性。我们的方法分为两个步骤：使用 k 均值聚类进行先验引出，然后在集成聚类方法中将适当的贝叶斯引导用作重采样方法。分析结果时引入了基于香农熵的不确定性度量。该提案清楚地表明了最佳聚类数，并更好地表示了聚类数据。在模拟数据上提供了实证结果，显示了所获得的方法和实证进展。]]></description>
      <guid>https://arxiv.org/abs/2409.08954</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于规则的变量优先级选择与模型无关的变量</title>
      <link>https://arxiv.org/abs/2409.09003</link>
      <description><![CDATA[arXiv:2409.09003v2 公告类型：新
摘要：虽然实现高预测精度是机器学习的基本目标，但同样重要的任务是找到具有高解释力的少数特征。一种流行的选择技术是置换重要性，它通过测量置换变量后预测误差的变化来评估变量的影响。然而，由于需要创建人工数据，这可能会有问题，其他方法也存在这个问题。另一个问题是变量选择方法可能因模型特定而受到限制。我们引入了一种新的独立于模型的方法，即变量优先级 (VarPro)，它通过利用规则来工作，而无需生成人工数据或评估预测误差。该方法相对易于使用，只需要计算简单统计数据的样本平均值，并且可以应用于许多数据设置，包括回归、分类和生存。我们研究了 VarPro 的渐近性质，并表明 VarPro 对噪声变量具有一致的过滤属性。使用合成数据和真实数据进行的实证研究表明，该方法实现了均衡的性能，并且与目前用于变量选择的许多最先进的程序相比具有优势。]]></description>
      <guid>https://arxiv.org/abs/2409.09003</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连续概率模型正则化最大似然计算的基础</title>
      <link>https://arxiv.org/abs/2409.08387</link>
      <description><![CDATA[arXiv:2409.08387v1 公告类型：交叉 
摘要：基于最小描述长度原则，归一化最大似然 (NML) 代码长度被广泛用作模型选择标准，其中选择具有最短 NML 代码长度的模型。计算 NML 代码长度的常用方法是使用由最大似然估计量的分布定义的函数的和（对于离散模型）或积分（对于连续模型）。虽然该方法已被证明可以正确计算离散模型的 NML 代码长度，但尚未提供连续情况的证明。因此，该方法是否能够准确计算连续模型的 NML 代码长度仍不清楚。在本文中，我们肯定地解决了这个问题，证明该方法对于连续情况也是正确的。值得注意的是，完成连续情况的证明并非易事，因为不能仅仅通过将离散情况中的和替换为积分来实现，因为离散模型情况证明中应用于和的分解技巧不适用于连续模型情况证明中的积分。为了克服这个问题，我们引入了一种基于几何测度理论中的余面积公式的新型分解方法，这对于建立连续情况的证明至关重要。]]></description>
      <guid>https://arxiv.org/abs/2409.08387</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Wasserstein 分布稳健多类支持向量机</title>
      <link>https://arxiv.org/abs/2409.08409</link>
      <description><![CDATA[arXiv:2409.08409v1 公告类型：交叉 
摘要：我们研究数据特征 $\mathbf{x}$ 及其标签 $\mathbf{y}$ 不确定的设置中的多类分类问题。我们发现，分布稳健的一对多 (OVA) 分类器在数据不平衡的环境中经常会遇到困难。为了解决这个问题，我们使用 Wasserstein 分布稳健优化来开发以 Crammer-Singer (CS) 损失为特征的多类支持向量机 (SVM) 的稳健版本。首先，我们证明对于所有 $\mathbf{x} \in \mathcal{X}$ 和 $\mathbf{y} \in \mathcal{Y}$，CS 损失都由 Lipschitz 连续函数从上方界定，然后我们利用强对偶结果来表达最坏情况风险问题的对偶，并表明由于 CS 损失的规律性，最坏情况风险最小化问题允许可处理的凸重构。此外，我们开发了我们提出的模型的内核版本来考虑非线性类分离，并表明它允许可处理的凸上界。我们还为我们提出的线性模型的特殊情况提出了一种投影次梯度方法算法，以提高可扩展性。我们的数值实验表明，在训练数据高度不平衡的环境中，我们的模型优于最先进的 OVA 模型。我们还通过在流行的现实世界数据集上进行的实验表明，我们提出的模型通常优于其正则化模型，因为前者考虑了不确定的标签，而后者则不然。]]></description>
      <guid>https://arxiv.org/abs/2409.08409</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CausalBench 介绍：用于因果分析和机器学习的灵活基准框架</title>
      <link>https://arxiv.org/abs/2409.08419</link>
      <description><![CDATA[arXiv:2409.08419v1 公告类型：交叉 
摘要：在见证机器学习 (ML) 技术在许多应用中取得非凡成功的同时，用户开始注意到 ML 的一个关键缺点：相关性无法替代因果关系。发现因果关系的传统方法是使用随机对照实验 (RCT)；然而，在许多情况下，这些方法不切实际或有时不道德。从观察数据中进行因果学习提供了一种有希望的替代方案。虽然因果学习相对较新，但它旨在远远超越传统的机器学习，但仍存在几个主要挑战。不幸的是，由于缺乏统一的基准数据集、算法、指标和因果学习评估服务接口，进展受到阻碍。在本文中，我们介绍了一个透明、公平且易于使用的评估平台 {\em CausalBench}，旨在 (a) 通过促进新算法、数据集和指标方面的科学合作，推动因果学习研究的进步；(b) 促进因果学习研究中的科学客观性、可重复性、公平性和对偏见的认识。CausalBench 提供基准数据、算法、模型和指标的服务，影响广泛的科学和工程学科的需求。]]></description>
      <guid>https://arxiv.org/abs/2409.08419</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于熵的水平集可视化不确定性建模测试和开发框架</title>
      <link>https://arxiv.org/abs/2409.08445</link>
      <description><![CDATA[arXiv:2409.08445v1 公告类型：交叉 
摘要：我们提出了一个简单的比较框架，用于测试和开发不确定行进立方体实现中的不确定性建模。选择表示不确定值概率分布的模型直接影响不确定性可视化算法的内存使用、运行时间和准确性。我们直接对集合数据使用熵计算来建立预期结果，然后比较各种概率模型的熵，包括均匀、高斯、直方图和分位数模型。我们的结果验证了与集合分布匹配的模型确实与熵匹配。我们进一步表明，非参数直方图模型中较少的箱更有效，而分位数模型中大量的箱接近数据准确性。]]></description>
      <guid>https://arxiv.org/abs/2409.08445</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改进 Stein 变分梯度下降的有限粒子收敛速度</title>
      <link>https://arxiv.org/abs/2409.08469</link>
      <description><![CDATA[arXiv:2409.08469v1 公告类型：交叉 
摘要：我们为核 Stein 差异 ($\mathsf{KSD}$) 和 Wasserstein-2 度量中的 Stein 变分梯度下降 (SVGD) 算法提供了有限粒子收敛速度。我们的主要见解是观察到，从常规初始分布开始，$N$ 个粒子位置的联合密度与 $N$ 倍乘积目标测量之间的相对熵的时间导数分裂为占主导地位的“负部分”，与预期 $\mathsf{KSD}^2$ 的 $N$ 倍成比例，以及较小的“正部分”。这一观察导致 $\mathsf{KSD}$ 速率为 $1/\sqrt{N}$ 阶，与~\cite{shi2024finite} 的最新结果相比，提供了接近最佳的双指数改进。在对核和势能做出温和假设的情况下，这些边界在维度 $d$ 上也呈线性增长。通过向核添加双线性分量，上述方法可用于进一步获得 Wasserstein-2 收敛。对于“双线性 + Mat\&#39;ern”核的情况，我们推导出 Wasserstein-2 速率，其表现出与 i.i.d. 设置类似的维数灾难。我们还获得了时间平均粒子定律的边际收敛和混沌的长期传播结果。]]></description>
      <guid>https://arxiv.org/abs/2409.08469</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于子图的链接预测扩散模型</title>
      <link>https://arxiv.org/abs/2409.08487</link>
      <description><![CDATA[arXiv:2409.08487v1 公告类型：交叉 
摘要：去噪扩散概率模型 (DDPM) 代表了一类当代生成模型，在综合和最大化数据似然性方面都具有卓越的品质。这些模型通过遍历数据受到扰动的前向马尔可夫链来工作，然后进行反向过程，其中神经网络学习消除扰动并恢复原始数据。人们越来越多地探索 DDPM 在图域中的应用。然而，他们中的大多数都集中在生成视角上。在本文中，我们旨在构建一种用于链接预测的新型生成模型。具体而言，我们将一对节点之间的链接预测视为其封闭子图的条件似然估计。通过专门的设计通过贝叶斯公式分解似然估计过程，我们能够分离子图结构的估计及其节点特征。这样的设计使我们的模型能够同时享受归纳学习和强大的泛化能力的优势。值得注意的是，在各种数据集上进行的全面实验验证了我们提出的方法具有许多优势：（1）无需重新训练即可跨数据集迁移，（2）在有限的训练数据上具有良好的泛化能力，（3）对图对抗攻击具有鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2409.08487</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果 GNN：一种用于网络因果推理的 GNN 驱动的工具变量方法</title>
      <link>https://arxiv.org/abs/2409.08544</link>
      <description><![CDATA[arXiv:2409.08544v1 公告类型：交叉 
摘要：随着网络数据应用的不断扩展，网络内的因果推理引起了越来越多的关注。然而，隐藏的混杂因素使因果效应的估计变得复杂。大多数方法依赖于强可忽略性假设，该假设假定不存在隐藏的混杂因素——这一假设在实践中既难以验证，又往往不切实际。为了解决这个问题，我们提出了 CgNN，这是一种新方法，它利用网络结构作为工具变量 (IV)，结合图神经网络 (GNN) 和注意力机制，以减轻隐藏的混杂因素偏差并改善因果效应估计。通过利用网络结构作为 IV，我们可以减少混杂因素偏差，同时保留与治疗的相关性。我们对注意力机制的整合增强了稳健性并提高了重要节点的识别能力。通过在两个真实数据集上的验证，我们的结果表明 CgNN 有效地减轻了隐藏的混杂偏差，并为复杂网络数据中的因果推理提供了一个强大的 GNN 驱动的 IV 框架。]]></description>
      <guid>https://arxiv.org/abs/2409.08544</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>