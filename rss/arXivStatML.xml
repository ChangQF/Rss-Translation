<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Tue, 11 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>非平滑随机近似中的在线协方差估计</title>
      <link>https://arxiv.org/abs/2502.05305</link>
      <description><![CDATA[ARXIV：2502.05305V1公告类型：新 
摘要：我们考虑应用随机近似（SA）方法来解决非平滑变分包容问题。现有的研究表明，SA方法的平均迭代均表现出渐近态性，在H \&#39;Ajek和Le Cam的局部最小值中具有最佳的限制协方差矩阵。但是，尚未提出任何方法来估计该协方差矩阵以非平滑且潜在的非单调（非convex）设置。在本文中，我们研究了在Zhu等人（2023）中引入的在线批处理协方差矩阵估计器。估算器对SA进行了适当的迭代，并计算批次之间的样本协方差，以作为限制协方差的估计。它的构造不需要事先了解总样本量，并且可以在新数据到达时递归执行更新。我们确定，只要正确指定了批处理大小序列（取决于步骤序列），估算器就会达到订单$ o（\ sqrt {d} n^{ -  1/8+\ varepsilon}的收敛速率） $对于任何$ \ varepsilon&gt; 0 $，其中$ d $和$ n $表示问题维度以及所使用的迭代次数（或示例）。尽管问题是非平滑的，并且潜在的非符号酮（非凸），但我们的收敛速率与仅在平滑且强烈的convex设置中仅使用一阶信息的协方差估计方法匹配的率。该协方差估计器的一致性可实现渐近有效的统计推断，包括构建置信区间和进行假设检验。]]></description>
      <guid>https://arxiv.org/abs/2502.05305</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DYNOGP：动态系统识别的深层高斯过程</title>
      <link>https://arxiv.org/abs/2502.05620</link>
      <description><![CDATA[ARXIV：2502.05620V1公告类型：新 
摘要：在这项工作中，我们基于特定类别的高斯过程（深GPS）提供了一种新型的动力系统系统识别方法。这些模型是通过互连线性动力学GP（相当于随机线性时间流动动力学系统）和静态GPS（以建模静态非线性）来构建的。我们的方法结合了数据驱动方法的优势，例如基于神经网络体系结构的方法，并能够输出概率分布。这为系统识别提供了一个更全面的框架，其中包括不确定性量化。使用模拟和实际数据，我们证明了所提出方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.05620</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于颠倒强化学习，目标条件有监督的学习和在线决策变形金刚的融合和稳定性</title>
      <link>https://arxiv.org/abs/2502.05672</link>
      <description><![CDATA[ARXIV：2502.05672V1公告类型：新 
摘要：本文对情节颠倒的强化学习，目标有监督的学习和在线决策变压器的融合和稳定性进行了严格的分析。这些算法在从游戏到机器人任务的各种基准的各种基准上进行了竞争性，但是它们的理论理解仅限于特定的环境条件。这项工作为算法启动了理论基础，该算法基于通过监督的学习或序列建模来接近强化学习的广泛范式。这项研究的核心是对基础环境的条件分析，算法可以识别最佳解决方案。我们还评估了在环境受到较小噪声水平的情况下，新兴解决方案是否保持稳定。具体而言，我们根据基础马尔可夫决策过程的过渡内核研究了命令条件政策，价值观和目标实现目标的连续性和渐近收敛性。我们证明，如果过渡内核位于确定性内核的足够小社区，则实现了近乎最佳的行为。上述数量在确定性内核上是连续的（相对于特定拓扑），无论是渐近的还是在有限数量的学习周期之后。开发的方法使我们能够根据基础过渡内核提出有关策略和值的收敛性和稳定性的第一个明确估计。在理论方面，我们介绍了许多新概念来加强学习，例如在细分空间中工作，研究商拓扑的连续性以及动态系统的定点理论的应用。理论研究伴随着对示例环境和数值实验的详细研究。]]></description>
      <guid>https://arxiv.org/abs/2502.05672</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>广义的维恩和维恩 - 默认校准，并在保形预测中应用</title>
      <link>https://arxiv.org/abs/2502.05676</link>
      <description><![CDATA[ARXIV：2502.05676V1公告类型：新 
摘要：确保模型校准对于可靠的预测至关重要，但仅提供渐近保证的可靠预测，但没有流行的无分布方法，例如直方图箱和等渗回归。我们引入了维恩和维恩 - 珀斯校准的统一框架，将VOVK的二进制分类方法推广到任意预测任务和损失功能。 Venn校准利用将包装校准器构建预测集，这些预测集包含有限样本中至少一个略有完美校准的点预测，从而在校准过程中捕获了认知不确定性。这些集合的宽度渐近地收缩至零，并收敛到有条件校准的点预测。此外，我们提出了Venn Multicalibration，这是一种用于跨亚群的有限样本校准的新方法。对于分位数损失，作为Venn多核电的特殊情况，群体条件和多校准的保形预测会产生，而Venn校准产生了实现分位数条件覆盖率的新型完美预测间隔。作为一个单独的贡献，我们将无分布的条件校准范围扩展到直方图融合和等渗校准的一般损失的保证。]]></description>
      <guid>https://arxiv.org/abs/2502.05676</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TD（0）学习收敛于多项式混合和非线性函数</title>
      <link>https://arxiv.org/abs/2502.05706</link>
      <description><![CDATA[ARXIV：2502.05706V1公告类型：新 
摘要：关于时间差异（TD）学习的理论工作为马尔可夫链生成的数据提供了有限样本和高概率的保证。但是，这些边界通常需要线性函数近似，实例依赖性步骤大小，算法修改和限制性混合速率。我们在更适用的假设下介绍了TD学习的理论发现，包括独立于实例的步骤大小，完整的数据利用和多项式界面性，适用于线性和非线性函数。 \ textbf {据我们所知，这是Markov数据在通用和实例无关的步骤尺寸下的TD（0）收敛的第一个证明。}虽然每个贡献本身很重要，但它们的组合允许这些界限有效地利用实际应用程序设置。我们的结果包括线性模型的边界和在广义梯度下的非线性和较旧的连续性。]]></description>
      <guid>https://arxiv.org/abs/2502.05706</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用形状约束的线性评估模型中的动态定价</title>
      <link>https://arxiv.org/abs/2502.05776</link>
      <description><![CDATA[ARXIV：2502.05776V1公告类型：新 
摘要：我们为线性估值模型中审查数据的动态定价提出了一种形状受限的方法，该方法消除了现有方法中通常需要的调整参数的需求。先前的工作已经解决了未知市场噪声分布F的挑战，使用策略从内核方法到强化学习算法，例如lipschitz（且更强的）假设，例如$ f_0 $ 。相比之下，我们的方法依赖于较弱的假设，即$ f_0 $是$ \ alpha $  - 在（0,1] $的某些$ \ alpha \ in（0,1] $中，我们都会在渐近的预期遗憾的是，我们获得了上限与$ \ alpha = 1 $（Lipschitz案例）的文献中的现有界限匹配。与文献中的几种现有方法进行比较，同时提供了完全免费调整参数的优势。]]></description>
      <guid>https://arxiv.org/abs/2502.05776</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混沌的繁殖用于平均场Langevin动力学及其用于模型集合的应用</title>
      <link>https://arxiv.org/abs/2502.05784</link>
      <description><![CDATA[ARXIV：2502.05784V1公告类型：新 
摘要：平均场Langevin Dynamics（MFLD）是一种优化方法，它通过在平均场状态下的两层神经网络中取出噪声梯度下降的平均场限制。最近，MFLD的混乱（POC）的传播引起了人们的注意，因为它通过颗粒和迭代的数量提供了优化复杂性的定量表征。 Chen等人的出色进步。 （2022）表明，由于颗粒数量增加，由于有限粒子引起的近似误差保持均匀，并且随着颗粒数量的增加而减少。在本文中，通过完善神经网络训练设置下的有缺陷的对数 - 库布勒夫不平等的不平等 - 这是早期工作的关键结果，我们为MFLD建立了改进的POC结果，从而消除了对正则化系数的指数依赖性优化复杂性的粒子近似项。作为应用程序，我们提出了一种基于POC的模型集成策略，并提供了理论保证。]]></description>
      <guid>https://arxiv.org/abs/2502.05784</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>渐近的FDR控制具有模型X仿型：矩匹配是否足够？</title>
      <link>https://arxiv.org/abs/2502.05969</link>
      <description><![CDATA[ARXIV：2502.05969V1公告类型：新 
摘要：我们提出了一个统一的理论框架，用于研究Model-X仿冒品框架的鲁棒性，通过研究对实际实施的近似仿冒程序的渐近假发现率（FDR）的控制。该过程通过将真实协变量分布替换为用户指定的分布，从而偏离了Model-X仿冒框架框架，可以使用样本中的观测值学习。通过在近似仿冒统计的三个条件下替换Model-X仿型变量的分布交换性条件，我们确定近似仿冒程序可以实现渐近FDR控制。使用我们的统一框架，我们进一步证明，可以说是最常用的仿冒变量生成方法 - 基于前两个时刻匹配的高斯仿制生成器 - 促进了渐近FDR控制，当时是在两位基于两位数的基于两位数的仿制统计数据时仿制推理过程。在文献中，我们的理论结果首次正式证明了高斯仿制发生器的有效性和鲁棒性。进行仿真和实际数据示例以验证理论发现。]]></description>
      <guid>https://arxiv.org/abs/2502.05969</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>指数家族中反问题的扩散模型</title>
      <link>https://arxiv.org/abs/2502.05994</link>
      <description><![CDATA[ARXIV：2502.05994V1公告类型：新 
摘要：扩散模型已成为解决反问题的强大工具，但先前的工作主要集中于使用高斯测量噪声的观察，从而限制了它们在现实世界中的使用。由于可能性得分的可行性，这种限制仍然存在，直到现在，在更简单的高斯似然情况下才近似。在这项工作中，我们将扩散模型扩展到处理逆问题，观察结果遵循指数家族的分布，例如泊松或二项式分布。通过利用指数家庭分布的共轭属性，我们介绍了证据技巧，这是一种可与可能性得分的可拖动近似的方法。在我们的实验中，我们证明了我们的方法论可以有效地对贝叶斯进行贝叶斯的推断，这些推论在空间不均匀的泊松过程中，其强度为复杂，就像Imagenet图像一样复杂。此外，我们通过表明它与当前最新的疟疾估计估计值的最新性能相竞争，从而证明了我们方法论的现实影响。]]></description>
      <guid>https://arxiv.org/abs/2502.05994</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变形金刚与多级集群中的EM算法与EM算法</title>
      <link>https://arxiv.org/abs/2502.06007</link>
      <description><![CDATA[ARXIV：2502.06007V1公告类型：新 
摘要：LLM使用变压器模型作为骨干，在复杂的机器学习任务中显示出显着的推理能力。由于对这种模型对无监督学习问题的有限理解的动机，我们研究了变形金刚在执行高斯混合模型多级聚类中的学习保证。我们开发了一种理论，在软磁性层与EM算法的工作流程之间的工作流程在聚集高斯的混合物方面之间存在牢固的联系。我们的理论通过证明软马克斯函数的多元映射的通用近似能力，为期望和最大化步骤提供了近似界限。除了近似保证外，我们还表明，使用足够数量的预训练样本和初始化，变形金刚可以实现所考虑的问题的最小最佳速率。我们广泛的模拟通过揭示变形金刚的强大学习能力甚至超出了理论的假设，阐明了LLMS强大的推论能力，从而验证了我们的理论。]]></description>
      <guid>https://arxiv.org/abs/2502.06007</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不确定性量化和因果关系决定的因素</title>
      <link>https://arxiv.org/abs/2502.06011</link>
      <description><![CDATA[ARXIV：2502.06011V1公告类型：新 
摘要：非政策评估（OPE）是强大决策中的一个关键挑战，该挑战旨在使用不同政策中收集的数据评估新政策的绩效。但是，现有的OPE方法遭受了统计不确定性以及因果考虑的几个局限性。在本文中，我们通过提出三个不同的作品来解决这些局限性。首先，我们考虑基于重要性采样估计器的高度差异问题。我们介绍了边际比率（MR）估计器，这是一种新型的OPE方法，它通过关注结果的边际分布而不是直接的策略转移来降低差异，从而改善了上下文匪徒的鲁棒性。接下来，我们提出保形外政预测（COPP），这是OPE中不确定性量化的原则方法，可提供有限的样本预测间隔，从而确保对风险敏感的应用程序进行强大的决策。最后，我们通过为连续决策设置开发新颖的界限来解决非政策决策中的因果难以确定性，这些决策设置在任意未衡量的混杂状态下仍然有效。我们应用这些界限来评估数字双胞胎模型的可靠性，并引入了一个伪造框架，以确定模型预测与现实世界行为不同的方案。我们的贡献为不确定性下的强大决策提供了新的见解，并建立了在静态和动态设置中评估政策的原则方法。]]></description>
      <guid>https://arxiv.org/abs/2502.06011</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用标志嵌套子空间学习</title>
      <link>https://arxiv.org/abs/2502.06022</link>
      <description><![CDATA[ARXIV：2502.06022V1公告类型：新 
摘要：许多机器学习方法寻找数据的低维表示。可以通过首先选择尺寸$ q $，然后在$ q $维二维子空间（Grassmannian）上优化某个目标功能来估算基础子空间。尝试不同的$ Q $收益率在一般非巢子空间中，这引发了数据表示之间的一致性重要问题。在本文中，我们提出了一个简单的技巧来在子空间学习方法中执行嵌套。它包括通过嵌套投影仪提升格拉斯曼尼亚优化问题来标记歧管（增加维度的嵌套子空间的空间）。我们将标志技巧应用于几种经典的机器学习方法，并证明它成功地解决了嵌套问题。]]></description>
      <guid>https://arxiv.org/abs/2502.06022</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可扩展的差异私人贝叶斯优化</title>
      <link>https://arxiv.org/abs/2502.06044</link>
      <description><![CDATA[ARXIV：2502.06044V1公告类型：新 
摘要：近年来，将贝叶斯优化扩展到高维问题（例如大型神经网络模型中的超级参数调音）方面已经有很多工作。这些可扩展的方法已经成功，比传统的全球贝叶斯优化或基于随机搜索的方法更快地发现高目标值。同时，这些大型神经网络模型经常使用敏感数据，但是差异隐私的保存并未与这些现代贝叶斯优化程序缩放。在这里，我们开发了一种使用梯度信息贝叶斯优化的私人估计潜在高维参数空间的方法。我们的理论结果证明，在适当的条件下，我们的方法将指数级收敛到最佳参数配置周围的球。此外，无论是否满足假设，我们都表明，我们的算法始终保持隐私，并在凭经验上证明了在高维超参数设置中的现有方法的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2502.06044</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Lipschitz驱动的推断：空间线性模型的偏差校正置信区间</title>
      <link>https://arxiv.org/abs/2502.06067</link>
      <description><![CDATA[ARXIV：2502.06067V1公告类型：新 
摘要：由于其可解释性，速度和可重复性，线性模型在现代空间应用中无处不在 - 包括气候科学，公共卫生和经济学。尽管从业者通常报告一种不确定性的形式，但流行的空间不确定性量化方法并不能共同处理模型错误指定和分配转移 - 尽管两者本质上都总是存在于空间问题中。在本文中，我们表明，空间线性模型中构建置信度（或可信度）间隔的现有方法无法提供正确的覆盖范围，这是由于不偏见的偏见。与依赖于I.I.D.的经典方法相反。假设在空间问题中是不合适的，在当前的工作中，我们做出了空间平滑度（Lipschitz）假设。然后，我们能够提出一种新的置信区间结构，以说明估计程序中的偏见。我们证明我们的新方法通过理论和实验实现了名义覆盖范围。可以在https://github.com/davidrburt/lipschitz-driven-inference上获得复制实验的代码。]]></description>
      <guid>https://arxiv.org/abs/2502.06067</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>顺序更改点本定位的检测后推断</title>
      <link>https://arxiv.org/abs/2502.06096</link>
      <description><![CDATA[ARXIV：2502.06096V1公告类型：新 
摘要：本文解决了顺序更改点分析中的基本但在很大程度上没有探索的挑战：在检测到的变化后进行推理。我们仅使用观察到的数据依赖数据的停止时间来研究更改点的问题，在该数据中，顺序检测算法$ \ MATHCAL A $声明了更改。当假定已知的更改前和后变化分布时，我们首先为未知更改点构建置信度集。然后，我们将框架扩展到复合前后的情况。我们在观察空间或$ \ Mathcal a $上不施加任何条件 - 我们只需要能够在模拟数据序列上运行$ \ Mathcal a $即可。总而言之，这项工作提供了理论上的声音和实际有效的工具来进行连续更改点本地化。]]></description>
      <guid>https://arxiv.org/abs/2502.06096</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>