<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 23 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>表格生物医学数据低性能机器学习中特征重要性的有效性</title>
      <link>https://arxiv.org/abs/2409.13342</link>
      <description><![CDATA[arXiv:2409.13342v1 公告类型：新
摘要：在表格生物医学数据分析中，将模型调整到高精度被认为是讨论特征重要性的先决条件，因为医学从业者期望特征重要性的有效性与性能相关。在这项工作中，我们挑战了普遍的看法，表明低性能模型也可以用于特征重要性。我们提出实验来观察特征等级随性能下降而发生的变化。使用三个合成数据集和六个真实生物医学数据集，我们将完整数据集中的特征等级与样本量减少（数据切割）或特征较少（特征切割）的数据集进行比较。在合成数据集中，特征切割不会改变特征等级，而数据切割则显示出更高的差异和更低的性能。在真实数据集中，特征切割显示的变化与数据切割相似或更小，尽管有些数据集表现出相反的情况。当通过消除相关性来控制特征交互时，特征切割始终表现出更好的稳定性。通过分析特征重要性值的分布，并从理论上检验模型无法区分特征之间的特征重要性的概率，我们发现，尽管通过特征切割会导致性能下降，但模型仍然可以区分特征重要性，但通过数据切割则无法区分。我们得出结论，如果数据量足够大，即使在较低的性能水平下，特征重要性的有效性也可以保持，这是导致表格医疗数据分析性能不佳的一个重要因素。本文展示了在分类器性能不令人满意的情况下，利用特征重要性分析和统计分析来相对比较特征的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.13342</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型医疗模型简介：使用针对患者事件序列进行训练的 transformer 进行最先进的医疗成本和风险预测</title>
      <link>https://arxiv.org/abs/2409.13000</link>
      <description><![CDATA[arXiv:2409.13000v1 公告类型：交叉 
摘要：随着美国医疗保健支出接近 5 万亿美元（NHE 情况说明书 2024），其中 25% 估计是浪费（美国医疗保健系统的浪费：估计成本和节省潜力，无日期），更好地预测风险和最佳患者护理的需求变得越来越重要。本文介绍了大型医疗模型 (LMM)，这是一种生成式预训练转换器 (GPT)，旨在指导和预测患者护理和医疗保健管理的广泛方面。该模型根据来自超过 1.4 亿条纵向患者索赔记录的医疗事件序列进行训练，使用由医学术语系统构建的专业词汇，并展示了预测医疗保健成本和识别潜在风险因素的卓越能力。通过实验和验证，我们展示了 LMM 不仅在成本和风险预测方面的能力，而且还展示了在复杂医疗条件下辨别复杂模式的能力以及识别患者护理中的新关系的能力。在预测多种疾病的研究中，LMM 能够将成本预测提高 14.1%，比最佳商业模型高，将慢性疾病预测提高 1.9%，比最佳变压器模型高。LMM 是医疗分析领域的一项重大进步，具有显著增强风险评估、成本管理和个性化医疗的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.13000</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>时间序列异常检测器的无偏评估</title>
      <link>https://arxiv.org/abs/2409.13053</link>
      <description><![CDATA[arXiv:2409.13053v1 公告类型：交叉 
摘要：时间序列异常检测 (TSAD) 是一个不断发展的研究领域，其动机是其关键应用，例如检测地震活动、工业工厂中的传感器故障、预测股市崩盘等。在各个领域，异常发生的频率明显低于正常数据，这使得 F1 分数成为异常检测最常用的指标。​​然而，在时间序列的情况下，由于“时间点”和“时间事件”之间的分离，使用标准 F1 分数并不简单。为了适应这一点，在 $F_1$ 分数评估之前调整异常预测，称为点调整 (PA)。然而，这些调整是基于启发式的，并且偏向于真正的阳性检测，导致检测器性能被高估。在这项工作中，我们提出了一种称为“平衡点调整”（BA）的替代调整协议。它解决了现有点调整方法的局限性，并通过 TSAD 评估的公理定义提供了公平性的保证。]]></description>
      <guid>https://arxiv.org/abs/2409.13053</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>指导有什么作用？简单环境中的细粒度分析</title>
      <link>https://arxiv.org/abs/2409.13074</link>
      <description><![CDATA[arXiv:2409.13074v1 公告类型：交叉
摘要：在扩散模型中使用指导最初是出于这样的前提：指导修正分数是数据分布的分数，该分数由条件似然的某个幂倾斜。在这项工作中，我们通过严格证明指导无法从预期的倾斜分布中采样来澄清这一误解。
我们的主要结果是对两种情况下的指导动态进行细粒度表征，(1) 紧支撑分布的混合和 (2) 高斯分布的混合，它们反映了指导在现实世界数据上表现出来的显着特性。在这两种情况下，我们都证明，随着指导参数的增加，指导模型从条件分布的支持边界进行更大量的采样。我们还证明，对于任何非零水平的分数估计误差，足够大的指导将导致远离支持的采样，从理论上证明了大指导会导致扭曲的生成这一经验发现。
除了在合成环境中通过经验验证这些结果之外，我们还展示了我们的理论见解如何为实际部署提供有用的建议。]]></description>
      <guid>https://arxiv.org/abs/2409.13074</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用复杂网络和机器学习预测足球比赛</title>
      <link>https://arxiv.org/abs/2409.13098</link>
      <description><![CDATA[arXiv:2409.13098v1 公告类型：交叉 
摘要：足球吸引了众多研究人员和体育行业专业人士的关注。因此，科学与体育运动的结合不断增长，对绩效分析和体育预测行业的投资不断增加。本研究旨在 (i) 强调使用复杂网络作为预测足球比赛结果的替代工具，以及 (ii) 展示如何将传球网络的结构分析与比赛统计数据相结合，以更深入地了解球队使用的比赛模式和策略。为了做到这一点，复杂网络指标和比赛统计数据被用于构建机器学习模型，以预测不同联赛足球队的胜负。结果表明，基于传球网络的模型与使用一般比赛统计数据的“传统”模型一样有效。另一项发现是，通过结合两种方法，可以得到比单独使用两种方法更准确的模型，这表明这两种方法的融合可以更深入地了解比赛模式，从而理解球队采用的战术、球员之间的关系、他们的位置以及比赛期间的互动。值得一提的是，网络指标和比赛统计数据对于混合模型都很重要且影响深远。此外，使用时间演化粒度较低的网络（例如为比赛的每个半场创建一个网络）比为整个比赛创建一个网络表现更好。]]></description>
      <guid>https://arxiv.org/abs/2409.13098</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索大型语言模型训练中局部 SGD 的缩放规律</title>
      <link>https://arxiv.org/abs/2409.13198</link>
      <description><![CDATA[arXiv:2409.13198v1 公告类型：交叉 
摘要：本文研究了 LLM 训练中局部 SGD 的缩放规律，LLM 训练是一种分布式优化算法，有助于在松散连接的设备上进行训练。通过大量实验，我们表明，在给定等效模型参数、数据集和计算资源的情况下，局部 SGD 与传统方法相比取得了有竞争力的结果。此外，我们探索了局部 SGD 在各种实际场景中的应用，包括多集群设置和边缘计算环境。我们的研究结果阐明了有效的多集群 LLM 训练的必要条件，并研究了在 LLM 训练过程中利用边缘计算资源的潜力和局限性。这证明了它作为单个大集群训练的替代方案的可行性。]]></description>
      <guid>https://arxiv.org/abs/2409.13198</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过随机抽样实现深度神经网络的有效训练</title>
      <link>https://arxiv.org/abs/2409.13280</link>
      <description><![CDATA[arXiv:2409.13280v1 公告类型：交叉 
摘要：神经算子 (NO) 使用深度神经网络来学习无限维函数空间之间的映射。深度算子网络 (DeepONet) 是一种流行的 NO 架构，已在各种科学和工程应用中成功实时预测复杂动态。在这项工作中，我们介绍了一种在 DeepONet 训练期间采用的随机采样技术，旨在提高模型的泛化能力，同时显著减少计算时间。所提出的方法针对 DeepONet 模型的主干网络，该网络输出与定义物理系统的有界域的时空位置相对应的基函数。传统上，在构建损失函数时，DeepONet 训练会考虑一个统一的时空点网格，每次迭代都会在该网格中评估所有输出函数。由于随机梯度下降 (SGD) 优化器的局限性，这种方法会导致更大的批量大小，从而导致泛化能力差和内存需求增加。所提出的对主干网络输入进行随机采样的方法可以缓解这些挑战，提高泛化能力并减少训练期间的内存需求，从而显著提高计算效率。我们通过三个基准示例验证了我们的假设，结果表明，与传统训练方法相比，在实现相当或更低的整体测试误差的同时，训练时间大幅减少。我们的结果表明，在训练期间将随机化纳入主干网络输入可提高 DeepONet 的效率和稳健性，为提高该框架在复杂物理系统建模方面的性能提供了一条有希望的途径。]]></description>
      <guid>https://arxiv.org/abs/2409.13280</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用秩 1 格进行数据压缩以进行机器学习中的参数估计</title>
      <link>https://arxiv.org/abs/2409.13453</link>
      <description><![CDATA[arXiv:2409.13453v1 公告类型：交叉 
摘要：均方误差及其正则化版本是监督机器学习中的标准损失函数。但是，计算大型数据集的这些损失在计算上可能要求很高。修改 J. Dick 和 M. Feischl [Journal of Complexity 67 (2021)] 的方法，我们提出了使用秩 1 格将大量数据集缩小到较小大小的算法。秩 1 格是准蒙特卡洛 (QMC) 点集，如果经过仔细选择，它们会很好地分布在多维单位立方体中。预处理步骤中的压缩策略根据原始数据和响应为每个格点分配一对权重，表示其相对重要性。因此，压缩数据使优化步骤中的迭代损失计算速度更快。我们分析了 QMC 数据压缩算法的误差以及函数预处理步骤的成本，这些函数的傅里叶系数衰减得足够快，以至于它们位于某些维纳代数或 Korobov 空间中。特别是，我们证明了只要函数足够平滑，我们的方法就可以实现任意高的收敛速度。]]></description>
      <guid>https://arxiv.org/abs/2409.13453</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>边界剥离：使用单类剥离的异常值检测方法</title>
      <link>https://arxiv.org/abs/2309.05630</link>
      <description><![CDATA[arXiv:2309.05630v2 公告类型：替换 
摘要：无监督异常值检测是数据分析中的关键阶段，并且仍然是一个动态的研究领域。良好的异常值检测算法应该具有计算效率、对调整参数选择具有鲁棒性，并且在不同的底层数据分布中始终表现良好。我们引入了一种无监督异常值检测算法——单类边界剥离。单类边界剥离使用由单类支持向量机生成的迭代剥离的灵活边界的平均有符号距离。单类边界剥离具有强大的超参数设置，并且为了增加灵活性，可以将其用作集成方法。在合成数据模拟中，当不存在异常值时，单类边界剥离的表现优于所有最先进的方法，而当存在异常值时，与基准方法相比，单类边界剥离保持了相当或更优越的性能。使用常见的基准数据集，单类边界剥离在正确分类、AUC 和处理时间方面具有竞争力。]]></description>
      <guid>https://arxiv.org/abs/2309.05630</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对抗性正则化的稳健生存分析</title>
      <link>https://arxiv.org/abs/2312.16019</link>
      <description><![CDATA[arXiv:2312.16019v4 公告类型：替换 
摘要：生存分析 (SA) 模拟事件发生的时间，可应用于医学、国防、金融和航空航天等领域。最近的研究表明，神经网络 (NN) 可以有效地捕获 SA 中的复杂数据模式，而简单的广义线性模型在这方面往往存在不足。然而，数据集的不确定性（例如，噪声测量、人为错误）会降低 NN 模型的性能。为了解决这个问题，我们利用 NN 验证方面的进步来开发稳健、全参数 SA 模型的训练目标。具体来说，我们提出了一种基于最小-最大优化问题的对抗稳健损失函数。我们采用 CROWN-区间边界传播 (CROWN-IBP) 来解决解决这个最小-最大问题所固有的计算挑战。评估了 10 多个 SurvSet 数据集后，我们的方法“对抗正则化生存分析 (SAWAR)”在负对数似然 (NegLL)、综合 Brier 评分 (IBS) 和一致性指数 (CI) 指标方面，在各种协变量扰动下始终优于基线对抗训练方法和最先进的 (SOTA) 深度 SA 模型。因此，我们证明对抗鲁棒性可增强 SA 预测性能和校准，减轻数据不确定性，并将跨不同数据集的泛化能力与基线相比提高高达 150%。]]></description>
      <guid>https://arxiv.org/abs/2312.16019</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>差分隐私凸优化的输出扰动：更快、更通用</title>
      <link>https://arxiv.org/abs/2102.04704</link>
      <description><![CDATA[arXiv:2102.04704v2 公告类型：replace-cross 
摘要：寻找高效、易于实现的差分隐私 (DP) 算法并提供强大的超额风险界限是现代机器学习中的一个重要问题。迄今为止，大多数工作都集中在隐私经验风险最小化 (ERM) 或隐私随机凸优化 (SCO) 上，这对应于人口损失最小化。然而，除了传统 ERM/SCO 设置中未捕获的平均性能之外，通常还有其他目标 - 例如公平性、对抗鲁棒性或对异常值的敏感性。此外，隐私 SCO 中的最新工作集中在 $(\varepsilon, \delta)$-DP ($\delta &gt; 0$) 上，而证明 $(\varepsilon, 0)$-差分隐私的严格超额风险和运行时界限仍然是一个具有挑战性的开放问题。我们的第一个贡献是提供已知最严格的 $(\varepsilon, 0)$ 差分隐私预期人口损失界限和最快的运行时间，适用于平滑和强凸损失函数。特别是，对于具有条件良好的平滑和强凸损失函数的 SCO，我们提供了具有最佳超额风险的线性时间算法。对于我们的第二个贡献，我们研究了广泛倾斜损失函数的 DP 优化 - 可用于促进公平性或稳健性，且不一定是 ERM 形式。我们建立了第一个已知的 DP 超额风险和运行时间界限来优化此类；在平滑性和强凸性假设下，我们的界限接近最优。对于我们的第三个贡献，我们将我们的理论专门用于 DP 对抗训练。我们的结果是使用也许是最简单但实用的差分隐私算法实现的：输出扰动。虽然这种方法在概念上并不新颖，但我们的新颖实施方​​案和分析表明，这种方法实现强隐私、实用性和运行时间保证的能力在先前的工作中尚未得到充分重视。]]></description>
      <guid>https://arxiv.org/abs/2102.04704</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过热图回归进行深度单幅图像相机校准以在曼哈顿世界假设下恢复鱼眼图像</title>
      <link>https://arxiv.org/abs/2303.17166</link>
      <description><![CDATA[arXiv:2303.17166v3 公告类型：replace-cross 
摘要：沿着长方体建筑物的曼哈顿世界对于相机角度估计很有用。然而，从曼哈顿世界的鱼眼图像中进行准确而稳健的角度估计仍然是一个悬而未决的挑战，因为一般场景图像往往缺乏线、弧和消失点等约束。为了实现更高的准确性和稳健性，我们提出了一种基于学习的校准方法，该方法使用热图回归（类似于使用关键点的姿势估计）来检测标记图像坐标的方向。同时，我们的两个估计器通过从一般场景图像重新映射来恢复旋转并消除鱼眼失真。在不考虑消失点约束的情况下，我们发现可以定义用于基于学习的方法的附加点。为了弥补图像中消失点的不足，我们引入了具有最佳空间均匀性 3D 排列的辅助对角点。大量实验表明，我们的方法在大型数据集和现成的相机上优于传统方法。]]></description>
      <guid>https://arxiv.org/abs/2303.17166</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>结构化径向基函数网络：多假设预测的建模多样性</title>
      <link>https://arxiv.org/abs/2309.00781</link>
      <description><![CDATA[arXiv:2309.00781v2 公告类型：replace-cross 
摘要：多模态问题可以通过使用多个假设框架来有效解决，但将这些框架集成到学习模型中带来了重大挑战。本文介绍了一种结构化径向基函数网络 (s-RBFN)，作为用于回归的多个假设预测器的集合。在训练预测器的过程中，首先根据它们的损失和真实标签形成质心 Voronoi 镶嵌，以几何方式表示多个假设的集合。然后，使用训练后的预测器计算带有其预测的结构化数据集，包括基函数的中心和尺度。随后使用该结构化数据集训练径向基函数网络，每个基函数都专注于特定的假设，以进行多个假设预测。s-RBFN 旨在高效训练，同时以参数方式控制集成学习中的多样性。用于训练结构化集成模型的最小二乘法为多个假设和结构化预测提供了闭式解决方案。在结构化数据集的形成过程中，使用一个参数通过控制镶嵌形状来避免模式崩溃。此参数提供了一种平衡 s-RBFN 多样性和泛化性能的机制。对两个多变量预测数据集（空气质量和能源设备预测）的实证验证表明，与其他模型及其单假设模型相比，结构化集成模型具有更优越的泛化性能和计算效率。]]></description>
      <guid>https://arxiv.org/abs/2309.00781</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经验组分布稳健优化及其他方面的高效算法</title>
      <link>https://arxiv.org/abs/2403.03562</link>
      <description><![CDATA[arXiv:2403.03562v2 公告类型：replace-cross 
摘要：在本文中，我们研究了群体分布稳健优化 (GDRO) 的经验对应物，其目的是最小化 $m$ 个不同群体的最大经验风险。我们将经验 GDRO 表述为 $\textit{two-level}$ 有限和凸凹极小最大优化问题，并开发了一种称为 ALEG 的算法以受益于其特殊结构。ALEG 是一种双循环随机原始对偶算法，它将方差减少技术结合到改进的镜像临近例程中。为了利用两级有限和结构，我们提出了一种简单的组抽样策略来构建具有较小 Lipschitz 常数的随机梯度，然后对所有组执行方差减少。理论分析表明，ALEG 在计算复杂度为 $\mathcal{O}\left(\frac{m\sqrt{\bar{n}\ln{m}}}{\varepsilon}\right)$ 的情况下实现了 $\varepsilon$ 精度，其中 $\bar n$ 是 $m$ 组样本的平均数量。值得注意的是，我们的方法比最先进的方法高出 $\sqrt{m}$ 倍。基于 ALEG，我们进一步开发了一种称为 ALEM 的两阶段优化算法来处理经验极小最大超额风险优化 (MERO) 问题。ALEM 的计算复杂度几乎与 ALEG 相当，超过了现有方法的速率。]]></description>
      <guid>https://arxiv.org/abs/2403.03562</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于数据相关随机特征的分散核岭回归</title>
      <link>https://arxiv.org/abs/2405.07791</link>
      <description><![CDATA[arXiv:2405.07791v3 公告类型：replace-cross 
摘要：随机特征（RF）已被广泛用于分散核岭回归（KRR）中的节点一致性。目前，一致性是通过对特征系数施加约束来保证的，这就要求不同节点上的随机特征相同。然而，在许多应用中，不同节点上的数据在数量或分布上差异很大，这就需要自适应和数据相关的方法来生成不同的RF。为了解决这一根本困难，我们提出了一种新的分散式KRR算法，该算法追求决策函数的一致性，具有很大的灵活性，可以很好地适应节点上的数据。收敛性是严格给出的，有效性是通过数值验证的：通过捕捉每个节点上数据的特征，同时保持与其他方法相同的通信成本，我们在六个真实数据集上实现了平均25.5%的回归精度提升。]]></description>
      <guid>https://arxiv.org/abs/2405.07791</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>