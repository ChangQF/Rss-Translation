<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 30 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>批量贝叶斯优化的最优初始化</title>
      <link>https://arxiv.org/abs/2404.17997</link>
      <description><![CDATA[arXiv:2404.17997v1 公告类型：交叉
摘要：现场实验和计算机模拟是测量不同设置下工程系统质量的有效但耗时的方法。为了减少所需的总时间，实验者可以采用贝叶斯优化（这种方法对测量很简洁），并批量同时测量多个设置。在实践中，实验者使用的批次非常少，因此，每个批次都必须提供尽可能多的信息。通常，批量贝叶斯优化 (BBO) 中的初始批次是根据设置值的准随机样本构建的。我们提出了一种批量设计采集函数，最小终端方差（MTV），它通过优化而不是随机采样来设计批量。 MTV 采用了实验设计中的设计标准函数，称为 I-Optimality，它最大限度地减少了质量评估后估计的方差，并在整个设置空间上进行了集成。 MTV 通过设置最佳的概率对积分进行加权，使其不仅能够设计初始批次，还能够设计所有后续批次。在采集函数中，对初始化和后续批次的适用性是新颖的。测试函数和模拟器的数值实验表明MTV优于其他BBO方法。]]></description>
      <guid>https://arxiv.org/abs/2404.17997</guid>
      <pubDate>Wed, 01 May 2024 01:03:40 GMT</pubDate>
    </item>
    <item>
      <title>共形排序检索</title>
      <link>https://arxiv.org/abs/2404.17769</link>
      <description><![CDATA[arXiv:2404.17769v1 公告类型：交叉
摘要：鉴于排序检索技术在各种信息系统中的广泛采用对我们的日常生活产生了重大影响，因此越来越需要评估和解决其预测中固有的不确定性。本文介绍了一种使用共形风险控制框架在排名检索问题的背景下定量测量和管理风险的新方法。我们的研究重点是典型的两阶段排名检索问题，其中检索阶段生成后续排名的候选者。通过仔细制定每个阶段的共形风险，我们开发了算法来有效地将这些风险控制在指定的范围内。我们提出的方法的有效性已经通过对三个用于排名检索任务的大型公共数据集（包括 MSLR-WEB 数据集、Yahoo LTRC 数据集和 MS MARCO 数据集）的综合实验得到了证明。]]></description>
      <guid>https://arxiv.org/abs/2404.17769</guid>
      <pubDate>Wed, 01 May 2024 01:03:39 GMT</pubDate>
    </item>
    <item>
      <title>策略梯度的控制随机化方法及其在最优切换中强化学习的应用</title>
      <link>https://arxiv.org/abs/2404.17939</link>
      <description><![CDATA[arXiv:2404.17939v1 公告类型：交叉
摘要：我们提出了一个针对连续时间强化学习的策略梯度方法的综合框架。这是基于随机控制问题和随机问题之间的联系，使应用能够跨越各种类别的马尔可夫连续时间控制问题，超出扩散模型，包括例如常规、脉冲和最佳停止/切换问题。通过利用控制随机化技术中的测量变化，我们为这些随机问题得出了新的策略梯度表示，其特征是参数化强度策略。我们进一步开发专门设计用于解决一般马尔可夫随机控制问题的行动者批评算法。我们的框架通过其在最优切换问题上的应用得到了证明，其中有两个能源领域的数值案例研究重点关注实物期权。]]></description>
      <guid>https://arxiv.org/abs/2404.17939</guid>
      <pubDate>Wed, 01 May 2024 01:03:39 GMT</pubDate>
    </item>
    <item>
      <title>回归的柯西-施瓦茨散度信息瓶颈</title>
      <link>https://arxiv.org/abs/2404.17951</link>
      <description><![CDATA[arXiv:2404.17951v1 公告类型：交叉
摘要：信息瓶颈（IB）方法普遍用于提高深度神经网络的泛化性、鲁棒性和可解释性。本质上，它的目标是通过在压缩项 $I(\mathbf{x};\mathbf{t})$ 和预测项 $I( y;\mathbf{t})$，其中$I(\cdot;\cdot)$指的是互信息(MI)。 MI 用于 IB，大部分以 Kullback-Leibler (KL) 散度表示，在回归情况下对应于基于均方误差 (MSE) 损失的预测，采用高斯假设和通过变分推理近似的压缩。在本文中，我们研究了回归问题的 IB 原理，并通过利用 Cauchy-Schwarz (CS) 散度的有利特性，开发了一种利用深度神经网络对 IB 进行参数化的新方法。通过这样做，我们摆脱了基于 MSE 的回归，并通过避免变分近似或分布假设来简化估计。我们研究了我们提出的 CS-IB 的泛化能力的提高，并展示了强大的对抗鲁棒性保证。我们在六个现实世界的回归任务中展示了其优于其他流行的深度 IB 方法的卓越性能。我们还观察到，CS-IB 发现的解决方案总是在信息平面中实现预测精度和压缩比之间的最佳权衡。代码可在 \url{https://github.com/SJYuCNEL/Cauchy-Schwarz-Information-Bottleneck} 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.17951</guid>
      <pubDate>Wed, 01 May 2024 01:03:39 GMT</pubDate>
    </item>
    <item>
      <title>所有合理参数机制下高斯协方差矩阵私人估计的下界</title>
      <link>https://arxiv.org/abs/2404.17714</link>
      <description><![CDATA[arXiv:2404.17714v1 公告类型：交叉
摘要：我们证明了私下估计高斯分布的协方差矩阵所需的样本数量的下界。我们的界限与最广泛已知的参数设置中的现有上限相匹配。我们的分析依赖于斯坦因-哈夫恒等式，这是先前指纹引理论证中使用的经典斯坦因恒等式的扩展。]]></description>
      <guid>https://arxiv.org/abs/2404.17714</guid>
      <pubDate>Wed, 01 May 2024 01:03:38 GMT</pubDate>
    </item>
    <item>
      <title>关于无限假设集的罗生门比率</title>
      <link>https://arxiv.org/abs/2404.17746</link>
      <description><![CDATA[arXiv:2404.17746v1 公告类型：交叉
摘要：给定一个分类问题和一组分类器，罗生门比率衡量分类器产生小于给定损失的比例。先前的工作探讨了在有限的分类器族的情况下大罗生门比的优势。这里我们考虑无限族的更一般情况。我们证明，大的罗生门比率保证了在族的随机子集中选择具有最佳经验准确性的分类器，这可能会提高泛化性，但不会增加经验损失太多。我们在涉及无限分类器族的两个例子中量化了罗生门比率，以说明罗生门比率很大的情况。在第一个示例中，我们使用仿射分类器估计正态分布类的分类的罗生门比率。在第二个例子中，当分类器族由双层 ReLU 神经网络组成时，我们使用修正的 Gram 矩阵获得了分类问题的罗生门比的下界。一般来说，我们表明可以使用训练数据集以及来自分类器系列的随机样本来估计罗生门比率，并且我们保证这种估计接近罗生门比率的真实值。]]></description>
      <guid>https://arxiv.org/abs/2404.17746</guid>
      <pubDate>Wed, 01 May 2024 01:03:38 GMT</pubDate>
    </item>
    <item>
      <title>具有难处理的规范化常数的完全和部分观测指数族图模型中的基于似然的推理</title>
      <link>https://arxiv.org/abs/2404.17763</link>
      <description><![CDATA[arXiv:2404.17763v1 公告类型：交叉
摘要：编码底层马尔可夫随机场的概率图模型是生成建模的基本构建块，用于学习具有复杂依赖结构的现代多元数据集中的潜在表示。其中，指数族图模型特别受欢迎，因为它们具有相当容易理解的统计特性以及基于伪似然方法的高维数据的计算可扩展性。这些模型已成功应用于许多领域，例如统计物理学中的伊辛模型和基因组学中的计数图模型。另一种模型允许一些节点是潜在的，以便允许可观察节点的边缘分布偏离指数族，以捕获更复杂的依赖关系。这些方法构成了人工智能生成模型的基础，例如玻尔兹曼机及其受限版本。在完全和部分观察的情况下，基于似然性（即最大似然性和完全贝叶斯）推理的一个基本障碍是似然性的棘手性。通常的解决方法是采用基于伪似然的方法，遵循 Besag (1974) 的开创性工作。本文的目的是证明这些模型的基于完全似然的分析以计算有效的方式是可行的。主要创新在于使用 Geyer (1991) 的技术来估计棘手的图形模型的棘手的归一化常数及其梯度。大量的数值结果、支持理论以及与基于伪似然方法的比较证明了所提出方法的适用性。]]></description>
      <guid>https://arxiv.org/abs/2404.17763</guid>
      <pubDate>Wed, 01 May 2024 01:03:38 GMT</pubDate>
    </item>
    <item>
      <title>具有双重上下文信息的低排名在线动态分类</title>
      <link>https://arxiv.org/abs/2404.17592</link>
      <description><![CDATA[arXiv:2404.17592v1 公告类型：交叉
摘要：随着电子商务的扩展，从大量目录中提供实时个性化推荐对零售平台提出了严峻的挑战。最大化收入需要仔细考虑个人客户特征和可用商品功能，以随着时间的推移优化分类。在本文中，我们考虑具有双重上下文（用户和项目特征）的动态分类问题。在高维场景中，维度的二次增长使计算和估计变得复杂。为了应对这一挑战，我们引入了一种新的低阶动态分类模型，将这个问题转化为可管理的规模。然后，我们提出了一种有效的算法来估计内在子空间，并利用置信上限方法来解决在线决策中的探索-利用权衡。理论上，我们建立$\tilde{O}((d_1+d_2)r\sqrt{T})$的后悔界限，其中$d_1，d_2$分别表示用户和项目特征的维度，$r$是参数矩阵的秩，$T$表示时间范围。这个界限代表了对先前文献的实质性改进，这是通过利用低秩结构实现的。广泛的模拟和对 Expedia 酒店推荐数据集的应用进一步证明了我们提出的方法的优势。]]></description>
      <guid>https://arxiv.org/abs/2404.17592</guid>
      <pubDate>Wed, 01 May 2024 01:03:37 GMT</pubDate>
    </item>
    <item>
      <title>DeepVARMA：用于化工行业指数预测的混合深度学习和 VARMA 模型</title>
      <link>https://arxiv.org/abs/2404.17615</link>
      <description><![CDATA[arXiv:2404.17615v1 Announce Type: cross 
摘要：化工行业指数是衡量化工行业发展的重要指标之一，对其进行预测对于了解行业经济形势和趋势至关重要。以多变量非平稳序列——合成材料指数为主要研究对象，本文提出了一种新的预测模型：DeepVARMA，以及其变体Deep-VARMA-re和DeepVARMA-en，它们结合了LSTM和VARMAX模型。新模型首先利用LSTM等深度学习模型去除目标时间序列的趋势并学习内生变量的表示，然后利用VARMAX模型对去趋势后的目标时间序列进行带有内生变量嵌入的预测，最后结合LSTM学习到的趋势和VARMAX模型学习到的依赖关系得到最终的预测值。实验结果表明：（1）新模型通过外生变量的LSTM编码与VARMAX模型相结合，取得了最好的预测精度。（2）在多变量非平稳序列预测中，DeepVARMA采用阶段性处理策略，与传统VARMA模型以及机器学习模型LSTM、RF、XGBoost相比，表现出更高的适应性和准确性。（3）与平滑序列预测相比，传统VARMA和VARMAX模型在预测非平滑序列时波动较大，而DeepVARMA表现出更好的灵活性和鲁棒性。本研究为化工行业未来发展和科学决策提供了更精准的工具和方法。]]></description>
      <guid>https://arxiv.org/abs/2404.17615</guid>
      <pubDate>Wed, 01 May 2024 01:03:37 GMT</pubDate>
    </item>
    <item>
      <title>关于异步挑战的注释：揭示 Hayashi-Yoshida 估计器中的公式偏差和数据丢失</title>
      <link>https://arxiv.org/abs/2404.18233</link>
      <description><![CDATA[arXiv:2404.18233v1 公告类型：新
摘要： Hayashi-Yoshida (\HY) 估计器表现出一种内在的伸缩特性，导致经常被忽视的计算偏差，我们将其表示为公式偏差或内在偏差。这种公式化偏差会消除潜在相关的数据点（即不存在的数据点），从而导致数据丢失。本文试图形式化和量化这种偏差引起的数据丢失。特别是，我们通过一个具体的例子强调了不存在的数据点的存在，并证明了伸缩属性引起这种类型的公式偏差的充分必要条件。由于这种类型的偏差在输入（即观察时间）时不存在，$ \Pi^{(1)} :=(t_i^{(1)})_{i=0,1,\ldots}$ 和 $\Pi^{(2)} :=(t_j^{(2) })_{j=0,1,\ldots}$ 是同步的，我们引入 (a,b) 异步对手。该对手根据速率 a&gt;0 和 b&gt;0 的两个独立同质泊松过程分别生成输入 $\Pi^{(1)}$ 和 $\Pi^{(2)}$。我们解决有关累积最小（或最小）平均数据点损失的基本问题，并确定 a 和 b 的值。我们证明，对于相同的速率 a=b，两个输入的平均累积数据丢失最小，达到 25%。我们提出了一种基于定理的算法，用于计算给定输入 $\Pi^{(1)}$ 和 $\Pi^{(2)}$ 的不存在数据点的确切数量，并提出替代方法。最后，我们使用模拟数据来实证比较 (\HY) 估计器的（累积）平均数据损失。]]></description>
      <guid>https://arxiv.org/abs/2404.18233</guid>
      <pubDate>Wed, 01 May 2024 01:03:36 GMT</pubDate>
    </item>
    <item>
      <title>使用规范约束、过度参数化、两层神经网络进行学习</title>
      <link>https://arxiv.org/abs/2404.18769</link>
      <description><![CDATA[arXiv:2404.18769v1 公告类型：新
摘要：最近的研究表明，再生核希尔伯特空间 (RKHS) 不是一个适合通过神经网络对函数进行建模的空间，因为即使在尝试近似单个 ReLU 神经元时也无法避免维数灾难 (CoD)（Bach，2017） 。在本文中，我们从样本复杂性和泛化特性的角度研究了具有有界范数（例如路径范数、巴伦范数）的超参数化两层神经网络的合适函数空间。首先，我们证明路径范数（以及巴伦范数）能够获得与宽度无关的样本复杂度界限，从而实现统一收敛保证。基于这个结果，我们推导出$\epsilon$的度量熵的改进结果——覆盖$\mathcal{O}(\epsilon^{-\frac{2d}{d+2}})$ ($d $ 是输入维度，依赖常数最多为 $d$ 的多项式阶），通过凸包技术，演示了使用 $\Omega(\epsilon^{-d})$ 与核方法的分离来学习目标在巴伦空间中发挥作用。其次，这个度量熵结果允许在一般矩假设设置下构建更清晰的泛化界限，实现 $\mathcal{O}(n^{-\frac{d+2}{2d+2}})$ 的速率。我们的分析是新颖的，因为它为度量熵提供了更清晰和精确的估计（对维度 $d$ 有明显的依赖关系），并在样本误差和输出误差的估计中提供了无界采样。]]></description>
      <guid>https://arxiv.org/abs/2404.18769</guid>
      <pubDate>Wed, 01 May 2024 01:03:36 GMT</pubDate>
    </item>
    <item>
      <title>通过深度学习进行实时数据增强进行预测</title>
      <link>https://arxiv.org/abs/2404.16918</link>
      <description><![CDATA[arXiv:2404.16918v1 公告类型：交叉 
摘要：深度学习方法越来越多地用于解决预测任务。成功应用这些方法的一个关键因素是足够大的训练样本量，但这并不总是可用的。在这些情况下，通常应用合成数据生成技术来扩充数据集。数据增强通常在拟合模型之前应用。然而，这些方法会创建一个单一的增强数据集，这可能会限制它们的有效性。这项工作引入了 OnDAT（时间序列的动态数据增强）来解决这个问题，方法是在训练和验证期间应用数据增强。与预先创建单个静态增强数据集的传统方法相反，OnDAT 会动态执行增强。通过在每次迭代中生成新的增强数据集，模型会暴露于不断变化的增强数据变化中。我们假设这个过程能够更好地探索数据空间，从而降低过度拟合的可能性并提高预测性能。我们使用最先进的深度学习预测方法和 8 个基准数据集（共包含 75797 个时间序列）验证了所提出的方法。实验表明，OnDAT 的预测性能优于在训练前应用数据增强的策略以及不涉及数据增强的策略。该方法和实验已公开。]]></description>
      <guid>https://arxiv.org/abs/2404.16918</guid>
      <pubDate>Wed, 01 May 2024 01:03:36 GMT</pubDate>
    </item>
    <item>
      <title>离散化条件下的条件独立性检验</title>
      <link>https://arxiv.org/abs/2404.17644</link>
      <description><![CDATA[arXiv:2404.17644v1 公告类型：新
摘要：测试条件独立性有很多应用，例如贝叶斯网络学习和因果发现。已经提出了不同的测试方法。然而，当只有离散观测值时，现有方法通常无法工作。具体来说，考虑 $X_1$、$\tilde{X}_2$ 和 $X_3$ 是观察变量，其中 $\tilde{X}_2$ 是潜在变量 $X_2$ 的离散化。将现有的测试方法应用于 $X_1$、$\tilde{X}_2$ 和 $X_3$ 的观察可能会导致关于变量 $X_1$、$X_2$ 和 $X_3$ 的基本条件独立性的错误结论。受此启发，我们提出了一个专门设计的条件独立性测试，以适应这种离散化的存在。为了实现这一目标，我们设计了桥方程来恢复反映潜在连续变量统计信息的参数。还导出了条件独立零假设下的适当检验统计量及其渐近分布。提供了理论结果和实证验证，证明了我们的测试方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.17644</guid>
      <pubDate>Wed, 01 May 2024 01:03:35 GMT</pubDate>
    </item>
    <item>
      <title>具有重尾奖励的低等级矩阵强盗</title>
      <link>https://arxiv.org/abs/2404.17709</link>
      <description><![CDATA[arXiv:2404.17709v1 公告类型：新
摘要：在随机低秩矩阵 bandit 中，arm 的期望奖励等于其特征矩阵与某个未知的 $d_1$ 乘以 $d_2$ 低秩参数矩阵 $\Theta^*$ 与秩 $ 之间的内积 $ r \ll d_1\楔形 d_2$。虽然所有先前的研究都假设收益与亚高斯噪声混合，但在这项工作中，我们放松了这种严格的假设，并考虑 \underline{low}-rank 矩阵 bandit 与 \underline{h}eavy-\underline{t 的新问题}ailed \underline{r}rewards (LowHTR)，其中对于 (0,1]$ 中的某些 $\delta \in，奖励仅具有有限的 $(1+\delta)$ 时刻。通过利用观察到的收益的截断和动态探索中，我们提出了一种称为 LOTUS 的新颖算法，其获得 $\tilde O(d^\frac{3}{2}r^\frac{1}{2}T^\frac{1}{1 +\delta}/\tilde{D}_{rr})$ 不知道 $T$，它与亚高斯噪声下最先进的遗憾界限相匹配~\citep{lu2021low,kang2022efficient} 与 $\此外，我们建立阶 $\Omega(d^\frac{\delta}{1+\delta} r^\frac{\delta}{1+\delta} T^\ 的下界。 LowHTR 的 frac{1}{1+\delta}) = \Omega(T^\frac{1}{1+\delta})$，这表明我们的 LOTUS 在 $T$ 的量级上接近最优。 ，我们改进了 LOTUS，使其不需要知道 $r$ 的秩 $\tilde O(dr^\frac{3}{2}T^\frac{1+\delta}{1+2\delta} )$regretbound，并且在高维场景下是高效的。我们还进行了模拟来证明我们的算法的实际优越性。]]></description>
      <guid>https://arxiv.org/abs/2404.17709</guid>
      <pubDate>Wed, 01 May 2024 01:03:35 GMT</pubDate>
    </item>
    <item>
      <title>线性模型中迭代算法的不确定性量化及其应用于提前停止</title>
      <link>https://arxiv.org/abs/2404.17856</link>
      <description><![CDATA[arXiv:2404.17856v1 公告类型：新
摘要：本文研究了在特征维度 $p$ 与样本大小 $ 相当的情况下，在高维线性回归问题中通过迭代算法获得的迭代 $\hbb^1,\dots,\hbb^T$ n$，即$p \asymp n$。分析和提出的估计器适用于梯度下降 (GD)、近端 GD 及其加速变体，例如快速迭代软阈值 (FISTA)。本文提出了新的估计器，用于针对沿轨迹的任何固定迭代 $t$ 的迭代 $\hbb^t$ 的泛化误差。这些估计量被证明在高斯设计下是 $\sqrt n$ 一致的。提供了早期停止的应用：当迭代的泛化误差是迭代$t$的U形函数时，估计允许从数据中选择一个迭代$\hatt$，它沿着轨迹。此外，我们提供了一种技术，用于为任何有限迭代 $t$ 的迭代 $\hbb^t$ 中的真实系数向量的分量开发去偏校正和有效置信区间。对合成数据的广泛模拟说明了理论结果。]]></description>
      <guid>https://arxiv.org/abs/2404.17856</guid>
      <pubDate>Wed, 01 May 2024 01:03:35 GMT</pubDate>
    </item>
    </channel>
</rss>