<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>https://arxiv.org/rss/</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 02 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>不确定性感知部分标签学习</title>
      <link>https://arxiv.org/abs/2402.00592</link>
      <description><![CDATA[在现实应用程序中，人们经常会遇到标签不明确的数据，其中不同的注释者分配冲突的类标签。部分标签学习允许在这种弱监督环境中训练分类器。虽然最先进的方法已经具有良好的预测性能，但它们经常遭受校准错误的不确定性估计的影响。然而，经过良好校准的不确定性估计很重要，尤其是在医学和自动驾驶等安全关键领域。在本文中，我们提出了一种利用 Dempster-Shafer 理论的新颖的基于最近邻的部分标签学习算法。对人工和真实数据集的大量实验表明，所提出的方法提供了经过良好校准的不确定性估计，并实现了有竞争力的预测性能。此外，我们证明我们的算法是风险一致的。]]></description>
      <guid>https://arxiv.org/abs/2402.00592</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:19 GMT</pubDate>
    </item>
    <item>
      <title>关于 Lasso 的设计相关次优性</title>
      <link>https://arxiv.org/abs/2402.00382</link>
      <description><![CDATA[本文研究了设计矩阵对估计线性回归中稀疏参数的能力（或不能）的影响。更具体地说，我们描述了当设计矩阵的最小奇异值远离零时的最佳估计率。除了这个信息论结果之外，我们还提供并分析了一个基于普通最小二乘估计器的软阈值处理的程序，该程序在统计上是最佳的，并且计算效率高。最令人惊讶的是，我们表明，尽管 Lasso 估计器广泛应用于稀疏线性回归，但当最小奇异值很小时，它可证明是极小极大速率次优。我们提出了一系列设计矩阵和稀疏参数，我们可以保证具有任何正则化参数选择的套索（包括那些依赖于数据和随机的参数）都会失败，因为它的估计率通过多项式不是最优的样本大小的因素。我们的下限足够强大，足以排除所有形式的套索的统计最优性，包括其非常流行的惩罚、规范约束和交叉验证的变体。]]></description>
      <guid>https://arxiv.org/abs/2402.00382</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:18 GMT</pubDate>
    </item>
    <item>
      <title>基于累积分布函数的一般时间点过程</title>
      <link>https://arxiv.org/abs/2402.00388</link>
      <description><![CDATA[时间点过程（TPP）在跨不同领域（包括社交网络和电子商务）的事件序列建模中发挥着关键作用，并且为推荐系统和信息检索策略的进步做出了重大贡献。通过对用户交互和交易等事件的分析，TPP 可以提供有关行为模式的宝贵见解，从而促进对未来趋势的预测。然而，由于这些模式的复杂性，准确预测未来事件仍然是一项艰巨的挑战。神经网络与 TPP 的集成迎来了先进深度 TPP 模型的发展。虽然这些模型擅长处理复杂和非线性的时间数据，但它们在建模强度函数方面遇到了限制，难以解决积分计算中的计算复杂性，并且难以有效地捕获长期时间依赖性。在这项研究中，我们引入了 CuFun 模型，它代表了一种围绕累积分布函数 (CDF) 的 TPP 新颖方法。 CuFun 的突出之处在于独特地采用单调神经网络进行 CDF 表示，并利用过去的事件作为比例因子。这项创新显着增强了模型在各种数据场景中的适应性和精度。我们的方法解决了传统 TPP 建模中固有的几个关键问题：它简化了对数似然计算，将适用性扩展到预定义的密度函数形式之外，并熟练地捕获长范围时间模式。我们的贡献包括引入基于 CDF 的开创性 TPP 模型、开发将过去事件信息纳入未来事件预测的方法，以及通过对合成和真实数据集进行广泛实验来实证验证 CuFun 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.00388</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:18 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士的高效探索</title>
      <link>https://arxiv.org/abs/2402.00396</link>
      <description><![CDATA[我们提供的证据表明，有效探索收集人类反馈以改进大型语言模型会带来巨大好处。在我们的实验中，代理依次生成查询，同时根据收到的反馈拟合奖励模型。我们表现​​最好的代理使用双汤普森采样生成查询，并由认知神经网络表示不确定性。我们的结果表明，高效的探索可以通过更少的查询实现高水平的性能。此外，不确定性估计和勘探方案的选择都起着至关重要的作用。]]></description>
      <guid>https://arxiv.org/abs/2402.00396</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:18 GMT</pubDate>
    </item>
    <item>
      <title>了解 Transformer 用于序列建模的表达能力和机制</title>
      <link>https://arxiv.org/abs/2402.00522</link>
      <description><![CDATA[我们对 Transformer 的近似特性进行了系统的研究，用于长、稀疏和复杂内存的序列建模。我们研究了 Transformer 的不同组件（例如点积自注意力、位置编码和前馈层）影响其表达能力的机制，并通过建立显式逼近率来研究它们的综合影响。我们的研究揭示了 Transformer 中关键参数的作用，例如层数和注意力头的数量，这些见解也为替代架构提供了自然的建议。]]></description>
      <guid>https://arxiv.org/abs/2402.00522</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:18 GMT</pubDate>
    </item>
    <item>
      <title>政策梯度探索神话背后</title>
      <link>https://arxiv.org/abs/2402.00162</link>
      <description><![CDATA[策略梯度算法是解决具有连续状态和动作空间的控制问题的有效强化学习方法。为了计算接近最优的策略，在实践中必须将探索术语包含在学习目标中。尽管这些术语的有效性通常是由探索环境的内在需要来证明的，但我们提出了一种新颖的分析并区分了这些技术的两种不同含义。首先，它们可以平滑学习目标并消除局部最优，同时保留全局最大值。其次，他们修改梯度估计，增加随机参数更新最终提供最优策略的概率。鉴于这些影响，我们讨论并说明了基于熵加成的实证探索策略，强调了它们的局限性，并为未来设计和分析此类策略的工作开辟了途径。]]></description>
      <guid>https://arxiv.org/abs/2402.00162</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:17 GMT</pubDate>
    </item>
    <item>
      <title>并非所有可学习的分布类都可以私下学习</title>
      <link>https://arxiv.org/abs/2402.00267</link>
      <description><![CDATA[我们给出了一类分布的例子，它可以在有限数量的样本的总变异距离中学习，但在 $(\varepsilon, \delta)$-差分隐私下不可学习。这驳斥了阿什蒂亚尼的猜想。]]></description>
      <guid>https://arxiv.org/abs/2402.00267</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:17 GMT</pubDate>
    </item>
    <item>
      <title>种植密集循环的信息理论阈值</title>
      <link>https://arxiv.org/abs/2402.00305</link>
      <description><![CDATA[我们研究了社会和生物科学中普遍存在的小世界网络的随机图模型。在此模型中，预期带宽 $n \tau$ 的密集循环（表示顶点的隐藏一维几何形状）被植入 $n$ 顶点上的环境随机图中。对于种植密集循环的检测和恢复，我们用 $n$、$\tau$ 和边缘信噪比 $\lambda$ 来表征信息论阈值。特别是，信息论阈值与最近的低次多项式算法工作中建立的计算阈值不同，从而证明了该问题存在统计与计算差距。]]></description>
      <guid>https://arxiv.org/abs/2402.00305</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:17 GMT</pubDate>
    </item>
    <item>
      <title>比较两层神经网络的谱偏差和鲁棒性：SGD 与自适应随机傅里叶特征</title>
      <link>https://arxiv.org/abs/2402.00332</link>
      <description><![CDATA[我们提出的实验结果强调了两层神经网络训练算法选择所导致的两个关键差异。神经网络的谱偏差是众所周知的，但对训练算法选择的谱偏差依赖性的研究较少。我们的实验表明，与随机梯度下降优化器 (SGD) 相比，自适应随机傅立叶特征算法 (ARFF) 可以产生接近于零的谱偏差。此外，我们使用 SGD 和 ARFF 训练两个结构相同的分类器达到相同的准确度水平，并根据经验评估它们针对对抗性噪声攻击的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2402.00332</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:17 GMT</pubDate>
    </item>
    <item>
      <title>使用高斯过程网络进行贝叶斯因果推理</title>
      <link>https://arxiv.org/abs/2402.00623</link>
      <description><![CDATA[从观测数据中发现因果关系并进行推断是统计学中的一个基本问题，给建模和计算带来了挑战。这些问题通常通过对联合分布（例如线性）施加严格的假设来解决。我们考虑高斯过程网络（GPN）模型中假设干预效果的贝叶斯估计问题，这是一个灵活的因果框架，允许以非参数方式描述因果关系。我们详细介绍了如何通过模拟整个网络的干预效果并将干预效果传播到下游变量来对 GPN 进行因果推理。我们通过仅将干预分布估计为局部变量的函数，通过加性高斯过程对条件分布进行建模，进一步得出更简单的计算近似值。我们将这两个框架扩展到已知因果图的情况之外，通过马尔可夫链蒙特卡罗方法纳入因果结构的不确定性。模拟研究表明，我们的方法能够识别非高斯、非线性观测数据的假设干预的影响，并准确反映因果估计的后验不确定性。最后，我们将基于 GPN 的因果推理方法与 $A.~thaliana$ 基因表达数据集上的现有方法的结果进行比较。]]></description>
      <guid>https://arxiv.org/abs/2402.00623</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:16 GMT</pubDate>
    </item>
    <item>
      <title>谱变换核回归</title>
      <link>https://arxiv.org/abs/2402.00645</link>
      <description><![CDATA[无标签数据是现代机器学习的关键组成部分。一般来说，未标记数据的作用是施加某种形式的平滑度，通常来自基本内核中编码的相似性信息，例如$\epsilon$-邻居内核或图的邻接矩阵。这项工作重新审视了谱变换核回归 (STKR) 的经典思想，并提供了一类新的通用且可扩展的 STKR 估计器，能够利用未标记的数据。直观地说，通过谱变换，STKR 利用了数据分布，未标记的数据可以为其提供附加信息。首先，我们通过表征“目标平滑度”的通用类型，并证明 STKR 可以学习任何足够平滑的函数，证明 STKR 是一种原则性且通用的方法。其次，我们为归纳设置和通用转换函数提供可扩展的 STKR 实现，而之前的工作主要限于传导设置。第三，我们得出两种情况的统计保证：具有已知多项式变换的 STKR，以及变换未知时具有内核 PCA 的 STKR。总的来说，我们相信这项工作有助于加深我们对如何使用未标记数据的理解，并且它的通用性使得更容易激发新方法。]]></description>
      <guid>https://arxiv.org/abs/2402.00645</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:16 GMT</pubDate>
    </item>
    <item>
      <title>用于生存分析的可解释人工智能：中值 SHAP 方法</title>
      <link>https://arxiv.org/abs/2402.00072</link>
      <description><![CDATA[随着机器学习在常规临床实践中的采用，需要针对医疗应用量身定制的可解释的人工智能方法。沙普利值引起了人们对局部解释模型的广泛兴趣。在这里，我们证明它们的解释在很大程度上取决于汇总统计量和估计量，这反过来又定义了我们所识别的“锚点”。我们表明，使用平均锚点的惯例可能会对生存分析产生误导性的解释，并引入中位数SHAP，这是一种解释预测个体生存时间的黑盒模型的方法。]]></description>
      <guid>https://arxiv.org/abs/2402.00072</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:16 GMT</pubDate>
    </item>
    <item>
      <title>更深或更广：从具有 Sobolev 损失的最优泛化误差的角度来看</title>
      <link>https://arxiv.org/abs/2402.00152</link>
      <description><![CDATA[构建神经网络的架构对于机器学习社区来说是一项具有挑战性的追求，而是否要更深入或更广泛的困境仍然是一个长期存在的问题。本文探讨了具有灵活层数的深层神经网络（DeNN）和具有有限隐藏层的更广泛的神经网络（WeNN）之间的比较，重点关注它们在 Sobolev 损失中的最佳泛化误差。分析研究表明，神经网络的架构会受到各种因素的显着影响，包括样本点的数量、神经网络内的参数以及损失函数的规律性。具体来说，更多的参数往往有利于 WeNN，而更多的样本点和更大的损失函数规律性则倾向于采用 DeNN。我们最终应用这一理论来使用深度 Ritz 和物理信息神经网络 (PINN) 方法来求解偏微分方程，从而指导神经网络的设计。]]></description>
      <guid>https://arxiv.org/abs/2402.00152</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:16 GMT</pubDate>
    </item>
    <item>
      <title>具有替代结果的持续治疗效果</title>
      <link>https://arxiv.org/abs/2402.00168</link>
      <description><![CDATA[在许多现实世界的因果推理应用中，主要结果（标签）通常会部分缺失，特别是当它们价格昂贵或难以收集时。如果缺失取决于协变量（即缺失不是完全随机的），则仅基于充分观察的样本的分析可能会存在偏差。纳入替代变量（与主要结果相关的完全观察到的治疗后变量）可以改善这种情况下的估计。在本文中，我们研究了替代物在估计连续治疗效果中的作用，并提出了一种双重稳健的方法来有效地将替代物纳入分析中，该方法同时使用标记和未标记数据，并且不会遇到上述选择偏差问题。重要的是，我们建立了所提出的估计量的渐近正态性，并表明与仅使用标记数据的方法相比，方差可能有所改进。广泛的模拟表明我们的方法具有吸引人的经验表现。]]></description>
      <guid>https://arxiv.org/abs/2402.00168</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:15 GMT</pubDate>
    </item>
    <item>
      <title>经验风险最小化与 f-散度族正则化的等价</title>
      <link>https://arxiv.org/abs/2402.00501</link>
      <description><![CDATA[在 $f$ 上的温和条件下，提出了通过 $f$-散度正则化 (ERM-$f$DR) 实现经验风险最小化的解决方案。在这种条件下，最优措施被证明是唯一的。给出了函数 $f$ 的特定选择的解决方案的示例。先前已知的常见正则化选择的解决方案是通过利用 $f$-散度系列的灵活性获得的。其中包括通过相对熵正则化（I 型和 II 型）实现经验风险最小化的独特解决方案。对解的分析揭示了在 ERM-$f$DR 问题中使用时 $f$-散度的以下属性： $i\bigl)$ $f$-散度正则化迫使解的支持与支持一致参考测量，它引入了强烈的归纳偏差，主导了训练数据提供的证据；且$ii\bigl)$任何$f$-散度正则化等价于对经验风险函数进行适当变换的不同$f$-散度正则化。]]></description>
      <guid>https://arxiv.org/abs/2402.00501</guid>
      <pubDate>Fri, 02 Feb 2024 21:11:15 GMT</pubDate>
    </item>
    </channel>
</rss>