<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 07 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过惰性算法进行私人在线学习</title>
      <link>https://arxiv.org/abs/2406.03620</link>
      <description><![CDATA[arXiv:2406.03620v1 公告类型：交叉 
摘要：我们研究隐私在线学习问题，特别是专家在线预测 (OPE) 和在线凸优化 (OCO)。我们提出了一种将惰性在线学习算法转换为隐私算法的新转换。我们使用现有的惰性算法将我们的转换应用于差异隐私 OPE 和 OCO 这些问题。我们的最终算法获得了遗憾，这显著改善了高隐私制度 $\varepsilon \ll 1$ 中的遗憾，对于 DP-OPE 获得 $\sqrt{T \log d} + T^{1/3} \log(d)/\varepsilon^{2/3}$，对于 DP-OCO 获得 $\sqrt{T} + T^{1/3} \sqrt{d}/\varepsilon^{2/3}$。我们还用 DP-OPE 的下限补充了我们的结果，表明这些速率对于自然的低切换隐私算法系列是最佳的。]]></description>
      <guid>https://arxiv.org/abs/2406.03620</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:28 GMT</pubDate>
    </item>
    <item>
      <title>反射策略优化</title>
      <link>https://arxiv.org/abs/2406.03678</link>
      <description><![CDATA[arXiv:2406.03678v1 公告类型：交叉 
摘要：在策略强化学习方法，如信任区域策略优化 (TRPO) 和近端策略优化 (PPO)，通常每次更新都需要大量数据，从而导致样本效率低下。本文介绍了反射策略优化 (RPO)，这是一种新颖的在策略扩展，它将过去和未来的状态动作信息融合在一起以进行策略优化。这种方法使代理能够进行自省，允许在当前状态下修改其动作。理论分析证实，策略性能单调提高并收缩解决方案空间，从而加快收敛过程。实证结果证明了 RPO 在两个强化学习基准中的可行性和有效性，最终实现了卓越的样本效率。这项工作的源代码可在 https://github.com/Edgargan/RPO 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.03678</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:28 GMT</pubDate>
    </item>
    <item>
      <title>非平衡多体胶体系统的神经力函数</title>
      <link>https://arxiv.org/abs/2406.03606</link>
      <description><![CDATA[arXiv:2406.03606v1 公告类型：交叉 
摘要：我们结合幂函数理论和机器学习，在单体场水平上研究胶体粒子的非平衡过阻尼多体系统。我们首先在稳定状态下从随机产生的外部场影响下的布朗粒子计算机模拟中采样与动力学相关的单体场。然后用这些数据训练神经网络，在空间中局部表示从单体密度和速度分布到单体内部力场的形式精确函数映射。训练后的网络用于分析非平衡超绝热力场和传输系数，如剪切和体积粘度。由于采用了局部学习方法，该网络可以应用于比采样单体场的原始模拟盒大得多的系统。结合精确的非平衡单体力平衡方程和连续性方程，该网络可以对时间相关情况下的动力学进行可行的预测。尽管训练仅基于稳定状态，但预测的动力学与模拟结果非常吻合。神经动力学密度泛函理论可以直接实现为极限情况，其中内部力场是平衡系统的力场。该框架是通用的，可直接应用于遵循布朗动力学的其他相互作用粒子多体系统。]]></description>
      <guid>https://arxiv.org/abs/2406.03606</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:27 GMT</pubDate>
    </item>
    <item>
      <title>仿射变换之外的对称性发现</title>
      <link>https://arxiv.org/abs/2406.03619</link>
      <description><![CDATA[arXiv:2406.03619v1 公告类型：交叉 
摘要：对称性检测已被证明可以改善各种机器学习任务。在连续对称性检测的背景下，目前最先进的实验仅限于检测仿射变换。在流形假设下，我们概述了一个框架，用于发现仿射变换组之外的数据中的连续对称性。我们还提供了一个类似的框架来发现离散对称性。我们通过实验将我们的方法与现有的称为 LieGAN 的方法进行了比较，并表明我们的方法在检测大样本量的仿射对称性方面具有竞争力，并且在小样本量方面优于 LieGAN。我们还表明我们的方法能够检测仿射组之外的连续对称性，并且通常比 LieGAN 具有更高的计算效率。]]></description>
      <guid>https://arxiv.org/abs/2406.03619</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:27 GMT</pubDate>
    </item>
    <item>
      <title>Graphon 具有代表性玩家的平均场游戏：分析和学习算法</title>
      <link>https://arxiv.org/abs/2405.08005</link>
      <description><![CDATA[arXiv:2405.08005v2 公告类型：交叉 
摘要：我们提出了一种在连续状态和动作空间上使用代表性玩家的离散时间图元博弈公式来研究具有代理间异构交互的随机博弈。与广泛采用的使用连续玩家的公式相比，这种公式具有哲学和数学上的优势。我们用温和的假设证明了图元均衡的存在性和唯一性，并表明该均衡可用于构建网络上有限玩家博弈的近似解，由于维数灾难，该近似解的分析和求解具有挑战性。开发了一种在线无预言机学习算法来数值求解均衡，并对其收敛性进行了样本复杂性分析。]]></description>
      <guid>https://arxiv.org/abs/2405.08005</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:26 GMT</pubDate>
    </item>
    <item>
      <title>数据复杂性的几何视图：使用扩散模型进行有效的局部内在维度估计</title>
      <link>https://arxiv.org/abs/2406.03537</link>
      <description><![CDATA[arXiv:2406.03537v1 公告类型：交叉 
摘要：高维数据通常位于低维子流形上，估计数据的局部本征维数 (LID)（即其所属子流形的维数）是一个长期存在的问题。LID 可以理解为局部变异因子的数量：数据变异因子越多，它就越复杂。估计这个数量已被证明在从神经网络中的泛化到检测分布外数据、对抗性示例和 AI 生成的文本等各种情况下都很有用。深度生成模型最近的成功为利用它们进行 LID 估计提供了机会，但当前基于生成模型的方法产生的估计不准确，需要多个预训练模型，计算量大，或者没有利用最好的深度生成模型，即扩散模型 (DM)。在这项研究中，我们展示了与 DM 相关的 Fokker-Planck 方程可以提供一个 LID 估计器，该估计器解决了上述所有缺陷。我们的估计器称为 FLIPD，与所有流行的 DM 兼容，并且在 LID 估计基准上优于现有基线。我们还将 FLIPD 应用于真实 LID 未知的自然图像。与竞争估计器相比，FLIPD 与非 LID 复杂性度量表现出更高的相关性，更好地匹配复杂性的定性评估，并且是唯一一个在稳定扩散规模下仍可处理高分辨率图像的估计器。]]></description>
      <guid>https://arxiv.org/abs/2406.03537</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:26 GMT</pubDate>
    </item>
    <item>
      <title>平滑约束下的动态角同步</title>
      <link>https://arxiv.org/abs/2406.04071</link>
      <description><![CDATA[arXiv:2406.04071v1 公告类型：新
摘要：给定一个无向测量图 $\mathcal{H} = ([n], \mathcal{E})$，经典的角度同步问题包括从一组噪声成对测量中恢复未知角度 $\theta_1^*,\dots,\theta_n^*$，形式为 $(\theta_i^* - \theta_j^*) \mod 2\pi$，对于所有 $\{i,j\} \in \mathcal{E}$。此问题出现在各种应用中，包括计算机视觉、分布式网络的时间同步和成对比较的排名。在本文中，我们考虑了这个问题的动态版本，其中角度以及测量图在 $T$ 个时间点上演变。假设潜在角度的演变具有平滑性条件，我们推导出三种算法来联合估计所有时间点的角度。此外，对于其中一种算法，我们在不同的统计模型下建立了均方误差 (MSE) 的非渐近恢复保证。具体而言，我们表明，在比静态设置更温和的条件下，MSE 会随着 $T$ 的增加而收敛到零。这包括测量图高度稀疏和断开的设置，以及测量噪声很大并且可能随着 $T$ 而增加的设置。我们通过对合成数据的实验来补充我们的理论结果。]]></description>
      <guid>https://arxiv.org/abs/2406.04071</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:25 GMT</pubDate>
    </item>
    <item>
      <title>低维数据上生存模型的大规模中性比较研究</title>
      <link>https://arxiv.org/abs/2406.04098</link>
      <description><![CDATA[arXiv:2406.04098v1 公告类型：新
摘要：这项工作提出了第一个大规模中立基准测试实验，重点关注单事件、右删失、低维生存数据。基准测试实验在方法论研究中至关重要，可以通过适当的实证评估科学地比较新的和现有的模型类别。生存文献中现有的基准测试范围通常很窄，例如，侧重于高维数据。此外，它们可能缺乏适当的调整或评估程序，或者是定性评论，而不是定量比较。这项综合研究旨在通过中立地评估广泛的方法并提供可推广的结论来填补这一空白。我们在 32 个公开可用的数据集上对 18 个模型进行了基准测试，从经典统计方法到许多常见的机器学习方法。基准测试针对歧视测量和适当的评分规则进行调整，以评估不同环境下的性能。通过评估 8 个生存指标，我们评估了测试模型的歧视、校准和整体预测性能。使用判别度量度，我们发现没有一种方法能显著优于 Cox 模型。但是，（调整后的）加速故障时间模型能够在以右删失对数似然法衡量的总体预测性能方面取得明显更好的结果。表现相当出色的机器学习方法包括判别下的斜随机生存森林和总体预测性能下的基于 Cox 的似然提升。我们得出结论，对于低维、右删失数据的标准生存分析设置中的预测目的，Cox 比例风险模型仍然是一种简单而强大的方法，足以满足从业者的需求。]]></description>
      <guid>https://arxiv.org/abs/2406.04098</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:25 GMT</pubDate>
    </item>
    <item>
      <title>变分推理、混合高斯、贝叶斯机器学习</title>
      <link>https://arxiv.org/abs/2406.04012</link>
      <description><![CDATA[arXiv:2406.04012v1 公告类型：新
摘要：变分推理 (VI) 是贝叶斯推理中的一种流行方法，它寻找参数族中后验分布的最佳近似值，从而最小化损失，该损失通常是 (反向) Kullback-Leibler (KL) 散度。尽管 VI 在经验上取得了成功，但它的理论性质最近才受到关注，而且主要是在参数族是高斯族时。这项工作旨在通过研究具有固定协方差和恒定权重的高斯混合设置，为非高斯情况下 VI 的理论研究做出贡献。从这个角度来看，这个特定家族的 VI 可以被视为 Mollified 相对熵的最小化，即基于 Diracs 的原子测度的卷积（相对于高斯核）与目标分布之间的 KL。原子测度的支持对应于高斯分量的局部化。因此，解决变分推理等同于优化狄拉克（粒子）的位置，这可以通过梯度下降来完成，并采用相互作用的粒子系统的形式。在优化缓和的相对熵时，我们研究了变分推理的两个误差源。第一个是优化结果，即下降引理，确定算法在每次迭代时都会降低目标。第二个是近似误差，它将目标上限设定在最佳有限混合和目标分布之间。]]></description>
      <guid>https://arxiv.org/abs/2406.04012</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:24 GMT</pubDate>
    </item>
    <item>
      <title>分割神经网络的互信息泛化界限</title>
      <link>https://arxiv.org/abs/2406.04047</link>
      <description><![CDATA[arXiv:2406.04047v1 公告类型：新
摘要：通过信息论的视角，人们研究了机器学习 (ML) 算法对未见数据进行良好推广的能力，即用输入输出互信息 (MI) 来限制泛化误差，即训练数据和学习假设之间的 MI。然而，由于难以在高维中评估 MI，这些界限对于现代 ML 应用（例如深度学习）的实用性有限。受最近关于神经网络可压缩性的发现的启发，我们考虑通过切片参数空间（即在随机低维子空间上训练）来操作的算法。我们引入了针对此类算法量身定制的新的、更严格的信息理论泛化界限，表明切片可以提高泛化能力。与标准 MI 界限相比，我们的界限具有显着的计算和统计优势，因为它们依赖于可扩展的替代依赖性度量，即分解互信息和 $k$ 切片互信息。然后，我们利用率失真理论将分析扩展到参数不需要精确位于随机子空间的算法。该策略产生了泛化界限，其中包含一个测量切片下模型压缩性的失真项，从而在不影响性能或需要模型压缩的情况下收紧现有界限。在此基础上，我们提出了一种正则化方案，使从业者能够通过压缩性来控制泛化。最后，我们通过经验验证了我们的结果，并实现了神经网络非空信息理论泛化界限的计算，这是一项以前无法实现的任务。]]></description>
      <guid>https://arxiv.org/abs/2406.04047</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:24 GMT</pubDate>
    </item>
    <item>
      <title>最小二乘回归的小批量梯度下降的离散误差动力学</title>
      <link>https://arxiv.org/abs/2406.03696</link>
      <description><![CDATA[arXiv:2406.03696v1 公告类型：新
摘要：我们研究了无放回采样时最小二乘回归的小批量梯度下降的离散动力学。我们表明，小批量梯度下降的动力学和泛化误差取决于原始特征 $X$ 和一组新特征 $\widetilde{X}$ 之间的样本交叉协方差矩阵 $Z$，其中每个特征都由学习过程中出现在它之前的小批量以平均方式修改。使用这种表示，我们严格确定小批量和全批量梯度下降的动力学在使用线性缩放规则的情况下在步长方面达到领先顺序。我们还研究了连续时间梯度流分析无法检测到的离散化效应，并表明与全批量梯度下降相比，小批量梯度下降收敛到步长相关的解。最后，我们假设一个随机矩阵模型，通过使用自由概率论的工具来数值计算 $Z$ 的谱，研究批处理的影响。]]></description>
      <guid>https://arxiv.org/abs/2406.03696</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>通过 GSD-Front 进行统计多标准基准测试</title>
      <link>https://arxiv.org/abs/2406.03924</link>
      <description><![CDATA[arXiv:2406.03924v1 公告类型：新
摘要：鉴于已经（并将继续）提出的大量分类器，比较它们的可靠方法变得越来越重要。对可靠性的要求分为三个主要方面：（1）比较应同时允许不同的质量指标。（2）比较应考虑由基准套件的选择引起的统计不确定性。（3）在基本假设的小偏差下，比较的稳健性应该是可验证的。为了解决（1），我们建议使用广义随机优势排序（GSD）来比较分类器，并将 GSD 前端作为经典帕累托前端的信息高效替代方案。对于（2），我们为 GSD 前端提出了一个一致的统计估计量，并构建了一个统计测试，以确定（潜在的新）分类器是否位于一组最先进分类器的 GSD 前端。对于 (3)，我们使用稳健统计和不精确概率技术放宽了我们提出的测试。我们在基准套件 PMLB 和平台 OpenML 上说明了我们的概念。]]></description>
      <guid>https://arxiv.org/abs/2406.03924</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>合成过采样：使用 LLM 解决数据不平衡的理论和实用方法</title>
      <link>https://arxiv.org/abs/2406.03628</link>
      <description><![CDATA[arXiv:2406.03628v1 公告类型：新
摘要：不平衡数据和虚假相关性是机器学习和数据科学中常见的挑战。过采样人为地增加了代表性不足的类别中的实例数量，已被广泛用于应对这些挑战。在本文中，我们介绍了 OPAL（\textbf{O}versam\textbf{P}ling with \textbf{A}artificial \textbf{L}LM-generated data），这是一种系统的过采样方法，利用大型语言模型 (LLM) 的功能为少数群体生成高质量的合成数据。最近关于使用深度生成模型生成合成数据的研究主要针对预测任务。我们的提议不同之处在于我们专注于处理不平衡数据和虚假相关性。更重要的是，我们开发了一种新理论，严格描述了使用合成数据的好处，并展示了转换器在为标签和协变量生成高质量合成数据方面的能力。我们进一步进行了大量数值实验，以证明我们提出的方法与一些有代表性的替代解决方案相比的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.03628</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>等价集限制潜在类别模型 (ESRLCM)</title>
      <link>https://arxiv.org/abs/2406.03653</link>
      <description><![CDATA[arXiv:2406.03653v1 公告类型：新
摘要：潜在类别模型 (LCM) 用于聚类多变量分类数据，通常用于解释调查响应。我们提出了一种称为等价集限制潜在类别模型 (ESRLCM) 的新型贝叶斯模型。该模型识别具有共同项目响应概率的集群，并且比传统的限制潜在属性模型更通用。我们验证了 ESRLCM 的可识别性，并证明了其在模拟和实际应用中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.03653</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>BEACON：一种用于昂贵黑盒系统中新颖性搜索的贝叶斯优化策略</title>
      <link>https://arxiv.org/abs/2406.03616</link>
      <description><![CDATA[arXiv:2406.03616v1 公告类型：新
摘要：新颖性搜索 (NS) 是指一类通过模拟或实验自动发现不同系统行为的探索算法。系统地获得多样化的结果是许多现实世界设计问题的关键组成部分，例如材料和药物发现、神经架构搜索、强化学习和机器人导航。由于这些复杂系统的输入和输出（即行为）之间的关系通常不是以封闭形式提供的，因此 NS 需要黑盒视角。因此，流行的 NS 算法依赖于进化优化和其他元启发式算法，这些算法需要对输入空间进行密集采样，当系统评估成本高昂时，这是不切实际的。我们提出了一种受贝叶斯优化启发的算法，用于样本效率高的 NS，该算法专为这种昂贵的黑盒系统而设计。我们的方法使用多输出高斯过程 (MOGP) 对输入到行为的映射进行建模，并通过最大化新颖性度量来选择下一个要评估的点，该度量取决于从 MOGP 中抽取的后验样本，该样本促进探索和利用。通过利用高效后验采样和高维高斯过程建模方面的进步，我们讨论了如何使我们的方法在数据量和输入数量方面具有可扩展性。我们在十个合成基准问题和八个实际问题（最多 2133 个输入）上测试了我们的方法，包括新应用，例如发现用于清洁能源技术的多种金属有机框架。我们表明，通过在有限的样本预算下找到大量不同的行为，我们的方法大大优于现有的 NS 算法。]]></description>
      <guid>https://arxiv.org/abs/2406.03616</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:21 GMT</pubDate>
    </item>
    </channel>
</rss>