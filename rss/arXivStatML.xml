<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 13 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过样本构建高斯过程</title>
      <link>https://arxiv.org/abs/2411.07277</link>
      <description><![CDATA[arXiv:2411.07277v1 公告类型：新
摘要：高斯过程面临两个主要挑战：为大型数据集构建模型和选择最佳模型。这篇硕士论文在低维情况下解决了这些挑战。我们检查最近的收敛结果，以确定具有最佳收敛速度的模型并确定基本参数。利用该模型，我们提出了一种基于 Samplet 的方法来有效地构建和训练高斯过程，将立方计算复杂度降低到对数线性尺度。该方法有助于实现最佳回归，同时保持高效的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.07277</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用部分信息分解量化知识蒸馏</title>
      <link>https://arxiv.org/abs/2411.07483</link>
      <description><![CDATA[arXiv:2411.07483v1 公告类型：新
摘要：知识蒸馏为在资源受限的环境中部署复杂的机器学习模型提供了一种有效的方法。它通常涉及训练较小的学生模型来模拟较大的教师模型的概率输出或内部特征表示。通过这样做，学生模型在下游任务上的表现通常比独立训练时要好得多。然而，教师的内部表征也可以编码与下游任务无关的噪音或附加信息。这一观察促使我们提出主要问题：知识转移的信息论极限是什么？为此，我们利用信息论中的一项称为部分信息分解 (PID) 的工作来量化与给定学生和下游任务相对应的教师表征的可蒸馏和蒸馏知识。此外，我们证明该指标可以实际用于蒸馏，以解决由教师和学生表征之间的复杂性差距引起的挑战。]]></description>
      <guid>https://arxiv.org/abs/2411.07483</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>外生随机性赋能随机森林</title>
      <link>https://arxiv.org/abs/2411.07554</link>
      <description><![CDATA[arXiv:2411.07554v1 公告类型：新
摘要：我们提供了理论和经验见解，探讨了外生随机性对具有独立于训练数据的树构建规则的随机森林的有效性的影响。我们正式引入了外生随机性的概念，并确定了两种常见的随机性：来自特征子采样的 I 型和来自树构建过程中的打破平局的 II 型。我们为单个树木和森林的均方误差 (MSE) 开发了非渐近展开，并建立了它们一致性的充分必要条件。在具有独立特征的线性回归模型的特殊示例中，我们的 MSE 展开更加明确，从而可以更好地理解随机森林的机制。它还使我们能够得出具有树和森林明确一致率的 MSE 的上限。在我们的理论发现的指导下，我们进行了模拟，以进一步探索外生随机性如何增强随机森林的性能。我们的研究结果表明，与单棵树相比，特征子采样可以降低随机森林的偏差和方差，从而充当平衡偏差和方差的自适应机制。此外，我们的结果还揭示了一个有趣的现象：由于特征子采样，噪声特征的存在可以作为增强随机森林性能的“福音”。]]></description>
      <guid>https://arxiv.org/abs/2411.07554</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对非高斯数据的 Tukey g-and-h 神经网络回归</title>
      <link>https://arxiv.org/abs/2411.07957</link>
      <description><![CDATA[arXiv:2411.07957v1 公告类型：新
摘要：本文通过使用 Tukey g-and-h 分布，使用神经网络解决非高斯回归问题。Tukey g-and-h 变换是一种灵活的参数变换，具有两个参数 $g$ 和 $h$，当应用于标准正态随机变量时，会引入偏度和峰度，从而产生通常称为 Tukey g-and-h 分布的分布。$g$ 和 $h$ 的特定值可以很好地近似其他分布族，例如柯西分布和学生 t 分布。Tukey g-and-h 分布的灵活性使其在统计界、应用科学和金融领域广受欢迎。在这项工作中，我们考虑训练神经网络以通过最小化相应的负对数似然来预测回归框架中 Tukey g-and-h 分布的参数，尽管后者没有闭式表达式。我们在模拟示例中展示了我们程序的效率，并将我们的方法应用于几种作物的全球作物产量的真实数据集。最后，我们展示了如何在预测分布和测试数据之间进行拟合优度分析。Pytorch 实现已在 Github 和 Pypi 包中提供。]]></description>
      <guid>https://arxiv.org/abs/2411.07957</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PICZL：基于图像的 AGN 光度红移</title>
      <link>https://arxiv.org/abs/2411.07305</link>
      <description><![CDATA[arXiv:2411.07305v2 公告类型：交叉 
摘要：计算 AGN 的光子 z 具有挑战性，主要是由于与 SMBH 及其宿主星系相关的相对辐射相互作用。SED 拟合方法在铅笔光束调查中有效，但在全天空调查中面临限制，因为可用的波段较少，无法准确捕捉 AGN 对 SED 的贡献。这一限制影响了 SRG/eROSITA 明确挑选和识别的数千万个 AGN。我们的目标是显着提高全天空调查中 AGN 的光度红移性能，同时避免合并多个数据集。相反，我们使用 DESI 成像遗产调查第 10 次数据发布中现成的数据产品，覆盖 &gt; 20,000 度$^{2}$，其中包含 grizW1-W4 波段的深度图像和基于目录的光度测定。我们介绍了 PICZL，这是一种利用 CNN 集合的机器学习算法。该算法利用跨通道方法，将图像中不同的 SED 特征与从目录级数据中获得的特征相结合。通过高斯混合模型的集成，可以实现全概率分布。在 8098 AGN 的验证样本中，PICZL 实现了 4.5% 的方差 $\sigma_{\textrm{NMAD}}$，异常值分数 $\eta$ 为 5.6%，优于之前使用 ML 为 AGN 计算精确光 z 的尝试。我们强调，模型的性能取决于许多变量，主要是数据的深度。本文对这些依赖关系进行了全面评估。我们的简化方法在考虑不同的数据质量时在整个调查区域保持一致的性能。未来的深度光度测量调查（如 LSST 和 Euclid）可以采用相同的方法，展示其大规模实现的潜力。通过本文，我们发布了 XMM-SERVS W-CDF-S、ELAIS-S1 和 LSS 领域的更新的照片 z（包括错误）。]]></description>
      <guid>https://arxiv.org/abs/2411.07305</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>比较有限资源下实现社会福利最大化的目标策略</title>
      <link>https://arxiv.org/abs/2411.07414</link>
      <description><![CDATA[arXiv:2411.07414v1 公告类型：交叉 
摘要：机器学习越来越多地用于选择哪些个人在人类服务、教育、发展等领域接受有限资源干预。然而，模型预测的正确数量通常并不明显。特别是，政策制定者很少能够获得随机对照试验 (RCT) 的数据，从而准确估计治疗效果——哪些人会从干预中受益更多。观察数据更有可能可用，从而在治疗效果估计中产生相当大的偏差风险。相反，从业者通常使用一种称为“基于风险的定位”的技术，其中模型仅用于预测每个人的现状结果（一项更简单、非因果任务）。那些预测风险较高的人会得到治疗。目前几乎没有经验证据表明哪些选择会导致社会领域中最有效的机器学习信息定位策略。在这项研究中，我们使用来自不同领域的 5 项现实世界 RCT 的数据来实证评估此类选择。我们发现基于风险的定位几乎总是不如基于有偏倚的治疗效果估计的定位。此外，即使政策制定者对帮助高风险个体有强烈的规范偏好，这些结果仍然成立。我们的结果表明，尽管风险预测模型在应用环境中被广泛使用，但从业者最好结合有关异质因果效应的甚至较弱的证据来指导定位。]]></description>
      <guid>https://arxiv.org/abs/2411.07414</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非马尔可夫决策过程的稳健离线强化学习</title>
      <link>https://arxiv.org/abs/2411.07514</link>
      <description><![CDATA[arXiv:2411.07514v1 公告类型：交叉 
摘要：分布式稳健离线强化学习 (RL) 旨在使用从名义模型收集的离线数据集，在最坏的不确定环境中找到表现最佳的策略。虽然稳健 RL 的最新进展集中在马尔可夫决策过程 (MDP) 上，但稳健非马尔可夫 RL 仅限于不确定集中的转换已知的规划问题。在本文中，我们研究了稳健离线非马尔可夫 RL 的学习问题。具体而言，当名义模型允许低秩结构时，我们提出了一种新算法，该算法具有新颖的数据集提炼和不同类型的不确定集下稳健值的下置信区间 (LCB) 设计。我们还为非马尔可夫 RL 中的这些稳健值推导出新的对偶形式，使我们的算法更适合实际实施。通过进一步引入一种专为离线低秩非马尔可夫决策过程量身定制的新型 I 型集中系数，我们证明了我们的算法可以使用 $O(1/\epsilon^2)$ 离线样本找到 $\epsilon$ 最优稳健策略。此外，我们将算法扩展到标准模型没有特定结构的情况。借助新的 II 型集中系数，扩展算法在所有不同类型的不确定性集下也具有多项式样本效率。]]></description>
      <guid>https://arxiv.org/abs/2411.07514</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协作和联合黑盒优化：贝叶斯优化视角</title>
      <link>https://arxiv.org/abs/2411.07523</link>
      <description><![CDATA[arXiv:2411.07523v1 公告类型：交叉 
摘要：我们专注于协作和联合黑盒优化 (BBOpt)，其中代理通过协作顺序实验优化其异构黑盒功能。从贝叶斯优化的角度来看，我们解决了 BBOpt 中分布式实验、异构性和隐私的基本挑战，并提出了三个统一的框架来解决这些问题：(i) 一个实验由中心协调的全局框架，(ii) 一个允许代理根据最少共享信息做出决策的本地框架，以及 (iii) 一个通过协作增强本地代理以改善决策的预测框架。我们对这些框架内的现有方法进行分类，并强调关键的未解决的问题，以充分发挥联合 BBOpt 的潜力。我们的总体目标是将联合学习从其主要的描述/预测范式转变为规范范式，特别是在 BBOpt 的背景下——一个本质上是顺序的决策问题。]]></description>
      <guid>https://arxiv.org/abs/2411.07523</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>任何低秩语言模型的模型窃取</title>
      <link>https://arxiv.org/abs/2411.07536</link>
      <description><![CDATA[arXiv:2411.07536v1 公告类型：交叉 
摘要：模型窃取，即学习者试图通过精心选择的查询恢复未知模型，是机器学习中的一个关键问题，因为它威胁到专有模型的安全性和它们所训练数据的隐私。近年来，人们对窃取大型语言模型 (LLM) 特别感兴趣。在本文中，我们旨在通过研究简单且数学上易于处理的环境来建立对窃取语言模型的理论理解。我们研究隐马尔可夫模型 (HMM) 的模型窃取，以及更普遍的低秩语言模型。
我们假设学习者在由 Kakade、Krishnamurthy、Mahajan 和 Zhang 引入的条件查询模型中工作。我们的主要结果是条件查询模型中的一种有效算法，用于学习任何低秩分布。换句话说，我们的算法可以成功窃取任何输出分布为低秩的语言模型。这改进了 Kakade、Krishnamurthy、Mahajan 和 Zhang 之前的结果，该结果还要求未知分布具有高“保真度”，这一属性仅在有限情况下成立。我们的算法背后有两个关键见解：首先，我们通过在指数级大维度的向量集合中构建重心跨度来表示每个时间步的条件分布。其次，为了从我们的表示中进行采样，我们迭代地解决一系列凸优化问题，这些问题涉及相对熵的投影，以防止在序列长度上累积误差。这是一个有趣的例子，至少从理论上讲，允许机器学习模型在推理时解决更复杂的问题可以大大提高其性能。]]></description>
      <guid>https://arxiv.org/abs/2411.07536</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>块衰落信道上的决策反馈上下文符号检测</title>
      <link>https://arxiv.org/abs/2411.07600</link>
      <description><![CDATA[arXiv:2411.07600v1 公告类型：交叉 
摘要：通过上下文学习 (ICL)，预训练的 Transformers 已经展示了使用示例提示 \textit{无需模型更新} 适应新任务的卓越能力。基于 Transformer 的无线接收器，其中提示由发送和接收信号对形式的导频数据组成，在导频数据丰富时表现出很高的估计精度。然而，在实践中，导频信息通常昂贵且有限。在这项工作中，我们提出了 \underline{DE}cision \underline{F}eedback \underline{IN}-Cont\underline{E}xt \underline{D}etection (DEFINED) 解决方案作为一种新的无线接收器设计，它绕过信道估计并直接使用（有时极其）有限的导频数据执行符号检测。 DEFINED 的关键创新在于 ICL 中提出的决策反馈机制，我们将检测到的符号依次合并到提示中，以改进后续符号的检测。在广泛的无线通信设置中进行的大量实验表明，DEFINED 实现了显著的性能改进，在某些情况下只需要一个导频对。]]></description>
      <guid>https://arxiv.org/abs/2411.07600</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>拟贝叶斯经验贝叶斯：泊松复合决策问题的顺序方法</title>
      <link>https://arxiv.org/abs/2411.07651</link>
      <description><![CDATA[arXiv:2411.07651v1 公告类型：交叉 
摘要：泊松复合决策问题是统计学中的一个经典问题，对于该问题，可以使用参数和非参数经验贝叶斯方法来估计静态或批处理域中的泊松均值。在本文中，我们考虑流媒体或在线域中的泊松复合决策问题。通过依赖准贝叶斯方法（通常称为牛顿算法），我们获得了易于评估、计算效率高且随着数据增加计算成本恒定的顺序泊松均值估计，这对于流数据来说是理想的。研究了所提出的估计的大样本渐近性质，并在遗憾分析方面提供了频率保证。我们在合成数据和真实数据上通过经验验证了我们的方法，并与最流行的替代方案进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2411.07651</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于动态 VAE 的后见之明，用于学习分解式 POMDP 的因果动态</title>
      <link>https://arxiv.org/abs/2411.07832</link>
      <description><![CDATA[arXiv:2411.07832v1 公告类型：交叉 
摘要：从部分观察中学习底层环境动态的表示是机器学习中的一个关键挑战。在部分可观察马尔可夫决策过程 (POMDP) 的背景下，状态表示通常是从过去的观察和行动的历史中推断出来的。我们证明，结合未来信息对于准确捕捉因果动态和增强状态表示至关重要。为了解决这个问题，我们引入了一个动态变分自动编码器 (DVAE)，旨在从 POMDP 中的离线轨迹中学习因果马尔可夫动力学。我们的方法采用了一个扩展的后见框架，在分解的 POMDP 设置中整合了过去、当前和多步未来信息。实证结果表明，与基于历史和典型的基于后见的模型相比，这种方法更有效地揭示了控制隐藏状态转换的因果图。]]></description>
      <guid>https://arxiv.org/abs/2411.07832</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>双重稳健回归不连续设计</title>
      <link>https://arxiv.org/abs/2411.07978</link>
      <description><![CDATA[arXiv:2411.07978v1 公告类型：交叉 
摘要：本研究引入了回归不连续 (RD) 设计的双重稳健 (DR) 估计量。在 RD 设计中，治疗效果是在准实验环境中估计的，其中治疗分配取决于运行变量是否超过预定义的截止值。RD 估计中的一种常见方法是应用非参数回归方法，例如局部线性回归。在这种方法中，有效性在很大程度上依赖于非参数估计量的一致性，并受到非参数收敛速度的限制，从而阻止了 $\sqrt{n}$ 一致性。为了解决这些问题，我们提出了 DR-RD 估计量，它结合了两个不同的条件预期结果估计量。如果这两个估计量中的任何一个是一致的，则治疗效果估计量保持一致。此外，由于去偏效应，如果两个回归估计量都满足某些温和条件，我们提出的估计量就能实现 $\sqrt{n}$-一致性，这也简化了统计推断。]]></description>
      <guid>https://arxiv.org/abs/2411.07978</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型作为因果效应生成器</title>
      <link>https://arxiv.org/abs/2411.08019</link>
      <description><![CDATA[arXiv:2411.08019v1 公告类型：交叉 
摘要：我们提出了一个基于大型语言模型 (LLM) 的可控因果结构数据生成框架。具体来说，我们定义了一个将任何语言模型和任何有向无环图 (DAG) 转换为序列驱动的结构因果模型 (SD-SCM) 的过程。广义上讲，SD-SCM 是一种具有用户定义结构和 LLM 定义结构方程的因果模型。我们描述了 SD-SCM 如何根据所需的因果结构从观察、干预和反事实分布中进行抽样。然后，我们利用此过程为因果推理方法提出了一种新型基准，无需手动指定变量之间的函数关系即可生成个体级反事实数据。我们创建了一个由数千个数据集组成的示例基准，并在这些数据集上测试了一套流行的估计方法，以进行平均值、条件平均值和个体治疗效果估计，包括有无隐藏混杂。除了生成数据之外，同样的程序还允许我们测试可能编码在 LLM 中的因果效应的存在。此程序可以支持审计 LLM 是否存在错误信息、歧视或其他不良行为。我们相信，SD-SCM 可以成为任何受益于具有可控因果结构的序列数据的应用程序中的有用工具。]]></description>
      <guid>https://arxiv.org/abs/2411.08019</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用确定性采样进行信号重建</title>
      <link>https://arxiv.org/abs/2310.09437</link>
      <description><![CDATA[arXiv:2310.09437v2 公告类型：替换 
摘要：我们研究了根据精心选择的分布对一组随机节点进行有限次数评估后平方可积函数的近似值。当假设函数属于再生核希尔伯特空间 (RKHS) 时，这一点尤其重要。这项工作提出结合几个基于两个可能的节点概率分布的自然有限维近似值。这些分布与行列式点过程有关，并使用 RKHS 的核来支持随机设计中适应 RKHS 的规律性。虽然之前关于行列式抽样的工作依赖于 RKHS 范数，但我们证明了 $L^2$ 范数中的均方保证。我们表明行列式点过程及其混合可以产生快速的收敛速度。我们的结果还揭示了当假设更平滑时速率如何变化，这种现象称为超收敛。此外，确定性抽样从文献中的标准 Christoffel 函数中推广了 i.i.d. 抽样。更重要的是，确定性抽样以比 i.i.d. 抽样更少的函数求值次数保证了所谓的实例最优性。]]></description>
      <guid>https://arxiv.org/abs/2310.09437</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>