<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Thu, 18 Jan 2024 03:14:57 GMT</lastBuildDate>
    <item>
      <title>解锁未标记数据：使用 Hui-Walter 范式进行集成学习，用于在线和静态设置中的性能估计。 （arXiv：2401.09376v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.09376</link>
      <description><![CDATA[在机器学习和统计建模领域，从业者
通常在可访问、静态、标记数据的假设下工作
评估和培训。然而，这种假设往往与现实存在偏差
其中数据可能是私有的、加密的、难以测量的或未标记的。在
在本文中，我们通过采用 Hui-Walter 范式（一种方法）来弥补这一差距
传统上应用于流行病学和医学，到机器领域
学习。这种方法使我们能够估计关键绩效指标，例如
误报率、漏报率以及没有场景的先验
基本事实是可用的。我们进一步扩展了这种在线处理模式
数据，为动态数据环境开辟了新的可能性。我们的
方法涉及将数据划分为潜在类以模拟多个
数据总体（如果自然总体不可用）并独立
训练模型来复制多个测试。通过交叉制表二进制
跨集成分类器和多个群体的结果，我们能够
通过吉布斯采样估计未知参数，无需
真实数据或标记数据。本文展示了我们的潜力
通过允许准确的方法来改变机器学习实践
动态和不确定数据条件下的模型评估。
]]></description>
      <guid>http://arxiv.org/abs/2401.09376</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>具有几何平滑动量的随机 Kaczmarz。 （arXiv：2401.09415v1 [数学.NA]）</title>
      <link>http://arxiv.org/abs/2401.09415</link>
      <description><![CDATA[本文研究了添加几何平滑动量的效果
随机 Kaczmarz 算法，它是随机梯度的一个实例
线性最小二乘损失函数的下降。我们证明一个结果关于
定义矩阵奇异向量方向上的预期误差
最小二乘损失。我们提出了几个数值例子来说明
我们的结果的效用并提出几个问题。
]]></description>
      <guid>http://arxiv.org/abs/2401.09415</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>减轻机器学习增强混合模拟中的分布变化。 （arXiv：2401.09259v1 [数学.NA]）</title>
      <link>http://arxiv.org/abs/2401.09259</link>
      <description><![CDATA[我们研究普遍出现的分配转移问题
机器学习增强混合模拟，其中部分模拟
算法被数据驱动的代理所取代。我们首先建立一个
理解机器学习结构的数学框架
增强混合仿真问题及其原因和影响
相关的分布变化。我们展示了分布变化之间的相关性
以及数值和理论上的模拟误差。然后，我们提出一个
基于切线空间正则化估计器的简单方法来控制
分布偏移，从而提高模拟的长期精度
结果。在线性动力学情况下，我们提供了全面的理论
分析以量化所提出方法的有效性。此外，我们
进行多项数值实验，包括模拟部分已知的
反应扩散方程并使用以下方程求解纳维-斯托克斯方程
使用数据驱动压力求解器的投影方法。在所有情况下，我们观察到
根据所提出的方法，模拟精度显着提高，
特别是对于具有高度分布偏移的系统，例如
具有较强的非线性反应机制，或大流量
雷诺数。
]]></description>
      <guid>http://arxiv.org/abs/2401.09259</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>带有马尔可夫噪声的两时间尺度随机逼近的中心极限定理：理论与应用。 （arXiv：2401.09339v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.09339</link>
      <description><![CDATA[双时间尺度随机逼近 (TTSA) 是最通用的方法之一
迭代随机算法的框架。这其中包括众所周知的
随机优化方法，例如 SGD 变体和专为
双水平或极小极大问题，以及像家庭这样的强化学习
基于梯度的时间差异（GTD）算法。在本文中，我们
在受控马尔可夫下对 TTSA 进行深入的渐近分析
通过中心极限定理 (CLT) 计算噪声，揭示 TTSA 的耦合动力学
受到底层马尔可夫链的影响，尚未解决
以前的 TTSA 的 CLT 结果仅具有 Martingale 差异噪声。建筑
基于我们的CLT，我们扩展了其高效采样的应用范围
分布式学习中从普通 SGD 到更广泛的 TTSA 环境的策略，
从而扩大了胡等人的范围。 （2022）。此外，我们还利用 CLT
结果推导出非线性 GTD 算法的统计特性
使用马尔可夫样本进行函数逼近并显示它们的相同性
渐近性能，从当前的有限时间来看这一观点并不明显
界限。
]]></description>
      <guid>http://arxiv.org/abs/2401.09339</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>使用并行随机优化几乎可以免费进行高置信度推理。 （arXiv：2401.09346v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.09346</link>
      <description><![CDATA[通过随机优化进行估计的不确定性量化
在线环境中的解决方案最近很受欢迎。这张纸
介绍了一种专注于构建置信度的新颖推理方法
具有高效计算和快速收敛到标称水平的间隔。
具体来说，我们建议使用少量独立的多次运行来
获取分布信息并构建基于 t 的置信区间。
我们的方法需要最少的额外计算和内存
估计的标准更新，使得推理过程几乎免费。
我们为置信区间提供严格的理论保证，
通过明确的证明覆盖范围大致准确
收敛速度并允许高置信度推断。在
特别是，为在线开发了一种新的高斯近似结果
估计器来表征我们的置信区间的覆盖属性
就相对误差而言。此外，我们的方法还允许
利用并行计算进一步加速使用多个计算
核心。它易于实现，并且可以与现有的随机模型集成
算法无需进行复杂的修改。
]]></description>
      <guid>http://arxiv.org/abs/2401.09346</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>深度学习模型的两尺度复杂性度量。 （arXiv：2401.09184v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.09184</link>
      <description><![CDATA[我们为统计模型引入了一种新颖的容量测量 2sED
有效维度。新数量可证明限制了泛化
模型温和假设下的误差。此外，对标准的模拟
数据集和流行的模型架构表明 2sED 与
训练误差。对于马尔可夫模型，我们展示了如何有效地
通过分层迭代方法从下面近似 2sED，其中
使我们能够处理具有大量参数的深度学习模型。
仿真结果表明该近似对于不同的情况是好的
著名的模型和数据集。
]]></description>
      <guid>http://arxiv.org/abs/2401.09184</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>计算多类分类中对抗训练下界的最佳传输方法。 （arXiv：2401.09191v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.09191</link>
      <description><![CDATA[尽管基于深度学习的算法取得了成功，但它仍广为人知
神经网络可能不够稳健。一个流行的执行范式
鲁棒性是对抗性训练（AT），然而，这引入了许多
计算和理论困难。最近的工作已经开发出
多类分类设置中的 AT 之间的联系
多边际最优运输（MOT），解锁一套新的研究工具
这个问题。在本文中，我们利用 MOT 连接来提出
用于计算通用较低的可计算处理的数值算法
最佳对抗风险的界限并确定最佳分类器。我们
提出两种基于线性规划（LP）和熵的主要算法
正则化（Sinkhorn）。我们的主要见解是，人们可以无害地截断
类之间的高阶交互，防止组合运行
MOT 问题中通常遇到的时间。我们验证这些结果
在 MNIST 和 CIFAR-$10$ 上进行的实验，证明了我们的易处理性
方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.09191</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>固定预算差异私人最佳手臂识别。 （arXiv：2401.09073v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.09073</link>
      <description><![CDATA[我们研究固定预算中线性老虎机的最佳臂识别（BAI）
差异隐私约束下的制度，当手臂奖励是
支持单位间隔。给定有限的预算 $T$ 和隐私
参数$\varepsilon&gt;0$，目标是最小化错误概率
在 $T$ 采样轮次后找到平均值最大的臂，并遵守
决策者的政策满足一定的约束{\em
$\varepsilon$-差分隐私} ($\varepsilon$-DP) 约束。我们构建
满足 $\varepsilon$-DP 约束（称为 {\sc DP-BAI}）的策略
提出{\em最大绝对行列式}的原则，并推导出
其错误概率的上限。此外，我们推导了一个极小极大值
限制错误概率，并证明下限和上限
边界在 $T$ 中呈指数衰减，两个边界中的指数匹配
(a) 臂的次优差距，(b) $\varepsilon$ 中的顺序，以及
(c) 问题复杂性可表示为两项之和，其中一项
描述标准固定预算 BAI 的复杂性（没有隐私
约束），另一个考虑 $\varepsilon$-DP 约束。
此外，我们还提供了一些辅助结果，有助于
错误概率下限的推导。这些结果，我们
假设，可能具有独立的利益，并且可能有助于证明
其他几个老虎机问题中错误概率的下限。然而
先前的工作为 BAI 在固定预算制度下提供结果，没有隐私
约束或在具有隐私约束的固定信任制度中，我们的
该工作通过为 BAI 提供结果来填补文献空白
$\varepsilon$-DP 约束下的固定预算制度。
]]></description>
      <guid>http://arxiv.org/abs/2401.09073</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:53 GMT</pubDate>
    </item>
    <item>
      <title>了解图神经网络的异质性。 （arXiv：2401.09125v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.09125</link>
      <description><![CDATA[具有异质性的图被视为对 Graph 具有挑战性的场景
神经网络 (GNN)，其中节点与不同的邻居连接
通过各种模式。在本文中，我们提出了理论理解
通过合并不同的异质性模式对 GNN 的影响
通过图卷积（GC）操作进入完全连接的网络
提出了异嗜随机块模型（HSBM），一种通用随机图
可以适应不同异质性模式的模型。首先，我们证明
通过应用 GC 操作，可分离性增益由两个决定
因素，即邻域分布的欧几里得距离和
$\sqrt{\mathbb{E}\left[\operatorname{deg}\right]}$，其中
$\mathbb{E}\left[\operatorname{deg}\right]$ 是平均节点度。它
表明需要评估异质性对分类的影响
与平均节点度一起。其次，我们证明了拓扑
噪声对可分离性有不利影响，相当于
贬低$\mathbb{E}\left[\operatorname{deg}\right]$。最后，申请的时候
多次 GC 操作，我们表明可分离性增益由下式决定：
$l$ 驱动的邻域分布的归一化距离。它
表明节点仍然具有可分离性，因为 $l$ 趋于无穷大
范围广泛的政权。对合成和现实世界进行广泛的实验
数据验证了我们理论的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2401.09125</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:53 GMT</pubDate>
    </item>
    <item>
      <title>监控平台数据流的机器学习预测。 （arXiv：2401.09144v1 [stat.AP]）</title>
      <link>http://arxiv.org/abs/2401.09144</link>
      <description><![CDATA[数据流预测是数字决策的重要输入
平台。机器学习算法是产生这种结果的有吸引力的候选者
预测。然而，数字平台需要一个大规模的预测框架
能够灵活应对性能突然下降。重新训练 ML 算法
与新数据批次输入相同的速度通常计算成本太高。
另一方面，不频繁的重新训练需要指定重新训练
频率，并且通常伴随着预测恶化的严重成本。到
确保准确稳定的预测，我们提出了一个简单的数据驱动
监控程序来回答何时应该使用 ML 算法的问题
重新训练。我们不调查数据流的不稳定性，而是测试
如果传入的流预测损失批次与明确定义的不同
参考批次。使用包含 15 分钟频率数据的新颖数据集
来自在伦敦运营的按需物流平台的数据流，我们应用
对流行 ML 算法（包括随机森林、XGBoost）的监控程序
和套索。我们证明基于监控的再训练可以产生准确的预测
与可行的基准进行比较，同时保留计算可行性。
此外，监测程序的选择比监测程序的选择更重要。
ML 算法，从而允许从业者结合所提出的
使用自己喜欢的预测算法监控程序。
]]></description>
      <guid>http://arxiv.org/abs/2401.09144</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:53 GMT</pubDate>
    </item>
    <item>
      <title>非参数学习的依赖性和复杂性之间的权衡——一种经验过程方法。 （arXiv：2401.08978v1 [数学.ST]）</title>
      <link>http://arxiv.org/abs/2401.08978</link>
      <description><![CDATA[独立同分布的经验过程理论观察已成为一种普遍存在的现象
用于理解各种统计的泛化属性的工具
问题。然而，在许多数据表现出时间性的应用中
依赖性（例如，在金融、医学成像、天气预报等方面）、
相应的经验过程却知之甚少。受此激励
观察，我们提出了经验的预期上界的一般界限
标准 $\beta/\rho$ 混合假设下的过程。与大多数之前的不同
工作中，我们的结果涵盖了长期和短期的制度
依赖性。我们的主要结果表明，在
底层函数类的复杂性以及函数之间的依赖关系
观察表征了一大类非参数的学习率
问题。这种权衡揭示了一个新现象，即即使在
远程依赖性，有可能达到与 i.i.d 相同的速率。
设置，前提是底层函数类足够复杂。我们
通过分析各种结果来展示我们的研究结果的实际意义
固定维度和增长维度的统计估计。我们的主要例子
包括泛化误差范围的综合案例研究
固定和增长平滑度类的非参数回归
使用神经网络的维度，形状限制的多元凸回归，
估计两个概率之间的最佳传输（Wasserstein）距离
Mammen-Tsybakov 裕度条件下的分布和分类 --
所有这些都在适当的混合假设下。在此过程中，我们还开发
$L_r$ ($1\le r\le 2$) 上的界限 - 具有依赖关系的局部经验过程
观察，然后我们利用这些观察来获得更快的速度（a）免调整
适应，以及（b）集合结构学习问题。
]]></description>
      <guid>http://arxiv.org/abs/2401.08978</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:52 GMT</pubDate>
    </item>
    <item>
      <title>等周测量下的快速并行采样。 （arXiv：2401.09016v1 [cs.DS]）</title>
      <link>http://arxiv.org/abs/2401.09016</link>
      <description><![CDATA[我们展示了如何从分布 $\pi$ 到 $\mathbb 上并行采样
R^d$ 满足 log-Sobolev 不等式并具有平滑的对数密度，由
并行化 Langevin（或欠阻尼 Langevin）算法。我们展示
我们的算法从接近的分布 $\hat\pi$ 输出样本
到 Kullback-Leibler (KL) 散度中的 $\pi$（分别为总变差 (TV)
距离），同时仅使用 $\log(d)^{O(1)}$ 平行回合和
$\widetilde{O}(d)$ （分别为 $\widetilde O(\sqrt d)$) 的梯度评估
全部的。这构成了第一个与TV距离并行采样的算法
保证。

对于我们的主要应用程序，我们展示了如何结合电视距离保证
我们的算法与先前的工作相结合并获得 RNC 采样到计数
超立方体 $\{\pm 1\}^n$ 上离散分布族的约简
在指数倾斜下闭合并且具有有界协方差。
因此，我们获得了一个用于定向欧拉游览的 RNC 采样器，并且
不对称行列式点过程，解决中提出的开放性问题
之前的作品。
]]></description>
      <guid>http://arxiv.org/abs/2401.09016</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:52 GMT</pubDate>
    </item>
    <item>
      <title>迈向银行业负责任的人工智能：解决公平决策的偏见。 （arXiv：2401.08691v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.08691</link>
      <description><![CDATA[在一个以人工智能普遍融合为特征的时代
将情报融入到不同行业的决策过程中
对信任的需求从未如此明显。本论文着手
对偏见和公平的全面探索，特别强调
它们对银行业产生影响，人工智能驱动的决策在银行业产生影响
造成重大社会后果。在此背景下，无缝集成
公平性、可解释性和人类监督至关重要，
最终建立了通常所说的
“负责任的人工智能”。这强调了解决偏见的关键性质
在发展与两者无缝结合的企业文化的过程中
人工智能法规和普遍人权标准，特别是在该领域
自动化决策系统。如今，道德原则已深入人心
人工智能模型的开发、训练和部署对于
遵守即将出台的欧洲法规并促进社会
好的。本论文围绕三个基本支柱构建：理解
偏见、减轻偏见和解释偏见。这些贡献是
通过在现实场景中的实际应用来验证
与联合圣保罗银行合作。此次合作不仅
有助于我们对公平的理解，同时也提供了实用的工具
负责任地实施基于人工智能的决策系统。排队
本着开源原则，我们发布了 Bias On Demand 和 FairView
可访问的Python包，进一步推动AI领域的进步
公平。
]]></description>
      <guid>http://arxiv.org/abs/2401.08691</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:51 GMT</pubDate>
    </item>
    <item>
      <title>差异特征漏报对算法公平性的影响。 （arXiv：2401.08788v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.08788</link>
      <description><![CDATA[公共部门的预测风险模型通常使用
对于更重要的亚人群来说，行政数据更加完整
依靠公共服务。例如，在美国，有关信息
政府机构通常可以利用医疗保健服务
受医疗补助和医疗保险支持的个人，但不接受私人资助
受保。对公共部门算法的批评已经发现了这样的问题
差异特征漏报是算法差异的驱动因素
决策。然而，这种形式的数据偏差仍未得到充分研究
技术观点。虽然之前的工作已经检验了公平性的影响
加性特征噪声和明显标记为缺失的特征，
设置数据缺失缺失指标（即差异特征
报告不足）一直缺乏研究关注。在这项工作中，我们
提出一种差异特征漏报的分析易处理模型
然后我们用它来描述这种数据偏差对
算法公平性。我们演示了标准缺失数据方法如何
通常无法减轻这种情况下的偏见，并提出一组新的
专门针对差异特征漏报而定制的方法。我们的
结果表明，在现实世界的数据环境中，报告不足通常会导致
以扩大差距。所提出的解决方法显示出成功
减缓不公平现象的增加。
]]></description>
      <guid>http://arxiv.org/abs/2401.08788</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:51 GMT</pubDate>
    </item>
    <item>
      <title>内在数据集属性对泛化的影响：揭示自然图像和医学图像之间的学习差异。 （arXiv：2401.08865v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.08865</link>
      <description><![CDATA[本文研究了神经网络如何学习的差异
不同的成像领域，在采用计算机时经常被忽视
视觉技术从自然图像领域到其他专业领域
医学图像等领域。最近的工作发现，泛化
经过训练的网络的误差通常随着内在维度的增加而增加
其训练集的 ($d_{data}$) 。然而，这种关系的陡峭性
医学（放射学）和自然成像之间存在显着差异
域，没有现有的理论解释。我们解决这个差距
通过建立并凭经验验证泛化尺度来获取知识
关于 $d_{data}$ 的定律，并建议大幅缩放
两个所考虑的域之间的差异可能至少部分是
归因于医学成像更高的内在“标签清晰度”($K_F$)
数据集，我们提出的一个指标。接下来，我们展示一个额外的好处
测量训练集标签清晰度的方法：它是负相关的
训练有素的模型具有对抗鲁棒性，这尤其导致模型
对于对对抗性具有更高脆弱性的医学图像
攻击。最后，我们将 $d_{data}$ 形式扩展到相关度量
学习表示内在维度（$d_{repr}$），得出
关于 $d_{repr}$ 的泛化标度律，并表明 $d_{data}$
用作 $d_{repr}$ 的上限。我们的理论结果得到了支持
通过对六个模型和十一个自然和医学成像进行彻底的实验
一系列训练集大小的数据集。我们的研究结果提供了一些见解
数据集内在属性对泛化、表示的影响
深度神经网络的学习和鲁棒性。
]]></description>
      <guid>http://arxiv.org/abs/2401.08865</guid>
      <pubDate>Thu, 18 Jan 2024 03:14:51 GMT</pubDate>
    </item>
    </channel>
</rss>