<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 17 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过高阶动作匹配实现平均场和随机系统的参数模型简化</title>
      <link>https://arxiv.org/abs/2410.12000</link>
      <description><![CDATA[arXiv:2410.12000v1 公告类型：新
摘要：这项工作的目的是学习具有随机和平均场效应并依赖于物理参数的物理系统的种群动态模型。学习到的模型可以作为经典数值模型的替代品，以有效地预测物理参数上的系统行为。基于最佳传输和动作匹配的 Benamou-Brenier 公式，我们使用变分问题来推断参数和时间相关的梯度场，这些梯度场代表了种群动态的近似值。然后可以使用推断出的梯度场快速生成样本轨迹，以模拟物理系统在种群层面上随物理参数变化的动态。我们表明，将蒙特卡罗采样与高阶求积规则相结合对于准确估计样本数据的训练目标和稳定训练过程至关重要。我们在 Vlasov-Poisson 不稳定性以及高维粒子和混沌系统上证明了我们的方法能够准确预测广泛参数范围内的群体动态，并且优于仅仅以时间和物理参数为条件的最先进的基于扩散和基于流的建模。]]></description>
      <guid>https://arxiv.org/abs/2410.12000</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用重要性加权变分推理进行学习：VR-IWAE 边界的梯度估计量的渐近性</title>
      <link>https://arxiv.org/abs/2410.12035</link>
      <description><![CDATA[arXiv:2410.12035v1 公告类型：新
摘要：已经提出了几种流行的涉及重要性加权思想的变分界限，以在最大似然优化的背景下推广和改进证据下限 (ELBO)，例如重要性加权自动编码器 (IWAE) 和变分 R\&#39;enyi (VR) 界限。使用这些界限学习感兴趣的参数的方法通常相当于运行结合重新参数化技巧的基于梯度的变分推理算法。然而，变分界限的选择如何影响变分推理算法的结果可能尚不清楚。最近，VR-IWAE 界限被引入作为统一 ELBO、IWAE 和 VR 界限方法的变分界限。在本文中，我们对 VR-IWAE 边界的重新参数化和双重重新参数化梯度估计量进行了两项分析，揭示了这些梯度估计量的优点和局限性，同时使我们能够比较 ELBO、IWAE 和 VR 边界方法。我们的工作推进了对重要性加权变分推理方法的理解，并通过实证说明了我们的理论发现。]]></description>
      <guid>https://arxiv.org/abs/2410.12035</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>黑箱随机模拟的深度最优传感器放置</title>
      <link>https://arxiv.org/abs/2410.12036</link>
      <description><![CDATA[arXiv:2410.12036v1 公告类型：新
摘要：选择具有成本效益的最佳传感器配置以便随后推断黑盒随机系统中的参数面临着巨大的计算障碍。我们提出了一种新颖而强大的方法，使用基于联合能量的模型对输入参数和解决方案的联合分布进行建模，该模型在模拟数据上进行训练。与现有的基于模拟的推理方法不同，这些方法必须与一组特定的点评估相关联，我们学习参数和解决方案的功能表示。这用作联合分布的独立于分辨率的即插即用替代品，可以对任何一组点进行调节，从而实现高效的传感器放置方法。我们证明了我们的框架在各种随机问题上的有效性，表明与传统方法相比，我们的方法以更低的计算成本提供了高度信息丰富的传感器位置。]]></description>
      <guid>https://arxiv.org/abs/2410.12036</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全局删失分位数随机森林</title>
      <link>https://arxiv.org/abs/2410.12209</link>
      <description><![CDATA[arXiv:2410.12209v1 公告类型：新
摘要：近年来，删失分位数回归在生存分析中越来越受欢迎，而许多现有工作依赖于线性假设。在这项工作中，我们提出了一种全局删失分位数随机森林 (GCQRF)，用于预测受右删失数据的条件分位数过程，这是一种基于森林的灵活、有竞争力的方法，能够捕捉复杂的非线性关系。考虑到树中的随机性，并将所提出的方法与随机不完全无限度 U 过程 (IDUP) 连接起来，我们在不假设无限森林的情况下量化预测过程的变化并建立其弱收敛性。此外，提出了基于样本外预测准确度的特征重要性排序度量。我们证明了所提出的方法比许多现有替代方法具有更高的预测准确度，并说明了所提出的重要性排序度量在模拟数据和真实数据上的使用。]]></description>
      <guid>https://arxiv.org/abs/2410.12209</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>线性对抗训练的有效优化算法</title>
      <link>https://arxiv.org/abs/2410.12677</link>
      <description><![CDATA[arXiv:2410.12677v1 公告类型：新
摘要：对抗训练可用于学习对扰动具有鲁棒性的模型。对于线性模型，它可以表述为凸优化问题。与深度学习背景下提出的方法相比，利用优化结构可以显著提高收敛速度。不过，使用通用凸求解器对于大规模问题可能效率低下。在这里，我们提出了针对线性模型对抗训练的定制优化算法，使大规模回归和分类问题更易于处理。对于回归问题，我们提出了基于迭代岭回归的求解器系列，对于分类，我们提出了基于投影梯度下降的求解器系列。这些方法基于原始问题的扩展变量重新表述。我们在数值示例中说明了它们的效率。]]></description>
      <guid>https://arxiv.org/abs/2410.12677</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>局部迁移学习高斯过程建模，应用于昂贵的计算机模拟器的代理建模</title>
      <link>https://arxiv.org/abs/2410.12690</link>
      <description><![CDATA[arXiv:2410.12690v2 公告类型：新
摘要：科学进步的一个关键瓶颈是复杂系统的计算机模拟成本高昂。替代模型提供了一种有吸引力的解决方案：此类模型在模拟器评估上进行训练，然后用于模拟和量化昂贵模拟器在未探索输入时的不确定性。在许多应用中，人们通常拥有相关系统的可用数据。例如，在设计新的喷气涡轮机时，可能存在对具有类似配置的涡轮机的研究。一个关键问题是如何将来自此类“源”系统的信息传输到感兴趣的“目标”系统上进行有效的替代训练。因此，我们提出了一种新的局部迁移学习高斯过程 (LOL-GP) 模型，该模型利用精心设计的高斯过程将此类信息传输到替代建模。LOL-GP 的关键新颖之处在于潜在正则化模型，它可以识别应执行转移的区域和应避免转移的区域。这种“局部迁移”特性在科学系统中是理想的：在某些参数下，此类系统可能表现相似，因此迁移是有益的；在其他参数下，它们可能表现不同，因此迁移是有害的。通过考虑局部迁移，LOL-GP 可以纠正现有迁移学习模型中“负迁移”的一个关键限制，即信息的迁移会降低预测性能。我们推导出一种 Gibbs 采样算法，用于在 LOL-GP 上进行有效的后验预测采样，适用于多源和多保真度迁移设置。然后，我们通过一系列数值实验和喷气涡轮设计应用展示了 LOL-GP 相对于现有方法的改进替代性能。]]></description>
      <guid>https://arxiv.org/abs/2410.12690</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种利用注意和特征增强对抗噪声干扰的稳健多源遥感影像匹配方法</title>
      <link>https://arxiv.org/abs/2410.11848</link>
      <description><![CDATA[arXiv:2410.11848v1 公告类型：交叉 
摘要：图像匹配是多源遥感图像应用的基本和关键任务。然而，遥感图像易受各种噪声影响。因此，如何有效地在噪声图像中实现精确匹配是一个具有挑战性的问题。针对这一问题，我们提出了一种利用注意力机制和特征增强来抵抗噪声干扰的鲁棒多源遥感图像匹配方法。在第一阶段，我们结合深度卷积和Transformer的注意力机制进行密集特征提取，构建具有更高辨别性和鲁棒性的特征描述子。随后，我们采用由粗到细的匹配策略实现密集匹配。在第二阶段，我们引入基于二分类机制的异常值去除网络，该网络可以在图像之间建立有效且几何一致的对应关系；通过对每个对应关系进行加权，进行正常值与异常值分类，并从密集匹配中去除异常值。最终，我们可以实现更高效、更准确的匹配。为了验证所提方法的性能，本文使用多源遥感影像数据集进行实验，并在无噪声、加性随机噪声和周期性条纹噪声等不同场景下与其他最新方法进行了比较。对比结果表明，所提方法具有更均衡的性能和鲁棒性。所提方法为解决噪声图像匹配难题提供了有价值的参考。]]></description>
      <guid>https://arxiv.org/abs/2410.11848</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于模拟的散射表征推理：散射就是你所需要的</title>
      <link>https://arxiv.org/abs/2410.11883</link>
      <description><![CDATA[arXiv:2410.11883v1 公告类型：交叉 
摘要：我们展示了首次成功使用散射表示而无需进一步压缩来进行基于模拟的图像推理 (SBI)（即场级），并以宇宙学案例研究为例。散射表示为后续学习任务提供了高效的表示空间，尽管更高维度的压缩空间带来了挑战。我们通过空间平均以及更具表现力的密度估计器克服了这些问题。与其他方法相比，这种方法不需要额外的模拟来训练或计算导数，是可解释的，并且能够抵御协变量偏移。正如预期的那样，我们表明，仅散射方法比传统的二阶汇总统计数据提取了更多信息。]]></description>
      <guid>https://arxiv.org/abs/2410.11883</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用精炼信息和模式交互选择对 KL 误差进行完整分解</title>
      <link>https://arxiv.org/abs/2410.11964</link>
      <description><![CDATA[arXiv:2410.11964v1 公告类型：交叉 
摘要：对数线性模型在过去几十年中获得了大量的理论关注，并且仍然是学习离散变量概率分布的基本工具。尽管它在统计力学和高维统计中非常流行，但绝大多数此类基于能量的建模方法仅关注双变量关系，例如玻尔兹曼机和马尔可夫图模型。虽然这些方法具有更易于解决的结构学习问题和更易于优化的参数分布，但它们往往忽略了存在于不同变量之间高阶相互作用中的丰富结构。使用信息几何领域的最新工具，我们重新审视对数线性模型的经典公式，重点关注高阶模式相互作用，超越了独立分布的 1 体模式和玻尔兹曼分布的 2 体模式。这种观点使我们能够定义 KL 误差的完整分解。这促使我们在可能的模式交互集上制定稀疏选择问题。正如稀疏图选择可以实现更好的泛化一样，我们发现我们学习到的分布能够更有效地利用实践中可用的有限数据量。在合成数据集和现实世界数据集上，我们展示了我们的算法在最大化生成任务的对数似然方面的有效性，以及对分类判别任务的易适应性。]]></description>
      <guid>https://arxiv.org/abs/2410.11964</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模型平衡有助于低数据训练和微调</title>
      <link>https://arxiv.org/abs/2410.12178</link>
      <description><![CDATA[arXiv:2410.12178v1 公告类型：交叉 
摘要：基础模型的最新进展强调了使用小型、精选的数据集将预训练模型与专业领域对齐的必要性。对这些基础模型的研究强调了低数据训练和微调的重要性。这个在自然语言处理 (NLP) 中众所周知的主题也在新兴的科学机器学习 (SciML) 领域受到越来越多的关注。为了解决低数据训练和微调的局限性，我们从重尾自正则化 (HT-SR) 理论中汲取灵感，分析了经验谱密度 (ESD) 的形状并揭示了不同模型层之间训练质量的不平衡。为了缓解这个问题，我们采用了最近提出的逐层学习率调度器 TempBalance，它可以有效地平衡跨层的训练质量并增强 NLP 和 SciML 任务的低数据训练和微调。值得注意的是，随着可用调整数据量的减少，TempBalance 的性能提升越来越显著。比较分析进一步凸显了 TempBalance 的有效性及其作为提高模型性能的“附加”方法的适应性。]]></description>
      <guid>https://arxiv.org/abs/2410.12178</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解受污染混合专家中极小极大参数估计的专家结构</title>
      <link>https://arxiv.org/abs/2410.12258</link>
      <description><![CDATA[arXiv:2410.12258v1 公告类型：交叉 
摘要：我们对受污染的专家混合中的参数估计进行了收敛分析。该模型的动机是提示学习问题，其中人们利用可以表示为专家的提示来微调大规模预训练模型以学习下游任务。分析中出现了两个基本挑战：（i）预训练模型和提示的混合比例可能会收敛到零，提示在训练期间消失；（ii）预训练模型和提示的参数之间的代数相互作用可以通过某些偏微分方程发生并减慢提示学习。作为回应，我们引入了一个可区分性条件来控制先前的参数交互。此外，我们还考虑了各种类型的专家结构，以了解它们对参数估计的影响。在每种情况下，我们都提供了参数估计的全面收敛速度以及相应的极小极大下限。]]></description>
      <guid>https://arxiv.org/abs/2410.12258</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>条件结果等价性：CATE 的分位数替代方案</title>
      <link>https://arxiv.org/abs/2410.12454</link>
      <description><![CDATA[arXiv:2410.12454v1 公告类型：交叉 
摘要：条件分位数治疗效果 (CQTE) 可以深入了解条件平均治疗效果 (CATE) 以外的治疗效果。这种提供多个响应分位数信息的能力使得 CQTE 在治疗效果不能通过位置偏移很好地建模的情况下特别有价值，即使是有条件地依赖于协变量。然而，CQTE 的估计具有挑战性，并且通常取决于作为协变量函数的各个分位数的平滑度，而不是 CQTE 本身的平滑度。这与 CATE 形成鲜明对比，在 CATE 中，当 CATE 本身平滑时，可以获得对干扰参数平滑度的依赖性较小的高质量估计。此外，CQTE 的相对平滑度缺乏 CATE 平滑度的可解释性，因此不清楚这是否是一个合理的假设。我们通过考虑一个新的估计量，即条件分位数比较器 (CQC)，将 CATE 和 CQTE 的理想特性结合起来。CQC 不仅保留了有关整个治疗分布的信息（与 CQTE 类似），而且还具有更自然的平滑示例，并且能够在辅助估计量中利用简单性。我们为估计量的误差提供了有限的样本界限，证明了其利用简单性的能力。我们在数值模拟中验证了我们的理论，结果表明我们的方法比基线产生了更准确的估计。最后，我们将我们的方法应用于一项关于就业激励对不同年龄组收入影响的研究。我们发现我们的方法能够揭示不同分位数之间影响的异质性。]]></description>
      <guid>https://arxiv.org/abs/2410.12454</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无过度参数化的神经网络损失景观表征</title>
      <link>https://arxiv.org/abs/2410.12455</link>
      <description><![CDATA[arXiv:2410.12455v2 公告类型：交叉 
摘要：优化方法在现代机器学习中起着至关重要的作用，为深度学习模型的卓越经验成就提供了动力。考虑到这些模型的损失景观具有复杂的非凸性，这些成功就更加引人注目了。然而，确保优化方法的收敛需要对目标函数施加特定的结构条件，而这些条件在实践中很少得到满足。一个突出的例子是广为人知的 Polyak-Lojasiewicz (PL) 不等式，近年来引起了广泛关注。然而，验证深度神经网络的此类假设需要大量且通常不切实际的过度参数化。为了解决这一限制，我们提出了一类新颖的函数，它可以表征现代深度模型的损失景观，而不需要大量的过度参数化，还可以包括鞍点。至关重要的是，我们证明了基于梯度的优化器在这一假设下具有收敛的理论保证。最后，我们通过理论分析和对各种深度学习模型进行实证实验来验证新函数类的合理性。]]></description>
      <guid>https://arxiv.org/abs/2410.12455</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用逆扩散 KL 散度训练神经采样器</title>
      <link>https://arxiv.org/abs/2410.12456</link>
      <description><![CDATA[arXiv:2410.12456v1 公告类型：交叉 
摘要：训练生成模型从非归一化密度函数中采样是机器学习中一项重要且具有挑战性的任务。传统的训练方法通常依赖于逆 Kullback-Leibler (KL) 散度，因为它易于处理。然而，逆 KL 的模式寻求行为阻碍了对多模态目标分布的有效近似。为了解决这个问题，我们建议最小化沿模型和目标密度的扩散轨迹的逆 KL。我们将这个目标称为逆扩散 KL 散度，它允许模型捕获多种模式。利用这个目标，我们训练神经采样器，它可以有效地一步从目标分布中生成样本。我们证明我们的方法提高了各种玻尔兹曼分布的采样性能，包括合成多模态密度和 n 体粒子系统。]]></description>
      <guid>https://arxiv.org/abs/2410.12456</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>低秩对抗性 PGD 攻击</title>
      <link>https://arxiv.org/abs/2410.12607</link>
      <description><![CDATA[arXiv:2410.12607v1 公告类型：交叉 
摘要：针对深度神经网络模型的对抗性攻击发展迅速，并被广泛用于研究这些网络的稳定性。在各种对抗性策略中，投影梯度下降 (PGD) 是一种在计算机视觉中被广泛采用的方法，因为它有效且实施快速，适合对抗性训练。在这项工作中，我们观察到在许多情况下，使用 PGD 计算的扰动主要仅影响原始图像奇异值谱的一部分，这表明这些扰动近似为低秩。受此观察的启发，我们提出了一种 PGD 的变体，可以有效地计算低秩攻击。我们在一系列标准模型以及经过对抗性训练的稳健模型上广泛验证了我们的方法。我们的分析表明，由于所提出的低秩 PGD 具有简单、快速的实现和具有竞争力的性能，因此可以有效地用于对抗性训练。值得注意的是，我们发现低秩 PGD 的表现通常与传统的全秩 PGD 攻击相当，有时甚至更好，同时占用的内存却少得多。]]></description>
      <guid>https://arxiv.org/abs/2410.12607</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>