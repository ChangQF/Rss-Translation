<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 04 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>学习具有模型形式不确定性的潜在空间动力学：一种随机降阶建模方法</title>
      <link>https://arxiv.org/abs/2409.00220</link>
      <description><![CDATA[arXiv:2409.00220v1 公告类型：新
摘要：本文提出了一种概率方法，使用算子推理技术表示和量化复杂系统降阶建模中的模型形式不确定性。此类不确定性可能出现在选择适当的状态空间表示时，出现在许多降阶建模方法所依赖的投影步骤中，或者作为训练期间考虑的副产品，仅举几例。根据文献中的先前研究，所提出的方法通过投影矩阵的随机化来扩展近似空间，从而捕获这些不确定性。这是通过将黎曼投影和回缩算子（作用于 Stiefel 流形的子集）与信息论公式相结合来实现的。通过识别和量化模型形式不确定性对推断算子的影响，评估了该方法在流体力学典型问题上的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.00220</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于预算分配的多任务组合赌博机</title>
      <link>https://arxiv.org/abs/2409.00561</link>
      <description><![CDATA[arXiv:2409.00561v1 公告类型：新
摘要：当今的顶级广告商通常同时管理数百个广告活动，并在全年不断推出新的广告活动。营销经理面临的一个关键挑战是确定每个广告活动中有限预算在各个广告系列之间的最佳分配，以最大化累积回报，尤其是考虑到回报结果的巨大不确定性。在本文中，我们建议将预算分配制定为多任务组合老虎机问题，并引入一种新颖的在线预算分配系统。所提出的系统：i）集成贝叶斯分层模型，智能地利用广告活动和广告系列的元数据和预算规模，确保有效的信息共享；ii）提供灵活性，以结合线性回归、高斯过程和神经网络等各种建模技术，以适应不同的环境复杂性；iii）采用汤普森抽样（TS）技术在探索和开发之间取得平衡。通过离线评估和在线实验，我们的系统表现出稳健性和适应性，有效地最大化了整体累积回报。所提程序的 Python 实现可在 https://anonymous.4open.science/r/MCMAB 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.00561</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度 ReLU 神经网络对 Sobolev 和 Besov 函数进行最优逼近</title>
      <link>https://arxiv.org/abs/2409.00901</link>
      <description><![CDATA[arXiv:2409.00901v1 公告类型：新 
摘要：本文研究了当误差以 $L^p([0,1]^d)$ 范数衡量时，Sobolev 空间 $\mathcal{W}^{s,q}([0,1]^d)$ 和 Besov 空间 $\mathcal{B}^s_{q,r}([0,1]^d)$ 中的函数如何有效地被宽度为 $W$、深度为 $L$ 的深度 ReLU 神经网络近似的问题。最近的几项研究已经对这一问题进行了研究，当 $p=q=\infty$ 时，得到了近似速率 $\mathcal{O}((WL)^{-2s/d})$ 直到对数因子，而当 Sobolev 嵌入条件 $1/q -1/pd$ 成立时，对于固定宽度的网络，速率 $\mathcal{O}(L^{-2s/d})$。我们通过证明速率 $\mathcal{O}((WL)^{-2sd})$ 在 Sobolev 嵌入条件下确实成立来推广这些结果。众所周知，这个速率在对数因子之前是最优的。我们证明中的关键工具是使用具有不同宽度和深度的深度 ReLU 神经网络对稀疏向量进行一种新的编码，这可能具有独立的兴趣。]]></description>
      <guid>https://arxiv.org/abs/2409.00901</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EnsLoss：用于防止分类过度拟合的随机校准损失集成</title>
      <link>https://arxiv.org/abs/2409.00908</link>
      <description><![CDATA[arXiv:2409.00908v1 公告类型：新
摘要：具有计算上可行的替代损失的经验风险最小化 (ERM) 是一种广泛接受的分类方法。值得注意的是，损失函数的凸性和校准 (CC) 属性确保 ERM 在最大化准确度方面的一致性，从而为替代损失提供了广泛的选择。在本文中，我们提出了一种新颖的集成方法，即 \textsc{EnsLoss}，它扩展了集成学习概念以在 ERM 框架内组合损失函数。我们方法的一个关键特征是考虑保留组合损失的“合法性”，即确保 CC 属性。具体而言，我们首先将损失的 CC 条件转换为损失导数，从而绕过对显式损失函数的需求并直接生成校准的损失导数。因此，受 Dropout 的启发，\textsc{EnsLoss} 通过一次双随机梯度下降（即随机批量样本和随机校准损失导数）训练过程实现了损失集成。我们从理论上建立了我们方法的统计一致性，并提供了对其优势的见解。通过在 14 个 OpenML 表格数据集和 46 个图像数据集上进行各种深度学习架构的实验，证明了 \textsc{EnsLoss} 与固定损失方法相比的数值有效性。Python 存储库和源代码可在 \textsc{GitHub} 的 \url{https://github.com/statmlben/rankseg} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.00908</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Bootstrap SGD：算法稳定性和稳健性</title>
      <link>https://arxiv.org/abs/2409.01074</link>
      <description><![CDATA[arXiv:2409.01074v1 公告类型：新
摘要：本文从算法稳定性和统计稳健性的角度研究了一些使用经验引导方法进行随机梯度下降 (SGD) 以最小化可分离希尔伯特空间上的经验风险的方法。前两种方法基于平均值，并从理论的角度进行研究。基于算法稳定性对类型 1 和类型 2 的引导 SGD 进行了泛化分析。提出了另一种类型的引导 SGD，以证明可以使用引导 SGD 构建中值曲线的纯分布无点置信区间。]]></description>
      <guid>https://arxiv.org/abs/2409.01074</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>符号扰动和法的样本复杂度</title>
      <link>https://arxiv.org/abs/2409.01243</link>
      <description><![CDATA[arXiv:2409.01243v1 公告类型：新
摘要：我们研究了符号扰动和 (SPS) 方法的样本复杂度，该方法在温和的统计假设（例如独立和对称噪声项）下为真实系统参数构建精确的非渐近置信区域。SPS 的标准版本处理线性回归问题，但是，它可以推广到随机线性（动态）系统，甚至具有闭环设置，以及非线性和非参数问题。尽管该方法的强一致性得到了严格证明，但到目前为止，仅针对标量线性回归问题分析了该算法的样本复杂度。在本文中，我们研究了一般线性回归问题的 SPS 样本复杂度。我们为有限样本大小的 SPS 置信区域直径建立了高概率上限，并表明 SPS 区域以与经典渐近置信椭圆体相同的最佳速率收缩。最后，通过实验研究了 SPS 置信区域的理论界限和经验大小之间的差异。]]></description>
      <guid>https://arxiv.org/abs/2409.01243</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于贝叶斯推理的 Stein 传输</title>
      <link>https://arxiv.org/abs/2409.01464</link>
      <description><![CDATA[arXiv:2409.01464v1 公告类型：新
摘要：我们引入了 $\textit{Stein transport}$，这是一种用于贝叶斯推理的新方法，旨在有效地推动一组粒子沿着预定义的缓和概率分布曲线移动。驱动矢量场是从再生核希尔伯特空间中选择的，可以通过合适的核岭回归公式或 Stein 几何中的无穷小最优传输图导出。Stein 传输的更新方程类似于 Stein 变分梯度下降 (SVGD) 的更新方程，但引入了随时间变化的得分函数以及附加到粒子上的特定权重。虽然 SVGD 依赖于长时间极限内的收敛，但 Stein 传输在有限时间 $t=1$ 时达到其后验近似。通过研究平均场极限，我们讨论了正则化和有限粒子效应引起的误差，并将 Stein 传输与生死动力学和 Fisher-Rao 梯度流联系起来。在一系列实验中，我们表明，与 SVGD 相比，Stein 传输不仅通常能够以显著减少的计算预算达到更准确的后验近似，而且还能够有效缓解 SVGD 中常见的方差崩溃现象。]]></description>
      <guid>https://arxiv.org/abs/2409.01464</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>持久同源性与神经网络的混合用于时间序列预测：海浪高度的案例研究</title>
      <link>https://arxiv.org/abs/2409.01519</link>
      <description><![CDATA[arXiv:2409.01519v1 公告类型：新
摘要：时间序列预测是各个领域的一个活跃研究领域，经常受到短期和长期因素波动影响的挑战。在本研究中，我们介绍了一种特征工程方法，可以增强神经网络模型的预测性能。具体来说，我们利用计算拓扑技术从输入数据中得出有价值的拓扑特征，从而提高模型的预测准确性。我们的重点是预测波高，利用基于前馈神经网络 (FNN)、循环神经网络 (RNN)、长短期记忆网络 (LSTM) 和带门控循环单元 (GRU) 的 RNN 中的拓扑特征的模型。对于提前时间预测，FNN、RNN、LSTM 和 GRU 模型的 $R^2$ 得分显著提高。此外，这些模型还显示出最大误差和均方误差的显著降低。]]></description>
      <guid>https://arxiv.org/abs/2409.01519</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>平滑稳健相位检索</title>
      <link>https://arxiv.org/abs/2409.01570</link>
      <description><![CDATA[arXiv:2409.01570v1 公告类型：新
摘要：噪声条件下的相位恢复问题旨在从一组具有不频繁但任意损坏的二次测量中恢复感兴趣的信号向量，它在许多科学应用中发挥着重要作用。然而，基于$\ell_1$损失的非凸稳健相位恢复的基本几何结构在很大程度上是未知的，即使在理想的无噪声设置下也无法研究虚假的局部解，其内在的非平滑性质也会影响优化算法的效率。本文介绍了基于卷积型平滑损失函数系列的平滑稳健相位恢复（SRPR）。从理论上讲，我们证明了 SRPR 具有高概率的良性几何结构：（1）在无噪声情况下，SRPR 没有虚假局部解，目标信号是全局解；（2）在偶尔但任意的损坏情况下，我们描述了 SRPR 的驻点并证明了其良性景观，这是文献中第一次对损坏的相位恢复进行景观分析。此外，我们证明了在无噪声情况下求解 SRPR 的梯度下降的局部线性收敛速度。在模拟数据集和图像恢复上进行了实验，以证明 SRPR 的数值性能。]]></description>
      <guid>https://arxiv.org/abs/2409.01570</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>线图的图元</title>
      <link>https://arxiv.org/abs/2409.01656</link>
      <description><![CDATA[arXiv:2409.01656v1 公告类型：新
摘要：图元是收敛图序列的极限。密集图的图元很有用，因为它们可以充当蓝图并生成具有相似属性的任意大小的图。但对于稀疏图而言并非如此。稀疏图收敛到零图元，使生成的图为空或无边。因此，经典的图元定义不适用于稀疏图。已经提出了几种方法来克服这一限制并更深入地理解稀疏图。然而，稀疏图的脆弱性使得这些方法在数学上很复杂。在本文中，我们展示了一种可以阐明稀疏图的某个子集的简单方法。该方法涉及将原始图映射到其线图。当原始图中的边共享一个顶点时，线图将边映射到顶点并连接边。我们表明，满足特定属性（我们称之为平方度属性）的图是稀疏的，但会产生密集线图。具体而言，星形图满足平方度属性，从而产生密集线图和线图的非零图元。类似地，超线性优先连接图几乎肯定会产生密集线图。相比之下，包括 Erdos-Renyi 图在内的密集图使线图变得稀疏，从而产生零图元。]]></description>
      <guid>https://arxiv.org/abs/2409.01656</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于高维分位数预测的稀疏 PAC-Bayesian 方法</title>
      <link>https://arxiv.org/abs/2409.01687</link>
      <description><![CDATA[arXiv:2409.01687v1 公告类型：新
摘要：分位数回归是一种用于估计条件分位数的稳健方法，在计量经济学、统计学和机器学习等领域取得了重大进展。在高维设置中，协变量的数量超过样本大小，已经开发出像套索这样的惩罚方法来应对稀疏性挑战。贝叶斯方法最初通过不对称拉普拉斯似然与分位数回归相关，也得到了发展，尽管后验方差问题导致了包括伪/分数似然在内的新方法。本文提出了一种用于高维分位数预测的新型概率机器学习方法。它使用伪贝叶斯框架，具有缩放的 Student-t 先验和朗之万蒙特卡罗，以实现高效计算。该方法通过 PAC-Bayes 界限证明了强有力的理论保证，建立了非渐近预言不等式，显示了极小最大最优预测误差和对未知稀疏性的适应性。它的有效性已通过模拟和真实数据得到验证，其性能与成熟的频率学派和贝叶斯技术相比具有竞争力。]]></description>
      <guid>https://arxiv.org/abs/2409.01687</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有病例对照数据和外部摘要信息的深度非参数逻辑模型</title>
      <link>https://arxiv.org/abs/2409.01829</link>
      <description><![CDATA[arXiv:2409.01829v1 公告类型：新
摘要：病例对照抽样设计是缓解二元数据中观察到的不平衡结构的关键策略。我们考虑使用病例对照数据并辅以外部摘要信息来估计非参数逻辑模型。外部摘要信息的结合确保了模型的可识别性。我们提出了一个两步估计程序。在第一步中，利用外部信息来估计边际病例比例。在第二步中，估计的比例用于构建加权目标函数以进行参数训练。采用深度神经网络架构进行函数逼近。我们进一步推导出所提估计量的非渐近误差界限。随后获得了收敛速度，并显示达到了非参数回归估计的最佳速度。进行了模拟研究以评估所提方法的理论发现。分析了一个实际数据示例以进行说明。]]></description>
      <guid>https://arxiv.org/abs/2409.01829</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越无约束特征：具有一般数据的浅层神经网络的神经塌缩</title>
      <link>https://arxiv.org/abs/2409.01832</link>
      <description><![CDATA[arXiv:2409.01832v1 公告类型：新
摘要：神经崩溃（NC）是深度神经网络（DNN）训练末期（TPT）出现的一种现象。同一类数据的特征会崩溃到各自的样本均值，样本均值呈现单纯形等角紧框架（ETF）。过去几年，大量研究致力于解释神经崩溃发生的原因以及它如何影响泛化。由于 DNN 的分析难度很大，大多数研究主要集中在无约束特征模型（UFM）上。虽然 UFM 在一定程度上解释了神经崩溃，但它无法提供网络架构和数据集如何影响神经崩溃的完整图景。在这项工作中，我们专注于浅层 ReLU 神经网络，并试图了解训练数据集的宽度、深度、数据维度和统计属性如何影响神经崩溃。我们对两层或三层神经网络的神经崩溃发生时间进行了完整的描述。对于两层 ReLU 神经网络，正则化经验风险函数的全局最小值呈现 NC 配置的充分条件取决于数据维度、样本大小和数据中的信噪比，而不是网络宽度。对于三层神经网络，我们表明只要第一层足够宽，就会发生 NC。关于 NC 与泛化之间的联系，我们表明泛化在很大程度上取决于数据的 SNR（信噪比）：即使发生 NC，如果数据中的 SNR 太低，泛化仍然可能很差。我们的结果通过表征浅层非线性网络下 N C 的出现并展示它如何依赖于数据属性和网络架构，大大扩展了 UFM 下 N C 的最新理论分析。]]></description>
      <guid>https://arxiv.org/abs/2409.01832</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不确定：未知噪音水平 Stein 无偏风险评估器</title>
      <link>https://arxiv.org/abs/2409.01985</link>
      <description><![CDATA[arXiv:2409.01985v1 公告类型：新
摘要：最近，已经提出了许多用于图像重建的自监督学习方法，这些方法可以仅从噪声数据中学习，而无需使用真实值参考。大多数现有方法集中在两类：i）Noise2Self 和类似的交叉验证方法，这些方法需要非常温和的噪声分布知识，ii）Stein 的无偏风险估计器 (SURE) 和类似方法，假设完全了解分布。与监督学习相比，第一类方法通常不是最优的，而第二类方法通常不切实际，因为噪声水平在实际应用中通常是未知的。在本文中，我们提供了一个描述这种表达力-鲁棒性权衡的理论框架，并提出了一种基于 SURE 的新方法，但与标准 SURE 不同，它不需要有关噪声水平的知识。通过一系列实验，我们表明，所提出的估计器在各种成像逆问题上优于其他现有的自监督方法。]]></description>
      <guid>https://arxiv.org/abs/2409.01985</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习进行电离层闪烁预测</title>
      <link>https://arxiv.org/abs/2409.00118</link>
      <description><![CDATA[arXiv:2409.00118v1 公告类型：交叉 
摘要：本研究探讨了如何使用全球导航卫星系统 (GNSS) 闪烁监测接收器的历史数据来预测振幅闪烁的严重程度，振幅闪烁是一种现象，电离层中的电子密度不规则性导致 GNSS 信号功率波动。这些波动可以使用 S4 指数来测量，但实时数据并不总是可用的。该研究的重点是开发一种机器学习 (ML) 模型，该模型可以预测振幅闪烁的强度，并根据各种时间和空间相关因素将其分为低、中或高严重程度级别。在测试的六种不同的 ML 模型中，XGBoost 模型是最有效的，在使用平衡数据集训练时表现出显着的 77% 的预测准确率。这项工作强调了机器学习通过准确预测振幅闪烁严重程度来提高 GNSS 信号和导航系统的可靠性和性能的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.00118</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>