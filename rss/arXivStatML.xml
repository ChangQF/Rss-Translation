<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Wed, 17 Jan 2024 06:18:02 GMT</lastBuildDate>
    <item>
      <title>具有覆盖保证的高斯过程替代评估的共形方法。 （arXiv：2401.07733v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.07733</link>
      <description><![CDATA[高斯过程（GP）是一种广泛使用的贝叶斯机器学习方法
构建计算机不确定性量化的替代模型
工业应用中的模拟代码。它提供了一个平均预测器
以及后验预测方差的估计，后者用于
产生贝叶斯可信区间。解释这些间隔依赖于
仿真模型的高斯性以及规范
先验并不总是合适的。我们建议解决这个问题
借助共形预测。在目前的工作中，一种方法
提出通过加权构建自适应交叉共形预测区间
GP 后验标准差的不合格分数。这
由此产生的共形预测区间表现出类似于
贝叶斯可信度设置并显示出与
代理模型局部近似误差，同时不受底层影响
模型假设并具有频率覆盖保证。这些估计量
因此可以用于评估 GP 替代模型的质量，并且可以
协助决策者针对具体情况选择最佳先验方案
GP的应用。该方法的性能通过
基于各种参考数据库的数值示例面板。此外，
该方法的潜在适用性在以下背景下得到证明
评估昂贵的堵塞模拟器的替代建模
核反应堆蒸汽发生器中的现象。
]]></description>
      <guid>http://arxiv.org/abs/2401.07733</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:02 GMT</pubDate>
    </item>
    <item>
      <title>具有任意循环数据采样的随机优化。 （arXiv：2401.07694v1 [数学.OC]）</title>
      <link>http://arxiv.org/abs/2401.07694</link>
      <description><![CDATA[为了获得随机的最优一阶收敛保证
优化时，需要使用循环数据采样算法
以足够的频率对每个数据点进行采样。最常用的数据
采样算法（例如 i.i.d.、MCMC、随机重新洗牌）确实是
在温和的假设下经常出现。在这项工作中，我们表明对于特定的
一类随机优化算法，我们不需要任何其他属性
（例如，独立性、指数混合和重新洗牌）比递归
数据采样算法保证一阶最优率
收敛。即，使用增量最小化的正则化版本
代理优化（MISO），我们证明对于非凸且可能
非光滑目标函数，预期最优性差距收敛于
一般循环采样方案下的最优速率 $O(n^{-1/2})$。
此外，隐含常数明确取决于“速度”
复发率”，通过访问给定数据的预期时间来衡量
点的平均值（“目标时间”）或最大值（“命中时间”）
当前位置。我们从理论上和经验上证明了收敛性
可以通过选择覆盖数据集的采样算法来加速
最有效。我们讨论我们的总体框架的应用
分散优化和分布式非负矩阵分解。
]]></description>
      <guid>http://arxiv.org/abs/2401.07694</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>二元和计数数据的高效非参数张量分解。 （arXiv：2401.07711v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.07711</link>
      <description><![CDATA[在许多应用中，观察并观察二元反应或事件计数
存储在高阶张量中。张量分解（TD）作为
处理此类高维和稀疏数据的强大工具。然而，许多
传统的TD是基于高斯分布显式或隐式设计的
分布，不适用于离散数据。此外，大多数 TD 依赖于
预定义的多线性结构，例如 CP 和 Tucker 格式。所以，
它们可能不足以有效地处理复杂的现实世界数据集。到
为了解决这些问题，我们提出了 ENTED，一个 \underline{E}fficient
\underline{N}on 参数 \underline{TE}nsor \underline{D} 分解
二进制和计数张量。具体来说，我们首先采用非参数
高斯过程（GP）取代传统的多线性结构。接下来，我们
利用 \pg 增强提供了一个统一的框架来建立
二元分布和计数分布的共轭模型。最后，要解决
GP 的计算问题，我们通过结合稀疏增强模型
归纳点的正交变分推理，提供了更多
GP 内的有效协方差近似和随机自然梯度
非参数模型的更新。我们在几个现实世界中评估我们的模型
张量完成任务，考虑二进制和计数数据集。结果
体现了所提出的更好的性能和计算优势
模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.07711</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>RedEx：通过凸优化超越固定表示方法。 （arXiv：2401.07606v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.07606</link>
      <description><![CDATA[优化神经网络是一项艰巨的任务，目前还没有做好
明白了。另一方面，固定的表示方法，例如核和
随机特征具有可证明的优化保证，但性能较差
由于他们天生无法学习表征。在本文中，我们
旨在通过提出一种名为 RedEx 的新颖架构来弥补这一差距
（Reduced Expander Extractor）与神经网络一样具有表现力，并且可以
也可以通过半定凸程序以分层方式进行训练
约束和优化保证。我们还证明 RedEx
超越了固定的表示方法，从某种意义上说，它可以有效地
学习固定表示方法无法学习的一系列目标函数。
]]></description>
      <guid>http://arxiv.org/abs/2401.07606</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机的成本敏感特征选择。 （arXiv：2401.07627v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.07627</link>
      <description><![CDATA[特征选择是数据科学任务中的一个关键过程，例如
分类，因为它识别了相关变量，从而使得
分类程序更容易解释，测量成本更便宜
通过减少噪音和数据过度拟合来提高效率。的相关性
分类过程中的特征与以下事实相关：
误分类成本通常是不对称的，因为误报和
假阴性案例可能会产生截然不同的后果。然而，
现成的特征选择程序很少考虑这样的情况
错误的成本敏感性。

在本文中，我们提出了一种基于数学优化的特征选择
嵌入最流行的分类程序之一的程序，
即支持向量机，适应不对称错误分类
成本。关键思想是用以下方式取代传统的利润最大化
最小化所选特征的数量，但对特征施加上限
误报率和漏报率。该问题被写成一个整数线性
问题加上支持向量机的二次凸问题
线性和径向内核。

报告的数值经验证明了所提出的方法的有用性
特征选择过程。事实上，我们对基准数据集的结果表明
特征数量大幅减少，同时
实现了假阳性率和假阴性率之间的期望权衡。
]]></description>
      <guid>http://arxiv.org/abs/2401.07627</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>利用先验知识发现具有未观察到的变量的因果加性模型及其在时间序列数据中的应用。 （arXiv：2401.07231v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.07231</link>
      <description><![CDATA[本文提出了两种不可观测因果加性模型的方法
变量（CAM-UV）。 CAM-UV 假设因果函数采用以下形式
广义加性模型和存在潜在的混杂因素。首先，我们
提出一种利用先验知识进行有效因果发现的方法。
然后，我们提出了该方法的扩展，用于及时推断因果关系
系列数据。原始的 CAM-UV 算法不同于其他现有的因果算法
函数模型，因为它不寻求观察到的结果之间的因果顺序
变量，而是旨在确定每个观察到的变量的原因。
因此，本文第一个提出的方法利用先验知识，
例如理解某些变量不能成为特定的原因
其他的。此外，通过结合先于原因的先验知识
它们的影响及时，我们将第一种算法扩展到第二种方法
时间序列数据中的因果发现。我们验证了第一个提出的方法
使用模拟数据来证明因果发现的准确性
随着更多先验知识的积累而增加。此外，我们还测试了
通过与现有时间序列因果比较提出的第二种方法
发现方法，使用模拟数据和现实世界数据。
]]></description>
      <guid>http://arxiv.org/abs/2401.07231</guid>
      <pubDate>Wed, 17 Jan 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>广义低阶矩阵强盗问题的有效框架。 （arXiv：2401.07298v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.07298</link>
      <description><![CDATA[在随机上下文低秩矩阵强盗问题中，预期
动作的奖励由动作特征之间的内积给出
矩阵和一些固定但最初未知的 $d_1$ by $d_2$ 矩阵 $\Theta^*$
等级为 $r \ll \{d_1, d_2\}$，并且代理按顺序采取基于
根据过去的经验来最大化累积奖励。在本文中，我们研究
广义的低秩矩阵强盗问题，最近被提出
\cite{lu2021low} 在广义线性模型（GLM）下提出
框架。克服计算的不可行性和理论的限制
针对这个问题的现有算法，我们首先提出了G-ESTT框架
通过使用 Stein 的方法修改了 \cite{jun2019bilinear} 的想法
子空间估计，然后通过以下方式利用估计的子空间
正则化思想。此外，我们显着提高了效率
G-ESTT 通过在估计子空间上使用新颖的排除思想来代替，并且
提出G-ESTS框架。我们还表明 G-ESTT 可以实现
$\tilde{O}(\sqrt{(d_1+d_2)MrT})$ 的遗憾界限，而 G-ESTS 可以实现
$\tilde{O}(\sqrt{(d_1+d_2)^{3/2}Mr^{3/2}T})$轻度后悔范围
假设达到对数项，其中 $M$ 是某个问题相关值。
在我们的问题设置中，合理假设 $M = O((d_1+d_2)^2)$，
G-ESTT的遗憾与当前的最佳遗憾一致
$\tilde{O}((d_1+d_2)^{3/2} \sqrt{rT}/D_{rr})$~\citep{lu2021low} ($D_{rr}$ 将
稍后定义）。为了完整起见，我们进行实验来说明
我们提出的算法，尤其是 G-ESTS，在计算上也是易于处理的
并始终优于其他最先进的（广义）线性矩阵
基于一系列模拟的老虎机方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.07298</guid>
      <pubDate>Wed, 17 Jan 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>深度学习统计理论综述：近似、训练动力学和生成模型。 （arXiv：2401.07187v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.07187</link>
      <description><![CDATA[在本文中，我们回顾了神经统计理论的文献
从三个角度看网络。第一部分 超额风险的结果
在回归的非参数框架中回顾了神经网络
或分类。这些结果依赖于神经网络的显式构建
网络，导致过度风险的快速收敛速度，在这些工具中
采用近似理论。通过这些结构，宽度
网络的深度和深度可以用样本大小、数据来表示
维度和函数平滑度。尽管如此，他们的基本分析仅
适用于深度非凸景观中的全局最小化
神经网络。这促使我们回顾神经网络的训练动态
第二部分的网络。具体来说，我们回顾了试图
回答“通过基于梯度的方法训练的神经网络如何找到
可以很好地概括未见过的数据的解决方案。”特别是，两个
回顾了著名的范式：神经正切核（NTK）范式，
和平均场（MF）范式。在最后一部分，我们回顾了最新的
生成模型的理论进展，包括生成对抗
大型网络 (GAN)、扩散模型和情境学习 (ICL)
语言模型（LLM）。前两个模型被认为是主要支柱
现代生成式人工智能时代的代表，而 ICL 则是法学硕士在以下方面的强大能力：
从上下文中的几个例子中学习。最后，我们通过以下方式结束本文
为深度学习理论提出了几个有希望的方向。
]]></description>
      <guid>http://arxiv.org/abs/2401.07187</guid>
      <pubDate>Wed, 17 Jan 2024 06:17:58 GMT</pubDate>
    </item>
    <item>
      <title>具有倾斜投影的概率降维向量自回归建模。 （arXiv：2401.07206v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.07206</link>
      <description><![CDATA[在本文中，我们提出了一种概率降维向量
自回归 (PredVAR) 模型可从中提取低维动态
高维噪声数据。该模型利用斜投影
将测量空间划分为一个子空间，该子空间容纳
降维动力学和互补的静态子空间。一个最优的
倾斜分解是为了获得最佳可预测性而推导的
预测误差协方差。在此基础上，我们开发了迭代 PredVAR
使用最大似然和期望最大化 (EM) 的算法
框架。该算法交替更新潜在的估计
动力学和最佳倾斜投影，产生动态潜变量
排序的可预测性和一致的显式潜在 VAR 模型
与外部投影模型。卓越的性能和效率
使用来自合成洛伦兹的数据集演示了所提出的方法
伊士曼化学公司的系统和工业流程。
]]></description>
      <guid>http://arxiv.org/abs/2401.07206</guid>
      <pubDate>Wed, 17 Jan 2024 06:17:58 GMT</pubDate>
    </item>
    <item>
      <title>赫布从第一原理中学习。 (arXiv:2401.07110v1 [cond-mat.dis-nn])</title>
      <link>http://arxiv.org/abs/2401.07110</link>
      <description><![CDATA[最近，神经网络Hopfield模型的原始存储处方
网络——以及其密集的概括——已经变成了一个
真正的赫布学习规则通过假设其哈密顿量的表达
对于监督和非监督协议。在这些笔记中，首先，我们
依靠最大熵极值化获得这些显式表达式
就像杰恩斯那样。除了提供这些食谱的正式推导之外
赫布学习，这种构造也凸显了拉格朗日如何约束
在熵极端化力网络的神经相关性结果中：
这些试图模仿隐藏在提供的数据集中的经验对应物
网络进行训练，网络越密集，时间越长
它能够捕获的相关性。接下来我们证明，在大数据中
限制，无论老师在场（或缺乏），不仅仅是这些
赫布学习规则收敛于原始存储处方
霍普菲尔德模型以及它们相关的自由能（因此，统计
Amit、Gutfreund 和 Sompolinsky 提供的机械图片完全
恢复）。作为副业，我们展示了标准成本之间的数学等价性
函数（哈密顿函数），在统计力学术语中首选，以及
二次损失函数，机器学习术语中的首选。备注
指数 Hopfield 模型（作为具有发散的密集网络的极限）
密度）和半监督协议也提供了。
]]></description>
      <guid>http://arxiv.org/abs/2401.07110</guid>
      <pubDate>Wed, 17 Jan 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>论群体公平与个体公平的（内）相容性。 （arXiv：2401.07174v1 [数学.ST]）</title>
      <link>http://arxiv.org/abs/2401.07174</link>
      <description><![CDATA[我们研究最佳统计奇偶解决方案之间的兼容性
以及个人的公平性。虽然个人公平寻求对待类似的
个体相似，最佳统计奇偶性旨在提供相似的
对待在各自领域内具有相对相似性的个体
敏感群体。这两种公平观点虽然从某种角度来说都是可取的
公平的观点，在应用中经常会发生冲突。我们的目标是
这项工作就是分析这种冲突的存在及其潜力
解决方案。特别是，我们为
最佳（后处理）统计奇偶性 $L^2$ 之间的兼容性
学习和 ($K$-Lipschitz 或 $(\epsilon,\delta)$) 个体公平性
要求。此外，当两者发生冲突时，我们
首先将前者放松到帕累托前沿（或等效的最优
$L^2$ 误差和统计差异之间的权衡），然后分析
边界与个人公平要求之间的兼容性。
我们的分析确定了沿着帕累托边界的区域满足
个人的公平性要求。 （最后，我们提供个人公平性
保证训练模型的组成和最优
后处理步骤，以便可以确定兼容性
后处理模型。）这为从业者提供了一种有价值的方法
达到统计奇偶性的帕累托最优，同时遵循
个人公平性的制约。
]]></description>
      <guid>http://arxiv.org/abs/2401.07174</guid>
      <pubDate>Wed, 17 Jan 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>使用结构因果模型对潜在选择进行建模。 （arXiv：2401.06925v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.06925</link>
      <description><![CDATA[选择偏差在现实世界的数据中普遍存在，并可能导致误导
如果处理不当，后果不堪设想。我们引入一个条件操作
结构因果模型 (SCM) 用于对因果关系中的潜在选择进行建模
看法。我们表明，调节操作将 SCM 转变为
SCM 中存在显式潜在选择机制，无需此类机制
选择机制，部分编码了因果语义
根据原始SCM选择子群体。此外，我们表明
这种调节操作保留了简单性、非循环性和线性性
SCM 的数量，并与边缘化通勤。得益于这些属性，
结合边缘化和干预，调节操作
为在因果关系中执行因果推理任务提供了一个有价值的工具
潜在细节已被抽象掉的模型。我们通过以下方式演示
示例如何将因果推理的经典结果概括为包括
选择偏差以及调节操作如何帮助建模
现实世界的问题。
]]></description>
      <guid>http://arxiv.org/abs/2401.06925</guid>
      <pubDate>Wed, 17 Jan 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>一种用于潜在因子分析的 ADRC 随机梯度下降算法。 （arXiv：2401.07012v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.07012</link>
      <description><![CDATA[高维不完全（HDI）矩阵包含许多复杂的
众多节点之间的交互。基于随机梯度下降 (SGD)
潜在因素分析（LFA）模型在提取信息方面非常有效
来自 HDI 矩阵的有价值的信息。然而，这样的模型通常
由于标准SGD算法遇到收敛速度慢的问题
只考虑当前的学习误差来计算随机梯度
不考虑学习错误的历史和未来状态。到
针对这一关键问题，本文创新性地提出了
ADRC 合并的 SGD (ADS) 算法通过改进实例学习误差
通过考虑历史和未来状态，遵循
自抗扰控制器 (ADRC) 控制器。有了它，进一步实现了基于ADS的LFA模型，以实现快速
以及 HDI 矩阵上的准确潜在因素分析。实证研究二
HDI 数据集表明所提出的模型优于
在计算效率和准确性方面最先进的 LFA 模型
用于预测 HDI 矩阵的缺失数据。
]]></description>
      <guid>http://arxiv.org/abs/2401.07012</guid>
      <pubDate>Wed, 17 Jan 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 DAG 进行深度学习。 （arXiv：2401.06864v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.06864</link>
      <description><![CDATA[社会科学理论经常假设一组事物之间存在因果关系
变量或事件。尽管有向无环图（DAG）越来越多
用于代表这些理论，但它们的全部潜力尚未得到充分发挥
并在实践中实现。作为非参数因果模型，DAG 不需要
关于假设关系的函数形式的假设。
然而，为了简化实证评估的任务，研究人员倾向于
无论如何都要援引这样的假设，即使它们通常是任意的并且确实
不反映任何理论内容或先验知识。此外，功能性
每当无法准确捕捉时，形式假设就会产生偏见
所研究的因果系统的复杂性。在这篇文章中，我们
引入因果图形标准化流（cGNF），这是一种新颖的方法
利用深度神经网络进行因果推理以实证评估
以 DAG 表示的理论。与传统方法不同，cGNF 建模
根据分析师提供的 DAG 进行数据的完全联合分布，
不依赖于对功能形式的严格假设。这样，
该方法允许对任何因果关系进行灵活的半参数估计
可以从 DAG 中识别的估计值，包括总效应，
条件效应、直接和间接效应以及路径特定效应。我们
通过对 Blau 和 Duncan (1967) 模型的重新分析来说明该方法
地位获得和 Zhou（2019）的条件与受控模型
流动性。为了促进采用，我们提供开源软件
一系列用于实现 cGNF 的在线教程。文章的结尾是
讨论当前的局限性和未来发展的方向。
]]></description>
      <guid>http://arxiv.org/abs/2401.06864</guid>
      <pubDate>Wed, 17 Jan 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>使用深度强化学习的 Open RAN LSTM 流量预测和切片管理。 （arXiv：2401.06922v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.06922</link>
      <description><![CDATA[随着自动驾驶、智慧城市等新兴应用
智能工厂、网络切片已成为5G的重要组成部分
超越网络作为迎合服务感知网络的一种手段。然而，
管理不同的网络切片，同时保持服务质量 (QoS)
是动态环境中的挑战。为了解决这个问题，本文
利用 ORAN 中分布式单元 (DU) 的异构体验
系统并引入了一种使用分布式 ORAN 切片 xApp 的新颖方法
深度强化学习（DDRL）。此外，为了增强
RL 代理的决策性能，一个基于长的预测 rApp
短期记忆（LSTM）被纳入以提供附加信息
xApp 的动态环境。仿真结果表明显着
网络性能的改进，特别是减少服务质量违规。
这强调了使用预测 rApp 和分布式的重要性
参与者的信息共同作为动态 xApp 的一部分。
]]></description>
      <guid>http://arxiv.org/abs/2401.06922</guid>
      <pubDate>Wed, 17 Jan 2024 06:17:55 GMT</pubDate>
    </item>
    </channel>
</rss>