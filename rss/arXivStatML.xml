<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Fri, 28 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基本的安全能力能力在微调大语模型中取舍</title>
      <link>https://arxiv.org/abs/2503.20807</link>
      <description><![CDATA[ARXIV：2503.20807V1公告类型：新 
摘要：某些特定于任务的数据集上的微型语言模型（LLMS）一直是LLM的主要用途。但是，从经验上观察到，这种增强能力的方法不可避免地会损害安全性，这一现象也称为LLM微调中的安全能力权衡。本文提出了一个理论框架，用于了解两个主要的安全性LLM微调策略中安全与能力之间的相互作用，从而提供了有关数据相似性，上下文重叠和对齐损失格局影响的新见解。我们的理论结果表征了LLM微调中安全能力权衡的基本限制，这些限制也通过数值实验验证。]]></description>
      <guid>https://arxiv.org/abs/2503.20807</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于内核的生成模型</title>
      <link>https://arxiv.org/abs/2503.20825</link>
      <description><![CDATA[ARXIV：2503.20825V1公告类型：新 
摘要：我们提出了一个新型的两阶段生成模型的框架，称为偏见基于内核的生成模型（DKGM），并具有来自内核密度估计（KDE）和随机近似的见解。在DKGM的第一阶段，我们使用KDE绕过估算数据密度的障碍，而不会失去太多的图像质量。 KDE的一个特征是过度厚度，这使生成的图像模糊。因此，在第二阶段，我们制定了减少图像的模糊性作为统计偏见问题的过程，并开发出一种新型的迭代算法以提高图像质量，这是灵感来自随机近似的启发。广泛的实验表明，CIFAR10上DKGM的图像质量与最新模型（例如扩散模型和GAN模型）相媲美。 DKGM在Celeba 128x128和Lsun（Church）128x128上的表现也具有竞争力。我们进行额外的实验，以利用KDE中的带宽如何影响dkgm的样本多样性和歧义效应。还讨论了DKGM和基于得分的模型之间的连接。]]></description>
      <guid>https://arxiv.org/abs/2503.20825</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>平方家庭：超越常规概率模型</title>
      <link>https://arxiv.org/abs/2503.21128</link>
      <description><![CDATA[ARXIV：2503.21128V1公告类型：新 
摘要：我们介绍了平方家庭，这是通过平方统计量的线性转换获得的概率密度的家族。平方家庭是奇异的，但是它们的奇异性可以很容易地处理，以形成常规模型。处理奇点之后，平方家庭具有许多方便的特性。他们的Fisher信息是由Bregman发电机引起的Hessian度量标准的共形转换。 Bregman发电机是标准化常数，并且对家庭产生统计差异。标准化常数允许有用的参数综合分解，这意味着与指数族不同，只有一个独立于参数独立的积分才能计算出该家族中所有归一化常数的积分。最后，平方族内核是唯一需要计算用于Fisher信息，统计差异和正常化常数的不可或缺的组成部分。然后，我们描述了平方家庭在更广泛的$ g $ families中如何特别的，这是通过将足够规则的功能$ g $应用于统计量的线性转换而获得的。在删除了特殊的奇异点之后，正均匀的家庭和指数家庭是唯一的$ g $ families，Fisher信息是Hessian Metric的共形转换，而发电机仅通过归一化常数依赖于参数。与指数式的家庭不同，均阶单位家庭也接受参数综合分解。我们研究平方族的参数估计和密度估计，在良好的且误指定的设置中。我们使用通用的近似属性表明，平方家庭可以以$ \ Mathcal {o}（n^{ -  1/2}）+c n^{ -  1/4} $的速度学习足够良好的目标密度，其中$ n $是dataPoints的数量，$ n $是$ n $是参数的数量，$ c $ is cum is soments and cum is somys somand is somys somys。]]></description>
      <guid>https://arxiv.org/abs/2503.21128</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepRV：用于加速疾病映射的预先训练的空间先验</title>
      <link>https://arxiv.org/abs/2503.21473</link>
      <description><![CDATA[ARXIV：2503.21473V1公告类型：新 
摘要：最近引入了先前编码的深层生成模型（例如PriorVae，$ \ pi $ vae和Priorcvae）已成为通过模拟高斯流程（例如高斯流程（GPS））的复杂随机过程的强大工具，用于可扩展的贝叶斯推断。但是，这些方法在很大程度上仍然是一种概念验证，并且对于从业者来说是无法访问的。我们提出了DeePRV，这是一种轻巧的，仅解码器的方法，可加速培训，并增强现实世界中的适用性，与当前的基于VAE的先前编码方法相比。利用概率编程框架（例如Numpyro）进行推理，DEEPRV实现了显着的加速，同时也提高了参数推理的质量，与完整的MCMC采样匹配。我们使用模拟数据，50岁以下的个体的性别癌症死亡率以及津巴布韦的HIV患病率展示了其在英国的过程仿真和空间分析中的有效性。为了弥合理论与实践之间的差距，我们提供了一种用户友好的API，从而实现了可扩展有效的贝叶斯推断。]]></description>
      <guid>https://arxiv.org/abs/2503.21473</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于约束的因果发现，具有分层的背景知识和单个或重叠数据集中的潜在变量</title>
      <link>https://arxiv.org/abs/2503.21526</link>
      <description><![CDATA[ARXIV：2503.21526V1公告类型：新 
摘要：在本文中，我们考虑在基于约束的因果发现中使用分层的背景知识。我们的重点是设置放松因果充足性，即允许可能出现的潜在变量，因为在多个重叠数据集的情况下，根本无法衡量相关信息，或者无法共同测量相关信息。我们首先对“分层FCI”（TFCI）算法的特性提出了新的见解。在此基础上，我们介绍了包含分层背景知识的iod（集成重叠数据集）算法的新扩展名，即“分层iod”（tiod）算法。我们表明，在完全使用分层背景知识的情况下，TFCI和TIOD是合理的，而TIOD和TFCI的简单版本则是合理的且完整的。我们进一步表明，通常可以期望与iod算法相比，TIOD算法甚至超出了马尔可夫当量类别的明显限制。我们为效率和信息性增长的条件提供了正式的结果。我们的结果伴随着一系列示例，说明了分层背景知识的确切作用和实用性。]]></description>
      <guid>https://arxiv.org/abs/2503.21526</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于私人机器学习的贝叶斯伪后验机制</title>
      <link>https://arxiv.org/abs/2503.21528</link>
      <description><![CDATA[ARXIV：2503.21528V1公告类型：新 
摘要：差异隐私（DP）对于部署的机器学习应用程序变得越来越重要，因为它为保护数据用于培训模型的个人的隐私提供了强大的保证。但是，机器学习中常用的DP机制倾向于在许多现实世界分布中挣扎，包括高度不平衡或标记的训练集。在这项工作中，我们通过使用伪后验分布提出了一种新的可扩展DP机制，用于深度学习模型，SWAG-PPM，该分布与纪录的可能性下降相对于其披露风险作为随机机制的成比例贡献。作为官方统计数据的激励例子，我们使用美国职业安全和健康管理局（OSHA）出版的高度不平衡的公共数据集证明了有关工作场所伤害文本分类任务的赃物-PPM。我们发现，Swag-PPM仅对非私有比较器表现出适度的效用退化，同时大大优于类似的隐私预算的行业标准DP-SGD。]]></description>
      <guid>https://arxiv.org/abs/2503.21528</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概率功能神经网络</title>
      <link>https://arxiv.org/abs/2503.21585</link>
      <description><![CDATA[ARXIV：2503.21585V1公告类型：新 
摘要：高维功能时间序列（HDFTS）通常以非线性趋势和高空间维度为特征。由于非线性，非机构性和高维度，此类数据对建模和预测构成了独特的挑战。我们提出了一种新颖的概率功能神经网络（PROFNET）来应对这些挑战。 Profnet通过概率建模整合了前馈和深神经网络的优势。该模型使用蒙特卡洛采样生成概率预测，还可以量化预测中的不确定性。在捕获各个区域的时间和空间依赖性时，Profnet为大型数据集提供了可扩展且统一的解决方案。日本死亡率的应用表明表现出色。这种方法提高了预测精度，并提供了可解释的不确定性估计，使其成为预测复杂的高维功能数据和HDFT的宝贵工具。]]></description>
      <guid>https://arxiv.org/abs/2503.21585</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非线性多重响应回归和潜在空间的学习</title>
      <link>https://arxiv.org/abs/2503.21608</link>
      <description><![CDATA[ARXIV：2503.21608V1公告类型：新 
摘要：在高维数据中识别低维的潜在结构长期以来一直是机器学习社区中的一个核心主题，这是由于需要数据压缩，存储，传输和更深层次的数据理解的驱动。传统方法，例如主组件分析（PCA）和自动编码器（AE），以无监督的方式运行，即使有可用的标签信息也忽略了标签信息。在这项工作中，我们引入了一种能够在无监督和监督的设置中学习潜在空间的统一方法。我们将问题提出为索引模型上下文中的非线性多响应回归。通过应用广义的Stein的引理，可以在不知道非线性链接功能的情况下估算潜在空间。我们的方法可以看作是PCA的非线性概括。此外，与作为“黑匣子”运行的AE和其他神经网络方法不同，我们的方法不仅提供了更好的解释性，而且还可以降低计算复杂性，同时提供强大的理论保证。全面的数值实验和实际数据分析证明了我们方法的出色性能。]]></description>
      <guid>https://arxiv.org/abs/2503.21608</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深入学习来源的法医识别</title>
      <link>https://arxiv.org/abs/2503.20994</link>
      <description><![CDATA[ARXIV：2503.20994V1公告类型：交叉 
摘要：我们使用对比性神经网络在Nbide数据集中的144个墨盒套管之间学习有用的相似性得分，在公共但不知名的源范式下。常见但不知名的源问题是法医中的问题原型，问题是两个对象是否共享一个共同的来源（例如，是从同一枪支发射的两个墨盒套管）。相似性得分通常用于解释此范式下的证据。我们直接将我们的结果与最先进的算法，一致的匹配细胞（CMC）进行了比较。当对2967墨盒套管的E3数据集进行培训时，对比度学习的ROC AUC为0.892。 CMC算法达到0.867。我们还进行了一项消融研究，在其中改变了神经网络体系结构。具体而言，网络的宽度或深度。消融研究表明，对比的网络性能结果对网络体系结构有些强大。这项工作的部分原因是使用通过对比度学习获得标准证据解释方法（例如基于得分的似然比）获得的相似性得分。]]></description>
      <guid>https://arxiv.org/abs/2503.20994</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>馈送神经网络模型中的不确定性传播</title>
      <link>https://arxiv.org/abs/2503.21059</link>
      <description><![CDATA[ARXIV：2503.21059V1公告类型：交叉 
摘要：我们开发了新的不确定性传播方法，用于馈电神经网络体系结构，具有漏水的relu激活功能，但在输入向量中受到随机扰动的影响。特别是，我们得出神经网络输出的概率密度函数（PDF）及其统计矩的分析表达式作为输入不确定性和网络参数的函数，即权重和偏见。一个关键的发现是，即使对于输入向量中的大扰动，泄漏的Relu激活函数的适当线性化也会产生准确的统计结果。这可以归因于信息通过网络传播的方式。我们还提出了新的可分析性易处理的高斯副替代模型，以近似神经网络输出的完整关节PDF。为了验证我们的理论结果，我们对代表两个多项式函数空间之间非线性的多层差异操作员进行了多层神经网络进行蒙特卡洛模拟和彻底的错误分析。我们的发现表明，理论预测和蒙特卡洛模拟之间有着极好的一致性。]]></description>
      <guid>https://arxiv.org/abs/2503.21059</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过随机后处理净化近似差异隐私</title>
      <link>https://arxiv.org/abs/2503.21071</link>
      <description><![CDATA[ARXIV：2503.21071V1公告类型：交叉 
摘要：我们提出了一个将$（\ varepsilon，\ delta）$转换为$（\ varepsilon）的框架 - 近似差异隐私（DP）机制为$（\ varepsilon，0）$  - 纯dp机制，我们称之为“纯化”的过程。这种算法技术利用校准噪声的随机后处理，以消除$ \ delta $参数，同时保存实用程序。通过将近似DP机制的更紧密的效用界限和计算效率与纯DP的更强保证相结合，我们的方法可以达到两全其美。我们说明了该框架在各种设置中的适用性，包括差异性经验风险最小化（DP-erm），数据依赖于数据的DP机制，例如提出测试释放（PTR）和查询释放任务。据我们所知，这是第一项提供系统的方法，可以将近似DP转换为纯DP，同时保持竞争精度和计算效率。]]></description>
      <guid>https://arxiv.org/abs/2503.21071</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可参数主题评估的计算理论</title>
      <link>https://arxiv.org/abs/2503.21138</link>
      <description><![CDATA[ARXIV：2503.21138V1公告类型：交叉 
摘要：评估对于推进跨领域的决策至关重要，但是现有的方法通常难以平衡理论严格和实际的可扩展性。为了降低实验评估的成本，我们引入了可参数受试者评估的计算理论。我们证明了广义评估误差和广义因果关系误差的上限。我们还证明了效率，并且对受试者对度量对度量的因果估计效应的效率保持一致。为了优化评估模型，我们提出了一个元学习者来处理异质评估对象空间。与其他计算方法相比，我们的（条件）评估模型在12个场景中降低了24.1％-99.0％的评估错误，包括个人医学，科学模拟，商业活动和量子贸易。与实验或模拟相比，评估时间缩短了3-7个数量级。]]></description>
      <guid>https://arxiv.org/abs/2503.21138</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭示不确定性的力量：进入贝叶斯神经网络的旅程</title>
      <link>https://arxiv.org/abs/2503.21153</link>
      <description><![CDATA[ARXIV：2503.21153V1公告类型：交叉 
摘要：上下文：天文学和天体物理学要求严格处理不确定性，以确保结果的可信度。人工智能的日益融合为解决这种必需品提供了新的途径。这种融合为创建能够量化不确定性来源和自动化复杂数据关系探索的各种来源的高级模型提供了机会。
  内容：我们引入了层次结构的贝叶斯体系结构，其概率关系是由神经网络建模的，该神经网络旨在预测质量，半径和年龄（我们的主要目标）等恒星属性。该体系结构处理源于预测模型本身固有的测量和认知不确定性引起的观察不确定性。结果，我们的系统生成分布，以封装我们预测的潜在值范围，从而对其可变性和鲁棒性有全面的理解。
  方法：我们的重点是使用一种称为化学时钟的技术约会主要序列恒星，该技术既是我们的主要天文挑战和模型原型。在这项工作中，我们使用层次结构来说明恒星参数之间的相关性，并优化数据集中的信息提取。我们还采用贝叶斯神经网络来捕获复杂的数据关系，以实现其多功能性和灵活性。
  结果：通过将我们的机器学习算法整合到贝叶斯框架中，我们成功地传播了错误，并有效地管理了不确定性处理，从而产生了以更广泛的不确定性边缘为特征的预测。这种方法促进了恒星约会中更保守的估计。我们的体系结构在测试数据集中的恒星中以平均绝对误差小于1 GA实现年龄预测。]]></description>
      <guid>https://arxiv.org/abs/2503.21153</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多层次蒙特卡洛进行熵登记的马尔可夫决策过程的有效学习</title>
      <link>https://arxiv.org/abs/2503.21224</link>
      <description><![CDATA[Arxiv：2503.21224V1公告类型：交叉 
摘要：针对Markov决策过程（MDP），具有较大或连续的状态和行动空间的Markov决策过程（MDP）的设计有效的学习算法仍然是一个基本挑战。假设访问环境的生成模型，我们将针对具有波兰状态和动作空间的熵调查的MDP解决这一挑战。我们提出了一种新型的多级蒙特卡洛（MLMC）算法，该算法将固定点迭代与MLMC技术和Bellman操作员的通用随机近似结合在一起。我们量化了所选近似Bellman操作员对所得MLMC估计器的准确性的精确影响。利用此误差分析，我们表明，使用偏见的Bellman运算符的普通MC估计值会导致准多项式样品复杂性，而贝尔曼操作员的无偏随机多层次近似值实现了预期的多种方案样本复杂性。值得注意的是，这些复杂性界限独立于状态和行动空间的维度或红衣，将我们的方法与现有算法区分开，其复杂性与这些空间的大小相比。我们通过数值实验来验证这些理论绩效。]]></description>
      <guid>https://arxiv.org/abs/2503.21224</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全因死亡率预测医疗保健数据中的功能增强的机器学习</title>
      <link>https://arxiv.org/abs/2503.21241</link>
      <description><![CDATA[ARXIV：2503.21241V1公告类型：交叉 
摘要：准确的患者死亡率预测可以有效的风险分层，导致个性化治疗计划并改善患者的预后。但是，预测医疗保健的死亡率仍然是一个重大挑战，现有的研究通常集中在特定疾病或有限的预测因子集上。这项研究采用了全面的功能工程方法，评估了使用MIMIC-III数据库评估全因院内死亡率预测的机器学习模型。在临床专业知识和文献的指导下，我们提取了关键特征，例如生命体征（例如心率，血压），实验室结果（例如肌酐，葡萄糖）和人口统计信息。随机森林模型以0.94的AUC实现了最高的性能，大大优于其他机器学习和深度学习方法。这表明了随机森林在处理高维，嘈杂的临床数据及其开发有效的临床决策支持工具的潜力方面的鲁棒性。我们的发现突出了仔细的功能工程对准确死亡率预测的重要性。我们通过讨论对临床采用的影响并提出未来方向的结论，包括增强模型鲁棒性和针对特定疾病的裁缝预测模型。]]></description>
      <guid>https://arxiv.org/abs/2503.21241</guid>
      <pubDate>Fri, 28 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>