<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Thu, 06 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>熵在数据分析和机器学习中的应用：评论</title>
      <link>https://arxiv.org/abs/2503.02921</link>
      <description><![CDATA[ARXIV：2503.02921V1公告类型：新 
摘要：由于其起源于19世纪的热力学，熵的概念也渗透到其他物理和数学领域，例如经典和量子统计力学，信息理论，概率理论，千古理论和动力学系统理论。具体来说，我们指的是经典熵：玻尔兹曼·吉布斯，冯·诺伊曼，香农，科尔莫戈罗夫 - 西奈和拓扑熵。除了它们的通用名称（正如我们在本评论中简要描述的）之外，经典熵的其他共性是他们扮演的重要角色，并且仍在各自领域及其他地区的理论和应用中发挥作用。因此，不足为奇的是，随着时间的流逝，已经提出了许多其他熵概念的其他实例，其中大多数是针对特定目的量身定制的。按照当前的用法，我们将仅将它们（无论是古典还是新）称为熵。确切地说，本综述的主题是他们在数据分析和机器学习中的应用。这些特定应用的原因是，熵非常适合表征概率质量分布，通常由有限状态过程或象征性信号生成。因此，我们将重点放在定义为概率质量分布的阳性功能的熵上，并提供回到香农和khinchin的公理表征。鉴于文献中的大量熵，我们选择了一个代表性群体，包括经典群体。本评论中总结的应用程序很好地说明了熵在数据分析和机器学习中的功能和多功能性。]]></description>
      <guid>https://arxiv.org/abs/2503.02921</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LAPD：Langevin辅助贝叶斯积极学习以进行物理发现</title>
      <link>https://arxiv.org/abs/2503.02983</link>
      <description><![CDATA[ARXIV：2503.02983V1公告类型：新 
摘要：从数据中发现物理定律是科学研究中的一个基本挑战，尤其是当获得高质量的数据稀缺或昂贵时。识别动态系统的传统方法通常会与噪声敏感性，数据使用效率低下以及无法有效量化不确定性的效率。为了应对这些挑战，我们提出了Langevin辅助主动发现（LAPD），这是一个贝叶斯框架，该框架整合了复制 - 交换随机梯度Langevin Monte Carlo，以同时实现有效的系统识别和鲁棒的不确定性量化（UQ）。通过在剥削过程中平衡系数空间中的梯度驱动探索并产生候选模型的集合，LAPD与嘈杂的数据实现了可靠，不确定性感知的识别。面对数据稀缺性，LAPD的概率基础进一步通过混合不确定性空间填充的获取函数促进了主动学习（AL）的整合。该策略依次选择信息数据，以降低数据收集成本，同时保持准确性。我们评估了LAPD在不同的非线性系统上，例如Lotka-Volterra，Lorenz，Burgers和对流扩散方程，与现有方法相比，它具有嘈杂和有限的数据以及较高的不确定性校准的稳健性。与随机数据采样相比，AL扩展可将Lotka-Volterra系统的所需测量值降低约60％，而对于汉堡方程，汉堡方程式的测量值约为40％，强调了其资源受限实验的潜力。我们的框架建立了一种可扩展的，不确定性感知的方法，用于对动态系统的数据有效发现，并在高保真数据获取非常昂贵的问题上具有广泛的适用性。]]></description>
      <guid>https://arxiv.org/abs/2503.02983</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PAC学习有改进</title>
      <link>https://arxiv.org/abs/2503.03184</link>
      <description><![CDATA[ARXIV：2503.03184V1公告类型：新 
摘要：机器学习中最基本的下限之一是，在几乎任何非平凡的环境中，它都需要$ \ textit {至少} $ 1/\ epsilon $样本才能学会错误$ \ epsilon $（如果学习的分类器被学会很复杂）。但是，假设数据点是有能力提高少量的代理，如果这样做会使他们获得（所需的）阳性分类。在这种情况下，我们实际上可以通过“足够接近”来实现$ \ textit {Zero} $错误。例如，想象一下用于测量某种工作中代理商技能的招聘测试，以便在某些阈值$ \ theta $中，得分高于$ \ theta $的代理商将是成功的，而那些得分低于$ \ theta $的人不会（即，在线学习一个阈值）。还假设通过付出努力，代理可以提高其技能水平少量$ r $。在这种情况下，如果我们学习了$ \ theta $的近似值$ \ hat {\ theta} $，以至于$ \ theta \ leq \ leq \ hat {\ theta} \ leq \ leq \ leq \ theta + r $并使用它来雇用它，实际上我们可以将任何符合人数分类为a griptiation（b），并且在任何方面都可以归类为a grotiation（a），并且在某种程度上是age necried at a a insive a a insive a a insive at a a a insive at a a a insive at a），并且（a）是（a），并且（A）是（A），并且（a）是（A）。作为积极的努力。因此，代理提高的能力有可能允许在标准模型中无法实现的目标，即零误差。
  在本文中，我们更广泛地探索了这一现象，给出一般的结果，并在哪种条件下进行改进的能力，可以使学习的样本复杂性降低，或者可以使学习变得更加努力。我们还从理论和经验上研究了哪种改进感知算法可以考虑到具有在其利益时具有有限程度改进的能力的代理商。]]></description>
      <guid>https://arxiv.org/abs/2503.03184</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>专家的软马克斯门控混合物的收敛速率</title>
      <link>https://arxiv.org/abs/2503.03213</link>
      <description><![CDATA[ARXIV：2503.03213V1公告类型：新 
摘要：专家（MOE）的混合物最近已成为一个有效的框架，通过在多个被称为专家的专业子模型之间将复杂的任务软化，以提高机器学习模型的效率和可扩展性。 MOE成功的核心是一种自适应软磁性机制，该机制负责确定每个专家与给定输入的相关性，然后动态分配专家各自的权重。尽管在实践中广泛使用，但在文献中缺乏对软智能门控对MoE的影响的全面研究。为了弥合本文中的这一差距，我们对配备标准的软磁场或其变体的MOE下的参数估计和专家估计进行了收敛分析，包括分别是密集的到parteparse门控和层次软化式磁场。此外，我们的理论还为样本高效的专家结构设计提供了有用的见解。特别是，我们证明它需要多个数据点以估算满足我们提出的\ emph {强识别性}条件的专家，即是常用的两层馈送前馈网络。与之形成鲜明对比的是，估计违反强大可识别性条件的线性专家，由于在偏微分方程的语言中表达的固有参数相互作用，因此需要许多数据点。所有理论上的结果都具有严格的保证。]]></description>
      <guid>https://arxiv.org/abs/2503.03213</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在同时图像增强的背景下探索卷积神经网络的专业化和敏感性</title>
      <link>https://arxiv.org/abs/2503.03283</link>
      <description><![CDATA[Arxiv：2503.03283v1公告类型：新 
摘要：与研究生物网络研究的方式相似，我们适应了治疗方法 - 控制范式可以解释人工智能研究，并通过多参数输入变化来丰富它。在这项研究中，我们提出了一个框架，用于研究受投入数据增加影响的内部推断。网络操作的内部变化反映在通过方差衡量的激活变化中，这些变化可以分解为与每种增强相关的组件，采用Sobol索引和Shapley值。这些数量使人们能够可视化对不同变量的敏感性，并将其用于引导激活的掩盖。此外，我们介绍了一种单级灵敏度分析的方式，其中候选者根据其与激活的靶向损害产生的预测偏差进行过滤。依靠观察到的相似之处，我们假设开发的框架可能会转移到复杂环境中的生物神经网络。]]></description>
      <guid>https://arxiv.org/abs/2503.03283</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>do-iqs：动态感知离线逆向Q学习，以使用未知增益功能的最佳停止</title>
      <link>https://arxiv.org/abs/2503.03515</link>
      <description><![CDATA[ARXIV：2503.03515V1公告类型：新 
摘要：我们考虑逆最佳停止（iOS）问题，基于停止的专家轨迹，一个人的目的是通过延续和停止增益功能近似来恢复最佳停止区域。停止区域的独特性允许在现实世界中使用iOS，并带来安全问题。尽管当前最新的逆增强学习方法同时恢复了Q功能和相应的最佳策略，但他们无法解决最佳停止问题带来的特定挑战。其中包括在停止区域附近的数据稀疏性，延续增益的非马克维亚性质，对边界条件的适当处理，对风险敏感应用的稳定离线方法的需求以及缺乏质量评估指标。这些挑战是通过提出的动态感知的离线逆向Q学习（DO-IQS）来解决的，该挑战通过将累积延续增益与世界动力学和Q-unctuntion相结合而不向环境进行查询，从而结合了时间信息。此外，提出了一种基于置信的过采样方法来治疗数据稀疏问题。我们证明了模型在真实和人造数据上的性能，包括针对关键事件问题的最佳干预措施。]]></description>
      <guid>https://arxiv.org/abs/2503.03515</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩展连续混合可识别性结果的标准</title>
      <link>https://arxiv.org/abs/2503.03536</link>
      <description><![CDATA[ARXIV：2503.03536V1公告类型：新 
摘要：对于随机变量的连续混合物，我们提供了一个简单的标准 - 生成功能可访问性 - 以将先前已知的基于内核的可识别性（或不识别性）结果扩展到新的内核分布。该标准基于相关内核生成的函数或拉普拉斯变换之间的功能关系，可以应用于离散和连续随机变量的连续混合物。为了说明所提出的方法，我们提出了几种特定内核的结果。]]></description>
      <guid>https://arxiv.org/abs/2503.03536</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>特征匹配干预：利用因果表示学习的观察数据</title>
      <link>https://arxiv.org/abs/2503.03634</link>
      <description><![CDATA[ARXIV：2503.03634V1公告类型：新 
摘要：从观察数据中发现因果发现的主要挑战是没有完美的干预措施，因此很难将因果特征与虚假特征区分开。我们提出了一种创新的方法，功能匹配干预（FMI），该方法使用匹配程序来模仿完美的干预措施。我们定义了因果潜在图，将结构性因果模型扩展到潜在特征空间，并提供了将FMI与因果图学习连接的框架。我们的功能匹配过程模拟了这些因果潜在图中的完美干预措施。理论结果表明，FMI表现出强大的分布（OOD）概括性。实验进一步突出了FMI的出色表现，在有效地识别仅从观察数据的有效识别因果特征方面。]]></description>
      <guid>https://arxiv.org/abs/2503.03634</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有限样本在回归问题中对未来保险索赔的有效预测</title>
      <link>https://arxiv.org/abs/2503.03659</link>
      <description><![CDATA[ARXIV：2503.03659V1公告类型：新 
摘要：在当前的保险文献中，回归问题中对保险索赔的预测通常是通过统计模型执行的。这种基于模型的方法可能会遇到几个缺点：（i）模型错误指定，（ii）选择效果和（iii）缺乏有限样本的有效性。本文通过使用保形预测来同时解决这三个问题 - 一种通用的机器学习策略进行有效的预测。所提出的方法既无模型和不含调音参数。它还可以保证在预分配的覆盖概率水平下有限样本有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.03659</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深层因果行为政策学习：医疗保健的申请</title>
      <link>https://arxiv.org/abs/2503.03724</link>
      <description><![CDATA[ARXIV：2503.03724V1公告类型：新 
摘要：我们提出了一种基于学习的深度方法，用于研究各种非随机医疗机构中的动态临床行为制度。我们提出的方法论 - 深层因果行为政策学习（DC -BPL） - 使用深度学习算法来学习高维临床动作路径的分布，并确定这些动作路径与患者结果之间的因果关系。具体而言，我们的方法是：（1）确定提供者分配对临床结果的因果影响； （2）得知给定提供者将采取不断发展的患者信息的临床动作分布； （3）并结合了这些步骤，以确定给定患者类型的最佳提供者并模仿该提供者的护理决定。在此策略的基础上，我们使用变压器架构在电子健康记录数据上训练大型临床行为模型（LCBM），并证明其估计临床行为政策的能力。我们提出了对使用LCBM学习的行为政策的新颖解释：它是对治疗患者的复杂（通常是隐性）知识的有效编码。这使我们能够学习一系列对广泛的医疗保健应用至关重要的政策，在这些应用程序中，绝大多数临床知识是通过多年的实践默认获得的，只有很少的信息与患者护理相关（例如，在教科书，研究或标准化的指南中）。]]></description>
      <guid>https://arxiv.org/abs/2503.03724</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型能否为贝叶斯逆问题提供严格的不确定性定量吗？</title>
      <link>https://arxiv.org/abs/2503.03007</link>
      <description><![CDATA[ARXIV：2503.03007V1公告类型：交叉 
摘要：近年来，扩散建模作为一种最先进的生成建模方法的升级引起了对它们作为贝叶斯反问题的先验的重大兴趣。但是，目前尚不清楚如何最佳地整合对先前分布的扩散模型，并具有给定的似然函数以获得后验样品。尽管为此目的开发的算法可以产生高质量的，对未知参数的不同点估计，但通常在分析上未知的问题上进行了测试，因此很难评估其在提供严格的不确定性量化时的性能。在这项工作中，我们通过扩散退火（BIPSDA）引入了一个新的框架，即基于扩散模型的后验采样。该框架统一了几个最近提出的基于扩散模型的后验采样算法，并包含新型算法，可以通过设计选择的灵活组合来实现，这些算法可以实现。我们的框架中的算法对具有高斯混合物的模型问题进行了测试，并受到图像插入，X射线断层扫描和相位检索的问题启发的可能性功能。在这种情况下，可以获得近似地面真相后样品，从而对算法的性能进行原则评估。结果表明，BIPSDA算法可以在基于X射线层析成像的图像和X射线层析成像问题上提供强大的性能，而具有挑战性的相位检索问题，即使已知后验密度也很难采样，但仍然超出了基于扩散模型的采样器的范围。]]></description>
      <guid>https://arxiv.org/abs/2503.03007</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>要理解多轮大语言模型推理：近似性，可学习性和可推广性</title>
      <link>https://arxiv.org/abs/2503.03128</link>
      <description><![CDATA[ARXIV：2503.03128V1公告类型：交叉 
摘要：大型语言模型（LLMS）的认知科学和多轮推理技术的最新进展表明，迭代思维过程改善了复杂任务中解决问题的绩效。受到这一点的启发，诸如思考链，辩论和自我限制之类的方法已应用于自动回归的LLMS，在数学推理，常识性推理和多跳问题回答等任务中取得了重大成功。尽管取得了这些成功，但多轮推理如何增强解决问题的能力的理论基础仍然没有得到充实。在这项工作中，我们研究了多轮自动回归模型的近似，可学习性和泛化属性。我们表明，具有有限上下文窗口的变压器是通用近似值器，用于图灵可计算函数的步骤，并且可以通过多轮推理近似任何可与Turing汇总的序列到序列函数。我们将PAC学习扩展到序列生成，并证明即使序列长度超过模型的上下文窗口，多轮的生成也是可以学习的。最后，我们检查了概括错误如何在各个回合中传播，并显示上述方法如何有助于限制此错误，从而确保输出保持在期望边界内。这项工作阐明了多轮序列学习和推理的系统理论基础，强调了其在推理复杂性中的作用。]]></description>
      <guid>https://arxiv.org/abs/2503.03128</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型的学习动力学中功率法光谱偏差的分析理论</title>
      <link>https://arxiv.org/abs/2503.03206</link>
      <description><![CDATA[ARXIV：2503.03206V1公告类型：交叉 
摘要：我们开发了一个分析框架，用于了解扩散模型训练期间学习分布如何演变。利用高斯等效原理，我们得出了具有任意数据的一层或两层线性denoiser设置中权重的梯度流动动力学的精确解。值得注意的是，这些解决方案使我们能够通过训练以封闭形式及其KL差异得出生成的分布。这些分析结果暴露了明显的幂律频谱偏差，即，对于权重和分布，模式的收敛时间遵循其方差的反向幂定律。高斯和图像数据集的经验实验表明，即使使用更深入或卷积的体系结构，幂律频谱偏置也仍然坚固。我们的结果强调了数据协方差在规定扩散模型学习不同模式的顺序和速率方面的重要性，从而提供了潜在的解释，以说明为什么早期停止可能导致图像生成模型中的细节不正确。]]></description>
      <guid>https://arxiv.org/abs/2503.03206</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有多个相关尖峰的随机张量中的统计限制</title>
      <link>https://arxiv.org/abs/2503.03356</link>
      <description><![CDATA[ARXIV：2503.03356V1公告类型：交叉 
摘要：我们使用随机矩阵理论的工具来研究多刺张量模型，即，对称随机高斯张量的等级$ r $变形。特别是，由于用于找到该模型的最大似然估计量的局部优化方法的性质，我们建议研究用于查找相应优化问题的关键点的相变现象，即Karush-Kuhn-Kuhn-Tucker（KKT）条件定义的那些点。此外，我们表征了与可能性的临界点相对应的估计信号和地面真相信号之间的限制对齐。在这些结果的帮助下，我们通过求解一个多项式方程系统，提出了一个新的估计器对等级$ r $ tensor的权重，这是渐近无偏见的最大似然估计器。]]></description>
      <guid>https://arxiv.org/abs/2503.03356</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经损失景观中的路径和环境空间</title>
      <link>https://arxiv.org/abs/2503.03382</link>
      <description><![CDATA[ARXIV：2503.03382V1公告类型：交叉 
摘要：了解神经网络损失表面的结构，尤其是低衰变隧道的出现，对于推进神经网络理论和实践至关重要。在本文中，我们提出了一种新颖的方法，将损失隧道直接嵌入神经网络的损失景观中。探索这些损失隧道的特性为它们的长度和结构提供了新的见解，并阐明了一些常见的误解。然后，我们将方法应用于贝叶斯神经网络，在那里我们通过识别陷阱并提出更自然的先验来改善子空间推断，以更好地指导采样程序。]]></description>
      <guid>https://arxiv.org/abs/2503.03382</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>