<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 05 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用高斯过程增强均值回归时间序列预测：金融预测中的函数和增强数据结构</title>
      <link>https://arxiv.org/abs/2403.00796</link>
      <description><![CDATA[arXiv:2403.00796v1 公告类型：交叉
摘要：在本文中，我们使用相对未探索的函数和增强数据结构，探索高斯过程（GP）在预测具有底层结构的均值回归时间序列中的应用。虽然许多传统的预测方法集中于时间序列数据的短期动态，但 GP 不仅可以预测平均预测，还可以预测未来轨迹的整个概率分布。这在金融环境中尤其有利，因为如果不正确的波动性评估导致资本损失，仅靠准确的预测可能是不够的。此外，在交易选择中，普通合伙人可以预测根据交易成本调整的多个夏普比率，从而帮助决策。本研究中使用的功能数据表示可以通过利用前几年的信息来实现长期预测，即使预测偏离了当年的训练数据。此外，增强表示通过合并未来时间点的多个目标来丰富训练集，从而促进长期预测。我们的实施与评估商品期货有效性的方法密切相关。然而，我们的测试方法不同。我们使用具有相似特征的模拟数据来代替真实数据。我们构建了一个测试环境，以在实践中常见的噪声增加、厚尾和不适当的内核条件下评估数据表示和模型。通过模拟数据，我们可以将随时间的预测分布与测试集实际分布的完整模拟进行比较，从而减少在实际数据上测试时间序列模型时的固有不确定性。我们通过增强来实现特征预测，并采用子采样来确保 GP 的可行性。]]></description>
      <guid>https://arxiv.org/abs/2403.00796</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:59 GMT</pubDate>
    </item>
    <item>
      <title>训练神经网络中低成本不确定性的预测刚性形式</title>
      <link>https://arxiv.org/abs/2403.02251</link>
      <description><![CDATA[arXiv:2403.02251v1 公告类型：新
摘要：回归方法是科学技术应用的基础。然而，拟合模型在其训练领域之外可能非常不可靠，因此其不确定性的量化在其许多应用中至关重要。基于约束优化问题的解决，我们提出“预测刚性”作为获得任意预训练回归器的不确定性的方法。我们在我们的框架和贝叶斯推理之间建立了紧密的联系，并且我们开发了最后一层近似，允许将新方法应用于神经网络。这种扩展提供了廉价的不确定性，无需对神经网络本身或其训练过程进行任何修改。我们展示了我们的方法在各种回归任务上的有效性，从简单的玩具模型到化学和气象学中的应用。]]></description>
      <guid>https://arxiv.org/abs/2403.02251</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:58 GMT</pubDate>
    </item>
    <item>
      <title>通过量子近似优化算法对尖峰张量模型进行统计估计</title>
      <link>https://arxiv.org/abs/2402.19456</link>
      <description><![CDATA[arXiv:2402.19456v1 公告类型：交叉
摘要：量子近似优化算法（QAOA）是一种通用的组合优化算法。在本文中，我们分析了 QAOA 在统计估计问题（即尖峰张量模型）上的性能，该模型表现出经典的统计计算差距。我们证明$1$步QAOA的弱恢复阈值与$1$步张量幂迭代的弱恢复阈值相匹配。额外的启发式计算表明，当 $p$ 是固定常数时，$p$-step QAOA 的弱恢复阈值与 $p$-step 张量幂迭代的弱恢复阈值相匹配。这进一步意味着张量展开的多步 QAOA 可以达到但不能超过尖峰 $q$ 张量的经典计算阈值 $\Theta(n^{(q-2)/4})$。
  同时，我们描述了 $p$-step QAOA 的渐近重叠分布，发现了一个通过模拟验证的有趣的正弦高斯定律。对于某些 $p$ 和 $q$，QAOA 获得的重叠比张量幂迭代重叠大一个常数因子。出于独立兴趣，我们的证明技术采用傅立叶变换来处理困难的组合和，这是一种不同于先前对无植入结构的自旋玻璃模型进行 QAOA 分析的新颖方法。]]></description>
      <guid>https://arxiv.org/abs/2402.19456</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:58 GMT</pubDate>
    </item>
    <item>
      <title>重尾扰动下噪声 (S)GD 的差分隐私</title>
      <link>https://arxiv.org/abs/2403.02051</link>
      <description><![CDATA[arXiv:2403.02051v1 公告类型：新
摘要：在过去几年中，向随机梯度下降（SGD）迭代注入重尾噪声越来越受到关注。虽然主要从学习理论和优化角度分析了所得算法的各种理论特性，但其隐私保护特性尚未建立。为了弥补这一差距，当注入的噪声遵循 $\alpha$ 稳定分布（包括一系列重尾分布（具有无限方差）以及高斯分布。考虑到 $(\epsilon, \delta)$-DP 框架，我们表明具有重尾扰动的 SGD 在广泛的范围内实现了 $(0, \tilde{\mathcal{O}}(1/n))$-DP损失函数的类别可以是非凸的，其中 $n$ 是数据点的数量。作为一个显着的副产品，与之前需要对梯度有界敏感性或剪切迭代的工作相反，我们的理论表明，在温和的假设下，这样的投影步骤实际上是不必要的。我们说明，与高斯情况相比，重尾噪声机制实现了类似的 DP 保证，这表明它可以成为轻尾机制的可行替代方案。]]></description>
      <guid>https://arxiv.org/abs/2403.02051</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:57 GMT</pubDate>
    </item>
    <item>
      <title>用于时间序列建模的新近加权时间分段集成</title>
      <link>https://arxiv.org/abs/2403.02150</link>
      <description><![CDATA[arXiv:2403.02150v1 公告类型：新
摘要：过程工业中的时间序列建模面临着处理复杂、多方面和不断变化的数据特征的挑战。传统的单一模型方法通常难以捕捉不同动态的相互作用，从而导致预测不理想。为了解决这个问题，我们引入了新近加权时间分段（ReWTS，发音为“根”）集成模型，这是一种新颖的基于块的多步骤预测方法。 ReWTS 模型的关键特征有两个：1) 它通过将训练数据分割成数据“块”并为每个块训练一个模型，促进模型专业化为不同的动态。 2）在推理过程中，优化过程评估最近的每个模型并选择活动模型，以便可以调用先前学习的动态的适当组合来预测未来。与一次性对所有数据进行训练的传统“全局”模型相比，这种方法不仅可以捕捉每个时期的细微差别，而且可以更有效地适应随时间变化的变化。我们利用挪威一家废水处理厂和一家饮用水处理厂两年的数据进行了比较分析，证明了 ReWTS 整体的优越性。在两个数据集上，它在各种模型架构的均方预测误差方面始终优于全局模型 10-70%，特别是对异常值表现出更大的弹性。这种方法在为流程工业和其他复杂系统中的决策和控制系统开发自动、适应性强的预测模型方面显示出了前景。]]></description>
      <guid>https://arxiv.org/abs/2403.02150</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:57 GMT</pubDate>
    </item>
    <item>
      <title>Hebbian-Hopfield 网络联想记忆的容量</title>
      <link>https://arxiv.org/abs/2403.01907</link>
      <description><![CDATA[arXiv:2403.01907v1 公告类型：新
摘要：在 \cite{Hop82} 中，Hopfield 介绍了一种基于 \emph{Hebbian} 学习规则的神经网络模型，并提出了它如何有效地作为联想记忆运行。通过研究随机二进制模式，他还发现，如果在存储的模式检索中容忍一小部分错误，则网络的容量（记忆模式的最大数量，$m$）会随着每个模式的大小 $n$ 线性缩放。此外，他还预测了 $\alpha_c=\lim_{n\rightarrow\infty}\frac{m}{n}\approx 0.14$。我们用两个著名模式的吸引力盆地来研究这个完全相同的场景： \textbf{\emph{(i)}} 来自 \cite{AmiGutSom85} 的 AGS 盆地；和 \textbf{\emph{(ii)}} 来自 \cite{Newman88,Louk94,Louk94a,Louk97,Tal98} 的 NLT。依靠\cite{Stojnicflrdt23}中的\emph{完全提升随机对偶理论}（fl RDT），我们在第一级提升上获得以下显式容量表征：
  \开始{方程}
  \alpha_c^{(AGS,1)} = \left ( \max_{\delta\in \left ( 0,\frac{1}{2}\right ) }\frac{1-2\delta}{\sqrt {2} \mbox{erfinv} \left ( 1-2\delta\right )} - \frac{2}{\sqrt{2\pi}} e^{-\left ( \mbox{erfinv}\left ( 1-2\delta \right )\right )^2}\right )^2 \approx \mathbf{0.137906} \end{方程}
  \开始{方程}
  \alpha_c^{(NLT,1)} = \frac{\mbox{erf}(x)^2}{2x^2}-1+\mbox{erf}(x)^2 \近似\mathbf{0.129490} , \quad 1-\mbox{erf}(x)^2- \frac{2\mbox{erf}(x)e^{-x^2}}{\sqrt{\pi}x}+\frac{ 2e^{-2x^2}}{\pi}=0。 \end{方程}
  大量的数值工作给出了第二级提升 $\alpha_c^{(AGS,2)} \approx \mathbf{0.138186}$ 和 $\alpha_c^{(NLT,2)} \approx \mathbf{0.12979}$ ，有效地揭示了非常快速的提升收敛。此外，获得的 AGS 特征与 AmiGutSom85 的基于副本对称性的特征和 SteKuh94 相应的对称破缺特征完全匹配。]]></description>
      <guid>https://arxiv.org/abs/2403.01907</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:56 GMT</pubDate>
    </item>
    <item>
      <title>具有公平潜在表示的二分图变分自动编码器可解决生态网络中的采样偏差</title>
      <link>https://arxiv.org/abs/2403.02011</link>
      <description><![CDATA[arXiv:2403.02011v1 公告类型：新
摘要：我们提出了一种使用图嵌入来表示二分网络的方法，该方法旨在解决研究生态网络的挑战，例如连接植物和传粉者的网络，其中需要考虑许多协变量，特别是控制抽样偏差。我们将变分图自动编码器方法应用于二分情况，这使我们能够在潜在空间中生成嵌入，其中两组节点根据连接概率进行定位。我们翻译了社会学中普遍考虑的公平框架，以解决生态学中的抽样偏差。通过将希尔伯特-施密特独立准则（HSIC）作为我们优化的损失中的附加惩罚项，我们确保潜在空间的结构独立于与采样过程相关的连续变量。最后，我们展示了我们的方法在应用于 Spipoll 数据集时如何改变我们对生态网络的理解，Spipoll 数据集是一个植物与传粉者相互作用的公民科学监测项目，许多观察者都参与其中，从而容易出现抽样偏差。]]></description>
      <guid>https://arxiv.org/abs/2403.02011</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:56 GMT</pubDate>
    </item>
    <item>
      <title>软约束薛定谔桥：一种随机控制方法</title>
      <link>https://arxiv.org/abs/2403.01717</link>
      <description><![CDATA[arXiv:2403.01717v1 公告类型：新
摘要：Schr\&quot;{o}dinger 桥可以被视为连续时间随机控制问题，其目标是找到具有预先指定的终端分布 $\mu_T$ 的最优控制扩散过程。我们建议推广这种随机控制问题通过允许终端分布不同于 $\mu_T$ 但惩罚两个分布之间的 Kullback-Leibler 散度来控制问题。我们将这种新的控制问题称为软约束 Schr\&quot;{o}dinger 桥（SSB）。这项工作的主要贡献是对 SSB 解的理论推导，表明最优控制过程的终端分布是 $\mu_T$ 和其他分布的几何混合。该结果进一步扩展到时间序列设置。 SSB 的应用之一是开发稳健的生成扩散模型。我们提出了一种基于分数匹配的算法，用于从几何混合物中采样，并通过 MNIST 数据集的数值示例展示了其用途。]]></description>
      <guid>https://arxiv.org/abs/2403.01717</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:55 GMT</pubDate>
    </item>
    <item>
      <title>通过锚定多元分析提高泛化能力</title>
      <link>https://arxiv.org/abs/2403.01865</link>
      <description><![CDATA[arXiv:2403.01865v1 公告类型：新
摘要：我们引入了锚回归（AR）的因果正则化扩展，以改进分布外（OOD）泛化。我们提出了锚兼容损失，与锚框架保持一致，以确保针对分布变化的鲁棒性。各种多变量分析 (MVA) 算法，例如（正交归一化）PLS、RRR 和 MLR，都属于锚框架。我们观察到简单的正则化增强了 OOD 设置的稳健性。提供了所选算法的估计器，展示了合成和现实世界气候科学问题的一致性和有效性。实证验证强调了锚正则化的多功能性，强调其与 MVA 方法的兼容性及其在增强可复制性同时防止分布变化方面的作用。扩展的 AR 框架推进了因果推理方法，满足了可靠的 OOD 泛化的需求。]]></description>
      <guid>https://arxiv.org/abs/2403.01865</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:55 GMT</pubDate>
    </item>
    <item>
      <title>通过不同任务的多任务强化学习进行高效的近视探索</title>
      <link>https://arxiv.org/abs/2403.01636</link>
      <description><![CDATA[arXiv:2403.01636v1 公告类型：新
摘要：多任务强化学习（MTRL）方法因其在许多重要的强化学习（RL）任务中的广泛应用而受到越来越多的关注。然而，虽然 MTRL 理论的最新进展集中在通过假设跨任务共享结构来提高统计效率，但探索（强化学习的一个重要方面）却在很大程度上被忽视了。本文通过表明当代理接受足够多样化的任务集训练时，具有近视探索设计的通用策略共享算法（例如 $\epsilon$-greedy ）通常效率低下，对于 MTRL 来说可以是样本高效的，从而解决了这一差距。 。据我们所知，这是地铁铁路“探索效益”的首次理论论证。它还可能揭示近视探索在实践中广泛应用的神秘成功。为了验证多样性的作用，我们在合成机器人控制环境中进行了实验，其中多样化的任务集与自动课程学习的任务选择相一致，经验表明这可以提高样本效率。]]></description>
      <guid>https://arxiv.org/abs/2403.01636</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:54 GMT</pubDate>
    </item>
    <item>
      <title>CATS：通过构建辅助时间序列作为外生变量来增强多元时间序列预测</title>
      <link>https://arxiv.org/abs/2403.01673</link>
      <description><![CDATA[arXiv:2403.01673v1 公告类型：新
摘要：对于多元时间序列预测（MTSF），最近的深度学习应用表明单变量模型通常优于多元模型。为了解决多变量模型中的困难，我们引入了一种构造辅助时间序列（CATS）的方法，其功能类似于 2D 时间上下文注意机制，它从原始时间序列（OTS）生成辅助时间序列（ATS）以有效地表示和结合系列间关系进行预测。 ATS 的关键原则——连续性、稀疏性和可变性——通过不同的模块来确定和实施。即使使用基本的 2 层 MLP 作为核心预测器，CATS 也达到了最先进的水平，与以前的多元模型相比，显着降低了复杂性和参数，使其成为高效且可转移的 MTSF 解决方案。]]></description>
      <guid>https://arxiv.org/abs/2403.01673</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:54 GMT</pubDate>
    </item>
    <item>
      <title>用于分布外检测的深度生成模型的 Fisher 信息度量的近似</title>
      <link>https://arxiv.org/abs/2403.01485</link>
      <description><![CDATA[arXiv:2403.01485v1 公告类型：新
摘要：基于似然的深度生成模型（例如基于分数的扩散模型和变分自动编码器）是最先进的机器学习模型，可逼近图像、文本或音频等数据的高维分布。它们可以自然地应用到的许多下游任务之一是分布外（OOD）检测。然而，Nalisnick 等人的开创性工作。我们重现的结果表明，深度生成模型始终推断出 OOD 数据比它们所训练的数据更高的对数似然，这标志着一个悬而未决的问题。在这项工作中，我们基于 OOD 数据应具有比训练数据更大的梯度范数的简单直觉，使用数据点相对于 OOD 检测深度生成模型参数的梯度进行分析。我们将梯度大小的测量形式化为费舍尔信息度量的近似值。我们证明费舍尔信息矩阵（FIM）具有较大的绝对对角线值，从而激发了使用卡方分布、逐层梯度范数作为特征。我们结合这些特征，为 OOD 检测创建了一种简单的、与模型无关且无超参数的方法，该方法估计给定数据点的分层梯度范数的联合密度。我们发现这些分层梯度范数是弱相关的，使得它们的组合使用信息丰富，并证明分层梯度范数满足（数据表示）不变性原则。我们的实证结果表明，该方法优于大多数深度生成模型和图像数据集配对的典型性测试。]]></description>
      <guid>https://arxiv.org/abs/2403.01485</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:53 GMT</pubDate>
    </item>
    <item>
      <title>通过将 Kullback-Leibler 散度与 Cohen Kappa 相关联来限制分类性能</title>
      <link>https://arxiv.org/abs/2403.01571</link>
      <description><![CDATA[arXiv:2403.01571v1 公告类型：新
摘要：机器学习分类算法的性能是通过估计指标来评估的，通常来自混淆矩阵，使用训练数据和交叉验证。然而，这些并不能证明已经实现了最佳性能。错误率的基本限制可以使用信息距离度量来估计。为此，我们制定了混淆矩阵以符合切尔诺夫-斯坦引理。这将错误率与描述两个类别的概率密度函数之间的 Kullback-Leibler 散度联系起来。这导致了一个关键结果，将 Cohen 的 Kappa 与电阻器平均距离联系起来，电阻器平均距离是两个 Kullback-Leibler 散度的并联电阻器组合。电阻器平均距离以位为单位，并使用 KullBack-Leibler 散度的 kNN 估计根据分类算法使用的相同训练数据进行估计。分类算法给出混淆矩阵和Kappa。详细讨论了理论和方法，然后将其应用于蒙特卡罗数据和真实数据集。分析了四个截然不同的真实数据集——乳腺癌、冠心病、破产和颗粒识别——具有连续值和离散值，以及它们的分类性能与预期理论极限的比较。在所有情况下，该分析都表明，由于这两类的潜在概率密度函数，算法的性能不可能更好。关于如何使用近似平衡的训练数据集来预测不平衡数据的算法性能，我们学到了重要的经验教训。机器学习非常强大，但分类性能最终取决于数据的质量以及变量与问题的相关性。]]></description>
      <guid>https://arxiv.org/abs/2403.01571</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:53 GMT</pubDate>
    </item>
    <item>
      <title>高维尾部指数回归：应用于社交媒体病毒帖子的文本分析</title>
      <link>https://arxiv.org/abs/2403.01318</link>
      <description><![CDATA[arXiv:2403.01318v1 公告类型：新
摘要：受社交媒体病毒式帖子信用分布（例如“点赞数”）的经验幂律的启发，我们引入了高维尾部指数回归及其参数的估计和推断方法。我们提出一个正则化估计器，建立其一致性，并得出其收敛率。为了进行推理，我们建议对正则化估计进行去偏，并建立去偏估计量的渐近正态性。模拟研究支持我们的理论。这些方法适用于 X（以前称为 Twitter）中有关 LGBTQ+ 的病毒帖子的文本分析。]]></description>
      <guid>https://arxiv.org/abs/2403.01318</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:52 GMT</pubDate>
    </item>
    <item>
      <title>大规模变分高斯状态空间模型</title>
      <link>https://arxiv.org/abs/2403.01371</link>
      <description><![CDATA[arXiv:2403.01371v1 公告类型：新
摘要：我们介绍了一种摊销变分推理算法和结构化变分近似，用于由高斯噪声驱动的非线性动力学状态空间模型。重要的是，所提出的框架允许有效评估 ELBO 和低方差随机梯度估计，而无需借助对角高斯近似，通过利用 (i) 蒙特卡洛近似的低秩结构通过动力学边缘化潜在状态 (ii ）一个推理网络，通过低秩精度矩阵更新来近似更新步骤（iii）将当前和未来的观测值编码为伪观测值 - 将近似平滑问题转换为（更简单的）近似过滤问题。总的来说，必要的统计数据和 ELBO 可以在 $O(TL(Sr + S^2 + r^2))$ 时间内计算出来，其中 $T$ 是序列长度，$L$ 是状态空间维度，$S $是用于近似预测步骤统计的样本数量，$r$是更新步骤中近似精度矩阵更新的秩（可以由比$L$低得多的维度组成）。]]></description>
      <guid>https://arxiv.org/abs/2403.01371</guid>
      <pubDate>Tue, 05 Mar 2024 21:11:52 GMT</pubDate>
    </item>
    </channel>
</rss>