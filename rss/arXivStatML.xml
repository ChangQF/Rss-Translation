<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 07 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>具有耦合线性约束的非凸极小极大问题的零阶原对偶交替投影梯度算法</title>
      <link>https://arxiv.org/abs/2402.03352</link>
      <description><![CDATA[在本文中，我们研究了确定性和随机设置下具有耦合线性约束的非凸极小极大问题的零阶算法，该算法近年来在机器学习、信号处理和许多其他领域引起了广泛的关注，例如资源中的对抗性攻击我们提出了两种单循环算法，即零阶原对偶交替投影梯度算法（ZO-PDAPG）和零阶正则化动量原对偶投影梯度算法（ZO-RMPDPG） ），用于解决具有耦合线性约束的确定性和随机非凸（强）凹极小极大问题。两种提出的算法获得 $\varepsilon$ 驻点的迭代复杂度被证明为 $\mathcal{O}(\varepsilon ^{-2})$ （分别为 $\mathcal{O}(\varepsilon ^{-4})$) 用于在确定性设置和 $\tilde{\mathcal{O}}(\varepsilon ^{-3}) 下求解具有耦合线性约束的非凸强凹（或非凸凹）极小极大问题$ (resp. $\tilde{\mathcal{O}}(\varepsilon ^{-6.5})$) 分别在随机设置下。据我们所知，它们是前两个具有迭代复杂度保证的零阶算法，用于解决确定性和随机设置下具有耦合线性约束的非凸（强）凹极小极大问题。]]></description>
      <guid>https://arxiv.org/abs/2402.03352</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:35 GMT</pubDate>
    </item>
    <item>
      <title>通过潜变量高斯过程进行可解释的多源数据融合</title>
      <link>https://arxiv.org/abs/2402.04146</link>
      <description><![CDATA[随着人工智能 (AI) 和机器学习 (ML) 的出现，科学和工程界的各个领域已经利用数据驱动的替代品对来自众多信息（数据）源的复杂系统进行建模。这种扩散导致开发用于执行特定功能的高级系统的成本和时间显着减少。此类替代品的高主张是广泛融合多种数据源而构建的，可能是已发表的论文、专利、开放存储库或其他资源。然而，人们并没有过多关注信息源的已知和未知基础物理参数的质量和全面性差异，这些差异可能在系统优化过程中产生下游影响。为了解决这个问题，提出了一种基于潜变量高斯过程（LVGP）的多源数据融合框架。各个数据源被标记为特征分类变量，映射到物理上可解释的潜在空间，从而允许开发源感知数据融合建模。此外，还引入了基于 LVGP 潜在变量的相异性度量来研究和理解数据源的差异。通过两个数学（代表性抛物线问题、2D Ackley 函数）和两个材料科学（FeCrAl 和 SmCoFe 合金的设计）案例研究对所提出的方法进行了论证和分析。从案例研究中可以看出，与使用单源和源无意识机器学习模型相比，所提出的多源数据融合框架可以为稀疏数据问题提供更好的预测、源的可解释性以及增强的建模能力利用不同来源之间的相关性和关系。]]></description>
      <guid>https://arxiv.org/abs/2402.04146</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>通过 MEG 应用的 Stiefel 矩阵估计进行弱监督协方差矩阵对齐</title>
      <link>https://arxiv.org/abs/2402.03345</link>
      <description><![CDATA[本文介绍了一种新颖的时间序列数据域适应技术，称为混合模型 Stiefel 适应（MSA），专门解决目标数据集中有限标记信号的挑战。利用与域相关的混合模型和最佳传输域适应假设，我们利用目标域中丰富的未标记数据，通过与域之间的等效信号方差建立成对对应关系来确保有效的预测。为识别关键的斯蒂菲尔矩阵奠定了理论基础，这对于从观测到的信号协方差的黎曼表示中恢复潜在的信号方差至关重要。我们提出了一个集成成本函数，可以根据任务同时学习这些矩阵、成对域关系以及预测器、分类器或回归器。应用于神经科学问题时，MSA 在使用来自 Cam-CAN 数据集的脑磁图 (MEG) 信号进行任务变化的脑年龄回归方面优于最新方法。]]></description>
      <guid>https://arxiv.org/abs/2402.03345</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络的 PAC-贝叶斯对抗鲁棒泛化界限</title>
      <link>https://arxiv.org/abs/2402.04038</link>
      <description><![CDATA[图神经网络（GNN）在各种与图相关的任务中越来越受欢迎。然而，与深度神经网络类似，GNN 也容易受到对抗性攻击。实证研究表明，对抗性鲁棒泛化对于建立有效的对抗性攻击防御算法具有关键作用。在本文中，我们使用 PAC-贝叶斯框架为两种流行的 GNN、图卷积网络（GCN）和消息传递图神经网络提供对抗性鲁棒泛化界限。我们的结果表明，图上扩散矩阵的谱范数和权重的谱范数以及扰动因子控制着两个模型的鲁棒泛化界限。我们的界限是（Liao et al., 2020）中开发的结果从标准设置到对抗性设置的非平凡概括，同时避免最大节点度的指数依赖性。作为推论，我们在标准设置中为 GCN 推导了更好的 PAC-Bayesian 鲁棒泛化界限，通过避免对最大节点度的指数依赖来改进（Liao 等人，2020）中的界限。]]></description>
      <guid>https://arxiv.org/abs/2402.04038</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>SCAFFLSA：量化和消除联合线性随机逼近和时间差分学习中的异质性偏差</title>
      <link>https://arxiv.org/abs/2402.04114</link>
      <description><![CDATA[在本文中，我们对联邦线性随机逼近（FedLSA）算法进行非渐近分析。我们明确量化了异构代理的本地训练引入的偏差，并研究了算法的样本复杂性。我们证明 FedLSA 的通信复杂性与所需精度 $\epsilon$ 成多项式缩放，这限制了联邦的好处。为了克服这个问题，我们提出了 SCAFFLSA，这是 FedLSA 的一种新变体，它使用控制变量来纠正局部训练的偏差，并在不假设统计异质性的情况下证明其收敛性。我们将所提出的方法应用于具有线性函数近似的联合时间差分学习，并分析相应的复杂性改进。]]></description>
      <guid>https://arxiv.org/abs/2402.04114</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>子采样并不神奇：为什么大批量适用于差分私有随机优化</title>
      <link>https://arxiv.org/abs/2402.03990</link>
      <description><![CDATA[我们研究了差分私有随机梯度下降（DP-SGD）中批量大小对总梯度方差的影响，寻求大批量大小有用性的理论解释。由于 DP-SGD 是现代 DP 深度学习的基础，其特性已被广泛研究，并且最近的工作凭经验发现大批量是有益的。然而，目前对此益处的理论解释充其量只是启发式的。我们首先观察到 DP-SGD 中的总梯度方差可以分解为子采样引起的方差和噪声引起的方差。然后我们证明，在无限次迭代的限制下，有效噪声引起的方差对于批量大小是不变的。剩余的子采样引起的方差随着批量大小的增加而减小，因此大批量会减少有效的总梯度方差。我们在数值上证实，当批量大小不小时，渐近状态在实际设置中是相关的，并且发现在渐近状态之外，随着批量大小的增加，总梯度方差下降得更多。我们还发现了一个充分条件，该条件意味着大批量大小同样会降低 DP-SGD 一次迭代的有效 DP 噪声方差。]]></description>
      <guid>https://arxiv.org/abs/2402.03990</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:32 GMT</pubDate>
    </item>
    <item>
      <title>内核数据包的一般理论：从状态空间模型到紧支持基础</title>
      <link>https://arxiv.org/abs/2402.04022</link>
      <description><![CDATA[众所周知，高斯过程 (GP) 的状态空间 (SS) 模型公式可以将 n 个数据点的训练和预测时间降低到 O(n)。我们证明 GP 的 $m$ 维 SS 模型公式等价于我们作为一般右核包 (KP) 引入的概念：GP 协方差函数 $K$ 的变换，使得 $\sum_{i=0 }^{m}a_iD_t^{(j)}K(t,t_i)=0$ 对于任意 $t \leq t_1$、0 $\leq j \leq m-1$ 和 $m+1$ 连续成立点$t_i$，其中${D}_t^{(j)}f(t)$表示作用于$t$的$j$阶导数。我们将这个想法扩展到 GP 的后向 SS 模型公式，从而得出接下来 $m$ 个连续点的左 KP 的概念： $\sum_{i=0}^{m}b_i{D}_t^{( j)}K(t,t_{m+i})=0$ 对于任何 $t\geq t_{2m}$。通过组合左右 KP，我们可以证明这些协方差函数的合适线性组合产生 $m$ 紧支持的 KP 函数：$\phi^{(j)}(t)=0$ 对于任何 $t\not \in(t_0,t_{2m})$ 和 $j=0,\cdots,m-1$。 KPs进一步将GP的预测时间减少到O(log n)甚至O(1)，并且可以应用于涉及GP导数的更一般的问题。]]></description>
      <guid>https://arxiv.org/abs/2402.04022</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:32 GMT</pubDate>
    </item>
    <item>
      <title>SMOTE的理论与实验研究：再平衡策略的局限性与比较</title>
      <link>https://arxiv.org/abs/2402.03819</link>
      <description><![CDATA[合成少数过采样技术（SMOTE）是处理不平衡数据集的常见再平衡策略。渐进地，我们证明 SMOTE（使用默认参数）通过简单地复制原始少数样本来重新生成原始分布。我们还证明 SMOTE 密度在少数分布的支持边界附近消失，因此证明了常见的 BorderLine SMOTE 策略的合理性。然后我们介绍两种新的 SMOTE 相关策略，并将它们与最先进的再平衡程序进行比较。我们表明，只有当数据集高度不平衡时才需要重新平衡策略。对于此类数据集，SMOTE、我们的建议或欠采样程序是最佳策略。]]></description>
      <guid>https://arxiv.org/abs/2402.03819</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>使用切片 Wasserstein Weisfeiler-Lehman 图内核的高斯过程回归</title>
      <link>https://arxiv.org/abs/2402.03838</link>
      <description><![CDATA[监督学习最近在计算物理领域引起了极大的关注，因为它能够有效地提取复杂的模式来完成求解偏微分方程或预测材料特性等任务。传统上，此类数据集由以网格形式给出的输入以及表示问题几何形状（视为图形）的大量节点以及通过数值求解器获得的相应输出组成。这意味着监督学习模型必须能够处理具有连续节点属性的大型稀疏图。在这项工作中，我们关注高斯过程回归，为此我们引入了切片 Wasserstein Weisfeiler-Lehman (SWWL) 图内核。与现有的图内核相比，所提出的 SWWL 内核具有正定性和显着降低的复杂性，这使得处理以前无法处理的数据集成为可能。新内核首先在分子数据集的图分类上进行验证，其中输入图有几十个节点。然后，SWWL 内核的效率通过计算流体动力学和固体力学中的图回归来说明，其中输入图由数万个节点组成。]]></description>
      <guid>https://arxiv.org/abs/2402.03838</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>变分自动编码器异常检测的统计测试</title>
      <link>https://arxiv.org/abs/2402.03724</link>
      <description><![CDATA[在本研究中，我们考虑使用变分自动编码器（VAE）对异常检测（AD）进行可靠性评估。在过去的十年中，基于 VAE 的 AD 从方法开发到应用研究等各个角度都得到了积极的研究。然而，当AD的结果用于高风险决策时，例如医学诊断，有必要确保检测到的异常的可靠性。在本研究中，我们提出 VAE-AD 测试作为在统计测试框架内量化基于 VAE 的 AD 统计可靠性的方法。使用 VAE-AD 测试，VAE 检测到的异常区域的可靠性可以以 p 值的形式进行量化。这意味着，如果当 p 值低于某个阈值时宣布异常，则可以将错误检测的概率控制在所需的水平。由于VAE-AD测试是基于一种称为选择性推理的新统计推理框架构建的，因此理论上在有限样本下保证了其有效性。为了证明所提出的 VAE-AD 测试的有效性和有效性，对人工数据进行了数值实验并应用于脑图像分析。]]></description>
      <guid>https://arxiv.org/abs/2402.03724</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>EERO：提前退出并带有拒绝选项，可在预算有限的情况下实现高效分类</title>
      <link>https://arxiv.org/abs/2402.03779</link>
      <description><![CDATA[先进机器学习模型日益复杂，需要创新方法来有效管理计算资源。其中一种方法是早期退出策略，它通过提供一种缩短更简单数据实例的处理路径的机制来允许自适应计算。在本文中，我们提出了 EERO，一种新的方法，将早期退出问题转化为使用带有拒绝选项的多个分类器的问题，以便更好地为每个实例选择退出头。我们使用指数权重聚合来校准在不同头部退出的概率，以保证固定预算。我们考虑贝叶斯风险、预算约束和头部特定预算消耗等因素。使用 ResNet-18 模型和 ConvNext 架构在 Cifar 和 ImageNet 数据集上进行的实验结果表明，我们的方法不仅可以有效管理预算分配，还可以提高过度思考场景中的准确性。]]></description>
      <guid>https://arxiv.org/abs/2402.03779</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>注意力与事后可解释性的结合：数学视角</title>
      <link>https://arxiv.org/abs/2402.03485</link>
      <description><![CDATA[基于注意力的架构，特别是 Transformer，是技术革命的核心。有趣的是，除了帮助在广泛的应用中获得最先进的结果之外，注意力机制本质上还提供了对模型内部行为的有意义的见解。这些见解可以用作解释吗？争论愈演愈烈。在本文中，我们从数学上研究了一个简单的基于注意力的架构，并指出了事后解释和基于注意力的解释之间的差异。我们表明，它们提供了完全不同的结果，并且尽管有其局限性，事后方法能够捕获比仅仅检查注意力权重更有用的见解。]]></description>
      <guid>https://arxiv.org/abs/2402.03485</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:29 GMT</pubDate>
    </item>
    <item>
      <title>空间设置中预测方法的一致验证</title>
      <link>https://arxiv.org/abs/2402.03527</link>
      <description><![CDATA[空间预测任务是天气预报、空气污染研究和其他科学工作的关键。确定统计或物理方法做出的预测的可信度对于科学结论的可信度至关重要。不幸的是，经典的验证方法无法处理可用于验证的位置与我们想要进行预测的（测试）位置之间的不匹配。这种不匹配通常不是协变量偏移的实例（通常形式化），因为验证和测试位置是固定的（例如，在网格上或在选择点上）而不是独立同分布。来自两个分布。在目前的工作中，我们对验证方法进行了形式化检查：随着验证数据变得任意密集，它们变得任意准确。我们证明经典方法和协变量平移方法可能无法通过此检查。相反，我们提出了一种基于协变量移位文献中现有想法的方法，但使它们适应手头的验证数据。我们证明我们的提案通过了我们的检查。我们在模拟和真实数据上凭经验证明了它的优势。]]></description>
      <guid>https://arxiv.org/abs/2402.03527</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:29 GMT</pubDate>
    </item>
    <item>
      <title>相关性下变量重要性排序的挑战</title>
      <link>https://arxiv.org/abs/2402.03447</link>
      <description><![CDATA[变量重要性在可解释的机器学习中起着关键作用，因为它有助于衡量因素对预测模型输出的影响。可以应用基于通过排列（或相关方法）生成“空”特征的模型不可知方法。由于这种分析能够解释黑盒模型（包括基于树的集成），因此通常在制药应用中使用。然而，变量重要性估计中的一个主要挑战和重大混杂因素是特征之间相关性的存在。最近，有人提出利用特征仿制品对边际排列进行一些调整来解决这个问题，例如称为条件预测影响（CPI）的变量重要性度量。对这些方法的评估和评价是我们工作的重点。我们首先提出一项全面的模拟研究，研究特征相关性对变量重要性评估的影响。然后，我们通过仿冒构造从理论上证明了高度相关的特征对 CPI 造成的限制。虽然我们预计仿冒变量与其相应的预测变量之间始终不存在相关性，但我们证明相关性线性增加超过预测变量之间的某个相关阈值。我们的研究结果强调了在处理高特征相关性时没有免费午餐，以及了解变量重要性估计方法背后的实用性和局限性的必要性。]]></description>
      <guid>https://arxiv.org/abs/2402.03447</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:28 GMT</pubDate>
    </item>
    <item>
      <title>用分布式神经计算打破维度诅咒</title>
      <link>https://arxiv.org/abs/2402.03460</link>
      <description><![CDATA[我们提出了一种使用可以分布在多台机器上的神经计算算法来克服维数灾难的理论方法。我们的模块化分布式深度学习范例，称为 \textit{神经通路}，只需将少量参数加载到 GPU VRAM 中即可实现任意精度。形式上，我们证明对于每个错误级别 $\varepsilon&gt;0$ 和每个 Lipschitz 函数 $f:[0,1]^n\to \mathbb{R}$，可以构建一个统一逼近 $f 的神经通路模型$ 到 $\varepsilon$ 的精度超过 $[0,1]^n$，同时只需要将 $\mathcal{O}(\varepsilon^{-1})$ 参数网络加载到内存中，并且 $\mathcal{O }(\varepsilon^{-1}\log(\varepsilon^{-1}))$ 在前向传播期间加载。这提高了传统非分布式深度学习模型（即 ReLU MLP）的最佳范围，该模型需要 $\mathcal{O}(\varepsilon^{-n/2})$ 参数才能达到相同的精度。唯一可以打破维度诅咒的深度学习模型是具有超表达激活函数的 MLP。然而，我们证明这些模型具有无限的 VC 维度，即使有有限的深度和宽度限制，与神经通路模型不同。这意味着只有后者才能概括。我们的分析在回归和分类任务中都经过了实验验证，证明我们的模型与更大的集中基准相比表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2402.03460</guid>
      <pubDate>Wed, 07 Feb 2024 06:16:28 GMT</pubDate>
    </item>
    </channel>
</rss>