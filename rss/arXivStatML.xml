<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Tue, 12 Dec 2023 06:17:43 GMT</lastBuildDate>
    <item>
      <title>综合生存分析：使用辅助聚合基线和生存分数进行学习。 （arXiv：2312.05854v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.05854</link>
      <description><![CDATA[生存分析 (SA) 是事件发生时间的默认方法
建模，因为它能够稀疏地估计事件概率
随着时间的推移发生的事件。在这项工作中，我们展示了如何改进训练
通过将 SA 模型的完整表达式解耦为 (1) 来推断 SA 模型
聚合基线危险，捕获给定的总体行为
人口，以及（2）独立分布的生存分数，该模型
其给定成员的特殊概率动态，在一个完全
参数设置。所提出的推理方法被证明是动态的
处理右删失观察视野，并实现竞争性
与其他最先进的方法相比，在各种
现实世界的数据集，包括计算效率低下的基于深度学习的数据集
需要 MCMC 进行推理的 SA 方法和模型。尽管如此，我们的方法
从一开始就取得了稳健的结果，同时不受
微调或超参数优化。
]]></description>
      <guid>http://arxiv.org/abs/2312.05854</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>用于从不平衡数据中学习的倾斜概率神经网络。 （arXiv：2312.05878v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.05878</link>
      <description><![CDATA[现实世界的数据集经常表现出不平衡的数据分布，其中某些
各阶层的代表性严重不足。在这种情况下，传统模式
分类器表现出对大多数类别的偏见，妨碍了准确的分类
对少数群体的预测。本文介绍了一种不平衡
使用带有偏差的概率神经网络 (PNN) 的面向数据的方法
正态概率核来解决这一重大挑战。 PNN 因
提供概率输出，实现预测的量化
信心和不确定性处理。通过利用偏斜法线
分布，提供了更大的灵活性，特别是对于不平衡的情况
和非对称数据，我们提出的倾斜概率神经网络
（SkewPNN）可以更好地表示底层类别密度。为了优化
所提出的方法在不平衡数据集、超参数上的性能
微调势在必行。为此，我们采用基于人群的启发式方法
算法，Bat优化算法，用于有效探索
超参数空间。我们还证明了密度的统计一致性
估计表明将顺利接近真实分布
随着样本量的增加。已经进行了实验模拟
不同的综合数据集，比较各种基准不平衡的学习者。
我们的真实数据分析表明 SkewPNN 的表现明显优于
针对平衡和不平衡的最先进的机器学习方法
大多数实验设置中的数据集。
]]></description>
      <guid>http://arxiv.org/abs/2312.05878</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>元学习中的黑客任务混杂因素。 （arXiv：2312.05771v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.05771</link>
      <description><![CDATA[元学习可以通过学习快速泛化到新任务
来自各种任务的元知识。直观地假设越多
模型在一批训练中学习的任务越多，它获得的知识就越丰富，
从而获得更好的泛化性能。然而，与此相反
凭直觉，我们的实验揭示了一个意想不到的结果：添加更多任务
在单个批次内实际上会降低泛化性能。到
为了解释这种意想不到的现象，我们进行了结构因果模型（SCM）
用于因果分析。我们的调查发现存在虚假信息
元学习中特定任务的因果因素和标签之间的相关性。
此外，不同批次的混杂因素也不同。我们提到
将这些混杂因素称为“任务混杂因素”。基于这一见解，我们
提出一种即插即用的元学习因果表示学习器（MetaCRL）
消除任务混淆因素。它编码了与以下因素脱钩的因果因素：
多个任务并利用基于不变的双层优化机制
确保元学习的因果关系。各种广泛的实验
基准数据集表明我们的工作达到了最先进的水平 (SOTA)
表现。
]]></description>
      <guid>http://arxiv.org/abs/2312.05771</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>统计空间非均匀扩散推断。 （arXiv：2312.05793v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.05793</link>
      <description><![CDATA[从离散观测的测量中推断扩散方程是
统计挑战在各个领域都具有重大意义，
生物物理系统中的单分子跟踪到金融建模
仪器。假设潜在的动态过程遵循
$d$ 维随机微分方程的形式
$$\mathrm{d}\boldsymbol{x}_t=\boldsymbol{b}(\boldsymbol{x}_t)\mathrm{d}
t+\Sigma(\boldsymbol{x}_t)\mathrm{d}\boldsymbol{w}_t,$$我们提出神经网络
基于网络的漂移 $\boldsymbol{b}$ 和
空间非均匀扩散张量 $D = \Sigma\Sigma^{T}$ 并提供
当 $\boldsymbol{b}$ 和 $D$ 为
$s$-H\&quot;旧连续。值得注意的是，我们的界限与极小极大最优值一致
即使在非参数函数估计中，速率 $N^{-\frac{2s}{2s+d}}$
观察数据中存在相关性，这需要仔细
建立快速泛化边界时的处理。我们的理论
结果得到了数值实验的支持，证明了准确的推理
空间不均匀扩散张量。
]]></description>
      <guid>http://arxiv.org/abs/2312.05793</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>高维线性高斯样本协方差矩阵的谱统计。 （arXiv：2312.05794v1 [数学.ST]）</title>
      <link>http://arxiv.org/abs/2312.05794</link>
      <description><![CDATA[普通最小二乘法（OLS）的性能\emph{估计
高维稳定状态转移矩阵} $A$(即谱半径
$\rho(A)&lt;1$) 来自线性时间的单个噪声观测轨迹
不变(LTI)\脚注{马尔可夫链文献中的线性高斯(LG)}系统
$X_{-}:(x_0,x_1, \ldots,x_{N-1})$ 满足 \begin{equation}

x_{t+1}=Ax_{t}+w_{t}, \hspace{10pt} \text{ 其中 } w_{t} \thicksim
N(0,I_{n}), \end{方程}

严重依赖样本协方差矩阵的负矩：
$(X_{-}X_{-}^{*})=\sum_{i=0}^{N-1}x_{i}x_{i}^{*}$ 和奇异值
$EX_{-}^{*}$，其中$E$是矩形高斯系综$E=[w_0, \ldots,
w_{N-1}]$。负矩需要对所有特征值进行精确估计
$\lambda_{1}\big(X_{-}X_{-}^{*}\big) \geq \ldots \geq
\lambda_{n}\big(X_{-}X_{-}^{*}\big)\geq 0$。利用最近的结果
\cite{naeem2023spectral} 中非厄米算子的谱定理，以及
测量现象集中和微扰理论（Gershgorins&#39;
和柯西交错定理）我们证明，只有当 $A=A^{*}$ 时，典型的
$\lambda_{j}\big(X_{-}X_{-}^{*}\big) \in \big[N-n\sqrt{N} 的顺序，
N+n\sqrt{N}\big]$ 对于所有 $j \in [n]$。然而，在\emph{高维度}时
$A$ 只有一个不同的特征值 $\lambda$ ，其几何重数为
一，然后一旦特征值离开 \emph{复半单位圆盘}，最大
特征值遭受维数灾难：
$\lambda_{1}\big(X_{-}X_{-}^{*}\big)=\Omega\big( \lfloor\frac{N}{n}\rfloor
e^{\alpha_{\lambda}n} \big)$，而最小特征值
$\lambda_{n}\big(X_{-}X_{-}^{*}\big) \in (0, N+\sqrt{N}]$。因此，OLS
估计器产生 \emph{相变} 并变为 \emph{瞬态：
增加迭代只会恶化估计误差}，所有这一切都发生在
动态是由稳定系统产生的。
]]></description>
      <guid>http://arxiv.org/abs/2312.05794</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>用于生成学习的条件随机插值。 （arXiv：2312.05579v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.05579</link>
      <description><![CDATA[我们提出了一种条件随机插值（CSI）学习方法
条件分布。 CSI学习概率流方程或随机
将参考分布传输到目标的微分方程
条件分布。这是通过首先学习漂移函数来实现的
以及基于条件随机的条件评分函数
插值，然后用于构建确定性过程
由常微分方程或扩散过程控制
条件抽样。在我们提出的 CSI 模型中，我们结合了自适应
扩散项来解决训练过程中出现的不稳定问题
过程。我们提供了条件评分函数的显式形式和
温和条件下条件期望的漂移函数，
这自然会导致采用非参数回归方法来估计
这些功能。此外，我们建立了非渐近误差界
通过条件随机学习目标条件分布
根据 KL 散度进行插值，考虑到神经网络
近似误差。我们举例说明CSI在图像生成上的应用
使用基准图像数据集。
]]></description>
      <guid>http://arxiv.org/abs/2312.05579</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>样本最优局部私有假设选择和交互性的可证明的好处。 （arXiv：2312.05645v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.05645</link>
      <description><![CDATA[我们研究局部约束下的假设选择问题
差别隐私。给定一类 $\mathcal{F}$ 的 $k$ 分布和
一组 i.i.d.来自未知分布 $h$ 的样本，假设的目标
选择是选择一个分布$\hat{f}$，其总变异距离为
$h$ 与 $\mathcal{F}$ 中的最佳分布相当（具有高
可能性）。我们设计了一个 $\varepsilon$-局部差分私有
($\varepsilon$-LDP) 算法使用 $\Theta\left(\frac{k}{\alpha^2\min
\{\varepsilon^2,1\}}\right)$ 样本保证 $d_{TV}(h,\hat{f})\leq
\alpha + 9 \min_{f\in \mathcal{F}}d_{TV}(h,f)$ 的概率很高。这
样本复杂度对于 $\varepsilon&lt;1$ 是最佳的，匹配下限
戈皮等人。 （2020）。该问题需要所有先前已知的算法
$\Omega\left(\frac{k\log k}{\alpha^2\min \{ \varepsilon^2 ,1\}} \right)$
样品工作。

此外，我们的结果证明了交互的力量
$\varepsilon$-LDP 假设选择。也就是说，它打破了已知的下界
$\Omega\left(\frac{k\log k}{\alpha^2\min \{ \varepsilon^2 ,1\}} \right)$ 为
非交互式假设选择的样本复杂性。我们的算法
仅使用 $\Theta(\log \log k)$ 轮交互就打破了这个障碍。

为了证明我们的结果，我们定义了\emph{关键查询}的概念
可能具有独立兴趣的统计查询算法（SQA）。
非正式地说，如果 SQA 满足以下条件，则可以使用少量关键查询：
成功取决于它所提出的少量查询的准确性。我们
然后设计一个使用较少数量关键查询的 LDP 算法。
]]></description>
      <guid>http://arxiv.org/abs/2312.05645</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>结构化无逆自然梯度：用于大型神经网络的内存高效且数值稳定的 KFAC。 （arXiv：2312.05705v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.05705</link>
      <description><![CDATA[深度学习的二阶方法（例如 KFAC）可用于
神经网络训练。然而，它们通常内存效率低下并且在数字上
由于克罗内克预处理，低精度训练不稳定
因子密集，需要高精度矩阵求逆或
分解。因此，此类方法并未广泛用于训练
大型神经网络，例如基于变压器的模型。我们针对这两点
通过 (i) 制定 KFAC 的无逆更新和 (ii) 实施
每个克罗内克因子的结构，产生我们称之为的方法
结构化无逆自然梯度下降（SINGD）。论大现代
神经网络，我们表明，与 KFAC 相比，SINGD 具有内存效率
并且在数值上具有鲁棒性，即使在半精度方面也常常优于 AdamW。
因此，我们的工作缩小了一阶方法和二阶方法之间的差距
大型神经网络的现代低精度训练。
]]></description>
      <guid>http://arxiv.org/abs/2312.05705</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>用于回归的多源域适应。 （arXiv：2312.05460v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.05460</link>
      <description><![CDATA[多源域适应（DA）旨在利用更多信息
比一个源域在目标域中进行预测，其中不同
域可能具有不同的数据分布。大多数现有方法
多源DA专注于分类问题，但数量有限
回归设置中的调查。在本文中，我们填补了这个空白
通过两步程序。首先，我们扩展一个灵活的单源 DA
通过结果粗化进行分类的算法，以使其
应用于回归问题。然后我们增强我们的单一来源 DA
结合集成学习的回归算法实现多源DA。我们
考虑集成算法中的三种学习范式，其中结合了
使用每个源域训练的目标自适应学习器呈线性：（i）a
多源叠加算法获得集成权重； (二)
基于相似性的加权，其中权重反映了每个的 DA 质量
适应目标的学习者； (iii) 堆叠和相似性的组合
重量。我们通过模拟和仿真来说明算法的性能
目标是预测高密度脂蛋白 (HDL) 的数据应用
使用肠道微生物组测定胆固醇水平。我们观察到持续改进
我们的多源 DA 算法相对于常规使用的算法的预测性能
所有这些场景中的方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.05460</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>多粒度因果结构学习。 （arXiv：2312.05549v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.05549</link>
      <description><![CDATA[揭示、建模并理解支撑自然的因果机制
现象是无数科学学科的基本努力。
同时，当发现因果关系时，新知识就会出现
数据。现有的因果学习算法主要关注孤立的
变量的影响，忽视多个变量错综复杂的相互作用
以及他们的集体行为模式。此外，无处不在的
高维数据为因果算法带来了大量的时间成本。
在本文中，我们开发了一种称为 MgCSL（多粒度因果关系）的新方法
结构学习），首先利用稀疏自动编码器来探索
粗粒度策略和从微观变量到因果关系的抽象
宏观的。然后 MgCSL 将多粒度变量作为输入进行训练
多层感知器并深入研究变量之间的因果关系。加强
为了提高对高维数据的功效，MgCSL 引入了简化的非循环性
约束来熟练地搜索变量之间的有向无环图。
实验结果表明 MgCSL 优于竞争基线，并且
找出功能磁共振成像数据集上可解释的因果关系。
]]></description>
      <guid>http://arxiv.org/abs/2312.05549</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>重新审视混合模型上草图绘制操作符的 RIP 保证。 （arXiv：2312.05573v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.05573</link>
      <description><![CDATA[在压缩混合建模草图的背景下，我们重新审视
草图算子的受限等距属性的现有证明
关于某些混合物模型。在审视了自己的缺点之后
现有的保证，我们提出了一种替代分析来规避
在绘制随机傅里叶特征时需要假设重要性采样
构建随机草图运算符。我们的分析基于新的确定性
受限等距常数的界限仅取决于一组
用于定义草图操作符的频率；然后我们利用这些
为随机草图算子建立浓度不等式的界限
从而获得所需的 RIP 保证。我们的分析也打开了大门
与频率相关的结构化草图的理论保证
快速随机线性算子。
]]></description>
      <guid>http://arxiv.org/abs/2312.05573</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>深贝叶斯因素。 （arXiv：2312.05411v1 [stat.ME]）</title>
      <link>http://arxiv.org/abs/2312.05411</link>
      <description><![CDATA[贝叶斯统计中没有其他模型或假设验证工具
它与贝叶斯因子一样广泛使用。我们专注于生成模型
是无似然的，因此可以计算贝叶斯因子
（边际似然比）远非显而易见。我们提出深度学习
基于两个竞争模型的模拟数据的贝叶斯因子估计器
使用似然比技巧。该估计器缺乏摘要
统计并消除了 ABC 模型选择的一些困难。我们
为我们的深贝叶斯因子的一致性建立充分的条件
估计器及其作为模型选择工具的一致性。我们调查
我们的估计器在使用各种示例的各种示例中的性能
与估计和模型决策准确性相关的质量指标。后
训练，我们的深度学习方法可以快速评估贝叶斯
来自任一假设模型的任何虚构数据的因子估计器，
不仅仅是观察到的数据$Y_0$。这使我们能够检查整个贝叶斯因子
两个模型下的分布并量化相对位置
根据这些分布，贝叶斯因子在 $Y_0$ 上进行评估。这样的尾部区域
无法对针对 $Y_0$ 定制的贝叶斯因子估计器进行评估。我们
发现我们的 Deep Bayes Factors 的性能与现有 MCMC 具有竞争力
需要了解似然函数的技术。我们也
考虑后验或内在贝叶斯因子估计的变体。我们
证明我们的方法在相对高维上的有用性
关于确定认知偏差的真实数据示例。
]]></description>
      <guid>http://arxiv.org/abs/2312.05411</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>用于可扩展和快速基于仿真的推理的一致性模型。 （arXiv：2312.05440v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.05440</link>
      <description><![CDATA[基于模拟的推理 (SBI) 不断寻找更具表现力的方法
从噪声中准确推断复杂模型参数的算法
数据。我们提出了神经后验估计（CMPE）的一致性模型，
新的自由形式条件采样器，用于可扩展、快速和摊销的 SBI
生成神经网络。 CMPE 结合了标准化流量的优点
和流匹配方法到单个生成架构中：本质上
提取连续概率流并实现快速的几次推理
具有不受约束的架构，可以根据结构进行定制
估计问题。我们的实证评估表明 CMPE 不仅
在三个硬低维上优于当前最先进的算法
问题，但也实现了高维竞争性能
贝叶斯去噪实验和估计计算要求
肿瘤球体生长的多尺度模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.05440</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>理性克里金法。 （arXiv：2312.05372v1 [stat.ME]）</title>
      <link>http://arxiv.org/abs/2312.05372</link>
      <description><![CDATA[本文提出了一种具有有理形式的新克里金法。显示的是
有理克里金法均值的广义最小二乘估计
比普通克里金法的表现要好得多。参数估计
并提出了理性克里金法的不确定性量化
高斯过程框架。其在仿真和应用中的潜在应用
还讨论了计算机模型的校准。
]]></description>
      <guid>http://arxiv.org/abs/2312.05372</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>连续时间参数线性系统的有限样本辨识。 （arXiv：2312.05382v1 [eess.SY]）</title>
      <link>http://arxiv.org/abs/2312.05382</link>
      <description><![CDATA[区分噪声、离散测量结果以适应普通情况
微分方程可能不合理地有效。假设平方可积
噪声和最小流动规律，我们构建并分析有限差分
微分滤波器和吉洪诺夫正则化最小二乘估计器
连续时间参数线性系统。将这些贡献结合起来
级数，我们获得了估计平均绝对误差的有限样本界限。
作为副产品，我们提供了对随机扰动的新颖分析
摩尔-彭罗斯伪逆。
]]></description>
      <guid>http://arxiv.org/abs/2312.05382</guid>
      <pubDate>Tue, 12 Dec 2023 06:17:38 GMT</pubDate>
    </item>
    </channel>
</rss>