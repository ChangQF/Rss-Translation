<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 29 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>生存模型的贝叶斯联合推理</title>
      <link>https://arxiv.org/abs/2404.17464</link>
      <description><![CDATA[arXiv:2404.17464v1 公告类型：交叉
摘要：在癌症研究中，总生存期和无进展生存期通常采用 Cox 模型进行分析。为了准确估计模型中的参数，需要观察足够的数据，更重要的是，需要观察足够的事件。在实践中，这常常是一个问题。合并来自不同医疗中心的数据集可能会有所帮助，但由于严格的隐私立法和后勤困难，这并不总是可行。最近，提出了广义线性模型的贝叶斯联合推理（BFI）策略。通过这种策略，统计分析是在收集（或存储）数据的当地中心进行的，并且仅将推理结果组合成单个估计模型；合并数据是没有必要的。 BFI 方法旨在根据当地中心的单独推理结果计算如果分析基于合并数据集将会获得什么结果。在本文中，我们将最初为广义线性模型开发的 BFI 方法推广到生存模型。模拟研究和真实数据分析显示出优异的性能；即，使用 BFI 方法获得的结果与分析合并数据获得的结果非常相似。可以使用用于进行分析的 R 包。]]></description>
      <guid>https://arxiv.org/abs/2404.17464</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>对抗贝叶斯分类器的对抗一致性和唯一性</title>
      <link>https://arxiv.org/abs/2404.17358</link>
      <description><![CDATA[arXiv:2404.17358v1 公告类型：交叉
摘要：对抗性训练是学习鲁棒分类器的常用技术。先前的工作表明，凸代理损失在对抗性背景下在统计上并不一致，或者换句话说，对抗性代理风险的最小化序列不一定会最小化对抗性分类错误。我们将对抗性代理损失的一致性与最小化器的属性与对抗性分类风险联系起来，称为 \emph{对抗性贝叶斯分类器}。具体来说，在合理的分布假设下，当且仅当对抗性贝叶斯分类器满足特定的唯一性概念时，对抗性学习的凸损失在统计上是一致的。]]></description>
      <guid>https://arxiv.org/abs/2404.17358</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>短期电力需求的任意分位数概率预测</title>
      <link>https://arxiv.org/abs/2404.17451</link>
      <description><![CDATA[arXiv:2404.17451v1 公告类型：交叉 
摘要：电力系统在多种无法确定的因素的不确定性下运行。分布预测用于控制和减轻与这种不确定性相关的风险。深度学习的最新进展有助于显着提高点预测的准确性，而准确的分布预测仍然是一个重大挑战。在本文中，我们提出了一种新的通用分布预测方法，能够预测任意分位数。我们表明，我们的通用方法可以无缝应用于两个不同的神经架构，从而在短期电力需求预测任务的背景下产生最先进的分布预测结果。我们通过对欧洲国家 35 小时电力需求时间序列的实证验证了我们的方法。我们的代码可在此处获得：https://github.com/boreshkinai/any-quantile。]]></description>
      <guid>https://arxiv.org/abs/2404.17451</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>离散贝叶斯优化的连续松弛</title>
      <link>https://arxiv.org/abs/2404.17452</link>
      <description><![CDATA[arXiv:2404.17452v1 公告类型：交叉
摘要：在只有很少的可用目标观测值的情况下，对离散数据进行有效优化是贝叶斯优化中的一个挑战。我们提出了目标函数的连续松弛，并表明推理和优化可以在计算上易于处理。我们特别考虑存在很少观察和严格预算的优化领域；其动机是优化蛋白质序列以评估昂贵的生化特性。我们的方法有两个优点：在连续环境中处理问题，并且可以直接合并可用的序列先验知识。更具体地说，我们利用问题域上可用的和学习的分布来对海灵格距离进行加权，从而产生协方差函数。我们证明了所得的采集函数可以通过连续或离散优化算法进行优化，并根据经验评估我们在两个生化序列优化任务上的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.17452</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>在贝叶斯主动学习中更好地利用未标记数据</title>
      <link>https://arxiv.org/abs/2404.17249</link>
      <description><![CDATA[arXiv:2404.17249v1 公告类型：交叉
摘要：完全监督模型在贝叶斯主动学习中占主导地位。我们认为，他们对未标记数据中存在的信息的忽视不仅损害了预测性能，而且损害了有关获取哪些数据的决策。我们提出的解决方案是半监督贝叶斯主动学习的简单框架。我们发现它产生的模型比传统的贝叶斯主动学习或随机获取数据的半监督学习性能更好。与传统方法相比，它也更容易扩大规模。我们的研究结果不仅支持向半监督模型的转变，还强调了结合研究模型和获取方法的重要性。]]></description>
      <guid>https://arxiv.org/abs/2404.17249</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>惰性数据实践损害公平性研究</title>
      <link>https://arxiv.org/abs/2404.17293</link>
      <description><![CDATA[arXiv:2404.17293v1 公告类型：交叉
摘要：数据实践塑造了机器学习公平性（fair ML）的研究和实践。关键数据研究通过强调缺点并提出改进建议，为该领域负责任的发展提供了重要的反思和批评。在这项工作中，我们对公平 ML 数据集进行了全面分析，展示了不反思但常见的做法如何阻碍算法公平性结果的范围和可靠性。我们系统地研究了表格数据集中编码的受保护信息及其在 142 种出版物的 280 项实验中的使用情况。
  我们的分析确定了三个主要关注领域：（1）数据和评估中\textbf{缺乏某些受保护属性的表征}； (2) 数据预处理过程中普遍存在的\textbf{排除少数群体}； (3)\textbf{不透明数据处理}威胁着公平性研究的普遍化。通过对重要数据集的利用进行示例性分析，我们展示了不反思的数据决策如何对少数群体、公平性指标以及由此产生的模型比较产生不成比例的影响。此外，我们还发现了一些补充因素，例如公开数据的限制、隐私考虑以及普遍缺乏意识，这些因素加剧了这些挑战。为了解决这些问题，我们提出了一套以透明度和负责任的包容性为中心的公平研究中数据使用的建议。这项研究强调了对公平机器学习中的数据实践进行严格重新评估的必要性，并提供了改进数据集的来源和使用的方向。]]></description>
      <guid>https://arxiv.org/abs/2404.17293</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>在线$\mathrm{L}^{\natural}$-凸最小化</title>
      <link>https://arxiv.org/abs/2404.17158</link>
      <description><![CDATA[arXiv:2404.17158v1 公告类型：交叉
摘要：在线决策问题是一个学习问题，玩家反复做出决策以最小化长期损失。应用中出现的这些问题通常具有非线性组合目标函数，开发此类问题的算法引起了相当多的关注。处理此类目标函数的现有通用框架是在线子模最小化。然而，实际问题通常超出了该框架的范围，因为子模函数的域仅限于单位超立方体的子集。为了解决现有框架的这一限制，我们在本文中引入了在线 $\mathrm{L}^{\natural}$-凸最小化，其中 $\mathrm{L}^{\natural}$-凸函数泛化子模函数，使得域是整数格的子集。我们提出了在线 $\mathrm{L}^{\natural}$-凸函数最小化的计算有效算法，在两个主要设置中：完整信息和强盗设置。我们分析了这些算法的遗憾，并特别表明我们的完整信息设置算法获得了与常数因子相关的紧密遗憾。我们还演示了几个激励示例，说明在线 $\mathrm{L}^{\natural}$-凸最小化的有用性。]]></description>
      <guid>https://arxiv.org/abs/2404.17158</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>用于估计限制平均生存时间的伪观察和超级学习器</title>
      <link>https://arxiv.org/abs/2404.17211</link>
      <description><![CDATA[arXiv:2404.17211v1 公告类型：交叉 
摘要：在右删失数据的背景下，我们研究基于一组协变量预测事件限制时间的问题。在二次损失下，这个问题等同于估计条件限制平均生存时间 (RMST)。为此，我们提出了一种灵活且易于使用的集成算法，该算法结合了伪观测和超级学习者。超级学习者的经典理论结果扩展到右删失数据，使用伪观测的新定义，即所谓的分裂伪观测。模拟研究表明，即使对于小样本量，分裂伪观测和标准伪观测也是相似的。该方法应用于维护和结肠癌数据集，与其他预测方法相比，显示了该方法在实践中的兴趣。我们利用之前研究开发的 RMST 适配风险测量、预测区间和变量重要性测量来补充我们的方法获得的预测。]]></description>
      <guid>https://arxiv.org/abs/2404.17211</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>对抗性贝叶斯分类器的唯一性概念</title>
      <link>https://arxiv.org/abs/2404.16956</link>
      <description><![CDATA[arXiv:2404.16956v1 公告类型：交叉
摘要：我们在二元分类的设置中提出了对抗性贝叶斯分类器的唯一性新概念。分析这种唯一性概念会产生一个简单的过程，用于计算一维数据分布族的所有对抗性贝叶斯分类器。然后利用这一特征来表明，随着扰动半径的增加，对抗性贝叶斯分类器的某些规律性概念会得到改善。我们通过各种例子证明对抗性贝叶斯分类器的边界经常位于贝叶斯分类器的边界附近。]]></description>
      <guid>https://arxiv.org/abs/2404.16956</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>内曼遇见因果机器学习：个体化治疗规则的实验评估</title>
      <link>https://arxiv.org/abs/2404.17019</link>
      <description><![CDATA[arXiv:2404.17019v1 公告类型：交叉 
摘要：一个世纪前，Neyman 展示了如何在最低限度的假设下使用随机实验来评估治疗效果。这种经典的重复抽样框架是当今跨学科科学家进行常规实验分析的基础。在本文中，我们证明 Neyman 的方法也可用于实验评估由现代因果机器学习算法得出的个性化治疗规则 (ITR) 的有效性。特别是，我们展示了如何解释基于交叉拟合的训练过程导致的额外不确定性。Neyman 方法的主要优势在于它可以应用于任何 ITR，而不管用于得出 ITR 的机器学习算法的属性如何。我们还有点令人惊讶地表明，对于某些指标，对 ITR 进行事后实验评估比进行事前实验评估（将一些单元随机分配给 ITR）更有效。我们的分析表明，奈曼的重复抽样框架对于因果推断而言，今天仍然具有与其诞生之初一样的相关性。]]></description>
      <guid>https://arxiv.org/abs/2404.17019</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>高维异质治疗效果估计的可微帕累托平滑加权</title>
      <link>https://arxiv.org/abs/2404.17483</link>
      <description><![CDATA[arXiv:2404.17483v1 公告类型：新
摘要：人们越来越有兴趣利用高维特征属性来估计个体之间的异质治疗效果。在这种高维异质治疗效果估计中实现高性能具有挑战性，因为在这种设置中，通常某些特征会引起样本选择偏差，而其他特征则不会，但可以预测潜在的结果。为了避免丢失此类预测特征信息，现有方法使用逆概率加权（IPW）来学习单独的特征表示。然而，由于 IPW 权重在数值上不稳定，它们在有限样本设置下会出现估计偏差。为了通过加权表示学习开发数值稳健的估计器，我们提出了一种可微的帕累托平滑加权框架，以端到端的方式取代极端权重值。实验结果表明，通过有效地校正权重值，我们的方法优于现有的方法，包括传统的加权方案。]]></description>
      <guid>https://arxiv.org/abs/2404.17483</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>通过人工反馈消除分布外检测中的误报</title>
      <link>https://arxiv.org/abs/2404.16954</link>
      <description><![CDATA[arXiv:2404.16954v1 公告类型：交叉
摘要：分布外（OOD）样本的鲁棒性对于在开放世界中安全部署机器学习模型至关重要。最近的工作重点是设计评分函数来量化 OOD 不确定性。为 OOD 检测的这些评分函数设置适当的阈值具有挑战性，因为 OOD 样本通常无法预先获得。通常，设置阈值以实现所需的真阳性率 (TPR)，例如 $95\%$ TPR。然而，正如在 Open-OOD 基准测试中观察到的那样，这可能会导致非常高的误报率 (FPR)，范围为 60% 到 96%。在安全关键的现实应用中，例如医疗诊断，动态处理各种 OOD 样本时控制 FPR 至关重要。为了应对这些挑战，我们提出了一个以数学为基础的 OOD 检测框架，该框架利用专家反馈来\emph{安全地}动态更新阈值。我们提供的理论结果表明，它可以保证始终满足 FPR 约束，同时最大限度地减少人类反馈的使用。我们框架的另一个关键特征是它可以与 OOD 不确定性量化的任何评分函数一起使用。对我们的系统在合成和基准 OOD 数据集上的实证评估表明，我们的方法可以将 FPR 维持在最多 $5\%$，同时最大化 TPR。]]></description>
      <guid>https://arxiv.org/abs/2404.16954</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>随机连通矩阵线性储层的分离能力</title>
      <link>https://arxiv.org/abs/2404.17429</link>
      <description><![CDATA[arXiv:2404.17429v1 公告类型：新
摘要：我们认为储层计算的成功取决于储层的分离能力，并表明随机线性储层的预期分离能力可以通过相关广义矩矩阵的谱分解来充分表征。特别令人感兴趣的是具有对称高斯矩阵或其条目全部独立的储层。在对称情况下，我们证明分离能力总是随着时间的推移而恶化；而对于短输入，当矩阵的条目按因子 $\rho_T/\sqrt{N}$ 缩放时，可以最好地实现与大型水库的分离，其中 $N$ 是水库的尺寸，$\rho_T$ 取决于关于输入时间序列的最大长度。在 i.i.d.在这种情况下，我们确定，当储层矩阵的条目按精确因子 $1/\sqrt{N}$ 缩放时，可以始终实现大型储层的最佳分离。我们进一步给出了时间序列长度函数的分离质量的上限。我们通过调查这种分离的可能性以及所选架构对分离一致性的影响来补充此分析。]]></description>
      <guid>https://arxiv.org/abs/2404.17429</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>通过随机集上的 PAC-贝叶斯理论对数据相关假设集的统一泛化界限</title>
      <link>https://arxiv.org/abs/2404.17442</link>
      <description><![CDATA[arXiv:2404.17442v1 公告类型：新
摘要：我们通过从 PAC-贝叶斯角度解决问题，提出了数据依赖的统一泛化界限。我们首先以严格的方式将 PAC-贝叶斯框架应用于“随机集”，其中假设训练算法在观察训练数据后输出依赖于数据的假设集。这种方法使我们能够证明数据相关的界限，这可以适用于多种情况。为了强调我们方法的力量，我们考虑两个主要应用。首先，我们提出了最近开发的基于分形维数的泛化界限的 PAC-贝叶斯公式。得出的结果更加严格，并且它们围绕一种简单的证明技术统一了现有结果。其次，我们证明了连续朗之万动力学和随机梯度朗之万动力学轨迹的一致界限。这些结果提供了有关噪声算法的泛化特性的新信息。]]></description>
      <guid>https://arxiv.org/abs/2404.17442</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>通过矩阵补全进行在线策略学习和推理</title>
      <link>https://arxiv.org/abs/2404.17398</link>
      <description><![CDATA[arXiv:2404.17398v1 公告类型：新
摘要：当特征稀疏且与历史特征正交时，做出在线决策可能具有挑战性，特别是当通过协作过滤学习最优策略时。我们将问题表述为矩阵完成老虎机（MCB），其中每个臂下的预期奖励由未知的低秩矩阵来表征。探索了$\epsilon$-贪婪老虎机和在线梯度下降算法。策略学习和遗憾表现是在特定的探索概率和步长时间表下研究的。探索概率衰减越快，遗憾就越小，但学习最优策略的准确性就越低。我们研究了一种基于逆倾向加权（IPW）的在线去偏方法和在线政策推理的通用框架。基于 IPW 的估计量在轻度臂最优条件下是渐近正态的。数值模拟证实了我们的理论发现。我们的方法应用于旧金山停车定价项目数据，揭示了有趣的发现并超越了基准政策。]]></description>
      <guid>https://arxiv.org/abs/2404.17398</guid>
      <pubDate>Mon, 29 Apr 2024 06:18:23 GMT</pubDate>
    </item>
    </channel>
</rss>