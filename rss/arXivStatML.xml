<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Wed, 05 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>易于解释的替代模型的数学基础</title>
      <link>https://arxiv.org/abs/2503.01942</link>
      <description><![CDATA[ARXIV：2503.01942V1公告类型：新 
摘要：本文介绍了一个严格的数学框架，用于神经网络解释性，更广泛地说明了基于基于群体的非表达操作员（GenEOS）变换的均称类似算子（GEOS）的模棱两可的运算符。中心概念涉及通过测量特定图的非交换性来量化GEO之间的距离。此外，本文提出了根据每个用户偏好可以定义的复杂度度量的Geos解释性的定义。此外，我们探讨了该框架的形式属性，并展示了如何将其应用于古典机器学习方案，例如与卷积神经网络的图像分类。]]></description>
      <guid>https://arxiv.org/abs/2503.01942</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在监督分类中，沿着两部分代码MDL的正规化路径量化过度拟合</title>
      <link>https://arxiv.org/abs/2503.02110</link>
      <description><![CDATA[ARXIV：2503.02110V1公告类型：新 
摘要：我们根据任意的先验或描述语言提供了修改后的两部分代码最小描述长度（MDL）学习规则的整个正则化曲线的完整表征。 \ citet {gl}以前从不可知论的PAC（常见性最坏情况）的角度来确定了MDL规则的缺乏渐近一致性，其罚款参数为$ \ lambda = 1 $，这表明它不含糊。 Driven by interest in understanding how benign or catastrophic under-regularization and overfitting might be, we obtain a precise quantitative description of the worst case limiting error as a function of the regularization parameter $\lambda$ and noise level (or approximation error), significantly tightening the analysis of \citeauthor{GL} for $\lambda=1$ and extending it to all other choices of $ \ lambda $。]]></description>
      <guid>https://arxiv.org/abs/2503.02110</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无梯度随机优化用于加性模型</title>
      <link>https://arxiv.org/abs/2503.02131</link>
      <description><![CDATA[ARXIV：2503.02131V1公告类型：新 
摘要：我们从嘈杂的观察值中解决了满足Polyak-{\ l} ojasiewicz或强凸状条件的目标函数的零级优化问题。此外，我们假设目标函数具有添加剂结构并满足高阶的平滑性特性，其特征是“较旧的功能家族。无梯度的优化。我们得出的结论是，与非参数估计问题相反，在无梯度优化中使用加性模型时，无法实现准确性的实质性提高。]]></description>
      <guid>https://arxiv.org/abs/2503.02131</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过恒定学习率随机梯度下降在线推断分位数</title>
      <link>https://arxiv.org/abs/2503.02178</link>
      <description><![CDATA[ARXIV：2503.02178V1公告类型：新 
摘要：本文提出了一种随机梯度下降（SGD）的在线推理方法，具有恒定的学习速率，该方法具有理论保证的分位数损失函数。由于分位数损耗函数既不光滑也不是强烈的凸，因此我们将这种SGD视为不可还原且正面复发的马尔可夫链。通过利用这种解释，我们显示了独特的渐近平稳分布的存在，无论任意固定的初始化如何。为了表征此限制分布的确切形式，我们为其力矩生成函数和尾巴概率得出了边界，控制了SGD迭代的第一矩和第二矩。通过这些技术，我们证明固定分布将恒定的学习率$ \ eta \ rightarrow0 $融合到高斯分布中。我们的发现提供了第一个中心限制定理（CLT）型理论保证，用于在非平滑和非巧妙的凸设置中恒定学习率SGD的最后一个迭代。我们进一步提出了一种递归算法来以在线方式构建SGD迭代的置信区间。数值研究表明，我们提出的分位数估计量和推理方法的有限样本性能。这项研究中的理论工具具有独立的兴趣，可以研究马尔可夫链中的一般过渡内核。]]></description>
      <guid>https://arxiv.org/abs/2503.02178</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过动态集群协议，分散的多代理多资源分配的分散增强学习</title>
      <link>https://arxiv.org/abs/2503.02437</link>
      <description><![CDATA[ARXIV：2503.02437V1公告类型：新 
摘要：本文解决了以分散的方式分配多个代理商中异质资源的挑战。我们提出的方法LGTC-IPPO通过集成动态群集共识来建立在独立的近端策略优化（IPPO）的基础上，该机制允许代理基于资源需求形成和适应本地子团队。这种分散的协调策略降低了对全球信息的依赖并增强可扩展性。我们对LGTC-IPPO评估了标准的多代理增强学习基线，以及各种团队规模和资源分布的集中专家解决方案。实验结果表明，即使代理或资源类型的数量增加，LGTC-IPPO也获得了更稳定的奖励，更好的协调和稳健的性能。此外，我们说明了动态聚类如何使代理能够有效地重新分配资源，以用于带有资源的方案。]]></description>
      <guid>https://arxiv.org/abs/2503.02437</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>标签转移的广义方法：条件概率变化模型</title>
      <link>https://arxiv.org/abs/2503.02583</link>
      <description><![CDATA[ARXIV：2503.02583V1公告类型：新 
摘要：在机器学习的许多实际应用中，经常在绘制标记训练示例的源分布与仅观察到未标记数据的目标分布之间出现差异。传统上，已经考虑了两个主要方案来解决这个问题：协变量转移（CS），其中只有特征变化的边际分布和标签转移（LS），涉及类变量的先前分布的变化。但是，这些框架并未包含所有形式的分配变化。本文引入了一种新的设置，有条件的概率转移（CPS），该设置捕获了当给定某些特定特征变化的类变量的条件分布时，而剩余特征的分布给定特定功能和类别保留了类。在这种情况下，我们基于使用多项式回归对类变量的条件概率进行建模，介绍条件概率移位模型（CPSM）。由于目标数据未观察到类变量，因此使用期望最大化算法估算其分布的多项式模型的参数。所提出的方法是通用的，可以与任何概率分类器结合使用。与现有方法相比，通过对合成数据集的实验证明了CPSM的有效性，并使用模拟医学数据库进行了案例研究，揭示了其在目标数据上的出色平衡分类准确性，尤其是在条件分布转移和未通过LS基于LS基于LS的方法检测到的情况下的情况下。]]></description>
      <guid>https://arxiv.org/abs/2503.02583</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高斯工艺模型混合连续和分类输入的加权欧几里得距离矩阵</title>
      <link>https://arxiv.org/abs/2503.02630</link>
      <description><![CDATA[ARXIV：2503.02630V1公告类型：新 
摘要：高斯工艺（GP）模型在科学和工程领域被广泛用作替代模型。但是，由于难以建立分类变量的相关结构，因此标准的GP模型仅限于连续变量。为了克服这种限制，我们引入了加权的欧几里得矩阵高斯工艺（WEGP）。 WEGP通过在此输入的所有分类选择中估算欧几里得距离矩阵（EDM）来构建每个分类输入的内核函数。 EDM表示为几个预定义的基本EDM的线性组合，每个EDM都按正重缩放。使用全贝叶斯框架推断出权重以及其他内核超参数。我们从理论上分析了WEGP的预测性能。数值实验将GP模型和WEGP的精度验证为贝叶斯优化（BO），我们在合成和现实世界优化问题上都实现了卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.02630</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对非参数重复上下文经纪的严重遗憾分析</title>
      <link>https://arxiv.org/abs/2503.02646</link>
      <description><![CDATA[ARXIV：2503.02646V1公告类型：新 
摘要：我们研究了重复经纪问题的上下文版本。在每次互动中，两个具有私人估值的交易者试图根据学习者的经纪人价格购买或出售，这是通过某些上下文信息告知的。该经纪人的目标是最大化交易者的净公用事业 - 也称为与甲骨文的遗憾相比，从贸易中最小化的收益，而对交易者的估值分布有了完美的了解。我们假设交易者的估值是未知物品当前市场价值的零均值扰动 - 可以任意从一种交互变为近代，并且类似的环境将与类似的市场价格相对应。我们分析了两个反馈设置：全反馈，在每次交互之后，交易者的估值都会向经纪人透露，以及有限的反馈，其中仅揭示了交易尝试。对于两种反馈类型，我们提出算法达到紧密的遗憾界限。我们通过提供紧密的1/2及时性结果来进一步增强绩效保证，这表明知道交易者估值分布的甲骨文至少从事先知道实际实现的交易者估值的无所不知的甲骨文的交易中获得了至少1/2的收益。]]></description>
      <guid>https://arxiv.org/abs/2503.02646</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高维</title>
      <link>https://arxiv.org/abs/2503.02798</link>
      <description><![CDATA[ARXIV：2503.02798V1公告类型：新 
摘要：使用Spike and-Slab先验的后验采样[MB88]，一种流行的多模式分布，用于模拟可变选择中的不确定性，被认为是贝叶斯稀疏线性回归的理论金标准方法[CPS09，ROC18]。但是，设计可证明的算法来执行此抽样任务是挑战性的。贝叶斯稀疏可变选择任务的现有后验采样器要么需要对信噪比（SNR）[YWJ16]进行牢固的假设，仅当测量计数至少在维度[MW24]中线性增长时，要么起作用，要么依靠启发式近似值在维度[MW24]中。我们给出了适用于任何SNR的尖峰和slab后验采样的第一种可证明的算法，并在问题维度中使用测量计数sublerear。具体而言，假设我们有一个测量矩阵$ \ mathbf {x} \ in \ Mathbb {r}^{n \ times d} $和嘈杂的观测值$ \ mathbf {y} = \ \ \ \ \ \ mathbf {x}}} \ MathBf {x} \ MathBf { $ \ mathbf {\ theta}^\ star $从Spike-and-slab先验$ \ pi $带有高斯式弥漫性密度和预期的稀疏K，其中$ \ mathbf {\ xi} \ sim \ sim \ sim \ mathcal \ mathcal {n}（n}（n}） \ sigma^2 \ mathbf {i} _n）$。我们为后部$ \ pi（\ cdot \ cdot \ cdot \ mathbf {x}，\ mathbf {y}）$提供一个多项式高准确样本，任何snr $ \ sigma^{ -  sigma^{ -  1} $&gt; 0，\ geq k^$ n \ geq k^3 $ text $矩阵集合满足受限制的等轴测特性。我们进一步给出一个在相同设置中以接近线性时间$ \ nd $运行的采样器，只要$ n \ geq k^5 \ cdot \ text {polylog}（d）$。为了证明我们的框架的灵活性，我们将结果扩展到用拉普拉斯弥漫性密度进行尖峰和slab的后验采样，当$ \ sigma = o（\ frac {1} {k} {k}）$时，可以实现相似的保证。]]></description>
      <guid>https://arxiv.org/abs/2503.02798</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无监督的归因动态网络嵌入并保证稳定性</title>
      <link>https://arxiv.org/abs/2503.02859</link>
      <description><![CDATA[ARXIV：2503.02859V1公告类型：新 
摘要：动态网络嵌入的稳定性可确​​保在不同时间表现相同的节点接收相同的嵌入，从而可以在时间上比较网络中的节点。我们介绍了归因于展开的邻接光谱嵌入（AUASE），这是一个稳定的动态网络的无监督表示学习框架，其中节点与时变的协变量信息归因于此。为了建立稳定性，我们证明了统一的收敛到相关的潜在位置模型。我们通过与三个真实属性网络上的最新网络表示方法进行比较来量化动态嵌入的好处。据我们所知，AUASE是唯一满足稳定性保证的动态嵌入而无需地面真相标签，我们证明，这为链接预测和节点分类提供了重大改进。]]></description>
      <guid>https://arxiv.org/abs/2503.02859</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过代理组的多级传统和多核算</title>
      <link>https://arxiv.org/abs/2503.02870</link>
      <description><![CDATA[ARXIV：2503.02870V2公告类型：新 
摘要：随着预测机学习算法在高风险决策中的使用增加，这些算法必须在敏感组中公平。不幸的是，由于缺失或不完整的敏感组数据，测量和执行现实应用程序中的公平性可能会具有挑战性。在这些环境中，已经提出了对代表敏感的属性作为实用有效的解决方案，但仅用于基于平等的公平概念。了解如何通过缺少敏感的组数据来评估和控制公平性，以了解更新，更灵活的框架，例如多辅助性和多中心，仍然没有探索。在这项工作中，我们通过证明在没有敏感的群体数据的情况下解决了这一差距，可以证明，替代敏感的属性可用于在真实的多辅助性和多核电上得出可行的上限，从而提供了对模型潜在的最差公平性违规的见解。此外，我们表明，调整模型以满足对近代敏感属性的多循环性和多核电的，可以显着减轻这些违规行为，从而对真实但未知的，敏感的群体减轻这些违规行为。通过对现实世界数据集的几个实验，我们说明即使敏感的组信息不完整或不可用，也可以实现近似的多频率和多核。]]></description>
      <guid>https://arxiv.org/abs/2503.02870</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从小型语言模型：重新审视联邦主义论文</title>
      <link>https://arxiv.org/abs/2503.01869</link>
      <description><![CDATA[ARXIV：2503.01869V1公告类型：交叉 
摘要：很长一段时间以来，联邦主义论文的作者身份一直是询问和辩论的主题，不仅是语言学家和历史学家，而且是统计学家。在可以说是第一个贝叶斯案例研究的情况下，Mosteller and Wallace（1963）提供了将所有有争议的论文归因于麦迪逊的第一个统计证据。我们的论文重新审视了这个历史数据集，但从大小的现代语言模型中。我们回顾一些更流行的大型语言模型（LLM）工具，并在文本分类的背景下从统计的角度检查它们。我们调查是否没有尝试进行任何尝试，一般嵌入构建体可用于风格和归因。我们解释了各种单词/短语嵌入之间的差异，并讨论了如何在文档中汇总它们。与我们的期望相反，我们说明了用单词嵌入的维度扩展可能并不总是有益于归因于降低主题嵌入的尺寸。我们的实验表明，默认的LLM嵌入（即使在手动微调之后）也可能无法始终提高作者身份归因精度。取而代之的是，对``功能单词&#39;&#39;训练的主题嵌入的贝叶斯分析产生了卓越的样本外分类性能。这表明，传统（小）统计语言模型具有可解释性和稳固的理论基础，可以在作者身份归因任务中具有重要优势。此分析可在GITHUB.COM/sowithub.com/sowonjenjeong/slm-llmm llmm llmm llmm llmm。]]></description>
      <guid>https://arxiv.org/abs/2503.01869</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>构建平衡数据集，以预测地震危害下结构系统中的故障模式</title>
      <link>https://arxiv.org/abs/2503.01882</link>
      <description><![CDATA[ARXIV：2503.01882V1公告类型：交叉 
摘要：在地震激发下对结构性故障模式的准确预测对于地震风险和弹性评估至关重要。传统的基于模拟的方法通常会导致以非失败或经常观察到的故障场景为主的不平衡数据集，从而限制了基于机器学习的预测的有效性。为了应对这一挑战，本研究提出了一个构建平衡数据集的框架，其中包括不同的故障模式。该框架由三个关键步骤组成。首先，确定临界地面运动特征（GMF）以有效地表示地面运动时间历史。其次，采用自适应算法来估计关键GMF和结构参数空间中各种故障域的概率密度。第三，通过使用缩放因子优化过程将这些概率密度产生的样品转化为地面运动时间历史。平衡数据集是通过对具有与生成样本相匹配的参数进行非线性响应历史记录分析来构建的，并受到相应的转换的地面运动时间历史。深度神经网络模型接受了平衡和不平衡数据集的培训，以突出数据集平衡的重要性。为了进一步评估该框架的适用性，使用受记录和合成地面运动的两个不同的结构模型进行了数值研究。结果证明了该框架在解决数据集不平衡和在地震故障模式预测中提高机器学习性能方面的鲁棒性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.01882</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不确定性的非合作游戏</title>
      <link>https://arxiv.org/abs/2503.01889</link>
      <description><![CDATA[ARXIV：2503.01889V1公告类型：交叉 
摘要：本文介绍了有限的非合作游戏的框架，每个玩家都面对一个全球不确定的参数，没有共同的先验。每个玩家都选择混合策略，并在不确定参数之前投射出一个新兴的主观。我们通过单方面的策略改变没有玩家可以改善她的预期效用，从而定义了“扩展平衡”，而新兴的主观先验使他们最大程度地提高了球员的预期遗憾。基于Brouwer的固定点定理并模仿Nash的构建的定点论点可确保存在。此外，“没有虚构的信仰”定理表明，如果参数对玩家真正重要，则任何主观平衡之前都必须保持不集中。这种方法提供了一个框架，该框架可以统一基于遗憾的统计决策理论和游戏理论，从而在存在深度不确定参数的情况下产生了处理战略决策的工具。]]></description>
      <guid>https://arxiv.org/abs/2503.01889</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VAE和gan：隐式近似使用简单基础分布和深层神经网络的复杂分布 - 原理，必要性和局限性</title>
      <link>https://arxiv.org/abs/2503.01898</link>
      <description><![CDATA[ARXIV：2503.01898V1公告类型：交叉 
摘要：本教程的重点是变异自动编码器（VAE）和生成对抗网络（GAN）的基本体系结构，无视它们的众多变体，以突出其核心原则。 VAE和GAN都利用简单的分布（例如高斯人）作为基础，并利用神经网络的强大非线性转化能力来近似任意复杂的分布。理论基础在于，多个高斯人的线性组合几乎可以近似任何概率分布，而神经网络则可以通过非线性转化进行进一步的细化。两种方法都隐含地近似复杂的数据分布。这种隐式近似是至关重要的，因为直接对高维分布进行建模通常是棘手的。但是，选择简单的潜在先验，虽然计算方便，但却引入了限制。在VAE中，固定的高斯先验迫使后验分布与之保持一致，可能导致信息丢失并降低表现力。这种限制既影响模型的可解释性，也影响了生成样品的质量。]]></description>
      <guid>https://arxiv.org/abs/2503.01898</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>