<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 15 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过在线熵匹配保护测试时间自适应：一种投注方法</title>
      <link>https://arxiv.org/abs/2408.07511</link>
      <description><![CDATA[arXiv:2408.07511v1 公告类型：交叉 
摘要：我们提出了一种通过在线自训练进行测试时间自适应的新方法，该方法由两个部分组成。首先，我们引入了一个统计框架，用于检测在未标记样本流上获得的分类器熵值的分布变化。其次，我们设计了一种在线自适应机制，利用检测工具捕获的分布变化证据来动态更新分类器的参数。由此产生的自适应过程驱动从自训练分类器获得的测试熵值的分布与源域的分布相匹配，从而建立对分布变化的不变性。这种方法不同于传统的自训练方法，后者侧重于最小化分类器的熵。我们的方法结合了投注马丁格尔和在线学习中的概念，形成了一种能够快速响应分布变化的检测工具。然后，我们揭示了我们的适应方案与最佳传输之间的紧密关系，这构成了我们新颖的自监督损失的基础。实验结果表明，我们的方法在分布发生变化的情况下提高了测试时间的准确性，同时在没有分布发生变化的情况下保持了准确性和校准性，并且在各种场景中优于领先的熵最小化方法。]]></description>
      <guid>https://arxiv.org/abs/2408.07511</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:50 GMT</pubDate>
    </item>
    <item>
      <title>格子中高阶相互作用的信息论测度</title>
      <link>https://arxiv.org/abs/2408.07533</link>
      <description><![CDATA[arXiv:2408.07533v1 公告类型：交叉 
摘要：仅依赖于成对关联的传统模型通常不足以捕捉多变量数据中固有的复杂统计结构。然而，现有的用于识别 $d&gt;3$ 变量组之间共享的信息的方法通常难以处理；围绕目标变量不对称；或者无法考虑联合概率分布的所有因式分解。在这里，我们提出了一个框架，该框架使用格和算子函数对系统地推导高阶度量，其中格捕获变量的代数关系结构，算子函数计算格上的度量。我们表明，许多现有的信息论高阶度量可以通过使用散度作为分区格子格上的算子函数来推导，从而阻止对 $d&gt;3$ 的所有交互进行准确量化。同样，我们表明使用 KL 散度作为算子函数也会导致对 $d&gt;3$ 的交互进行不必要的取消。为了表征 $d$ 变量之间的所有相互作用，我们引入了在完整分区格子上定义的 Streitberg 信息，使用 KL 散度的泛化作为算子函数。我们在合成数据上用数字验证了我们的结果，并通过将 Streitberg 信息应用于股票市场回报和神经电生理数据来说明其用途。]]></description>
      <guid>https://arxiv.org/abs/2408.07533</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:50 GMT</pubDate>
    </item>
    <item>
      <title>通过密度矩阵检测潜在异常</title>
      <link>https://arxiv.org/abs/2408.07623</link>
      <description><![CDATA[arXiv:2408.07623v1 公告类型：交叉 
摘要：本文介绍了一种新颖的异常检测框架，该框架将基于密度估计的异常检测方法的稳健统计原理与深度学习模型的表示学习能力相结合。源自该框架的方法有两种不同的版本：一种是采用基于自适应傅里叶特征和密度矩阵的密度估计模型的浅层方法，另一种是集成自动编码器来学习数据的低维表示的深度方法。通过估计新样本的密度，这两种方法都能够找到正态性分数。这些方法可以无缝集成到端到端架构中，并使用基于梯度的优化技术进行优化。为了评估它们的性能，在各种基准数据集上进行了广泛的实验。结果表明，与其他最先进的方法相比，该方法的两个版本都可以实现相当或更优异的性能。值得注意的是，浅层方法在维度较少的数据集上表现更好，而基于自动编码器的方法在维度较高的数据集上表现出更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.07623</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:50 GMT</pubDate>
    </item>
    <item>
      <title>通过光谱共振实现联合图形重构和特征去噪</title>
      <link>https://arxiv.org/abs/2408.07191</link>
      <description><![CDATA[arXiv:2408.07191v1 公告类型：交叉 
摘要：图神经网络 (GNN) 将图结构和与节点相关的特征向量作为输入。两者都包含有关标签的噪声信息。在这里，我们提出了联合去噪和重新布线 (JDR)——一种联合去噪图结构和特征的算法，它可以提高任何下游算法的性能。我们通过定义和最大化图和特征矩阵的主要特征空间之间的对齐来实现这一点。为了近似地解决这个计算困难的问题，我们提出了一种启发式方法，可以有效地处理具有许多类和不同程度的同质性或异质性的真实世界图数据集。我们通过实验验证了我们的方法在合成数据和真实世界图数据集上的有效性。结果表明，在使用 GNN 作为下游模型的节点分类任务上，JDR 始终优于现有的重新布线方法。]]></description>
      <guid>https://arxiv.org/abs/2408.07191</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:49 GMT</pubDate>
    </item>
    <item>
      <title>通过 Hessian 平均和自适应梯度采样方法实现快速无约束优化</title>
      <link>https://arxiv.org/abs/2408.07268</link>
      <description><![CDATA[arXiv:2408.07268v1 公告类型：交叉 
摘要：我们考虑通过基于 Hessian 平均的子采样牛顿法最小化有限和和期望目标函数。这些方法允许梯度不精确，并且具有固定的每次迭代 Hessian 近似成本。最近的研究（Na et al. 2023）表明，Hessian 平均可用于实现强凸函数的快速 $\mathcal{O}\left(\sqrt{\tfrac{\log k}{k}}\right)$ 局部超线性收敛，同时保持固定的每次迭代 Hessian 成本。然而，这些方法需要梯度精确性和强凸性，这对它们的实际实现提出了挑战。为了解决这个问题，我们考虑了 Hessian 平均方法，该方法通过基于范数条件的自适应采样策略允许梯度不精确。对于有限和问题，我们利用确定性抽样技术，分别得出强凸函数和非凸函数的全局线性和次线性收敛速度。在这种情况下，我们能够推导出改进的确定性局部超线性收敛速度 $\mathcal{O}\left(\tfrac{1}{k}\right)$。对于 %expected 风险期望问题，我们利用随机抽样技术，并推导出强凸函数和非凸函数的全局线性和次线性收敛速度，以及 $\mathcal{O}\left(\tfrac{1}{\sqrt{k}}\right)$ 局部超线性收敛速度，全部以期望值计算。我们提出了不同于以前概率结果的新型分析技术。此外，我们通过对角线近似提出了这些方法的可扩展且有效的变体，并推导出用于大规模问题的新型对角平均牛顿 (Dan) 方法。我们的数值结果表明，Hessian 平均不仅有助于收敛，而且可以使 ResNets 在解决 CIFAR100 分类等难题上取得最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2408.07268</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:49 GMT</pubDate>
    </item>
    <item>
      <title>具有距离核的 MMD 函数的 Wasserstein 梯度流和分位数函数的柯西问题</title>
      <link>https://arxiv.org/abs/2408.07498</link>
      <description><![CDATA[arXiv:2408.07498v1 公告类型：交叉 
摘要：我们全面描述了最大均值差异 (MMD) 函数 $\mathcal F_\nu := \text{MMD}_K^2(\cdot, \nu)$ 的 Wasserstein 梯度流，该梯度流朝向实线上给定的目标测度 $\nu$，其中我们重点关注负距离核 $K(x,y) := -|x-y|$。在一维中，Wasserstein-2 空间可以等距嵌入到分位数函数的锥体 $\mathcal C(0,1) \subset L_2(0,1)$ 中，从而通过解决 $L_2(0,1)$ 上的相关柯西问题来表征 Wasserstein 梯度流。基于在 $L_2(0,1)$ 上构建 $\mathcal F_\nu$ 的适当对应项及其次微分，我们提供了柯西问题的解。对于离散目标测度 $\nu$，这会产生分段线性解公式。我们证明了流在 $\mathcal C(0,1)$ 子集上的不变性和平滑性。对于某些 $\mathcal F_\nu$ 流，这意味着初始点测度会立即变为绝对连续，并随着时间的推移保持这种状态。最后，我们使用隐式欧拉方案通过各种数值示例说明流的行为，并展示与显式欧拉方案的差异，后者更容易计算，但收敛保证有限。]]></description>
      <guid>https://arxiv.org/abs/2408.07498</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:49 GMT</pubDate>
    </item>
    <item>
      <title>具有高维奖励的离线策略强化学习</title>
      <link>https://arxiv.org/abs/2408.07660</link>
      <description><![CDATA[arXiv:2408.07660v1 公告类型：新
摘要：传统的离线策略强化学习 (RL) 专注于最大化标量奖励的预期回报。相比之下，分布式 RL (DRL) 研究欧几里得空间中分布贝尔曼算子的回报分布，从而为效用提供高度灵活的选择。本文为 DRL 建立了强大的理论基础。我们证明了即使奖励空间是无限维可分 Banach 空间，贝尔曼算子的收缩性质。此外，我们证明高维或无限维回报的行为可以用低维欧几里得空间有效地近似。利用这些理论见解，我们提出了一种新颖的 DRL 算法，解决了以前使用传统强化学习方法无法解决的问题。]]></description>
      <guid>https://arxiv.org/abs/2408.07660</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:48 GMT</pubDate>
    </item>
    <item>
      <title>使用高斯过程切换线性动力系统对潜在神经动力学进行建模</title>
      <link>https://arxiv.org/abs/2408.03330</link>
      <description><![CDATA[arXiv:2408.03330v1 公告类型：交叉 
摘要：了解神经群体的集体活动如何与计算和最终行为相关是神经科学的一个关键目标。为此，用低维潜在动力学描述高维神经时间序列的统计方法在表征神经系统方面发挥了重要作用。然而，成功的方法涉及两个相互矛盾的标准：（1）方法应该具有足够的表达能力来捕捉复杂的非线性动力学，（2）它们应该保持可解释性的概念，而这种概念通常只有更简单的线性模型才能保证。在本文中，我们开发了一种平衡这两个目标的方法：高斯过程切换线性动力系统 (gpSLDS)。我们的方法建立在以前的工作基础上，通过随机微分方程对潜在状态的演化进行建模，其非线性动力学由高斯过程 (GP-SDE) 描述。我们提出了一种新颖的核函数，它可以强制平滑插值的局部线性动力学，因此可以表达类似于循环切换线性动力学系统 (rSLDS) 的灵活但可解释的动力学。我们的方法解决了 rSLDS 的关键限制，例如离散状态边界附近动力学中的伪振荡，同时还提供了动力学的后验不确定性估计。为了拟合我们的模型，我们利用了修改后的学习目标，与以前的 GP-SDE 拟合方法相比，它提高了内核超参数的估计精度。我们将我们的方法应用于合成数据和两个神经科学实验中记录的数据，与 rSLDS 相比，它表现出良好的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.03330</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:48 GMT</pubDate>
    </item>
    <item>
      <title>使用扩展事故三角克服不平衡安全数据</title>
      <link>https://arxiv.org/abs/2408.07094</link>
      <description><![CDATA[arXiv:2408.07094v1 公告类型：交叉 
摘要：人们越来越有兴趣使用安全分析和机器学习来支持预防工作场所事故，尤其是在建筑和卡车运输等高风险行业。尽管现有的安全分析研究取得了显着进展，但它们受到数据集不平衡的影响，这是安全分析中常见的问题，导致预测不准确。这可能导致管理问题，例如资源分配不正确和干预不当。为了克服数据不平衡问题，我们扩展了事故三角理论，声称数据样本的重要性应基于伤害严重程度、事故频率和事故类型等特征。因此，提出了三种基于为少数类中的样本分配不同权重的过采样方法。我们发现不同的机器学习算法之间存在显着的改进。由于缺乏开源安全数据集，我们分享了三个不平衡的数据集，例如 9 年的全国建筑事故记录数据集及其相应的代码。]]></description>
      <guid>https://arxiv.org/abs/2408.07094</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:48 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程中的后验协方差结构</title>
      <link>https://arxiv.org/abs/2408.07379</link>
      <description><![CDATA[arXiv:2408.07379v1 公告类型：新
摘要：本文对高斯过程中的后验协方差场进行了全面分析，并将其应用于后验协方差矩阵。该分析基于高斯先验协方差，但该方法也适用于其他协方差核。我们的几何分析揭示了高斯核的带宽参数和观测值的空间分布如何影响后验协方差以及相应的协方差矩阵，从而可以直接识别协方差幅度高或低的区域。从自适应有限元方法中的后验误差估计技术中汲取灵感，我们还提出了几种估计量来有效地测量绝对后验协方差场，可用于有效的协方差矩阵近似和预处理。我们进行了广泛的实验来说明我们的理论发现及其实际应用。]]></description>
      <guid>https://arxiv.org/abs/2408.07379</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:47 GMT</pubDate>
    </item>
    <item>
      <title>用于学习潜在几何的解码器集成</title>
      <link>https://arxiv.org/abs/2408.07507</link>
      <description><![CDATA[arXiv:2408.07507v1 公告类型：新
摘要：潜在空间几何为与深度生成模型的潜在变量交互提供了一个严格且具有经验价值的框架。这种方法通过拉回度量将欧几里得潜在空间重新解释为黎曼空间，从而允许对潜在空间进行标准微分几何分析。不幸的是，数据流形通常是紧凑的，容易断开连接或充满空洞，这表明与欧几里得潜在空间存在拓扑不匹配。解决这种不匹配的最成熟方法是让不确定性成为拓扑的代理，但在神经网络模型中，这通常是通过缺乏原理且通常无法扩展到高维表示的粗略启发式方法来实现的。我们建议使用解码器集合来捕获模型不确定性，并展示如何轻松计算相关预期流形上的测地线。从经验上讲，我们发现这简单可靠，从而更接近易于使用的潜在几何。]]></description>
      <guid>https://arxiv.org/abs/2408.07507</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:47 GMT</pubDate>
    </item>
    <item>
      <title>“多大才够大？”在连续高斯过程中调整模型大小</title>
      <link>https://arxiv.org/abs/2408.07588</link>
      <description><![CDATA[arXiv:2408.07588v1 公告类型：新
摘要：对于许多机器学习方法，创建模型需要在训练之前设置一个控制模型容量的参数，例如 DNN 中的神经元数量或 GP 中的诱导点。增加容量可以提高性能，直到捕获数据集中的所有信息。在此之后，计算成本不断增加，而性能却没有提高。这就引出了一个问题：“多大才足够大？”我们在持续学习中研究高斯过程（单层神经网络）的这个问题。在这里，数据逐渐可用，因此在训练之前不会知道最终的数据集大小，从而阻止使用启发式方法来设置模型大小。我们提供了一种自动调整此方法的方法，同时保持接近最佳的性能，并表明我们的方法的单个超参数设置在具有广泛属性的数据集中表现良好。]]></description>
      <guid>https://arxiv.org/abs/2408.07588</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:47 GMT</pubDate>
    </item>
    <item>
      <title>Alpha-Trimming：随机森林的局部自适应树修剪</title>
      <link>https://arxiv.org/abs/2408.07151</link>
      <description><![CDATA[arXiv:2408.07151v1 公告类型：新
摘要：我们证明，自适应地控制随机森林中单个回归树的大小可以提高预测性能，这与树木应该完全生长的传统观点相反。提出了一种快速修剪算法，即 alpha-trimming，作为在随机森林中修剪树木的有效方法，其中在信噪比较低的区域进行更积极的修剪。通过调整信息准则惩罚的权重作为调整参数来控制总体修剪量，标准随机森林是我们 alpha-trimmed 随机森林的一个特例。alpha-trimming 的一个显着特点是，一旦树木完全生长，就可以调整其调整参数而无需重新拟合随机森林中的树木。在 46 个示例数据集的基准测试套件中，使用我们的修剪算法通常会显着降低均方预测误差，并且与默认参数设置下具有完全生长的树木的随机森林相比，均方预测误差从未显着增加。]]></description>
      <guid>https://arxiv.org/abs/2408.07151</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:46 GMT</pubDate>
    </item>
    <item>
      <title>通过平均场朗之万动力学用神经网络学习多指标模型</title>
      <link>https://arxiv.org/abs/2408.07254</link>
      <description><![CDATA[arXiv:2408.07254v1 公告类型：新
摘要：我们研究使用用均值场朗之万算法训练的两层神经网络在高维中学习多指标模型的问题。在对数据进行温和的分布假设下，我们利用神经网络对潜在低维结构的自适应性来表征控制样本和计算复杂度的有效维度$d_{\mathrm{eff}}$。当数据表现出这样的结构时，$d_{\mathrm{eff}}$可以明显小于环境维度。我们证明样本复杂度几乎随$d_{\mathrm{eff}}$线性增长，绕过了最近基于梯度的特征学习分析中出现的信息和生成指数的限制。另一方面，在最坏的情况下，计算复杂度可能不可避免地随$d_{\mathrm{eff}}$呈指数增长。受改进计算复杂度的启发，我们通过研究权重被限制在具有正 Ricci 曲率的紧流形（例如超球面）上的设置，迈出了平均场朗之万算法的多项式时间收敛的第一步。在那里，我们研究了可实现多项式时间收敛的假设，而欧几里得设置中的类似假设会导致指数时间复杂度。]]></description>
      <guid>https://arxiv.org/abs/2408.07254</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:46 GMT</pubDate>
    </item>
    <item>
      <title>局部稳定点过程的自适应重要性抽样</title>
      <link>https://arxiv.org/abs/2408.07372</link>
      <description><![CDATA[arXiv:2408.07372v1 公告类型：新
摘要：解决了在有界区域内寻找局部稳定点过程统计量的期望值的问题。我们提出了一种自适应重要性抽样来解决这个问题。在我们的提议中，我们将重要性点过程限制为同质泊松点过程家族，这使我们能够快速生成重要性点过程的独立样本。通过应用交叉熵最小化方法找到重要性点过程的最佳强度。在所提出的方案中，函数的期望值和最佳强度以自适应方式迭代估计。我们表明所提出的估计量几乎肯定收敛到目标值，并证明了它的渐近正态性。我们解释了如何将所提出的方案应用于估计平稳成对交互点过程的强度。所提出的方案的性能与马尔可夫链蒙特卡罗模拟和完美抽样进行了数值比较。]]></description>
      <guid>https://arxiv.org/abs/2408.07372</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:46 GMT</pubDate>
    </item>
    </channel>
</rss>