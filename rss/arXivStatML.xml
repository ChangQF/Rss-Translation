<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Wed, 27 Dec 2023 06:17:19 GMT</lastBuildDate>
    <item>
      <title>随机观察的统计逆向学习问题。 （arXiv：2312.15341v1 [数学.ST]）</title>
      <link>http://arxiv.org/abs/2312.15341</link>
      <description><![CDATA[我们概述了统计反问题的最新进展
随机实验设计，涵盖线性和非线性逆
问题。研究了不同的正则化方案以产生鲁棒的
和稳定的解决方案。我们讨论谱正则化的最新结果
方法和投影正则化，探索这两种方法
希尔伯特量表的背景并提出新的见解，特别是在
通过投影进行正则化。此外，我们概述了最近的进展
使用凸惩罚进行正则化。收敛率分析为
概率意义上的样本量，在两者中产生极小极大率
期望和概率。为了实现这些结果，结构
利用复制核希尔伯特空间来建立极小极大速率
统计学习设置。我们详细说明了支撑这些的假设
我们证明的关键要素。最后我们演示一下这些方法的应用
药代动力学/药效学中非线性反问题的概念
（PK/PD）模型，其任务是预测药物浓度的变化
患者。
]]></description>
      <guid>http://arxiv.org/abs/2312.15341</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>短期大容量多 A(rmed)/B(andits) 测试。 （arXiv：2312.15356v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.15356</link>
      <description><![CDATA[现代平台利用随机实验来做出明智的决策
来自一组给定的项目（“治疗”）。作为一个特别具有挑战性的
在这种情况下，这些物品可能 (i) 大量到达，有数千件新物品
每小时释放的物品，并且（ii）寿命短，例如，由于
项目的瞬态性质或潜在的非平稳性推动平台
随着时间的推移，将同一个项目视为不同的副本。受此激励，我们
研究封装了关键的贝叶斯多重博弈强盗问题
多变量测试（或“多 A/B 测试”）问题的特征
大量的短期武器。在每一轮中，一组 $k$ 手臂到达，每个手臂
可用于 $w$ 轮。在不知道每只手臂的平均奖励的情况下，
学习者选择多组$n$手臂并立即观察他们的实现
奖励。我们的目标是尽量减少由于不知道平均回报而造成的损失，
对给定先验分布生成的实例进行平均。我们表明
当 $k = O(n^\rho)$ 对于某个常数 $\rho&gt;0$ 时，我们提出的策略是
$\tilde O(n^{-\min \{\rho, \frac 12 (1+\frac 1w)^{-1}\}})$ 损失
足够大的先验分布类别。我们通过以下方式补充这个结果
显示每项政策都会遭受 $\Omega (n^{-\min \{\rho, \frac 12\}})$ 损失
在同一类发行版上。我们进一步验证了其有效性
我们的政策是通过在{\em Glance}上进行的大规模现场实验来确定的，
内容卡服务平台正是面临上述挑战。一个简单的
我们的策略变体比平台当前推荐器的性能高出 4.32\%
占总时长和总点击次数的 7.48%。
]]></description>
      <guid>http://arxiv.org/abs/2312.15356</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>具有噪声结果的最优决策树。 （arXiv：2312.15357v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.15357</link>
      <description><![CDATA[在基于池的主动学习中，学习者会获得一个未标记的数据集，并且
旨在通过查询标签来有效地学习未知假设
数据点。这可以表述为经典的最优决策树
（ODT）问题：给定一组测试、一组假设和一个结果
每对检验和假设，我们的目标是找到一个低成本的检验
识别真实假设的过程（即决策树）。这
优化问题在以下假设下得到了广泛的研究：
每个测试都会产生确定性的结果。然而，在众多的应用中，
例如，临床试验，结果可能是不确定的，这使得
来自确定性设置的想法无效。在这项工作中，我们研究了
ODT 问题的基本变体，其中一些测试结果是有噪声的，
即使在噪声持续存在的更一般情况下，即重复一个
测试给出了相同的噪声输出。我们的近似算法提供
几乎是最好的保证，并且适用于一般情况
每个测试或每个假设都有大量嘈杂的结果，其中性能
以此数字不断降低。我们对我们的算法进行了数值评估
用于识别有毒化学品和学习线性分类器，并观察到
我们的算法的成本非常接近信息论的最小值。
]]></description>
      <guid>http://arxiv.org/abs/2312.15357</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>AdamL：一种结合损失函数的快速自适应梯度方法。 （arXiv：2312.15295v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.15295</link>
      <description><![CDATA[自适应一阶优化器是深度学习的基本工具，
尽管由于不均匀，它们可能会受到较差的概括性影响
梯度缩放。在这项工作中，我们提出了 AdamL，Adam 的一个新变体
优化器，考虑损失函数信息以获得
更好的泛化结果。我们提供充分的条件，共同
利用Polyak-Lojasiewicz不等式，保证AdamL的线性收敛。
作为我们分析的副产品，我们证明了类似的收敛特性
EAdam 和 AdaBelief 优化器。基准函数的实验结果
表明 AdamL 通常实现最快收敛或最低收敛
与 Adam、EAdam 和 AdaBelief 相比的目标函数值。这些
在考虑诸如此类的深度学习任务时，证实了优越的性能
作为训练卷积神经网络，训练生成对抗
使用普通卷积神经网络和长期短期网络
记忆网络。最后，对于普通卷积神经网络来说，
AdamL 从 Adam 的其他变体中脱颖而出，并且不需要手册
训练后期调整学习率。
]]></description>
      <guid>http://arxiv.org/abs/2312.15295</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>让我成为 BNN：根据预训练模型估计贝叶斯不确定性的简单策略。 （arXiv：2312.15297v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.15297</link>
      <description><![CDATA[深度神经网络 (DNN) 是各种计算机视觉的强大工具
任务，但他们经常难以可靠地量化不确定性 -
实际应用的关键要求。贝叶斯神经网络
(BNN) 具备不确定性估计能力，但无法扩展到大型 DNN
训练起来非常不稳定。为了应对这一挑战，我们引入了
适应性贝叶斯神经网络 (ABNN)，一种简单且可扩展的策略
以事后方式将 DNN 无缝转换为 BNN
计算和培训开销。 ABNN 保留了主要的预测
DNN 的特性，同时增强其不确定性量化能力
通过简单的 BNN 适应层（附加到归一化层）和
对预训练模型的微调步骤很少。我们进行广泛的实验
跨多个数据集进行图像分类和语义分割
任务，我们的结果表明 ABNN 达到了最先进的水平
无需通常与集成相关的计算预算的性能
方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.15297</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>有限内存的统计推断：一项调查。 （arXiv：2312.15225v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.15225</link>
      <description><![CDATA[各种形式的统计推断问题一直是
长达数十年的广泛研究的主题。大部分的努力都集中在
将行为描述为可用数量的函数
样本，很少关注内存限制对
表现。最近，后一个话题引起了人们的极大兴趣
工程和计算机科学文献。在这份调查报告中，我们尝试
回顾内存下统计推断的最新技术
几个典型问题的约束，包括假设检验，
参数估计和分布特性测试/估计。我们讨论
这个发展领域的主要成果，并通过确定反复出现的主题，
我们提取一些用于算法构建的基本构建块，如
以及下界推导的有用技术。
]]></description>
      <guid>http://arxiv.org/abs/2312.15225</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>定价的因果预测。 （arXiv：2312.15282v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.15282</link>
      <description><![CDATA[本文提出了一种定价中需求预测的新方法
语境。在这里，对价格之间的因果关系进行建模作为输入
需求变量至关重要，因为零售商的目标是在（利润）范围内设定价格
下游决策问题中的最优方式。我们的方法带来
将用于因果推理的双机器学习方法结合在一起
最先进的基于变压器的预测模型。在广泛的实证研究中
实验中，我们一方面表明我们的方法估计了因果关系
通过合成但真实的数据，在完全受控的环境中效果更好。
另一方面，我们在现实世界的数据上证明了我们的方法
在离策略设置中（即，当存在
定价政策的变化），而在政策上仅略有落后
环境。
]]></description>
      <guid>http://arxiv.org/abs/2312.15282</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>了解对比表示学习和分布外检测中的标准化。 （arXiv：2312.15288v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.15288</link>
      <description><![CDATA[对比表征学习已成为一种出色的方法
用于异常检测。在这项工作中，我们探索了 $\ell_2$-范数
对比特征及其在分布外检测中的应用。我们
提出了一种基于对比学习的简单方法，其中结合了
通过区分分布中的正常样本来获取分布外数据
对比层空间。我们的方法可以作为异常值灵活应用
暴露（OE）方法，其中分布外数据是一个巨大的集合
随机图像，或作为一种完全自我监督的学习方法，其中
分布外数据是通过应用分布转移自行生成的
转变。能够合并额外的分发外内容
样本为数据集提供了一个可行的解决方案，其中 AD 方法基于
对比学习通常表现不佳，例如航空图像或
显微镜图像。此外，通过学习到的高质量特征
对比学习持续提高 OE 场景中的性能，甚至
当可用的分布外数据集不够多样化时。我们的
大量的实验证明了我们提出的方法的优越性
各种场景，包括单模态和多模态设置，具有不同的
图像数据集。
]]></description>
      <guid>http://arxiv.org/abs/2312.15288</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>学习丰富的排名。 （arXiv：2312.15081v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.15081</link>
      <description><![CDATA[虽然排名的基础已经很完善，但是排名
文献主要集中于简单的单峰模型，例如这
Mallows 和 Plackett-Luce 模型，定义以
单一总订购。显式混合模型提供了一些工具
对多模式排名数据进行建模，尽管从数据中学习此类模型是
常常很困难。在这项工作中，我们贡献了上下文重复选择
（CRS）模型利用选择建模的最新进展来带来
自然的多模态和丰富的排名空间。我们提供严格的
模型下最大似然估计的理论保证
通过结构相关的尾部风险和预期风险界限。作为一个
副产品，我们还对预期风险提供了第一个严格限制
多项 Logit (MNL) 选择模型的最大似然估计量和
Plackett-Luce (PL) 排名模型，以及第一个尾部风险约束
PL排名模型。 CRS 模型显着优于现有方法
用于对各种设置中的真实世界排名数据进行建模，从赛车到
排名选择投票。
]]></description>
      <guid>http://arxiv.org/abs/2312.15081</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>关于量子极限学习机的基本方面。 (arXiv:2312.15124v1 [quant-ph])</title>
      <link>http://arxiv.org/abs/2312.15124</link>
      <description><![CDATA[量子极限学习机（QELM）已成为一种有前途的
量子机器学习框架。他们的吸引力在于丰富的功能
由量子基底动力学引起的图 - 量子储库 -
以及通过线性回归进行有效的测量后训练。在这里，我们
通过将 QELM 的预测分解为
傅里叶级数。我们证明可实现的傅里叶频率是确定的
由数据编码方案，而傅立叶系数取决于
水库和测量。值得注意的是，QELM 的表达能力是
从根本上限制了傅里叶频率的数量和
可观测量，而预测的复杂性取决于储层。作为
关于可扩展性的警告，我们确定了四个可能导致
随着系统规模的增长，可观测值呈指数浓度
（随机性、硬件噪声、纠缠和全局测量）并显示
这如何将 QELM 变成无用的与输入无关的预言机。我们的分析
阐明了 QELM 的潜力和基本局限性，并奠定了
为系统地探索其他量子储库系统奠定基础
机器学习任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.15124</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>通过反馈提高回声状态网络的性能。 （arXiv：2312.15141v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.15141</link>
      <description><![CDATA[使用非线性动力系统的油藏计算提供了
对于涉及复杂任务的神经网络来说，具有成本效益的替代方案
顺序数据处理、时间序列建模和系统识别。
回声状态网络（ESN），一种储层计算机，镜像神经网络
网络，但简化了训练。他们应用固定的、随机的线性变换
到内部状态，然后是非线性变化。这一过程在指导下
输入信号和线性回归，使系统适应目标
特征，减少计算需求。 ESN 的潜在缺点
是固定水库可能无法提供特定用途所需的复杂性
问题。当直接改变（训练）内部ESN时会重新引入
计算负担，可以通过以下方式实现间接修改
将某些输出重定向为输入。这种反馈会影响内部
储层状态，产生具有增强复杂性的 ESN，适用于更广泛的
挑战。在本文中，我们证明了通过喂食某些成分
通过输入将水库状态返回到网络中，我们可以极大地
提高给定 ESN 的性能。我们严格证明，对于任意
给定 ESN，反馈几乎总是会提高输出的准确性。为了
一组三个任务，每个任务代表不同的问题类别，我们发现
通过反馈，平均误差测量值减少了 $30\%-60\%$。
值得注意的是，反馈至少提供了与
将初始计算节点数量加倍，计算成本高昂
以及技术上具有挑战性的替代方案。这些结果表明
该反馈方案具有广泛的适用性和实质性的实用性。
]]></description>
      <guid>http://arxiv.org/abs/2312.15141</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>连续时间集合序列的概率建模。 （arXiv：2312.15045v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.15045</link>
      <description><![CDATA[神经标记时间点过程是对
连续时间事件统计参数模型的现有工具箱
数据。这些模型对于每个事件都关联的序列非常有用
单个项目（单一类型的事件或“标记”）——但这样的模型不是
适合每个事件都与一组相关联的实际情况
项目。在这项工作中，我们开发了一个用于建模集值的通用框架
连续时间数据，与任何基于强度的循环神经网络兼容
点过程模型。此外，我们开发了可以使用的推理方法
此类模型可以回答概率查询，例如“项目的概率
$A$ 在项目 $B$ 之前被观察到，”以序列历史为条件。计算
对于神经模型来说，此类查询的确切答案通常很棘手，因为
问题设置的连续时间性质和
每个事件的潜在结果的组合空间很大。讲话
为此，我们开发了一类用于查询的重要性采样方法
基于集合的序列并展示了数量级的改进
通过对四个真实世界进行系统实验，比直接采样的效率更高
数据集。我们还说明了如何使用该框架来执行模型
使用不涉及一步预测的可能性进行选择。
]]></description>
      <guid>http://arxiv.org/abs/2312.15045</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>通过预期自由能最小化的信息寻求多项式 NARX 模型预测控制。 （arXiv：2312.15046v1 [eess.SY]）</title>
      <link>http://arxiv.org/abs/2312.15046</link>
      <description><![CDATA[我们提出了一种自适应模型预测控制器，可以平衡驱动
系统达到目标状态并寻求信息丰富的系统观察
关于非线性自回归外生模型的参数。
控制器的目标函数源自预期自由能
函数并包含表达不确定性的信息论术语
模型参数和输出预测。实验说明了参数如何
不确定性影响控制目标并评估建议的控制器
用于钟摆摆动任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.15046</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>少数派博弈中的最优协调：强化学习的解决方案。 （arXiv：2312.14970v1 [physical.soc-ph]）</title>
      <link>http://arxiv.org/abs/2312.14970</link>
      <description><![CDATA[有效分配对于自然和人类社会都很重要
个人经常争夺有限的资源。少数派游戏或许是
最简单的模型，深入了解人类如何协调
资源利用率最大化。然而，该模型假设静态
先验提供的策略，未能捕获其适应性
自然。在这里，我们转向强化学习的范式，其中
个人的策略是通过评估过去的经验和
未来的奖励。具体来说，我们采用Q-learning算法，每个
玩家拥有一个 Q 表来指导他们的决策。我们揭示
当个体达到最优分配时，总体能够达到最优分配
珍惜过去的经历和未来的回报，
能够平衡 Q 表的利用和探索
随机行动。当个人倾向于使用时，最优分配就会被破坏
仅开发或仅探索，仅部分协调
甚至观察到反协调。机理分析表明，
中等水平的探索可以逃脱亚稳态周期的局部最小值
状态，并达到全局最小值的最优协调。
有趣的是，最佳协调是通过对称性破缺来强调的
行动偏好，近一半的人选择一方，而
另一半更喜欢另一半。最优协调的出现是
对人口规模和其他游戏参数具有鲁棒性。因此我们的工作
为少数派博弈提供了一个自然的解决方案，并深入了解了
一般的资源分配问题。此外，我们的工作表明
所提出的强化学习范式在破译许多方面的潜力
社会经济背景下的难题。
]]></description>
      <guid>http://arxiv.org/abs/2312.14970</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:13 GMT</pubDate>
    </item>
    <item>
      <title>联合 Q 学习：低通信成本的线性遗憾加速。 （arXiv：2312.15023v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.15023</link>
      <description><![CDATA[在本文中，我们考虑表格的联合强化学习
情景马尔可夫决策过程（MDP），其中，在一个协调下
中央服务器，多个代理协作探索环境并
在不共享原始数据的情况下学习最优策略。虽然线性加速
代理数量已达到某些指标，例如收敛性
率和样本复杂度，在类似的设置下，尚不清楚是否是
可以设计一种无模型算法来实现线性遗憾加速
沟通成本低。我们提出了两种联合 Q-Learning 算法，称为
分别为 FedQ-Hoeffding 和 FedQ-Bernstein，并表明
相应的总遗憾与它们相比实现了线性加速
当时间范围足够大时，单代理对应，而
通信成本与时间步总数成对数关系
$T$。这些结果依赖于事件触发的同步机制
代理和服务器，服务器时的新颖步长选择
聚合状态动作值的局部估计以形成全局
估计，以及一组新的集中不等式来限制总和
非鞅差异。这是第一个展示线性遗憾的作品
加速比和对数通信成本可以通过无模型来实现
联合强化学习中的算法。
]]></description>
      <guid>http://arxiv.org/abs/2312.15023</guid>
      <pubDate>Wed, 27 Dec 2023 06:17:13 GMT</pubDate>
    </item>
    </channel>
</rss>