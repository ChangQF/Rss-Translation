<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 06 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>具有线性相关数据的线性回归的渐近性</title>
      <link>https://arxiv.org/abs/2412.03702</link>
      <description><![CDATA[arXiv:2412.03702v1 公告类型：新
摘要：在本文中，我们研究了在协变量表现出线性依赖结构的环境中线性回归的渐近性，这与标准的独立性假设背道而驰。我们使用具有时空协方差的随机过程对协变量进行建模，并分析了高维比例制度下岭回归的性能，其中样本数量和特征维度成比例增长。证明了高斯普遍性定理，表明在用保持均值和协方差的高斯向量替换协变量的情况下，渐近性是不变的。接下来，利用随机矩阵理论的工具，我们推导出估计误差的精确表征。估计误差由涉及时空协方差矩阵的谱特性的不动点方程表征，从而实现高效计算。然后，我们研究了相关数据背景下的最佳正则化、过度参数化和双下降现象。模拟验证了我们的理论预测，揭示了依赖性如何影响估计误差和正则化参数的选择。]]></description>
      <guid>https://arxiv.org/abs/2412.03702</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从广义平稳随机过程学习网络</title>
      <link>https://arxiv.org/abs/2412.03768</link>
      <description><![CDATA[arXiv:2412.03768v1 公告类型：新
摘要：由潜在输入驱动的复杂网络系统在神经科学、金融和工程等领域很常见。这里的一个关键推理问题是从节点输出（势）中学习边缘连通性。我们专注于受稳态线性守恒定律控制的系统：$X_t = {L^{\ast}}Y_{t}$，其中 $X_t, Y_t \in \mathbb{R}^p$ 分别表示输入和势，$p \times p$ 拉普拉斯算子 $L^{\ast}$ 的稀疏模式对边缘结构进行编码。假设 $X_t$ 是具有已知谱密度矩阵的广义平稳随机过程，我们通过 $\ell_1$ 正则化的 Whittle 最大似然估计量 (MLE) 从 $Y_t$ 的时间相关样本中学习 $L^{\ast}$ 的支持。正则化对于在高维环境中学习大规模网络特别有用，其中网络大小 $p$ 大大超过样本数量 $n$。
我们表明 MLE 问题是严格凸的，允许唯一的解决方案。在新的相互不相干条件和 $(n, p, d)$ 的某些充分条件下，我们表明 ML 估计以高概率恢复 $L^\ast$ 的稀疏模式，其中 $d$ 是 $L^{\ast}$ 基础图的最大度。我们为 $L^\ast$ 提供了元素最大值、Frobenius 和算子范数的恢复保证。最后，我们通过对合成和基准数据集进行的几项模拟研究来补充我们的理论结果，包括工程系统（电力和水网络）以及来自神经系统（如人脑）的真实世界数据集。]]></description>
      <guid>https://arxiv.org/abs/2412.03768</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用异构块协方差模型进行社区检测</title>
      <link>https://arxiv.org/abs/2412.03780</link>
      <description><![CDATA[arXiv:2412.03780v1 公告类型：新
摘要：社区检测是根据对象的成对关系对其进行聚类的任务。大多数基于模型的社区检测方法，例如随机块模型及其变体，都是为具有二进制（是/否）边的网络设计的。在许多实际场景中，边通常具有连续的权重，跨越正值和负值，这反映了不同的连接级别。为了应对这一挑战，我们引入了异构块协方差模型 (HBCM)，该模型在协方差矩阵内定义了社区结构，其中边具有带符号的连续权重。此外，它在与社区内的其他对象建立连接时考虑了对象的异质性。提出了一种新的变分期望最大化算法来估计组成员身份。HBCM 提供了可证明的一致成员身份估计，并且在具有不同设置的数值模拟中观察到了其良好的性能。该模型应用于小鼠胚胎的单细胞 RNA-seq 数据集和股票价格数据集。本文的补充材料可以在线获取。]]></description>
      <guid>https://arxiv.org/abs/2412.03780</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有限维扩散图的表现如何？</title>
      <link>https://arxiv.org/abs/2412.03992</link>
      <description><![CDATA[arXiv:2412.03992v1 公告类型：新
摘要：在对子流形族 $\subset {\mathbb R}^D$ 的一组假设下，我们推导出一系列在有限维和几乎等距的扩散图 (DM) 之后仍然有效的几何属性，包括几乎均匀的密度、有限多项式近似和局部可达性。利用这些属性，我们对 DM 算法引入的嵌入误差建立了严格的界限，即 $O\left((\frac{\log n}{n})^{\frac{1}{8d+16}}\right)$。这些结果为理解 DM 在实际应用中的性能和可靠性提供了坚实的理论基础。]]></description>
      <guid>https://arxiv.org/abs/2412.03992</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>桥型估计器的路径优化及其应用</title>
      <link>https://arxiv.org/abs/2412.04047</link>
      <description><![CDATA[arXiv:2412.04047v1 公告类型：新
摘要：稀疏参数模型在统计学习中具有重要意义，通常通过正则化估计量进行分析。对于惩罚参数 $\lambda$ 的任何可能值，路径方法可以有效地计算惩罚估计量的完整解路径。在本文中，我们处理桥型问题的路径优化；即，我们感兴趣的是最小化损失函数，例如负对数似然或残差平方和，加上 $\ell^q$ 范数之和，其中 $q\in(0,1]$ 涉及自适应系数。对于某些损失函数，这种正则化渐近地实现了 oracle 属性（例如选择一致性）。然而，由于目标函数涉及非凸和不可微项，因此最小化问题在计算上具有挑战性。
本文的目的是应用一些源自非凸优化理论的通用算法，有效地计算具有多重惩罚的自适应桥接估计器的路径解。特别是，我们考虑了两种不同的方法：加速近端梯度下降和块交替优化。讨论了这些算法的收敛性和路径一致性。为了评估我们的方法，我们将这些算法应用于在离散时间观察到的扩散过程的惩罚估计。后者代表了时间相关数据统计领域的一个最新研究课题。]]></description>
      <guid>https://arxiv.org/abs/2412.04047</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型基准的脆弱性：它们能准确反映真正的 LLM 性能吗？</title>
      <link>https://arxiv.org/abs/2412.03597</link>
      <description><![CDATA[arXiv:2412.03597v1 公告类型：交叉 
摘要：追求大型语言模型 (LLM) 中的排行榜排名产生了一个基本悖论：模型在标准化测试中表现出色，但未能展示真正的语言理解和适应性。我们对 NLP 评估框架的系统分析揭示了整个评估范围内普遍存在的漏洞，从基本指标到复杂的基准，如 GLUE 和 MMLU。这些漏洞通过基准利用、数据集污染和评估偏差表现出来，造成了对语言理解能力进步的错误看法。通过对当代评估方法的广泛审查，我们发现静态基准设计、人工评估协议和 LLM-as-judge 框架存在重大局限性，所有这些都损害了当前绩效评估的可靠性。随着 LLM 能力的发展和现有基准变得多余，我们为抵抗操纵、最大限度地减少数据污染和评估特定领域任务的新评估方法奠定了基础。这需要动态调整的框架，解决当前的限制并更准确地反映 LLM 性能。]]></description>
      <guid>https://arxiv.org/abs/2412.03597</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在基于语言的代理系统上正确进行语义反向传播</title>
      <link>https://arxiv.org/abs/2412.03624</link>
      <description><![CDATA[arXiv:2412.03624v1 公告类型：交叉 
摘要：基于语言的代理系统近年来显示出巨大的前景，从解决小规模研究问题过渡到部署到具有挑战性的现实任务中。然而，优化这些系统通常需要大量的人工。最近的研究表明，这些系统可以表示为计算图，从而实现自动优化。尽管取得了这些进展，但目前基于图的代理系统优化 (GASO) 的大多数努力都未能在系统输出反馈的情况下正确地将反馈分配给系统组件。为了应对这一挑战，我们用语义梯度形式化了语义反向传播的概念——这是一种通过利用具有共同后继的节点之间的关系来协调几种关键优化技术的概括，包括反向模式自动微分和最新​​的 TextGrad。这是一种计算方向信息的方法，用于计算代理系统每个组件的更改如何改善系统的输出。为了使用这些梯度，我们提出了一种称为语义梯度下降的方法，它使我们能够有效地解决 GASO。我们在 BIG-Bench Hard 和 GSM8K 上的结果表明，我们的方法优于现有的解决 GASO 问题的最先进的方法。对 LIAR 数据集的详细消融研究表明了我们方法的简约性。我们的实现的完整副本可在 https://github.com/HishamAlyahya/semantic_backprop 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2412.03624</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Hartree-Fock 理论中的电子动力学非线性最优控制</title>
      <link>https://arxiv.org/abs/2412.03672</link>
      <description><![CDATA[arXiv:2412.03672v1 公告类型：交叉 
摘要：考虑确定最佳施加电场以将分子从初始状态驱动到期望目标状态的问题。对于即使是中等大小的分子，直接使用精确的运动方程——时间相关的薛定谔方程 (TDSE)——解决这个问题在数值上也是难以解决的。我们在时间相关的 Hartree-Fock (TDHF) 理论中提出了这个问题的解决方案，这是 TDSE 的平均场近似。最优性的定义是最小化总控制力，同时最大化期望和实现的目标状态之间的重叠。我们将这个问题定义为受非线性 TDHF 方程约束的优化问题；我们使用信任区域优化来解决它，梯度通过定制的伴随状态方法计算。对于三个分子系统，我们表明，通过非常小的控制神经网络参数化，我们的方法可以得到在可接受的约束和公差内实现期望目标的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2412.03672</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过学习梯度图实现不受人口统计学影响的公平性</title>
      <link>https://arxiv.org/abs/2412.03706</link>
      <description><![CDATA[arXiv:2412.03706v1 公告类型：交叉 
摘要：众所周知，机器学习系统容易对某些人口统计群体做出有偏见的预测，从而导致算法公平性问题。由于隐私问题和数据质量问题，某些人口统计信息可能无法在训练数据中使用，而不同人口统计数据的复杂相互作用可能导致大量未知的少数群体亚群，这些都限制了群体公平性的适用性。许多现有的关于没有人口统计数据的公平性的研究都假设群体和特征之间存在相关性。然而，我们认为模型梯度对于没有人口统计数据的公平性也很有价值。在本文中，我们表明梯度和群体之间的相关性有助于识别和提高群体公平性。利用对抗加权架构，我们构建了一个图，其中具有相似梯度的样本连接在一起，并从中学习不同样本的权重。与将特征和标签中的组聚类为代理敏感属性的代理分组方法不同，我们的方法利用图结构作为软分组机制，这对噪声具有更强的鲁棒性。结果表明，我们的方法对噪声具有很强的鲁棒性，并且可以在整体准确率不会降低太多的情况下显著提高公平性。]]></description>
      <guid>https://arxiv.org/abs/2412.03706</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>树集成中重新分类的最佳概率特征偏移</title>
      <link>https://arxiv.org/abs/2412.03722</link>
      <description><![CDATA[arXiv:2412.03722v1 公告类型：交叉 
摘要：在本文中，我们提供了一种基于数学优化的新型方法，通过树集合分类规则对给定观察的特征进行扰动，将其重新分类到某个所需类别。该方法基于以下事实：观察达到所需类别的最可行变化并不总是与目标类别的最近距离点（在特征空间中）相一致；个体在少数特征上付出努力以达到所需类别；并且每个个体都具有将其每个特征更改为给定值的概率，这决定了改变为目标类别的总体概率。总而言之，我们提供了不同的方法来查找个体必须付出努力才能最大化达到目标类别的概率的特征。我们的方法还允许我们对树集合中最重要的特征进行排序。所提出的方法在真实数据集上进行了测试，验证了该建议。]]></description>
      <guid>https://arxiv.org/abs/2412.03722</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Hyper：强化学习中的超参数稳健高效探索</title>
      <link>https://arxiv.org/abs/2412.03767</link>
      <description><![CDATA[arXiv:2412.03767v1 公告类型：交叉 
摘要：探索和利用困境对强化学习 (RL) 提出了重大挑战。最近，基于好奇心的探索方法在解决困难探索问题方面取得了巨大成功。然而，它们需要在不同的环境中进行广泛的超参数调整，这严重限制了这类方法的适用性和可访问性。在本文中，我们通过分析代理行为来描述这个问题，得出选择合适的超参数的基本困难。然后，我们确定了当代理带着好奇心学习时优化的难度和不稳定性。我们提出了我们的方法，超参数稳健探索 (\textbf{Hyper})，它通过有效地规范探索的访问和解耦利用以确保稳定的训练，从而大大缓解了这个问题。我们从理论上证明了 \textbf{Hyper} 在函数近似设置下是可证明有效的，并通过经验证明了它在各种环境中的吸引力和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2412.03767</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习研究人员所说的“可重复”是什么意思？</title>
      <link>https://arxiv.org/abs/2412.03854</link>
      <description><![CDATA[arXiv:2412.03854v1 公告类型：交叉 
摘要：人工智能 (AI) 和机器学习 (ML) 正在进入“可重复性危机”的担忧在过去几年中引发了大量研究。然而，对于每篇论文，人们通常不清楚“可重复性”是什么意思。我们的工作试图澄清整个社区所展示的“可重复性”的范围。为此，我们建议将研究细化到八个一般主题领域。从这个角度来看，我们发现这些领域中的每一个都包含许多没有宣传自己是关于“可重复性”的作品，部分原因是它们可以追溯到几十年前，当时这个问题还没有引起更广泛的关注。]]></description>
      <guid>https://arxiv.org/abs/2412.03854</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过以数据为中心的视角实现从弱到强的泛化</title>
      <link>https://arxiv.org/abs/2412.03881</link>
      <description><![CDATA[arXiv:2412.03881v1 公告类型：交叉 
摘要：弱到强泛化现象是重要机器学习应用的驱动力，包括高度数据高效的学习以及最近的超比对。虽然数十年的研究已经产生了许多产生强大经验性能的算法，但对哪些数据方面能够实现弱到强泛化的理解却尚未得到充分研究。我们提出了一种简单的以数据为中心的机制来表征弱到强泛化：重叠密度。直观地说，泛化跟踪包含重叠的点的数量，即简单模式（可通过弱模型学习）和具有挑战性的模式（只能通过更强的模型学习），因为对于这样的点，弱预测可用于通过更强的模型学习具有挑战性的模式。我们提供了一种实用的重叠检测算法来在数据集中找到这样的点，并利用它们在多个数据源中学习在寻求最大化重叠密度时要查询哪些数据，从而增强弱到强的泛化。我们提出了一个理论结果，表明泛化效益是我们数据选择算法的重叠密度和遗憾界限的函数。从经验上讲，我们在各种设置上验证了该机制和重叠检测算法。]]></description>
      <guid>https://arxiv.org/abs/2412.03881</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>采用基于梯度的方法的统一视图进行最终模型数据归因</title>
      <link>https://arxiv.org/abs/2412.03906</link>
      <description><![CDATA[arXiv:2412.03906v1 公告类型：交叉
摘要：训练数据归因 (TDA) 是将模型行为归因于训练数据中的元素的任务。本文提请关注一种常见的设置，即人们只能访问最终训练的模型，而不能访问训练算法或来自训练的中间信息。为了在这种“仅限最终模型”的设置中作为 TDA 的黄金标准，我们建议进行进一步训练，并进行适当的调整和平均，以测量给定模型对训练实例的敏感度。然后，我们通过展示它们都以不同的方式近似进一步训练的黄金标准，统一了现有的基于梯度的 TDA 方法。我们通过经验研究了这些基于梯度的近似对表格、图像和文本数据集和模型的进一步训练的质量。我们发现一阶方法的近似质量有时很高，但随着进一步训练的量而下降。相比之下，影响函数方法给出的近似值更稳定，但质量却出奇地低。]]></description>
      <guid>https://arxiv.org/abs/2412.03906</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>事后贝叶斯深度学习的固定均值高斯过程</title>
      <link>https://arxiv.org/abs/2412.04177</link>
      <description><![CDATA[arXiv:2412.04177v1 公告类型：交叉 
摘要：最近，人们对对预训练深度神经网络 (DNN) 的预测进行事后不确定性估计的兴趣日益浓厚。通过反向传播给定一个预训练的 DNN，这些方法通过添加输出置信度度量（例如误差线）来增强原始网络，而不会影响其初始准确性。在这种情况下，我们引入了一种新型稀疏变分高斯过程 (GP) 系列，其中使用通用核时后验均值固定为任何连续函数。具体而言，我们将这个 GP 的均值固定为预训练 DNN 的输出，使我们的方法能够有效地拟合 GP 的预测方差以估计 DNN 预测不确定性。我们的方法利用变分推理 (VI) 进行有效的随机优化，训练成本与训练点的数量无关，可以有效地扩展到 ImageNet 等大型数据集。所提出的方法称为固定均值 GP (FMGP)，与架构无关，仅依靠预训练模型的输出来调整预测方差。实验结果表明，与最先进的方法相比，FMGP 可以提高不确定性估计和计算效率。]]></description>
      <guid>https://arxiv.org/abs/2412.04177</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>