<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 20 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>半随机块模型谱算法的鲁棒性</title>
      <link>https://arxiv.org/abs/2412.14315</link>
      <description><![CDATA[arXiv:2412.14315v1 公告类型：新
摘要：在图二分问题中，我们给出了一个图 $G$，其中有两个大小相等的未标记社区，目标是恢复这些社区中的顶点。一种流行的启发式方法称为谱聚类，它基于对应于 $G$ 的拉普拉斯算子的第二小特征值的特征向量输出估计的社区分配。可以证明谱算法可以恢复由某些概率模型（例如随机块模型 (SBM)）生成的图的聚类结构。然而，众所周知，谱聚类对模型错误指定不具有鲁棒性。基于半定规划的技术已被证明更为稳健，但它们会产生大量的计算开销。
在这项工作中，我们研究了谱算法对半随机对手的鲁棒性。非正式地讲，半随机对手可以“有益地”以与真实解决方案一致的方式更改模型的规范。我们的半随机对手尤其可以在集群内添加边或增加边出现在集群内的概率。半随机对手是一种有用的工具，可以确定算法对输入的统计假设的过度拟合程度。
从积极的一面来看，我们确定了半随机对手的类别，在这些类别下，使用_非规范化_拉普拉斯算子的光谱二分法具有很强的一致性，即，它准确地恢复了植入的分区。从消极的一面来看，我们表明，在这些类别中，使用_规范化_拉普拉斯算子的光谱二分法输出的分区会在恒定的顶点分数上产生分类错误。最后，我们展示了补充我们理论发现的数值实验。]]></description>
      <guid>https://arxiv.org/abs/2412.14315</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有相互信息和支持点的统计欠采样</title>
      <link>https://arxiv.org/abs/2412.14527</link>
      <description><![CDATA[arXiv:2412.14527v1 公告类型：新
摘要：大型数据集中的类别不平衡和分布差异对分类任务机器学习提出了重大挑战，通常会导致模型出现偏差，少数类别的预测性能较差。这项工作介绍了两种新颖的欠采样方法：基于互信息的分层简单随机抽样和支持点优化。这些方法优先选择代表性数据，有效地最大限度地减少信息丢失。跨多个分类任务的实证结果表明，我们的方法优于传统的欠采样技术，实现了更高的平衡分类精度。这些发现凸显了将统计概念与机器学习相结合以解决实际应用中类别不平衡问题的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.14527</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从点到概率梯度提升，用于索赔频率和严重程度预测</title>
      <link>https://arxiv.org/abs/2412.14916</link>
      <description><![CDATA[arXiv:2412.14916v1 公告类型：新
摘要：决策树算法的梯度提升在精算应用中的应用越来越广泛，因为它们比传统的广义线性模型表现出更好的预测性能。第一个梯度提升机算法存在许多改进和复杂化。我们以统一的符号表示并对比了所有现有的点和概率梯度提升决策树算法：GBM、XGBoost、DART、LightGBM、CatBoost、EGBM、PGBM、XGBoostLSS、循环 GBM 和 NGBoost。在这项全面的数值研究中，我们在五个公开的索赔频率和严重程度数据集上比较了它们的性能，这些数据集的大小不同，包含不同数量的（高基数）分类变量。我们解释了如何使用频率模型中的提升来处理不同的风险暴露。我们根据计算效率、预测性能和模型充分性对算法进行了比较。 LightGBM 和 XGBoostLSS 在计算效率方面胜出。与所考虑的黑盒算法相比，完全可解释的 EGBM 实现了具有竞争力的预测性能。我们发现模型充分性和预测准确性之间没有权衡：两者可以同时实现。]]></description>
      <guid>https://arxiv.org/abs/2412.14916</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FedSTaS：实现高效联邦学习的客户端分层和客户端级别采样</title>
      <link>https://arxiv.org/abs/2412.14226</link>
      <description><![CDATA[arXiv:2412.14226v1 公告类型：交叉 
摘要：联邦学习 (FL) 是一种机器学习方法，涉及以隐私保护的方式在多个分散客户端之间协作训练全局模型。引入了几种 FL 方法来处理通信效率低下的问题，但没有解决如何有效地以隐私保护的方式对每轮参与的客户端进行采样。在本文中，我们提出了 \textit{FedSTaS}，这是一种受 \textit{FedSTS} 和 \textit{FedSampling} 启发的客户端和数据级采样方法。在每个联邦学习轮次中，\textit{FedSTaS} 根据客户端的压缩梯度对其进行分层，使用最佳 Neyman 分配重新分配要采样的客户端数量，并使用数据统一采样策略从每个参与客户端采样本地数据。在三个数据集上的实验表明，在固定数量的训练轮次内，\textit{FedSTaS} 可以获得比 \textit{FedSTS} 更高的准确率。]]></description>
      <guid>https://arxiv.org/abs/2412.14226</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非凸和随机优化的投影梯度法：新的复杂性和自动调节的步长</title>
      <link>https://arxiv.org/abs/2412.14291</link>
      <description><![CDATA[arXiv:2412.14291v1 公告类型：交叉 
摘要：我们提出了一种新的投影梯度 (PG) 方法，用于最小化凸紧集上的平滑但不一定是凸函数。我们首先对“原始” PG 方法进行新颖的分析，实现了寻找问题近似驻点的最著名迭代复杂度。然后，我们开发了一种“自动调节”投影梯度 (AC-PG) 变体，该变体实现了相同的迭代复杂度，而无需输入梯度的 Lipschitz 常数或任何线搜索过程。关键思想是使用从先前迭代中收集的一阶信息来估计 Lipschitz 常数，并表明可以适当控制因低估 Lipschitz 常数而导致的误差。然后，我们将 PG 方法推广到随机设置，通过提出随机投影梯度 (SPG) 方法和方差减小随机梯度 (VR-SPG) 方法，在不同的 oracle 设置中实现新的复杂度界限。我们还为这两种随机 PG 方法提出了自动调节的步长策略，并建立了可比的收敛保证。]]></description>
      <guid>https://arxiv.org/abs/2412.14291</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概念漂移下的分布稳健策略学习</title>
      <link>https://arxiv.org/abs/2412.14297</link>
      <description><![CDATA[arXiv:2412.14297v1 公告类型：交叉 
摘要：分布稳健策略学习旨在找到一种在最坏情况分布偏移下表现良好的策略，但现有的大多数稳健策略学习方法都考虑了协变量和结果的最坏情况联合分布。当我们有更多关于分布偏移来源的信息时，联合建模策略可能会不必要地保守。本文研究了一个更细微的问题——概念漂移下的稳健策略学习，此时只有结果和协变量之间的条件关系会发生变化。为此，我们首先提供一个双稳健估计量，用于评估一组扰动条件分布下给定策略的最坏情况平均奖励。我们表明，即使以低于根 $n$ 的速率估计干扰参数，策略值估计量也具有渐近正态性。然后，我们提出了一种学习算法，该算法输出在给定策略类 $\Pi$ 内最大化估计策略值的策略，并表明所提算法的次优性差距为 $\kappa(\Pi)n^{-1/2}$ 阶，其中 $\kappa(\Pi)$ 是 Hamming 距离下 $\Pi$ 的熵积分，$n$ 是样本大小。提供了匹配的下限以显示速率的最优性。所提出的方法已在数值研究中实施和评估，与现有基准相比显示出显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2412.14297</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混沌和机器学习动力系统的集合卡尔曼滤波器的长期准确性</title>
      <link>https://arxiv.org/abs/2412.14318</link>
      <description><![CDATA[arXiv:2412.14318v1 公告类型：交叉 
摘要：滤波涉及从部分和噪声观测中在线估计动态系统的状态。在状态为高维的应用中，集合卡尔曼滤波器通常是首选方法。本文建立了集合卡尔曼滤波器的长期精度。我们介绍了动力学和观测条件，在这些条件下估计误差在长期范围内保持较小。我们的理论涵盖了一类广泛的部分观测混沌动力学系统，其中包括 Navier-Stokes 方程和 Lorenz 模型。此外，我们证明了具有替代动力学的集合卡尔曼滤波器的长期精度，从而验证了机器学习预测模型在集合数据同化中的使用。]]></description>
      <guid>https://arxiv.org/abs/2412.14318</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>条件群对称性的随机化检验</title>
      <link>https://arxiv.org/abs/2412.14391</link>
      <description><![CDATA[arXiv:2412.14391v1 公告类型：交叉 
摘要：对称性在科学、机器学习和统计学中起着核心作用。虽然对群体分布不变性的统计检验历史悠久，但文献中却没有对等方差或条件不变性形式的条件对称性进行检验。这项工作开启了在指定局部紧群作用下对条件分布的对称性（不变性或等方差）进行非参数随机化检验的研究。我们开发了一个具有有限样本 I 类错误控制的随机化测试的通用框架，并使用核方法实施具有有限样本功率下限的测试。我们还描述并实现了测试的近似版本，这些版本是渐近一致的。我们在合成示例上对它们的属性进行了实证研究，并将其应用于高能粒子物理中两个问题的对称性测试。]]></description>
      <guid>https://arxiv.org/abs/2412.14391</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用最佳传输距离比较嘈杂的神经群体动态</title>
      <link>https://arxiv.org/abs/2412.14421</link>
      <description><![CDATA[arXiv:2412.14421v1 公告类型：交叉 
摘要：生物和人工神经系统形成高维神经表征，支撑其计算能力。量化神经表征中的几何相似性的方法已成为识别可能在神经系统之间共享的计算原理的流行工具。这些方法通常假设神经反应是确定性和静态的。然而，生物系统和一些人工系统的响应是嘈杂的并且随着时间的推移而动态展开。此外，这些特性会对系统的计算能力产生重大影响。在这里，我们证明现有的指标无法捕捉具有嘈杂动态响应的神经系统之间的关键差异。然后，我们提出了一个用于比较嘈杂神经轨迹几何形状的度量标准，该度量标准可以推导出高斯过程之间的最佳传输距离。我们使用该度量标准来比较运动系统不同区域的神经响应模型，并比较文本到图像合成的潜在扩散模型的动态。]]></description>
      <guid>https://arxiv.org/abs/2412.14421</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>线性模型分布外泛化中的良性过拟合</title>
      <link>https://arxiv.org/abs/2412.14474</link>
      <description><![CDATA[arXiv:2412.14474v1 公告类型：交叉 
摘要：良性过拟合是指过度参数化的模型完美拟合训练数据（包括数据中的噪声），但仍能很好地推广到看不见的测试数据的现象。虽然先前的工作在分布内设置下对这种现象提供了一些理论理解，但现代机器学习通常在更具挑战性的分布外 (OOD) 机制下运行，其中目标（测试）分布可能与源（训练）分布有很大不同。在这项工作中，我们通过关注协变量偏移下过度参数化线性模型的基本设置，迈出了理解 OOD 机制中良性过拟合的第一步。我们提供非渐近保证，证明即使在 OOD 机制下，当目标协方差满足某些结构条件时，标准岭回归中也会发生良性过拟合。我们确定了几个与源和目标协方差有关的重要量，它们决定了 OOD 泛化的性能。我们的结果是准确的，在专门针对每种设置时，可以证明恢复先前的分布内良性过拟合保证 [Tsigler and Bartlett, 2023]，以及参数不足的 OOD 保证 [Ge et al., 2024]。此外，我们还为更一般的目标协方差矩阵系列提供了理论结果，其中标准岭回归仅实现了超额风险的缓慢统计速率 $O(1/\sqrt{n})$，而主成分回归 (PCR) 保证实现快速速率 $O(1/n)$，其中 $n$ 是样本数。]]></description>
      <guid>https://arxiv.org/abs/2412.14474</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用解缠结变分图自动编码器对网络观测数据进行治疗效果评估</title>
      <link>https://arxiv.org/abs/2412.14497</link>
      <description><![CDATA[arXiv:2412.14497v1 公告类型：交叉 
摘要：从观察数据估计个体治疗效果 (ITE) 已在各个领域引起越来越多的关注，其中一个关键挑战是识别影响治疗和结果的潜在混杂因素。网络化观察数据通过利用网络信息推断潜在混杂因素，为解决此问题提供了新的机会。然而，大多数现有方法假设观察到的变量和网络信息仅作为潜在混杂因素的代理变量，这在实践中往往失败，因为有些变量影响治疗但不影响结果，反之亦然。解缠表征学习的最新进展将潜在因素解缠为工具、混杂和调整因素，为 ITE 估计带来了希望。在此基础上，我们提出了一种新型解缠变分图自动编码器，它学习解缠因子以对网络化观察数据进行治疗效果估计。我们的图编码器使用希尔伯特-施密特独立性标准进一步确保因子独立性。对来自现实世界社交网络的两个半合成数据集和一个合成数据集进行的大量实验表明，我们的方法达到了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.14497</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>噪声高维张量估计中的尖峰置换恢复</title>
      <link>https://arxiv.org/abs/2412.14650</link>
      <description><![CDATA[arXiv:2412.14650v1 公告类型：交叉 
摘要：我们研究多尖峰张量问题的高维梯度流动力学，其目标是从嘈杂的高斯张量观测中估计 $r$ 个未知信号向量（尖峰）。具体来说，我们分析最大似然估计程序，该程序涉及优化高度非凸的随机函数。我们确定梯度流有效恢复所有尖峰所需的样本复杂度，而不对信噪比 (SNR) 的分离施加任何假设。更准确地说，我们的结果提供了保证恢复尖峰所需的样本复杂度，直至置换。我们的工作建立在我们的配套论文 [Ben Arous, Gerbelot, Piccolo 2024] 的基础上，该论文研究了朗之万动力学并确定了确保精确恢复尖峰（恢复的置换与身份匹配）所需的 SNR 的样本复杂度和分离条件。在恢复过程中，估计量和隐藏向量之间的相关性会按顺序增加。这些相关性变得显著的顺序取决于它们的初始值和相应的 SNR，这最终决定了恢复的尖峰的排列。]]></description>
      <guid>https://arxiv.org/abs/2412.14650</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭开不确定性的面纱：深入研究多模态大型语言模型的校准和性能</title>
      <link>https://arxiv.org/abs/2412.14660</link>
      <description><![CDATA[arXiv:2412.14660v1 公告类型：交叉 
摘要：多模态大型语言模型 (MLLM) 将视觉和文本数据结合起来，用于图像字幕和视觉问答等任务。正确的不确定性校准对于在医疗保健和自动驾驶等领域的可靠使用至关重要，但具有挑战性。本文研究了代表性的 MLLM，重点关注它们在各种场景中的校准，包括视觉微调之前和之后，以及基础 LLM 的多模态训练之前和之后。我们观察到它们的性能存在校准误差，同时，这些场景中的校准没有显着差异。我们还强调了文本和图像之间的不确定性有何不同，以及它们的集成如何影响整体不确定性。为了更好地理解 MLLM 的校准误差及其自我评估不确定性的能力，我们构建了 IDK（我不知道）数据集，这是评估它们如何处理未知数的关键。我们的研究结果表明，MLLM 倾向于给出答案而不是承认不确定性，但这种自我评估会随着适当的及时调整而得到改善。最后，为了校准 MLLM 并提高模型可靠性，我们提出了温度缩放和迭代及时优化等技术。我们的结果为改进 MLLM 以在多模态应用中有效和负责任地部署提供了见解。代码和 IDK 数据集：\href{https://github.com/hfutml/Calibration-MLLM}{https://github.com/hfutml/Calibration-MLLM}。]]></description>
      <guid>https://arxiv.org/abs/2412.14660</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解释量子机器学习的机会和局限性</title>
      <link>https://arxiv.org/abs/2412.14753</link>
      <description><![CDATA[arXiv:2412.14753v1 公告类型：交叉
摘要：许多机器学习模型的共同特征是，通常很难理解和解释是什么导致模型产生给定的输出。虽然神经网络的可解释性在过去几年一直是一个活跃的研究领域，但人们对量子机器学习模型的了解却相对较少。尽管最近有一些研究分析了可解释性的某些具体方面，但到目前为止，对于量子学习模型在可解释性方面可以期待什么，还没有明确的宏观视角。在这项工作中，我们通过确定这个方向有希望的研究途径并列出预期的未来结果来解决这个问题。我们还提出了两种专门为量子机器学习模型设计的解释方法，据我们所知，这是同类方法中的首创。除了对该领域的预览之外，我们还比较了现有和新颖的方法来解释量子学习模型的预测。通过研究量子机器学习中的可解释性，我们可以为该领域的可持续发展做出贡献，防止未来出现信任问题。]]></description>
      <guid>https://arxiv.org/abs/2412.14753</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用贝叶斯加性回归树处理不可忽略缺失数据的联合模型：应用于叶片光合性状数据</title>
      <link>https://arxiv.org/abs/2412.14946</link>
      <description><![CDATA[arXiv:2412.14946v1 公告类型：交叉 
摘要：处理缺失数据对预测分析提出了重大挑战，当对缺失数据过程做出过于简单的假设时，往往会导致有偏见的结论。在数据不是随机缺失（MNAR）的情况下，联合建模数据和缺失数据指标至关重要。受实际数据应用的启发，该应用具有与叶片光合特性和几个环境协变量相关的部分缺失的多变量结果，我们提出了两种在选择模型框架下处理响应变量缺失数据的方法，适合恢复各种缺失机制。这两种方法都使用贝叶斯加性回归树（BART）的多变量扩展来灵活地对结果进行建模。第一种方法同时使用 probit 回归模型来联合建模缺失。在缺失和数据之间的关系更复杂或非线性的情况下，我们提出了第二种方法，使用 probit BART 模型来表征缺失数据过程，从而同时采用两个 BART 模型。两种模型都能有效处理可忽略的协变量缺失值。与现有的缺失数据方法相比，这两种模型的有效性已通过大量模拟（单变量和多变量设置）以及上述对叶片光合特性数据的应用得到证实。]]></description>
      <guid>https://arxiv.org/abs/2412.14946</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>