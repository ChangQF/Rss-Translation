<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Mon, 08 Jan 2024 06:18:05 GMT</lastBuildDate>
    <item>
      <title>分层随机平滑。 （arXiv：2310.16221v3 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2310.16221</link>
      <description><![CDATA[现实世界的数据很复杂，通常由可
分解为多个实体（例如图像分解为像素，图形分解为
互连的节点）。随机平滑是一个强大的框架
模型可以证明对输入的微小变化具有鲁棒性 - 通过保证
之前随机添加噪声时多数投票的稳健性
分类。然而，通过随机化来证明如此复杂的数据的稳健性
当对手不任意扰乱整个系统时，平滑就具有挑战性
对象（例如图像），但仅是其实体的子集（例如像素）。作为一个
解决方案，我们引入分层随机平滑：我们部分平滑
对象通过仅在其随机选择的子集上添加随机噪声
实体。通过以比现有方法更有针对性的方式添加噪声，我们
在保持高精度的同时获得更强的鲁棒性保证。我们
使用不同的噪声分布初始化分层平滑，
为离散和连续域产生新颖的鲁棒性证书。我们
实验证明图像中分层平滑的重要性
和节点分类，它产生卓越的鲁棒性和准确性
权衡。总的来说，分层平滑是一个重要的贡献
面向模型 - 可证明对扰动具有鲁棒性
准确的。
]]></description>
      <guid>http://arxiv.org/abs/2310.16221</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:04 GMT</pubDate>
    </item>
    <item>
      <title>注释敏感性：训练数据收集方法影响模型性能。 （arXiv：2311.14212v2 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2311.14212</link>
      <description><![CDATA[当从人类注释者那里收集训练数据时，
注释工具、给注释者的指示、
注释者的特征及其交互会影响训练
数据。这项研究表明，在创建一个
注释工具也会影响根据结果训练的模型
注释。我们引入术语注释敏感性来指代
注释数据收集方法对注释本身的影响以及
关于下游模型的性能和预测。我们收集仇恨的注释
注释的五个实验条件下的言语和攻击性语言
仪器，随机分配注释器到条件。然后我们微调 BERT
在五个结果数据集上建立模型并评估模型性能
每个条件的保留部分。我们发现之间存在很大差异
1) 仇恨言论/攻击性语言注释的比例的条件，
2) 模型性能，3) 模型预测，4) 模型学习曲线。我们的
结果强调了注释工具所发挥的关键作用
在机器学习文献中很少受到关注。我们呼吁
关于仪器如何以及为何影响注释的额外研究
为仪器设计最佳实践的发展提供信息。
]]></description>
      <guid>http://arxiv.org/abs/2311.14212</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:04 GMT</pubDate>
    </item>
    <item>
      <title>离散裂缝网络模拟存在固有随机性的敏感性分析。 （arXiv：2312.04722v2 [stat.AP] 已更新）</title>
      <link>http://arxiv.org/abs/2312.04722</link>
      <description><![CDATA[大规模离散裂缝网络 (DFN) 模拟器是以下领域的标准配置：
自直接以来涉及粒子地下传输的研究
对现实世界地下裂缝网络的观察通常是
不可行的。虽然这些模拟器已经在多个领域取得了巨大的成功
工程应用，对感兴趣数量 (QoI) 的估计 - 例如
粒子到达系统边缘的突破时间 - 遭受
两种不同类型的不确定性。 DFN 模拟器的运行需要几个
要设置的参数值决定裂缝的位置和大小，
裂缝密度和系统的整体渗透率；
正确参数选择的不确定性将导致一定程度的
QoI 的不确定性，称为认知不确定性。此外，由于 DFN
模拟器依靠随机过程来放置裂缝并控制流动，
了解这种随机性如何影响 QoI 需要多次运行
模拟器在不同的随机种子。 QoI 的不确定性归因于
同一随机过程的不同实现（即不同的种子）导致
第二种类型的不确定性，称为任意不确定性。在本文中，
我们进行敏感性分析，直接归因于不确定性
在 QoI 中观察到每个输入参数的认知不确定性
到任意的不确定性。我们做出了多种设计选择来处理
在 DFN 模拟器中观察到异方差性，其中任意不确定性
不同输入的变化，因为质量制定了几个标准
统计方法不可接受。除了输入的具体要点之外
变量对 DFN 模拟器的不确定性影响最大，这是一个主要贡献
本文介绍了一个统计上严格的工作流程
描述 DFN 流动模拟中的不确定性
异方差性。
]]></description>
      <guid>http://arxiv.org/abs/2312.04722</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:04 GMT</pubDate>
    </item>
    <item>
      <title>针对弱或无效仪器的鲁棒性：利用机器学习探索非线性治疗模型。 （arXiv：2203.12808v4 [stat.ME] 已更新）</title>
      <link>http://arxiv.org/abs/2203.12808</link>
      <description><![CDATA[我们讨论可能无效的观察性研究的因果推断
工具变量。我们提出了一种称为两阶段的新颖方法
通过探索非线性处理模型来进行曲率识别（TSCI）
机器学习。 {第一阶段的机器学习能够提高
工具变量的强度和针对不同形式违规的调整
工具变量假设。} TSCI 的成功需要
工具变量对治疗的影响与其违规形式不同。
实施了一种新颖的偏差校正步骤，以消除由
机器学习的潜在高复杂性。我们提出的 \texttt{TSCI}
估计量被证明是渐近无偏和高斯的，即使
机器学习算法不能一致地估计治疗模型。
此外，我们设计了一种依赖于数据的方法来从多种方法中选择最好的方法
候选人违规表格。我们应用 TSCI 来研究教育对人的影响
收益。
]]></description>
      <guid>http://arxiv.org/abs/2203.12808</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:03 GMT</pubDate>
    </item>
    <item>
      <title>通过自适应合并对纵向网络进行有效估计。 （arXiv：2211.07866v4 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2211.07866</link>
      <description><![CDATA[纵向网络由多个时间边缘之间的序列组成
节点，实时观察时间边缘。它变成了
随着在线社交平台和电子商务的兴起而无处不在，但很大程度上
文学研究不足。在本文中，我们提出了一种有效的
纵向网络的估计框架，利用自适应的优势
网络合并、张量分解和点处理。它合并了相邻的
稀疏网络，以扩大观察到的边缘数量并减少
估计方差，而网络合并引入的估计偏差
通过利用自适应网络的局部时间结构来控制
邻里。提出了投影梯度下降算法以方便
估计，其中每次迭代中估计误差的上限为
已确立的。进行彻底的分析以量化渐近
该方法的行为，表明它可以显着减少
估计误差，并为网络合并提供指导
各种场景。我们进一步证明了所提出方法的优点
通过对合成数据集和军事化的广泛数值实验
州际争端数据集。
]]></description>
      <guid>http://arxiv.org/abs/2211.07866</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:03 GMT</pubDate>
    </item>
    <item>
      <title>类泛化误差：信息理论分析。 （arXiv：2401.02904v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.02904</link>
      <description><![CDATA[现有的监督学习泛化理论通常采用
整体方法并为预期的概括提供界限
整个数据分布，隐含地假设模型概括
所有课程都类似。但在实践中，存在显着的
不同类之间的泛化性能存在差异，这不能
被现有的泛化界限所捕获。在这项工作中，我们解决了这个问题
通过从理论上研究类泛化误差来解决问题，
量化每个单独类别的泛化性能。我们推导出一个
使用 KL 的类泛化误差的新颖信息论界限
散度，我们进一步使用条件获得几个更紧的界限
互信息（CMI），在以下情况下更容易估计
实践。我们凭经验验证了我们在不同神经网络中提出的界限
网络并表明它们准确地捕捉了复杂的类泛化
错误行为。此外，我们还表明，本研究中开发的理论工具
论文还可以应用于除此之外的多种应用中。
]]></description>
      <guid>http://arxiv.org/abs/2401.02904</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:02 GMT</pubDate>
    </item>
    <item>
      <title>Dagma-DCE：可解释的、非参数可微的因果发现。 （arXiv：2401.02930v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.02930</link>
      <description><![CDATA[我们引入了 Dagma-DCE，这是一种可解释且与模型无关的方案
可微的因果发现。当前的非参数或超参数方法
可微的因果发现使用“独立”的不透明代理来
证明包含或排除因果关系的合理性。我们展示
从理论上和经验上来看，这些代理可能是任意不同的
比实际的因果强度。与现有的可微因果并列
发现算法，\textsc{Dagma-DCE} 使用可解释的度量
因果强度来定义加权邻接矩阵。在一些模拟
数据集，我们展示了我们的方法实现了最先进的性能水平。我们
另外表明 \textsc{Dagma-DCE} 允许有原则的阈值处理
以及领域专家的稀疏性惩罚。我们的方法的代码可用
开源于 https://github.com/DanWaxman/DAGMA-DCE，并且可以轻松地
适应任意可微模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.02930</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:02 GMT</pubDate>
    </item>
    <item>
      <title>关于非平滑自动微分的数值可靠性：MaxPool 案例研究。 （arXiv：2401.02736v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.02736</link>
      <description><![CDATA[本文考虑了自动微分（AD）的可靠性
涉及非平滑 MaxPool 操作的神经网络。我们调查了
AD 在不同精度级别（16、32、64 位）上的行为以及
各种数据集上的卷积架构（LeNet、VGG 和 ResNet）
（MNIST、CIFAR10、SVHN 和 ImageNet）。尽管 AD 可能不正确，但最近
研究表明它几乎在所有地方都与导数一致，
即使存在非平滑操作（例如 MaxPool 和 ReLU）。上
另一方面，在实践中，AD 使用浮点数（不是真实的
数字），因此，有必要探索AD可以在其上进行的子集
数字不正确。这些子集包括分叉区（其中 AD 是
不正确的实数）和补偿区（其中AD不正确的
浮点数但对实数正确）。使用 SGD 进行训练
过程中，我们研究了非光滑雅可比行列式的不同选择的影响
MaxPool函数的精度为16位和32位。这些发现表明
具有较低范数的非平滑 MaxPool 雅可比行列式有助于保持稳定和
有效的测试准确性，而那些具有更高规范的可能会导致
不稳定和性能下降。我们还观察到，影响
MaxPool 在学习上的非平滑雅可比行列式可以通过使用批处理来减少
标准化、类似 Adam 的优化器或提高精度水平。
]]></description>
      <guid>http://arxiv.org/abs/2401.02736</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>扩散变分推理：作为表达变分后验的扩散模型。 （arXiv：2401.02739v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.02739</link>
      <description><![CDATA[我们提出去噪扩散变分推理（DDVI），一种近似的方法
依赖于扩散模型的潜变量模型的推理算法
作为表达变分后验。我们的方法增强了变分
具有辅助潜伏的后验，产生一类富有表现力的模型
通过反转用户指定的噪声在潜在空间中执行扩散
过程。我们通过优化边际上的新下界来拟合这些模型
受唤醒睡眠算法启发的可能性。我们的方法很容易
实现（它适合 ELBO 的正规化扩展），与
黑盒变分推理，并且优于其他类别
基于标准化流或对抗网络来近似后验。什么时候
应用于深层潜变量模型，我们的方法产生去噪
扩散VAE（DD-VAE）算法。我们在激励任务中使用该算法
生物学——从人类基因组推断潜在祖先——表现优于强者
千基因组数据集的基线。
]]></description>
      <guid>http://arxiv.org/abs/2401.02739</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>通过具有核嵌入的功能深度神经网络进行非线性功能回归。 （arXiv：2401.02890v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.02890</link>
      <description><![CDATA[随着深度学习在各个科学领域的快速发展
技术，例如语音识别、图像分类和自然
语言处理，最近也广泛应用于函数数据
分析（FDA）取得了一些经验上的成功。然而，由于无限
维度输入，我们需要一个强大的降维方法来实现函数式
学习任务，特别是非线性函数回归。在这个
论文中，基于平滑核积分变换的思想，我们提出了
功能性深度神经网络具有高效且完全依赖于数据的能力
降维方法。我们的功能网络的架构包括
内核嵌入步骤：具有数据相关性的积分变换
光滑的内核；投影步骤：通过投影进行降维
基于嵌入核的特征函数基础；最后是一个富有表现力的
用于预测的深度 ReLU 神经网络。平滑内核的利用
嵌入使我们的功能网络具有离散不变性、高效性、
对噪声观测具有鲁棒性，能够利用两者中的信息
输入函数和响应数据，对数量要求不高
离散点以保证泛化性能不受损害。我们进行
理论分析包括近似误差和泛化误差
分析和数值模拟来验证我们的这些优势
功能网。
]]></description>
      <guid>http://arxiv.org/abs/2401.02890</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>TripleSurv：用于生存分析的三重态时间自适应坐标损失。 （arXiv：2401.02708v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.02708</link>
      <description><![CDATA[生存分析的一个核心挑战是对
经过审查的事件发生时间数据，其中感兴趣的事件可能是死亡，
失败或发生特定事件。先前的研究表明
排序和最大似然估计（MLE）损失函数被广泛使用
用于生存分析。然而，排名损失仅集中于排名
生存时间并且不考虑样本的潜在影响
生存时间值。此外，MLE 是无界的并且很容易受到
异常值（例如，审查数据），这可能会导致建模性能不佳。
处理学习过程的复杂性并利用宝贵的生存机会
时间值，我们提出了一个时间自适应坐标损失函数 TripleSurv，
通过引入生存差异来实现自适应调整
样本对进入排名之间的时间，这可以鼓励模型
对配对的相对风险进行定量排名，最终提高准确性
的预测。最重要的是，TripleSurv 擅长量化
通过对对的排序来确定样本之间的相对风险，并考虑
时间间隔作为校准模型鲁棒性的权衡
样本分布。我们的 TripleSurv 根据三个现实世界的生存进行评估
数据集和公共综合数据集。结果表明我们的方法
优于最先进的方法并表现出良好的模型性能
以及对各种复杂数据分布进行建模的鲁棒性
不同的审查率。我们的代码将在接受后可用。
]]></description>
      <guid>http://arxiv.org/abs/2401.02708</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>多元向量值函数的共享活动子空间。 （arXiv：2401.02735v1 [stat.ME]）</title>
      <link>http://arxiv.org/abs/2401.02735</link>
      <description><![CDATA[本文提出了几种方法作为计算共享的基线
多元向量值函数的活动子空间。目标是
最小化原始空间上函数评估之间的偏差
以及重建后的那些。这可以通过操纵来完成
计算梯度或对称正（半）定（SPD）矩阵
从每个分量函数的梯度得到单个结构
所有组件功能共有。这些方法可以应用于任何数据
与现有的向量值不同，与底层分布无关
限制为正态分布的方法。我们测试了
这些方法对五个优化问题的有效性。实验
表明，一般来说，SPD 级方法优于梯度级方法
，并且在正常情况下接近向量值方法
分配。有趣的是，在大多数情况下，只需取
SPD 矩阵用于识别最佳共享活动子空间。
]]></description>
      <guid>http://arxiv.org/abs/2401.02735</guid>
      <pubDate>Mon, 08 Jan 2024 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>用于张量序列恢复的有保证的非凸分解方法。 （arXiv：2401.02592v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.02592</link>
      <description><![CDATA[在本文中，我们为
因式分解方法。具体来说，为了避免缩放模糊性并
为了便于理论分析，我们对所谓的左正交进行优化
TT 格式强制大多数因素之间的正交性。确保
对于正交结构，我们利用黎曼梯度下降（RGD）
在 Stiefel 流形上优化这些因素。我们首先深入研究一下TT
分解问题并建立RGD的局部线性收敛。
值得注意的是，随着收敛速度的增加，收敛速度只会经历线性下降。
张量阶数增加。然后我们研究旨在恢复的传感问题
来自线性测量的 TT 格式张量。假设传感算子
满足限制等距性质（RIP），我们证明，通过适当的
初始化，可以通过光谱初始化、RGD获得
也以线性速率收敛到真实张量。此外，我们
扩大我们的分析范围，以涵盖涉及高斯噪声的场景
测量。我们证明 RGD 可以可靠地恢复地面事实
线性速率，恢复误差仅表现出多项式增长
与张量阶数的关系。我们进行了各种实验来验证我们的
理论发现。
]]></description>
      <guid>http://arxiv.org/abs/2401.02592</guid>
      <pubDate>Mon, 08 Jan 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>使用 MCMC 提高高维贝叶斯优化的样本效率。 （arXiv：2401.02650v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.02650</link>
      <description><![CDATA[顺序优化方法经常面临着以下问题：
高维空间中的维数。目前的方法
高斯过程框架仍然受到计算复杂性的困扰
跟踪高斯过程后验并需要分区优化
问题进入小区域以确保探索或假设潜在的
低维结构。带着候选点过境的想法
为了更有前途的位置，我们提出了一种基于马尔可夫链的新方法
蒙特卡罗从近似后验中有效采样。我们提供
高斯过程 Thompson 收敛的理论保证
采样设置。我们还通过实验表明，大都会-黑斯廷斯
我们的算法的 Langevin Dynamics 版本优于最先进的算法
高维序列优化和强化学习方法
基准。
]]></description>
      <guid>http://arxiv.org/abs/2401.02650</guid>
      <pubDate>Mon, 08 Jan 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>任意条目依赖下的结构化矩阵学习和马尔可夫转移核的估计。 （arXiv：2401.02520v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.02520</link>
      <description><![CDATA[结构化矩阵估计问题主要在以下方面进行了研究
强噪声依赖性假设。本文考虑了一个总体框架
噪声低秩加稀疏矩阵恢复，其中噪声矩阵可能出现
来自条目之间具有任意依赖性的任何联合分布。我们
提出一个非相干约束最小二乘估计并证明其
确定性下界和匹配极小极大意义上的紧密性
各种噪声分布下的风险。为了实现这一目标，我们建立了一部小说
结果断言两个任意低秩不相干之间的差异
矩阵必须将能量分散到其各个条目中，换句话说，不能
太稀疏，这揭示了不相干低阶矩阵的结构
并且可能具有独立的利益。然后我们展示我们的应用
几个重要的统计机器学习问题的框架。在里面
估计结构化马尔可夫转移核的问题，提出
方法实现了极小极大最优性，结果可以推广为
估计条件均值算子，这是强化的关键组成部分
学习。多任务回归和结构化协方差的应用
还提出了估计。我们提出了一种交替最小化算法
近似解决潜在的困难优化问题。数值
结果证实了我们的方法的有效性，该方法通常会收敛
只需几步即可。
]]></description>
      <guid>http://arxiv.org/abs/2401.02520</guid>
      <pubDate>Mon, 08 Jan 2024 06:17:58 GMT</pubDate>
    </item>
    </channel>
</rss>