<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 30 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>神经网络执行充分的降维</title>
      <link>https://arxiv.org/abs/2412.19033</link>
      <description><![CDATA[arXiv:2412.19033v1 公告类型：新
摘要：本文研究了神经网络与充分降维 (SDR) 之间的联系，证明了神经网络在适当的秩正则化下在回归任务中固有地执行 SDR。具体而言，第一层的权重跨越中心均值子空间。我们建立了基于神经网络的中心均值子空间估计量的统计一致性，强调了神经网络在解决与 SDR 相关的挑战方面的适用性。数值实验进一步验证了我们的理论发现，并强调了与现有方法相比，神经网络促进 SDR 的潜在能力。此外，我们讨论了解开中心子空间的扩展，扩大了我们的研究范围。]]></description>
      <guid>https://arxiv.org/abs/2412.19033</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>情境动态定价中的局部探索实现了无量纲遗憾</title>
      <link>https://arxiv.org/abs/2412.19252</link>
      <description><![CDATA[arXiv:2412.19252v1 公告类型：新
摘要：我们研究了具有线性需求模型的情境动态定价问题。我们提出了一种新颖的局部探索然后提交 (LetC) 算法，该算法从纯探索阶段开始，然后是细化阶段，在学习到的最佳定价策略附近进行探索，最后进入纯开发阶段。当时间范围超过协变量维度的多项式时，该算法被证明可以实现极小最大最优、无维度遗憾界限。此外，我们提供了一个涵盖整个时间范围的通用理论框架，展示了如何在时间范围有限的情况下平衡探索和开发。该分析由一种新颖的临界不等式驱动，该不等式描述了动态定价中的探索-开发权衡，反映了正则化回归中偏差-方差权衡的现有对应物。我们的理论结果通过对合成数据和真实数据进行的大量实验得到验证。]]></description>
      <guid>https://arxiv.org/abs/2412.19252</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过投注实现自适应共形推理</title>
      <link>https://arxiv.org/abs/2412.19318</link>
      <description><![CDATA[arXiv:2412.19318v1 公告类型：新
摘要：共形预测是量化机器学习模型预测不确定性的宝贵工具。然而，它的适用性依赖于数据可交换性的假设，而这一条件在现实世界中往往无法满足。在本文中，我们考虑了自适应共形推理的问题，而没有对数据生成过程做任何假设。现有的自适应共形推理方法基于使用在线梯度下降的变体来优化弹球损失。这类方法的一个显著缺点是它们明确依赖于学习率的选择并对其敏感。在本文中，我们提出了一种不同的自适应共形推理方法，该方法利用无参数的在线凸优化技术。我们证明我们的方法在名义水平上控制了长期错误覆盖频率，并展示了其令人信服的经验性能，而无需执行繁琐的参数调整。]]></description>
      <guid>https://arxiv.org/abs/2412.19318</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>复合假设模型下变点异常的渐近最优搜索</title>
      <link>https://arxiv.org/abs/2412.19392</link>
      <description><![CDATA[arXiv:2412.19392v1 公告类型：新
摘要：我们解决了在有限的 M 个过程中寻找异常过程中的变化点的问题。具体来说，我们解决了一个复合假设模型，其中每个过程都会生成遵循具有未知参数（向量）的共同分布的测量值。此参数属于正常或异常空间，具体取决于过程的当前状态。在变化点之前，所有过程（包括异常过程）都处于正常状态；在变化点之后，异常过程转变为异常状态。我们的目标是设计一种顺序搜索策略，通过平衡样本复杂性和检测准确性来最小化贝叶斯风险。我们提出了一种具有以下显着特性的确定性搜索算法。首先，我们通过分析证明，当正常和异常过程的分布都未知时，当错误概率趋近于零时，该算法在最小化贝叶斯风险方面是渐近最优的。在第二种设置中，当零假设下的参数已知时，该算法实现了渐近最优性，并且基于真实正常状态改善了检测时间。仿真结果验证了理论结果。]]></description>
      <guid>https://arxiv.org/abs/2412.19392</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>来自异构人类反馈的低秩情境强化学习</title>
      <link>https://arxiv.org/abs/2412.19436</link>
      <description><![CDATA[arXiv:2412.19436v1 公告类型：新
摘要：从人类反馈中进行强化学习 (RLHF) 已成为将大型语言模型与人类偏好相结合的基石。然而，人类反馈的异质性是由不同的个人背景和偏好驱动的，这对奖励学习提出了重大挑战。为了解决这个问题，我们提出了一个低秩上下文 RLHF (LoCo-RLHF) 框架，该框架集成了上下文信息，以更好地模拟异质反馈，同时保持计算效率。我们的方法建立在上下文偏好模型的基础上，利用用户上下文和查询-答案对之间交互的内在低秩结构来缓解特征表示的高维性。此外，我们通过我们的简化子空间悲观主义 (PRS) 策略解决了反馈分布变化的挑战，该策略受到悲观主义离线强化学习技术的启发。我们从理论上证明，与现有方法相比，我们的策略实现了更紧密的次优差距。大量实验验证了 LoCo-RLHF 的有效性，展示了其在个性化 RLHF 设置中的卓越性能及其对分布变化的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2412.19436</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度线性霍克斯过程</title>
      <link>https://arxiv.org/abs/2412.19634</link>
      <description><![CDATA[arXiv:2412.19634v1 公告类型：新
摘要：标记时间点过程 (MTPP) 用于对到达时间不规则的不同类型事件序列进行建模，其应用范围广泛，从医疗保健和社交网络到金融。我们通过在现代深度状态空间模型 (SSM) 和线性霍克斯过程 (LHP) 之间建立联系来解决现有点过程模型中的缺点，最终形成了我们称之为深度线性霍克斯过程 (DLHP) 的 MTPP。DLHP 将深度 SSM 中的线性微分方程修改为随机跳跃微分方程，类似于 LHP。离散化后，可以使用并行扫描有效地实现所得到的递归。这为 MTPP 模型带来了并行性和线性缩放。这与基于注意力的 MTPP（二次缩放）和基于 RNN 的 MTPP（不跨序列长度并行）形成对比。我们通过实证研究证明，DLHP 在八个真实数据集的广泛指标上与现有模型相当或优于现有模型。我们提出的 DLHP 模型是利用 SSM 的独特架构功能构建新一类 MTPP 模型的首个实例。]]></description>
      <guid>https://arxiv.org/abs/2412.19634</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度 ReLU 网络——注入容量上限</title>
      <link>https://arxiv.org/abs/2412.19677</link>
      <description><![CDATA[arXiv:2412.19677v1 公告类型：新
摘要：我们研究深度 ReLU 前馈神经网络 (NN) 及其注入能力。主要重点是 \emph{精确} 确定所谓的注入能力。对于任何给定的隐藏层架构，它被定义为网络输出数量与输入数量之间的最小比率，以确保从可实现的输出唯一地恢复输入。最近在精确研究单个 ReLU 层注入特性方面取得的重大进展被转移到深度网络级别。特别是，我们开发了一个程序，将深度 $l$ 层网络注入性连接到 $\ell_0$ 球形感知器的 $l$ 扩展，从而大规模推广研究单层注入性和 [82] 中讨论的所谓 (1 扩展) $\ell_0$ 球形感知器的容量之间的同构。然后创建并利用基于 \emph{随机对偶理论} (RDT) 的机制来统计处理扩展的 $\ell_0$ 球形感知器和深度 ReLU NN 的属性。还进行了大量的数值评估，以将整个 RDT 机制投入实际使用。从中我们观察到所需层扩展的快速下降趋势，即我们观察到快速的 \emph{扩展饱和效应}。仅 $4$ 层深度就足以接近无需扩展的水平——这一结果与实际实验中的观察结果非常相似，并且迄今为止任何现有的数学方法都无法完全触及。]]></description>
      <guid>https://arxiv.org/abs/2412.19677</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在存在缺失结果数据的情况下，因果机器学习用于异质治疗效果</title>
      <link>https://arxiv.org/abs/2412.19711</link>
      <description><![CDATA[arXiv:2412.19711v1 公告类型：新
摘要：在估计异质治疗效果时，缺失的结果数据会使治疗效果估计复杂化，导致某些人群亚群代表性不佳。在这项工作中，我们讨论了这个常被忽视的问题，并考虑了随机缺失 (MAR) 结果数据对条件平均治疗效果 (CATE) 的因果机器学习估计量的影响。然后，我们为 CATE 提出了两个去偏机器学习估计量，即 mDR 学习器和 mEP 学习器，它们分别通过将审查权重的逆概率集成到 DR 学习器和 EP 学习器中来解决代表性不足的问题。我们表明，在合理的条件下，这些估计量是 oracle 高效的，并通过模拟数据设置说明了它们的良好性能，将它们与现有的 CATE 估计量进行比较，包括与使用常见缺失数据技术的估计量进行比较。我们提供了这些估算器的实施指导，并使用 ACTG175 试验展示了它们的应用示例，探索在 HIV-1 感染者中比较齐多夫定单一疗法与替代抗逆转录病毒疗法时的治疗效果异质性。]]></description>
      <guid>https://arxiv.org/abs/2412.19711</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学会忘记：使用递归稀疏谱特征高斯过程进行贝叶斯时间序列预测</title>
      <link>https://arxiv.org/abs/2412.19727</link>
      <description><![CDATA[arXiv:2412.19727v1 公告类型：新
摘要：签名核是任意长度的时间序列之间的核，具有随机分析的强大理论保证。它已在机器学习中得到应用，例如高斯过程的协方差函数。底层签名特征的优势在于它们提供了时间序列的结构化全局描述。但是，当局部信息至关重要并且需要遗忘时，此属性很快就会成为祸害；到目前为止，仅通过临时方法（例如将时间序列切成子段）解决了此问题。为了克服这个问题，我们提出了一种原则性的、数据驱动的方法，即为签名引入一种新颖的遗忘机制。这允许模型动态调整其上下文长度以关注更新的信息。为了实现这一点，我们重新审视最近引入的随机傅立叶签名特征，并使用高斯过程 (GP) 开发随机傅立叶衰减签名特征 (RFDSF)。这产生了一种具有变分推理的贝叶斯时间序列预测算法，该算法提供了一种可扩展的概率算法，该算法使用递归一次性处理时间序列并将其转换为时间步骤上的联合预测分布。例如，在大约 10^{-2}$ 秒内和 $&lt; 1\text{GB}$ 的 GPU 内存中处理长度为 $10^4$ 步的序列。我们证明它优于其他基于 GP 的替代方案，并与最先进的概率时间序列预测算法相媲美。]]></description>
      <guid>https://arxiv.org/abs/2412.19727</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LASER：一种局部自适应非参数回归的新方法</title>
      <link>https://arxiv.org/abs/2412.19802</link>
      <description><![CDATA[arXiv:2412.19802v1 公告类型：新
摘要：在本文中，我们介绍了 \textsf{LASER}（局部自适应平滑回归估计器），这是一种计算效率高的局部自适应非参数回归方法，可执行可变带宽局部多项式回归。我们证明它在其域中的所有点上都能（近乎）最佳地适应底层回归函数的局部 H\&quot;{o}lder 指数 \texttt{同时}。此外，我们表明，存在一个全局调整参数的理想选择，在上述局部自适应性下成立。尽管关于非参数回归的文献很多，但具有如此强的局部自适应性概念的可证明保证的可行方法的例子却很少。与流行的替代局部自适应方法相比，所提出的方法在广泛的数值实验中取得了优异的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.19802</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多元信息分数的祖先图高效搜索和评分算法</title>
      <link>https://arxiv.org/abs/2412.17508</link>
      <description><![CDATA[arXiv:2412.17508v1 公告类型：交叉 
摘要：我们提出了一种贪婪的搜索和评分算法，用于祖先图，其中包括有向边和双向边，源自未观察到的潜在变量。祖先图的归一化似然分数是根据顶点 C 的相关“ac 连接子集”的多变量信息估计的，这些顶点通过限制在 C 的祖先集内的碰撞路径连接。为了提高计算效率，提出的两步算法依赖于限制在每个节点（步骤 1）和边（步骤 2）的近邻顶点的局部信息分数。这种计算策略虽然仅限于包含最多两个碰撞路径的 ac 连接子集的信息贡献，但在具有挑战性的基准数据集上，它的表现优于最先进的因果发现方法。]]></description>
      <guid>https://arxiv.org/abs/2412.17508</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BoostMD：利用先前时间步骤中的 ML 力场特征来加速分子采样</title>
      <link>https://arxiv.org/abs/2412.18633</link>
      <description><![CDATA[arXiv:2412.18633v1 公告类型：交叉 
摘要：模拟原子级过程，例如蛋白质动力学和催化反应，对于生物学、化学和材料科学的进步至关重要。机器学习力场 (MLFF) 已成为实现接近量子力学精度的强大工具，具有良好的泛化能力。然而，与经典力场相比，它们的实际应用通常受到较长推理时间的限制，尤其是在运行许多生物应用所需的大量分子动力学 (MD) 模拟时。在本研究中，我们介绍了 BoostMD，这是一种旨在加速 MD 模拟的替代模型架构。BoostMD 利用在先前时间步骤计算的节点特征来根据位置变化预测能量和力。这种方法降低了学习任务的复杂性，使 BoostMD 比传统的 MLFF 更小、速度更快。在模拟过程中，计算密集型参考 MLFF 仅每 $N$ 步评估一次，而轻量级 BoostMD 模型以计算成本的一小部分处理中间步骤。我们的实验表明，与参考模型相比，BoostMD 实现了 8 倍的加速，并可推广到未见过的二肽。此外，我们发现 BoostMD 在运行分子动力学时可以准确地对真实玻尔兹曼分布进行采样。通过将高效的特征重用与精简的架构相结合，BoostMD 为进行大规模、长时间尺度的分子模拟提供了强大的解决方案，使高精度 ML 驱动建模更易于访问和实用。]]></description>
      <guid>https://arxiv.org/abs/2412.18633</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Metropolis 调整的预条件朗之万算法从受限空间进行高精度采样</title>
      <link>https://arxiv.org/abs/2412.18701</link>
      <description><![CDATA[arXiv:2412.18701v1 公告类型：交叉 
摘要：在这项工作中，我们提出了一种一阶采样方法，称为 Metropolis 调整的预处理朗之万算法，用于从支持是 $\mathbb{R}^{d}$ 的适当凸子集的目标分布中进行近似采样。我们提出的方法是将 Metropolis-Hastings 过滤器应用于由具有度量 $\mathscr{G}$ 的预处理朗之万算法的单步形成的马尔可夫链的结果，并且受到自然梯度下降算法的启发进行优化。我们推导出该方法的混合时间的非渐近上限，用于从潜力相对于 $\mathscr{G}$ 有界的目标分布中进行采样，以及对于限制在支持的指数分布。我们的分析表明，如果 $\mathscr{G}$ 满足 Kook 和 Vempala (2024) 中引入的更强的自协调概念，那么这些混合时间上限对维度的依赖性将比仅自协调时更强。我们还提供了数值实验来证明我们提出的方法的实用性。由于我们的混合时间上限对误差容限具有多对数依赖性，因此我们的方法是一种高精度采样器。]]></description>
      <guid>https://arxiv.org/abs/2412.18701</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于高斯噪声贝叶斯优化中遗憾界限的改进</title>
      <link>https://arxiv.org/abs/2412.18789</link>
      <description><![CDATA[arXiv:2412.18789v1 公告类型：交叉 
摘要：具有高斯过程 (GP) 代理模型的贝叶斯优化 (BO) 是一种强大的黑箱优化方法。获取函数是 BO 算法的关键部分，因为它们决定了如何选择新样本。一些最广泛使用的获取函数包括置信上限 (UCB) 和汤普森采样 (TS)。BO 算法的收敛性分析集中在贝叶斯和频率论设置下的累积遗憾上。在本文中，我们在高斯噪声的频率论设置下建立了 GP 预测误差的新逐点界限。因此，我们证明了 GP-UCB 和 GP-TS 的累积遗憾界限的收敛速度有所提高。值得注意的是，高斯噪声下的新预测误差界限可以应用于一般的 BO 算法和收敛分析，例如，有噪声的预期改进 (EI) 的渐近收敛。]]></description>
      <guid>https://arxiv.org/abs/2412.18789</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过高阶校准实现可证明的不确定性分解</title>
      <link>https://arxiv.org/abs/2412.18808</link>
      <description><![CDATA[arXiv:2412.18808v1 公告类型：交叉 
摘要：我们给出了一种原则性方法，将模型的预测不确定性分解为随机和认知成分，并明确将它们与现实世界的数据分布联系起来。虽然文献中的许多作品都提出了这样的分解，但它们缺乏我们提供的那种正式保证。我们的方法基于高阶校准的新概念，它将普通校准推广到高阶预测器的设置，这些预测器可以预测每个点的标签分布的混合。我们展示了如何使用访问 $k$ 个快照（即每个点都有 $k$ 个独立条件标签的示例）来测量和实现高阶校准。在高阶校准下，保证在某一点估计的随机不确定性与在所有进行预测的点上平均的真实世界随机不确定性相匹配。据我们所知，这是第一个这种类型的正式保证，它对真实世界的数据分布没有任何假设。重要的是，高阶校准也适用于现有的高阶预测器，如贝叶斯和集成模型，并为此类模型提供自然的评估指标。我们通过实验证明，我们的方法可以为图像分类产生有意义的不确定性分解。]]></description>
      <guid>https://arxiv.org/abs/2412.18808</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>