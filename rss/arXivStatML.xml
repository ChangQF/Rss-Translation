<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 29 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用随机克里金法的双目标排序和选择</title>
      <link>https://arxiv.org/abs/2209.03919</link>
      <description><![CDATA[arXiv:2209.03919v3 公告类型：替换
摘要：我们考虑双目标排名和选择问题，其目标是在一组有限的候选者中正确识别帕累托最优解，其中两个目标结果已被观察到具有不确定性（例如，在运行多目标随机模拟优化之后）程序）。在识别这些解决方案时，扰乱观察到的性能的噪声可能会导致两种类型的错误：真正帕累托最优的解决方案可能会被错误地认为是受支配的，而真正受支配的解决方案可能会被错误地认为是帕累托最优。我们提出了一种新颖的贝叶斯双目标排名和选择方法，该方法顺序地将额外样本分配给竞争性解决方案，以减少在识别具有最佳预期性能的解决方案时的错误分类错误。该方法使用随机克里金法来构建客观结果的可靠预测分布，并利用此信息来决定如何重新采样。实验结果表明，所提出的方法优于标准分配方法以及众所周知的最先进算法。此外，我们表明其他竞争算法也受益于随机克里金信息的使用；然而，所提出的方法仍然优越。]]></description>
      <guid>https://arxiv.org/abs/2209.03919</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>CAP：一种具有 FCR 控制的在线选择性共形预测通用算法</title>
      <link>https://arxiv.org/abs/2403.07728</link>
      <description><![CDATA[arXiv:2403.07728v2 公告类型：替换
摘要：我们以在线方式研究选择后预测推理问题。为了避免将资源投入到不重要的单位，在报告其预测区间之前对当前个体进行初步选择在在线预测任务中是常见且有意义的。由于在线选择会导致所选预测区间的时间多重性，因此控制衡量总体错误覆盖水平的实时错误覆盖率（FCR）非常重要。我们开发了一个名为 CAP（自适应挑选后校准）的通用框架，该框架对历史数据执行自适应挑选规则，以在选择当前个体的情况下构建校准集，然后为未观察到的标签输出共形预测区间。我们提供易于处理的程序来构建流行的在线选择规则的校准集。我们证明了 CAP 可以在有限样本和无分布的情况下实现精确的选择条件覆盖保证。为了解释在线数据的分布变化，我们还将 CAP 嵌入到一些最新的动态共形预测算法中，并表明所提出的方法可以提供长期的 FCR 控制。合成数据和真实数据的数值结果证实，CAP 可以有效地将 FCR 控制在目标水平附近，并在各种设置下的现有基线上产生更窄的预测区间。]]></description>
      <guid>https://arxiv.org/abs/2403.07728</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>从有限的成对偏好比较中进行度量学习</title>
      <link>https://arxiv.org/abs/2403.19629</link>
      <description><![CDATA[arXiv:2403.19629v1 公告类型：交叉
摘要：我们研究了理想点模型下偏好比较的度量学习，其中如果一个项目更接近他们潜在的理想项目，则用户会更喜欢一个项目。这些项目嵌入到 $\mathbb{R}^d$ 中，配备了用户之间共享的未知马哈拉诺比斯距离。虽然最近的工作表明，在每个用户进行 $\mathcal{O}(d)$ 成对比较的情况下，可以同时恢复指标和理想项目，但在实践中，我们通常对 $o(d)$ 比较的预算有限。我们研究该指标是否仍然可以恢复，尽管我们知道现在不再可能学习单个理想项目。我们表明，一般来说，$o(d)$ 比较不会揭示有关指标的信息，即使用户数量无限。然而，当对表现出低维结构的项目进行比较时，每个用户可以有助于学习限制于低维子空间的度量，以便可以共同识别该度量。我们提出了一种分而治之的方法来实现这一目标，并提供理论恢复保证和实证验证。]]></description>
      <guid>https://arxiv.org/abs/2403.19629</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>流形上函数逼近的随机向量函数链接网络</title>
      <link>https://arxiv.org/abs/2007.15776</link>
      <description><![CDATA[arXiv:2007.15776v3 公告类型：替换
摘要：前馈神经网络的学习速度非常慢，几十年来一直是深度学习应用的瓶颈。例如，广泛用于训练神经网络的基于梯度的学习算法在必须迭代调整所有网络参数时往往会运行缓慢。为了解决这个问题，研究人员和实践者都尝试引入随机性来减少学习要求。基于 Igelnik 和 Pao 的原始构建，具有随机输入到隐藏层权重和偏差的单层神经网络在实践中取得了成功，但缺乏必要的理论依据。在本文中，我们开始填补这一理论空白。我们提供了一个（更正的）严格证明，证明 Igelnik 和 Pao 构造是紧域上连续函数的通用逼近器，逼近误差渐近衰减，就像 $O(1/\sqrt{n})$ 对于数字 $n$ 而言网络节点。然后，我们将此结果扩展到非渐近设置，证明只要 $n$ 足够大，就可以以高概率实现任何所需的近似误差。我们进一步采用这种随机神经网络架构来逼近欧几里得空间的平滑、紧凑子流形上的函数，为渐近和非渐近形式提供理论保证。最后，我们通过数值实验说明流形上的结果。]]></description>
      <guid>https://arxiv.org/abs/2007.15776</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>驯服交互式粒子 Langevin 算法——超线性情况</title>
      <link>https://arxiv.org/abs/2403.19587</link>
      <description><![CDATA[arXiv:2403.19587v1 公告类型：交叉
摘要：随机优化的最新进展产生了交互式粒子 Langevin 算法（IPLA），该算法利用交互粒子系统（IPS）的概念从近似后验密度中有效地进行采样。这在期望最大化 (EM) 框架内变得尤为重要，其中 E 步在计算上具有挑战性，甚至难以处理。尽管之前的研究主要集中在涉及对数密度梯度最多呈线性增长的凸情况的场景，但我们的工作扩展了该框架以包括多项式增长。驯服技术用于产生显式离散化方案，该方案在这种非线性下产生一类新的稳定算法，称为驯服交互式粒子朗之万算法（tIPLA）。我们在最佳速率下获得了新类的 Wasserstein-2 距离的非渐近收敛误差估计。]]></description>
      <guid>https://arxiv.org/abs/2403.19587</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:32 GMT</pubDate>
    </item>
    <item>
      <title>Top-$k$ 分类和基数感知预测</title>
      <link>https://arxiv.org/abs/2403.19625</link>
      <description><![CDATA[arXiv:2403.19625v1 公告类型：交叉
摘要：我们提出了对 top-$k$ 分类的详细研究，即预测输入的 $k$ 最可能类别的任务，超出了单类预测的范围。我们证明了多类分类中的几种流行的替代损失函数，例如 comp-sum 和约束损失，受到相对于 top-$k$ 损失的 $H$ 一致性界限的支持。这些界限保证了与假设集 $H$ 相关的一致性，由于其非渐近性和假设集的特定性质，提供了比贝叶斯一致性更强的保证。为了解决准确性和基数 $k$ 之间的权衡，我们通过实例相关的成本敏感学习进一步引入基数感知损失函数。对于这些函数，我们得出成本敏感的补偿和约束代理损失，建立它们的 $H$ 一致性界限和贝叶斯一致性。最大限度地减少这些损失会导致新的基数感知算法用于 top-$k$ 分类。我们报告了在 CIFAR-100、ImageNet、CIFAR-10 和 SVHN 数据集上进行的广泛实验的结果，证明了这些算法的有效性和优势。]]></description>
      <guid>https://arxiv.org/abs/2403.19625</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:32 GMT</pubDate>
    </item>
    <item>
      <title>多专家延迟回归</title>
      <link>https://arxiv.org/abs/2403.19494</link>
      <description><![CDATA[arXiv:2403.19494v1 公告类型：交叉
摘要：学习推迟多个专家是一个学习者可以选择将预测推迟给多个专家的框架。虽然这个问题在分类环境中受到了极大的关注，但由于标签空间的无限和连续性质，它在回归中提出了独特的挑战。在这项工作中，我们引入了一种新颖的延迟回归框架，其中涉及将预测延迟给多个专家。我们对单阶段场景（同时学习预测器和延迟函数）和两阶段场景（涉及具有学习延迟函数的预训练预测器）进行了全面分析。我们为这两种情况引入了新的代理损失函数，并证明它们受到 $H$ 一致性边界的支持。这些界限提供了比贝叶斯一致性更强的一致性保证，因为它们是非渐近的并且是特定于假设集的。我们的框架是多功能的，适用于多个专家，适应任何有界回归损失，解决依赖于实例和依赖于标签的成本，并支持单阶段和两阶段方法。副产品是我们的单阶段公式包括最近的弃权框架回归（Cheng et al., 2023）作为一种特殊情况，其中仅考虑单个专家、平方损失和与标签无关的成本。最小化我们提出的损失函数直接导致了延迟回归的新算法。我们报告了广泛的实验结果，显示了我们提出的算法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.19494</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>作为高斯过程的张量网络约束核机</title>
      <link>https://arxiv.org/abs/2403.19500</link>
      <description><![CDATA[arXiv:2403.19500v1 公告类型：交叉
摘要：张量网络（TN）最近被用来通过限制模型权重来加速内核机器，从而节省指数级的计算和存储。在本文中，我们证明了规范多元分解（CPD）和张量训练（TT）约束的内核机的输出恢复了高斯过程（GP），当将独立同分布放置时，我们充分描述了该过程。先验于它们的参数。我们分析了 CPD 和 TT 约束模型的收敛性，并展示了对于相同数量的模型参数，与 CPD 相比，TT 如何产生表现出更多 GP 行为的模型。我们在两个数值实验中凭经验观察了这种行为，分别分析了 GP 的收敛性和预测性能。由此，我们在 TN 约束的内核机器和 GP 之间建立了连接。]]></description>
      <guid>https://arxiv.org/abs/2403.19500</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>线性规划的 Fisher-Rao 梯度流和国家行动自然政策梯度</title>
      <link>https://arxiv.org/abs/2403.19448</link>
      <description><![CDATA[arXiv:2403.19448v1 公告类型：交叉
摘要：Kakade 的自然策略梯度方法在过去几年中得到了广泛的研究，显示出带正则化和不带正则化的线性收敛。我们研究了另一种自然梯度方法，该方法基于状态-动作分布的 Fisher 信息矩阵，但在理论方面很少受到关注。这里，状态-动作分布遵循状态-动作多胞体内部相对于线性势的 Fisher-Rao 梯度流。因此，我们更广泛地研究线性程序的 Fisher-Rao 梯度流，并显示线性收敛速度取决于线性程序的几何形状。同样，这产生了对线性程序的熵正则化引起的误差的估计，从而改进了现有结果。我们扩展了这些结果，并展示了扰动 Fisher-Rao 梯度流和自然梯度流在达到近似误差时的次线性收敛。特别是，这些一般结果涵盖了国家行动自然政策梯度的情况。]]></description>
      <guid>https://arxiv.org/abs/2403.19448</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>$H$-回归的一致性保证</title>
      <link>https://arxiv.org/abs/2403.19480</link>
      <description><![CDATA[arXiv:2403.19480v1 公告类型：交叉
摘要：我们对回归的 $H$ 一致性界限进行了详细研究。我们首先提出新的定理，这些定理概括了先前给出的用于建立 $H$ 一致性界限的工具。事实证明，这种概括对于分析特定于回归的 $H$ 一致性界限至关重要。接下来，我们在对称分布和有界假设集的假设下，证明平方损失的代理损失函数的一系列新颖的 $H$ 一致性界限。这包括 Huber 损失、所有 $\ell_p$ 损失、$p \geq 1$、平方 $\epsilon$ 不敏感损失的正结果，以及用于 $\epsilon$ 不敏感损失的负结果平方支持向量回归 (SVR)。我们进一步利用对 $H$ 一致性的分析进行回归，并得出对抗性回归的原则性替代损失（第 5 节）。这很容易建立对抗性回归的新算法，我们在第 6 节中报告了有利的实验结果。]]></description>
      <guid>https://arxiv.org/abs/2403.19480</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>用于顺序查询建议的基于最大效用的 Arm 选择策略</title>
      <link>https://arxiv.org/abs/2108.13810</link>
      <description><![CDATA[arXiv:2108.13810v1 公告类型：交叉
摘要：我们考虑闭环交互式学习环境中的查询推荐问题，例如在线信息收集和探索性分析。该问题可以使用具有可数个手臂的多臂老虎机 (MAB) 框架自然地建模。适用于可数多个臂的标准 MAB 算法首先选择一组随机的候选臂，然后在此下游候选集上应用标准 MAB 算法，例如 UCB。我们表明，这种选择策略通常会导致更高的累积遗憾，为此，我们提出了一种基于武器最大效用的选择策略。我们表明，在在线信息收集等任务中，采用顺序查询建议，查询序列是相关的，并且通过选择相对于当前执行的查询具有最大效用的查询，可以将潜在最佳查询的数量减少到可管理的大小。我们使用最近的真实在线文献发现服务日志文件的实验结果表明，所提出的臂选择策略相对于最先进的基线算法大大改善了累积遗憾。 % 以及各种上下文多臂老虎机算法常用的随机选择策略。我们的数据模型和源代码可在 ~\url{https://anonymous.4open.science/r/0e5ad6b7-ac02-4577-9212-c9d505d3dbdb/} 获取。]]></description>
      <guid>https://arxiv.org/abs/2108.13810</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:29 GMT</pubDate>
    </item>
    <item>
      <title>似然 OOD 检测悖论的几何解释</title>
      <link>https://arxiv.org/abs/2403.18910</link>
      <description><![CDATA[arXiv:2403.18910v1 公告类型：交叉
摘要：基于似然的深度生成模型（DGM）通常表现出令人费解的行为：当在相对复杂的数据集上进行训练时，它们为来自较简单来源的分布外（OOD）数据分配更高的似然值。更神秘的是，尽管 OOD 样本的可能性更高，但这些 DGM 从未生成过 OOD 样本。这种双管齐下的悖论尚未得到最终解释，使得基于可能性的 OOD 检测不可靠。我们的主要观察是，如果高似然区域包含最小概率质量，则不会生成它们。我们证明了大密度与低概率质量的这种看似矛盾是如何在仅限于低维流形的数据周围发生的。我们还表明，可以通过局部固有维度 (LID) 估计来识别这种情况，并提出一种 OOD 检测方法，该方法将可能性和从预训练的 DGM 获得的 LID 估计配对。我们的方法可以应用于标准化流量和基于分数的扩散模型，并使用相同的 DGM 主干获得匹配或超越最先进的 OOD 检测基准的结果。我们的代码可在 https://github.com/layer6ai-labs/dgm_ood_detection 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.18910</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:29 GMT</pubDate>
    </item>
    <item>
      <title>近贝叶斯最优算法的不确定性量化</title>
      <link>https://arxiv.org/abs/2403.19381</link>
      <description><![CDATA[arXiv:2403.19381v1 公告类型：新
摘要：贝叶斯建模可以量化预测不确定性，这在安全关键型应用中至关重要。然而，对于许多机器学习 (ML) 算法来说，构建或实现其对应的贝叶斯算法是很困难的。在这项工作中，我们提出了一种很有前途的方法来应对这一挑战，该方法基于这样的假设：常用的机器学习算法在各种任务中都是有效的，因此可能接近贝叶斯最优。未知的任务分配。我们证明，通过使用该算法构建鞅后验，可以恢复由任务分布定义的贝叶斯后验，该分布是未知的，但在此设置中是最佳的。我们进一步提出了一种适用于通用机器学习算法的实用不确定性量化方法。基于各种非神经网络和神经网络算法的实验证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.19381</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:28 GMT</pubDate>
    </item>
    <item>
      <title>有向图聚类随机块模型的最大似然估计</title>
      <link>https://arxiv.org/abs/2403.19516</link>
      <description><![CDATA[arXiv:2403.19516v1 公告类型：新
摘要：本文从统计学的角度研究了有向图聚类问题，其中我们将聚类表述为估计有向随机块模型（DSBM）中的潜在社区。我们对 DSBM 进行最大似然估计（MLE），从而根据观察到的图结构确定最可能的社区分配。除了统计观点之外，我们还进一步建立了该 MLE 公式与一种新颖的流优化启发式之间的等价性，它共同考虑了两个重要的有向图统计数据：边缘密度和边缘方向。基于这种新的有向聚类公式，我们引入了两种高效且可解释的有向聚类算法：谱聚类算法和基于半定规划的聚类算法。我们使用矩阵扰动理论的工具提供了谱聚类算法的错误聚类顶点数量的理论上限。我们在定量和定性方面将我们提出的算法与合成数据和真实数据上现有的定向聚类方法进行比较，从而为我们的理论贡献提供了进一步的基础。]]></description>
      <guid>https://arxiv.org/abs/2403.19516</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:28 GMT</pubDate>
    </item>
    <item>
      <title>Causal-StoNet：高维复杂数据的因果推理</title>
      <link>https://arxiv.org/abs/2403.18994</link>
      <description><![CDATA[arXiv:2403.18994v1 公告类型：新
摘要：随着数据科学的进步，收集日益复杂的数据集已变得司空见惯。在此类数据集中，数据维度可能非常高，并且底层数据生成过程可能是未知且高度非线性的。因此，利用高维复杂数据进行因果推断的任务已成为医学、计量经济学和社会科学等许多学科的基本问题。然而，现有的因果推理方法经常是在数据维度较低或底层数据生成过程是线性或近似线性的假设下开发的。为了应对这些挑战，本文提出了一种处理高维复杂数据的新型因果推理方法。所提出的方法基于深度学习技术，包括最近文献中开发的稀疏深度学习理论和随机神经网络。通过使用这些技术，所提出的方法可以以连贯的方式解决高维和未知数据生成过程。此外，当数据集中存在缺失值时，也可以使用所提出的方法。广泛的数值研究表明，所提出的方法优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2403.18994</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:27 GMT</pubDate>
    </item>
    </channel>
</rss>