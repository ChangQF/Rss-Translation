<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Mon, 31 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>结构和稀疏的部分最小二乘相干性，用于多元皮质肌肉分析</title>
      <link>https://arxiv.org/abs/2503.21802</link>
      <description><![CDATA[ARXIV：2503.21802V1公告类型：交叉 
摘要：多元皮质肌肉分析最近已成为评估皮质脊髓神经途径的有前途的方法。但是，当前的多元方法会遇到诸如高维度和有限的样本量之类的挑战，从而限制了它们的进一步应用。在本文中，我们提出了一种结构化和稀疏的部分最小二乘相干算法（SSPLSC）来提取与皮质肌相互作用相关的共享潜在空间表示。我们的方法通过集成了部分最小二乘（PLS）的目标函数，稀疏性约束和基于连接性的结构性约束，解决了嵌入式优化框架，从而解决了概括性，可解释性和空间结构。为了解决优化问题，我们在统一框架内开发了有效的交替迭代算法，并通过实验证明了其收敛性。一个合成和几个现实世界数据集的广泛实验结果表明，SSPLSC可以在某些代表性的多元皮质肌肉融合方法上实现竞争性或更好的性能，尤其是在以有限的样本量和高噪声水平为特征的情况下。这项研究提供了一种用于皮质肌肉分析的新型多元融合方法，为评估神经系统疾病中皮质脊髓途径完整性的变革性工具提供了变革性的工具。]]></description>
      <guid>https://arxiv.org/abs/2503.21802</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>最好的N是最好的吗？推理时间对齐中的覆盖范围，缩放和最佳性</title>
      <link>https://arxiv.org/abs/2503.21878</link>
      <description><![CDATA[ARXIV：2503.21878V1公告类型：交叉 
摘要：推理时间计算为缩放语言模型性能提供了一个重要的轴，但是通过诸如$ n $采样之类的技术来缩放计算会导致由于奖励黑客入侵而导致性能降低。为了对如何最好地利用额外计算的理论理解，我们专注于推理时间对齐，我们将其正式化为改善预培训的政策的响应以提高感兴趣的问题，鉴于可以访问不完善的奖励模型。我们根据（i）响应质量和（ii）计算推理时间对齐算法的性能，并提供新的结果，以突出预训练的政策对性能和计算缩放的高质量响应的重要性：
  1。我们表明，最佳的$ n $对齐方式与$ n $的理想选择可以在严格的覆盖范围下实现最佳性能，但是当$ n $较大时，在奖励黑客范围内遭受了奖励，并且在更现实的覆盖条件下未能实现紧张的保证。
  2。我们介绍了$ \ texttt {pebleenceTime-pessimism} $，一种新算法，通过故意使用推理时间计算来减轻奖励黑客，在面对不确定性通过拒绝采样时实施悲观原则；我们证明它的性能是最佳的，并且不会随$ n $而降级，这意味着它是缩放单调的。
  我们通过实验评估来补充理论结果，该结果证明了$ \ texttt {pebleenceTime -pessimismism} $在各种任务和模型中的好处。]]></description>
      <guid>https://arxiv.org/abs/2503.21878</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>滚动的高斯流程模型，用于曲线的曲线</title>
      <link>https://arxiv.org/abs/2503.21980</link>
      <description><![CDATA[ARXIV：2503.21980V1公告类型：交叉 
摘要：给定平面曲线，想象一下沿着该曲线滚动一个球而不会滑或扭曲，这意味着要在球体上绘制曲线。众所周知，这样的滚动操作会在球体和平面之间诱导局部等轴测图，从而使两条曲线彼此唯一确定，此外，该操作延伸到任何维度的一般歧管类别。我们使用滚动来构建高斯过程的类似物，从欧几里得高斯工艺开始。所得模型是生成的，并且可以根据统计推断为统计推断，以给定数据作为歧管上的曲线。我们用单位球体上的示例，对称正定矩阵以及涉及3D方向的机器人应用进行说明。]]></description>
      <guid>https://arxiv.org/abs/2503.21980</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用Google趋势的人工趋势指数用于私人消费</title>
      <link>https://arxiv.org/abs/2503.21981</link>
      <description><![CDATA[ARXIV：2503.21981V1公告类型：交叉 
摘要：近年来，使用分析趋势，情感或新闻进行经济预测或创建指标的数据库已获得了很大的普及，尤其是在Google趋势平台上。本文探讨了Google搜索数据开发新指数的潜力，该指数改善了经济预测，特别关注经济活动的关键组成部分之一：私人消费（秘鲁的GDP占64％）。通过选择和估计分类变量，应用机器学习技术，表明Google数据可以识别实时生成领先指标的模式并提高预测的准确性。最后，结果表明，Google的“食物”和“旅游”类别大大减少了投影错误，强调了以细分方式使用此信息以改善宏观经济预测的重要性。]]></description>
      <guid>https://arxiv.org/abs/2503.21981</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用概率对称性破坏来改善均值网络</title>
      <link>https://arxiv.org/abs/2503.21985</link>
      <description><![CDATA[ARXIV：2503.21985V1公告类型：交叉 
摘要：模棱两可将已知对称性编码到神经网络中，通常会增强概括。但是，均值网络不能打破对称性：按照定义，等效网络的输出必须至少具有与输入相同的自我对称性。这构成了一个重要的问题，这两种问题（1）对于自我对称是常见的域上的预测任务，以及（2）对于生成模型，必须打破对称性才能从高度对称的潜在空间重建。可以通过考虑模棱两可的条件分布而不是均衡功能来解决这种基本限制。我们提出了新的理论结果，这些结果建立了代表此类分布的必要条件。具体而言，该表示形式提供了一个实用的框架，可以通过随机规范化在任何e夫网络中打破对称性。我们的方法，Sympe（破坏对称性的位置编码），在位置编码方面接受了一种简单的解释。这种方法扩大了模棱两可的网络的代表力，同时保留了对称性的电感偏见，我们通过概括范围证明这是合理的。实验结果表明，Sympe显着提高了图形，图形自动编码器和晶格旋转系统建模的扩散模型的组等级和图神经网络的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.21985</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>tempdisagg：时间分解时间序列数据的Python框架</title>
      <link>https://arxiv.org/abs/2503.22054</link>
      <description><![CDATA[ARXIV：2503.22054V1公告类型：交叉 
摘要：tempdisagg是一种现代，可扩展且可提供生产的Python框架，用于时间序列数据的时间分解。它使用多种计量经济学技术（包括Chow-lin，Denton，Litterman，Fernandez和统一的插值）将低频骨料转化为一致的高频估计，并及时增强了变体，并具有诸如自动启动式汇集的关键参数的自动估计。该软件包还介绍了超越经典方法的功能，包括通过非阴性最小二乘优化的稳健集合建模，在多个聚合规则下对负值的估计校正校正以及通过专用后极化器模块对缺失值的可选回归归档。在建筑上，它遵循了一个模块化设计，灵感来自Scikit-Learn，提供了干净的API，用于验证，建模，可视化和结果解释。]]></description>
      <guid>https://arxiv.org/abs/2503.22054</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经过模块化培训的经常性网络中的低级和稀疏傅立叶结构</title>
      <link>https://arxiv.org/abs/2503.22059</link>
      <description><![CDATA[ARXIV：2503.22059V1公告类型：交叉 
摘要：模块化添加任务是一个有用的测试床，可在深度学习中观察经验现象，包括\ emph {grokking}的现象。先前的工作表明，一层变压器体系结构学习傅立叶乘法电路以求解模块化的添加任务。在本文中，我们表明在模块化添加任务上训练的经过培训的复发性神经网络（RNN）也使用傅立叶乘法策略。我们将模型权重的低等级结构确定为特定的傅立叶频率，并将模型组件归因于特定的傅立叶频率，从而在傅立叶空间中稀疏表示。我们还从经验上表明，RNN可以强大地消除单个频率，而性能会大大降低，因为更多的频率是从模型中消失的。]]></description>
      <guid>https://arxiv.org/abs/2503.22059</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与竞争代理商一起学习的政策</title>
      <link>https://arxiv.org/abs/2204.01884</link>
      <description><![CDATA[ARXIV：2204.01884V5公告类型：替换 
摘要：决策者通常旨在根据他们可以治疗的代理人的能力限制来学习治疗任务政策。当代理商能够对此类政策进行战略性做出反应时，就会发生竞争，从而使对最佳政策的估计变得复杂。在本文中，我们研究了这种干扰存在的容量受限的治疗分配。我们考虑了一个动态模型，决策者在每个时间步骤中分配治疗方法，而异质的代理在近视上最适合先前的治疗作业政策。当代理数量较大但有限时，我们表明，根据给定政策，接受治疗的阈值会收敛于该政策的平均场均衡阈值。基于此结果，我们为策略梯度开发了一致的估计器。在1988年国家教育纵向研究的数据中，我们证明，在存在战略行为的情况下，该估计值可用于学习能力约束的政策。]]></description>
      <guid>https://arxiv.org/abs/2204.01884</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>压缩然后测试：在接近线性的时间内进行功能强大的内核测试</title>
      <link>https://arxiv.org/abs/2301.05974</link>
      <description><![CDATA[ARXIV：2301.05974V3公告类型：替换 
摘要：内核两样本测试提供了一个强大的框架，可根据$ n $样本点区分任何一对发行版。但是，现有的内核测试要么以$ n^2 $时间进行运行，要么牺牲不适当的功率来提高运行时。为了解决这些缺点，我们引入了压缩式测试（CTT），这是一个基于样品压缩的高功率内核测试的新框架。 CTT廉价地通过将每个$ n $ n $点样品压入一个小但可证明的高保真核心来近似于昂贵的测试。对于标准内核和亚指数分布，CTT继承了二次时间测试的统计行为 - 在接近线性的时间内运行时恢复相同的最佳检测边界。我们将这些进步与较便宜的排列测试相结合，这是通过新的功率分析证明的。时间vs.-质量保证的低等级近似值；以及一个快速的聚合程序，以识别特别区分内核。在我们使用真实和模拟数据的实验中，CTT及其扩展在最新的近似MMD测试中提供了20-200倍的加速，而没有功率损失。]]></description>
      <guid>https://arxiv.org/abs/2301.05974</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VAE的高维渐近学：后塌陷的阈值和数据集大小的依赖性速率曲线的依赖性</title>
      <link>https://arxiv.org/abs/2309.07663</link>
      <description><![CDATA[ARXIV：2309.07663V2公告类型：替换 
摘要：在变异自动编码器（VAE）中，变异后部经常崩溃到先前的（被称为后塌陷），这导致表示质量不佳。 VAE中引入了可调节的高参数beta，以解决此问题。这项研究彻底评估了通过在高维极限下分析最小VAE，而在β和数据集大小上发生后塌陷的情况。此外，此设置可以评估VAE的速率分数曲线。我们的结果表明，与典型的正则化参数不同，VAE面临着一定beta阈值的“不可避免的后塌陷”，无论数据集尺寸如何。此外，派生速率延伸曲线的数据集大小依赖性表明，需要相对较大的数据集来实现高率的利率延伸曲线。这些发现可靠地解释在具有高度非线性VAE的各种真实数据集中观察到的概括行为。]]></description>
      <guid>https://arxiv.org/abs/2309.07663</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>瓦斯尔斯坦空间中的多种学习</title>
      <link>https://arxiv.org/abs/2311.08549</link>
      <description><![CDATA[ARXIV：2311.08549V3公告类型：替换 
摘要：本文旨在在绝对连续概率的空间中建立流形学习算法的理论基础，$ \ Mathcal {p} _ {\ Mathrm {\ Mathrm {a.c。}}}}（\ omega）$带有$ \ omega $ compact and compact and convex of $ \ a imate $ \ mathbbbbbbbbbbbbbb i} $ \ mathbb {w} $。我们首先引入$ \ Mathcal {p} _ {\ Mathrm {a.c。}}（\ omega）$的submanifolds $ \ lambda $的构造（$ \ mathrm {\ mathrm {\ omega）$，配备了公制$ \ Mathbb {w} _ \ lambda $，$ \ \ $ \ $ \ \ $ {与其他构造相反，这些子手机不一定是平坦的，但仍允许以类似的方式进行本地线性化，与$ \ Mathbb {r}^d $的Riemannian Submanifolds。然后，我们将展示$（\ lambda，\ mathbb {w} _ {\ lambda}）$的潜在歧管结构如何从样本中学到$ \ {\ lambda_i \} _ { $ \ mathcal {p} _ {\ mathrm {a.c。}}}（\ omega）$。特别是，我们表明指标空间$（\ lambda，\ mathbb {w} _ {\ lambda}）$可以从与nodes $ \ {\ lambda_i \} _ _ = 1}^n $ = 1}^n $ = 1}^n $ from gromov- wasserstein的意义上渐近地恢复$ w（\ lambda_i，\ lambda_j）$。此外，我们还证明了如何使用从$ \ lambda $中的最佳传输映射到足够接近且多样的样品$ \ {\ lambda_i \ \ \ \ lambda_i \ \ \} _}^n off Fords o \ lambda $的最佳传输图来通过光谱分析来渐近地恢复样本$ \ lambda $的切线空间。该论文以Submanifolds $ \ lambda $的一些明确结构和数值示例结束，内容涉及通过光谱分析恢复切线空间的数值示例。]]></description>
      <guid>https://arxiv.org/abs/2311.08549</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在类似神经网络的架构中对尖端非线性的控制学习</title>
      <link>https://arxiv.org/abs/2408.13114</link>
      <description><![CDATA[ARXIV：2408.13114V2公告类型：替换 
摘要：我们提出了一个一般的变分框架，用于训练在受到某些斜率约束的层次计算体系结构中自由形式非线性的培训。我们添加到传统训练损失的正规化使每种可训练激活的二阶总变化处罚。斜率约束使我们能够施加诸如1-lipschitz稳定性，牢固的非扩张性和单调性/可逆性之类的属性。这些属性对于确保某些类别的信号处理算法的正确运行至关重要（例如，插件和播放方案，独立的近端近端梯度，可逆流）。我们证明，使用自适应非均匀线性细条的非线性实现了既定约束优化问题的全局最佳最佳。然后，我们通过以合适的（非均匀）B-Spline表示非线性来显示如何以数值来解决所得的功能优化问题。最后，我们通过（弱）凸正则化图像的数据驱动的设计来说明我们的框架的使用，以降级图像和反向问题的分辨率。]]></description>
      <guid>https://arxiv.org/abs/2408.13114</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>功能响应能力分数：索引的模型不足的解释</title>
      <link>https://arxiv.org/abs/2410.22598</link>
      <description><![CDATA[Arxiv：2410.22598V2公告类型：替换 
摘要：机器学习模型通常在贷款和招聘等应用程序中自动化决策。在这种情况下，消费者保护规则要求部署模型的公司向决策主体解释预测。这些规则是通过信念可以通过揭示个人可以用来竞争或改善其结果的信息来促进追索权的一种动机。实际上，许多公司通过为个人提供其预测最重要的功能列表来遵守这些规则，他们根据功能重要性得分从特征归因方法（例如Shap或lime）中识别出来。在这项工作中，我们展示了这些实践如何通过强调不会导致结果改善的功能并解释无法改变的预测来破坏消费者。我们建议通过根据其响应能力得分突出特征来解决这些问题，即个人可以通过更改特定功能来实现目标预测的可能性。我们开发有效的方法来计算任何模型和任何数据集的响应能力得分。我们对贷款解释的反应性进行了广泛的实证研究。我们的结果表明，消费者金融的标准实践可以通过向消费者提供理由而无需追索的原因而适得其反，并证明我们的方法如何通过突出响应式功能和确定固定的预测来改善消费者的保护。]]></description>
      <guid>https://arxiv.org/abs/2410.22598</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NN训练的频谱因素呈阳性曲率学习</title>
      <link>https://arxiv.org/abs/2502.06268</link>
      <description><![CDATA[Arxiv：2502.06268V3公告类型：替换 
摘要：许多训练方法，例如Adam（W）和洗发水，都可以学习一个正定曲率矩阵，并在预处理之前应用逆根。最近，诸如洗发水之类的非对抗训练方法引起了人们的重大关注。但是，由于矩阵分解昂贵的矩阵根计算，它们的计算效率低下，并且仅限于特定类型的曲率信息。为了解决这个问题，我们提出了一种黎曼优化方法，该方法可以动态适应光谱依次的阳性曲率估计，从而有效地应用了任意矩阵根和通用曲率学习。我们证明了我们方法在阳性原始基质优化和协方差适应性的无梯度优化中的功效和多功能性，以及其在曲率学习方面的神经网络培训方面的效率。]]></description>
      <guid>https://arxiv.org/abs/2502.06268</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对抗性强大的拓扑推断</title>
      <link>https://arxiv.org/abs/2206.01795</link>
      <description><![CDATA[Arxiv：2206.01795V2公告类型：替换 - 交叉 
摘要：紧凑型集合的距离函数在拓扑数据分析的范式中起着至关重要的作用。特别是，距离函数的级别集用于持续同源性的计算 - 拓扑数据分析管道的骨干。尽管它稳定在Hausdorff距离处扰动，但持续的同源性对异常值高度敏感。在这项工作中，我们在存在异常值的情况下开发了持续同源性统计学推断的框架。从鲁棒统计数据中的最新发展中汲取灵感，我们提出了距离函数（\ textsf {MOM DIST}）的\ textit {MEANS的中间}变体并建立了其统计属性。特别是，我们表明，即使在存在异常值的情况下，\ textsf {MOM DIST}引起的级别过滤和加权过滤都是真正基础种群对应物的一致估计量，并且在对抗性环境中的最小值 - 最佳性能附近展示。最后，我们通过模拟和应用来证明所提出的方法的优势。]]></description>
      <guid>https://arxiv.org/abs/2206.01795</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>