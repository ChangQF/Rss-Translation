<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 13 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用聚类捕获有向图进行异常得分</title>
      <link>https://arxiv.org/abs/2501.05530</link>
      <description><![CDATA[arXiv:2501.05530v1 公告类型：新
摘要：本文介绍了两种基于 Cluster Catch Digraphs (CCD) 的新型异常分数 (OS)：出站异常分数 (OOS) 和入站异常分数 (IOS)。这些分数增强了异常值检测结果的可解释性。这两种 OS 都采用基于图、密度和分布的技术，针对具有不同集群形状和强度的高维数据进行定制。 OOS 评估一个点相对于其最近邻居的异常程度，而 IOS 评估一个点从其集群中的其他点收到的总“影响”。这两个操作系统都能有效地识别全局和局部异常值，不受数据共线性的影响。此外，IOS 对掩蔽问题具有鲁棒性。通过广泛的蒙特卡罗模拟，我们将这两个操作系统的性能与基于 CCD、传统和最先进的异常值检测方法进行了比较。这两个操作系统在人工和现实世界数据集上都比基于 CCD 的方法表现出显着的整体改进，尤其是 IOS，它在所有方法中提供了最佳的整体性能，尤其是在高维设置中。
关键词：异常值检测、异常值得分、基于图的聚类、聚类捕获有向图、高维数据。]]></description>
      <guid>https://arxiv.org/abs/2501.05530</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协变量依赖混合贝叶斯网络</title>
      <link>https://arxiv.org/abs/2501.05745</link>
      <description><![CDATA[arXiv:2501.05745v1 公告类型：新
摘要：从数据中学习贝叶斯网络的结构可以洞察底层过程和生成数据的因果关系，但其实用性取决于数据群体的同质性，而这一条件在实际应用中经常被违反。在这种情况下，使用单一网络结构进行推理可能会产生误导，因为它可能无法捕捉到亚群体差异。为了解决这个问题，我们提出了一种新方法，即对贝叶斯网络的混合进行建模，其中组件概率取决于个人特征。我们的方法可以识别网络结构和亚群体成员的人口统计预测因素，从而帮助进行个性化干预。我们通过模拟和青少年心理健康案例研究评估了我们的方法，证明了它在改善健康、教育和社会政策方面的定制干预措施方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.05745</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模拟贝叶斯神经网络对权重分布的形状不敏感</title>
      <link>https://arxiv.org/abs/2501.05564</link>
      <description><![CDATA[arXiv:2501.05564v1 公告类型：交叉 
摘要：最近的研究表明，用均值场变分推理 (MFVI) 训练的贝叶斯神经网络 (BNN) 可以在模拟硬件中实现，与标准数字实现相比，有望节省大量能源。然而，虽然高斯通常用作 MFVI 中的变分分布，但很难精确控制采样模拟设备产生的噪声分布的形状。本文介绍了一种使用真实设备噪声作为变分分布进行 MFVI 训练的方法。此外，我们通过经验证明，无论变分分布的形状如何，具有相同权重均值和方差的 BNN 的预测分布都会收敛到相同的分布。这个结果表明，模拟设备设计人员在硬件实现执行 MFVI 的 BNN 时不需要考虑设备噪声分布的形状。]]></description>
      <guid>https://arxiv.org/abs/2501.05564</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>rmlnomogram：一个 R 包，用于为任何机器学习算法构建可解释的列线图</title>
      <link>https://arxiv.org/abs/2501.05772</link>
      <description><![CDATA[arXiv:2501.05772v1 公告类型：交叉 
摘要：背景：当前的列线图只能为回归算法创建。为任何机器学习 (ML) 算法提供列线图可能会加速临床环境中的模型部署或提高模型可用性。我们开发了一个 R 包和 Web 应用程序来构建具有任何 ML 算法的模型可解释性的列线图。方法：我们制定了一个函数将 ML 预测模型转换为列线图，需要具有以下特征的数据集：(1) 预测值的所有可能组合；(2) 模型的相应输出；(3) 每个预测因子的相应可解释性值（可选）。还创建了 Web 应用程序。结果：我们的 R 包可以为无概率的分类预测因子和二元结果 (1)、有概率的分类预测因子和二元结果 (2) 或连续结果 (3) 以及具有单个数值预测因子的分类和具有概率的二元结果 (4) 或连续结果 (5) 创建 5 种类型的列线图。分别地，第一种和剩余类型最佳地允许最多 15 个和 5 个预测因子，最多 3,200 个组合。Web 应用程序具有这样的限制。类型 2 到 5 的可解释性值是可能的。结论：我们的 R 包和 Web 应用程序可以使用相当数量的预测因子构建具有任何 ML 算法的模型可解释性的列线图。]]></description>
      <guid>https://arxiv.org/abs/2501.05772</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>随机稀疏提升：有限稀疏网络的构建、分析和收敛</title>
      <link>https://arxiv.org/abs/2501.05930</link>
      <description><![CDATA[arXiv:2501.05930v1 公告类型：交叉 
摘要：我们提出了一个框架来定义一大类神经网络，通过构造，当参数数量增加时，梯度流训练可以证明达到任意低的损失。与非凸优化的固定空间全局最优性不同，这种新的收敛形式以及为证明这种收敛而引入的技术为不久的将来可用的深度学习收敛理论铺平了道路，而无需与参数数量和训练样本相关的过度参数化假设。我们从一个简单的计算图和一个提升它的机制来定义这些架构，从而增加了参数的数量，概括了增加多层感知器宽度的想法。我们表明，此类中存在与大多数常见深度学习模型类似的架构，通过在初始化时稀疏化通常架构的权重张量来获得。利用代数拓扑和随机图论工具，我们使用计算图的几何形状来传播属性，保证这些大型稀疏模型收敛到任意精度。]]></description>
      <guid>https://arxiv.org/abs/2501.05930</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从离散时间策略到连续时间扩散采样器：渐近等价和更快的训练</title>
      <link>https://arxiv.org/abs/2501.06148</link>
      <description><![CDATA[arXiv:2501.06148v1 公告类型：交叉 
摘要：我们研究训练神经随机微分方程或扩散模型的问题，以便在没有目标样本的情况下从玻尔兹曼分布中采样。现有的训练此类模型的方法使用可微分模拟或离线强化学习 (RL) 来强制生成和噪声过程的时间反转。我们证明了无穷小离散化步骤极限下目标族之间的等价性，将熵 RL 方法 (GFlowNets) 与连续时间对象 (偏微分方程和路径空间度量) 联系起来。我们进一步表明，在训练过程中适当选择粗时间离散化可以大大提高样本效率和使用时间局部目标，从而以降低计算成本在标准采样基准上实现具有竞争力的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.06148</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高斯混合熵近似的理论误差分析</title>
      <link>https://arxiv.org/abs/2202.13059</link>
      <description><![CDATA[arXiv:2202.13059v5 公告类型：替换 
摘要：高斯混合分布通常用于表示一般概率分布。尽管使用高斯混合进行不确定性估计非常重要，但高斯混合的熵无法通过分析计算。在本文中，我们研究了近似熵，该近似熵表示为具有混合系数的单峰高斯分布的熵之和。无论维度如何，这种近似都很容易通过分析计算，但缺乏理论保证。我们从理论上分析了真实熵和近似熵之间的近似误差，以揭示这种近似何时有效。这个误差本质上是由高斯混合中每个高斯分量之间的距离控制的。为了测量这种分离，我们引入了均值与高斯混合中每个高斯分量的方差之和之间的距离之比，并揭示了当比率趋于无穷大时，误差收敛到零。此外，概率估计表明这种收敛情况更有可能发生在高维空间中。因此，我们的结果保证了这种近似对于高维问题（例如涉及大量参数的神经网络）非常有效。]]></description>
      <guid>https://arxiv.org/abs/2202.13059</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有多元非线性的神经结构的函数空间最优性</title>
      <link>https://arxiv.org/abs/2310.03696</link>
      <description><![CDATA[arXiv:2310.03696v3 公告类型：替换 
摘要：我们研究了一大类具有多元非线性/激活函数的浅层神经结构的函数空间最优性（特别是 Banach 空间最优性）。为此，我们构建了一个新的 Banach 空间系列，该系列通过正则化算子、$k$ 平面变换和稀疏性促进范数定义。我们证明了一个表示定理，该定理指出，在这些 Banach 空间上提出的学习问题的解集完全由具有多元非线性的神经结构表征。这些最优架构具有跳过连接，并与正交权重归一化和多指标模型紧密相关，这两者最近都引起了神经网络社区的关注。我们的框架与许多经典非线性兼容，包括整流线性单元 (ReLU) 激活函数、范数激活函数和薄板/多谐波样条理论中的径向基函数。我们还表明，底层空间是再生核 Banach 空间和变分空间的特殊实例。我们的研究结果揭示了神经网络在数据上训练时学习到的函数的规律性，尤其是多变量非线性函数，并为实践中发现的几种架构选择提供了新的理论动机。]]></description>
      <guid>https://arxiv.org/abs/2310.03696</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于多视图学习的贝叶斯联合加性因子模型</title>
      <link>https://arxiv.org/abs/2406.00778</link>
      <description><![CDATA[arXiv:2406.00778v3 公告类型：替换 
摘要：在各种应用环境中，在同一组样本上收集多种不同类型的数据越来越普遍。我们在本文中特别关注的是研究这种多视图特征与响应之间的关系。在精准医疗的背景下出现了一个激励应用，其中收集多组学数据以与临床结果相关联。在结合多模态信息以改进结果预测的同时，推断视图内和视图之间的依赖关系是很有意义的。信噪比在不同视图之间可能会有很大差异，这促使人们使用比标准晚期和早期融合更细致的统计工具。这一挑战伴随着保持可解释性、选择特征和获得准确的不确定性量化的需求。我们提出了一种联合加性因子回归模型 (JAFAR)，该模型具有结构化的加性设计，考虑了共享和特定于视图的组件。我们通过一种新颖的依赖累积收缩过程 (D-CUSP) 先验确保可识别性。我们通过部分折叠的 Gibbs 采样器提供有效的实现，并扩展我们的方法以允许灵活的特征和结果分布。从免疫组、代谢组和蛋白质组数据预测分娩开始时间表明，与最先进的竞争对手相比，我们的性能有所提高。我们的开源软件（R 包）可在 https://github.com/niccoloanceschi/jafar 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.00778</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无需等待的离线调优和重新求解，实现在线决策</title>
      <link>https://arxiv.org/abs/2412.09594</link>
      <description><![CDATA[arXiv:2412.09594v2 公告类型：替换 
摘要：在线线性规划 (OLP) 在收入管理和资源分配中得到了广泛的应用。最先进的 OLP 算法通过反复求解包含更新资源信息的线性规划 (LP) 子问题来实现低遗憾。然而，基于 LP 的方法计算成本高，并且对于大规模应用通常效率低下。相比之下，最近的一阶 OLP 算法计算效率更高，但通常遗憾保证更差。为了解决这些缺点，我们提出了一种结合基于 LP 和一阶 OLP 方法优势的新算法。该算法以预定义频率 $f$ 定期重新求解 LP 子问题，并使用最新的对偶价格来指导在线决策。此外，一阶方法在 LP 重新求解之间的每个间隔内并行运行，从而平滑资源消耗。我们的算法实现了$\mathscr{O}(\log (T/f) + \sqrt{f})$遗憾，提供了一种“无等待”的在线决策过程，平衡了一阶方法的计算效率和基于 LP 的方法的卓越遗憾保证。]]></description>
      <guid>https://arxiv.org/abs/2412.09594</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>朴素特征选择：稀疏朴素贝叶斯的近乎紧凸松弛</title>
      <link>https://arxiv.org/abs/1905.09884</link>
      <description><![CDATA[arXiv:1905.09884v3 公告类型：replace-cross 
摘要：由于其线性复杂性，朴素贝叶斯分类仍然是一种有吸引力的监督学习方法，尤其是在非常大规模的环境中。我们提出了一种稀疏版本的朴素贝叶斯，可用于特征选择。这导致了一个组合最大似然问题，对于该问题，我们在二进制数据的情况下提供了一个精确的解决方案，或者在多项式情况下提供了一个界限。我们证明，随着附加特征的边际贡献减少，我们的凸松弛界限变得紧密，使用从 Shapley-Folkman 定理推导出来的先验对偶间隙界限。我们展示了如何生成满足这些界限的原始解决方案。二进制和多项式稀疏模型都可以在问题规模上几乎线性地在时间上求解，与经典的朴素贝叶斯相比，这代表了非常小的额外相对成本。在文本数据上进行的数值实验表明，朴素贝叶斯特征选择方法在统计上与最先进的特征选择方法（例如递归特征消除、$l_1$ 惩罚逻辑回归和 LASSO）一样有效，同时速度要快几个数量级。]]></description>
      <guid>https://arxiv.org/abs/1905.09884</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>共形数据合成</title>
      <link>https://arxiv.org/abs/2312.08999</link>
      <description><![CDATA[arXiv:2312.08999v2 公告类型：replace-cross 
摘要：随着日益复杂的深度学习架构的激增，数据合成是一种非常有前途的技术，可以满足数据饥渴模型的需求。然而，可靠地评估“合成器”模型输出的质量是一个开放的研究问题，对于高风险领域具有重大相关风险。为了应对这一挑战，我们提出了一种独特的合成算法，该算法基于共形预测框架从高置信度特征空间区域生成数据。我们通过全面探索核心参数的影响、深入讨论实用建议以及对五个基准数据集进行广泛的实证评估来支持我们提出的算法。为了展示我们的方法在普遍存在的现实世界挑战中的多功能性，数据集是根据其各种困难特征精心挑选的：样本数量少、类别不平衡和不可分离性。在所有试验中，使用我们可信的合成数据扩展的训练集的表现至少与原始集一样好，并且经常显著提高深度学习性能，F1 分数最高可达 61 个百分点。]]></description>
      <guid>https://arxiv.org/abs/2312.08999</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用距离剖面进行稳健点匹配</title>
      <link>https://arxiv.org/abs/2312.12641</link>
      <description><![CDATA[arXiv:2312.12641v5 公告类型：replace-cross 
摘要：我们展示了基于距离轮廓的实际匹配程序的异常值稳健性和噪声稳定性。尽管基于距离轮廓等不变量匹配点的想法在文献中由来已久，但人们对此类程序的理论特性了解甚少，尤其是在存在异常值和噪声的情况下。我们提供了理论分析，表明在某些概率设置下，即使存在异常值和噪声，所提出的匹配程序也能以高概率成功。我们使用真实数据示例展示了所提出方法的性能，并提供了模拟研究来补充理论发现。最后，我们将距离轮廓的概念扩展到抽象设置，并将所提出的匹配程序与 Gromov-Wasserstein 距离及其下限联系起来，并根据距离轮廓的属性得出了新的样本复杂度结果。本文通过提供基于距离轮廓等不变量的匹配程序的理论基础为文献做出了贡献，这些不变量在实践中得到了广泛应用，但很少进行理论分析。]]></description>
      <guid>https://arxiv.org/abs/2312.12641</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过分解梯度下降恢复低管秩张量</title>
      <link>https://arxiv.org/abs/2401.11940</link>
      <description><![CDATA[arXiv:2401.11940v3 公告类型：replace-cross 
摘要：本文考虑了从少量损坏的线性测量中恢复具有底层低管秩结构的张量的问题。解决此类问题的传统方法需要计算张量奇异值分解 (t-SVD)，这是一个计算密集型过程，因此不适用于处理大规模张量。为了应对这一挑战，我们提出了一种基于类似于 Burer-Monteiro (BM) 方法的分解程序的高效低管秩张量恢复方法。确切地说，我们的基本方法是将大张量分解为两个较小的因子张量，然后通过分解梯度下降 (FGD) 解决问题。该策略消除了对 t-SVD 计算的需求，从而降低了计算成本和存储要求。我们提供了严格的理论分析，以确保 FGD 在无噪声和有噪声情况下的收敛性。此外，值得注意的是，我们的方法不需要精确估计张量的 tubal-rank。即使在 tubal-rank 被稍微高估的情况下，我们的方法仍然表现出稳健的性能。一系列实验表明，与其他流行的方法相比，我们的方法在多种场景中表现出优越的性能，包括更快的计算速度和更小的收敛误差。]]></description>
      <guid>https://arxiv.org/abs/2401.11940</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高维贝叶斯优化的预期坐标改进</title>
      <link>https://arxiv.org/abs/2404.11917</link>
      <description><![CDATA[arXiv:2404.11917v2 公告类型：replace-cross 
摘要：贝叶斯优化 (BO) 算法在解决低维昂贵优化问题中非常流行。将贝叶斯优化扩展到高维是一项有意义但具有挑战性的任务。主要挑战之一是很难找到好的填充解决方案，因为获取函数也是高维的。在这项工作中，我们提出了高维贝叶斯优化的预期坐标改进 (ECI) 标准。所提出的 ECI 标准衡量了通过将当前最佳解决方案沿一个坐标移动可以获得的潜在改进。所提出的方法在每次迭代中选择具有最高 ECI 值的坐标进行细化，并通过迭代坐标逐渐覆盖所有坐标。所提出的 ECI-BO（基于预期坐标改进的贝叶斯优化）算法相对于标准 BO 算法的最大优势在于，所提出的算法的填充选择问题始终是一个一维问题，因此可以轻松解决。数值实验表明，该算法的计算结果明显优于标准贝叶斯算法，与五种最先进的高维贝叶斯算法相比也具有竞争力，为高维贝叶斯优化提供了一种简单而有效的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.11917</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>