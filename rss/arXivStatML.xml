<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 15 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>深度学习的拓扑可解释性</title>
      <link>https://arxiv.org/abs/2305.08642</link>
      <description><![CDATA[arXiv:2305.08642v2 公告类型：替换
摘要：随着基于人工智能的系统在日常生活中的日益普及，了解其决策机制的需求也相应增加。我们对基于人工智能的决策系统做出的统计推论的信任程度越来越受到关注，特别是在刑事司法或医疗诊断等高风险系统中，不正确的推论可能会带来悲惨的后果。尽管深度学习 (DL) 模型成功地为涉及现实世界数据的问题提供了解决方案，但仍无法量化其预测的确定性。这些模型通常非常有信心，即使它们的解决方案不正确。
  这项工作提出了一种方法，通过采用拓扑和几何数据分析技术来推断在临床和非临床文本上训练的两个深度学习分类模型中的显着特征。我们创建模型特征空间的图，并通过特征和预测统计数据的相似性将输入聚集到图的顶点中。然后，我们提取子图，展示给定标签的高预测准确性。这些子图包含有关深度学习模型已识别为其决策相关的特征的大量信息。我们使用概率度量之间的距离度量来推断给定标签的这些特征，并证明我们的方法与 LIME 和 SHAP 可解释性方法相比的稳定性。这项工作表明我们可以深入了解深度学习模型的决策机制。这种方法使我们能够确定模型是否根据与问题密切相关的信息做出决策，或者是否识别数据中的无关模式。]]></description>
      <guid>https://arxiv.org/abs/2305.08642</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>用于截断密度估计的近似斯坦因类</title>
      <link>https://arxiv.org/abs/2306.00602</link>
      <description><![CDATA[arXiv:2306.00602v2 公告类型：替换
摘要：估计截断密度模型很困难，因为这些模型具有棘手的归一化常数并且难以满足边界条件。分数匹配可以用来解决截断密度估计问题，但需要一个连续的加权函数，该函数在边界处取零，在其他地方取正值。这种加权函数（及其梯度）的评估通常需要截断边界的封闭形式表达式并找到复杂优化问题的解决方案。在本文中，我们提出了近似的斯坦因类，这反过来又导致了用于截断密度估计的宽松斯坦因恒等式。我们开发了一种新颖的差异度量，截断核斯坦因差异（TKSD），它不需要提前固定权重函数，并且可以仅使用边界上的样本进行评估。我们通过最小化 TKSD 的拉格朗日对偶来估计截断密度模型。最后，实验表明，即使没有边界的显式函数形式，我们的方法的准确性也比以前的工作有所改进。]]></description>
      <guid>https://arxiv.org/abs/2306.00602</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>使用可解释的人工智能和迁移学习通过有限的观测数据来理解和预测大西洋阻塞的维持</title>
      <link>https://arxiv.org/abs/2404.08613</link>
      <description><![CDATA[arXiv:2404.08613v1 公告类型：交叉
摘要： 阻塞事件是极端天气的重要原因，尤其是持续时间较长的阻塞事件会使天气系统陷入困境。然而，气候模型低估了阻塞事件的持续时间。可解释的人工智能是一类数据分析方法，可以帮助识别长期阻塞事件的物理原因并诊断模型缺陷。我们在 Marshall 和 Molteni (1993) 开发的理想化准地转模型上演示了这种方法。我们训练了一个卷积神经网络（CNN），随后建立了一个以初始高压异常为条件的大西洋阻塞持续性的稀疏预测模型。沙普利加法解释（SHAP）分析表明，美国东南部和北大西洋的高压异常（由加拿大大西洋上空的槽分开）对预测大西洋地区持续阻塞事件有重大贡献。这与之前通过波列分析识别同一区域的前兆的工作一致。当我们将相同的 CNN 应用于 ERA5 大气再分析中的阻塞时，没有足够的数据来准确预测持久性阻塞。我们通过利用 Marshall-Molteni 模型的大量数据对 CNN 进行预训练，然后使用迁移学习来实现比直接训练更好的预测，从而部分克服了这一限制。迁移学习之前和之后的 SHAP 分析可以对再分析和准地转模型中的预测特征进行比较，从而量化理想化模型中的动态偏差。这项工作展示了机器学习方法提取有意义的极端天气事件前兆并利用有限的观测数据实现更好预测的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.08613</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>RFFNet：通过随机傅里叶特征的大规模可解释核方法</title>
      <link>https://arxiv.org/abs/2211.06410</link>
      <description><![CDATA[arXiv:2211.06410v2 公告类型：替换
摘要：核方法为非线性和非参数学习提供了一种灵活且有理论依据的方法。虽然内存和运行时要求阻碍了它们对大型数据集的适用性，但最近开发了许多低秩核近似（例如随机傅里叶特征）来扩展此类核方法。然而，这些可扩展的方法基于各向同性核的近似，无法消除不相关特征的影响。在这项工作中，我们为一系列自动相关性确定（ARD）内核设计了随机傅立叶特征，并引入了 RFFNet，这是一种新的大规模内核方法，可通过一阶随机优化动态学习内核相关性。我们为该方法的非凸目标函数提出了一种有效的初始化方案，评估硬阈值 RFFNet 的学习相关性是否为变量选择产生合理的规则，并对 RFFNet 的组件进行了广泛的消融研究。对模拟和真实数据的数值验证表明，我们的方法具有较小的内存占用和运行时间，实现了较低的预测误差，并有效地识别相关特征，从而产生更具可解释性的解决方案。我们为用户提供一个高效的、基于 PyTorch 的库，该库遵循 scikit-learn 标准 API 和代码，用于完全重现我们的结果。]]></description>
      <guid>https://arxiv.org/abs/2211.06410</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>具有核 Stein 差异的极小极大最优拟合优度检验</title>
      <link>https://arxiv.org/abs/2404.08278</link>
      <description><![CDATA[arXiv:2404.08278v1 公告类型：交叉
摘要：我们使用核化斯坦因差异（KSD）探索一般域拟合优度检验的极小极大最优性。 KSD 框架提供了一种灵活的拟合优度测试方法，避免强分布假设，适应欧几里得空间之外的各种数据结构，并且仅依赖参考分布的部分知识，同时保持计算效率。我们建立了 KSD 的通用框架和算子理论表示，包含文献中许多现有的 KSD 测试，这些测试因领域而异。我们揭示了 KSD 的特征和局限性，并证明了它在特定替代空间下的非最优性，当考虑 $\chi^2$-divergence 作为分离度量时，在一般域上定义。为了解决这个非最优问题，我们提出了一种修改后的极小极大最优测试，通过结合频谱正则化器，从而克服了标准 KSD 测试的缺点。我们的结果是在 Stein 核的弱矩条件下建立的，这放宽了基于核的假设检验分析中先前工作所需的有界核假设。此外，我们引入了一种自适应测试，能够通过适应未知参数来实现对数因子的极小极大最优性。通过数值实验，我们说明了与非正则化的测试相比，我们提出的测试在各个领域的优越性能。]]></description>
      <guid>https://arxiv.org/abs/2404.08278</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>TSLANet：重新思考时间序列表示学习的 Transformer</title>
      <link>https://arxiv.org/abs/2404.08472</link>
      <description><![CDATA[arXiv:2404.08472v1 公告类型：交叉
摘要：时间序列数据以其内在的长期和短期依赖性为特征，对分析应用程序提出了独特的挑战。虽然基于 Transformer 的模型擅长捕获远程依赖性，但它们在噪声敏感性、计算效率以及较小数据集的过度拟合方面面临限制。为此，我们引入了一种新颖的时间序列轻量级自适应网络（TSLANet），作为各种时间序列任务的通用卷积模型。具体来说，我们提出了一个自适应谱块，利用傅立叶分析来增强特征表示并捕获长期和短期交互，同时通过自适应阈值减轻噪声。此外，我们引入了交互式卷积块，并利用自监督学习来改进 TSLANet 解码复杂时间模式的能力，并提高其在不同数据集上的鲁棒性。我们的综合实验表明，TSLANet 在分类、预测和异常检测等各种任务中均优于最先进的模型，展示了其在各种噪声水平和数据大小范围内的弹性和适应性。该代码位于 \url{https://github.com/emadeldeen24/TSLANet}]]></description>
      <guid>https://arxiv.org/abs/2404.08472</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>指数加权移动模型</title>
      <link>https://arxiv.org/abs/2404.08136</link>
      <description><![CDATA[arXiv:2404.08136v1 公告类型：交叉
摘要：向量时间序列的指数加权移动模型（EWMM）基于过去观测数据的指数衰减损失函数，在每个时间段拟合一个新的数据模型。众所周知且广泛使用的指数加权移动平均线 (EWMA) 是一种特殊情况，它使用平方损失函数来估计平均值。对于二次损失函数，可以使用更新二次函数参数的简单递归来拟合 EWMM。对于其他损失函数，必须存储整个过去的历史，并且拟合问题随着时间的增加而变得越来越大。我们提出了一种计算 EWMM 近似值的通用方法，该方法只需要存储固定数量的过去样本的窗口，并使用附加的二次项来近似与窗口之前的数据相关的损失。这种近似 EWMM 依赖于凸优化，并解决不随时间增长的问题。我们将近似产生的估计值与精确 EWMM 方法的估计值进行比较。]]></description>
      <guid>https://arxiv.org/abs/2404.08136</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>通过回归分类进行保形预测</title>
      <link>https://arxiv.org/abs/2404.08168</link>
      <description><![CDATA[arXiv:2404.08168v1 公告类型：交叉
摘要：回归的保形预测（CP）可能具有挑战性，特别是当输出分布是异方差、多模态或倾斜时。有些问题可以通过估计输出的分布来解决，但实际上，这种方法可能对估计误差敏感并产生不稳定的区间。~在这里，我们通过将回归问题转换为分类问题然后使用 CP 来规避这些挑战用于分类以获得用于回归的 CP 集。〜为了保持连续输出空间的顺序，我们设计了一个新的损失函数并对 CP 分类技术进行了必要的修改。〜许多基准的经验结果表明，这种简单的方法给出了令人惊讶的结果在许多实际问题上取得了良好的效果。]]></description>
      <guid>https://arxiv.org/abs/2404.08168</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>镜像下降的虚假平稳性和硬度结果</title>
      <link>https://arxiv.org/abs/2404.08073</link>
      <description><![CDATA[arXiv:2404.08073v1 公告类型：交叉
摘要：尽管 Bregman 近端型算法（例如镜像下降）在机器学习中取得了相当大的成功，但仍然存在一个关键问题：通常基于 Bregman 散度的现有平稳性度量能否可靠地区分平稳点和非平稳点？在本文中，我们提出了一个突破性的发现：所有现有的平稳性度量都必然意味着虚假平稳点的存在。我们进一步建立了一个与算法无关的硬度结果：当初始点不利时，即使对于凸问题，Bregman 近端型算法也无法以有限步逃离虚假驻点。我们的硬度结果指出了欧几里得几何和布雷格曼几何之间的固有区别，并向机器学习和优化社区引入了基础理论和数值挑战。]]></description>
      <guid>https://arxiv.org/abs/2404.08073</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的帧量化</title>
      <link>https://arxiv.org/abs/2404.08131</link>
      <description><![CDATA[arXiv:2404.08131v1 公告类型：交叉
摘要：我们提出了一种训练后量化算法，其误差估计依赖于框架理论的思想。具体来说，我们对有限单位范数紧框架使用一阶 Sigma-Delta ($\Sigma\Delta$) 量化来量化神经网络中的权重矩阵和偏差。在我们的场景中，我们在步长和帧元素数量方面得出原始神经网络和量化神经网络之间的误差界限。我们还演示了如何利用帧的冗余来实现更高精度的量化神经网络。]]></description>
      <guid>https://arxiv.org/abs/2404.08131</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>PINNACLE：PINN 自适应搭配和实验点选择</title>
      <link>https://arxiv.org/abs/2404.07662</link>
      <description><![CDATA[arXiv:2404.07662v1 公告类型：交叉
摘要：物理信息神经网络（PINN）将偏微分方程作为软约束，使用包含多种训练点类型的复合损失函数进行训练：在训练过程中选择不同类型的搭配点来强制执行每个偏微分方程和初始/边界条件，以及通过实验或模拟获得通常成本高昂的实验点。使用这种损失函数训练 PINN 具有挑战性，因为它通常需要选择大量不同类型的点，每个点具有不同的训练动态。与过去专注于搭配或实验点选择的工作不同，这项工作引入了 PINN 自适应搭配位置和实验点选择（PINNACLE），这是第一个联合优化所有训练点类型选择的算法，同时自动调整搭配比例随着训练的进行，点类型。 PINNACLE 基于通过神经正切核 (NTK) 对 PINN 训练动态的分析，使用了之前未考虑过的训练点类型之间相互作用的信息。我们从理论上证明了 PINNACLE 使用的标准与 PINN 泛化误差相关，并从经验上证明了 PINNACLE 在正向、逆向和迁移学习问题上能够优于现有的点选择方法。]]></description>
      <guid>https://arxiv.org/abs/2404.07662</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>结合统计深度和费马距离进行不确定性量化</title>
      <link>https://arxiv.org/abs/2404.08476</link>
      <description><![CDATA[arXiv:2404.08476v1 公告类型：新
摘要：我们使用称为“透镜深度”（LD）的统计概念与费马距离相结合来测量神经网络预测中的域外不确定性，该概念能够精确捕获物体的“深度”。点相对于特征空间中的分布，而不对分布形式进行任何假设。我们的方法没有可训练的参数。该方法适用于任何分类模型，因为它在测试时直接应用于特征空间并且不干预训练过程。因此，它不会影响原始模型的性能。所提出的方法在玩具数据集上提供了出色的定性结果，并且与强基线方法相比，可以对标准深度学习数据集提供有竞争力或更好的不确定性估计。]]></description>
      <guid>https://arxiv.org/abs/2404.08476</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>滑下楼梯：相关潜在变量如何利用神经网络加速学习</title>
      <link>https://arxiv.org/abs/2404.08602</link>
      <description><![CDATA[arXiv:2404.08602v1 公告类型：新
摘要：神经网络使用随机梯度下降（SGD）从数据中提取特征。特别是，高阶输入累积量（HOC）对其性能至关重要。然而，从 $d$ 维输入的第 $p$th 累积量中提取信息在计算上是困难的：使用在线 SGD 从 $p$ 阶张量（张量 PCA）恢复单个方向所需的样本数量随着 $ d^{p-1}$，这对于高维输入是禁止的。这一结果提出了神经网络如何有效地从其输入的 HOC 中提取相关方向的问题。在这里，我们表明，沿不同输入累积量编码的方向的潜在变量之间的相关性加速了从高阶相关性中的学习。我们通过从高维度随机开始使用在线 SGD 来弱恢复这些方向所需的单个神经元所需的样本数量得出近乎尖锐的阈值，从而分析地展示了这种效应。我们的分析结果在两层神经网络的模拟中得到了证实，并揭示了神经网络中分层学习的新机制。]]></description>
      <guid>https://arxiv.org/abs/2404.08602</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>通过仿真优化提示选择语言模型</title>
      <link>https://arxiv.org/abs/2404.08164</link>
      <description><![CDATA[arXiv:2404.08164v1 公告类型：新
摘要：随着生成语言模型的进步，提示的选择近年来引起了人们的广泛关注。提示是用户提供的指令或描述，作为内容生成中生成语言模型的指导。尽管现有的提示选择方法是基于人工的，但我们考虑通过模拟优化来促进这种选择，旨在最大化所选提示的预定义分数。具体来说，我们提出了一个两阶段框架。在第一阶段，我们确定足够数量的可行提示集，其中每个提示由一个中等维度的向量表示。在评估和选择的后续阶段，我们构建了关于代表提示的中等维度向量的分数代理模型。我们建议根据构建的代理模型依次选择评估提示。我们证明了我们框架中顺序评估程序的一致性。我们还进行数值实验来证明我们提出的框架的有效性，为实施提供实际指导。]]></description>
      <guid>https://arxiv.org/abs/2404.08164</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>论神经符号学习中的独立性假设</title>
      <link>https://arxiv.org/abs/2404.08458</link>
      <description><![CDATA[arXiv:2404.08458v1 公告类型：新
摘要：最先进的神经符号学习系统使用概率推理来引导神经网络进行符合符号逻辑约束的预测。许多此类系统假设所考虑的符号的概率在给定输入的情况下是条件独立的，以简化学习和推理。我们研究并批评了这一假设，强调它如何阻碍优化并阻止不确定性量化。我们证明，损失函数会使条件独立的神经网络产生偏差，使其对其预测变得过于自信。因此，他们无法代表多个有效选项的不确定性。此外，我们证明这些损失函数很难优化：它们是非凸的，并且它们的最小值通常是高度断开的。我们的理论分析为取代条件独立假设和设计更具表现力的神经符号概率模型奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2404.08458</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:37 GMT</pubDate>
    </item>
    </channel>
</rss>