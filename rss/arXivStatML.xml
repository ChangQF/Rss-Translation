<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Wed, 03 Jan 2024 03:14:23 GMT</lastBuildDate>
    <item>
      <title>非线性约束下的加速一阶优化。 （arXiv：2302.00316v2 [math.OC] 已更新）</title>
      <link>http://arxiv.org/abs/2302.00316</link>
      <description><![CDATA[我们利用一阶算法之间的类比来进行约束
优化和非光滑动力系统来设计一类新的
用于约束优化的加速一阶算法。不像
Frank-Wolfe 或投影梯度，这些算法避免了优化
每次迭代时的整个可行集。我们证明收敛到平稳
即使在非凸设置中，我们也得出了加速率
连续时间和离散时间的凸设置。一个
这些算法的重要属性是约束表达为
用速度而不是位置来表示，这自然会导致稀疏，
可行集的局部和凸近似（即使可行集
是非凸的）。因此，复杂性往往随着数量的增加而温和增长。
决策变量和约束的数量，这使得算法
适合机器学习应用。我们将我们的算法应用到
压缩感知和稀疏回归问题，表明我们可以处理
有效地非凸 $\ell^p$ 约束 ($p&lt;1$)，同时恢复
$p=1$ 的最先进性能。
]]></description>
      <guid>http://arxiv.org/abs/2302.00316</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>上下文套索：通过深度神经网络的稀疏线性模型。 （arXiv：2302.00878v4 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2302.00878</link>
      <description><![CDATA[稀疏线性模型是可解释机器的几个核心工具之一
随着预测模型的渗透，学习是一个日益重要的领域
许多领域的决策。不幸的是，稀疏线性模型还远远不够。
其输入特征的功能不如黑盒模型灵活，例如
深度神经网络。考虑到这种能力差距，我们研究了一个并不罕见的问题
输入特征二分为两组的情况：解释性
特征，它们是作为可解释变量中的变量包含的候选者
模型和上下文特征，从候选变量中选择
确定它们的效果。这种二分法将我们引向上下文套索，一种新的
将稀疏线性模型拟合到解释性的统计估计器
稀疏模式和系数作为函数变化的特征
上下文特征。拟合过程学习这个函数
通过深度神经网络非参数化。为了获得稀疏系数，我们
使用投影形式的新颖套索正则化器训练网络
将网络输出映射到 $\ell_1$ 约束空间的层
线性模型。对真实数据和合成数据进行一系列广泛的实验
表明仍然高度透明的学习模型可以
比常规套索更稀疏，而不牺牲预测能力
标准深度神经网络。
]]></description>
      <guid>http://arxiv.org/abs/2302.00878</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>广义线性老虎机中的排名。 （arXiv：2207.00109v2 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2207.00109</link>
      <description><![CDATA[我们研究广义线性老虎机中的排名问题。每一次，
学习代理选择一个有序的项目列表并观察随机
结果。在推荐系统中，显示最热门的有序列表
由于位置和项目依赖性，有吸引力的项目并不总是最佳的
导致复杂的奖励函数。一个非常幼稚的例子是缺乏
当所有最有吸引力的物品都来自同一类别时，多样性。我们
对有序列表中的位置和项目依赖性进行建模并设计 UCB 和
针对此问题的汤普森采样类型算法。我们的工作概括了
现有的几个方向的研究，包括位置依赖性
位置折扣是一个特殊情况，并将排名问题连接到
图论。
]]></description>
      <guid>http://arxiv.org/abs/2207.00109</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>使用条件扩散模型的有损图像压缩。 （arXiv：2209.06950v8 [eess.IV] 已更新）</title>
      <link>http://arxiv.org/abs/2209.06950</link>
      <description><![CDATA[本文概述了一种端到端优化的有损图像压缩框架
使用扩散生成模型。该方法依赖于变换编码
范式，其中图像被映射到潜在空间以进行熵编码，并且，
从那里，映射回数据空间以进行重建。相比之下
基于 VAE 的神经压缩，其中（平均）解码器是确定性的
神经网络，我们的解码器是条件扩散模型。我们的方法因此
引入了一个额外的“content”潜在变量，在该变量上进行相反的操作
扩散过程是有条件的，并使用该变量来存储信息
关于图像。剩余的“纹理”变量表征
扩散过程在解码时综合。我们证明模型的
性能可以针对感兴趣的感知指标进行调整。我们广泛的
涉及多个数据集和图像质量评估指标的实验
表明我们的方法比基于 GAN 的方法产生更强的 FID 分数
模型，同时还可以与基于 VAE 的模型产生具有竞争力的性能
几个失真指标。此外，训练扩散
$\mathcal{X}$-参数化只需一次即可实现高质量重建
解码步骤很少，极大地影响了模型的实用性。我们的代码
位于：\url{https://github.com/buggyyang/CDC_compression}
]]></description>
      <guid>http://arxiv.org/abs/2209.06950</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>线性时不变动力系统的联合学习。 （arXiv：2112.10955v6 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2112.10955</link>
      <description><![CDATA[线性时不变系统是系统论和数学领域中非常流行的模型
应用程序。系统识别中仍然存在的一个基本问题
现有文献中尚未解决的问题是利用之间的共性
相关的线性系统，以更准确地估计其转移矩阵。
为了解决这个问题，本文研究了联合的方法
估计多个系统的转移矩阵。假设
转移矩阵是某些未知共享基的未知线性函数
矩阵。我们建立了充分反映有限时间估计错误率
轨迹长度、尺寸和系统数量的作用
考虑。所呈现的结果相当一般并表明
通过跨系统汇集数据可以实现显着的收益
与单独学习每个系统的比较。此外，它们被证明是
对模型错误指定具有鲁棒性。为了获得结果，我们开发了新颖的
对于解决类似的联合学习问题感兴趣的技术。
它们包括严格限制的估计误差
过渡矩阵的特征结构，建立尖锐的高概率
相关随机矩阵的奇异值的界限以及捕获效果
随着系统随着时间的推移而演变，会出现错误指定的转移矩阵。
]]></description>
      <guid>http://arxiv.org/abs/2112.10955</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:20 GMT</pubDate>
    </item>
    <item>
      <title>有效地理清因果关系。 （arXiv：2201.01942v2 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2201.01942</link>
      <description><![CDATA[本文提出了一种有效的学习解缠结方法
基于条件差异的因果机制表示
原始分布和新分布的概率。我们估算差异
具有模型的泛化能力，使其适合标准机器
学习框架并可以有效地计算。相比之下
最先进的方法，依赖于学习者的适应速度
新的分布，所提出的方法只需要评估模型的
泛化能力。我们为优势提供了理论解释
所提出的方法，我们的实验表明所提出的技术是
样本效率提高 1.9--11.0$\times$，速度比之前的 9.4--32.4 倍
以前的方法处理各种任务。源代码位于
\url{https://github.com/yuanpeng16/EDCR}。
]]></description>
      <guid>http://arxiv.org/abs/2201.01942</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:20 GMT</pubDate>
    </item>
    <item>
      <title>具有差分隐私的高效稀疏最小绝对偏差回归。 （arXiv：2401.01294v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.01294</link>
      <description><![CDATA[近年来，保护隐私的机器学习算法已经
因其在许多领域的重要应用而受到越来越多的关注
科学领域。然而，在文献中，大多数隐私保护
算法要求学习目标是强凸的，而 Lipschitz
平滑，因此不能涵盖广泛的鲁棒损失函数（例如，
分位数/最小绝对损失）。在这项工作中，我们的目标是快速开发
针对稀疏鲁棒回归问题的隐私保护学习解决方案。
我们的学习损失由稳健的最小绝对损失和 $\ell_1$ 组成
稀疏惩罚项。快速解决给定隐私下的非平滑损失
预算，我们开发了快速稳健且保护隐私的估计（FRAPPE）
最小绝对偏差回归算法。我们的算法实现了
通过将稀疏 LAD 问题重新表述为惩罚最小问题来进行快速估计
平方估计问题并采用三级噪声注入来保证
$(\epsilon,\delta)$-差分隐私。我们证明我们的算法可以
与
最先进的隐私保护回归算法。最后，我们
进行实验来验证我们提出的 FRAPPE 算法的效率。
]]></description>
      <guid>http://arxiv.org/abs/2401.01294</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:19 GMT</pubDate>
    </item>
    <item>
      <title>自对弈微调将弱语言模型转换为强语言模型。 （arXiv：2401.01335v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.01335</link>
      <description><![CDATA[通过监督微调利用人工注释数据的力量
（SFT）对于推进大型语言模型（LLM）至关重要。在本文中，我们
深入研究从弱 LLM 中培养出强 LLM 的前景，而无需
需要获取额外的人工注释数据。我们提出一个新的
微调方法称为自玩微调（SPIN），它从
监督微调模型。 SPIN 的核心是自我对弈机制，
法学硕士通过与自身实例进行对抗来完善其能力。
更具体地说，法学硕士从之前的数据中生成自己的训练数据
迭代，通过识别这些自我生成的响应来完善其策略
来自人类注释数据获得的数据。我们的方法逐步
将法学硕士从一个新生模型提升为一个强大的模型，解锁了完整的
SFT 人工注释演示数据的潜力。理论上，我们
证明我们方法的训练目标函数的全局最优
只有当LLM政策与目标数据分布一致时才能实现。
根据经验，我们在几个基准数据集上评估我们的方法，包括
HuggingFace 开放 LLM 排行榜、MT-Bench 和来自 Big-Bench 的数据集。我们的
结果表明，SPIN 可以显着提高法学硕士在各个领域的表现
各种基准，甚至优于通过直接训练的模型
偏好优化 (DPO) 补充了额外的 GPT-4 偏好数据。
这揭示了自我对弈的前景，从而实现
法学硕士的人类水平表现，无需专家对手。
]]></description>
      <guid>http://arxiv.org/abs/2401.01335</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:19 GMT</pubDate>
    </item>
    <item>
      <title>高维混合变量的线性判别分析。 （arXiv：2112.07145v3 [stat.ME] 已更新）</title>
      <link>http://arxiv.org/abs/2112.07145</link>
      <description><![CDATA[同时包含分类变量和连续变量的数据集经常出现
随着现代测量技术的飞速发展，许多领域都遇到了
随着技术的发展，这些变量的维度可能非常高。尽管
连续高维数据建模的最新进展
变量，缺乏可以处理混合组的方法
变量。为了填补这一空白，本文开发了一种新方法
对具有混合变量的高维观测进行分类。我们的框架
建立在位置模型的基础上，其中连续的分布
以分类变量为条件的变量被假定为高斯变量。我们克服了
必须将数据分割成指数级数量的单元格的挑战，或者
通过核平滑组合分类变量，并提供新的
对其带宽选择的看法，以确保与博赫纳引理的类似，
这与通常的偏差-方差权衡不同。我们证明这两个
我们模型中的参数集可以单独估计并提供
他们的估计受到惩罚的可能性。估计精度结果
并建立了错误分类率，并且竞争
通过广泛的模拟说明了所提出的分类器的性能
和真实数据研究。
]]></description>
      <guid>http://arxiv.org/abs/2112.07145</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:19 GMT</pubDate>
    </item>
    <item>
      <title>PAC-Bayes-Chernoff 的损失范围为无界。 （arXiv：2401.01148v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.01148</link>
      <description><![CDATA[我们提出了一种新的高概率 PAC-Bayes 预言机，其边界为无界
损失。这个结果可以理解为 Chernoff 的 PAC-Bayes 版本
边界。证明技术依赖于统一限制某些尾部
基于损失的 Cram\&#39;er 变换的随机变量。我们重点强调两个
我们主要结果的应用。首先，我们证明我们的界限解决了开放问题
在许多 PAC-Bayes 边界上优化自由参数的问题。最后，我们
表明我们的方法允许对损失进行灵活的假设
函数，产生新的边界，概括了以前的边界，并且可以
最小化以获得吉布斯式后验。
]]></description>
      <guid>http://arxiv.org/abs/2401.01148</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:18 GMT</pubDate>
    </item>
    <item>
      <title>使用对比学习对有根树中连续时间序列的二进制事件进行编码。 （arXiv：2401.01242v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.01242</link>
      <description><![CDATA[宽带基础设施所有者并不总是了解他们的客户的情况
连接在本地网络中，其结构为有根树。最近
研究能够使用离散时间推断本地网络的拓扑
来自树的叶子（客户）的系列数据。在这项研究中，我们提出了一个
从连续时间学习二进制事件编码器的对比方法
系列数据。作为初步结果，我们表明我们的方法有一些
学习有价值的编码器的潜力。
]]></description>
      <guid>http://arxiv.org/abs/2401.01242</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:18 GMT</pubDate>
    </item>
    <item>
      <title>张量 PCA 的幂迭代的锐利分析。 （arXiv：2401.01047v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.01047</link>
      <description><![CDATA[我们研究张量 PCA 模型的幂迭代算法
Richard 和 Montanari (2014) 中介绍了这一点。之前的工作研究
张量幂迭代的属性要么限于常数
迭代，或者需要一个不平凡的数据独立初始化。在这个
论文中，我们超越了这些限制并分析了随机的动态
初始化张量幂迭代最多为多项式步数。我们的
贡献有三重：首先，我们对
幂法收敛到植入信号所需的迭代次数，对于
宽范围的信噪比。其次，我们的分析表明
功率迭代的实际算法阈值小于
文献中通过 polylog(n) 因子推测，其中 n 是环境
方面。最后，我们提出了一个简单有效的停止标准
幂迭代，可证明输出高度相关的解决方案
与真实信号。大量的数值实验验证了我们的理论
结果。
]]></description>
      <guid>http://arxiv.org/abs/2401.01047</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>多视图学习的 PAC-贝叶斯域适应界限。 （arXiv：2401.01048v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.01048</link>
      <description><![CDATA[本文提出了领域适应领域的一系列新结果
多视图学习设置。将多个视图合并到域中
以往的研究很少关注适应性。这样，我们
提出使用 Pac-Bayesian 理论进行泛化界限分析
巩固目前分别处理的两种范式。首先，
在 Germain 等人之前的工作的基础上，我们调整了之间的距离
Germain 等人提出的分布。用于域适应概念
的多视图学习。因此，我们引入了一种量身定制的新颖距离
用于多视图域自适应设置。然后，我们给出 Pac-Bayesian 界限
用于估计引入的分歧。最后我们来对比一下不同的新品
与之前的研究有一定的界限。
]]></description>
      <guid>http://arxiv.org/abs/2401.01048</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>最优传输中具有零且非负 MTW 张量的成本族。 （arXiv：2401.00953v1 [数学.AP]）</title>
      <link>http://arxiv.org/abs/2401.00953</link>
      <description><![CDATA[我们明确计算 MTW 张量（或交叉曲率）以获得最佳结果
$\mathbb{R}^n$ 上的传输问题，成本函数形式为 $\mathsf{c}(x,
y) = \mathsf{u}(x^{\mathfrak{t}}y)$，其中 $\mathsf{u}$ 是标量函数
与逆$\mathsf{s}$，$x^{\ft}y$是非简并双线性对
向量$x, y$属于$\mathbb{R}^n$的开子集。条件
在 Kim-McCann 度量下，MTW 张量在零向量上消失是
四阶非线性 ODE，可以简化为以下形式的线性 ODE
$\mathsf{s}^{(2)} - S\mathsf{s}^{(1)} + P\mathsf{s} = 0$（常数）
系数$P$和$S$。由此产生的反函数包括 {\it Lambert}
和{\它广义的反双曲\斜杠三角}函数。这
平方欧几里得度量和 $\log$ 类型成本相当于
这些解决方案。家庭的最佳地图也很明确。为了成本
双曲空间双曲面模型上类似形式的函数
单位球面，我们也用代数表达式来表达这个张量
使用 Gauss-Codazzi 方程对 $\mathsf{s}$ 求导，得到新的
这些流形的严格常规费用的家庭，包括新家庭
{\it 幂函数成本}。我们分析$\sinh$型双曲成本，
提供 $\mathsf{c}$-凸函数和散度的示例。
]]></description>
      <guid>http://arxiv.org/abs/2401.00953</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>用于分位数因果推断的反演估计方程。 （arXiv：2401.00987v1 [stat.ME]）</title>
      <link>http://arxiv.org/abs/2401.00987</link>
      <description><![CDATA[因果推理文献经常侧重于估计均值
潜在的结果，而潜在结果的分位数可能带有
重要的附加信息。我们提出了一种通用方法，基于
逆估计方程，概括一类广泛的因果推理
从估计潜在结果的平均值到其分位数的解决方案。
我们假设可以使用识别矩函数来识别平均值
阈值转换的潜在结果，基于此，一个方便的
潜在结果分位数估计方程的构建为
建议的。此外，我们还给出了高效的一般构造。
潜在结果的均值和分位数的影响函数，以及
确定他们的联系。我们激励分位数估计量的估计者
具有有效的影响函数，并发展其渐近性质
当使用参数模型或数据自适应机器学习器时
估计干扰函数。我们的结果的广泛含义是
可以重新设计平均因果估计值的现有结果，以促进因果关系
对分位数进行推断，而不是从头开始。我们的结果是
通过几个例子来说明。
]]></description>
      <guid>http://arxiv.org/abs/2401.00987</guid>
      <pubDate>Wed, 03 Jan 2024 03:14:16 GMT</pubDate>
    </item>
    </channel>
</rss>