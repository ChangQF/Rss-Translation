<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Mon, 01 Jan 2024 03:14:39 GMT</lastBuildDate>
    <item>
      <title>快速 Slate 策略优化：超越 Plackett-Luce。 （arXiv：2308.01566v2 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2308.01566</link>
      <description><![CDATA[大规模机器学习日益重要的构建模块
系统基于返回石板；给定查询的项目的有序列表。
该技术的应用包括：搜索、信息检索和
推荐系统。当行动空间很大时，决策系统
限制于特定的结构来快速完成在线查询。这
论文讨论了这些大规模决策系统的优化
任意奖励函数。我们将这个学习问题纳入政策中
优化框架并提出一类新的政策，诞生于一种新颖的
放松决策职能。这导致了一个简单而有效的
可扩展到大规模动作空间的学习算法。我们比较我们的方法
到普遍采用的 Plackett-Luce 策略类并证明
我们的方法对动作空间大小顺序问题的有效性
数百万。
]]></description>
      <guid>http://arxiv.org/abs/2308.01566</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>SymmPI：具有组对称性的数据的预测推理。 （arXiv：2312.16160v2 [stat.ME] 已更新）</title>
      <link>http://arxiv.org/abs/2312.16160</link>
      <description><![CDATA[量化预测的不确定性是现代科学的核心问题
统计数据。预测推理方法已经在
各种假设，通常——例如，在标准保形预测中
——依赖特殊条件下数据分布的不变性
变换群，例如置换群。此外，许多现有的
预测推理方法旨在预测未观察到的结果
特征结果观察序列。与此同时，有兴趣
更一般的观察模型下的预测推理（例如，部分
观察到的特征）以及满足更一般分布的数据
对称性（例如，旋转不变或与坐标无关的观测值
在物理学中）。在这里，我们提出了 SymmPI，一种预测推理方法
当数据分布在任意观察中具有一般群对称性时
楷模。我们的方法利用分布等变的新概念
转换，处理数据同时保留其分布
不变性。我们证明 SymmPI 在分布式下具有有效的覆盖范围
不变性并表征其在分布变化下的性能，
将最近的结果作为特殊情况恢复。我们应用 SymmPI 来预测
与网络中的顶点相关的未观察到的值，其中分布
在保持网络结构不变的重新标记下保持不变。在
两层分层模型和经验数据中的多次模拟
分析示例，与现有方法相比，SymmPI 的性能优越。
]]></description>
      <guid>http://arxiv.org/abs/2312.16160</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>具有接近最优样本复杂性的基于分布式鲁棒模型的离线强化学习。 （arXiv：2208.05767v4 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2208.05767</link>
      <description><![CDATA[本文关注模型鲁棒性和样本的中心问题
离线强化学习（RL）的效率，旨在学习
根据历史数据做出决策，无需主动探索。由于
由于环境的不确定性和多变性，学习
稳健的策略——样本尽可能少——甚至表现良好
当部署的环境偏离用于收集数据的标称环境时
历史数据集。我们考虑离线的分布稳健的公式
RL，专注于具有不确定性的表格鲁棒马尔可夫决策过程
由有限范围内的 Kullback-Leibler 散度指定的集合
无限水平设置。为了解决样本稀缺问题，基于模型的
将分布鲁棒值迭代与
提出了面对不确定性的悲观主义原则，通过惩罚
通过精心设计的数据驱动惩罚项进行稳健的价值估计。
在历史数据集的温和且量身定制的假设下，测量
分布转移不需要完全覆盖状态行动空间，
我们建立了所提出算法的有限样本复杂性。我们
进一步发展信息论下界，这表明
当不确定性存在时，学习 RMDP 至少与标准 MDP 一样困难
水平足够小，并且证实了我们上限的紧密度
到一系列（有效）地平线长度的多项式因子
不确定性水平。据我们所知，这提供了第一个可证明的
在模型不确定性下学习的近乎最优的鲁棒离线强化学习算法
和部分覆盖。
]]></description>
      <guid>http://arxiv.org/abs/2208.05767</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>具有指定缺失数据机制的高斯混合模型的贝叶斯规则估计分析。 （arXiv：2210.13785v2 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2210.13785</link>
      <description><![CDATA[半监督学习（SSL）方法已成功应用于
广泛的工程和科学领域。本文研究了
具有未分类缺失机制的生成模型框架
观察结果，由 Ahfock 和 McLachlan (2020) 介绍。我们证明在一个
部分分类样本，使用贝叶斯分配规则的分类器
缺失数据机制可以超越二分类中的完全监督分类器
正态同方差模型，特别是具有中度至低度重叠和
缺失类别标签的比例，或者重叠较大但缺失很少的类别标签的比例
标签。它还优于没有缺失数据机制的分类器
无论重叠区域或缺失类标签的比例如何。我们的
不等式二元和三元正态混合模型的探索
通过模拟得到的协方差进一步证实了我们的发现。最后，我们
说明所提出的分类器与缺失数据机制的使用
神经元间和皮肤病变数据集。
]]></description>
      <guid>http://arxiv.org/abs/2210.13785</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>具有高斯噪声的矩阵：奇异子空间扰动的最佳估计。 （arXiv：1803.00679v3 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/1803.00679</link>
      <description><![CDATA[Davis-Kahan-Wedin $\sin \Theta$ 定理描述了奇异性如何
当受到小扰动时，矩阵的子空间会发生变化。这
在最坏的情况下，经典结果是尖锐的。在本文中，我们证明了一个
Davis-Kahan-Wedin $\sin \Theta$ 定理的随机版本，当
扰动是高斯随机矩阵。在某些结构假设下，
我们获得了一个显着改进经典的最佳界限
Davis-Kahan-Wedin $\sin \Theta$ 定理。我们的关键工具之一是新的
奇异值的扰动界限，可能是独立的
兴趣。
]]></description>
      <guid>http://arxiv.org/abs/1803.00679</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>使用先验信息进行降维以进行知识发现。 （arXiv：2111.13646v4 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2111.13646</link>
      <description><![CDATA[本文解决了将高维数据映射到
低维空间，存在其他已知特征。这个问题是
在科学和工程中普遍存在
大多数应用中的可控/可测量功能。为了解决这个问题，
本文提出了一大类方法，称为
条件多维标度（MDS）。一种优化算法
还开发了条件MDS的目标函数。的收敛性
该算法是在温和的假设下得到证明的。有条件MDS如图所示
亲属关系、面部表情、纺织面料、汽车品牌认知，
和圆柱体加工示例。这些例子展示了以下优点
条件 MDS 相对于传统降维在提高
估计降维空间的质量并简化可视化
和知识发现任务。这项工作的计算机代码可在
开源 cml R 包。
]]></description>
      <guid>http://arxiv.org/abs/2111.13646</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>用于预测过程监控的可解释和可解释的机器学习方法：系统文献综述。 （arXiv：2312.17584v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.17584</link>
      <description><![CDATA[本文对
机器学习 (ML) 模型的可解释性和可解释性
使用 PRISMA 框架进行预测流程挖掘。鉴于
人工智能 (AI) 和 ML 系统的快速发展，理解
这些技术的“黑匣子”性质变得越来越关键。
本文特别关注流程挖掘领域，深入研究了
解释经过复杂业务流程训练的机器学习模型的挑战
数据。我们区分本质上可解释的模型和那些
需要事后解释技术，提供全面的
概述当前方法及其在不同领域的应用
应用领域。通过严格的文献分析，本研究
提供了可解释性和可解释性状态的详细综合
在预测过程挖掘中，识别关键趋势、挑战和未来
方向。我们的研究结果旨在为研究人员和从业者提供
更深入地了解如何开发和实施更值得信赖的、
用于预测过程的透明、有效的智能系统
分析。
]]></description>
      <guid>http://arxiv.org/abs/2312.17584</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>用户策略和值得信赖的算法。 （arXiv：2312.17666v1 [cs.CY]）</title>
      <link>http://arxiv.org/abs/2312.17666</link>
      <description><![CDATA[许多面向人的算法——包括那些支持推荐的算法
系统或招聘决策工具——接受其提供的数据的培训
用户。这些算法的开发者通常采用这样的假设：
数据生成过程是外生的：即用户对给定的反应如何
提示（例如，推荐或雇用建议）取决于提示和
不在生成它的算法上。例如，假设一个
人的行为遵循真实分布是外生性
假设。实际上，当算法与人类交互时，这种假设
很少成立，因为用户可能具有战略意义。最近的研究文件，对于
例如，TikTok 用户在得知这一情况后改变了他们的滚动行为
TikTok 使用它来管理他们的信息流，而 Uber 司机则改变了他们的接受方式
并根据 Uber 算法的变化取消乘车服务。

我们的工作通过建模来研究这种战略行为的影响
用户与其数据驱动平台之间的交互是重复的、
两人游戏。我们首先发现用户策略实际上可以有所帮助
短期内有平台。然后我们证明它会破坏平台的数据并且
最终损害了他们做出反事实决策的能力。我们连接
这种现象增加了用户的信任，并表明设计值得信赖的算法
可以与准确的估计齐头并进。最后，我们提供一个
可信度的正规化激发了潜在的干预措施。
]]></description>
      <guid>http://arxiv.org/abs/2312.17666</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 Swin Transformers 对动脉瘤性蛛网膜下腔出血后的头部 CT 扫描进行基于深度学习的血液分割的全自动流程。 （arXiv：2312.17553v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17553</link>
      <description><![CDATA[背景：自发性蛛网膜下腔的准确体积评估
出血 (SAH) 是一项劳动密集型任务，需要使用现有的手动和
可能与其临床和预后相关的半自动方法
影响。在目前的研究中，我们试图开发和验证
人工智能驱动的全自动 SAH 血液分割工具
通过非对比计算机断层扫描 (NCCT) 扫描的患者
基于变压器的 Swin UNETR 架构。方法：我们回顾性分析
确诊动脉瘤性蛛网膜下腔出血患者的 NCCT 扫描
(aSAH) 利用 Swin UNETR 进行分割。的性能
所提出的方法根据手动分段的地面实况数据进行评估
使用 Dice 得分、并集交集 (IoU)、体积等指标
相似指数 (VSI)、对称平均表面距离 (SASD) 和
敏感性和特异性。来自外部机构的验证队列
包括在内是为了测试模型的普遍性。结果：模型
通过内部强大的性能指标证明了高精度
和外部验证队列。值得注意的是，它实现了高 Dice 系数
(0.873)、IoU (0.810)、VSI (0.840)、灵敏度 (0.821) 和特异性 (0.996)
值和低 SASD (1.866)，表明在分割血液方面的熟练程度
SAH患者。模型的效率体现在它的处理速度上，
表明实时应用的潜力。结论：我们的天鹅
基于 UNETR 的模型在自动分割方面取得了重大进展
NCCT 图像上 aSAH 后的血液。尽管计算强度很大，该模型
在具有用户友好界面的标准硬件上有效运行，
促进更广泛的临床采用。跨不同领域的进一步验证
数据集有必要确认其临床可靠性。
]]></description>
      <guid>http://arxiv.org/abs/2312.17553</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:34 GMT</pubDate>
    </item>
    <item>
      <title>有意识分配的参数优化（POCA）。 （arXiv：2312.17404v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.17404</link>
      <description><![CDATA[现代机器学习算法的性能取决于
选择一组超参数。超参数的常见示例是
学习率和密集神经网络中的层数。自动机器学习是
优化的一个分支，在该领域做出了重要贡献。
在 Auto-ML 中，基于超频带的方法消除了性能不佳的问题
在低预算下评估后的配置是最重要的
有效的。然而，这些算法的性能很大程度上取决于
他们有效地将计算预算分配给各种超参数
配置。我们提出了新的 Conscious 参数优化
分配（POCA），一种基于超频带的算法，可自适应地分配
将预算输入到它生成的超参数配置中
贝叶斯抽样方案。我们将 POCA 与其最接近的竞争对手进行比较：
优化人造玩具功能和深度神经网络的超参数
网络并发现 POCA 在两种设置中都能更快地找到强大的配置。
]]></description>
      <guid>http://arxiv.org/abs/2312.17404</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>用于近似贝叶斯认知不确定性估计的生成后验网络。 （arXiv：2312.17411v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.17411</link>
      <description><![CDATA[在许多现实世界的问题中，训练数据集是有限的，但是
大量未标记的数据。我们提出了一种新方法，生成后验
网络（GPN），使用未标记的数据来估计认知不确定性
高维问题。 GPN 是一种生成模型，给定先验
函数上的分布，直接近似后验分布
通过针对先前的样本对网络进行正则化。我们证明
从理论上讲，我们的方法确实近似于贝叶斯后验，并且
经验表明它改善了认知不确定性估计
优于竞争方法的可扩展性。
]]></description>
      <guid>http://arxiv.org/abs/2312.17411</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>与众不同：协变量转变的光谱适应回归。 （arXiv：2312.17463v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.17463</link>
      <description><![CDATA[设计能够稳健执行的深度神经网络分类器
与可用训练数据不同的分布是一个活跃的领域
机器学习研究。然而，分布外泛化
回归——对连续目标建模的类似问题——仍然存在
相对未经探索。为了解决这个问题，我们回到首要原则
并分析普通最小二乘法 (OLS) 的闭式解如何
回归对协变量偏移敏感。我们的特点是
OLS 模型在特征谱方面的分布外风险
源数据和目标数据的分解。然后我们利用这一见解
提出一种调整预训练最后一层权重的方法
神经回归模型对源自 a 的输入数据表现更好
不同的分布。我们演示了这种轻量级光谱适应如何
程序可以提高合成和的分布外性能
真实世界的数据集。
]]></description>
      <guid>http://arxiv.org/abs/2312.17463</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>STanHop：用于记忆增强时间序列预测的稀疏串联 Hopfield 模型。 （arXiv：2312.17346v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.17346</link>
      <description><![CDATA[我们提出了多变量时间的 STanHop-Net（稀疏串联 Hopfield 网络）
具有记忆增强功能的系列预测。在我们的核心
方法是 STanHop，一种新颖的基于 Hopfield 的神经网络模块，
稀疏地学习时间和跨序列表示并将其存储在
依赖数据的时尚。本质上，STanHop 顺序学习时间
使用两个串联稀疏 Hopfield 表示和跨系列表示
层。此外，StanHop 还集成了两个额外的外部存储器
模块：即插即用模块和调谐即用模块，用于无火车和
分别是任务感知记忆增强。它们使 StanHop-Net 能够迅速
对某些突发事件做出反应。在方法论上，我们构造
StanHop-Net 通过以分层方式堆叠 STanHop 块，使得
具有特定于分辨率的稀疏性的多分辨率特征提取。
理论上，我们引入现代 Hopfield 模型的稀疏扩展
（广义稀疏现代霍普菲尔德模型）并表明它赋予了更紧密的
与密集对应物相比，内存检索错误不受影响
内存容量。根据经验，我们验证了我们的框架在以下方面的有效性
合成和现实世界的设置。
]]></description>
      <guid>http://arxiv.org/abs/2312.17346</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:32 GMT</pubDate>
    </item>
    <item>
      <title>一种解决降序算子回归问题的随机算法。 （arXiv：2312.17348v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.17348</link>
      <description><![CDATA[我们提出并分析了一种为寻址向量值而设计的算法
可能涉及无限维输入和输出的回归问题
空间。该算法是降阶回归的随机适应，
最佳地学习低秩向量值函数（即
运算符）通过正则化经验风险最小化采样数据之间
等级限制。我们提出了高斯草图技术用于原始
和双重优化目标，产生随机降序回归
(R4) 高效且准确的估计器。对于我们的每个 R4 算法
我们证明，由此产生的正则化经验风险是预期的
w.r.t.草图的随机性，任意接近最优值
超参数已正确调整。数值实验说明了
我们的边界的严格性并在两种不同的情况下显示出优势：（i）
使用综合和大规模解决向量值回归问题
神经科学数据集，以及 (ii) 回归非线性的 Koopman 算子
随机动力系统。
]]></description>
      <guid>http://arxiv.org/abs/2312.17348</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:32 GMT</pubDate>
    </item>
    <item>
      <title>梯度牙线：通过雅克比行列式的动态控制改进梯度下降。 （arXiv：2312.17306v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.17306</link>
      <description><![CDATA[训练循环神经网络 (RNN) 仍然是一个挑战，因为
长时间范围内梯度的不稳定性，这可能导致爆炸
和梯度消失。最近的研究将这些问题与
前向动力学的 Lyapunov 指数值，描述了
无穷小扰动的增长或收缩。在这里，我们提出梯度
牙线法，一种通过推动李亚普诺夫来解决梯度不稳定性的新方法
学习过程中向前动态趋于零的指数。我们实现了这一目标
通过使用可微分的反向传播来正则化 Lyapunov 指数
线性代数。这使我们能够“清理”梯度，稳定它们并
从而改善网络训练。我们证明梯度牙线控制
不仅是梯度范数，还包括长期的条件数
雅可比行列式，促进多维误差反馈传播。我们发现
在训练之前应用梯度牙线可以提高成功率
涉及长时间范围的任务的速率和收敛速度。为了
具有挑战性的任务，我们表明训练期间的梯度牙线可以进一步
增加可以通过时间反向传播桥接的时间范围。
此外，我们还证明了我们的方法在各种 RNN 上的有效性
可变时间复杂度的架构和任务。此外，我们
提供我们的梯度牙线算法的简单实现，可以
在实践中使用。我们的结果表明，通过正则化梯度牙线
Lyapunov指数可以显着增强RNN训练的有效性
并缓解梯度爆炸和消失问题。
]]></description>
      <guid>http://arxiv.org/abs/2312.17306</guid>
      <pubDate>Mon, 01 Jan 2024 03:14:31 GMT</pubDate>
    </item>
    </channel>
</rss>