<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 25 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>上升的休息老虎机：下界和有效算法</title>
      <link>https://arxiv.org/abs/2411.14446</link>
      <description><![CDATA[arXiv:2411.14446v1 公告类型：新
摘要：本文属于随机多臂老虎机 (MAB) 领域，即那些能够仅使用所选选项（又名 $arm$）给出的反馈在线学习的顺序选择技术。我们研究了一种特殊的休息老虎机，其中手臂的预期奖励是单调不减的和凹的。我们通过推导合适的遗憾下限来研究遗憾最小化问题的固有样本复杂性。然后，我们为休息情况 $\textit{R-ed-UCB}$ 设计了一种算法，根据实例的属性提供遗憾界限，并在某些情况下提供 $\widetilde{\mathcal{O}}(T^{\frac{2}{3}})$。我们通过几个合成生成的任务和针对真实世界数据集的在线模型选择问题，将我们的算法与非平稳 MAB 的最新方法进行了实证比较]]></description>
      <guid>https://arxiv.org/abs/2411.14446</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程的稀疏上确界</title>
      <link>https://arxiv.org/abs/2411.14664</link>
      <description><![CDATA[arXiv:2411.14664v1 公告类型：新 
摘要：我们给出了中心高斯过程上确界的维度无关稀疏化结果：设 $T$ 为 $\mathbb{R}^n$ 中任意（可能为无限）有界向量集，设 $\{{\boldsymbol{X}}_t\}_{t\in T}$ 为 $T$ 上的正则高斯过程。我们证明存在一个 $O_\varepsilon(1)$ 大小的子集 $S \subseteq T$ 和一组实值 $\{c_s\}_{s \in S}$，使得 $\sup_{s \in S} \{{\boldsymbol{X}}_s + c_s\}$ 是 $\sup_{t \in T} {\boldsymbol{X}}_t$ 的 $\varepsilon$ 近似器。值得注意的是，$S$ 的大小与 $T$ 的大小和环境维度 $n$ 完全无关。
我们利用这一点来表明，当将其视为高斯空间上的函数时，每个范数本质上都是一个军政府：给定 $\mathbb{R}^n$ 上的任何范数 $\nu(x)$，都有另一个范数 $\psi(x)$，它仅取决于 $x$ 沿 $O_\varepsilon(1)$ 方向的投影，对于该范数，对于 $\psi({\boldsymbol{g}})$，是 $\nu({\boldsymbol{g}})$ 的乘法 $(1 \pm \varepsilon)$ 近似，概率为 ${\boldsymbol{g}} \sim N(0,I_n)$，​​为 $1-\varepsilon$。
我们还利用中心高斯过程上确界的稀疏化结果，给出了有界几何宽度凸集的稀疏化引理：在 $\mathbb{R}^n$ 中，距离原点 $O(1)$ 的任何半空间（可能无穷多个）交点，在 $N(0,I_n)$ 下，与只有 $O_\varepsilon(1)$ 个半空间的交点 $\varepsilon$ 接近。
我们描述了对不可知学习和容错属性测试的应用。]]></description>
      <guid>https://arxiv.org/abs/2411.14664</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于高维数据中自适应因果表示的双重机器学习</title>
      <link>https://arxiv.org/abs/2411.14665</link>
      <description><![CDATA[arXiv:2411.14665v1 公告类型：新
摘要：提出了从观测数据进行自适应因果表示学习的方法，结合了半参数估计方程框架内的有效样本分割技术。支持点样本分割（SPSS）是一种基于能量距离的子采样方法，用于因果推理中的高效双机器学习（DML）。与传统的随机分割不同，选择并分割支持点作为随机样本中完整原始数据的最佳代表点，并提供底层数据生成分布的最佳子表示。它们提供了完整大数据集的最佳表示，而通过传统随机数据分割获得的底层分布的单位结构信息很可能不会被保留。使用 SPSS，采用三种机器学习估计器进行因果推理，即支持向量机（SVM）、深度学习（DL）和混合超级学习器（SL）与深度学习（SDL）。使用 SPSS 对所提出的 SVM、DL 和 SDL 表示法与 Chernozhukov 等人 (2018) 的基准测试结果进行了比较研究，后者在 401(k) 养老金计划实际数据上采用了随机森林、神经网络和回归树以及随机 k 折交叉拟合技术。模拟表明，SPSS 中的 DL 以及 SPSS 中的 DL 和 SL 的混合方法在计算效率和估计质量方面分别优于 SPSS 中的 SVM。]]></description>
      <guid>https://arxiv.org/abs/2411.14665</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于迭代加权框架的广义弹性网络惩罚稀疏线性回归算法</title>
      <link>https://arxiv.org/abs/2411.14875</link>
      <description><![CDATA[arXiv:2411.14875v1 公告类型：新
摘要：弹性网络惩罚经常用于高维统计中的参数回归和变量选择。当预测变量的数量大大超过观测值的数量时，它与套索相比特别有益。然而，经验证据表明，与 $\ell_1$-norm 惩罚相比，$\ell_q$-norm 惩罚（其中 $0 &lt; q &lt; 1$）通常提供更好的回归，在各种情况下表现出增强的稳健性。在本文中，我们探索了一种广义弹性网络模型，该模型在损失函数中使用 $\ell_r$-norm（其中 $r \geq 1$）来适应各种类型的噪声，并使用 $\ell_q$-norm（其中 $0 &lt; q &lt; 1$）来替换弹性网络惩罚中的 $\ell_1$-norm。理论上，我们为所提出的广义弹性网络模型的广义一阶驻点的非零项建立了可计算的下界。为了实现，我们基于局部 Lipschitz 连续 $\epsilon$ 近似到 $\ell_q$ 范数开发了两种高效算法。第一种算法采用交替方向乘数法 (ADMM)，而第二种算法采用近端主化-最小化法 (PMM)，其中子问题使用半光滑牛顿法 (SNN) 解决。我们还对模拟数据和真实数据进行了广泛的数值实验，结果表明两种算法都表现出优异的性能。值得注意的是，PMM-SSN 比 ADMM 更有效，尽管后者提供了更简单的实现。]]></description>
      <guid>https://arxiv.org/abs/2411.14875</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>结构化神经密度估计的维度独立率</title>
      <link>https://arxiv.org/abs/2411.15095</link>
      <description><![CDATA[arXiv:2411.15095v1 公告类型：新
摘要：我们表明深度神经网络在学习结构化密度（例如图像、音频、视频和文本应用中出现的密度）时实现了与维度无关的收敛速度。更准确地说，我们证明，当基础密度是马尔可夫图时，具有简单 $L^2$ 最小化损失的神经网络在非参数密度估计中实现了 $n^{-1/(4+r)}$ 的速率，该图的最大团大小最多为 $r$，并且我们提供证据表明，在上述应用中，此大小通常是恒定的，即 $r=O(1)$。然后，我们确定 $L^1$ 中的最佳速率为 $n^{-1/(2+r)}$，与标准非参数速率 $n^{-1/(2+d)}$ 相比，这表明此类问题的有效维度是马尔可夫随机场中最大团的大小。这些速率与数据的环境维度无关，因此适用于图像、声音、视频和文本数据的实际模型。我们的结果为深度学习能够规避维数灾难提供了新颖的理由，在这些情况下展示了与维度无关的收敛速度。]]></description>
      <guid>https://arxiv.org/abs/2411.15095</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于梯度的变分经验贝叶斯多元回归优化</title>
      <link>https://arxiv.org/abs/2411.14570</link>
      <description><![CDATA[arXiv:2411.14570v1 公告类型：交叉 
摘要：变分经验贝叶斯 (VEB) 方法提供了一种实用的方法来拟合大型、稀疏、多元回归模型。这些方法通常使用坐标上升来优化变分目标函数，这种方法称为坐标上升变分推理 (CAVI)。在这里，我们提出了基于梯度（拟牛顿）方法的替代优化方法，我们称之为基于梯度的变分推理 (GradVI)。GradVI 利用了 Kim 等人的最新成果。[arXiv:2208.10910]，该成果将 VEB 回归目标函数写为惩罚回归。不幸的是，惩罚函数没有封闭形式，我们提出并比较了两种处理此问题的方法。在 CAVI 表现良好的简单情况下，我们表明 GradVI 产生类似的预测性能，并且当预测变量高度相关时，GradVI 会在更少的迭代中收敛。此外，与 CAVI 不同，GradVI 中的关键计算是简单的矩阵向量积，因此在设计矩阵允许快速矩阵向量积（例如，我们在此处展示的趋势过滤应用程序）的环境中，GradVI 比 CAVI 快得多，并且适合并行实现，而 CAVI 则不适合。GradVI 也非常灵活，可以利用自动微分轻松实现不同的先验系列。我们的方法是在开源 Python 软件 GradVI 中实现的（可从 https://github.com/stephenslab/gradvi 获得）。]]></description>
      <guid>https://arxiv.org/abs/2411.14570</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>总结贝叶斯非参数混合后验——高斯混合的切片最优传输度量</title>
      <link>https://arxiv.org/abs/2411.14674</link>
      <description><![CDATA[arXiv:2411.14674v1 公告类型：交叉 
摘要：现有的总结混合模型后验推断的方法侧重于确定聚类隐含随机分区的点估计，密度估计是次要目标（Wade and Ghahramani，2018；Dahl 等人，2022）。我们提出了一种总结非参数贝叶斯混合模型后验推断的新方法，优先考虑混合测量（或混合）的密度估计作为推理目标。该方法的一个关键特征是与模型无关的性质，它在底层采样模型中任意复杂的依赖结构下仍然有效。使用决策理论框架，我们的方法通过最小化后验预期损失来确定点估计。损失函数定义为损失函数与混合测量之间的差异。估计混合测量意味着对混合密度的推断。利用混合测度的离散性质，我们使用切片 Wasserstein 距离的一个版本。我们引入了两种高斯混合的特定变体。第一种是混合切片 Wasserstein，它在欧几里得空间和对称正定矩阵流形的乘积上应用广义测地线投影。第二种是切片混合 Wasserstein，利用高斯混合测度的线性进行有效投影。]]></description>
      <guid>https://arxiv.org/abs/2411.14674</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>递归高斯过程状态空间模型</title>
      <link>https://arxiv.org/abs/2411.14679</link>
      <description><![CDATA[arXiv:2411.14679v1 公告类型：交叉 
摘要：从数据中学习动态模型不仅是基础，而且对于推进原理发现、时间序列预测和控制器设计也具有巨大的前景。在各种方法中，高斯过程状态空间模型 (GPSSM) 因其灵活性和可解释性的结合而最近引起了广泛关注。然而，对于在线学习，该领域缺乏一种适用于数据分布和模型功能先验信息有限的场景的有效方法。为了解决这个问题，本文提出了一种递归 GPSSM 方法，该方法具有对操作域和高斯过程 (GP) 超参数的自适应能力。具体而言，我们首先利用一阶线性化推导出系统状态和 GP 模型之间联合分布的贝叶斯更新方程，从而实现闭式和域独立学习。其次，基于信息标准开发了一种用于诱导点的在线选择算法，以实现轻量级学习。第三，为了支持在线超参数优化，我们从当前过滤分布中恢复历史测量信息。对合成和真实世界数据集的综合评估表明，与最先进的在线 GPSSM 技术相比，我们的方法具有卓越的准确性、计算效率和适应性。]]></description>
      <guid>https://arxiv.org/abs/2411.14679</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自由能投影模拟（FEPS）：具有可解释性的主动推理</title>
      <link>https://arxiv.org/abs/2411.14991</link>
      <description><![CDATA[arXiv:2411.14991v1 公告类型：交叉 
摘要：在过去十年中，自由能量原理 (FEP) 和主动推理 (AIF) 在将学习和认知的概念模型与感知和行动的数学模型联系起来方面取得了许多成功。这项工作是由多学科兴趣推动的，这些兴趣旨在理解自组织复杂自适应系统的各个方面，包括代理元素。已经提出了各种执行主动推理的强化学习 (RL) 模型，并使用深度神经网络对标准 RL 任务进行训练。最近的工作重点是通过结合最新的机器学习技术来提高此类代理在复杂环境中的性能。在本文中，我们采用了另一种方法。在 FEP 和 AIF 施加的约束范围内，我们尝试通过引入自由能量投影模拟 (FEPS) 以可解释的方式对代理进行建模，而无需深度神经网络。仅使用内部奖励，FEPS 代理就可以构建它们与之交互的部分可观察环境的表示。按照 AIF，通过最小化预期的自由能量，从这个世界模型中得出完成给定任务的策略。利用模型的可解释性，引入了一些技术来处理长期目标并减少由错误的隐藏状态估计引起的预测误差。我们在两个受行为生物学启发的 RL 环境中测试了 FEPS 模型：定时响应任务和部分可观察网格中的导航任务。我们的结果表明，FEPS 代理通过仅根据预测准确性适当地将其观察结果情境化，完全解决了这两个环境的模糊性。此外，它们还可以灵活地为环境中的任何目标观察推断最佳策略。]]></description>
      <guid>https://arxiv.org/abs/2411.14991</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>共享表征的个性化联邦强化学习的线性加速</title>
      <link>https://arxiv.org/abs/2411.15014</link>
      <description><![CDATA[arXiv:2411.15014v1 公告类型：交叉 
摘要：联邦强化学习 (FedRL) 使多个代理能够协作学习策略，而无需共享在代理与环境交互期间收集的本地轨迹。然而，在实践中，不同代理面临的环境往往是异构的，导致现有 FedRL 算法在单个代理上学习的单一策略性能不佳。在本文中，我们更进一步，通过利用异构环境中代理之间可能共享的通用结构，引入了一个 \emph{个性化} FedRL 框架 (PFedRL)。具体来说，我们开发了一类名为 PFedRL-Rep 的 PFedRL 算法，该算法学习 (1) 所有代理之间协作的共享特征表示，以及 (2) 针对其本地环境个性化的代理特定权重向量。我们分析了 PFedTD-Rep 的收敛性，PFedTD-Rep 是该框架的一个特定实例，具有时间差 (TD) 学习和线性表示。据我们所知，我们是第一个证明 PFedRL 设置中代理数量线性收敛加速的人。为了实现这一点，我们展示了 PFedTD-Rep 是具有马尔可夫噪声的联合双时间尺度随机近似的一个例子。实验结果表明，PFedTD-Rep 以及基于深度 Q 网络 (DQN) 的控制设置的扩展不仅可以改善异构设置中的学习，还可以更好地泛化到新环境。]]></description>
      <guid>https://arxiv.org/abs/2411.15014</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于网格的对抗聚类算法</title>
      <link>https://arxiv.org/abs/1804.04780</link>
      <description><![CDATA[arXiv:1804.04780v2 公告类型：替换 
摘要：如今，越来越多的数据被收集用于检测和预防网络攻击。在网络安全应用中，数据分析技术必须处理试图欺骗数据分析模型并避免被发现的主动对手。这种对抗行为的存在促使人们开发用于各种任务的稳健且有弹性的对抗学习技术。之前的大部分工作都集中在对抗分类技术上，这些技术假设存在大量经过仔细标记的数据实例。然而，在实践中，标记数据实例通常需要昂贵且耗时的人力专业知识，并成为一个重大瓶颈。同时，大量未标记的实例也可用于了解对手的行为。为了应对上述挑战，本文开发了一种基于网格的新型对抗聚类算法。我们的对抗聚类算法能够识别核心正常区域，并利用博弈论思想在正常对象的中心周围绘制防御墙。我们的算法还识别攻击对象的子聚类、聚类内的重叠区域以及可能存在潜在异常的异常值。]]></description>
      <guid>https://arxiv.org/abs/1804.04780</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连续生成神经网络：函数空间中基于小波的架构</title>
      <link>https://arxiv.org/abs/2205.14627</link>
      <description><![CDATA[arXiv:2205.14627v3 公告类型：替换 
摘要：在这项工作中，我们介绍和研究了连续生成神经网络 (CGNN)，即连续设置中的生成模型：CGNN 的输出属于无限维函数空间。该架构受 DCGAN 启发，具有一个完全连接的层、多个卷积层和非线性激活函数。在连续的 $L^2$ 设置中，每层空间的维度都被紧支撑小波的多分辨率分析的尺度所取代。我们提出了卷积滤波器和非线性的条件，以保证 CGNN 是可注入的。该理论可应用于逆问题，并允许推导 Lipschitz 稳定性估计（可能是非线性的）无限维逆问题，其中未知数属于 CGNN 生成的流形。包括信号去模糊在内的几个数值模拟说明并验证了这种方法。]]></description>
      <guid>https://arxiv.org/abs/2205.14627</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Huber能量测度量化</title>
      <link>https://arxiv.org/abs/2212.08162</link>
      <description><![CDATA[arXiv:2212.08162v3 公告类型：替换 
摘要：我们描述了一种度量量化程序，即一种通过 $Q$ 狄拉克质量之和（$Q$ 为量化参数）找到目标概率定律（更一般地为有符号有限变分度量）的最佳近似值的算法。该程序通过最小化原始度量与其量化版本之间的统计距离来实现；该距离由负定核构建，如有必要，可以动态计算并输入到随机优化算法（例如 SGD、Adam 等）。我们从理论上研究了最佳度量量化器存在的基本问题，并确定了保证适当行为所需的核属性。我们提出了两个用于平方统计距离的最佳线性无偏（BLUE）估计量，并在无偏程序（称为 HEMQ）中使用它们来找到最佳量化。我们在多个数据库上测试了 HEMQ：多维高斯混合、维纳空间立方体、意大利葡萄酒品种和 MNIST 图像数据库。结果表明，HEMQ 算法稳健且用途广泛，并且对于 Huber 能量核类而言，符合预期的直观行为。]]></description>
      <guid>https://arxiv.org/abs/2212.08162</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度网络可以修剪到多稀疏：基本极限观点</title>
      <link>https://arxiv.org/abs/2306.05857</link>
      <description><![CDATA[arXiv:2306.05857v3 公告类型：替换 
摘要：网络剪枝是减轻深度神经网络存储和计算负担的常用方法。然而，网络剪枝的基本极限仍然缺乏。为了弥补这一差距，在这项工作中，我们将采用第一性原理方法，即直接对损失函数施加稀疏性约束，并利用凸几何中的统计维度框架，从而能够表征尖锐相变点，即剪枝率的基本极限。通过这个极限，我们能够确定决定剪枝率极限的两个关键因素，即权重大小和网络锐度。一般来说，损失景观越平坦或权重大小越小，剪枝率越小。此外，我们提供了有效的对策来解决剪枝极限计算中的挑战，这涉及对大规模非正 Hessian 矩阵的精确谱估计。此外，通过修剪率阈值的视角，我们可以对现有修剪算法中的几种启发式方法提供严格的解释。进行了大量的实验，表明我们的理论修剪率阈值与实验结果非常吻合。所有代码均可从以下网址获取：https://github.com/QiaozheZhang/Global-One-shot-Pruning]]></description>
      <guid>https://arxiv.org/abs/2306.05857</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>随机傅里叶签名特征</title>
      <link>https://arxiv.org/abs/2311.12214</link>
      <description><![CDATA[arXiv:2311.12214v2 公告类型：替换 
摘要：张量代数产生了最强大的相似性度量之一，称为签名核，并伴随着随机分析的有吸引力的理论保证。以前计算签名核的算法在序列的长度和数量方面呈二次方增长。为了缓解这种严重的计算瓶颈，我们开发了一种基于随机傅里叶特征的签名核加速，作用于固有的非欧几里得序列域。我们展示了对所提出的签名核无偏估计量的统一近似保证，同时保持其计算在序列长度和数量上呈线性。此外，结合张量投影的最新进展，我们推导出两个更具可扩展性的时间序列特征，具有良好的集中特性以及时间和内存上的计算复杂度。我们的实证结果表明，计算成本的降低对于中等规模数据集的准确性来说几乎是无用的，并且能够扩展到高达一百万个时间序列的大型数据集。]]></description>
      <guid>https://arxiv.org/abs/2311.12214</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>