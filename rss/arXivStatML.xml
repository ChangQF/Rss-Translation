<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 03 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>自适应组合最大化：超越近似贪婪策略</title>
      <link>https://arxiv.org/abs/2404.01930</link>
      <description><![CDATA[arXiv:2404.01930v1 公告类型：交叉
摘要：我们研究自适应组合最大化，这是机器学习的核心挑战，在主动学习以及许多其他领域都有应用。我们研究贝叶斯设置，并考虑基数约束和最小成本覆盖下的最大化目标。我们提供了新的全面近似保证，其中包含了以前的结果，并大大加强了它们。我们的近似保证同时支持最大增益比以及近子模效用函数，并且包括基数约束下的最大化和最小成本覆盖保证。此外，我们为修改后的先验提供了近似保证，这对于获得不依赖于先验中的最小概率的主动学习保证至关重要。此外，我们发现了自适应选择策略的一个新参数，我们将其称为“最大增益比”。我们证明，该参数比之前的近似保证中使用的贪婪近似参数严格限制较少，并且表明它可以用来提供比之前的结果更强的近似保证。特别是，我们表明最大增益比永远不会大于策略的贪婪近似因子，并且它可以小得多。这提供了对使策略可用于自适应组合最大化的属性的新见解。]]></description>
      <guid>https://arxiv.org/abs/2404.01930</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>使用罗生门分区稳健地估计因子数据中的异质性</title>
      <link>https://arxiv.org/abs/2404.02141</link>
      <description><![CDATA[arXiv:2404.02141v1 公告类型：交叉
摘要：观察数据和随机对照试验中的许多统计分析都会问：感兴趣的结果如何随可观察协变量的组合而变化？各种药物组合如何影响健康结果，或者技术的采用如何取决于激励措施和人口统计数据？我们的目标是将这个阶乘空间划分为协变量组合的“池”，其中池之间的结果不同（但池内的结果不同）。现有方法（i）在关于协变量之间关联的假设下搜索单个“最佳”分区，或（ii）从整个可能分区集中采样。这两种方法都忽略了这样一个现实：尤其是对于协变量的相关结构，许多划分协变量空间的方法可能在统计上无法区分，尽管对政策或科学的影响截然不同。我们开发了另一种观点，称为罗生门分区集（RPS）。 RPS 中的每个项目使用树状几何结构来划分协变量空间。 RPS 合并了后验值接近最大后验分区的所有分区，即使它们提供了本质上不同的解释，并且使用不对协变量之间的关联做出假设的先验来实现这一点。这个先验是 $\ell_0$ 先验，我们证明它是极小极大最优。给定 RPS，我们计算特征影响向量对结果的任何可测量函数的后验，条件是处于 RPS 中。我们还描述了相对于整个后验的近似误差，并提供了 RPS 大小的界限。模拟表明，与传统的正则化技术相比，该框架可以得出可靠的结论。我们将我们的方法应用于三个实证背景：慈善捐赠的价格影响、染色体结构（端粒长度）以及小额信贷的引入。]]></description>
      <guid>https://arxiv.org/abs/2404.02141</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>语言模型对齐的渐近</title>
      <link>https://arxiv.org/abs/2404.01730</link>
      <description><![CDATA[arXiv:2404.01730v1 公告类型：交叉
摘要：设 $p$ 表示生成语言模型。令 $r$ 表示奖励模型，该模型返回一个标量，该标量捕获首选从 $p$ 抽奖的程度。语言模型对齐的目标是将 $p$ 更改为新的分布 $\phi$，从而获得更高的预期奖励，同时保持 $\phi$ 接近 $p。$ 一种流行的对齐方法是 KL 约束强化学习(RL)，它选择一个分布 $\phi_\Delta$，在相对熵约束 $KL(\phi_\Delta || p) \leq 的条件下最大化 $E_{\phi_{\Delta}} r(y)$ \Delta.$ 另一种简单的对齐方法是 best-of-$N$，其中从 $p$ 中抽取 $N$ 样本，并选择奖励最高的样本。在本文中，我们提供了最优 KL 约束 RL 解决方案的封闭形式表征。我们证明，任何在 KL 散度和奖励之间实现可比权衡的对齐方法都必须在相对熵方面接近最佳 KL 约束 RL 解决方案。为了进一步分析对齐方法的属性，我们引入两个简化的假设：我们让语言模型是无记忆的，并且奖励模型是线性的。尽管这些假设可能无法反映复杂的现实场景，但它们能够在信息论量方面精确表征最佳 N$ 对齐和 KL 约束 RL 方法的渐近行为。我们证明了最优 KL 约束 RL 解的奖励满足大偏差原理，并充分表征了其速率函数。我们还表明，奖励的缩放累积量的增长率以适当的 Renyi 交叉熵为特征。最后，我们证明 best-of-$N$ 渐近等价于 KL 约束的 RL 解决方案，证明它们的预期奖励是渐近相等的，并得出两个分布在 KL 散度上必须接近的结论。]]></description>
      <guid>https://arxiv.org/abs/2404.01730</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>用于金融时间序列预测的监督自动编码器 MLP</title>
      <link>https://arxiv.org/abs/2404.01866</link>
      <description><![CDATA[arXiv:2404.01866v1 公告类型：交叉
摘要：本文研究了通过监督自动编码器使用神经网络增强金融时间序列预测，旨在提高投资策略的绩效。它使用夏普比率和信息比率专门研究了噪声增强和三重屏障标签对风险调整回报的影响。该研究重点关注 2010 年 1 月 1 日至 2022 年 4 月 30 日期间的交易资产——标准普尔 500 指数、欧元/美元和比特币/美元。研究结果表明，具有平衡噪声增强和瓶颈大小的监督自动编码器显着提高战略有效性。然而，过多的噪声和较大的瓶颈尺寸可能会损害性能，这凸显了精确参数调整的重要性。本文还提出了一种可与三重屏障标记一起使用的新颖优化指标的推导。这项研究的结果具有重大的政策意义，表明金融机构和监管机构可以利用所提出的技术来增强市场稳定性和投资者保护，同时鼓励在各个金融部门采用更明智的战略投资方法。]]></description>
      <guid>https://arxiv.org/abs/2404.01866</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>模型崩溃不可避免吗？通过积累真实数据和合成数据来打破递归魔咒</title>
      <link>https://arxiv.org/abs/2404.01413</link>
      <description><![CDATA[arXiv:2404.01413v1 公告类型：交叉
摘要：生成模型的激增，与网络规模数据的预训练相结合，提出了一个及时的问题：当这些模型根据自己生成的输出进行训练时会发生什么？最近对模型数据反馈循环的调查发现，此类循环可能导致模型崩溃，这种现象是每次模型拟合迭代时性能逐渐下降，直到最新模型变得无用。然而，最近研究模型崩溃的几篇论文假设新数据会随着时间的推移取代旧数据，而不是假设数据会随着时间的推移而积累。在本文中，我们比较了这两种设置，并表明积累数据可以防止模型崩溃。我们首先研究一个分析上易于处理的设置，其中一系列线性模型适合先前模型的预测。之前的工作表明，如果替换数据，测试误差会随着模型拟合迭代次数线性增加；我们通过证明如果数据累积，则测试误差具有与迭代次数无关的有限上限，从而扩展了该结果。接下来，我们通过在文本语料库上预训练语言模型序列来实证测试积累数据是否可以类似地防止模型崩溃。我们确认替换数据确实会导致模型崩溃，然后证明积累数据可以防止模型崩溃；这些结果适用于一系列模型大小、架构和超参数。我们进一步表明，类似的结果也适用于真实数据的其他深度生成模型：用于分子生成的扩散模型和用于图像生成的变分自动编码器。我们的工作提供了一致的理论和经验证据，表明数据积累可以减轻模型崩溃。]]></description>
      <guid>https://arxiv.org/abs/2404.01413</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>ImageNet 模型中的偏差可以解释泛化吗？</title>
      <link>https://arxiv.org/abs/2404.01509</link>
      <description><![CDATA[arXiv:2404.01509v1 公告类型：交叉
摘要：模型对从训练分布长尾中提取的稀有分布内（ID）样本和训练外分布（OOD）样本的稳健泛化是当前深度学习方法的主要挑战之一。对于图像分类，这表现为对抗性攻击的存在、扭曲图像的性能下降以及缺乏对草图等概念的泛化。目前对神经网络泛化的理解非常有限，但已经发现了一些区分模型与人类视觉的偏差，并且可能导致这些限制。因此，人们进行了多次尝试来减少训练过程中的这些偏差，以提高泛化能力，并取得了不同程度的成功。我们退后一步，对这些尝试进行健全性检查。将架构固定到完善的 ResNet-50 上，我们对通过不同训练方法获得的 48 个 ImageNet 模型进行了大规模研究，以了解这些偏差（包括形状偏差、光谱偏差和关键频带）如何以及是否与泛化相互作用。我们广泛的研究结果表明，与之前的发现相反，这些偏差不足以准确地整体预测模型的泛化能力。我们在 https://github.com/paulgavrikov/biases_vs_generalization 提供对所有检查点和评估代码的访问]]></description>
      <guid>https://arxiv.org/abs/2404.01509</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>未配对多模态数据的倾向得分对齐</title>
      <link>https://arxiv.org/abs/2404.01595</link>
      <description><![CDATA[arXiv:2404.01595v1 公告类型：交叉
摘要：多模态表示学习技术通常依赖于配对样本来学习共同表示，但在生物学等领域，测量设备经常破坏样本的配对样本很难收集。本文提出了一种方法来解决多模态表示学习中跨不同模态对齐不配对样本的挑战。我们在因果推理中的潜在结果和多模态观察中的潜在观点之间进行了类比，这使我们能够使用鲁宾的框架来估计匹配样本的公共空间。我们的方法假设我们收集在实验上受到治疗干扰的样本，并用它来估计每种模式的倾向得分，该倾向得分封装了潜在状态和治疗之间的所有共享信息，并可用于定义样本之间的距离。我们尝试了两种利用该距离的对齐技术——共享最近邻（SNN）和最佳传输（OT）匹配——并发现 OT 匹配在合成和优化中比最先进的对齐方法有显着改进。多模态设置和来自 NeurIPS 多模态单细胞集成挑战的真实数据。]]></description>
      <guid>https://arxiv.org/abs/2404.01595</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>具有转换成本的对抗性组合强盗</title>
      <link>https://arxiv.org/abs/2404.01883</link>
      <description><![CDATA[arXiv:2404.01883v1 公告类型：新
摘要：我们研究了对抗性组合老虎机问题，其中考虑了老虎机反馈和半老虎机反馈设置，每轮中每个选定臂的切换成本为 $\lambda$。在具有 $K$ 基臂和 $T$ 时间范围的不经意的对抗性情况下，我们推导出极小最大遗憾的下限并设计算法来接近它们。为了证明这些下限，我们基于 Dekel 等人之前工作的想法，为两种反馈设置设计了随机损失序列。 （2014）。老虎机反馈的下限为 $ \tilde{\Omega}\big( (\lambda K)^{\frac{1}{3}} (TI)^{\frac{2}{3}}\big) $ 而半老虎机反馈则为 $ \tilde{\Omega}\big( (\lambda K I)^{\frac{1}{3}} T^{\frac{2}{3}}\big) $ 其中 $I$ 是每轮比赛中组合臂中的基础臂数。为了接近这些下限，我们设计了批量运行的算法，通过将时间范围划分为多个批次来限制操作之间的切换数量。对于老虎机反馈设置，仅观察到组合臂的总损失，我们引入了 Batched-Exp2 算法，该算法实现了遗憾上限 $\tilde{O}\big((\lambda K)^{\frac {1}{3}}T^{\frac{2}{3}}I^{\frac{4}{3}}\big)$ 因为 $T$ 趋于无穷大。在半强盗反馈设置中，观察到组合臂的所有损失，我们提出了 Batched-BROAD 算法，该算法实现了遗憾上限 $\tilde{O}\big( (\lambda K)^{\frac {1}{3}} (TI)^{\frac{2}{3}}\big)$。]]></description>
      <guid>https://arxiv.org/abs/2404.01883</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>学习解决不确定性下的车间调度</title>
      <link>https://arxiv.org/abs/2404.01308</link>
      <description><![CDATA[arXiv:2404.01308v1 公告类型：交叉
摘要：作业车间调度问题（JSSP）是一个组合优化问题，其中需要在机器上调度任务，以最小化完工时间或延迟等标准。为了解决更现实的场景，我们将概率分布与每个任务的持续时间相关联。我们的目标是制定一个稳健的时间表，即最小化平均完工时间。本文介绍了一种利用深度强化学习 (DRL) 技术来搜索稳健解决方案的新方法，强调持续时间不确定的 JSSP。这项研究的主要贡献包括：(1) JSSP 的 DRL 应用的进步，增强了泛化性和可扩展性，(2) 一种解决持续时间不确定的 JSSP 的新方法。 Wheatley 方法集成了图神经网络 (GNN) 和 DRL，已公开供进一步研究和应用。]]></description>
      <guid>https://arxiv.org/abs/2404.01308</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>具有估计记录策略的双鲁棒离策略评估</title>
      <link>https://arxiv.org/abs/2404.01830</link>
      <description><![CDATA[arXiv:2404.01830v1 公告类型：新
摘要：我们引入了一种新颖的马尔可夫决策过程双鲁棒（DR）离策略评估（OPE）估计器 DRUnknown，专为日志记录策略和价值函数未知的情况而设计。所提出的估计器首先估计日志记录策略，然后在考虑日志记录策略的估计效果的同时，通过最小化估计器的渐近方差来估计价值函数模型。当正确指定日志记录策略模型时，DRUnknown 在包含现有 OPE 估计器的类中实现最小渐近方差。当值函数模型也正确指定时，DRUnknown 是最优的，因为其渐近方差达到半参数下界。我们展示了在上下文强盗和强化学习中进行的实验结果，以将 DRUnknown 的性能与现有方法的性能进行比较。]]></description>
      <guid>https://arxiv.org/abs/2404.01830</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:29 GMT</pubDate>
    </item>
    <item>
      <title>子标记何时起作用？</title>
      <link>https://arxiv.org/abs/2404.01832</link>
      <description><![CDATA[arXiv:2404.01832v1 公告类型：新
摘要：我们研究了回归树（机器学习中流行的非参数方法）上的子分类或子样本聚合的有效性。首先，我们为树的逐点一致性给出充分的条件。我们形式化地表示（i）偏差取决于细胞的直径，因此分裂较少的树往往有偏差，（ii）方差取决于细胞中的观察数量，因此分裂较多的树往往具有较大的方差。虽然已知这些偏差和方差的陈述在协变量空间中全局成立，但我们表明，在某些约束下，它们在局部也是正确的。其次，我们将子分类的性能与不同分裂数量的树的性能进行比较。我们发现（1）对于任何给定数量的分割，子标记对单个树的改进，并且（2）对于许多分割的这种改进比对于少数分割的改进更大。然而，(3) 如果单个树的大小没有得到最佳选择，以最佳大小生长的单棵树可能会优于子树。最后一个结果违背了种植大型随机树以消除偏差，然后求平均值以减少方差的常见做法。]]></description>
      <guid>https://arxiv.org/abs/2404.01832</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:29 GMT</pubDate>
    </item>
    <item>
      <title>Fair MP-BOOST：公平且可解释的小补丁增强</title>
      <link>https://arxiv.org/abs/2404.01521</link>
      <description><![CDATA[arXiv:2404.01521v1 公告类型：新
摘要：集成方法，特别是 boosting，已经成为表格数据的高效且广泛接受的机器学习技术。在本文中，我们的目标是利用传统增强方法的强大预测能力，同时增强公平性和可解释性。为了实现这一目标，我们开发了 Fair MP-Boost，这是一种随机提升方案，通过在训练期间自适应学习特征和观察来平衡公平性和准确性。具体来说，Fair MP-Boost 根据自适应学习的特征和观察采样概率，对观察和特征的小子集（称为小补丁 (MP)）顺序进行采样。我们通过组合损失函数或组合特征重要性分数来设计这些概率，以同时解决准确性和公平性问题。因此，Fair MP-Boost 优先考虑重要且公平的特征以及具有挑战性的实例，以选择最相关的小补丁进行学习。学习到的概率分布还产生对 Fair MP-Boost 中特征重要性和重要观察结果的内在解释。通过对模拟和基准数据集的实证评估，我们展示了 Fair MP-Boost 的可解释性、准确性和公平性。]]></description>
      <guid>https://arxiv.org/abs/2404.01521</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:28 GMT</pubDate>
    </item>
    <item>
      <title>FAIRM：学习算法公平性和具有极小极大最优性的领域泛化的不变表示</title>
      <link>https://arxiv.org/abs/2404.01608</link>
      <description><![CDATA[arXiv:2404.01608v1 公告类型：新
摘要：机器学习方法通​​常假设测试数据与训练数据具有相同的分布。然而，由于应用程序中存在多个级别的异构性，这种假设可能不成立，从而引发了算法公平性和领域泛化方面的问题。在这项工作中，我们通过不变原理解决公平和可推广的机器学习问题。我们提出了一种基于训练环境的预言机 FAIRM，它在多样性条件下具有理想的公平性和领域泛化特性。然后，我们在弱分布假设下提供了具有有限样本理论保证的经验 FAIRM。然后，我们开发有效的算法来在线性模型中实现 FAIRM，并展示具有极小极大最优性的非渐近性能。我们使用合成数据和 MNIST 数据在数值实验中评估我们的方法，并表明它优于同类方法。]]></description>
      <guid>https://arxiv.org/abs/2404.01608</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:28 GMT</pubDate>
    </item>
    <item>
      <title>防止高斯过程潜变量模型中的模型崩溃</title>
      <link>https://arxiv.org/abs/2404.01697</link>
      <description><![CDATA[arXiv:2404.01697v1 公告类型：新
摘要：高斯过程潜变量模型（GPLVM）是一个多功能的无监督学习模型系列，通常用于降维。然而，使用 GPLVM 进行数据建模的常见挑战包括内核灵活性不足和投影噪声选择不当，这会导致一种模型崩溃，其主要特征是模糊的潜在表示，无法反映数据的底层结构。本文首先通过线性 GPLVM 的视角从理论上检验投影方差对模型崩溃的影响，从而解决这些问题。其次，我们通过集成光谱混合（SM）内核和可微分随机傅立叶特征（RFF）内核近似来解决由于内核灵活性不足而导致的模型崩溃问题，这通过现成的自动微分工具确保了计算可扩展性和效率用于学习变分推理框架内的核超参数、投影方差和潜在表示。所提出的 GPLVM，名为advisedRFLVM，在不同的数据集上进行了评估，并且在信息丰富的潜在表示和缺失数据插补方面始终优于各种显着的竞争模型，包括最先进的变分自动编码器（VAE）和 GPLVM 变体。]]></description>
      <guid>https://arxiv.org/abs/2404.01697</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:28 GMT</pubDate>
    </item>
    <item>
      <title>具有仿射噪声方差的广义平滑非凸优化中 RMSProp 和 Adam 的收敛保证</title>
      <link>https://arxiv.org/abs/2404.01436</link>
      <description><![CDATA[arXiv:2404.01436v1 公告类型：新
摘要：本文在坐标广义平滑度和仿射噪声方差的最宽松假设下，首次对非凸优化中的 RMSProp 和 Adam 进行紧收敛分析。我们首先分析 RMSProp，它是 Adam 的一个特例，具有自适应学习率但没有一阶动量。具体来说，为了解决自适应更新、无界梯度估计和 Lipschitz 常数之间的依赖性带来的挑战，我们证明了下降引理中的一阶项收敛，并且其分母以梯度范数函数为上界。基于这个结果，我们表明具有适当超参数的 RMSProp 收敛到 $\epsilon$ 驻点，迭代复杂度为 $\mathcal O(\epsilon^{-4})$。然后，我们将我们的分析推广到 Adam，其中额外的挑战是由于梯度和一阶动量之间的不匹配。我们在下降引理的一阶项上开发了一个新的上限，它也是梯度范数的函数。我们证明具有适当超参数的 Adam 收敛到 $\epsilon$ 驻点，迭代复杂度为 $\mathcal O(\epsilon^{-4})$。我们的 RMSProp 和 Adam 的复杂性结果与 \cite{arjevani2023lower} 中建立的复杂性下限相匹配。]]></description>
      <guid>https://arxiv.org/abs/2404.01436</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:27 GMT</pubDate>
    </item>
    </channel>
</rss>