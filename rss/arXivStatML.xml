<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 07 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>经验风险最小化正则化中相对熵的不对称性</title>
      <link>https://arxiv.org/abs/2410.02833</link>
      <description><![CDATA[arXiv:2410.02833v1 公告类型：新
摘要：在具有相对熵正则化（ERM-RER）的经验风险最小化（ERM）背景下分析了相对熵不对称的影响。考虑了两种正则化：$(a)$ 待优化度量相对于参考度量的相对熵（Type-I ERM-RER）；或 $(b)$ 参考度量相对于待优化度量的相对熵（Type-II ERM-RER）。主要结果是对 Type-II ERM-RER 问题的解决方案及其关键属性的表征。通过比较易于理解的 Type-I ERM-RER 与 Type-II ERM-RER，突出了熵不对称的影响。分析表明，在这两种情况下，相对熵正则化都会迫使解决方案的支持度下降到参考度量的支持度，从而引入强烈的归纳偏差，这可能会掩盖训练数据提供的证据。最后，证明了 II 型正则化等同于 I 型正则化，只要对经验风险函数进行适当的变换即可。]]></description>
      <guid>https://arxiv.org/abs/2410.02833</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CAnDOIT：利用时间序列的观察和干预数据进行因果发现</title>
      <link>https://arxiv.org/abs/2410.02844</link>
      <description><![CDATA[arXiv:2410.02844v1 公告类型：新
摘要：因果关系研究在许多科学分支中都至关重要，但对于智能系统的许多实际应用也是如此。特别是，在包含隐藏因素的情况下识别因果关系对于仅依赖观察数据构建因果模型的方法来说是一项重大挑战。本文提出了 CAnDOIT，这是一种因果发现方法，用于使用观察和干预时间序列数据重建因果模型。在因果分析中使用干预数据对于现实世界的应用至关重要，例如机器人技术，其中场景非常复杂，仅靠观察数据通常不足以发现正确的因果结构。该方法的验证首先在随机生成的合成模型上进行，然后在机器人操作环境中因果结构学习的著名基准上进行。实验表明，该方法可以有效处理来自干预的数据并利用它们来提高因果分析的准确性。 CAnDOIT 的 Python 实现也已开发完毕，并在 GitHub 上公开提供：https://github.com/lcastri/causalflow。]]></description>
      <guid>https://arxiv.org/abs/2410.02844</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分层混合专家中的专家评估：超越 Softmax 门控函数</title>
      <link>https://arxiv.org/abs/2410.02935</link>
      <description><![CDATA[arXiv:2410.02935v1 公告类型：新
摘要：随着混合专家 (MoE) 架构在开发大型基础模型中的重要性日益突出，我们研究了分层混合专家 (HMoE)，这是 MoE 的一种特殊变体，擅长处理复杂输入并提高目标任务的性能。我们的研究强调了使用各种门控函数的优势，超越了 HMoE 框架内的 softmax 门控。我们从理论上证明，将定制的门控函数应用于每个专家组可以使 HMoE 实现稳健的结果，即使仅在选定的层次级别应用最佳门控函数也是如此。跨不同场景的经验验证支持这些理论主张。这包括大规模多模态任务、图像分类以及潜在域发现和预测任务，其中我们修改后的 HMoE 模型显示出巨大的性能改进。]]></description>
      <guid>https://arxiv.org/abs/2410.02935</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过李雅普诺夫势从优化到采样</title>
      <link>https://arxiv.org/abs/2410.02979</link>
      <description><![CDATA[arXiv:2410.02979v1 公告类型：新
摘要：我们研究使用朗之万动力学从高维分布中采样的问题，朗之万动力学是梯度下降的一种自然且流行的变体，在每一步中都会添加适当缩放的高斯噪声。朗之万动力学和梯度下降之间的相似性引出了一个自然的问题：如果可以通过梯度下降从所有初始化中优化分布的对数密度，给定对梯度的 oracle 访问，我们可以使用朗之万动力学从分布中采样吗？我们以低但适当的温度水平对这个问题给出肯定的回答，这在优化和实际应用的背景下都是自然的。作为推论，我们表明我们可以从几个新的自然且有趣的非对数凹密度类中采样，这是一个重要的设置，其中我们的例子相对较少。]]></description>
      <guid>https://arxiv.org/abs/2410.02979</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解 Transformer 在下一个 Token 预测中的通用性</title>
      <link>https://arxiv.org/abs/2410.03011</link>
      <description><![CDATA[arXiv:2410.03011v1 公告类型：新
摘要：因果 Transformers 经过训练可以预测给定上下文的下一个标记。虽然人们普遍认为自注意力对于编码序列的因果结构至关重要，但这种上下文自回归学习能力背后的确切潜在机制仍不清楚。在本文中，我们通过研究 Transformers 对下一个标记预测的近似能力，向理解这一现象迈出了一步。具体来说，我们探索因果 Transformers 在给定自回归序列 $(x_1, \dots, x_t)$ 作为提示的情况下预测下一个标记 $x_{t+1}$ 的能力，其中 $ x_{t+1} = f(x_t) $，并且 $ f $ 是一个随每个序列变化的上下文相关函数。在理论方面，我们专注于特定情况，即当 $ f $ 为线性时或当 $ (x_t)_{t \geq 1} $ 为周期时。我们明确构建了一个 Transformer（具有线性、指数或 softmax 注意力），它通过因果核下降法在上下文中学习映射 $f$。我们提出的因果核下降法可证明仅基于过去和当前观察值 $ (x_1, \dots, x_t) $ 估计 $x_{t+1} $，并与希尔伯特空间中的 Kaczmarz 算法相关。我们展示了实验结果，验证了我们的理论发现，并表明它们适用于更一般的映射 $f$。]]></description>
      <guid>https://arxiv.org/abs/2410.03011</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>时间序列的森林邻近度</title>
      <link>https://arxiv.org/abs/2410.03098</link>
      <description><![CDATA[arXiv:2410.03098v1 公告类型：新
摘要：RF-GAP 最近被引入作为一种改进的随机森林邻近度测量。在本文中，我们提出了 PF-GAP，它是 RF-GAP 邻近度到邻近森林的扩展，是一种准确而有效的时间序列分类模型。我们将森林邻近度与多维缩放结合使用来获得单变量时间序列的向量嵌入，并将嵌入与使用各种时间序列距离测量获得的嵌入进行比较。我们还使用森林邻近度和局部异常值因子来研究错误分类点和异常值之间的联系，并与使用时间序列距离测量的最近邻分类器进行比较。我们表明，与最近邻分类器相比，森林邻近度可能表现出错误分类点和异常值之间的更强联系。]]></description>
      <guid>https://arxiv.org/abs/2410.03098</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>嵌套深度学习模型：脑信号数据的基础模型</title>
      <link>https://arxiv.org/abs/2410.03191</link>
      <description><![CDATA[arXiv:2410.03191v1 公告类型：新
摘要：癫痫影响全球超过 5000 万人，基于 EEG/MEG 的尖峰检测在诊断和治疗中起着至关重要的作用。手动识别尖峰非常耗时，需要专门的培训，这限制了可用于分析 EEG/MEG 数据的专业人员的数量。为了解决这个问题，已经开发了各种算法方法。然而，当前的方法在处理不同的通道配置和识别尖峰起源的特定通道方面面临挑战。本文介绍了一种旨在克服这些限制的新型嵌套深度学习 (NDL) 框架。NDL 在所有通道上应用信号的加权组合，确保适应不同的通道设置，并允许临床医生更准确地识别关键通道。通过对真实 EEG/MEG 数据集的理论分析和实证验证，与传统方法相比，NDL 在尖峰检测和通道定位方面表现出更高的准确性。结果表明，NDL 提高了预测准确性，支持跨模态数据集成，并且可以针对各种神经生理应用进行微调。]]></description>
      <guid>https://arxiv.org/abs/2410.03191</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习利用布朗噪声进行操控</title>
      <link>https://arxiv.org/abs/2410.03221</link>
      <description><![CDATA[arXiv:2410.03221v1 公告类型：新
摘要：本文考虑了有界速度跟随问题的遍历版本，假设决策者缺乏对底层系统参数的了解，并且必须在控制的同时学习它们。我们提出了基于移动经验平均值的算法，并开发了一个将统计方法与随机控制理论相结合的框架。我们的主要结果是对数预期遗憾率。为了实现这一点，我们对底层过程的遍历收敛速度和所考虑的估计量的风险进行了严格的分析。]]></description>
      <guid>https://arxiv.org/abs/2410.03221</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>阐明流量匹配预测中概率路径的设计选择</title>
      <link>https://arxiv.org/abs/2410.03229</link>
      <description><![CDATA[arXiv:2410.03229v1 公告类型：新
摘要：流匹配最近已成为生成建模的强大范例，并已扩展到潜在空间中的概率时间序列预测。然而，概率路径模型的具体选择对预测性能的影响仍未得到充分探索。在这项工作中，我们证明使用流匹配预测时空数据对概率路径模型的选择高度敏感。受此见解的启发，我们提出了一种旨在提高预测性能的新型概率路径模型。我们在各种动态系统基准测试中的实证结果表明，与现有的概率路径模型相比，我们的模型在训练过程中实现了更快的收敛速度和更好的预测性能。重要的是，我们的方法在推理过程中非常有效，只需要几个采样步骤。这使得我们提出的模型适用于实际应用，并为概率预测开辟了新的途径。]]></description>
      <guid>https://arxiv.org/abs/2410.03229</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>受 $\epsilon$ 污染的 Credal 集的最优传输</title>
      <link>https://arxiv.org/abs/2410.03267</link>
      <description><![CDATA[arXiv:2410.03267v1 公告类型：新
摘要：我们提供了 Monge 和 Kantorovich 最优传输问题的低概率版本。我们表明，当低概率是 $\epsilon$ 污染集的下包络时，我们的 Monge 版本和我们的 Kantorovich 问题的受限版本与它们各自的经典版本一致。我们还给出了我们版本的 Kantorovich 最优计划存在的充分条件，以及这两个问题等价的充分条件。作为副产品，我们表明对于 $\epsilon$ 污染，Monge 和 Kantorovich 最优传输问题的低概率版本不必一致。我们还讨论了我们的结果在机器学习和人工智能中的应用。]]></description>
      <guid>https://arxiv.org/abs/2410.03267</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于生物医学图像分割的共形置信集</title>
      <link>https://arxiv.org/abs/2410.03406</link>
      <description><![CDATA[arXiv:2410.03406v1 公告类型：新
摘要：我们开发了置信集，为用于图像分割的黑盒机器学习模型的输出提供空间不确定性保证。为此，我们将共形推理调整到成像设置，根据地面真实掩码内部和外部转换后的 logit 分数的最大值的分布在校准数据集上获得阈值。我们证明，当将这些置信集应用于模型的新预测时，保证以期望的概率包含真实的未知分割掩码。我们表明，在执行校准之前在学习数据集上学习适当的分数转换对于优化性能至关重要。我们在息肉肿瘤数据集上说明并验证了我们的方法。为此，我们从针对息肉分割训练的深度神经网络中获得 logit 分数，并表明使用距离转换分数来获得外部置信集和内部置信集的原始分数可以严格限制肿瘤位置，同时控制错误覆盖率。]]></description>
      <guid>https://arxiv.org/abs/2410.03406</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非平稳稀疏谱持久过程</title>
      <link>https://arxiv.org/abs/2410.03581</link>
      <description><![CDATA[arXiv:2410.03581v1 公告类型：新
摘要：现有的永久过程通常会对核类型或平稳性施加约束，从而限制模型的表现力。为了克服这些限制，我们提出了一种利用非平稳核的稀疏谱表示的新方法。该技术放宽了对核类型和平稳性的约束，允许更灵活的建模，同时将计算复杂度降低到线性水平。此外，我们通过分层堆叠多个光谱特征映射引入了深度核变体，进一步增强了模型的表现力以捕获数据中的复杂模式。在合成数据集和真实世界数据集上的实验结果证明了我们方法的有效性，特别是在数据非平稳性明显的情况下。此外，还进行了消融研究，以深入了解各种超参数对模型性能的影响。]]></description>
      <guid>https://arxiv.org/abs/2410.03581</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>极小最大最优信任感知多臂老虎机</title>
      <link>https://arxiv.org/abs/2410.03651</link>
      <description><![CDATA[arXiv:2410.03651v1 公告类型：新
摘要：在人类完美执行推荐策略的前提下，多臂老虎机 (MAB) 算法在顺序决策应用中取得了重大成功。然而，现有的方法往往忽略了学习算法中人类信任的关键因素。当缺乏信任时，人类可能会偏离推荐的策略，导致学习表现不佳。受此差距的启发，我们通过将动态信任模型集成到标准 MAB 框架中来研究信任感知 MAB 问题。具体而言，它假设推荐和实际实施的策略因人类信任而不同，而信任又随着推荐策略的质量而发展。我们在存在信任问题的情况下建立了极小最大遗憾，并证明了诸如上置信界限 (UCB) 算法之类的 vanilla MAB 算法的次优性。为了克服这一限制，我们引入了一种新颖的两阶段信任感知程序，可以证明该程序可以实现近乎最优的统计保证。进行了一项模拟研究来说明我们提出的算法在处理信任问题时的优势。]]></description>
      <guid>https://arxiv.org/abs/2410.03651</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>库存管理的神经协调和容量控制</title>
      <link>https://arxiv.org/abs/2410.02817</link>
      <description><![CDATA[arXiv:2410.02817v1 公告类型：交叉 
摘要：本文解决了容量限制定期审查库存控制问题，重点关注零售商在有限的共享资源（例如设施中的存储或入库劳动力）下管理多种产品。具体来说，本文的动机是以下问题：(1) 回测容量控制机制意味着什么，(2) 我们能否设计和回测与库存管理深度强化学习的最新进展兼容的容量控制机制？首先，由于我们只有亚马逊容量限制的单一历史样本路径，我们提出了一种从覆盖现实场景空间的可能约束路径分布中抽样的方法。这种新颖的方法可以更稳健、更现实地测试库存管理策略。其次，我们将 Madeka 等人 2022 年的 exo-IDP（外生决策过程）公式扩展到容量限制定期审查库存控制问题，并表明某些容量限制控制问题并不比监督学习更难。第三，我们引入了一个“神经协调器”，旨在预测容量价格，指导系统遵守目标约束，以取代传统的模型预测控制器。最后，我们应用改进的 DirectBackprop 算法来学习深度 RL 购买策略并训练神经协调器。我们的方法通过大规模回测进行评估，证明具有神经协调器的 RL 购买策略在累积折扣奖励和容量遵守方面均优于经典基线（在某些情况下，我们看到高达 50% 的改进）。]]></description>
      <guid>https://arxiv.org/abs/2410.02817</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于神经网络的汉密尔顿-雅可比可达性的收敛保证</title>
      <link>https://arxiv.org/abs/2410.02904</link>
      <description><![CDATA[arXiv:2410.02904v1 公告类型：交叉 
摘要：我们为 DeepReach 提供了一种新的均匀收敛保证，DeepReach 是一种基于深度学习的方法，用于解决与可达性分析相关的 Hamilton-Jacobi-Isaacs (HJI) 方程。具体来说，我们证明了 DeepReach 算法（由 Bansal 等人在 2020 年的同名论文中介绍）是稳定的，即如果算法的损失函数收敛到零，则得到的神经网络近似值会均匀收敛到 HJI 方程的经典解（假设存在经典解）。我们还对该算法进行了数值测试，复制了原始 DeepReach 论文中提供的实验，并通过实证研究了使用上确界范数损失度量进行训练对近似误差的影响。]]></description>
      <guid>https://arxiv.org/abs/2410.02904</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>