<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 11 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>学习高斯单指数模型的计算复杂度</title>
      <link>https://arxiv.org/abs/2403.05529</link>
      <description><![CDATA[arXiv:2403.05529v1 公告类型：交叉
摘要：单索引模型是具有植入结构的高维回归问题，其中标签依赖于通过通用、非线性和潜在的非确定性变换输入的未知一维投影。因此，它们涵盖了广泛的统计推理任务，并提供了丰富的模板来研究高维体系中的统计和计算权衡。
  虽然恢复隐藏方向的信息论样本复杂度在维度 $d$ 中是线性的，但我们表明，在统计查询 (SQ) 和低次多项式 (LDP) 框架内，计算高效的算法必然需要 $ \Omega(d^{k^\star/2})$ 样本，其中 $k^\star$ 是与我们明确表征的模型相关的“生成”指数。此外，我们通过使用部分跟踪算法建立匹配上限，表明该样本复杂度也是足够的。因此，我们的结果提供了每当 $k^\star&gt;2$ 时计算与统计之间存在巨大差距的证据（在 SQ 和 LDP 类别下）。为了完成研究，我们提供了具有任意大生成指数 $k^\star$ 的平滑和 Lipschitz 确定性目标函数的示例。]]></description>
      <guid>https://arxiv.org/abs/2403.05529</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:35 GMT</pubDate>
    </item>
    <item>
      <title>一种学习漂移离散分布的改进算法</title>
      <link>https://arxiv.org/abs/2403.05446</link>
      <description><![CDATA[arXiv:2403.05446v1 公告类型：交叉
摘要：我们提出了一种新的自适应算法，用于学习分布漂移下的离散分布。在此设置中，我们观察随时间变化的离散分布的一系列独立样本，目标是估计当前分布。由于我们只能访问每个时间步长的单个样本，因此良好的估计需要仔细选择要使用的过去样本的数量。为了使用更多的样本，我们必须进一步求助于过去的样本，并且由于分布变化引入的偏差，我们会产生漂移误差。另一方面，如果我们使用少量的过去样本，由于估计的方差很大，我们会产生很大的统计误差。我们提出了一种新颖的自适应算法，可以在没有任何漂移先验知识的情况下解决这种权衡问题。与以前的自适应结果不同，我们的算法使用数据相关的界限来表征统计误差。这种技术性使我们能够克服以前工作的局限性，即需要固定的有限支撑，其尺寸预先已知并且不能随时间变化。此外，我们可以根据漂移分布的复杂性获得更严格的界限，并且还可以考虑具有无限支持的分布。]]></description>
      <guid>https://arxiv.org/abs/2403.05446</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>多视角对比学习</title>
      <link>https://arxiv.org/abs/2403.05490</link>
      <description><![CDATA[arXiv:2403.05490v1 公告类型：交叉
摘要：对比学习通常在许多不相关的负面观点中匹配相关观点对。视图可以被生成（例如通过增强）或被观察。当存在两个以上相关视图（我们称为多视图任务）时，我们研究匹配，并使用信息最大化和足够的统计数据导出新的表示学习目标。我们表明，在无限计算的情况下，应该最大化相关视图的数量，并且在固定的计算预算下，减少唯一样本的数量同时增加这些样本的视图数量是有益的。特别是，在 ImageNet1k 上以批量大小 256 训练 128 个周期的多视图对比模型优于在批量大小 4096 上训练 1024 个周期的 SimCLR，挑战了对比模型需要大批量大小和许多训练周期的信念。]]></description>
      <guid>https://arxiv.org/abs/2403.05490</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>持续学习和灾难性遗忘</title>
      <link>https://arxiv.org/abs/2403.05175</link>
      <description><![CDATA[arXiv:2403.05175v1 公告类型：交叉
摘要：本章深入探讨了持续学习的动态，即从非平稳数据流中增量学习的过程。虽然持续学习是人脑的一项自然技能，但对于人工神经网络来说却非常具有挑战性。一个重要的原因是，当学习新东西时，这些网络往往会快速而彻底地忘记以前学过的东西，这种现象被称为灾难性遗忘。特别是在过去的十年中，持续学习已成为深度学习领域广泛研究的课题。本书章节回顾了该领域产生的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.05175</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>训练对角线性网络时利用连续时间来理解动量</title>
      <link>https://arxiv.org/abs/2403.05293</link>
      <description><![CDATA[arXiv:2403.05293v1 公告类型：交叉
摘要：在这项工作中，我们研究了动量对梯度下降优化轨迹的影响。我们利用连续时间方法来分析步长 $\gamma$ 和动量参数 $\beta$ 的动量梯度下降，这使我们能够识别内在量 $\lambda = \frac{ \gamma }{ (1 - \beta)^2 }$ 唯一定义了优化路径并提供了简单的加速规则。当在过参数回归设置中训练 2 层对角线性网络时，我们通过隐式正则化问题来表征恢复的解决方案。然后我们证明 $\lambda$ 的小值有助于恢复稀疏解。最后，我们给出了随机动量梯度下降的类似但较弱的结果。我们提供数值实验来支持我们的主张。]]></description>
      <guid>https://arxiv.org/abs/2403.05293</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>意见动态模型中参数的变分推理</title>
      <link>https://arxiv.org/abs/2403.05358</link>
      <description><![CDATA[arXiv:2403.05358v1 公告类型：交叉
摘要：尽管经常使用基于代理的模型（ABM）来研究社会现象，但参数估计仍然是一个挑战，通常依赖于昂贵的基于模拟的启发式方法。这项工作使用变分推理来估计意见动态 ABM 的参数，将估计问题转化为可以直接解决的优化任务。
  我们的建议依赖于概率生成 ABM（PGABM）：我们首先根据 ABM 规则合成概率生成模型。然后，我们将推理过程转化为适合自动微分的优化问题。特别是，我们使用 Gumbel-Softmax 重新参数化来进行分类代理属性，并使用随机变分推理来进行参数估计。此外，我们探讨了使用具有不同复杂性的变分分布的权衡：正态分布和归一化流。
  我们在具有代理角色（领导者和追随者）的有界置信模型上验证我们的方法。我们的方法比基于模拟和 MCMC 方法更准确地估计宏观（有界置信区间和适得其反阈值）和微观（200 美元分类、代理级角色）。因此，我们的技术使专家能够根据现实世界的观察来调整和验证他们的 ABM，从而通过数据驱动的分析提供对社会系统中人类行为的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.05358</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>堆叠作为加速梯度下降</title>
      <link>https://arxiv.org/abs/2403.04978</link>
      <description><![CDATA[arXiv:2403.04978v1 公告类型：交叉
摘要：堆叠是一种启发式技术，通过逐步增加层数并通过复制旧层的参数来初始化新层来训练深度残差网络，事实证明，它在提高训练深度神经网络的效率方面非常成功。在本文中，我们对堆叠的功效提出了理论解释：即堆叠实现了 Nesterov 加速梯度下降的一种形式。该理论还涵盖了更简单的模型，例如在 boosting 方法中构建的加性系综，并为在每轮 boosting 中初始化新分类器的类似广泛使用的实用启发式提供了解释。我们还证明，对于某些深度线性残差网络，通过对允许更新错误的 Nesterov 加速梯度方法的新势函数分析，堆叠确实提供了加速训练。我们还进行了概念验证实验来验证我们的理论。]]></description>
      <guid>https://arxiv.org/abs/2403.04978</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:32 GMT</pubDate>
    </item>
    <item>
      <title>可证明的多方强化学习与不同的人类反馈</title>
      <link>https://arxiv.org/abs/2403.05006</link>
      <description><![CDATA[arXiv:2403.05006v1 公告类型：交叉
摘要：带有人类反馈的强化学习（RLHF）是一种新兴的范式，旨在使模型与人类偏好保持一致。通常，RLHF 会汇总多个具有不同观点且可能相互冲突的个人的偏好。我们的工作 \textit{启动了多方 RLHF 的理论研究，明确模拟了多个个体的不同偏好。我们展示了传统的 RLHF 方法可能会失败，因为学习单一奖励函数无法捕获和平衡多个个体的偏好。为了克服这些限制，我们结合元学习来学习多种偏好，并采用不同的社会福利函数来聚合多方的偏好。我们关注离线学习环境，建立样本复杂度界限，以及效率和公平保证，以优化纳什、功利和 Leximin 福利函数等多种社会福利函数。我们的结果显示多方 RLHF 和传统单方 RLHF 的样本复杂性有所不同。此外，我们考虑无奖励设置，其中每个人的偏好不再与奖励模型一致，并根据离线偏好数据给出冯·诺依曼获胜者的悲观变体。总而言之，我们的工作展示了多方 RLHF 的优势，但也凸显了其更高的统计复杂性。]]></description>
      <guid>https://arxiv.org/abs/2403.05006</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:32 GMT</pubDate>
    </item>
    <item>
      <title>我们知道，并非所有门票都是平等的：用特定领域的知识指导修剪</title>
      <link>https://arxiv.org/abs/2403.04805</link>
      <description><![CDATA[arXiv:2403.04805v1 公告类型：交叉
摘要：神经结构学习对于科学发现和可解释性至关重要。然而，注重计算资源效率的当代剪枝算法在选择与领域专业知识相一致的有意义的模型时面临着算法障碍。为了缓解这一挑战，我们提出了 DASH，它通过可用的特定领域结构信息来指导修剪。在学习动态基因调控网络模型的背景下，我们表明，DASH 与现有的交互伙伴常识相结合，提供了与生物学一致的特定于数据的见解。对于这项任务，我们在具有真实信息的合成数据和两个现实世界应用中展示了 DASH 的有效性，它大大优于竞争方法，并提供了更有意义的生物学见解。我们的工作表明，特定领域的结构信息具有改善模型衍生的科学见解的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.04805</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>R\'enyi 差分隐私的群体隐私放大和统一子采样放大</title>
      <link>https://arxiv.org/abs/2403.04867</link>
      <description><![CDATA[arXiv:2403.04867v1 公告类型：交叉
摘要：差分隐私（DP）具有各种理想的属性，例如对后处理的鲁棒性、群体隐私和子采样放大，这些属性可以彼此独立地导出。我们的目标是确定是否可以通过联合考虑这些属性的多个来获得更强的隐私保证。为此，我们重点关注群体隐私和二次采样放大的结合。为了提供适合机器学习算法的保证，我们在 R\&#39;enyi-DP 框架中进行分析，它比 $(\epsilon,\delta)$-DP 具有更有利的组合属性。作为此分析的一部分，我们开发了一个统一的框架，用于通过 R\&#39;enyi-DP 的二次采样保证来推导放大，这代表了隐私核算方法的第一个此类框架，并且具有独立的意义。我们发现它不仅让我们改进和推广 R\&#39;enyi-DP 的现有放大结果，而且还得出比现有原理更强的可证明严格的群体隐私放大保证。这些结果确立了不同 DP 特性的联合研究作为一个有前途的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2403.04867</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>有限状态主方程的深度逆向法和伽辽金法</title>
      <link>https://arxiv.org/abs/2403.04975</link>
      <description><![CDATA[arXiv:2403.04975v1 公告类型：交叉
摘要：本文提出并分析了两种求解有限状态平均场博弈（MFG）主方程的神经网络方法。求解 MFG 为具有有限但大量代理的随机微分博弈提供了近似纳什均衡。主方程是偏微分方程 (PDE)，其解表征任何可能的初始分布的 MFG 平衡。我们提出的第一种方法依赖于时间分量的后向归纳，而第二种方法直接处理偏微分方程而不离散时间。对于这两种方法，我们证明了两种类型的结果：存在使算法的损失函数任意小的神经网络，相反，如果损失很小，则神经网络是主方程解的良好近似。我们通过对文献中高达 15 维的基准问题的数值实验来结束本文，并与固定初始分布的经典方法计算的解决方案进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2403.04975</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>Copula 的高效准随机采样</title>
      <link>https://arxiv.org/abs/2403.05281</link>
      <description><![CDATA[arXiv:2403.05281v1 公告类型：新
摘要：本文研究了蒙特卡罗计算中联结函数准随机采样的有效方法。传统方法，如条件分布方法（CDM），在处理高维或隐式联结函数时存在局限性，这些联结函数是指现有参数联结函数无法准确表示的联结函数。相反，本文建议使用生成模型，例如生成对抗网络（GAN），为任何 copula 生成准随机样本。 GAN 是一种隐式生成模型，用于学习复杂数据的分布，从而方便采样。在我们的研究中，GAN 用于学习从均匀分布到 copula 的映射。一旦学习了这种映射，从联结中获得准随机样本只需要输入来自均匀分布的准随机样本。这种方法为任何联接函数提供了更灵活的方法。此外，我们还提供了基于联结的准随机样本的准蒙特卡罗估计量的理论分析。通过模拟和实际应用，特别是在风险管理领域，我们验证了所提出的方法并证明了其相对于各种现有方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2403.05281</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>高维贝叶斯优化的自适应降维估计方法</title>
      <link>https://arxiv.org/abs/2403.05425</link>
      <description><![CDATA[arXiv:2403.05425v1 公告类型：新
摘要：贝叶斯优化（BO）在中低维欧几里得空间的各种应用中显示出令人印象深刻的结果。然而，将 BO 扩展到高维设置仍然是一个重大挑战。我们通过提出一个两步优化框架来应对这一挑战。最初，我们使用最小平均方差估计（MAVE）方法确定目标函数的有效降维（EDR）子空间。随后，我们在此 EDR 子空间内构建高斯过程模型，并使用预期改进标准对其进行优化。我们的算法提供了同时或按顺序操作这些步骤的灵活性。在顺序方法中，我们通过在子空间估计和函数优化之间分配采样预算来精心平衡探索与利用的权衡，并且我们的算法在高维上下文中的收敛速度已经建立。数值实验验证了我们的方法在具有挑战性的场景中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.05425</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>具有 Fr\'{e}chet 型尾部分布的跟随扰动领导者：对抗性强盗和两全其美的最优性</title>
      <link>https://arxiv.org/abs/2403.05134</link>
      <description><![CDATA[arXiv:2403.05134v1 公告类型：新
摘要：本文研究了对抗性和随机 $K$ 武装强盗中的跟随扰动领导者 (FTPL) 策略的最优性。尽管具有各种正则化选择的跟随正则化领导者（FTRL）框架被广泛使用，但依赖于随机扰动的 FTPL 框架尽管其固有的简单性，并没有受到太多关注。在对抗性老虎机中，有人推测，如果扰动遵循具有 Fr\&#39;{e}chet 型尾部的分布，则 FTPL 可能会实现 $\mathcal{O}(\sqrt{KT})$ 遗憾。本田等人最近的工作。 (2023) 表明，具有形状为 $\alpha=2$ 的 Fr\&#39;{e}chet 分布的 FTPL 确实达到了这个界限，特别是随机老虎机中的对数遗憾，这意味着两全其美 (BOBW) 的能力FTPL。然而，这个结果仅部分解决了上述猜想，因为他们的分析很大程度上依赖于具有这种形状的 Fr\&#39;{e}chet 分布的具体形式。在本文中，我们建立了一个充分的扰动条件，以在对抗性设置中实现 $\mathcal{O}(\sqrt{KT})$ 遗憾，其中包括 Fr\&#39;{e}chet、Pareto 和 Student -$t$ 发行版。我们还证明了具有某些 Fr\&#39;{e}chet 型尾部分布的 FTPL 的 BOBW 可实现性。我们的结果不仅有助于通过极值理论的视角解决现有猜想，而且还可能通过从 FTPL 到 FTRL 的映射，深入了解 FTRL 中正则化函数的影响。]]></description>
      <guid>https://arxiv.org/abs/2403.05134</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:29 GMT</pubDate>
    </item>
    <item>
      <title>贪婪特征选择：通过贪婪方法进行依赖于分类器的特征选择</title>
      <link>https://arxiv.org/abs/2403.05138</link>
      <description><![CDATA[arXiv:2403.05138v1 公告类型：新
摘要：本研究的目的是引入一种用于分类任务的特征排序的新方法，称为贪婪特征选择。在统计学习中，特征选择通常通过独立于用于使用减少的特征数量来执行预测的分类器的方法来实现。相反，贪婪特征选择根据所选的分类器在每个步骤中识别最重要的特征。在本文中，从模型容量指标（例如 Vapnik-Chervonenkis（VC）维度或核对齐）方面对这种方案的好处进行了理论上的研究，并通过考虑其在预测地球有效表现问题中的应用进行了数值测试。活跃的太阳。]]></description>
      <guid>https://arxiv.org/abs/2403.05138</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:29 GMT</pubDate>
    </item>
    </channel>
</rss>