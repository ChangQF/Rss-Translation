<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 28 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>ED-Filter：用于饮食失调分类的动态特征过滤</title>
      <link>https://arxiv.org/abs/2501.14785</link>
      <description><![CDATA[arXiv:2501.14785v1 公告类型：新
摘要：进食障碍 (ED) 是引起心理健康界担忧的重要精神问题。心理健康专业人士越来越认识到来自 Twitter 等社交媒体平台的数据的实用性。然而，Twitter 数据的高维度和广泛的特征集对 ED 分类提出了巨大的挑战。为了克服这些障碍，我们引入了一种新方法，即一种称为 ED-Filter 的知情分支定界搜索技术。该策略显著改善了传统特征选择算法（如过滤器和包装器）的缺点。ED-Filter 迭代地识别一组最佳的有希望的特征，以最大限度地提高进食障碍分类的准确性。为了适应 Twitter ED 数据的动态特性，我们使用基于贪婪的混合深度学习算法增强了 ED-Filter。该算法可以快速识别次优特征，以适应不断变化的数据格局。Twitter 进食障碍数据的实验结果证实了 ED-Filter 的有效性和效率。该方法在分类准确性方面表现出显著的提高，并证明了其在社交媒体平台上饮食失调检测中的价值。]]></description>
      <guid>https://arxiv.org/abs/2501.14785</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用图协方差和 LLM 解释分类特征交互</title>
      <link>https://arxiv.org/abs/2501.14932</link>
      <description><![CDATA[arXiv:2501.14932v1 公告类型：新 
摘要：现代数据集通常由具有丰富特征和相关时间戳的大量样本组成。分析此类数据集以发现潜在事件通常需要复杂的统计方法和大量领域专业知识。一个值得注意的例子，也是本文的主要数据重点，是来自反贩运数据协作组织 (CTDC) 的全球合成数据集——这是一个全球人口贩运数据中心，包含 2002 年至 2022 年期间超过 200,000 条匿名记录，每条记录都有许多分类特征。在本文中，我们提出了一种快速且可扩展的方法来分析和提取重要的分类特征交互，并查询大型语言模型 (LLM) 以生成解释这些交互的数据驱动见解。我们的方法首先使用独热编码对分类特征进行二值化步骤，然后计算每次的图协方差。该图协方差量化了分类数据中依赖结构的时间变化，并被确立为伯努利分布下的一致依赖性度量。我们使用此度量来识别重要的特征对，例如那些随时间变化趋势最频繁的特征对，或在特定时刻表现出依赖性突然激增的特征对。这些提取的特征对及其时间戳随后被传递给 LLM，该 LLM 的任务是生成驱动这些依赖性变化的潜在事件的潜在解释。我们的方法的有效性通过大量模拟得到证明，并且将其应用于 CTDC 数据集揭示了有意义的特征对和观察到的特征交互背后的潜在数据故事。]]></description>
      <guid>https://arxiv.org/abs/2501.14932</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用条件密度估计进行个体治疗效果的适形推断</title>
      <link>https://arxiv.org/abs/2501.14933</link>
      <description><![CDATA[arXiv:2501.14933v1 公告类型：新
摘要：在多样化和复杂数据日益普及的时代，对个体治疗效果 (ITE) 的准确预测在医疗保健、经济和公共政策等领域变得至关重要。当前最先进的方法虽然通过共形分位数回归 (CQR) 和相关技术提供有效的预测区间，但通常会产生过于保守的预测区间。在这项工作中，我们引入了一种共形推理方法，使用给定协变量的结果的条件密度来对 ITE 进行推理。我们利用参考分布技术在两阶段共形 ITE 框架下有效地估计分数函数的条件密度。我们表明，我们的预测区间不仅边缘有效，而且比现有方法更窄。实验结果进一步验证了我们方法的实用性。]]></description>
      <guid>https://arxiv.org/abs/2501.14933</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稳健密度估计的森林中值</title>
      <link>https://arxiv.org/abs/2501.15157</link>
      <description><![CDATA[arXiv:2501.15157v1 公告类型：新
摘要：稳健密度估计是指即使数据受到异常值的污染，密度函数的估计仍然保持一致。我们发现，某一点的现有森林密度估计本质上可以抵抗包含该点的单元格之外的异常值，我们将其称为 \textit{非局部异常值}，但不能抵抗其余的 \textit{局部异常值}。为了实现对所有异常值的稳健性，我们提出了一种集成学习算法，称为 \textit{用于稳健密度估计的森林中位数} (\textit{MFRDE})，该算法对在子采样数据集上拟合的森林密度估计器采用逐点中值运算。与现有的基于核的稳健方法相比，MFRDE 使我们能够选择更大的子采样大小，在实现稳健性的同时以更少的精度牺牲密度估计。在理论方面，我们引入了局部异常值指数来量化局部异常值的数量。在这个指数下，我们表明，即使样本规模中的异常值数量达到一定的多项式阶数，MFRDE 也能够实现与未污染数据上相同算法几乎相同的收敛速度，而基于核的稳健方法则失败了。在实践方面，真实数据实验表明 MFRDE 优于现有的基于核的稳健方法。此外，我们将 MFRDE 应用于异常检测，以展示进一步的应用。]]></description>
      <guid>https://arxiv.org/abs/2501.15157</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>时间序列异常检测的自监督学习综述：最新进展与挑战</title>
      <link>https://arxiv.org/abs/2501.15196</link>
      <description><![CDATA[arXiv:2501.15196v1 公告类型：新
摘要：由于时间相关数据的顺序性和动态性，时间序列异常检测面临各种挑战。传统的无监督方法经常遇到泛化困难，通常会过度拟合训练期间观察到的已知正常模式，并难以适应看不见的正常性。为了应对这一限制，时间序列的自监督技术已引起人们的关注，成为解决这一障碍并提高异常检测器性能的潜在解决方案。本文全面回顾了最近利用自监督学习进行时间序列异常检测的方法。提出了一种分类法，根据这些方法的主要特征对其进行分类，以便清楚地了解它们在该领域的多样性。本调查中包含的信息以及将定期更新的其他详细信息可在以下 GitHub 存储库中找到：https://github.com/Aitorzan3/Awesome-Self-Supervised-Time-Series-Anomaly-Detection。]]></description>
      <guid>https://arxiv.org/abs/2501.15196</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过稀有转换路径上的深度自适应采样估计提交函数</title>
      <link>https://arxiv.org/abs/2501.15522</link>
      <description><![CDATA[arXiv:2501.15522v1 公告类型：新
摘要：提交函数是研究分子模拟中罕见但重要事件的核心。众所周知，计算提交函数会受到维数灾难的影响。最近，使用神经网络估计提交函数因其在高维问题中的潜力而受到关注。训练神经网络以近似提交函数需要从罕见事件的直接模拟中采样转换数据，这是非常低效的。转换数据的稀缺使得近似提交函数变得具有挑战性。为了解决这个问题，我们提出了一个有效的框架来生成过渡态区域的数据点，这有助于训练神经网络近似提交函数。我们设计了一种用于转换路径的深度自适应采样方法 (DASTR)，其中使用深度生成模型来生成样本以有效捕获转换信息。具体而言，我们将损失函数的被积函数中的非负函数视为非归一化概率密度函数，并用深度生成模型对其进行近似。深度生成模型产生的新样本主要分布在过渡态区域，其他区域样本较少。该分布为逼近提交函数提供了有效样本，显著提高了准确率。我们通过仿真和实际例子证明了所提方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.15522</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向元学习更清晰的信息论泛化界限</title>
      <link>https://arxiv.org/abs/2501.15559</link>
      <description><![CDATA[arXiv:2501.15559v1 公告类型：新
摘要：近年来，信息论泛化界限已成为分析元学习算法泛化能力的一种有前途的方法。然而，现有的结果仅限于两步界限，无法更清晰地描述元泛化差距，同时考虑环境级和任务级依赖性。本文通过为元学习建立新的单步信息论界限来解决这一根本限制。我们的界限比以前基于 MI 和 CMI 的界限具有显著优势，特别是在紧密性、与采样任务和每个任务的样本相关的扩展行为以及计算可处理性方面。此外，我们通过梯度协方差分析为两类噪声和迭代元学习算法的泛化行为提供了新颖的理论见解，其中元学习者使用整个元训练数据（例如 Reptile），或在任务中使用单独的训练和测试数据（例如模型不可知元学习 (MAML)）。数值结果验证了导出的界限在捕捉元学习的泛化动态方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.15559</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>I-可信模型。概率分类器可信度评估框架</title>
      <link>https://arxiv.org/abs/2501.15617</link>
      <description><![CDATA[arXiv:2501.15617v1 公告类型：新
摘要：随着概率模型继续渗透到我们社会的各个方面并促进科学进步，超越传统指标（例如预测准确性和错误率）并评估其可信度已成为必要。基于基于能力的信任理论，这项工作形式化了 I-trustworthy 框架——一种通过将局部校准与可信度联系起来评估概率分类器在推理任务中的可信度的新框架。为了评估 I-trustworthiness，我们使用局部校准误差 (LCE) 并开发一种假设检验方法。该方法利用基于核的检验统计量，即核局部校准误差 (KLCE)，来测试概率分类器的局部校准。本研究通过为 KLCE 的无偏估计量提供收敛界限，提供了理论保证。此外，我们还提出了一种诊断工具，用于识别和测量校准错误情况下的偏差。通过将所提出的检验统计量应用于模拟和真实世界数据集，证明了其有效性。最后，研究了相关重新校准方法的 LCE，并提供了现有方法无法实现 I-可信度的证据。]]></description>
      <guid>https://arxiv.org/abs/2501.15617</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>尺度不敏感神经网络显著性检验</title>
      <link>https://arxiv.org/abs/2501.15753</link>
      <description><![CDATA[arXiv:2501.15753v1 公告类型：新
摘要：本文开发了一个不敏感于尺度的神经网络重要性测试框架，通过三个关键创新大大推广了现有方法。首先，我们用 Rademacher 复杂度界限取代度量熵计算，从而能够在不需要有界权重或特定架构约束的情况下分析神经网络。其次，我们削弱了目标函数的正则性条件，只需要 Sobolev 空间成员 $H^s([-1,1]^d)$ 和 $s &gt; d/2$，从而显著放宽了先前的平滑度假设，同时保持了最佳近似率。第三，我们引入了一种基于矩界限而不是权重约束的改进筛空间构造，为现代深度学习实践提供了更自然的理论框架。我们的方法实现了这些推广，同时保留了最佳收敛速度并为测试统计量建立了有效的渐近分布。技术基础结合了局部化理论、尖锐的集中不等式和尺度不敏感的复杂性度量，以处理无界权重和一般 Lipschitz 激活函数。该框架在保持数学严谨性的同时，更好地将理论保证与当代深度学习实践结合起来。]]></description>
      <guid>https://arxiv.org/abs/2501.15753</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SAPPHIRE：预处理随机方差减少，实现更快的大规模统计学习</title>
      <link>https://arxiv.org/abs/2501.15941</link>
      <description><![CDATA[arXiv:2501.15941v1 公告类型：新
摘要：正则化经验风险最小化 (rERM) 在基因组学和广告等数据密集型领域中变得非常重要，其中随机梯度方法通常用于解决最大的问题。然而，病态目标和非平滑正则化器会破坏传统随机梯度方法的性能，导致收敛速度慢和计算成本高。为了应对这些挑战，我们提出了 $\texttt{SAPPHIRE}$（基于 $\textbf{S}$ketching 的 $\textbf{A}$pproximations 用于 $\textbf{P}$roximal $\textbf{P}$reconditioning 和 $\textbf{H}$essian $\textbf{I}$nexactness 以及 Variance-$\textbf{RE}$educed Gradients）算法，该算法集成了基于草图的预处理来解决病态问题，并使用缩放近端映射来最小化非平滑正则化器。这种随机方差减少算法实现了无条件数线性收敛到最优值，为病态复合大规模凸机器学习问题提供了高效且可扩展的解决方案。大量关于套索和逻辑回归的实验表明，$\texttt{SAPPHIRE}$ 的收敛速度通常比其他常见选择（例如 $\texttt{Catalyst}$、$\texttt{SAGA}$ 和 $\texttt{SVRG}$）快 20 倍。即使目标为非凸或预处理器很少更新，这种优势仍然存在，凸显了其稳健性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2501.15941</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>电力市场中可再生能源的价值导向预测协调</title>
      <link>https://arxiv.org/abs/2501.16086</link>
      <description><![CDATA[arXiv:2501.16086v1 公告类型：新
摘要：预测协调被认为是实现一致性和提高预测准确性的有效方法。然而，协调预测在下游决策任务中的价值大多被忽视。在具有异构损失函数的多智能体设置中，这种疏忽可能会导致不公平的结果，从而导致协调过程中的冲突。为了解决这个问题，我们提出了一种以价值为导向的预测协调方法，该方法侧重于单个智能体的预测值。通过使用纳什讨价还价框架来确保公平性。具体来说，我们将这个问题建模为一个合作的讨价还价游戏，其中每个智能体都旨在优化自己的收益，同时为整个协调过程做出贡献。然后，我们提出了一种基于经验风险最小化的参数估计的原始对偶算法。从应用的角度来看，我们考虑一个聚合的风能交易问题，其中利润使用加权分配规则进行分配。我们通过几个数值实验证明了我们方法的有效性，表明它能够持续为所有相关代理带来利润的增加。]]></description>
      <guid>https://arxiv.org/abs/2501.16086</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用分布式能量距离测量机器学习中的异质性</title>
      <link>https://arxiv.org/abs/2501.16174</link>
      <description><![CDATA[arXiv:2501.16174v1 公告类型：新
摘要：在分布式和联合学习中，数据源之间的异质性仍然是有效模型聚合和收敛的主要障碍。我们专注于特征异质性，并引入能量距离作为量化分布差异的敏感度量。虽然我们表明能量距离对于检测数据分布变化非常有效，但它在大型系统中的直接使用成本可能非常高。为了解决这个问题，我们开发了泰勒近似，以保留关键的理论定量特性，同时减少计算开销。通过模拟研究，我们展示了如何准确捕捉特征差异来促进分布式学习的收敛。最后，我们提出了一种能量距离的新应用，以分配惩罚权重以对齐异构节点之间的预测，最终增强联合和分布式环境中的协调。]]></description>
      <guid>https://arxiv.org/abs/2501.16174</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>噪声高斯混合模型中最优自蒸馏的影响</title>
      <link>https://arxiv.org/abs/2501.16226</link>
      <description><![CDATA[arXiv:2501.16226v1 公告类型：新
摘要：自蒸馏 (SD) 是一种模型根据自身预测进行自我改进的技术，作为一种简单而强大的机器学习方法，它引起了人们的关注。尽管它被广泛使用，但其有效性背后的机制仍不清楚。在本研究中，我们利用复制理论研究了超参数调整的多阶段 SD 在具有噪声标记高斯混合数据的二元分类任务中的有效性。我们的研究结果表明，SD 性能改进的主要驱动因素是通过硬伪标签进行去噪，在中等大小的数据集中观察到最显着的收益。我们还证明了实用启发式方法的有效性，例如早期停止以提取有意义的信号和针对不平衡数据的偏差修复。这些结果提供了理论保证和实践见解，促进了我们对 SD 在噪声环境中的理解和应用。]]></description>
      <guid>https://arxiv.org/abs/2501.16226</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>矩阵微积分（用于机器学习及其他领域）</title>
      <link>https://arxiv.org/abs/2501.14787</link>
      <description><![CDATA[arXiv:2501.14787v1 公告类型：交叉 
摘要：本课程面向熟悉初等微积分和线性代数的本科生，介绍了微分学在更一般的向量空间上的函数的扩展，例如以矩阵为输入并返回矩阵逆或因式分解的函数、ODE 解的导数，甚至随机函数的随机导数。它强调实际的计算应用，例如大规模优化和机器学习，其中必须重新想象导数才能通过复杂的计算进行传播。该课程还讨论了导致“伴随”或“反向模式”微分（又名“反向传播”）的效率问题，并简要介绍了现代自动微分 (AD) 技术。]]></description>
      <guid>https://arxiv.org/abs/2501.14787</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有部分区间删失事件发生时间结果的工具变量分析的半参数贝叶斯方法</title>
      <link>https://arxiv.org/abs/2501.14837</link>
      <description><![CDATA[arXiv:2501.14837v1 公告类型：交叉 
摘要：本文开发了一种半参数贝叶斯工具变量分析方法，用于在处理未观察到的混杂因素和测量误差时估计内生变量的因果效应，其中部分间隔删失的事件发生时间数据，其中某些受试者的事件时间是准确观察到的，但其他受试者的事件时间是左删失、右删失或间隔删失的。我们的方法基于两阶段狄利克雷过程混合工具变量 (DPMIV) 模型，该模型使用狄利克雷过程 (DPM) 的双变量高斯混合模型同时对暴露变量的第一阶段随机误差项和事件发生时间结果的第二阶段随机误差项进行建模。 DPM 模型可以广义地理解为具有未指定数量的高斯分量的混合模型，它放宽了正态误差假设并允许由数据确定混合分量的数量。我们为 DPMIV 模型开发了一种针对部分区间删失数据的 MCMC 算法，并进行了广泛的模拟以评估我们的 DPMIV 方法与一些竞争方法相比的性能。我们的模拟表明，我们提出的方法在不同误差分布下都具有稳健性，并且在各种情况下都可以比其参数对应方法具有更好的性能。我们进一步证明了我们的方法在英国生物库数据上的有效性，以研究收缩压对从糖尿病发作到心血管疾病发展时间的因果影响。]]></description>
      <guid>https://arxiv.org/abs/2501.14837</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>