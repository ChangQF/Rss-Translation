<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Mon, 15 Jan 2024 03:14:42 GMT</lastBuildDate>
    <item>
      <title>调解员反馈下的纯粹探索。 （arXiv：2308.15552v2 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2308.15552</link>
      <description><![CDATA[随机多臂老虎机是一个顺序决策框架，
在每个交互步骤中，学习者选择一只手臂并观察
随机奖励。在最佳臂识别 (BAI) 的背景下
问题中，智能体的目标在于找到最优的手臂，即
尽可能准确、高效地获得最高的预期奖励。
尽管如此，经典 BAI 问题的顺序交互协议，
代理可以完全控制每轮被拉动的手臂，
不能有效地模拟几个感兴趣的决策问题（例如，
离策略学习、部分可控环境和人类反馈）。
因此，在这项工作中，我们提出了一种新颖的严格概括
经典的 BAI 问题，我们称之为最佳臂识别问题
调解员的反馈（BAI-MF）。更具体地说，我们考虑以下场景
学习者可以访问一组中介者，每个中介者选择
根据随机且可能未知的方式代表代理人武装
政策。然后，调解员将拉动的手臂传回给代理
以及观察到的奖励。在这种情况下，代理的目标在于
依次选择要查询的中介者以高概率识别
最佳臂同时最小化识别时间，即样本
复杂。为此，我们首先推导并分析一个统计下界
关于我们一般调解员反馈场景特定的样本复杂性。
然后，我们提出了一个顺序决策策略来发现最好的
假设学习者知道调解者的政策。
正如我们的理论所验证的，该算法几乎与下界匹配
肯定并且在期待中。最后，我们将这些结果扩展到以下情况：
对于获得可比结果的学习者来说，中介者的政策是未知的。
]]></description>
      <guid>http://arxiv.org/abs/2308.15552</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:41 GMT</pubDate>
    </item>
    <item>
      <title>关于扩散模型的泛化性质。 （arXiv：2311.01797v3 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2311.01797</link>
      <description><![CDATA[扩散模型是一类生成模型，用于建立
经验观察但未知的目标之间的随机传输图
分布和已知先验。尽管他们在现实世界中取得了非凡的成功
应用程序，对其泛化能力的理论理解
仍然不发达。这项工作开始了全面的理论研究
探索扩散模型的泛化属性。我们建立
泛化差距的理论估计与
基于分数的扩散模型的训练动态，建议多项式
样本大小 $n$ 的泛化误差较小 ($O(n^{-2/5}+m^{-4/5})$)
和模型容量 $m$，避免了维数灾难（即，不是
当提前停止时，数据维度呈指数级增长。此外，我们
将我们的定量分析扩展到依赖数据的场景，其中目标
分布被描述为一系列逐渐增加的密度
增加模式之间的距离。这恰恰说明了不利的情况
基本事实中的“模式转变”对模型泛化的影响。而且，
这些估计不仅是理论构建，而且还被
通过数值模拟证实。我们的研究结果有助于
对扩散模型的泛化特性的严格理解和
提供可以指导实际应用的见解。
]]></description>
      <guid>http://arxiv.org/abs/2311.01797</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:41 GMT</pubDate>
    </item>
    <item>
      <title>将强化学习理论与实践与有效视野联系起来。 （arXiv：2304.09853v3 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2304.09853</link>
      <description><![CDATA[深度强化学习 (RL) 在某些环境中效果令人印象深刻
在其他方面却遭遇灾难性的失败。理想情况下，强化学习理论应该能够提供
了解为什么会这样，即实际预测的界限
表现。不幸的是，目前的理论并不完全具备这种能力。我们
将标准深度 RL 算法与先前的样本复杂度界限进行比较
引入一个新的数据集 BRIDGE。它由来自 155 个确定性 MDP 组成
常见的深度 RL 基准及其相应的表格
表示，这使我们能够准确计算实例相关的边界。
我们选择关注确定性环境，因为它们有很多共同点
随机环境的有趣特性，但更容易分析。
使用 BRIDGE，我们发现先验边界与深度 RL 时的相关性并不好
成功与失败，但发现了一个令人惊讶的特性。当行动
在随机策略下具有最高 Q 值的也具有最高的
最优策略下的 Q 值（即当对
随机策略的 Q 函数），深度强化学习往往会成功；当他们不这样做时，深度强化学习
往往会失败。我们将这个属性概括为一个新的复杂性度量
MDP，我们称之为有效视野，大致相当于多少
MDP 中需要先行搜索步骤来识别
当通过随机推出评估叶节点时，下一个最佳操作。使用
BRIDGE，我们证明基于水平的有效边界更加紧密
反映了 PPO 和 DQN 相对于先前样本的经验表现
四个指标的复杂性界限。我们还发现，与现有的
界限，有效范围可以预测使用奖励塑造的效果
或预先训练的探索策略。我们的代码和数据可在
https://github.com/cassidlaidlaw/ effective-horizo​​n
]]></description>
      <guid>http://arxiv.org/abs/2304.09853</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:40 GMT</pubDate>
    </item>
    <item>
      <title>非线性元学习可以保证更快的速度。 （arXiv：2307.10870v3 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2307.10870</link>
      <description><![CDATA[最近许多关于\emph{元学习}的理论著作旨在实现
保证利用相关任务中的相似表征结构
旨在简化目标任务。重要的是，理论上的主要目标是
主题是了解收敛率的程度
学习一个共同的表示——\emph{可能会随着$N$的数量而变化
任务}（以及每个任务的样本数）。此设置的第一步
当任务之间共享表示时证明此属性，
和特定于任务的回归函数是线性的。这种线性设置很容易
揭示了聚合任务的好处，例如通过平均参数。在
然而，实践中，表示通常是高度非线性的，引入
每项任务中存在的不平凡的偏差不能像在
线性情况。在目前的工作中，我们得出了理论保证
具有非线性表示的元学习。特别是，假设
共享非线性映射到无限维 RKHS，我们证明
可以通过仔细的正则化来减轻额外的偏差
特定于任务的回归函数的平滑度，
]]></description>
      <guid>http://arxiv.org/abs/2307.10870</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:40 GMT</pubDate>
    </item>
    <item>
      <title>论私人学习中训练数据重构的查询复杂度。 （arXiv：2303.16372v6 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2303.16372</link>
      <description><![CDATA[我们分析白盒对手需要向
私人学习者以重建其训练数据。对于 $(\epsilon,
\delta)$ DP 学习者，其训练数据来自任意紧凑度量
空间，我们提供对手查询的\emph{第一个已知下界
复杂性}作为学习者隐私参数的函数。 \emph{我们的
对于每个 $\epsilon \geq 0, \delta \in [0, 1]$，结果都是极小极大最优，
涵盖 $\epsilon$-DP 和 $(0, \delta)$ DP 作为推论}。超出此，
我们获得 $(\alpha, \epsilon)$ R\&#39;enyi DP 的查询复杂度下界
对任何 $\alpha &gt; 有效的学习者1、\epsilon\geq 0$。最后，我们
通过以下方法分析对局部紧凑度量空间的数据重建攻击
Metric DP 的框架，DP 的概括，说明了底层
数据的度量结构。在此设置中，我们提供了第一个已知的
无界、高维空间中的数据重建分析
获得接近紧模对数的查询复杂度下界
因素。
]]></description>
      <guid>http://arxiv.org/abs/2303.16372</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:39 GMT</pubDate>
    </item>
    <item>
      <title>OKRidge：可扩展的最优 k-稀疏岭回归。 （arXiv：2304.06686v3 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2304.06686</link>
      <description><![CDATA[我们考虑科学发现中的一个重要问题，即识别
非线性动力系统的稀疏控制方程。这涉及到
解决稀疏岭回归问题以证明最优性，以便
确定哪些项驱动潜在的动态。我们建议快速
算法 OKRidge，用于稀疏岭回归，使用新颖的下界
计算首先涉及鞍点公式，然后从那里，
求解 (i) 线性系统或 (ii) 使用基于 ADMM 的方法，其中
可以通过求解另一个线性算子来有效地评估近端算子
系统和等渗回归问题。我们还提出了一种方法
热启动我们的求解器，它利用波束搜索。通过实验，我们的
方法达到可证明的最优性，运行时间为数量级
比商业化解决的现有 MIP 配方更快
求解器古罗比。
]]></description>
      <guid>http://arxiv.org/abs/2304.06686</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:39 GMT</pubDate>
    </item>
    <item>
      <title>利用内核 Stein 差异控制力矩。 （arXiv：2211.05408v3 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2211.05408</link>
      <description><![CDATA[核斯坦因差异 (KSD) 衡量分布的质量
近似值，即使目标密度具有
棘手的归一化常数。值得注意的应用包括诊断
近似 MCMC 采样器和非标准化的拟合优度检验
统计模型。目前的工作分析了收敛控制
KSD 的属性。我们首先展示用于弱收敛的标准 KSD
控制无法控制矩收敛。为了解决这个限制，我们接下来
为替代扩散 KSD 的控制提供充分的条件
矩收敛和弱收敛。作为直接的结果，我们开发了，
每个 $q &gt; 0$，第一个已知准确表征 $q$ 的 KSD -Wasserstein
收敛。
]]></description>
      <guid>http://arxiv.org/abs/2211.05408</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>具有分数匹配的产品 Jacobi-Theta Boltzmann 机。 （arXiv：2303.05910v2 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2303.05910</link>
      <description><![CDATA[概率密度函数的估计是一项不平凡的任务
在过去的几年里，这个问题一直是通过机器学习技术来解决的。
使用受玻尔兹曼启发的模型可以获得成功的应用
机器（BM）架构。在这份手稿中，产品雅可比-西塔
玻尔兹曼机（pJTBM）作为玻尔兹曼机的受限版本引入
具有对角隐扇区连接的黎曼-Theta 玻尔兹曼机 (RTBM)
矩阵。我们证明，基于费舍尔散度的分数匹配可以是
用于拟合概率密度时，pJTBM 比使用 pJTBM 更有效
原始 RTBM。
]]></description>
      <guid>http://arxiv.org/abs/2303.05910</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>岭函数估计良性过拟合现象的有限样本分析。 （arXiv：2007.12882v5 [stat.ML] 更新）</title>
      <link>http://arxiv.org/abs/2007.12882</link>
      <description><![CDATA[最近在大规模机器学习方面进行了大量的数值实验
允许揭示一个相当违反直觉的相变，作为
样本量与模型中参数数量之间的比率。作为
参数数量 $p$ 接近样本大小 $n$，泛化
误差增加，但令人惊讶的是，超过
阈值$p=n$。这一现象，带到了理论界
\cite{belkin2019reconciling} 中的注意力已被彻底调查
最近，更具体地针对比深度神经网络更简单的模型，例如
当参数被取为最小范数解时的线性模型
最小二乘问题，首先在渐进状态下，当 $p$ 和 $n$
趋于无穷大，参见例如\cite{hastie2019surprises}，最近在
有限维体系，更具体地说，对于线性模型
\cite{bartlett2020benign}, \cite{tsigler2020benign},
\引用{lecue2022几何}。在本文中，我们提出了有限样本
分析 \textit{ridge} 类型的非线性模型，我们研究了
\textit{过度参数化制度}的双下降现象
\textit{估计问题}和\textit{预测}问题。我们的成果
提供最佳估计器与真实估计器的距离的精确分析
参数以及泛化界限，它补充了最近的工作
\cite{bartlett2020benign} 和 \cite{chinot2020benign}。我们的分析基于
与连续牛顿法密切相关的工具
\cite{neuberger2007连续} 以及对
预测最小 $\ell_2$-norm 解的性能。
]]></description>
      <guid>http://arxiv.org/abs/2007.12882</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>EC-NAS：用于神经架构搜索的能耗感知表格基准。 （arXiv：2210.06015v3 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2210.06015</link>
      <description><![CDATA[深度选择、培训和部署的能源消耗
学习模型最近出现了显着上升。这项工作的目的是
促进节能深度学习模型的设计，这些模型需要
减少计算资源并优先考虑环境可持续性
聚焦能源消耗。神经架构搜索 (NAS) 的优势
来自表格基准，该基准通过以下方式经济有效地评估 NAS 策略
预先计算的性能统计数据。我们提倡将能源效率纳入其中
作为 NAS 中的附加性能标准。为此，我们引入一个
增强的表格基准包含各种能源消耗数据
架构。该基准被指定为 EC-NAS，已在
一种开源格式，用于推进节能 NAS 的研究。 EC-NAS
结合了替代模型来预测能源消耗，有助于
减少数据集创建的能源消耗。我们的发现
通过利用多目标优化强调 EC-NAS 的潜力
算法，揭示能源使用和准确性之间的平衡。这
表明了识别能源消耗架构的可行性
或不影响性能。
]]></description>
      <guid>http://arxiv.org/abs/2210.06015</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>在高维设置中，通过未观察到的混杂进行有效的因果推断。 （arXiv：2401.06564v1 [stat.ME]）</title>
      <link>http://arxiv.org/abs/2401.06564</link>
      <description><![CDATA[最近提出了各种方法来估计因果效应
在一组数据生成中一致有效的置信区间
当高维干扰模型估计时的过程
模型选择后或机器学习估计器。这些方法通常
要求观察所有混杂因素以确保识别
影响。我们通过展示半参数推理的有效性来做出贡献
在存在未观察到的混杂因素和高维的情况下获得
令人讨厌的模型。我们提出了允许未观察到的不确定性区间
混淆，并表明当数量
相对于样本量而言，未观察到的混杂因素很小；后者是
以收敛速度形式化。模拟实验说明了
所建议区间的有限样本属性并研究
提高区间经验覆盖率的替代程序
当未观察到的混杂量很大时。最后，一个案例研究
用怀孕期间吸烟对出生体重的影响来说明
使用所介绍的方法进行敏感性分析
未观察到的混杂。
]]></description>
      <guid>http://arxiv.org/abs/2401.06564</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>噪声自适应（加速）随机重球动量。 （arXiv：2401.06738v1 [数学.OC]）</title>
      <link>http://arxiv.org/abs/2401.06738</link>
      <description><![CDATA[我们分析了随机重球（SHB）动量的收敛性
光滑、强凸的设置。基达比等人。 （2018）表明 SHB（与
小批量）即使对于
二次方程，并推测 SHB 的实际增益是
小批量。我们通过证明 SHB 可以获得
当小批量大小大于某个阈值时加速速率。在
特别是，对于条件数 $\kappa$ 的强凸二次方程，我们
证明具有标准步长和动量参数的 SHB 会导致
$O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ 收敛速度，
其中$T$是迭代次数，$\sigma^2$是方差
随机梯度。为了确保收敛到最小化，我们提出了
多阶段方法可产生噪声自适应
$O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$
速度。对于一般的强凸函数，我们使用平均
SHB 的解释以及指数步长来证明
$O\left(\exp\left(-\frac{T}{\kappa} \right) + \frac{\sigma^2}{T} \right)$
以噪声自适应方式收敛到最小化器。最后，我们
实证证明了所提出算法的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2401.06738</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>使用噪声数据进行多保真代理建模的综合框架：灰盒视角。 （arXiv：2401.06447v1 [stat.ME]）</title>
      <link>http://arxiv.org/abs/2401.06447</link>
      <description><![CDATA[计算机模拟（又名白盒模型）比
曾经对复杂的工程系统进行建模。然而，计算模型
独自一人往往无法完全捕捉现实的复杂性。当身体
虽然实验是可以进行的，但增强不完整的实验是很有趣的
计算模型提供的信息。关注灰盒建模
合并来自数据驱动（又名黑匣子）的信息的问题
模型和白盒（即基于物理的）模型。在本文中，我们建议
通过使用多保真代理模型 (MFSM) 来执行此任务。 MFSM
将来自具有不同计算保真度的模型的信息集成到
新的代理模型。我们提出的多保真度代理建模框架
处理受噪声污染的数据并能够估计潜在的
无噪音高保真功能。我们的方法论强调交付
对其预测中的不确定性进行精确估计，其形式为
置信度和预测区间，通过定量结合
影响问题的不同类型的不确定性，源于
测量噪声和由于实验有限而缺乏知识
高保真度和低保真度模型的设计预算。应用于灰盒
建模时，我们的 MFSM 框架将噪声实验数据视为
高保真度和白盒计算模型作为低保真度
同行。我们方法的有效性通过以下方式展示
综合示例和风力涡轮机应用。
]]></description>
      <guid>http://arxiv.org/abs/2401.06447</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>促进因果累加模型。 （arXiv：2401.06523v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.06523</link>
      <description><![CDATA[我们提出了一种基于提升的方法来学习加性结构方程
来自观测数据的模型 (SEM)，重点关注理论方面
确定变量之间的因果顺序。我们介绍一个分数家族
基于任意回归技术的函数，为此我们建立
始终有利于真正因果顺序的必要条件。我们的
分析表明，提早停止的提升符合这些标准，并且
因此为因果排序提供了一致的评分函数。为了解决
面对高维数据集带来的挑战，我们通过以下方式调整我们的方法：
加法 SEM 空间中的分量梯度下降。我们的模拟
研究强调了我们对于较低维度的理论结果并证明了
我们的高维适应能力与最先进的技术具有竞争力
方法。此外，它在选择方面表现出稳健性
超参数使过程易于调整。
]]></description>
      <guid>http://arxiv.org/abs/2401.06523</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>通过基于扩散的蒙特卡罗，无需等周法即可实现更快的采样。 （arXiv：2401.06325v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.06325</link>
      <description><![CDATA[从超出范围的一般目标分布 $p_*\propto e^{-f_*}$ 中进行采样
等周条件，Huang 等人。 （2023）建议进行抽样
通过反向扩散，产生了基于扩散的蒙特卡罗（DMC）。
具体来说，DMC 遵循扩散过程的逆 SDE，即
利用 a 将目标分布转换为标准高斯分布
非参数分数估计。然而，原始的DMC算法
遇到高梯度复杂度，导致指数依赖
所获得样本的误差容限$\epsilon$。在本文中，我们
证明DMC的高复杂性源于其冗余
设计了分数估计，并提出了一种更有效的算法，称为
RS-DMC，基于一种新颖的递归分数估计方法。特别是，我们
首先将整个扩散过程分为多个段，然后
将分数估计步骤（在任何时间步骤）表示为一系列
相应地相互关联的均值估计和采样子问题，它们是
以递归方式相关。重要的是，我们表明，通过适当的
分段分解的设计，所有采样子问题只需要
解决强对数凹分布，这可以非常有效地
使用基于 Langevin 的采样器进行求解，其收敛速度很快。
结果，我们证明了RS-DMC的梯度复杂度只有
对 $\epsilon$ 的拟多项式依赖，显着改善
Huang 等人的指数梯度复杂性。 （2023）。此外，根据
常用的耗散条件，我们的算法被证明要快得多
比流行的基于 Langevin 的算法。我们的算法设计和
理论框架阐明了解决采样问题的新方向
问题，这些问题可能在社区中具有更广泛的适用性。
]]></description>
      <guid>http://arxiv.org/abs/2401.06325</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:34 GMT</pubDate>
    </item>
    </channel>
</rss>