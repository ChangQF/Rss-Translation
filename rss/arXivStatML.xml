<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 10 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>自然实验的基准估计量：一种新的数据集和一种双重稳健算法</title>
      <link>https://arxiv.org/abs/2409.04500</link>
      <description><![CDATA[arXiv:2409.04500v1 公告类型：新
摘要：从自然实验中估计治疗效果（其中治疗是预先分配的）是一个重要且研究充分的问题。我们介绍了一个从早期儿童识字非营利组织获得的新型自然实验数据集。令人惊讶的是，将 20 多个已建立的估计量应用于数据集会在评估非营利组织的功效时产生不一致的结果。为了解决这个问题，我们创建了一个基准，使用合成结果来评估估计量的准确性，其设计由领域专家指导。该基准广泛探索了现实世界条件（如样本量、治疗相关性和倾向得分准确性）变化时的性能。根据我们的基准，我们观察到基于简单直观的回归调整的双稳健治疗效果估计量类通常比其他更复杂的估计量高出几个数量级。为了更好地支持我们对双重稳健估计量的理论理解，我们推导出任何此类估计量的方差的闭式表达式，该表达式使用数据集拆分来获得无偏估计。该表达式启发我们设计一种新的双重稳健估计量，该估计量在拟合回归调整函数时使用一种新的损失函数。我们在 Python 包中发布了数据集和基准；该包以模块化方式构建，以方便使用新的数据集和估计量。]]></description>
      <guid>https://arxiv.org/abs/2409.04500</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非平稳设置的滑动窗口汤普森抽样</title>
      <link>https://arxiv.org/abs/2409.05181</link>
      <description><![CDATA[arXiv:2409.05181v1 公告类型：新
摘要：$\textit{Restless Bandits}$ 描述了连续决策问题，其中奖励随时间变化，与决策者采取的行动无关。事实证明，当底层环境发生变化时，经典的 Bandit 算法会失效，这清楚地表明，为了应对更具挑战性的场景，需要专门设计的算法。在本文中，我们扩展和修正了 \cite{trovo2020sliding} 的工作，分析了两种受 Thompson-Sampling 启发的算法，即 $\texttt{BETA-SWTS}$ 和 $\texttt{$\gamma$-SWGTS}$，这些算法是为了应对设置的非平稳性质所带来的额外复杂性而引入的；具体来说，我们推导出在伯努利和亚高斯奖励的任意不稳定环境中遗憾的一般公式，并且通过引入新的量，我们深入研究了哪些贡献为算法的错误奠定了更深层次的基础。最后，我们从一般公式中推断出两种最常见的非平稳设置的遗憾：突然变化的环境和平稳变化的环境。]]></description>
      <guid>https://arxiv.org/abs/2409.05181</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过锚定集成为贝叶斯神经网络提供功能先验，助力力学替代模型应用</title>
      <link>https://arxiv.org/abs/2409.05234</link>
      <description><![CDATA[arXiv:2409.05234v1 公告类型：新
摘要：近年来，神经网络 (NN) 在力学和材料建模应用中的替代建模任务中越来越受欢迎。虽然传统的 NN 是确定性函数，仅依靠数据来学习输入-输出映射，但在贝叶斯框架内进行 NN 训练可以量化不确定性，特别是由于缺乏训练数据而产生的认知不确定性，并通过贝叶斯先验整合先验知识。然而，NN 参数空间的高维性和非物理性，以及参数（NN 权重）和预测输出之间的复杂关系，使得先验设计和后验推理都具有挑战性。在这项工作中，我们提出了一种基于锚定集成的新型 BNN 训练方案，它可以整合函数空间中可用的先验信息，例如来自低保真模型。锚定方案利用了从预训练到函数先验实现过程中学习到的 NN 参数之间的低秩相关性。我们还进行了一项研究，以证明 NN 权重之间的相关性（在现有的 BNN 实现中经常被忽略）对于在函数空间和参数空间先验之间适当地传递知识至关重要。首先在一个小的 1D 示例上研究了我们新颖的 BNN 算法的性能，以说明该算法在插值和外推设置中的行为。然后，对多输入输出材料替代模型示例进行了全面评估，其中我们展示了该算法在分布内和分布外数据的不确定性估计的准确性和质量方面的能力。]]></description>
      <guid>https://arxiv.org/abs/2409.05234</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>群体成员规范错误下的稳健非自适应群体测试</title>
      <link>https://arxiv.org/abs/2409.05345</link>
      <description><![CDATA[arXiv:2409.05345v1 公告类型：新摘要：给定 $p$ 个样本，每个样本可能有缺陷也可能没有缺陷，组测试 (GT) 旨在通过对 $n &lt; p$ 个“组”进行测试来确定它们的缺陷状态，其中通过混合 $p$ 个样本的子集形成一个组。假设缺陷样本的数量与 $p$ 相比非常小，即使只有少量组，GT 算法也可以出色地恢复所有 $p$ 个样本的状态。然而，大多数现有方法都假设组成员身份是准确指定的。由于各种资源限制，此假设可能并非在所有应用中都正确。例如，当技术人员在实验室中准备组时，不知不觉地将与指定值不同的样本子集混合在一起时，可能会发生此类错误。我们开发了一种新的 GT 方法，即去偏稳健套索测试方法 (DRLT)，它可以处理此类组成员身份规范错误。所提出的 DRLT 方法基于一种消除偏差的方法，即减少 Lasso（一种流行且有效的稀疏回归技术）产生的估计中的固有偏差。我们还提供了我们的估计器产生的重建误差的理论上限。然后，我们的方法与两个精心设计的假设检验相结合，分别用于 (i) 在组成员资格规范存在错误的情况下识别有缺陷的样本，以及 (ii) 识别具有错误成员资格规范的组。DRLT 方法扩展了有关 LASSO 等统计估计器偏差缓解的文献，以处理由于组成员资格规范错误等因素导致某些测量值包含异常值的重要情况。我们给出的数值结果表明，我们的方法在识别有缺陷的样本以及错误指定的组方面优于几种基线和稳健回归技术。]]></description>
      <guid>https://arxiv.org/abs/2409.05345</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>递归嵌套过滤以实现高效摊销贝叶斯实验设计</title>
      <link>https://arxiv.org/abs/2409.05354</link>
      <description><![CDATA[arXiv:2409.05354v1 公告类型：新
摘要：本文介绍了由内而外嵌套粒子滤波器 (IO-NPF)，这是一种用于非交换设置中摊销顺序贝叶斯实验设计的新型、完全递归算法。我们将策略优化定义为非马尔可夫状态空间模型中的最大似然估计，在实验次数上实现（最多）$\mathcal{O}(T^2)$ 计算复杂度。我们提供理论上的收敛保证，并引入一种向后采样算法来减少轨迹退化。IO-NPF 为顺序贝叶斯实验设计提供了一种实用、可扩展且可证明一致的方法，与现有方法相比，其效率更高。]]></description>
      <guid>https://arxiv.org/abs/2409.05354</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>循环神经网络的近似界限及其在回归中的应用</title>
      <link>https://arxiv.org/abs/2409.05577</link>
      <description><![CDATA[arXiv:2409.05577v1 公告类型：新
摘要：我们研究深度 ReLU 循环神经网络 (RNN) 的近似能力，并探索使用 RNN 的非参数最小二乘回归的收敛特性。我们推导出 RNN 对 H\&quot;older 平滑函数的近似误差的上限，即 RNN 在每个时间步长的输出可以近似仅依赖于过去和当前信息的 H\&quot;older 函数，称为过去相关函数。这使得精心构建的 RNN 能够同时近似一系列过去相关的 H\&quot;older 函数。我们应用这些近似结果来推导出回归问题中经验风险最小化器的预测误差的非渐近上限。我们的误差界限在指数 $\beta$ 混合和 i.i.d. 数据假设下都实现了极小极大最优速率，从而改进了现有的假设。我们的结果为 RNN 的性能提供了统计保证。]]></description>
      <guid>https://arxiv.org/abs/2409.05577</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>何时重采样/重新加权可以改善不平衡分类中的特征学习？：一项玩具模型研究</title>
      <link>https://arxiv.org/abs/2409.05598</link>
      <description><![CDATA[arXiv:2409.05598v1 公告类型：新
摘要：研究了一个二分类的玩具模型，目的是阐明在存在类别不平衡的情况下，类别重采样/重新加权对特征学习性能的影响。在分析中，对特征取高维极限，同时保持数据集大小与特征维数的比率有限，并采用统计力学中的非严格复制方法。结果表明，存在一种情况，即无论选择损失或分类器如何，无重采样/重新加权情况都能提供最佳的特征学习性能，支持了 Cao 等人（2019 年）；Kang 等人（2019 年）的最新发现。还揭示了结果的关键是损失和问题设置的对称性。受此启发，我们提出了一个进一步简化的模型，该模型对多类设置表现出相同的属性。这些阐明了在分类不平衡的情况下类别重采样/重新加权何时变得有效。]]></description>
      <guid>https://arxiv.org/abs/2409.05598</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用朴素贝叶斯进行分类的最佳投影</title>
      <link>https://arxiv.org/abs/2409.05635</link>
      <description><![CDATA[arXiv:2409.05635v1 公告类型：新
摘要：在朴素贝叶斯分类模型中，类条件密度被估计为其沿基本基础方向的边际密度的乘积。我们研究获取此分解的替代基础的问题，目的是增强相关分类模型的判别能力。我们将问题表述为投影追踪，以找到执行分类的最佳线性投影。最优性是根据多项式似然来确定的，其中使用投影数据的朴素贝叶斯分解来估计概率。投影追踪提供了降维和可视化的额外好处。我们讨论了与类条件独立成分分析的直观联系，并展示了如何在实际应用中直观地实现这一点。使用大量（162）公开可用的基准数据集并与相关替代方案进行比较来研究所得分类模型的性能。我们发现，所提出的方法大大优于其他流行的概率判别分析模型，并且与支持向量机具有很强的竞争力。]]></description>
      <guid>https://arxiv.org/abs/2409.05635</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于 CATE 估计的 K 倍因果 BART</title>
      <link>https://arxiv.org/abs/2409.05665</link>
      <description><![CDATA[arXiv:2409.05665v1 公告类型：新
摘要：本研究旨在提出和评估一种名为 K 重因果贝叶斯加性回归树 (K 重因果 BART) 的新模型，以改进对平均治疗效果 (ATE) 和条件平均治疗效果 (CATE) 的估计。该研究采用合成和半合成数据集，包括广受认可的婴儿健康和发展计划 (IHDP) 基准数据集，来验证模型的性能。尽管在合成场景中取得了有希望的结果，但 IHDP 数据集表明，所提出的模型并不是 ATE 和 CATE 估计的最新模型。尽管如此，该研究还是提供了一些新颖的见解：1. ps-BART 模型可能是 CATE 和 ATE 估计的首选，因为与其他基准模型（包括贝叶斯因果森林 (BCF) 模型）相比，它具有更好的泛化能力，许多人认为它是当前最好的 CATE 估计模型；2. 随着治疗效果异质性的增加，BCF 模型的性能会显着下降，而 ps-BART 模型仍然保持稳健；3. 当治疗效果异质性较低时，模型往往对 CATE 不确定性量化过于自信；4. 第二种 K-Fold 方法是不必要的，因为它会增加计算成本而不会提高性能；5. 详细分析揭示了理解数据集特征和使用细致入微的评估方法的重要性；6. Curth 等人 (2021) 的结论是，对于 IHDP 数据集，间接策略对 CATE 估计更胜一筹，这与本研究的结果相矛盾。这些发现对现有的假设提出了挑战，并为未来研究增强因果推理方法指明了方向。]]></description>
      <guid>https://arxiv.org/abs/2409.05665</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士总是会产生幻觉，我们必须接受这一点</title>
      <link>https://arxiv.org/abs/2409.05746</link>
      <description><![CDATA[arXiv:2409.05746v1 公告类型：新
摘要：随着大型语言模型在各个领域变得越来越普遍，批判性地检查其固有的局限性变得非常重要。这项工作认为，语言模型中的幻觉不仅仅是偶尔的错误，而是这些系统的必然特征。我们证明幻觉源于 LLM 的基本数学和逻辑结构。因此，不可能通过架构改进、数据集增强或事实核查机制来消除它们。我们的分析借鉴了计算理论和哥德尔第一不完全性定理，该定理引用了停机、空虚和接受问题等问题的不可判定性。我们证明 LLM 过程的每个阶段 - 从训练数据汇编到事实检索、意图分类和文本生成 - 都会有产生幻觉的非零概率。这项工作引入了结构幻觉的概念作为这些系统的内在性质。通过建立幻觉的数学确定性，我们对幻觉可以完全缓解的流行观念提出了挑战。]]></description>
      <guid>https://arxiv.org/abs/2409.05746</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>绝对排名：基准优化算法的基本规范化</title>
      <link>https://arxiv.org/abs/2409.04479</link>
      <description><![CDATA[arXiv:2409.04479v1 公告类型：交叉 
摘要：由于涉及的数值尺度的多样性，评估许多问题上优化算法的性能是一项复杂的挑战。传统的数据处理方法，例如假设检验和贝叶斯推理，通常采用基于排名的方法来规范这些不同尺度上的性能值。然而，这种基于排名的方法出现了一个重大问题：新算法的引入可能会破坏原始排名。本文广泛探讨了这个问题，提出了一个令人信服的案例来强调这个问题，并对其根本原因进行了彻底的分析。这些努力为全面研究潜在解决方案铺平了道路。在此研究的基础上，本文介绍了一种称为“绝对排名”的新数学模型和一种基于抽样的计算方法。这些贡献附带了实用的实施建议，旨在提供一个更强大的框架来应对跨多种算法和问题的性能评估中数值尺度变化的挑战。]]></description>
      <guid>https://arxiv.org/abs/2409.04479</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用高斯过程进行算子学习</title>
      <link>https://arxiv.org/abs/2409.04538</link>
      <description><![CDATA[arXiv:2409.04538v1 公告类型：交叉 
摘要：算子学习专注于近似函数无限维空间之间的映射 $\mathcal{G}^\dagger:\mathcal{U} \rightarrow\mathcal{V}$，例如 $u:\Omega_u\rightarrow\mathbb{R}$ 和 $v:\Omega_v\rightarrow\mathbb{R}$。这使得它特别适合求解参数非线性偏微分方程 (PDE)。虽然大多数用于算子学习的机器学习方法依赖于深度神经网络 (NN) 的变体，但最近的研究表明，高斯过程 (GP) 在提供可解释性和理论保证的同时也具有竞争力。在本文中，我们介绍了一种基于 GP/NN 的混合算子学习框架，该框架充分利用了两种方法的优势。我们不是近似函数值算子 $\mathcal{G}^\dagger$，而是使用 GP 来近似其相关的实值双线性形式 $\widetilde{\mathcal{G}}^\dagger:\mathcal{U}\times\mathcal{V}^*\rightarrow\mathbb{R}.$。该双线性形式定义为 $\widetilde{\mathcal{G}}^\dagger(u,\varphi) := [\varphi,\mathcal{G}^\dagger(u)],$，这使我们能够通过 $\mathcal{G}^\dagger(u)(y)=\widetilde{\mathcal{G}}^\dagger(u,\delta_y)$ 恢复算子 $\mathcal{G}^\dagger$。GP 均值函数可以为零，也可以由神经算子参数化，对于每种设置，我们都开发了一种基于最大似然估计的稳健训练机制（MLE）可以选择性地利用所涉及的物理原理。数值基准测试表明：（1）它通过将基础神经算子用作 GP 的均值函数来提高基础神经算子的性能，（2）它使零样本数据驱动模型能够在没有事先训练的情况下进行准确预测。我们的框架还可以处理多输出算子，其中 $\mathcal{G}^\dagger:\mathcal{U} \rightarrow\prod_{s=1}^S\mathcal{V}^s$，并通过乘积核结构和 Kronecker 乘积矩阵表示受益于计算加速。]]></description>
      <guid>https://arxiv.org/abs/2409.04538</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有恒定步长的不安分匪徒的削减指数学习算法</title>
      <link>https://arxiv.org/abs/2409.04605</link>
      <description><![CDATA[arXiv:2409.04605v1 公告类型：交叉 
摘要：我们研究了多臂老虎机的 Whittle 指标学习算法。我们考虑使用 Q 学习的指标学习算法。我们首先介绍具有探索策略的 Q 学习算法——具有恒定步长的 epsilon-greedy、softmax、epsilon-softmax。我们将 Q 学习的研究扩展到单臂老虎机的指标学习。指标学习算法是随机近似的双时间尺度变体，在较慢的时间尺度上我们更新指标学习方案，在较快的时间尺度上我们假设固定指标值更新 Q 学习。在 Q 学习中，更新是异步方式。我们研究恒定步长的双时间尺度随机近似算法。我们对具有恒定步长的指标学习的双时间尺度随机近似进行了分析。此外，我们介绍了使用深度 Q 网络 (DQN) 学习的索引学习和使用状态聚合方法的线性函数逼近的研究。我们使用数值示例描述了我们算法的性能。我们已经证明使用 Q 学习、DQN 和函数逼近的索引学习可以学习 Whittle 指数。]]></description>
      <guid>https://arxiv.org/abs/2409.04605</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>采样高斯机制注释</title>
      <link>https://arxiv.org/abs/2409.04636</link>
      <description><![CDATA[arXiv:2409.04636v1 公告类型：交叉 
摘要：在这些笔记中，我们证明了 R\&quot;ais\&quot;a, O. 等人在论文中提出的最新猜想。[子采样不是魔法：为什么大批量适用于差异隐私随机优化 (2024)]。论文的定理 6.2 断言，对于采样高斯机制（子采样和加性高斯噪声的组合），有效噪声水平 $\sigma_{\text{eff}} = \frac{\sigma(q)}{q}$ 随子采样率 $q$ 而减小。因此，为了更好地权衡隐私效用，最好使用更大的子采样率。我们的笔记提供了猜想 6.3 的严格证明，该猜想在原始论文中未得到解决，从而完成了定理 6.2 的证明。]]></description>
      <guid>https://arxiv.org/abs/2409.04636</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在 Transformer 中存在统计偏差的情况下，泛化与记忆</title>
      <link>https://arxiv.org/abs/2409.04654</link>
      <description><![CDATA[arXiv:2409.04654v1 公告类型：交叉 
摘要：本研究旨在了解统计偏差如何影响模型在算法任务中推广到分布内和分布外数据的能力。先前的研究表明，Transformer 可能会无意中学会依赖这些虚假相关性，从而高估其泛化能力。为了研究这一点，我们在几个合成算法任务上评估了 Transformer 模型，系统地引入和改变这些偏差的存在。我们还分析了 Transformer 模型的不同组件如何影响其泛化。我们的研究结果表明，统计偏差会损害模型在分布外数据上的性能，从而高估其泛化能力。这些模型在推理方面严重依赖这些虚假相关性，正如它们在包括此类偏差的任务上的表现所表明的那样。]]></description>
      <guid>https://arxiv.org/abs/2409.04654</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>