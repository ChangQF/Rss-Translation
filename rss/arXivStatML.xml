<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Tue, 25 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>从广义线性测量中精确恢复稀疏的二进制向量</title>
      <link>https://arxiv.org/abs/2502.16008</link>
      <description><![CDATA[ARXIV：2502.16008V1公告类型：新 
摘要：我们考虑了从广义线性测量值（例如逻辑回归）中精确恢复的问题。我们分析了线性估计算法（Plan，Vershynin，Yudovina，2017年），并在所需测量的数量上显示信息理论下限。由于我们的结果，对于嘈杂的一个位量化的线性测量（$ \ mathsf {1bcsbinary} $），我们获得了$ o（（（k+\ sigma^2）\ log {n}）的样本复杂性，哪里\ sigma^2 $是噪声方差。由于信息理论下限，这表明这是最佳的。我们还获得了逻辑回归的严格样本复杂性表征。
  由于$ \ mathsf {1bcsbinary} $比嘈杂的线性测量值（$ \ mathsf {sparselinearreg} $）要严格困难，因此由于增加了量化，因此对于$ \ mathsf {sparselinearreg} $而言，相同的样本复杂性是可以实现的。虽然可以通过流行的套索算法获得该样品复杂性，但线性估计在计算上更有效。对于$ \ mathsf {sparselinearreg} $的任何一组测量值，我们的下限均具有（相似的界限以高斯测量矩阵而闻名），并且与最大可能的上界紧密匹配。对于$ \ mathsf {sparselinearreg} $，它是在Gamarnik和Zadik中推测的，2017年，存在统计计算差距，测量的数量至少应为$（2K+\ sigma^2）有效算法存在。值得注意的是，我们的结果表明，$ \ mathsf {1bcsbinary} $和逻辑回归没有这种统计计算差距。]]></description>
      <guid>https://arxiv.org/abs/2502.16008</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果决策的评论</title>
      <link>https://arxiv.org/abs/2502.16156</link>
      <description><![CDATA[ARXIV：2502.16156V1公告类型：新 
摘要：为了做出有效的决定，重要的是要对行动，环境和结果之间的因果关系有透彻的理解。这篇综述旨在通过因果关系来阐明决策的三个关键方面：1）通过因果结构学习发现因果关系，2）通过因果效应学习理解这些关系的影响； 3）应用从中获得的知识。通过因果政策学习来支持决策的前两个方面。此外，我们确定了阻碍因果决策更广泛利用的挑战，并讨论了克服这些挑战的最新进展。最后，我们提供了未来的研究方向，以应对这些挑战，并进一步增强实践中因果决策的实施，并根据拟议的因果决策提出了现实世界中的应用程序。我们旨在通过将该领域的各种方法合并为基于Python的集合来提供全面的方法和实践实施框架。 URL：https：//causaldm.github.io/causal-decision-making。]]></description>
      <guid>https://arxiv.org/abs/2502.16156</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强学习的统计推论：选择性调查</title>
      <link>https://arxiv.org/abs/2502.16195</link>
      <description><![CDATA[Arxiv：2502.16195V1公告类型：新 
摘要：强化学习（RL）关注的是情报剂如何在给定环境中采取行动以最大程度地提高他们获得的累积奖励。在医疗保健中，应用RL算法可以帮助患者改善其健康状况。在共享平台中，应用RL算法可以提高驾驶员的收入和客户满意度。在过去的十年中，RL可以说是机器学习中最活跃的研究前沿之一。尽管如此，与计算机科学相反，统计学作为一个领域，直到最近才开始在深度和广度上与RL互动。本文对RL的统计推断工具进行了选择性的综述，涵盖了假设测试和置信区间的构建。我们的目标是突出RL对RL的统计推断对统计和机器学习社区的价值，并在这个充满活力的研究领域中促进更广泛的经典统计推断工具的应用。]]></description>
      <guid>https://arxiv.org/abs/2502.16195</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>纠正条件覆盖范围的纠正合格分数</title>
      <link>https://arxiv.org/abs/2502.16336</link>
      <description><![CDATA[ARXIV：2502.16336V1公告类型：新 
摘要：我们提出了一种新方法，用于在拆分保形预测框架内产生置信度集。我们的方法对任何给定的合格分数进行了可训练的转换，以提高条件覆盖范围，同时确保确切的边际覆盖范围。转换基于对条件分位数分数的估计。所得的方法对于在标准的保形分位数回归方法的适用性有限的多输出问题中构建自适应置信度特别有益。我们开发了一种理论结合，该结合捕获了分位数估计的准确性对近似条件有效性的影响，这与仅提供边际覆盖率的共形预测方法的经典界限不同。我们从实验上表明，我们的方法对局部数据结构具有很高的适应性，并且在条件覆盖范围内优于现有方法，从而提高了各种应用中统计推断的可靠性。]]></description>
      <guid>https://arxiv.org/abs/2502.16336</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Winsorized PCA中的子空间恢复：对准确性和鲁棒性的见解</title>
      <link>https://arxiv.org/abs/2502.16391</link>
      <description><![CDATA[ARXIV：2502.16391V1公告类型：新 
摘要：在本文中，我们利用通用数据转换技术探索了使用Winsorized主体组件分析（WPCA）探索子空间恢复的理论属性，该技术可以限制极端值来减轻异常值的影响。尽管在多元分析的各种任务中广泛使用了Winsorization，但其理论属性，尤其是用于子空间恢复的理论属性，已受到有限的关注。我们提供了WPCA准确性的详细分析，表明增加样品数量的同时减少异常值的比例可以保证WPCA从WPCA相对于真实种群子空间的样本子空间的一致性。此外，我们建立了扰动界限，以确保从受污染数据获得的WPCA子空间保持接近从纯数据中恢复的子空间。此外，我们将分解点的经典概念扩展到子空间值统计数据，并得出WPCA分解点的下限。我们的分析表明，WPCA对异常值表现出强大的鲁棒性，同时在轻度假设下保持一致性。提供了一个玩具示例来数字说明扰动范围和崩溃点的上限的行为，从而强调了Winsorization在子空间恢复中的实用程序。]]></description>
      <guid>https://arxiv.org/abs/2502.16391</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一致评分功能中预测和实现的转换</title>
      <link>https://arxiv.org/abs/2502.16542</link>
      <description><![CDATA[ARXIV：2502.16542V1公告类型：新 
摘要：通过转换（严格）一致的评分函数的实现和预测变量构建的评分函数已在经验上进行了广泛研究，但其理论基础仍未探索。为了解决这一差距，我们为这些转换的评分函数及其有益的功能建立了（严格）一致性的形式特征。我们的分析侧重于两个相互关联的情况：（a）仅应用于实现变量的转换，以及（b）共同应用于实现和预测变量的徒转化。我们为（严格）识别函数制定了类似的特征。由此产生的理论框架广泛适用于统计和机器学习方法。当应用于Bregman和Expectile评分功能时，我们的框架显示了如何实现两个关键进展：（a）严格解释从经过转换得分功能训练的模型的先前经验发现，以及（b）新颖可识别且可识别的功能的系统构建，具体是专门的G转换的期望和G转化的期望。通过将理论见解与实际应用统一，这项工作推进了在复杂的预测任务中设计评分功能的原则方法。]]></description>
      <guid>https://arxiv.org/abs/2502.16542</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>适用的平均奖励强化学习的政策评估有限样本分析</title>
      <link>https://arxiv.org/abs/2502.16816</link>
      <description><![CDATA[ARXIV：2502.16816V1公告类型：新 
摘要：我们介绍了在强大的平均奖励马尔可夫决策过程（MDP）中进行政策评估的第一个有限样本分析。这种环境中的先前工作仅建立了渐近收敛的保证，从而打开了样本复杂性的问题。在这项工作中，我们通过确定稳健的贝尔曼操作员是Span Memi-Norm下的收缩，并开发具有控制偏见的随机近似框架来解决这一差距。我们的方法基于多层蒙特卡洛（MLMC）技术，以有效地估算强大的钟声操作员。为了克服标准MLMC固有的无限预期样品复杂性，我们引入了基于几何分布的截断机制，确保了有限的恒定样品复杂性，同时保持了与截断水平呈指数型的小偏差。我们的方法实现了$ \ tilde {\ Mathcal {o}}}（\ Epsilon^{ -  2}）$的订单 - 最佳样本复杂性，用于强大的策略评估和强大的平均奖励估计，这标志着强大的强化学习理论的显着进步。]]></description>
      <guid>https://arxiv.org/abs/2502.16816</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无监督的预训练和转移学习的可证明的好处</title>
      <link>https://arxiv.org/abs/2502.16849</link>
      <description><![CDATA[ARXIV：2502.16849V1公告类型：新 
摘要：无监督的预训练和转移学习是通用技术，可以初始化神经网络的培训算法，尤其是在标记有限的数据的环境中。在本文中，我们研究了无监督的预训练和转移学习对高维监督学习样本复杂性的影响。具体而言，我们考虑通过在线随机梯度下降训练单层神经网络的问题。我们确定在非常一般的假设下，训练和转移学习（在概念转移下）通过多项式因素（在维度中）降低了样本的复杂性。我们还揭示了一些令人惊讶的设置，在样品复杂性方面，预训练对随机初始化进行了指数改进。]]></description>
      <guid>https://arxiv.org/abs/2502.16849</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>浅层relu网络在弱交互数据上的收敛</title>
      <link>https://arxiv.org/abs/2502.16977</link>
      <description><![CDATA[ARXIV：2502.16977V1公告类型：新 
摘要：我们分析了$ n $数据点对梯度流训练的一层层次恢复网络的收敛。我们的主要贡献利用了环境空间的高维度，这意味着输入样本的相关性较低，以证明具有$ \ log（n）$神经元宽度的网络足以使全球收敛具有很高的可能性。我们的分析使用polyak- {\ l} ojasiewicz沿梯度流轨迹的视点，该轨迹提供了$ \ frac {1} {n} $的指数收敛速率。当数据完全正交时，我们给出了收敛速度的进一步精致特征，证明其渐近行为位于订单之间$ \ frac {1} {n} {n} $和$ \ frac {1} {\ sqrt {\ sqrt {n}} $ ，并以收敛速率表现出相变现象，在此期间，它从下限演变为上部，以及在顺序的相对时间$ \ frac {1} {\ log（n）} $。]]></description>
      <guid>https://arxiv.org/abs/2502.16977</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>您假设的DAG是错误的，这是处理方法</title>
      <link>https://arxiv.org/abs/2502.17030</link>
      <description><![CDATA[ARXIV：2502.17030V1公告类型：新 
摘要：假设代表变量因果关系的先验知识的定向无环图（DAG）是导致估计的常见起点。现有文献通常会引用假设的领域专家知识或因果发现算法以证明这一假设是合理的。在实践中，这两个都不能高度信心提出一个DAG。领域专家犹豫不决地排除依赖性的确定性或关于关系的持续争议；因果发现通常依赖于无法测试的假设本身，或者仅提供等效类的DAG类别，并且通常对超参数和阈值选择敏感。我们提出了一种基于梯度的高效优化方法，该方法为因果图的集合提供了因果查询的界限 - 与不完善的先验知识兼容 - 对于详尽的枚举而言，这可能仍然太大。我们的边界对因果查询获得了良好的覆盖范围和清晰度，例如线性和非线性合成环境中的平均治疗效果以及实际数据。我们的方法旨在提供易于使用的，并且广泛适用于对“如果您假设的DAG错了怎么办？”的有效批评。]]></description>
      <guid>https://arxiv.org/abs/2502.17030</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分类中的随机预测和自然稀疏性：理论分析</title>
      <link>https://arxiv.org/abs/2502.17061</link>
      <description><![CDATA[ARXIV：2502.17061V1公告类型：新 
摘要：时间序列分类至关重要，包括医疗诊断，工业监测，财务预测和人类活动认可。火箭算法已成为一种简单而功能强大的方法，通过应用于时间序列数据的随机卷积内核来实现最新性能，然后进行非线性转换。它的体系结构近似于一个隐藏的卷积神经网络，同时消除了参数训练，从而确保了计算效率。尽管取得了经验成功，但有关其理论基础的基本问题仍未得到探索。我们通过在压缩传感框架内形式化火箭的随机卷积过滤器来桥接理论和实践，证明随机预测保留了时间序列数据中的歧视模式。该分析揭示了内核参数与输入信号特征之间的关系，从而实现了算法配置的更多原则方法。此外，我们证明了其非线性，基于卷积后的正值比例，表达了时间序列数据的固有稀疏性。我们的理论研究还证明，火箭满足了两个关键条件：翻译不变性和噪声稳健性。这些发现增强了可解释性，并为极端情况下的参数优化提供了指导，从而推进了时间序列分类的理论理解和实际应用。]]></description>
      <guid>https://arxiv.org/abs/2502.17061</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于用于建模混合频率和纵向数据的分位数回归森林</title>
      <link>https://arxiv.org/abs/2502.17137</link>
      <description><![CDATA[ARXIV：2502.17137V1公告类型：新 
摘要：本文的目的是扩展分位数回归森林（QRF）算法的应用以处理混合频率和纵向数据。为此，已经利用标准统计方法来构建两种新型算法：混合频率分解回归森林（MIDAS-QRF）和有限的混合物分位数回归森林（FM-QRF）。 MIDAS-QRF将QRF的灵活性与混合数据采样（MIDAS）方法相结合，从而使非参数分位数估计与在不同频率下观察到的变量相结合。另一方面，FM-QRF将随机效应机器学习算法扩展到QR框架，从而在纵向数据设置中进行有条件的分位数估计。这项论文的贡献在方法论和经验上都存在。从方法上讲，MIDAS-QRF和FM-QRF代表了在QR机器学习框架中处理混合频率和纵向数据的两种新方法。从经验上讲，所提出的模型在财务风险管理和气候变化影响评估中的应用表明，其有效性是准确且灵活的模型，该模型将应用于复杂的经验环境中。]]></description>
      <guid>https://arxiv.org/abs/2502.17137</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>马尔可夫链蒙特卡洛算法的差异隐私保证</title>
      <link>https://arxiv.org/abs/2502.17150</link>
      <description><![CDATA[ARXIV：2502.17150V1公告类型：新 
摘要：本文旨在为Markov Chain Monte Carlo（MCMC）算法提供差异隐私（DP）保证。在第一部分中，我们根据MCMC算法的输出以及与这些方法相关的蒙特卡洛估计量的样本确保了DP保证，这是在对基础马尔可夫链的收敛属性下的假设下的。特别是，我们的结果突出显示了确保目标分布在差异上是私人本身的关键条件。在第二部分中，我们将分析专门针对未经调整的Langevin算法和随机梯度Langevin动力学，并在其（R \&#39;enyi）DP上确保保证。为此，我们开发了一种基于Girsanov定理的新方法，并结合了一个扰动技巧，以获得无限域和非凸面设置的界限。我们建立：（i）$ n $ n $ the the $ n $迭代后的状态时，（ii）整个连锁轨迹的隐私范围时，就会获得$ n $ n $隐私保证的统一保证。这些发现为保护隐私的MCMC提供了具体的指南。]]></description>
      <guid>https://arxiv.org/abs/2502.17150</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>椭圆形的线性匪徒：最小值最佳算法</title>
      <link>https://arxiv.org/abs/2502.17175</link>
      <description><![CDATA[ARXIV：2502.17175V1公告类型：新 
摘要：我们考虑了一组动作是椭圆形的线性随机匪徒。我们为此问题提供了第一个已知的最小值最佳算法。我们首先在任何算法的遗憾中得出了一种新颖的信息理论下限，必须至少$ \ omega（\ min（d \ sigma \ sqrt {t} + d \ | \ | \ | \ theta \ | ___ {a}，a}，， \ | \ theta \ | _ {a} t））$，其中$ d $是尺寸，$ t $ time horizo​​n， $ \ sigma^2 $噪声差异，$ a $ a矩阵定义一组动作和$ \ theta $未知参数的向量。然后，我们提供了一种算法，该算法的遗憾匹配与乘法通用常数。从某种意义上说，该算法是非古典的，它不是乐观的，也不是采样算法。主要思想是结合一个新颖的顺序程序，以估计$ \ | \ theta \ | $，然后是根据此估算所告知的探索和招聘策略。该算法在高度计算上是高效的，并且运行仅需要时间$ o（dt + d^2 \ log（t/d） + d^3）$和内存$ o（d^2）$，与已知的乐观相反算法，在多项式时间内无法实现。我们超越了最小值的最优性，并表明我们的算法是局部渐近的最小值最佳，这是最佳的更强烈的概念。我们进一步提供数值实验来说明我们的理论发现。]]></description>
      <guid>https://arxiv.org/abs/2502.17175</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>什么时候忘记？机器上的复杂性权衡</title>
      <link>https://arxiv.org/abs/2502.17323</link>
      <description><![CDATA[ARXIV：2502.17323V1公告类型：新 
摘要：机器未学习（MU）旨在从训练有素的模型中删除特定数据点的影响，以努力以全模型再培训成本的一小部分实现这一目标。在本文中，我们分析了未学习方法的效率，并在该问题的最小值计算时间上建立了第一个上和下限，以表征最有效的算法在最困难的目标函数上的性能。具体而言，对于强烈凸的目标函数，并且在假设忘记数据与未学习方法无法访问的假设下，我们为未学习复杂性比率提供了一个相图 - 一种新的度量标准，将最佳学习方法的计算成本与完整模型进行比较再培训。该相图显示了三个不同的机制：一个以降低成本进行学习是不可行的，另一个是不学习的，因为添加噪音足够，而第三个则在第三次学习可以在重新训练方面具有显着的计算优势。这些发现突出了因素，例如数据维度，要忘记的样本的数量以及在确定未学习的实际可行性中的关键作用。]]></description>
      <guid>https://arxiv.org/abs/2502.17323</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>