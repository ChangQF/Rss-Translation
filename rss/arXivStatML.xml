<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 10 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Aux-NAS：利用辅助标签，额外的推理成本可以忽略不计</title>
      <link>https://arxiv.org/abs/2405.05695</link>
      <description><![CDATA[arXiv:2405.05695v1 公告类型：交叉 
摘要：我们旨在利用独立（辅助）任务中的额外辅助标签来提升我们关注的主要任务性能，同时保留主要任务的单任务推理成本。虽然大多数现有的辅助学习方法都是基于优化的，依赖于损失权重/梯度操纵，但我们的方法是基于架构的，对主要任务和辅助任务具有灵活的非对称结构，从而产生不同的网络进行训练和推理。具体来说，从两个单任务网络/分支（每个代表一个任务）开始，我们提出了一种新方法，其中不断发展的网络在收敛后仅存在主到辅助链接作为跨任务连接。这些连接可以在主要任务推理期间被删除，从而产生单任务推理成本。我们通过制定神经架构搜索（NAS）问题来实现这一点，其中我们在搜索空间中初始化双向连接并引导 NAS 优化收敛到仅具有单侧主到辅助连接的架构。此外，我们的方法可以与基于优化的辅助学习方法相结合。使用 VGG、ResNet 和 ViT 主干在 NYU v2、CityScapes 和 Taskonomy 数据集上对六个任务进行的大量实验验证了其良好的性能。代码可在 https://github.com/ethanygao/Aux-NAS 上找到。]]></description>
      <guid>https://arxiv.org/abs/2405.05695</guid>
      <pubDate>Fri, 10 May 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>预训练的文本到图像扩散模型是用于控制的多功能表示学习器</title>
      <link>https://arxiv.org/abs/2405.05852</link>
      <description><![CDATA[arXiv:2405.05852v1 公告类型：交叉
摘要：具体的人工智能代理需要对通过视觉和语言输入介导的物理世界进行细粒度的理解。仅从特定于任务的数据很难学习此类功能。这导致了预训练视觉语言模型的出现，作为一种工具，将从互联网规模的数据中学习到的表示转移到下游任务和新领域。然而，常用的对比训练表示（例如 CLIP 中的表示）已被证明无法使具体代理获得足够细粒度的场景理解，而这种理解对于控制至关重要。为了解决这个缺点，我们考虑预先训练的文本到图像扩散模型的表示，这些模型经过显式优化以根据文本提示生成图像，因此包含反映高度细粒度的视觉空间信息的文本条件表示。使用预先训练的文本到图像扩散模型，我们构建了稳定的控制表示，它允许学习泛化到复杂的开放环境的下游控制策略。我们表明，使用稳定控制表示学习的策略在广泛的模拟控制设置（包括具有挑战性的操纵和导航任务）中与最先进的表示学习方法具有竞争力。最值得注意的是，我们表明稳定控制表示使学习策略能够在 OVMM（一个困难的开放词汇导航基准）上展示出最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.05852</guid>
      <pubDate>Fri, 10 May 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>不精确的多臂强盗</title>
      <link>https://arxiv.org/abs/2405.05673</link>
      <description><![CDATA[arXiv:2405.05673v1 公告类型：交叉
摘要：我们引入了一种新颖的多臂老虎机框架，其中每个臂都与结果空间上的固定未知信用集相关联（这可能比奖励更丰富）。手臂到信用集的对应关系来自一类已知的假设。然后，我们定义与这些信用集定义的较低预测相对应的遗憾概念。同样，该设置可以被视为两人零和游戏，其中，在每一轮中，代理选择一个手臂，而对手从与该手臂相关的一组选项中选择结果的分布。遗憾是根据游戏的价值来定义的。对于某些自然假设类，与随机线性老虎机松散相似（这是结果设置的特殊情况），我们提出了一种算法并证明了相应的后悔上限。我们还证明了特定特殊情况下遗憾的下限。]]></description>
      <guid>https://arxiv.org/abs/2405.05673</guid>
      <pubDate>Fri, 10 May 2024 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>加速高阶 Langevin Monte Carlo 算法的非渐近估计</title>
      <link>https://arxiv.org/abs/2405.05679</link>
      <description><![CDATA[arXiv:2405.05679v1 公告类型：交叉
摘要：在本文中，我们提出了两种新算法，即 aHOLA 和 aHOLLA，用于从可能具有超线性增长潜力的高维目标分布中进行采样。我们在 Wasserstein-1 和 Wasserstein-2 距离上建立 aHOLA 的非渐近收敛界限，在局部 H\&quot;{o 下，收敛率分别等于 $1+q/2$ 和 $1/2+q/4$ }lder 条件，指数 $q\in(0,1]$ 和目标分布势的无穷大条件下的凸性。在某些全局连续性条件和耗散性条件下，aHOLLA 获得了类似的结果。至关重要的是，我们实现了状态所提出的算法在非凸设置中的收敛速度高于现有算法，进行了数值实验以从多个分布中进行采样，结果支持了我们的主要发现。]]></description>
      <guid>https://arxiv.org/abs/2405.05679</guid>
      <pubDate>Fri, 10 May 2024 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 James-Stein 估计器进行黑盒变分推理的方差控制</title>
      <link>https://arxiv.org/abs/2405.05485</link>
      <description><![CDATA[arXiv:2405.05485v1 公告类型：交叉
摘要：黑盒变分推理是最近一系列使变分推理更加“黑盒”的努力中一个很有前途的框架。然而，在基本版本中，它要么由于不稳定而无法收敛，要么需要对更新步骤进行一些微调在执行之前，我们提出了一种通过将随机梯度上升重新定义为多元估计问题来调节其参数更新的方法，我们检查 James-Stein 估计器的属性作为算术平均值的替代。所提出的方法对证据下界梯度的估计比 Rao-Blackwellization 的方差减少相对较弱，但提供了更简单且不需要分析师进行微调的权衡，这也证明了基准数据集的性能。在模型拟合和收敛时间方面具有与 Rao-Blackwellized 方法相当或更好的一致性能。]]></description>
      <guid>https://arxiv.org/abs/2405.05485</guid>
      <pubDate>Fri, 10 May 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>深层次图对齐内核</title>
      <link>https://arxiv.org/abs/2405.05545</link>
      <description><![CDATA[arXiv:2405.05545v1 公告类型：交叉
摘要：典型的 R 卷积图核调用将图分解为非同构子结构并进行比较的核函数。然而，忽视这些子结构之间隐含的相似性和拓扑位置信息限制了它们的性能。在本文中，我们引入深度分层图对齐内核（DHGAK）来解决这个问题。具体来说，关系子结构按照其深度嵌入空间中的聚类分布分层对齐。属于同一簇的子结构在再生核希尔伯特空间（RKHS）中被分配相同的特征图，其中图特征图是通过核均值嵌入导出的。理论分析保证DHGAK是半正定的并且在RKHS中具有线性可分性。在各种基准数据集上与最先进的图内核进行比较证明了 DGAK 的有效性和效率。该代码可在 Github (https://github.com/EWesternRa/DHGAK) 上获取。]]></description>
      <guid>https://arxiv.org/abs/2405.05545</guid>
      <pubDate>Fri, 10 May 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>逆条件流如何替代分布回归</title>
      <link>https://arxiv.org/abs/2405.05429</link>
      <description><![CDATA[arXiv:2405.05429v1 公告类型：交叉
摘要：为了更好地理解深度学习算法的基本原理，人们越来越多地研究简单模型（例如线性回归）的神经网络表示。然而，分布回归模型（例如 Cox 模型）的神经表示迄今为止很少受到关注。我们通过提出使用逆流变换（DRIFT）的分布回归框架来缩小这一差距，其中包括上述模型的神经表示。我们凭经验证明，在涉及连续、有序、时间序列和生存结果的多种应用中，DRIFT 模型的神经表示可以替代经典的统计模型。我们确认 DRIFT 中的模型在部分效应估计、预测和任意不确定性量化方面在经验上与多种统计方法的性能相匹配。 DRIFT 涵盖可解释的统计模型和灵活的神经网络，为统计建模和深度学习开辟了新途径。]]></description>
      <guid>https://arxiv.org/abs/2405.05429</guid>
      <pubDate>Fri, 10 May 2024 06:17:58 GMT</pubDate>
    </item>
    <item>
      <title>使用离线和在线数据的无模型鲁棒$\phi$-发散强化学习</title>
      <link>https://arxiv.org/abs/2405.05468</link>
      <description><![CDATA[arXiv:2405.05468v1 公告类型：交叉
摘要：鲁棒的 $\phi$ 正则化马尔可夫决策过程（RRMDP）框架专注于设计控制策略，该策略对于由于模拟器（标称）模型与现实世界设置之间的不匹配而导致的参数不确定性具有鲁棒性。这项工作做出了两个重要贡献。首先，我们提出了一种称为鲁棒$\phi$正则化拟合Q迭代（RPQ）的无模型算法，用于学习$\epsilon$最优鲁棒策略，该策略仅使用通过推出行为策略收集的历史数据（名义模型的稳健探索性要求）。据我们所知，我们首次对一类$\phi$-散度进行统一分析，通过一般函数逼近在高维系统中实现稳健的最优策略。其次，我们引入了混合鲁棒 $\phi$ 正则化强化学习框架，以使用历史数据和在线采样来学习最佳鲁棒策略。针对这个框架，我们提出了一种称为混合鲁棒总变分正则化 Q 迭代（HyTQ：发音高度 Q）的无模型算法。据我们所知，我们在混合鲁棒$\phi$正则化强化学习框架下提供了第一个改进的大规模问题中的数据外分布假设，并具有通用函数逼近。最后，我们为我们的算法的学习策略在具有任意大状态空间的系统上的性能提供了理论保证。]]></description>
      <guid>https://arxiv.org/abs/2405.05468</guid>
      <pubDate>Fri, 10 May 2024 06:17:58 GMT</pubDate>
    </item>
    <item>
      <title>可解释性需要新的范式</title>
      <link>https://arxiv.org/abs/2405.05386</link>
      <description><![CDATA[arXiv:2405.05386v1 公告类型：交叉
摘要：可解释性是用人类可以理解的术语解释模型的研究。目前，可解释性分为两种范式：内在范式，认为只有设计用于解释的模型才能被解释；事后范式，认为黑盒模型可以被解释。这场争论的核心是每个范式如何确保其解释是忠实的，即忠实于模型的行为。这很重要，因为错误但令人信服的解释会导致人们对人工智能 (AI) 缺乏支持的信心，这可能是危险的。本文的立场是，我们应该在对忠诚保持警惕的同时思考新的范式。首先，通过考察科学范式的历史，我们看到范式在不断发展。然后，通过检查当前的范式，我们可以了解它们的潜在信念、它们带来的价值以及它们的局限性。最后，本文提出了 3 种新兴的可解释性范式。第一个范式设计模型，以便可以轻松衡量忠诚度。另一种方法是优化模型，使解释变得可信。最后一个范式建议开发能够产生预测和解释的模型。]]></description>
      <guid>https://arxiv.org/abs/2405.05386</guid>
      <pubDate>Fri, 10 May 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>ASPIRE：贝叶斯逆问题的迭代摊销后验推理</title>
      <link>https://arxiv.org/abs/2405.05398</link>
      <description><![CDATA[arXiv:2405.05398v1 公告类型：交叉
摘要：由于其不确定性量化，逆问题的贝叶斯解决方案是规避风险的应用程序的首选框架。这些好处是以通常难以处理的计算为代价的。机器学习和变分推理 (VI) 的新进展通过从示例中学习降低了计算障碍。出现了两种代表不同权衡的 VI 范式：摊销和非摊销。摊销 VI 可以快速产生结果，但由于推广到许多观察到的数据集，它会产生次优的推理结果。非摊销 VI 的推理速度较慢，但​​可以找到更好的后验近似值，因为它专门针对单个观察到的数据集。当前的摊销 VI 技术遇到了次优墙，如果没有更具表现力的神经网络或额外的训练数据，就无法改进。我们提出了一种解决方案，可以使用相同的网络架构和训练数据迭代改进摊销后验。我们的方法的优点是需要额外的计算，但这些计算仍然很节俭，因为它们基于物理混合方法和汇总统计。重要的是，这些计算大多保持离线状态，因此我们的方法保持廉价且可重用的在线评估，同时弥合这两种范式的近似差距。我们用基于物理和迭代细化的摘要表示我们提出的方法 ASPIRE - 摊销后验。我们首先在已知后验的程式化问题上验证我们的方法，然后展示其在超声高维和非线性经颅医学成像问题上的实际用途。与文献中的基线方法和以前的方法相比，我们的方法作为后验推理的计算高效且高保真度的方法脱颖而出。]]></description>
      <guid>https://arxiv.org/abs/2405.05398</guid>
      <pubDate>Fri, 10 May 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>对地下水位深度估计的批判性评估：机器学习中的挑战和机遇</title>
      <link>https://arxiv.org/abs/2405.04579</link>
      <description><![CDATA[arXiv:2405.04579v1 公告类型：交叉
摘要：地下水位深度（WTD）的精细分辨率空间模式可以为依赖地下水的系统（包括生态、水文和人为系统）的动态提供信息。一般来说，静态 WTD 的大尺度（例如大陆或全球）空间地图可以使用基于物理 (PB) 或基于机器学习 (ML) 的模型进行模拟。我们使用 XGBoost 算法以及美国和加拿大超过 2000 万个 WTD 真实和代理观测数据构建了 WTD 的三个高分辨率 (500 m) ML 模拟。这三个 ML 模型使用 WTD 驾驶员和 WTD 之间已知的物理关系进行约束，并通过顺序添加 WTD 的真实观察和代理观察进行训练。我们解释了物理约束机器学习模型的黑匣子，并将其与地下水水文学的现有文献进行了比较。通过广泛的（逐像素）评估，我们证明，与三种可用的 WTD PB 模拟相比，我们的模型可以更准确地预测北美大部分生态区域中未见的 WTD 真实和代理观测结果。然而，我们仍然认为大规模 WTD 估计还远未成为一个已解决的问题。我们的理由是，由于观测数据有偏差且不可信、基于物理的方程的错误指定以及机器学习模型的过度灵活性，我们的社区对 WTD 的 ML 或 PB 模拟的信心太高，并且可验证的 WTD 准确模拟确实存在问题。文献中尚不存在，特别是在干旱的高海拔地区。最终，我们深入讨论了未来的方向，这些方向可能有助于水文地质学家决定如何进行 WTD 估计，特别关注机器学习的应用。]]></description>
      <guid>https://arxiv.org/abs/2405.04579</guid>
      <pubDate>Fri, 10 May 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>协调程序归纳与率失真理论</title>
      <link>https://arxiv.org/abs/2405.05294</link>
      <description><![CDATA[arXiv:2405.05294v1 公告类型：交叉 
摘要：人类学习的许多方面都被认为是构建心理程序的过程：从获取符号数字表示到关于世界的直观理论。与此同时，通过速率失真理论 (RDT) 使用信息处理来模拟人类认知有着悠久的传统。然而，当心理表征采用程序形式时，如何应用 RDT 仍然不太清楚。在这项工作中，我们通过提出速率（描述长度）、失真（错误）和计算成本（搜索预算）之间的三向权衡来调整 RDT。我们在旋律任务上使用模拟来研究这种权衡的含义，并表明构建跨任务的共享程序库可以带来全局利益。然而，这是以对课程的敏感性为代价的，这也是人类学习者的特征。最后，我们使用部分信息分解的方法来生成训练课程，从而产生更有效的库和更好的泛化。]]></description>
      <guid>https://arxiv.org/abs/2405.05294</guid>
      <pubDate>Fri, 10 May 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>使用反事实解释重建模型：减轻决策边界转移</title>
      <link>https://arxiv.org/abs/2405.05369</link>
      <description><![CDATA[arXiv:2405.05369v1 公告类型：交叉
摘要：反事实解释找到了以最小的输入扰动实现有利的模型结果的方法。然而，反事实解释也可以通过策略性地训练代理模型来窃取模型，以给出与原始（目标）模型类似的预测。在这项工作中，我们通过专门利用反事实解释也非常接近决策边界这一事实来研究模型提取。我们提出了一种新的模型提取策略，称为反事实钳位攻击（CCA），该策略使用独特的损失函数来训练代理模型，该损失函数以与普通实例不同的方式处理反事实。我们的方法还缓解了现有模型提取攻击中出现的决策边界转移的相关问题，这些攻击将反事实视为普通实例。我们还使用多胞形理论推导了模型近似误差与查询数量之间的新颖数学关系。实验结果表明，我们的策略在几个现实世界数据集上提高了目标模型预测和代理模型预测之间的保真度。]]></description>
      <guid>https://arxiv.org/abs/2405.05369</guid>
      <pubDate>Fri, 10 May 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>通过广义贝叶斯进行异常值鲁棒卡尔曼过滤</title>
      <link>https://arxiv.org/abs/2405.05646</link>
      <description><![CDATA[arXiv:2405.05646v1 公告类型：新
摘要：我们推导了一种新颖的、可证明稳健的封闭式贝叶斯更新规则，用于在存在异常值和错误指定的测量模型的情况下在状态空间模型中进行在线过滤。我们的方法将广义贝叶斯推理与扩展和集成卡尔曼滤波器等过滤方法相结合。我们使用前者来显示鲁棒性，使用后者来确保非线性模型情况下的计算效率。我们的方法以低得多的计算成本匹配或优于其他稳健的过滤方法（例如基于变分贝叶斯的方法）。我们通过离群值测量的一系列过滤问题（例如对象跟踪、高维混沌系统中的状态估计以及神经网络的在线学习）来实证证明这一点。]]></description>
      <guid>https://arxiv.org/abs/2405.05646</guid>
      <pubDate>Fri, 10 May 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>非简并函数的批量随机老虎机</title>
      <link>https://arxiv.org/abs/2405.05733</link>
      <description><![CDATA[arXiv:2405.05733v1 公告类型：新
摘要：本文研究非简并函数的批量老虎机学习问题。我们引入了一种算法，可以近乎最优地解决非简并函数的批量老虎机问题。更具体地说，我们引入一种称为几何窄化（GN）的算法，其遗憾界限的阶数为 $\widetilde{{\mathcal{O}}} ( A_{+}^d \sqrt{T} )$。另外，GN只需要$\mathcal{O} (\log \log T)$个批次就能实现这个遗憾。我们还为此问题提供了下界分析。更具体地说，我们证明在倍增维度 $d$ 的某些（紧凑）倍增度量空间上： 1. 对于任何策略 $\pi$，存在一个问题实例，$\pi$ 承认顺序为 ${\欧米茄} ( A_-^d \sqrt{T})$; 2. 没有策略可以使用少于 $ \Omega ( \log \log T ) $ 轮的通信来实现所有问题实例的顺序为 $ A_-^d \sqrt{T} $ 的遗憾。我们的下限分析表明，GN 算法以最少的批次数实现了接近最佳的遗憾。]]></description>
      <guid>https://arxiv.org/abs/2405.05733</guid>
      <pubDate>Fri, 10 May 2024 06:17:55 GMT</pubDate>
    </item>
    </channel>
</rss>