<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 24 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>动量 SGD 与欠阻尼朗之万扩散之间的误差估计</title>
      <link>https://arxiv.org/abs/2410.17297</link>
      <description><![CDATA[arXiv:2410.17297v1 公告类型：新
摘要：动量随机梯度下降是随机梯度下降的一种流行变体，最近有报道称它与欠阻尼朗之万扩散有着密切的关系。在本文中，我们在 1-Wasserstein 和总变分距离中建立了它们之间的定量误差估计。]]></description>
      <guid>https://arxiv.org/abs/2410.17297</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可扩展隐式图学习</title>
      <link>https://arxiv.org/abs/2410.17464</link>
      <description><![CDATA[arXiv:2410.17464v1 公告类型：新
摘要：图元是表示图结构的连续模型，允许生成不同大小的图。我们提出了可扩展隐式图元学习 (SIGL)，这是一种可扩展的方法，它结合了隐式神经表示 (INR) 和图神经网络 (GNN)，以从观察到的图中估计图元。与面临固定分辨率和可扩展性问题等重要限制的现有方法不同，SIGL 可以学习任意分辨率的连续图元。GNN 用于确定正确的节点顺序，从而改善图对齐。此外，我们描述了估计量的渐近一致性，表明更具表现力的 INR 和 GNN 可产生一致的估计量。我们在合成和真实世界中的图中评估了 SIGL，表明它优于现有方法并能有效地扩展到更大的图，使其成为图数据增强等任务的理想选择。]]></description>
      <guid>https://arxiv.org/abs/2410.17464</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>半隐式函数梯度流</title>
      <link>https://arxiv.org/abs/2410.17935</link>
      <description><![CDATA[arXiv:2410.17935v1 公告类型：新
摘要：基于粒子的变分推理方法 (ParVI) 使用由粒子表示的非参数变分族根据 Kullback-Leibler (KL) 散度的核化 Wasserstein 梯度流来近似目标分布。最近的工作引入了函数梯度流来替代内核以获得更好的灵活性。然而，确定性更新机制可能会受到有限的探索的影响，并且需要对新样本进行昂贵的重复运行。在本文中，我们提出了半隐式函数梯度流 (SIFG)，这是一种使用扰动粒子作为近似族的函数梯度 ParVI 方法。相应的函数梯度流可以通过去噪分数匹配来估计，具有很强的理论收敛保证。我们还提出了一种自适应版本的方法，可以自动选择合适的噪声幅度。大量实验证明了所提出的框架在模拟和真实数据问题上的有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2410.17935</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>偏见放大的有效理论</title>
      <link>https://arxiv.org/abs/2410.17263</link>
      <description><![CDATA[arXiv:2410.17263v1 公告类型：交叉 
摘要：机器学习模型可能会捕获和放大数据中存在的偏差，导致不同社会群体的测试表现不同。为了更好地理解、评估和减轻这些可能的偏差，需要更深入地从理论上理解模型设计选择和数据分布属性如何导致偏差。在这项工作中，我们在岭回归的背景下提出了一个精确的分析理论，包括有随机投影和没有随机投影的情况，前者在简化的机制下对神经网络进行建模。我们的理论对机器学习偏差提供了统一而严格的解释，为各种特征和参数机制中的偏差放大和少数群体偏差等现象提供了见解。例如，我们证明可能存在最佳的正则化惩罚或训练时间以避免偏差放大，并且组之间的测试误差可能存在根本差异，而这些差异不会随着参数化的增加而消失。重要的是，我们的理论预测与文献中报道的几个实证观察结果一致。我们在各种合成和半合成数据集上对我们的理论进行了广泛的实证验证。]]></description>
      <guid>https://arxiv.org/abs/2410.17263</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用重采样和 GAN 方法改进保险巨灾数据</title>
      <link>https://arxiv.org/abs/2410.17294</link>
      <description><![CDATA[arXiv:2410.17294v1 公告类型：交叉 
摘要：有关灾难事件的精确而庞大的数据集对于保险公司非常重要。为了提高此类数据的质量，提出了三种基于 bootstrap、bootknife 和 GAN 算法的方法。使用数值实验和实际数据，基于均方误差 (MSE) 和平均绝对误差 (MAE) 比较这些方法的模拟输出。然后，还考虑了一种直接算法来构建有关此类输出的模糊专家意见。]]></description>
      <guid>https://arxiv.org/abs/2410.17294</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算在线线性优化的最佳正则器</title>
      <link>https://arxiv.org/abs/2410.17336</link>
      <description><![CDATA[arXiv:2410.17336v1 公告类型：交叉 
摘要：跟随正则化领导者 (FTRL) 算法是一类流行的在线线性优化 (OLO) 学习算法，可保证亚线性遗憾，但正则化器的选择会显著影响遗憾界限中的维度相关因素。我们提出了一种算法，该算法以特定 OLO 实例的凸对称动作集和损失集作为输入，并输出一个正则化器，这样使用该正则化器运行 FTRL 可保证遗憾在最佳可能遗憾界限的通用常数因子内。具体来说，对于任何（凸、对称）动作集和损失集的选择，我们证明存在一个 FTRL 实例，它可以在最佳学习算法的常数因子内实现遗憾，从而加强了 Srebro 等人在 2011 年的普遍性结果。
我们的算法需要预处理时间和空间在 OLO 实例的维度 $d$ 上呈指数增长，但可以在线高效运行，假设动作集和损失集的成员资格和线性优化预言机分别（并且对于常数维度 $d$ 的情况是完全多项式时间）。我们用一个下限来补充这一点，表明即使确定给定的正则化器是否相对于给定的范数为 $\alpha$-strongly-convex 也是 NP-hard。]]></description>
      <guid>https://arxiv.org/abs/2410.17336</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>合作型多智能体约束随机线性赌博机</title>
      <link>https://arxiv.org/abs/2410.17382</link>
      <description><![CDATA[arXiv:2410.17382v1 公告类型：交叉 
摘要：在本研究中，我们探索了一种协作多智能体随机线性老虎机设置，涉及一个由 $N$ 个智能体组成的网络，这些智能体在本地进行通信以最小化他们的集体遗憾，同时将他们的预期成本保持在指定阈值 $\tau$ 以下。每个智能体都会遇到一个独特的线性老虎机问题，该问题以其自己的奖励和成本参数（即局部参数）为特征。智能体的目标是确定与这些参数的平均值或所谓的全局参数相对应的最佳整体动作。在每一轮中，都会根据智能体当前对系统的了解随机选择一个动作。然后所有智能体都会执行这个选定的动作，然后它们会观察各自的奖励和成本。我们提出了一种安全的分布式置信上限算法，即 \textit{MA-OPLB}，并对其 $T$ 轮遗憾建立了一个高概率界限。 MA-OPLB 采用加速共识方法，其中代理可以通过与邻居通信适当的信息来计算整个网络的平均奖励和成本估计值。我们表明，我们的遗憾界限是 $ \mathcal{O}\left(\frac{d}{\tau-c_0}\frac{\log(NT)^2}{\sqrt{N}}\sqrt{\frac{T}{\log(1/|\lambda_2|)}}\right)$ 量级，其中 $\lambda_2$ 是通信矩阵的第二大（绝对值）特征值，$\tau-c_0$ 是可行行动的已知成本差距。我们还通过实验展示了我们提出的算法在不同网络结构中的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.17382</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于结构功能耦合的枢纽节点识别的学习图过滤器</title>
      <link>https://arxiv.org/abs/2410.17410</link>
      <description><![CDATA[arXiv:2410.17410v1 公告类型：交叉
摘要：在过去的二十年里，网络科学的工具被用来描述大脑结构和功能网络的组织。网络组织的一个衡量标准是枢纽节点识别。枢纽是网络中的专门节点，连接与专门功能过程相对应的不同大脑单元。识别枢纽节点的传统方法利用不同类型的中心性度量和参与系数来描述节点重要性的各个方面。这些方法完全依赖于由功能磁共振成像 (fMRI) 构建的功能连接网络，而忽略了大脑中的结构-功能耦合。在本文中，我们介绍了一种基于图信号处理 (GSP) 的枢纽检测框架，该框架利用结构连接和功能激活来识别枢纽节点。所提出的框架将功能活动建模为结构连接上的图信号。然后基于枢纽节点稀疏、与邻居相比具有更高活动水平的前提来检测枢纽节点，并且非枢纽节点的活动可以建模为基于图的过滤器的输出。基于这些假设，我们制定了一个优化框架 GraFHub，用于学习最佳多项式图滤波器的系数并检测中心节点。我们根据来自人类连接组计划 (HCP) 的模拟数据和静息状态 fMRI (rs-fMRI) 数据对所提出的框架进行了评估。]]></description>
      <guid>https://arxiv.org/abs/2410.17410</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多响应实验处理的排序</title>
      <link>https://arxiv.org/abs/2410.17604</link>
      <description><![CDATA[arXiv:2410.17604v1 公告类型：交叉 
摘要：我们提出了一个概率排名模型来确定多响应实验中的最佳治疗。在当代实践中，治疗应用于个体，目的是同时实现多个理想属性。然而，通常存在相互竞争的属性，并且如果不损害另一个属性的最优性，就无法实现一个属性的最优性。通常，我们仍然想知道哪种治疗方法总体上最好。在我们的框架中，我们首先根据治疗排名来制定总体最优性。然后，我们推断潜在排名，该排名允许我们报告从最优到最不最优的治疗，并提供理想的理想属性。我们通过模拟和实际数据分析展示了如何在实践中实现推断排名的可靠性。我们采用贝叶斯方法并推导出相关的马尔可夫链蒙特卡罗算法来将我们的模型与数据拟合。最后，我们讨论了将我们的方法作为基于试验的研究中实验评估的标准工具的前景。]]></description>
      <guid>https://arxiv.org/abs/2410.17604</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>潜在动态系统的可识别表示和模型学习</title>
      <link>https://arxiv.org/abs/2410.17882</link>
      <description><![CDATA[arXiv:2410.17882v1 公告类型：交叉 
摘要：从低级观测中学习可识别的表示和模型对于智能航天器可靠地完成下游任务非常有用。对于时间观测，为了确保数据生成过程可证明地被反转，大多数现有工作要么假设动态机制中的噪声变量（有条件地）独立，要么需要可以直接影响每个潜在变量的干预。然而，在实践中，外生输入/干预与潜在变量之间的关系可能遵循一些复杂的确定性机制。在这项工作中，我们研究了潜在动态系统的可识别表示和模型学习问题。关键思想是我们使用受可控规范形式启发的归纳偏差，根据定义，它是不变的、稀疏的和输入相关的。我们证明，对于线性或仿射非线性潜在动态系统，可以识别表示直至缩放并确定模型直至一些简单的变换。研究结果有望为发展更可信的智能航天器决策与控制方法提供一定的理论保障。]]></description>
      <guid>https://arxiv.org/abs/2410.17882</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>潜在动态下的强化学习：走向统计和算法模块化</title>
      <link>https://arxiv.org/abs/2410.17904</link>
      <description><![CDATA[arXiv:2410.17904v1 公告类型：交叉
摘要：强化学习的实际应用通常涉及代理在复杂的高维观察上进行操作的环境，但底层（“潜在”）动态相对简单。然而，除了诸如小潜在空间之类的限制性设置之外，潜在动态下强化学习的基本统计要求和算法原理尚不清楚。
本文从统计和算法的角度探讨了 $\textit{general}$ 潜在动态下的强化学习问题。在统计方面，我们的主要负面结果表明，大多数经过充分研究的强化学习设置与函数逼近在与丰富的观察相结合时变得难以处理；我们用一个积极的结果来补充这一点，将潜在的前推覆盖性确定为实现统计可处理性的一般条件。在算法上，我们开发了可证明有效的可观测到潜在归约（即将潜在 MDP 的任意算法转换为可对丰富观测进行操作的算法的归约），分为两种情况：一种是代理可以访问潜在动态的后见观察 [LADZ23]，另一种是代理可以估计自我预测的潜在模型 [SAGHCB20]。总之，我们的研究结果是朝着在潜在动态下建立统一的强化学习统计和算法理论迈出的第一步。]]></description>
      <guid>https://arxiv.org/abs/2410.17904</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度学习用于数据稀缺的动态系统模型校正</title>
      <link>https://arxiv.org/abs/2410.17913</link>
      <description><![CDATA[arXiv:2410.17913v1 公告类型：交叉 
摘要：我们提出了一个深度学习框架，用于仅利用稀缺的高保真数据集来校正现有的动态系统模型。在许多实际情况下，人们会有一个低保真模型，它可以相当好地捕捉动态，但由于模型的固有局限性和底层物理的复杂性，它缺乏高分辨率。当高分辨率数据可用时，很自然地会寻求模型校正以提高模型预测的分辨率。我们关注的是高保真数据量太小以至于大多数现有的数据驱动建模方法无法应用的情况。在本文中，我们使用一种只需要稀缺的高保真数据集的模型校正方法来应对这些挑战。我们的方法首先寻找一个深度神经网络 (DNN) 模型来近似现有的低保真模型。然后通过使用稀缺的高保真数据，该方法通过迁移学习 (TL) 来校正 DNN 模型。经过 TL 后，我们得到了一个对底层动态具有高预测精度的改进 DNN 模型。该方法的一个显著特点是它不假设模型校正项的特定形式。相反，它通过 TL 对低保真度模型进行内在校正。一组数值示例证明了该方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.17913</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从有限样本矩阵估计核积分算子的谱矩</title>
      <link>https://arxiv.org/abs/2410.17998</link>
      <description><![CDATA[arXiv:2410.17998v2 公告类型：交叉 
摘要：当输入和特征的数量受到有限测量的限制时，分析输入数据分布中采样特征的结构具有挑战性。传统方法通常依赖于从有限测量矩阵导出的样本协方差矩阵的特征值谱；然而，这些谱对测量矩阵的大小很敏感，导致见解有偏差。在本文中，我们介绍了一种新算法，该算法在有限采样测量矩阵的无限输入和特征的极限下提供核积分算子的谱矩的无偏估计。我们的方法基于动态规划，效率高，能够估计算子谱的矩。我们证明了我们的估计器在径向基函数 (RBF) 核上的准确性，强调了它与理论谱的一致性。此外，我们展示了我们的方法在理解神经网络中学习表示的几何形状方面的实用性和鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2410.17998</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用未标记的先前数据进行有效的在线探索</title>
      <link>https://arxiv.org/abs/2410.18076</link>
      <description><![CDATA[arXiv:2410.18076v1 公告类型：交叉 
摘要：无监督预训练在许多监督领域都具有变革性。然而，将这些想法应用于强化学习 (RL) 提出了一个独特的挑战，因为微调不涉及模仿特定于任务的数据，而是通过迭代自我改进来探索和定位解决方案。在这项工作中，我们研究如何利用未标记的先前轨迹数据来学习有效的探索策略。虽然先前数据可用于预训练一组低级技能，或作为在线 RL 的额外离策略数据，但目前尚不清楚如何有效地将这些想法结合起来进行在线探索。我们的方法 SUPE（从未标记的先前数据中获取的探索技能）表明，仔细结合这些想法可以增加它们的好处。我们的方法首先使用变分自动编码器 (VAE) 提取低级技能，然后使用乐观奖励模型对未标记的轨迹进行伪重新标记，将先前数据转换为高级、与任务相关的示例。最后，SUPE 使用这些转换后的示例作为在线 RL 的额外离策略数据，以学习高级策略，该策略由预训练的低级技能组成，以有效探索。我们通过经验证明，SUPE 可靠地优于先前的策略，成功解决了一系列长期、稀疏奖励任务。代码：https://github.com/rail-berkeley/supe。]]></description>
      <guid>https://arxiv.org/abs/2410.18076</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变分因果推理</title>
      <link>https://arxiv.org/abs/2209.05935</link>
      <description><![CDATA[arXiv:2209.05935v3 公告类型：替换 
摘要：当结果为高维（例如基因表达、脉冲响应、人脸）且协变量相对有限时，估计反事实处理下个体的潜在结果对于传统因果推理和监督学习方法来说是一项具有挑战性的任务。在这种情况下，要在反事实处理下构建一个人的结果，至关重要的是利用协变量之上的观察到的事实结果中包含的个人信息。我们提出了一个深度变分贝叶斯框架，该框架严格整合了反事实处理下结果构建的两个主要信息来源：一个来源是嵌入在高维事实结果中的个体特征；另一个来源是事实上接受了这种感兴趣的处理的类似受试者（具有相同协变量的受试者）的反应分布。]]></description>
      <guid>https://arxiv.org/abs/2209.05935</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>