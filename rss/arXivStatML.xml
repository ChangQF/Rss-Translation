<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Wed, 26 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>gnns注定要被输入图的拓扑结束吗？</title>
      <link>https://arxiv.org/abs/2502.17739</link>
      <description><![CDATA[ARXIV：2502.17739V1公告类型：新 
摘要：图神经网络（GNN）在从图形结构数据中学习方面取得了巨大的成功。但是，输入图的拓扑对GNN行为的影响仍然很少了解。在这项工作中，我们探讨了GNN是否固有地受到其输入图的结构的限制，重点是局部拓扑特征如何与消息通话方案相互作用，以产生全局现象，例如超平厚度或表达性表示。我们介绍了$ k $ -HOP相似性的概念，并研究本地相似的社区是否导致了一致的节点表示。这种相互作用可能会导致有效的学习或不可避免的过度平衡，具体取决于图的固有特性。我们的经验实验验证了这些见解，强调了图形拓扑对GNN性能的实际意义。]]></description>
      <guid>https://arxiv.org/abs/2502.17739</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与后漂移的广义协变量转移下的共形预测</title>
      <link>https://arxiv.org/abs/2502.17744</link>
      <description><![CDATA[ARXIV：2502.17744V1公告类型：新 
摘要：在统计学习的许多实际应用中，收集足够多的许多培训数据通常是昂贵，耗时甚至不现实的。在这种情况下，旨在利用相关来源领域的知识来提高目标领域的学习绩效的转移学习方法更有益。在各种分布假设下开发了许多转移学习方法。在本文中，我们研究了一种特定类型的分类问题，称为传递学习的新分布假设，称为共形预测。共同预测框架下的分类器预测了一组合理的标签，而不是每个数据实例的一个标签，提供了一个更加谨慎，更安全的决定。我们考虑\ textIt {协方差偏移的概括，具有后漂移}设置用于传输学习。在此设置下，我们提出了一个加权的共形分类器，该分类器同时利用源和目标样本，并在目标域中具有覆盖范围保证。理论研究表明有利的渐近特性。数值研究进一步说明了所提出的方法的实用性。]]></description>
      <guid>https://arxiv.org/abs/2502.17744</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>统计学家大语模型的概述</title>
      <link>https://arxiv.org/abs/2502.17814</link>
      <description><![CDATA[ARXIV：2502.17814V1公告类型：新 
摘要：大型语言模型（LLMS）已成为人工智能（AI）中的变革工具，在文本生成，推理和决策等各种任务中表现出非凡的功能。尽管他们的成功主要是由计算能力和深度学习体系结构的进步驱动的，但在不确定性量化，决策，因果推理和分配转移等领域的出现问题需要更深入地参与统计领域。本文探讨了统计学家可以为LLM的发展做出重要贡献的潜在领域，尤其是那些旨在使人类用户具有信任度和透明度的领域。因此，我们专注于不确定性量化，可解释性，公平性，隐私，水印和模型适应等问题。我们还考虑了LLM在统计分析中的可能作用。通过桥接AI和统计数据，我们旨在促进更深入的合作，从而促进LLM的理论基础和实际应用，最终塑造其在应对复杂社会挑战中的作用。]]></description>
      <guid>https://arxiv.org/abs/2502.17814</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实际和合成数据的黄金比率混合以稳定生成模型训练</title>
      <link>https://arxiv.org/abs/2502.18049</link>
      <description><![CDATA[ARXIV：2502.18049V1公告类型：新 
摘要：最近的研究确定了称为模型崩溃的递归生成模型训练中的一种有趣的现象，其中对先前模型生成的数据训练的模型表现出严重的性能降解。解决这个问题并制定更有效的培训策略已成为生成模型研究中的核心挑战。在本文中，我们从理论上在一个新的框架中研究了这种现象，在该框架中，生成模型是通过上一个训练步骤的新收集的真实数据和合成数据的组合进行迭代训练的。为了制定整合实际和合成数据的最佳培训策略，我们在各种情况下评估了加权训练方案的性能，包括高斯分布估计和线性回归。从理论上讲，我们表征了合成数据的混合比例和加权方案对最终模型性能的影响。我们的关键发现是，在不同的设置中，在不同比例的合成数据下，渐近表达式遵循统一的表达，揭示了利用合成数据和生成模型性能之间的基本权衡。值得注意的是，在某些情况下，分配给真实数据的最佳权重与黄金比率的倒数相对应。最后，我们在广泛的模拟数据集和一个真实的表格数据集上验证了我们的理论结果。]]></description>
      <guid>https://arxiv.org/abs/2502.18049</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯推断功能空间的近乎最佳近似</title>
      <link>https://arxiv.org/abs/2502.18279</link>
      <description><![CDATA[ARXIV：2502.18279V1公告类型：新 
摘要：我们为在繁殖内核希尔伯特空间（RKHS）上定义的贝叶斯后期的可扩展推理算法。给定可能性函数和代表先验的高斯随机元素，可以作为RKHS值的langevin扩散的固定分布获得相应的贝叶斯后措施$ \ pi _ {\ text {b}} $。我们通过投影到Kosambi-Karhunen-lo \&#39;eve Eve扩展的第一个$ M $组件上的投影近似无限尺寸的Langevin扩散。利用这些$ m $组件所获得的近似后验，我们通过依靠总概率和充分假设的定律来对$ \ pi _ {\ text {b}} $执行推断。结果方法缩放为$ O（m^3+jm^2）$，其中$ j $是从后验度量$ \ pi _ {\ text {b}} $产生的样品数量。有趣的是，该算法恢复了由于稀疏的变化高斯过程（SVGP）引起的后部（参见Titsias，2009年）作为一种特殊情况，这是由于这两种方法构成了这两种方法的基础。但是，尽管SVGP在参数上被限制为高斯过程，但我们的方法基于非参数变化族$ \ Mathcal {p}（\ m athbb {r}^m）$，由$ \ athbb的$ \ athbb上的无用概率度量组成{r}^m $。结果，我们的方法可证明接近贝叶斯后$ \ pi _ {\ text {b}} $的最佳$ m $二维变异近似$用于凸和Lipschitz连续的负log可能性，与SVGP相吻合的特殊情况高斯错误的可能性。]]></description>
      <guid>https://arxiv.org/abs/2502.18279</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>内核正交的嵌套期望</title>
      <link>https://arxiv.org/abs/2502.18284</link>
      <description><![CDATA[ARXIV：2502.18284V1公告类型：新 
摘要：本文考虑了估计嵌套期望的具有挑战性的计算任务。现有的算法，例如嵌套的蒙特卡洛或多层蒙特卡洛，已知是一致的，但需要大量的内部和外部水平样品进行收敛。取而代之的是，我们提出了一个由嵌套内核正交估计器组成的新型估计器，并且我们证明，当积分具有足够的平滑度时，它的收敛速率比所有基线方法更快。然后，我们从经验上证明，我们提出的方法确实确实需要更少的样本来估计对现实世界应用的嵌套期望，包括贝叶斯优化，期权定价和健康经济学。]]></description>
      <guid>https://arxiv.org/abs/2502.18284</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用EOF和机器学习模型在气候数据中的时空预测：智利的案例研究</title>
      <link>https://arxiv.org/abs/2502.17495</link>
      <description><![CDATA[ARXIV：2502.17495V1公告类型：交叉 
摘要：有效的资源管理和环境规划，在高气候变异性的地区，例如智利，需求先进的预测工具。这项研究通过采用创新和计算有效的混合方法来解决这一挑战，该方法将机器学习（ML）方法与预测的时间序列与已建立的统计技术相结合。时空数据使用时间依赖性经验正交函数（EOFS）进行分解，称为\（\ phi_ {k}（t）\）及其相应的空间系数，\（\ alpha_ {k}（k}（s）\）降低维度。小波分析提供了来自\（\ phi_ {k}（t）\）功能的高分辨率时间和频率信息，而神经网络则预测这些功能在中范围的Hixon \（H \）中。通过利用各种ML模型，尤其是小波-Ann Hybrid模型，我们预测（\ phi_ {k}（t+h）\）直到time horizo​​n \（h \），然后使用这些扩展数据重建了时空数据EOF。该方法应用于涵盖智利领土的气候数据网格。它从高维多元时空数据预测问题转变为低维单变量的预测问题。此外，群集分析具有动态时间扭曲，以定义降雨时间序列之间的相似性，以及空间连贯性和可预测性评估，这对确定增强模型性能的地理区域起着重要作用。这种方法还阐明了在空间相干性和可预测性低的地区或群集中预测性能差的原因。通过利用聚类MEDOIDS，预测过程变得更加实用和有效。这种复合方法大大降低了计算复杂性，同时产生了合理准确性和效用的预测。]]></description>
      <guid>https://arxiv.org/abs/2502.17495</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>硬性约束学习方法具有可训练的影响力功能的进化方程</title>
      <link>https://arxiv.org/abs/2502.17497</link>
      <description><![CDATA[Arxiv：2502.17497V1公告类型：交叉 
摘要：本文开发了一种用于求解进化方程的新型深度学习方法，该方法将顺序学习策略与具有可训练参数的增强的硬约束策略整合在一起，从而解决了标准物理知识的神经网络（PINN）在大型时间领域中的低计算准确性。顺序学习策略将一个大的时间领域分为多个子间隔物，并按时间顺序逐一解决，这自然尊重因果关系并改善Pinn溶液的稳定性。改进的硬约束策略严格确保Pinn解决方案在时间间隔节点上的连续性和平滑度，同时将信息从上一个间隔传递到下一个间隔，从而避免了远离该位置的错误/琐事解决方案初始时间。此外，通过研究不同类型方程对硬约束的要求，我们设计了一种新颖的影响力功能，该功能具有可训练的参数以实现硬约束，这为有效的硬约束策略提供了理论和技术支持，并显着改善了普遍性和计算我们方法的准确性。此外，提出了一种自适应时间域分配算法，该算法在提出的方法的应用以及提高计算效率和准确性中起着重要作用。数值实验验证该方法的性能。本文随附的数据和代码可在https://github.com/zhizhi4452/hcs上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.17497</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>合奏RL通过分类器模型：增强交易策略中的风险返回权衡取舍</title>
      <link>https://arxiv.org/abs/2502.17518</link>
      <description><![CDATA[ARXIV：2502.17518V1公告类型：交叉 
摘要：本文介绍了一项有关在金融交易策略中使用集合加固学习（RL）模型的综合研究，利用分类器模型来提高绩效。通过将A2C，PPO和SAC等RL算法与诸如支持矢量机（SVM），决策树和逻辑回归等传统分类器等传统分类器相结合，我们研究了如何可以整合不同的分类器组以改善风险回收折衷。该研究评估了各种集合方法的有效性，并将其与关键财务指标的单个RL模型进行了比较，包括累积回报，Sharpe比率（SR），Calmar比率和最大降低（MDD）。我们的结果表明，合奏方法在风险调整后的收益方面始终超过基本模型，从而更好地管理缩减和整体稳定性。但是，我们确定了集合性能对选择方差阈值{\ tau}的选择的敏感性，从而突出了动态{\ tau}调整以实现最佳性能的重要性。这项研究强调了将RL与分类器组合以进行自适应决策的价值以及对金融交易，机器人技术和其他动态环境的影响。]]></description>
      <guid>https://arxiv.org/abs/2502.17518</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>最佳恢复符合最小值估计</title>
      <link>https://arxiv.org/abs/2502.17671</link>
      <description><![CDATA[ARXIV：2502.17671V1公告类型：交叉 
摘要：统计和机器学习中的一个基本问题是从可能的嘈杂观察到其点样本中估算功能$ f $。目标是设计一种数值算法，以在规定的规范中构建近似值$ \ hat f $ to $ f $，该规范均非实现最佳错误（作为数字$ m $观测值和Variance $ \ sigma的函数） ^2 $的噪音）。这个问题在非参数统计（嘈杂的观察结果）和最佳恢复（无噪声观察结果）中都受到了极大的关注。定量范围需要$ f $的假设，称为模型类假设。经典结果假设$ f $在BESOV空间的单位球中。在非参数统计中，找到$ \ hat f $的算法的最佳性能被称为最小值率，并在这种情况下已经研究了噪声是高斯。在最佳恢复中，算法的最佳性能被称为最佳恢复率，并且在这种情况下也已确定。虽然人们希望在噪声水平$ \ sigma $趋于零时，最小值速率会恢复最佳回收率，但事实证明，最小值的当前结果并不能仔细确定对$ \ sigma $的依赖被带走。本文处理此问题，并确定BESOV类的噪声级感知（NLA）最小值速率，当以$ L_Q $ -NORM测量具有匹配的上和下限时错误。最终结果是最小值率与最佳回收率之间的对帐。 NLA minimax速率连续取决于噪声水平，并在$ \ sigma $倾向于零时恢复最佳恢复速率。]]></description>
      <guid>https://arxiv.org/abs/2502.17671</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有限制域和平稳损失的差异私有SGD的隐私和实用性分析的改进</title>
      <link>https://arxiv.org/abs/2502.17772</link>
      <description><![CDATA[ARXIV：2502.17772V1公告类型：交叉 
摘要：差异化私有随机梯度下降（DPSGD）被广泛用于保护机器学习模型期间敏感数据，但其隐私保证通常以模型性能为代价，这在很大程度上是由于准确量化隐私损失的固有挑战。尽管最近的努力通过仅专注于最终产出和有限域案件来增强隐私的保证，但他们仍然施加限制性假设，例如凸性和其他参数限制，并且通常缺乏对效用的彻底分析。在本文中，我们为DPSGD提供了严格的隐私和实用性表征，以在有限和无界域中的平滑损耗功能。我们通过利用嘈杂的平滑还原属性来跟踪多个迭代的隐私损失，并通过利用投影的非扩张性和剪接SGD属性来建立实用程序分析。特别是，我们表明，对于具有有界域的DPSGD，（i）隐私损失仍然可以在没有凸度假设的情况下收敛，并且（ii）较小的有界直径可以在某些条件下同时改善隐私和实用性。数值结果验证了我们的结果。]]></description>
      <guid>https://arxiv.org/abs/2502.17772</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>积极推断最佳测量序列</title>
      <link>https://arxiv.org/abs/2502.18142</link>
      <description><![CDATA[Arxiv：2502.18142V1公告类型：交叉 
摘要：测量物理量（例如光强度）是许多重建和决策情景不可或缺的一部分，但就获取时间，入侵或对环境和存储的损害而言可能是昂贵的。数据最小化和遵守数据保护法也是一个重要的考虑因素。如果可以进行一系列测量，则有些可能比其他测量目标更有用，并且符合整体测量目标。我们开发了一种主动的顺序推理算法，该算法使用从变量自动编码器（VAE）中使用低维表示潜在空间来选择下一个测量值。我们的目的是通过进行尽可能少的测量来恢复高维数据。我们将VAE编码器调整为映射部分数据测量值，以适合完整数据的潜在空间。该算法从该潜在空间中绘制样本，并使用VAE解码器在部分测量中生成数据。对生成的数据进行了估计的测量，并通过部分VAE编码器回馈潜在空间，在进行测量之前可以对其进行评估。从没有测量和潜在空间上的正常先验开始，我们考虑选择下一个测量并更新下一步的预测后验。使用时尚MNIST数据集和新型的卷积Hadamard模式测量基础来说明该算法。我们看到有用的模式在10个步骤内选择，从而导致引导生成图像的收敛性。与使用随机变异推断分别推断每个生成的数据点的后验分布的参数相比，部分VAE框架可以有效地处理生成的数据的批处理，并获得最小测量的较高结果。]]></description>
      <guid>https://arxiv.org/abs/2502.18142</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多画依赖变量的浓度更清晰的浓度不平等</title>
      <link>https://arxiv.org/abs/2502.18167</link>
      <description><![CDATA[Arxiv：2502.18167V1公告类型：交叉 
摘要：在多任务学习（MTL）中，每个任务都涉及图依赖图的数据，现有理论分析的概括结果产生了$ O（\ frac {1} {\ sqrt {n}}）$ O（\ frac {1}}）$ ，其中$ n $是培训样本的数量。这归因于缺乏基础较尖锐的浓度不平等变量。为了填补这一空白，本文提出了一种新的相应的Bennett不等式，从而使$ o（\ frac {\ log n} {n} {n}）$的更尖锐风险限制。具体而言，在拟议的Bennett不平等的基础上，我们为经验过程提出了一种新的相应的Talagrand不平等，并进一步开发了局部Rademacher复杂性的分析框架，以增强MTL在MTL中具有多仪依赖数据的理论通用分析。最后，我们将理论进步应用于诸如宏观-AUC优化之类的应用，这证明了我们的理论结果优于以前的工作，这也通过实验结果证实了这一点。]]></description>
      <guid>https://arxiv.org/abs/2502.18167</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>空间点过程的私人合成差异</title>
      <link>https://arxiv.org/abs/2502.18198</link>
      <description><![CDATA[Arxiv：2502.18198V1公告类型：交叉 
摘要：本文提出了一种生成差异隐私（DP）框架内空间点模式的合成数据的方法。具体而言，我们定义了一个差异私人泊松点合成器（PPS）和Cox点合成器（CPS），以生成合成点模式，并使用$ \ alpha $ -neighborhood的概念来放松DP的原始定义。我们提出了三个示例模型来构建差异化的私人PP和CP，为其参数提供足够的条件，以确保DP给定指定的隐私预算。此外，我们证明合成器可以应用于线性网络上的点模式。仿真实验表明，所提出的方法有效地维持了合成数据的隐私和效用。]]></description>
      <guid>https://arxiv.org/abs/2502.18198</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度学习中的贝叶斯计算</title>
      <link>https://arxiv.org/abs/2502.18300</link>
      <description><![CDATA[ARXIV：2502.18300V1公告类型：交叉 
摘要：这篇评论论文旨在用于马尔可夫链手册蒙特卡洛手册的第二版。我们将介绍大概推理技术作为应用于深度学习模型的贝叶斯计算方法。我们通过为（1）贝叶斯神经网络和（2）深层生成模型提供流行的计算方法来组织本章，并解释了它们在后推理和解决方案中的独特挑战。]]></description>
      <guid>https://arxiv.org/abs/2502.18300</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>