<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Wed, 10 Jan 2024 06:17:53 GMT</lastBuildDate>
    <item>
      <title>注意熵通信。 （arXiv：2307.11423v2 [cs.IT] 已更新）</title>
      <link>http://arxiv.org/abs/2307.11423</link>
      <description><![CDATA[注意力的概念，强调重要性的数值权重
事实证明，特定的数据与人工智能非常相关。
相对熵（RE，又名 Kullback-Leibler 散度）在
传播理论。这里我们把注意力和RE这几个概念结合起来。关于
还指导带宽有限的通信中消息的最佳编码
作为通过最大熵原理（MEP）的最佳消息解码。在里面
编码场景，RE 可以从四个要求导出，即
分析的、本地的、适当的和校准的。加权RE，用于注意力
事实证明，沟通的指导是不正确的。看看如何正确
注意力沟通可以出现，我们分析一个消息发送者的场景
谁想要确保消息的接收者能够执行消息灵通的操作
行动。如果接收方使用 MEP 解码消息，则发送方仅
需要知道接收者的效用函数才能提供最佳信息，但不需要知道
接收者的初始知识状态。如果只有效用的曲率
函数最大值已知，因此需要准确地传达
注意函数，在本例中是通过该曲率加权并重新归一化的
概率函数。这里提出熵注意力通信作为
熵通信的期望概括，允许加权，同时
是适当的，从而有助于设计最佳通信协议
技术应用并帮助理解人类交流。为了
例如，我们的分析显示了如何得出预期的合作水平
与其他诚实的沟通伙伴利益不一致。
]]></description>
      <guid>http://arxiv.org/abs/2307.11423</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>基础模型时代的风险评估和统计意义。 （arXiv：2310.07132v2 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2310.07132</link>
      <description><![CDATA[我们提出了一个分布式框架来评估社会技术风险
具有量化统计显着性的基础模型。我们的方法取决于
基于一阶和二阶的新统计相对检验
真实随机变量的随机优势。我们证明第二阶
该测试中的统计数据与常用的平均风险模型相关联
计量经济学和数学金融学在选择时平衡风险和效用
之间的选择。使用这个框架，我们正式开发了一个具有风险意识的
给定护栏的基础模型选择方法量化为
指定的指标。受到投资组合优化和选择理论的启发
数学金融，我们为每个模型定义一个指标组合作为手段
聚合指标集合，并根据指标进行模型选择
这些投资组合的随机主导地位。我们的统计显着性
检验在理论上得到了通过中心极限的渐近分析的支持
通过引导方差估计在实践中实例化定理。我们用我们的
比较各种大型语言模型有关风险的框架
偏离指令并输出有毒内容。
]]></description>
      <guid>http://arxiv.org/abs/2310.07132</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络分类器学习似然比。 （arXiv：2305.10500v2 [hep-ph] 已更新）</title>
      <link>http://arxiv.org/abs/2305.10500</link>
      <description><![CDATA[似然比是统计推断的关键量
能够进行假设检验、构建置信区间的科学，
重新分配权重等等。许多现代科学应用，
然而，利用数据或模拟驱动的模型来计算
似然比可能非常困难甚至不可能。通过应用
所谓的“似然比技巧”，似然比的近似值
可以使用基于神经网络的巧妙参数化来计算
分类器。可以定义许多不同的神经网络设置
满足这个过程，每个过程在近似
使用有限训练数据时的似然比。我们呈现一系列
详细介绍几种常见损失函数性能的实证研究
以及分类器输出的参数化以近似似然
两个单变量和多元高斯分布的比率以及
模拟高能粒子物理数据集。
]]></description>
      <guid>http://arxiv.org/abs/2305.10500</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>重新审视在线拉普拉斯模型选择。 （arXiv：2307.06093v2 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2307.06093</link>
      <description><![CDATA[拉普拉斯近似提供了封闭形式的模型选择目标
对于神经网络（NN）。在线变体，联合优化神经网络参数
超参数，如重量衰减强度，重新引起了人们的兴趣
贝叶斯深度学习社区。然而，这些方法违反了拉普拉斯定律
方法的关键假设是围绕模式执行近似
的损失，让人质疑他们的稳健性。本作品重新衍生于网络
拉普拉斯方法，显示它们以模式校正的变分界限为目标
拉普拉斯证据的变体，不做出平稳性假设。
在线拉普拉斯及其模式校正对应物共享驻点，其中
1. NN参数是最大后验，满足拉普拉斯
方法的假设，以及 2. 超参数最大化拉普拉斯证据，
激励在线方法。我们证明这些最优值大致是
通过使用全批量梯度下降的在线算法在实践中获得
UCI 回归数据集。优化的超参数可以防止过度拟合
优于基于验证的早期停止。
]]></description>
      <guid>http://arxiv.org/abs/2307.06093</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>浅层 ReLU$^k$ 神经网络的最佳逼近率及其在非参数回归中的应用。 （arXiv：2304.01561v3 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2304.01561</link>
      <description><![CDATA[我们研究了一些变化空间的近似能力，对应于
浅层 ReLU$^k$ 神经网络。表明足够光滑
函数包含在这些具有有限变差范数的空间中。为了
平滑度较低的函数，近似率
建立变异范数。利用这些结果，我们能够证明
浅层神经元数量的最佳逼近率
ReLU$^k$ 神经网络。它还显示了如何使用这些结果
导出深度神经网络和卷积神经网络的近似界限
网络（CNN）。作为应用，我们研究非参数的收敛率
使用三种 ReLU 神经网络模型进行回归：浅层神经网络、
超参数化神经网络和 CNN。特别是，我们表明浅
神经网络可以实现学习 H\&quot;older 的极小极大最优速率
函数，它补充了深度神经网络的最新结果。这是
还证明了过度参数化（深层或浅层）神经网络可以
实现非参数回归的近乎最佳速率。
]]></description>
      <guid>http://arxiv.org/abs/2304.01561</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>通过可控的信任权衡审核和生成合成数据。 （arXiv：2304.10819v3 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2304.10819</link>
      <description><![CDATA[现实世界的数据经常表现出偏见、不平衡和隐私风险。合成的
数据集的出现就是为了解决这些问题。该范式依赖于
生成式人工智能模型可生成公正的、保护隐私的数据，同时
保持对原始数据的保真度。然而，评估
合成数据集和模型的可信度是一个严峻的挑战。我们
引入整体审计框架，全面评估
合成数据集和人工智能模型。它的重点是防止偏见和
歧视，确保对源数据的忠实度，评估效用，
鲁棒性和隐私保护。我们展示了该框架的
通过审核不同用例中的各种生成模型来提高有效性
例如教育、医疗保健、银行和人力资源，涵盖不同领域
数据模式，例如表格、时间序列、视觉和自然语言。
这种整体评估对于遵守法规至关重要
保障措施。我们引入可信度指数来对合成数据集进行排名
基于他们的保障权衡。此外，我们还提出了一个
可信度驱动的模型选择和交叉验证过程
培训，以跨各种数据类型的“TrustFormers”为例。这
该方法允许在合成数据中进行可控的可信度权衡
创建。我们的审计框架促进利益相关者之间的合作，
包括数据科学家、治理专家、内部评审员、外部评审员
认证机构和监管机构。这种透明的报告应该成为一种标准
防止偏见、歧视和侵犯隐私的做法，确保
遵守政策并提供责任、安全和绩效
保证。
]]></description>
      <guid>http://arxiv.org/abs/2304.10819</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>通过元学习 Transformer 进行通用情境学习。 （arXiv：2212.04458v2 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2212.04458</link>
      <description><![CDATA[现代机器学习要求系统设计者指定以下方面：
学习管道，例如损失、架构和优化器。
元学习或学习学习的目的是学习这些方面，并且
承诺以更少的手动工作来释放更大的功能。一
元学习的一个特别雄心勃勃的目标是训练通用目的
从头开始的上下文学习算法，仅使用黑盒模型
最小的感应偏置。这样的模型接收训练数据，并产生
跨广泛问题的测试集预测，没有任何明确的
推理模型、训练损失或优化算法的定义。在
本文我们展示了 Transformers 和其他黑盒模型可以
经过元训练以充当通用的上下文学习者。我们表征
泛化算法、记忆算法和
由于模型大小的变化而根本无法进行元训练的算法，
任务数量和元优化。我们进一步证明了能力
的元训练算法受到可访问状态大小的瓶颈
（记忆）确定下一个预测，与标准模型不同
被认为是参数计数的瓶颈。最后，我们提出实用的
诸如偏置训练分布之类的干预措施可以改善
通用情境学习的元训练和元泛化
算法。
]]></description>
      <guid>http://arxiv.org/abs/2212.04458</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>基于混合谱方法和谐波振荡器的时空高斯过程的不可分离协方差核。 （arXiv：2302.09580v3 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2302.09580</link>
      <description><![CDATA[高斯过程提供了一个灵活的非参数框架
高维空间中函数的逼近。协方差核是
高斯过程的主要引擎，包含支撑的相关性
预测分布。对于具有时空数据集的应用程序，
合适的内核应该模拟联合空间和时间依赖性。可分离
时空协方差核提供简单性和计算效率。
然而，不可分离的内核包括更好的时空相互作用
捕获观察到的相关性。大多数承认显式的不可分离内核
表达式基于数学考虑（可接受条件）
而不是第一性原理推导。我们提出了一种混合光谱方法
用于生成基于物理参数的协方差核。我们用
这种方法派生出一类新的物理驱动的、不可分离的
协方差核的根源在于随机、线性、阻尼、
谐振子（LDHO）。新内核结合了以下功能
时空相关性的单调和振荡衰减。 LDHO 协方差
核涉及由色散引入的时空相互作用
调制振荡器系数的关系。我们得出明确的
三个振荡器中时空协方差核的关系
制度（欠阻尼、临界阻尼、过阻尼）并研究它们
特性。我们通过推导进一步说明混合谱方法
基于 Ornstein-Uhlenbeck 模型的协方差核。
]]></description>
      <guid>http://arxiv.org/abs/2302.09580</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>线性递归特征机可证明恢复低秩矩阵。 （arXiv：2401.04553v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.04553</link>
      <description><![CDATA[机器学习的一个基本问题是理解神经网络如何
网络做出准确的预测，同时似乎绕过了诅咒
维度。一个可能的解释是，常见的训练算法
神经网络隐式地执行降维——这个过程称为
特征学习。最近的工作表明，特征学习的效果可以
从称为平均梯度的经典统计估计器中得出
外积（AGOP）。作者提出递归特征机（RFM）：
一种通过交替执行特征学习的算法
(1) 通过 AGOP 重新加权特征向量以及 (2) 学习预测
在变换后的空间中发挥作用。在这项工作中，我们开发了第一个
RFM 如何执行降维的理论保证
关注稀疏线性中出现的一类超参数化问题
回归和低秩矩阵恢复。具体来说，我们表明 RFM
仅限于线性模型（lin-RFM）概括了经过充分研究的迭代
重新加权最小二乘 (IRLS) 算法。我们的结果揭示了
神经网络中的特征学习与经典稀疏之间的联系
恢复算法。此外，我们还提供了 lin-RFM 的实现
扩展到具有数百万个缺失条目的矩阵。我们的实现是
比标准 IRLS 算法更快，因为它不包含 SVD。它也表现出色
用于稀疏线性回归和低秩矩阵的深度线性网络
完成。
]]></description>
      <guid>http://arxiv.org/abs/2401.04553</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>用于多视图聚类的多层随机块模型的混合。 （arXiv：2401.04682v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.04682</link>
      <description><![CDATA[在这项工作中，我们提出了一种聚合多个的原始方法
来自不同信息源的聚类。每个分区是
由观察之间的共同隶属矩阵编码。我们的方法使用
多层随机块模型 (SBM) 的混合到组共同成员
将具有相似信息的矩阵分解为各个分量并划分观测值
考虑到它们在范围内的特殊性，分为不同的集群
成分。建立模型参数的可识别性并
提出了变分贝叶斯 EM 算法来估计这些
参数。贝叶斯框架允许选择最佳数量
集群和组件。使用合成数据对所提出的方法进行比较
使用共识聚类和基于张量的社区检测算法
在大规模复杂网络中。最后利用该方法进行分析
全球食品贸易网络，导致利益结构。
]]></description>
      <guid>http://arxiv.org/abs/2401.04682</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>用于节点分类的分布自由预测集。 （arXiv：2211.14555v3 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2211.14555</link>
      <description><![CDATA[图神经网络（GNN）能够实现高分类精度
在许多重要的现实世界数据集上，但没有提供严格的概念
预测的不确定性。量化 GNN 模型的置信度很困难
由于图结构引起的数据点之间的依赖性。我们
利用保形预测的最新进展来构建预测集
用于归纳学习场景中的节点分类。我们通过采取
现有的共形分类方法依赖于
\textit{可交换}数据并通过适当加权来修改它
共形分数反映网络结构。我们通过实验证明
我们的方法使用流行的 GNN 模型在标准基准数据集上进行
提供比简单应用程序更严格、更好的校准预测集
的共形预测。
]]></description>
      <guid>http://arxiv.org/abs/2211.14555</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>使用扩散图的稳定生成建模。 （arXiv：2401.04372v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.04372</link>
      <description><![CDATA[我们考虑从未知分布中采样的问题，其中
只有足够多的训练样本可用。这样的
环境最近引起了人们对生成环境的极大兴趣
造型。在本文中，我们提出了一种结合扩散的生成模型
地图和朗之万动力学。扩散图用于近似漂移
来自可用训练样本的术语，然后在
离散时间 Langevin 采样器生成新样本。通过设置内核
带宽以匹配未调整的 Langevin 中使用的时间步长
算法，我们的方法通常有效地规避了任何稳定性问题
与时间步进刚性随机微分方程相关。更多的
准确地说，我们引入了一种新颖的分步方案，确保生成的
样本保留在训练样本的凸包内。我们的框架
可以自然地扩展以生成条件样本。我们展示了
通过对合成数据集的实验我们提出的方案的性能
随着维度的增加和随机亚网格尺度参数化
条件抽样问题。
]]></description>
      <guid>http://arxiv.org/abs/2401.04372</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>半监督深度 Sobolev 回归：估计、变量选择及其他。 （arXiv：2401.04535v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.04535</link>
      <description><![CDATA[我们提出 SDORE，一种半监督深度 Sobolev 回归器，用于
基础回归函数的非参数估计及其
坡度。 SDORE 采用深度神经网络来最小化经验风险
梯度范数正则化，允许计算梯度范数
未标记的数据。我们对收敛速度进行了全面的分析
SDORE 并建立回归函数的极小极大最优率。
至关重要的是，我们还得出了相关插件的收敛速度
梯度估计器，即使存在显着的域偏移。这些
理论研究结果为选择正则化提供了有价值的预先指导
参数并确定神经网络的大小，同时展示
在半监督学习中利用未标记数据的可证明的优势。到
据我们所知，SDORE 是第一个可证明的基于神经网络的
同时估计回归函数及其
梯度，具有多种应用，包括非参数变量选择
和反问题。 SDORE 的有效性通过
广泛的数值模拟和真实数据分析。
]]></description>
      <guid>http://arxiv.org/abs/2401.04535</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>预测动态图的结构。 （arXiv：2401.04280v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.04280</link>
      <description><![CDATA[动态图嵌入、归纳和增量学习有利于
预测任务，例如节点分类和链接预测。然而，
从时间序列中预测未来时间步的图结构
图，允许新节点并没有引起太多关注。在本文中，我们
提出这样一种方法。我们使用时间序列方法来预测节点度
在未来的时间点并将其与通量平衡分析相结合——线性
生物化学中的编程方法——获得未来的结构
图表。此外，我们探索了不同的预测图分布
参数值。我们使用合成数据集和真实数据集来评估该方法，
展示其实用性和适用性。
]]></description>
      <guid>http://arxiv.org/abs/2401.04280</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>宽和深 ReLU 神经网络的普遍一致性以及 Kolmogorov-Donoho 最优函数类的 Minimax 最优收敛率。 （arXiv：2401.04286v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2401.04286</link>
      <description><![CDATA[在本文中，我们首先扩展了FL93的结果并证明了通用性
基于广度和深度 ReLU 神经网络的分类规则的一致性
针对物流损失进行训练的网络。与 FL93 中的方法不同的是
分解估计和经验误差，我们直接分析
基于观察的分类风险，即神经网络的实现
足够宽的网络能够插入任意数量的
点。其次，我们给出一类概率的充分条件
基于神经网络的分类器实现极小极大的措施
最优收敛率。我们的结果源于实践者的
观察到神经网络经常被训练以实现 0 训练误差，
我们提出的神经网络分类器就是这种情况。我们的校样铰链
关于经验风险最小化和近似的最新发展
深度 ReLU 神经网络对各种感兴趣的函数类别的速率。
在经典平滑函数空间中的应用说明了
我们的结果的有用性。
]]></description>
      <guid>http://arxiv.org/abs/2401.04286</guid>
      <pubDate>Wed, 10 Jan 2024 06:17:47 GMT</pubDate>
    </item>
    </channel>
</rss>