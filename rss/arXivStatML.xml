<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 25 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>自适应共形推理没有任何共形性</title>
      <link>https://arxiv.org/abs/2409.15548</link>
      <description><![CDATA[arXiv:2409.15548v1 公告类型：新
摘要：共形预测是一种广泛使用的无分布不确定性量化框架，它在用户定义的显着性水平上生成有效的预测集。然而，这个框架依赖于数据生成分布是可交换的假设，这一条件在时间序列和其他结构化数据中经常被违反。在这种情况下，共形预测的有效性保证就会失效。
自适应共形推理 (ACI) 已被提出作为不可交换数据的解决方案，通过动态调整显着性水平以保留至少有限样本保证的边际覆盖误差率。本文表明，尽管 ACI 的名字如此，但它并不严格要求使用共形预测器。相反，它可以有效地与更一般的置信度预测器概念一起运行，这通常在计算上更简单。关键要求是较大的显着性水平对应于较小的预测集，这一属性称为嵌套预测集。
通过对合成数据和真实数据进行实验，我们研究了具有共形预测器的 ACI 是否比置信度预测器更具优势。我们的结果表明，在某些情况下，置信度预测器的表现同样出色，有时甚至优于共形预测器，尽管需要进一步的实证研究来确定何时一种方法可能更可取。]]></description>
      <guid>https://arxiv.org/abs/2409.15548</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概念转变下的泛化与专业化</title>
      <link>https://arxiv.org/abs/2409.15582</link>
      <description><![CDATA[arXiv:2409.15582v1 公告类型：新
摘要：机器学习模型在分布偏移下通常很脆弱，即测试时的数据分布与训练期间的数据分布不同。了解这种故障模式对于识别和减轻大规模采用机器学习的安全风险至关重要。在这里，我们分析了概念偏移下的岭回归——一种分布偏移的形式，其中输入标签关系在测试时发生变化。我们推导出高维极限中预测风险的精确表达式。我们的结果揭示了概念偏移对泛化性能的非平凡影响，这取决于输入的稳健和非稳健特征的性质。我们表明，即使没有双下降，测试性能也可以表现出非单调的数据依赖性。最后，我们在 MNIST 和 FashionMNIST 上的实验表明，这种有趣的行为也存在于分类问题中。]]></description>
      <guid>https://arxiv.org/abs/2409.15582</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自适应学习后测试：统计上有效且高效的超参数选择</title>
      <link>https://arxiv.org/abs/2409.15844</link>
      <description><![CDATA[arXiv:2409.15844v1 公告类型：新
摘要：我们引入了自适应学习然后测试 (aLTT)，这是一种有效的超参数选择程序，可为 AI 模型的总体风险提供有限样本统计保证。与依赖于传统基于 p 值的多重假设检验 (MHT) 的现有学习然后测试 (LTT) 技术不同，aLTT 通过利用电子流程实现了具有提前终止的顺序数据相关 MHT。因此，aLTT 可以减少测试轮数，使其特别适合测试成本高或存在安全风险的场景。除了保持统计有效性外，在离线强化学习的在线策略选择和工程系统的超参数调整等应用中，aLTT 被证明可以实现与 LTT 相同的性能，同时仅需要一小部分测试轮次。]]></description>
      <guid>https://arxiv.org/abs/2409.15844</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>委托代理协作学习问题的决策理论模型</title>
      <link>https://arxiv.org/abs/2409.16068</link>
      <description><![CDATA[arXiv:2409.16068v1 公告类型：新摘要：在本技术说明中，我们考虑了一个具有委托代理设置的协作学习框架，其中委托人在每个时间步骤根据一组 $K$ 个代理的当前参数估计如何有效地与单独的测试数据集相关联来确定一组适当的聚合系数，该测试数据集不是代理的训练模型数据集的一部分。而作为一个团队一起行动的代理则使用具有均值场交互项的离散时间版本的朗之万动力学来更新其参数估计，但由各自不同的训练模型数据集指导。在这里，我们提出了一个决策理论框架，明确描述了委托人如何逐步确定代理在其均值场交互项中使用的一组非负且总和为一的聚合系数，最终使它们达成一致的最佳参数估计。有趣的是，由于代理之间固有的反馈和合作行为，尽管委托人和代理都不一定需要了解样本分布或彼此数据集的质量，但所提出的框架在稳定性和泛化方面提供了一些优势。]]></description>
      <guid>https://arxiv.org/abs/2409.16068</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果关系挖掘：人工智能辅助搜索工具变量</title>
      <link>https://arxiv.org/abs/2409.14202</link>
      <description><![CDATA[arXiv:2409.14202v1 公告类型：交叉 
摘要：工具变量 (IVs) 方法是因果推理的主要实证策略。寻找 IVs 是一个启发式和创造性的过程，证明其有效性（尤其是排除限制）在很大程度上是修辞性的。我们建议使用大型语言模型 (LLM) 通过叙述和反事实推理来搜索新的 IV，类似于人类研究人员的方式。然而，明显的区别在于 LLM 可以成倍地加速这一过程并探索极大的搜索空间。我们演示了如何构建提示来搜索潜在有效的 IV。我们认为多步骤提示很有用，角色扮演提示适合模仿经济主体的内生决策。我们将我们的方法应用于经济学中的三个众所周知的例子：教育回报、生产函数和同伴效应。然后，我们扩展我们的策略来寻找（i）回归和差异中的控制变量和（ii）回归不连续设计中的运行变量。]]></description>
      <guid>https://arxiv.org/abs/2409.14202</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>近似正交投影单元：利用自然梯度稳定回归网络训练</title>
      <link>https://arxiv.org/abs/2409.15393</link>
      <description><![CDATA[arXiv:2409.15393v1 公告类型：交叉 
摘要：神经网络 (NN) 因其特征提取和函数逼近能力而在前沿软测量模型中得到广泛研究。当前基于网络的方法的研究主要集中在模型的离线准确性上。值得注意的是，在工业软传感器环境中，在线优化稳定性和可解释性是优先考虑的，其次是准确性。这需要更清楚地了解网络的训练过程。为了弥补这一差距，我们提出了一种名为近似正交投影单元 (AOPU) 的新型 NN，它具有坚实的数学基础并具有出色的训练稳定性。AOPU 在双参数处截断梯度反向传播，优化可跟踪参数更新，并增强训练的鲁棒性。我们进一步证明 AOPU 在 NN 中实现了最小方差估计 (MVE)，其中截断梯度近似于自然梯度 (NG)。在两个化学过程数据集上的经验结果清楚地表明，AOPU 在实现稳定收敛方面优于其他模型，标志着软测量领域的重大进步。]]></description>
      <guid>https://arxiv.org/abs/2409.15393</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用因果图识别自相关时间序列中的弹性</title>
      <link>https://arxiv.org/abs/2409.15530</link>
      <description><![CDATA[arXiv:2409.15530v1 公告类型：交叉 
摘要：可以使用工具变量 (IV) 从观测数据中估计需求价格弹性。然而，在具有自相关时间序列的设置中，简单的 IV 估计量可能不一致。我们认为因果时间图可以简化 IV 识别并帮助选择一致的估计量。为此，我们建议首先通过未观察到的混杂因素对平衡条件进行建模，得出有向无环图 (DAG)，同时保持同时确定价格和数量的假设。然后，我们利用图形推理的最新进展来推导有效的 IV 估计量，包括通过同时估计干扰效应来实现一致性的估计量。我们进一步认为，观察可能有效的估计量之间的显着差异有助于拒绝错误的模型假设，从而提高我们对潜在经济动态的理解。我们将这种方法应用于德国电力市场，根据模拟和现实世界的数据估计需求价格弹性。研究结果强调了在基于 IV 的分析中考虑结构自相关性的重要性。]]></description>
      <guid>https://arxiv.org/abs/2409.15530</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>药物研发中的量子机器学习：在学术界和制药行业中的应用</title>
      <link>https://arxiv.org/abs/2409.15645</link>
      <description><![CDATA[arXiv:2409.15645v1 公告类型：交叉 
摘要：量子计算和机器学习的结合——量子机器学习——为化学领域的重大进步提供了潜力。这篇评论专门探讨了在药物发现的背景下，基于门的量子计算机上量子神经网络的潜力。我们讨论了量子机器学习的理论基础，包括数据编码、变分量子电路和混合量子经典方法。重点介绍了药物发现的应用，包括分子特性预测和分子生成。我们提供了一个平衡的观点，强调了潜在的好处和必须解决的挑战。]]></description>
      <guid>https://arxiv.org/abs/2409.15645</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有随机模型的随机优化的信赖域序列二次规划</title>
      <link>https://arxiv.org/abs/2409.15734</link>
      <description><![CDATA[arXiv:2409.15734v1 公告类型：交叉 
摘要：在这项工作中，我们考虑解决具有随机目标和确定性等式约束的优化问题。我们提出了一种信赖区域顺序二次规划方法来寻找一阶和二阶驻点。我们的方法利用随机模型来表示目标函数，该模型由目标的随机观测构建，旨在以高但固定的概率满足适当的自适应精度条件。为了收敛到一阶驻点，我们的方法在每次迭代中计算一个梯度步骤，该梯度步骤由最小化目标的二次近似来定义，该近似受问题约束的（宽松）线性近似和信赖区域约束的约束。为了收敛到二阶驻点，我们的方法还计算了一个特征步长来探索简化的 Hessian 矩阵的负曲率，以及一个二阶校正步长来解决由于问题约束的非线性而产生的潜在 Maratos 效应。这种影响可能会阻碍该方法远离鞍点。梯度和特征步长计算都利用了一种新颖的无参数步长和信赖域半径分解，考虑了可行性残差、最优性残差和负曲率之间的比例。我们为我们的方法建立了全局几乎肯定的一阶和二阶收敛保证，并展示了 CUTEst 问题、回归问题和鞍点问题的计算结果，以证明其优于现有的基于线搜索的随机方法。]]></description>
      <guid>https://arxiv.org/abs/2409.15734</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有函数逼近的上下文老虎机的二阶界限</title>
      <link>https://arxiv.org/abs/2409.16197</link>
      <description><![CDATA[arXiv:2409.16197v1 公告类型：交叉 
摘要：许多工作已经开发出针对具有函数近似的上下文强盗的无遗憾算法，其中上下文-动作对的平均奖励属于一个函数类。虽然解决这个问题的方法有很多，但其中一种越来越重要的方法是使用基于乐观原则的算法，例如乐观最小二乘法。可以证明，该算法的遗憾与排除维度（函数类复杂度的统计度量）、函数类大小的对数和时间范围的乘积的平方根成比例。不幸的是，即使每次奖励的测量噪声的方差都在变化并且非常小，乐观最小二乘算法的遗憾也会与时间范围的平方根成比例。在这项工作中，我们首次开发出满足遗憾边界的算法，该边界不是用时间范围的平方根来衡量，而是在方差未知时使用函数逼近的上下文强盗的设置中用测量方差总和的平方根来衡量。这些边界推广了在上下文线性问题中推导二阶边界的现有技术。]]></description>
      <guid>https://arxiv.org/abs/2409.16197</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自适应联合分布学习</title>
      <link>https://arxiv.org/abs/2110.04829</link>
      <description><![CDATA[arXiv:2110.04829v5 公告类型：替换 
摘要：我们开发了一个使用张量积再生核希尔伯特空间 (RKHS) 估计联合概率分布的新框架。我们的框架适用于 Radon-Nikodym 导数的低维、正则化和正模型，我们从高达数百万的样本量中估计该模型，从而缓解了 RKHS 建模的固有局限性。定义明确的正则化和正条件分布是我们方法的自然副产品。我们的提议计算速度快，适用于从预测到分类的学习问题。我们的理论发现得到了有利的数值结果的补充。]]></description>
      <guid>https://arxiv.org/abs/2110.04829</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Wasserstein 距离下的稳健估计</title>
      <link>https://arxiv.org/abs/2302.01237</link>
      <description><![CDATA[arXiv:2302.01237v2 公告类型：替换 
摘要：我们研究 Wasserstein 距离下的稳健分布估计问题，Wasserstein 距离是最佳传输 (OT) 理论中流行的概率分布差异度量。给定来自未知分布 $\mu$ 的 $n$ 个样本，其中 $\varepsilon n$ 受到对抗性破坏，我们寻求具有最小 Wasserstein 误差的 $\mu$ 估计值。为了解决这个任务，我们借鉴了 OT 和稳健统计的两个框架：部分 OT (POT) 和最小距离估计 (MDE)。我们证明了 POT 的新结构属性，并使用它们来证明部分 Wasserstein 距离下的 MDE 在许多设置中实现了极小最大最优稳健估计风险。在此过程中，我们推导出 POT 的一种新对偶形式，它在标准 OT 的经典 Kantorovich 对偶中添加了 sup-norm 惩罚。由于流行的 Wasserstein 生成对抗网络 (WGAN) 框架通过 Kantorovich 对偶实现了 Wasserstein MDE，我们的惩罚对偶通过对 WGAN 进行基本修改，实现了使用受污染数据集的大规模生成建模。提供了数值实验，证明了我们的方法在减轻对抗性破坏影响方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2302.01237</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于 1 位矩阵补全的优化-最小化高斯-牛顿法</title>
      <link>https://arxiv.org/abs/2304.13940</link>
      <description><![CDATA[arXiv:2304.13940v3 公告类型：替换 
摘要：在 1 位矩阵完成中，目标是从部分二进制观测集估计底层低秩矩阵。我们提出了一种新的 1 位矩阵完成方法，称为主要化-最小化高斯-牛顿 (MMGN)。我们的方法基于主要化-最小化原理，将原始优化问题转换为一系列标准低秩矩阵完成问题。我们通过明确执行假设的低秩结构的分解方法解决每个子问题，然后应用高斯-牛顿法。使用模拟和真实数据示例，我们说明与现有的 1 位矩阵完成方法相比，MMGN 输出的估计值相当，甚至更准确。此外，它通常速度明显更快，并且对底层矩阵的尖峰不太敏感。与直接最小化原始目标的三种标准通用优化方法相比，MMGN 也表现出明显的计算优势，尤其是当观察到的条目比例较小时。]]></description>
      <guid>https://arxiv.org/abs/2304.13940</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用排列不变编码器和更严格的变分目标学习多模态生成模型</title>
      <link>https://arxiv.org/abs/2309.00380</link>
      <description><![CDATA[arXiv:2309.00380v3 公告类型：替换 
摘要：为多模态数据设计深度隐变量模型一直是机器学习研究的一个长期主题。多模态变分自动编码器 (VAE) 是一种流行的生成模型类，它学习共同解释多种模态的潜在表示。人们提出了此类模型的各种目标函数，通常将其作为多模态数据对数似然的下限或出于信息理论考虑。为了对来自不同模态子集的潜在变量进行编码，专家产品 (PoE) 或专家混合 (MoE) 聚合方案已被常规使用，并被证明会产生不同的权衡，例如，关于它们的生成质量或跨多种模态的一致性。在这项工作中，我们考虑了一个可以紧密近似数据对数似然的变分目标。我们开发了更灵活的聚合方案，通过基于置换不变神经网络结合来自不同模态的编码特征，避免了 PoE 或 MoE 方法中的归纳偏差。我们的数值实验说明了多模态变分目标和各种聚合方案之间的权衡。我们表明，当人们想要近似可识别模型中观察到的模态和潜在变量的真实联合分布时，我们的变分目标和更灵活的聚合模型会变得有益。]]></description>
      <guid>https://arxiv.org/abs/2309.00380</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在函数空间中嵌入知识图谱</title>
      <link>https://arxiv.org/abs/2409.14857</link>
      <description><![CDATA[arXiv:2409.14857v2 公告类型：替换 
摘要：我们引入了一种不同于传统方法的新型嵌入方法，该方法在有限维函数空间而不是有限向量空间内进行操作，因此与标准知识图嵌入技术有很大不同。最初使用多项式函数来计算嵌入，然后使用具有不同层复杂度的神经网络进行更复杂的表示。我们认为，使用函数进行嵌入计算可以增强表达能力并允许更多的自由度，从而实现诸如组合、导数和实体表示的原始等操作。此外，我们精心概述了我们方法的逐步构建，并提供了可重复的代码，从而促进了该领域的进一步探索和应用。]]></description>
      <guid>https://arxiv.org/abs/2409.14857</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>