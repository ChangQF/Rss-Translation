<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 15 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>关于替代物在利用有限的结果数据有效估计治疗效果中的作用</title>
      <link>https://arxiv.org/abs/2003.12408</link>
      <description><![CDATA[arXiv:2003.12408v3 公告类型：替换
摘要：在许多实验和观察性研究中，观察感兴趣的结果通常很困难或昂贵，从而减少了估计平均治疗效果 (ATE) 的有效样本量，即使是可识别的。我们研究了如何将仅观察到非主要兴趣的替代结果的单位数据合并起来，从而提高 ATE 估计的精度。我们不会施加严格的代孕条件，这允许代孕者完美替代目标结果。相反，我们用对替代结果的大量观察来补充可用的（尽管有限的）目标结果观察（它们本身识别 ATE），除了随机分配和缺失以及相应的重叠条件之外没有任何假设。为了量化潜在的收益，我们得出了在有和没有替代项的情况下 ATE 估计的效率界限差异，无论是当大量或相当数量的单位缺失结果时。我们开发了强大的 ATE 估计和推理方法来实现这些效率增益。我们通过研究职业培训的长期收入影响来实证证明收益。]]></description>
      <guid>https://arxiv.org/abs/2003.12408</guid>
      <pubDate>Wed, 15 May 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>学习线性多树结构方程模型</title>
      <link>https://arxiv.org/abs/2107.10955</link>
      <description><![CDATA[arXiv:2107.10955v4 公告类型：替换
摘要：我们感兴趣的是当数据从线性结构方程模型（SEM）生成并且因果结构可以通过多树来表征时学习有向无环图（DAG）的问题。在高斯多树模型下，我们研究了著名的 Chow-Liu 算法的样本大小的充分条件，以准确恢复多树的骨架和等价类，多树由 CPDAG 唯一表示。另一方面，骨架和 CPDAG 恢复所需样本量的必要条件也根据信息论下界得出，与各自的充分条件相匹配，从而清晰地表征了这些任务的难度。我们还考虑了线性多树模型下的逆相关矩阵估计问题，并根据v结构的维数和总数建立了估计误差界限。我们还考虑组线性多树模型的扩展，其中每个节点代表一组变量。我们的理论发现通过全面的数值模拟得到了说明，基准数据的实验也证明了当真实的图形结构只能用多树来近似时多树学习的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2107.10955</guid>
      <pubDate>Wed, 15 May 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>通过自动微分和概率编程简化去偏推理</title>
      <link>https://arxiv.org/abs/2405.08675</link>
      <description><![CDATA[arXiv:2405.08675v1 公告类型：交叉
摘要：我们引入了一种算法，可以简化高效估计器的构建，使更广泛的受众可以使用它们。 “Dimple”将表示感兴趣的参数的计算机代码作为输入，并输出一个有效的估计器。与标准方法不同，它不需要用户导出称为有效影响函数的函数导数。 Dimple 通过将自动微分应用于感兴趣的统计函数来避免这项任务。这样做需要将此函数表示为满足新的可微分条件的原语组合。 Dimple 还使用这种组合来确定它必须估计的滋扰。在软件中，原语可以彼此独立地实现，并在不同的估计问题中重用。我们提供了一个概念验证的 Python 实现，并通过示例展示了它如何允许用户仅用几行代码即可从参数指定到高效估计。]]></description>
      <guid>https://arxiv.org/abs/2405.08675</guid>
      <pubDate>Wed, 15 May 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>集体适应的稳定性和多样性</title>
      <link>https://arxiv.org/abs/nlin/0408039</link>
      <description><![CDATA[arXiv:nlin/0408039v2 公告类型：交叉
摘要：我们从离散时间随机微观模型出发，推导了一类描述集体适应的宏观微分方程。每个智能体的行为是局部实现最佳动作的适应与导致随机行为的记忆丧失之间的动态平衡。我们表明，尽管个体主体以纯粹自利的方式与环境和其他主体交互，但宏观行为可以解释为博弈动力学。应用于几种熟悉的、明确的游戏交互表明，适应动态表现出集体行为的多样性。宏观方程基础假设的简单性表明，这些行为应该在集体适应中得到广泛的预期。我们还从信息论的角度分析了适应动态，并讨论了主体之间信息流引起的自组织，给出了集体适应的新观点。]]></description>
      <guid>https://arxiv.org/abs/nlin/0408039</guid>
      <pubDate>Wed, 15 May 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>使用梯度相似度进行数据评估</title>
      <link>https://arxiv.org/abs/2405.08217</link>
      <description><![CDATA[arXiv:2405.08217v1 公告类型：交叉
摘要：高质量的数据对于准确的机器学习和可操作的分析至关重要，然而，错误标记或噪声数据是许多领域的常见问题。区分低质量和高质量数据可能具有挑战性，通常需要专业知识和大量的人工干预。数据评估算法是一类方法，旨在根据数据集中每个样本对给定预测任务的贡献或重要性来量化其价值。这些数据值显示出识别错误标记的观察结果的令人印象深刻的能力，过滤低值数据可以提高机器学习性能。在这项工作中，我们提出了一种现有方法的简单替代方案，称为梯度相似度数据评估（DVGS）。这种方法可以轻松应用于任何梯度下降学习算法，可以很好地扩展到大型数据集，并且在损坏标签发现和噪声量化等任务中的性能与基线评估方法相当或更好。我们在表格、图像和 RNA 表达数据集上评估 DVGS 方法，以显示该方法跨领域的有效性。我们的方法能够快速准确地识别低质量数据，这可以减少数据清理任务中对专家知识和人工干预的需求。]]></description>
      <guid>https://arxiv.org/abs/2405.08217</guid>
      <pubDate>Wed, 15 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>通过经典和量子机器学习普遍复制混沌特征</title>
      <link>https://arxiv.org/abs/2405.08484</link>
      <description><![CDATA[arXiv:2405.08484v1 公告类型：交叉
摘要：通过机器学习（ML）复制非线性动力学的混沌特性最近引起了广泛的关注。在这项工作中，我们提出一种 ML 模型，经过训练可以从几个最新的历史状态中提前预测状态，可以准确地复制离散动态系统的分岔图和 Lyapunov 指数。单个机器学习模型可以普遍捕获不同超参数值的特征，而之前的工作考虑通过将超参数固定为特定值来独立训练机器学习模型。我们在一维和二维 Logistic 图上的基准测试表明，变分量子电路可以比长短期记忆（一种公认的经典 ML 模型）以更高的精度再现长期特征。我们的工作从性能和模型复杂性之间的关系的角度揭示了混沌特征的机器学习与标准任务的机器学习之间的本质区别。我们的结果表明，量子电路模型在减轻过度拟合、实现更高的准确性和稳定性方面表现出潜在的优势。]]></description>
      <guid>https://arxiv.org/abs/2405.08484</guid>
      <pubDate>Wed, 15 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>通过双机器学习使用工具变量学习决策策略</title>
      <link>https://arxiv.org/abs/2405.08498</link>
      <description><![CDATA[arXiv:2405.08498v1 公告类型：交叉
摘要：在数据丰富的环境中学习决策策略的一个常见问题是离线数据集中的虚假相关性，这可能是由隐藏的混杂因素引起的。工具变量 (IV) 回归利用称为工具的关键无混杂变量，是学习混杂行动、结果和上下文变量之间因果关系的标准技术。最近的 IV 回归算法使用两阶段方法，其中在第一阶段学习的深度神经网络 (DNN) 估计器直接插入第二阶段，其中另一个 DNN 用于估计因果效应。天真地插入估计器可能会在第二阶段导致严重偏差，特别是当第一阶段估计器中存在正则化偏差时。我们提出了 DML-IV，一种非线性 IV 回归方法，可以减少两阶段 IV 回归中的偏差并有效地学习高性能策略。我们推导出一个新颖的学习目标来减少偏差，并按照双/去偏差机器学习 (DML) 框架设计 DML-IV 算法。学习到的 DML-IV 估计器具有很强的收敛速度，并且 $O(N^{-1/2})$ 次优保证在数据集无混杂时与那些匹配。 DML-IV 在 IV 回归基准上优于最先进的 IV 回归方法，并在存在工具的情况下学习高性能策略。]]></description>
      <guid>https://arxiv.org/abs/2405.08498</guid>
      <pubDate>Wed, 15 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>使用通用力校正机器学习方法预测不同航道中的船舶响应</title>
      <link>https://arxiv.org/abs/2405.08033</link>
      <description><![CDATA[arXiv:2405.08033v1 公告类型：交叉
摘要：如果机器学习（ML）方法能够对不同于训练数据集的输入进行预测，那么它就是可推广的。对于波浪引起的船舶响应的预测，如果机器学习方法要在设计评估中发挥作用，那么泛化性是一个重要的考虑因素。此外，训练数据集的大小对方法的实用性有重大影响，特别是当使用昂贵的高保真数值工具生成训练数据时。本文考虑了一种混合机器学习方法，该方法可以校正低保真度运动方程中的力。该方法应用于两个不同的案例研究：不规则激励下杜芬方程的非线性响应，以及逆海中快速排水量船 (FDS) 的高保真升沉和纵摇响应数据。在这两种情况下，通过对与训练数据集中不同的不规则波浪条件下的响应进行预测来确定该方法的普遍性。还研究了混合模型中基于物理的低保真项对泛化性的影响。将预测与两个基准进行比较：基于线性物理的模型和数据驱动的 LSTM 模型。研究发现，在小数据集上进行训练时，混合方法可以提高预测准确性和泛化性。]]></description>
      <guid>https://arxiv.org/abs/2405.08033</guid>
      <pubDate>Wed, 15 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯成像方法报告的概率可信吗？</title>
      <link>https://arxiv.org/abs/2405.08179</link>
      <description><![CDATA[arXiv:2405.08179v1 公告类型：交叉
摘要：贝叶斯统计是成像科学的基石，支撑着从马尔可夫随机场到基于分数的去噪扩散模型的许多不同方法。除了强大的图像估计方法之外，贝叶斯范式还提供了不确定性量化和使用图像数据作为定量证据的框架。这些概率能力对于实验结果的严格解释以及定量成像流程与科学和决策过程的稳健连接非常重要。然而，现有贝叶斯成像方法提供的概率在重复实验时是否有意义，或者它们仅作为信念的主观度量才有意义？本文提出了蒙特卡罗方法来探讨这个问题。然后，我们利用提出的蒙特卡罗方法并运行需要 1,000 GPU 小时的大型实验来探测五种典型贝叶斯成像方法的准确性，这些方法代表了过去几十年中一些主要贝叶斯成像策略（基于分数的去噪扩散）技术、利用 Lipschitz 正则化 DnCNN 降噪器的即插即用 Langevin 算法、具有基于字典的先验训练并受对数凹性约束约束的贝叶斯方法、具有总变分先验的经验贝叶斯方法以及层次化贝叶斯方法。基于高斯马尔可夫随机场模型的贝叶斯吉布斯采样器）。我们发现，在少数情况下，现代贝叶斯成像技术报告的概率与大量重复实验中观察到的长期平均值广泛一致，但现有的贝叶斯成像方法通常无法提供可靠的不确定性量化结果。]]></description>
      <guid>https://arxiv.org/abs/2405.08179</guid>
      <pubDate>Wed, 15 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>通过数据驱动校准解决基于仿真的推理中的错误指定</title>
      <link>https://arxiv.org/abs/2405.08719</link>
      <description><![CDATA[arXiv:2405.08719v1 公告类型：新
摘要：在生成建模稳步进展的推动下，基于模拟的推理（SBI）已经能够对随机模拟器进行推理。然而，最近的研究表明，模型指定错误可能会损害 SBI 的可靠性。这项工作引入了鲁棒后验估计（ROPE），这是一个框架，通过一小部分现实世界的地面真实参数测量校准集来克服模型错误指定。我们将错误指定差距形式化为现实世界的学习表示与模拟观察之间的最佳传输问题的解决方案。假设感兴趣参数的先验分布已知且明确，我们的方法在模拟器所有可能的错误指定下提供校准不确定性和信息推断之间的可控平衡。我们对四个综合任务和两个现实世界问题的实证结果表明，ROPE 的性能优于基线，并且始终返回信息丰富且经过校准的可信区间。]]></description>
      <guid>https://arxiv.org/abs/2405.08719</guid>
      <pubDate>Wed, 15 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>互信息和列联表的编码</title>
      <link>https://arxiv.org/abs/2405.05393</link>
      <description><![CDATA[arXiv:2405.05393v1 公告类型：交叉
摘要：互信息通常用作给定对象集的竞争标签之间相似性的度量，例如量化分类和社区检测任务中的性能。然而，正如最近所争论的那样，传统定义的互信息可能会返回有偏差的结果，因为它忽略了所谓的列联表的信息成本，而列联表是相似性计算的关键组成部分。原则上，可以通过减去适当的信息成本来纠正偏差，从而得到称为减少互信息的修改度量，但实际上，人们只能计算该信息成本的上限以及减少互信息的值关键取决于界限建立得有多好。在本文中，我们描述了一种编码列联表的改进方法，该方法在典型用例中给出了更好的界限，并在标签非常相似的常见情况下接近理想值，正如我们用大量数值结果所证明的那样。]]></description>
      <guid>https://arxiv.org/abs/2405.05393</guid>
      <pubDate>Wed, 15 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>深度神经网络的可扩展子采样推理</title>
      <link>https://arxiv.org/abs/2405.08276</link>
      <description><![CDATA[arXiv:2405.08276v1 公告类型：新
摘要：近年来，深度神经网络（DNN）在机器学习应用中受到越来越多的关注。最近，开发了一种非渐近误差界来衡量带有 ReLU 激活函数的全连接 DNN 估计器的性能，用于估计回归模型。手头的论文基于 DNN 逼近能力的最新结果，对当前的误差界限进行了小幅改进。然而，更重要的是，应用非随机子采样技术（可扩展子采样）来构造“子标记”DNN 估计器。在规律性条件下，结果表明，子标签 DNN 估计器的计算效率很高，且不会牺牲估计或预测任务的准确性。除了点估计/预测之外，我们还提出了基于子标记 DNN 估计器构建置信度和预测区间的不同方法。除了渐进有效之外，所提出的置信/预测区间似乎在有限样本中效果良好。总而言之，可扩展的子采样 DNN 估计器在统计推断方面提供了完整的包，即 (a) 计算效率； (b) 点估计/预测精度； (c) 允许构建实际有用的置信区间和预测区间。]]></description>
      <guid>https://arxiv.org/abs/2405.08276</guid>
      <pubDate>Wed, 15 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>基于模糊知识和复杂数据互补的弱监督因果发现</title>
      <link>https://arxiv.org/abs/2405.08699</link>
      <description><![CDATA[arXiv:2405.08699v1 公告类型：新
摘要：基于观测数据的因果发现对于破译复杂系统背后的因果机制非常重要。然而，由于先验知识较差、领域不一致以及小样本量高维数据集的挑战，现有因果发现方法的有效性受到限制。为了解决这一差距，我们提出了一种新颖的弱监督模糊知识和数据共同驱动的因果发现方法，称为 KEEL。 KEEL采用模糊因果知识模式来封装各种类型的模糊知识，并形成相应的弱化约束。这种模式不仅减少了对专业知识的依赖，而且允许各种类型的有限且容易出错的模糊知识来指导因果发现。它可以增强因果发现的泛化性和鲁棒性，特别是在高维和小样本场景中。此外，我们将扩展线性因果模型（ELCM）集成到KEEL中以处理多分布和不完整的数据。对不同数据集的大量实验证明了 KEEL 在准确性、鲁棒性和计算效率方面优于几种最先进的方法。对于真实蛋白质信号转导过程中的因果发现，KEEL 在数据有限的情况下优于基准方法。总之，KEEL 可以有效地以更高的精度解决因果发现任务，同时减轻对广泛领域专业知识的要求。]]></description>
      <guid>https://arxiv.org/abs/2405.08699</guid>
      <pubDate>Wed, 15 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>加性效应辅助学习</title>
      <link>https://arxiv.org/abs/2405.08235</link>
      <description><![CDATA[arXiv:2405.08235v1 公告类型：新
摘要：如今，持有不同数据集的研究人员和数据分析师相互寻求帮助以提高建模性能是很流行的。我们考虑这样一个场景：不同的学习者持有具有潜在不同变量的数据集，并且他们的观察结果可以通过非私有标识符进行对齐。他们的合作面临以下困难：首先，由于商业利益或隐私法规等原因，学习者可能需要保持数据值甚至变量名称不公开；其次，由于通信成本等原因，它们之间的传输轮数受到限制。为了应对这些挑战，我们为代理 Alice 开发了一个两阶段辅助学习架构，以寻求另一个代理 Bob 的帮助。在第一阶段，我们提出了一种基于隐私意识的假设检验的筛选方法，让 Alice 可以决定 Bob 数据的有用性，而这种方式只需要 Bob 传输粗略数据。一旦爱丽丝认识到鲍勃的有用性，爱丽丝和鲍勃就会进入第二阶段，他们共同应用协同迭代模型训练过程。通过有限的汇总统计数据传输，我们表明，无论是理论上还是数值上，Alice 都可以实现预言机性能，就好像训练来自集中式数据一样。]]></description>
      <guid>https://arxiv.org/abs/2405.08235</guid>
      <pubDate>Wed, 15 May 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>无限视野贴现决策过程的汤普森抽样</title>
      <link>https://arxiv.org/abs/2405.08253</link>
      <description><![CDATA[arXiv:2405.08253v1 公告类型：新
摘要：我们对由未知参数参数化的马尔可夫决策过程进行建模，并研究基于采样的算法（称为汤普森采样）的渐近行为。遗憾的标准定义并不总是适合评估一项政策，特别是当底层链结构是通用的时。我们表明，标准（预期）遗憾可以（超）线性增长，并且无法捕捉现实环境中具有非平凡状态演化的学习概念。通过分解标准（预期）后悔，我们开发了一种新的指标，称为预期残留后悔，它忘记了过去行为的不可改变的后果。相反，它衡量的是对当前时期的最佳奖励的遗憾。我们证明了 Thompson 采样算法的预期残差遗憾的上限是以指数方式快速收敛到 0 的一项。我们提出了 Thompson 采样的后验采样误差几乎肯定收敛到 0 的条件。然后，我们介绍预期残留遗憾的概率版本以及它几乎肯定会收敛到 0 的当前条件。因此，我们为采样算法提供了一个可行的学习概念，它将在比之前考虑的更广泛的环境中发挥作用。]]></description>
      <guid>https://arxiv.org/abs/2405.08253</guid>
      <pubDate>Wed, 15 May 2024 06:18:24 GMT</pubDate>
    </item>
    </channel>
</rss>