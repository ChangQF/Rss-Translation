<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 20 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>有界支持噪声下高斯过程回归的误差界限及其在安全认证中的应用</title>
      <link>https://arxiv.org/abs/2408.09033</link>
      <description><![CDATA[arXiv:2408.09033v1 公告类型：交叉 
摘要：高斯过程回归 (GPR) 是一种强大而优雅的方法，用于从噪声数据中学习复杂函数，具有广泛的应用范围，包括安全关键领域。此类应用具有两个关键特征：(i) 它们需要严格的误差量化，(ii) 由于物理约束等原因，噪声通常是有界的和非高斯的。虽然在存在非高斯噪声的情况下应用 GPR 的误差界限存在，但它们在实践中往往过于严格和保守。在本文中，我们为有界支持噪声下的 GPR 提供了新的误差界限。具体而言，通过依赖浓度不等式并假设潜在函数在与 GP 核相对应的再生核希尔伯特空间 (RKHS) 中具有低复杂度，我们推导出 GPR 误差的概率和确定性界限。我们表明，这些误差比现有的最先进界限要严格得多，特别适合具有神经网络内核的 GPR，即深度内核学习 (DKL)。此外，受安全关键领域应用的启发，我们说明了如何将这些界限与随机屏障函数相结合，以成功地从有限数据中量化未知动态系统的安全概率。我们通过几个基准测试和与现有界限的比较来验证我们方法的有效性。结果表明，我们的界限始终较小，并且 DKL 可以产生比样本噪声更严格的误差界限，从而显著提高控制系统的安全概率。]]></description>
      <guid>https://arxiv.org/abs/2408.09033</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:40 GMT</pubDate>
    </item>
    <item>
      <title>学习受审查数据的稳健处理规则</title>
      <link>https://arxiv.org/abs/2408.09155</link>
      <description><![CDATA[arXiv:2408.09155v1 公告类型：交叉 
摘要：关于通过最大化预期结果直接估计最佳治疗规则的文献正在快速增长。在生物医学研究和操作应用中，经常观察到审查生存结果，在这种情况下，限制平均生存时间和生存概率非常重要。在本文中，我们提出了两个用于学习具有审查生存结果的最佳治疗规则的稳健标准；前者的目标是最大化限制平均生存时间的最佳治疗规则，其中限制由给定的分位数（例如中位数）指定；后者的目标是最大化缓冲生存概率的最佳治疗规则，其中预定阈值会根据限制平均生存时间进行调整。我们为提出的最佳治疗规则提供了理论依据，并开发了一种基于采样的凸差算法来学习它们。在模拟研究中，我们的估计器与现有方法相比表现出更好的性能。我们还使用艾滋病临床试验数据演示了所提出的方法。]]></description>
      <guid>https://arxiv.org/abs/2408.09155</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:40 GMT</pubDate>
    </item>
    <item>
      <title>具有秩统计的稳健谱聚类</title>
      <link>https://arxiv.org/abs/2408.10136</link>
      <description><![CDATA[arXiv:2408.10136v1 公告类型：新
摘要：本文分析了一种稳健的谱聚类方法在噪声数据矩阵中恢复潜在结构的统计性能。我们考虑将基于特征向量的聚类应用于非参数秩统计矩阵，该矩阵是从原始数据矩阵逐项得出的。这种方法是稳健的，因为与传统的谱聚类程序不同，即使观察到的数据矩阵包含重尾条目并具有异质方差分布，它也可以证明恢复种群级潜在块结构。
我们的主要理论贡献有三方面，并且在灵活的数据生成条件下成立。首先，我们确定具有秩统计的稳健谱聚类可以一致地恢复潜在块结构，将其视为图中的节点社区，当数据矩阵很大时，除了消失的节点之外，所有节点的未观察到的社区成员身份都可以高概率地正确恢复。其次，我们改进了前一个结果，并进一步确定，在某些条件下，任何单个、指定感兴趣节点的社区成员身份都可以渐近地精确恢复，在大数据极限下概率趋于 1。第三，我们建立了与矩阵的截断特征结构相关的渐近正态性结果，矩阵的条目是秩统计，这是通过将当代逐项矩阵扰动分析与所谓的简单线性秩统计的经典非参数理论相结合而实现的。总的来说，这些结果证明了基于秩的数据转换与谱技术相结合用于降维时的统计效用。此外，对于人类连接组数据集，我们的方法可以实现简约的降维，并更好地恢复真实的神经解剖簇结构。]]></description>
      <guid>https://arxiv.org/abs/2408.10136</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>ROC 曲线下面积对二元分类的评估最为一致</title>
      <link>https://arxiv.org/abs/2408.10193</link>
      <description><![CDATA[arXiv:2408.10193v1 公告类型：新
摘要：评估指标是二元分类任务中模型评估和模型选择的重要问题。本研究调查了在不同数据场景下评估不同模型的指标一致性。通过统计模拟分析了 150 多个数据场景和 18 个模型评估指标，我发现对于二元分类任务，受流行程度影响较小的评估指标可以为一组不同的模型提供更一致的排名。特别是，ROC 曲线下面积 (AUC) 在不同模型的排名中方差最小。作为模型性能的更严格衡量标准，马修相关系数的方差第二小。这些模式适用于丰富的数据场景和五种常用的机器学习模型以及一个简单的随机猜测模型。结果对二元分类任务中的模型评估和模型选择具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2408.10193</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>具有连续样本空间的统计流形的最优传输自然梯度</title>
      <link>https://arxiv.org/abs/1805.08380</link>
      <description><![CDATA[arXiv:1805.08380v4 公告类型：交叉 
摘要：我们研究具有连续样本空间的参数统计模型中的 Wasserstein 自然梯度。我们的方法是将概率密度空间中的 $L^2$-Wasserstein 度量张量拉回到参数空间，为后者配备一个正定度量张量，在该张量下它变为黎曼流形，称为 Wasserstein 统计流形。一般来说，它不是密度空间的完全测地线子流形，因此它的测地线将不同于 Wasserstein 测地线，除了众所周知的高斯分布情况，这一事实也可以在我们的框架下得到验证。我们使用子流形几何在参数空间中推导出梯度流和自然梯度下降法。当参数化密度位于 $\bR$ 中时，诱导度量张量建立一个显式公式。在优化问题中，我们观察到当 Wasserstein 距离为目标函数时，自然梯度下降法优于标准梯度下降法。在这种情况下，我们证明所得算法在渐近状态下的行为类似于牛顿法。证明计算了 Wasserstein 距离的精确 Hessian 公式，这进一步激发了优化过程的另一个预处理器。最后，我们给出了一些例子来说明自然梯度在几个参数统计模型中的有效性，包括高斯测度、高斯混合、伽马分布和拉普拉斯分布。]]></description>
      <guid>https://arxiv.org/abs/1805.08380</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能的自适应不确定性量化</title>
      <link>https://arxiv.org/abs/2408.08990</link>
      <description><![CDATA[arXiv:2408.08990v1 公告类型：交叉 
摘要：这项工作涉及当代应用（包括生成式 AI）中的共形预测，其中黑盒模型是在用户无法访问的数据上进行训练的。镜像分裂共形推理，我们设计了一个围绕黑盒算法的包装器，该算法可以校准一致性分数。此校准是局部的，分两个阶段进行，首先自适应地将预测空间划分为组，然后逐组进行分段校准。通过将稳健回归树拟合到校准集上的一致性分数来实现自适应分区（自分组）。这种新的树变体的设计方式是，添加单个新观察不会以压倒性大的概率改变树拟合。这种添加一个的稳健性属性使我们能够得出有限样本组条件覆盖保证，这是边际保证的细化。此外，与传统的分裂共形推理不同，自适应分裂和组内校准可产生可以局部拉伸和收缩的自适应带。我们使用非参数回归在几个模拟和真实示例上展示了局部收紧的好处。最后，我们考虑了两个当代分类应用程序，用于获得围绕 GPT-4o 预测的不确定性量化。我们根据自我报告的症状对皮肤病诊断进行共形化，并根据美国立法者的意识形态摘要预测他们的状态。我们展示了不确定性集的显着局部收紧，同时实现了类似的边际覆盖率。]]></description>
      <guid>https://arxiv.org/abs/2408.08990</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>卷积条件神经过程</title>
      <link>https://arxiv.org/abs/2408.09583</link>
      <description><![CDATA[arXiv:2408.09583v1 公告类型：新
摘要：神经过程是一类模型，它们使用神经网络直接参数化从数据集到预测的映射。直接参数化此映射使得能够在小数据问题中使用表达性神经网络，而神经网络传统上会过度拟合。神经过程可以产生经过良好校准的不确定性，有效地处理缺失数据，并且易于训练。这些特性使该模型系列在医疗保健或环境科学等广泛的应用领域中具有吸引力。
本论文以三种方式推进神经过程。
首先，我们提出了卷积神经过程 (ConvNPs)。ConvNPs 通过建立一种称为平移等变的对称性来提高神经过程的数据效率。ConvNPs 依赖于卷积神经网络而不是多层感知器。
其次，我们提出了高斯神经过程 (GNPs)。GNPs 直接参数化神经过程预测中的依赖关系。目前，对预测中的依赖关系进行建模的方法依赖于潜在变量，因此需要近似推理，从而削弱了该方法的简单性。
第三，我们提出了自回归条件神经过程 (AR CNP)。AR CNP 无需对模型或训练程序进行任何修改即可训练神经过程，并在测试时以自回归方式推出模型。AR CNP 为神经过程框架配备了一个新旋钮，其中可以将训练时的建模复杂性和计算成本换成测试时的计算成本。
除了方法上的进步之外，本论文还提出了一种软件抽象，它支持采用组合方法来实现神经过程。这种方法允许用户通过以不同的方式组合基本构建块来快速探索神经过程模型的空间。]]></description>
      <guid>https://arxiv.org/abs/2408.09583</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>高斯混合模型中的确认偏差</title>
      <link>https://arxiv.org/abs/2408.09718</link>
      <description><![CDATA[arXiv:2408.09718v1 公告类型：新
摘要：确认偏差，即以符合个人先入之见的方式解释信息的倾向，会对科学研究产生深远影响，导致即使观察数据不支持研究人员的假设，结论也会反映研究人员的假设。这个问题在涉及高度嘈杂观察的科学领域尤其重要，例如低温电子显微镜。
本研究调查了高斯混合模型中的确认偏差。我们考虑以下实验：一组科学家假设他们正在分析从高斯混合模型中提取的数据，该模型以已知信号（假设）为质心。然而，实际上，观测结果完全由噪声组成，没有任何信息结构。研究人员使用 K 均值或期望最大化算法的单次迭代来估计质心，这两种算法都很流行。尽管观测结果纯属噪声，但我们表明这些算法产生的估计值与初始假设相似，存在偏差，这与对这些噪声观测值进行平均将收敛到零的无偏预期相矛盾。也就是说，尽管观测结果中没有明显的假设（高斯混合的假定质心），但算法产生的估计值反映了假设的模型。具体而言，除其他结果外，我们证明了算法产生的估计值与相应的假设之间存在正相关性。我们还推导出有限和无限数量假设的估计值的显式闭式表达式。这项研究强调了低信噪比环境中确认偏差的风险，深入了解了科学方法中的潜在陷阱，并强调了审慎解释数据的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.09718</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>ALTBI：通过优化内部记忆效应构建改进的异常值检测模型</title>
      <link>https://arxiv.org/abs/2408.09791</link>
      <description><![CDATA[arXiv:2408.09791v1 公告类型：新
摘要：异常值检测 (OD) 是通过学习正常观测值（或内点）的独特模式，从给定或即将到来的数据中识别异常观测值（或异常值）的任务。最近，一项研究基于对深度生成模型的新观察，引入了一种强大的无监督 OD (UOD) 求解器，称为内点记忆 (IM) 效应，这表明生成模型在早期学习阶段会先记住内点，然后再记住异常值。在本研究中，我们旨在开发一种理论上可行的方法，通过最大限度地利用 IM 效应来解决 UOD 任务。我们首先观察到，当给定的训练数据包含较少的异常值时，IM 效应会更明显。这一发现表明，如果我们在设计损失函数时能够有效地从小批量中排除异常值，那么在 UOD 机制中增强 IM 效果的潜力。为此，我们引入了两种主要技术：1) 在模型训练过程中增加小批量大小；2) 使用自适应阈值计算截断损失函数。我们从理论上表明，这两种技术可以有效地从截断损失函数中滤除异常值，使我们能够充分利用 IM 效应。结合额外的集成策略，我们提出了我们的方法，并将其称为带批量增量的自适应损失截断 (ALTBI)。我们提供了大量实验结果来证明，与其他近期方法相比，ALTBI 在识别异常值方面实现了最先进的性能，即使计算成本明显降低。此外，我们表明，当与隐私保护算法相结合时，我们的方法可实现稳健的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.09791</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>通过深度学习预测路径依赖过程</title>
      <link>https://arxiv.org/abs/2408.09941</link>
      <description><![CDATA[arXiv:2408.09941v1 Announce Type: new 
摘要：本文研究了一种基于离散观测历史信息的路径依赖过程预测的深度学习方法。该方法通过将预测视为非参数回归，通过模拟样本和深度神经网络获得回归函数来实现。将该方法应用于分数布朗运动及其驱动的随机微分方程的解时，我们从理论上证明了$L_2$误差收敛到0，并进一步讨论了该方法的适用范围。当离散观测的频率趋于无穷大时，基于离散观测的预测收敛到基于连续观测的预测，这意味着我们可以用该方法进行近似。我们将该方法应用于分数布朗运动和分数Ornstein-Uhlenbeck过程作为例子。与理论最优预测结果进行比较，以均方误差为衡量指标，数值模拟表明该方法能够得到较为准确的预测结果，并分析了预测周期、Hurst指数等因素对预测精度的影响。]]></description>
      <guid>https://arxiv.org/abs/2408.09941</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>通过状态空间学习进行时间序列分析</title>
      <link>https://arxiv.org/abs/2408.09120</link>
      <description><![CDATA[arXiv:2408.09120v1 公告类型：新
摘要：状态空间模型的时间序列分析广泛用于预测和提取不可观察的成分，如水平、斜率和季节性以及解释变量。然而，它们对传统卡尔曼滤波的依赖经常会妨碍它们的有效性，这主要是由于高斯假设以及缺乏有效的子集选择方法来适应当今大数据应用中的大量潜在解释变量。我们的研究引入了状态空间学习 (SSL)，这是一种新颖的框架和范式，它利用统计学习的能力来构建一个全面的时间序列建模和预测框架。通过利用正则化的高维回归框架，我们的方法联合提取典型的时间序列不可观察成分，检测和解决异常值，并在多项式时间和全局最优保证中选择高维空间内外生变量的影响。通过受控的数值实验，我们证明了我们的方法在解释变量子集选择准确性方面优于相关基准。我们还提出了一种直观的预测方案，并使用来自 M4 竞赛的 48,000 个月时间序列数据集展示了相对于传统时间序列模型的卓越性能。我们扩展了我们方法的适用性，将任何具有时变系数的线性状态空间公式重新表述为高维正则化回归，将我们研究的影响扩展到时间序列分析以外的其他工程应用。最后，我们提出的方法在 Julia 开源包“StateSpaceLearning.jl”中实现。]]></description>
      <guid>https://arxiv.org/abs/2408.09120</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>回归中的深度极限无模型预测</title>
      <link>https://arxiv.org/abs/2408.09532</link>
      <description><![CDATA[arXiv:2408.09532v1 公告类型：新
摘要：在本文中，我们提供了一种基于深度神经网络 (DNN) 的新型无模型方法，以在一般回归设置下完成点预测和预测区间。通常，人们依靠参数或非参数模型来连接因变量和自变量（Y 和 X）。然而，这种经典方法严重依赖于正确的模型规范。即使对于非参数方法，也经常假设某种加法形式。新提出的无模型预测原理揭示了没有任何模型假设的预测过程。关于这一原则的先前工作显示出比其他标准替代方案更好的性能。最近，DNN 作为机器学习方法之一，由于其在实践中的出色表现而受到越来越多的关注。在无模型预测思想的指导下，我们尝试应用完全连接的前向 DNN 将 X 和一些适当的参考随机变量 Z 映射到 Y。通过最小化专门设计的损失函数来训练目标 DNN，以便 Y 在 X 上的条件随机性通过训练后的 DNN 外包给 Z。与其他基于 DNN 的方法相比，我们的方法更稳定、更准确，尤其是在最佳点预测方面。通过特定的预测程序，我们的预测区间可以捕捉估计的可变性，从而为有限样本案例提供更好的覆盖率。我们的方法的卓越性能已通过模拟和实证研究得到验证。]]></description>
      <guid>https://arxiv.org/abs/2408.09532</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>样本最优大规模最优子集选择</title>
      <link>https://arxiv.org/abs/2408.09537</link>
      <description><![CDATA[arXiv:2408.09537v1 公告类型：新
摘要：排名和选择 (R&amp;S) 传统上旨在从一组有限的替代方案中选择具有最大平均性能的唯一最佳替代方案。然而，为了更好地支持决策，提供一小部分平均性能在前 $m$ 位的替代方案可能更有用。这种问题称为最优子集选择 (OSS)，通常比传统的 R&amp;S 更难解决。当替代方案的数量相当大时，这一挑战变得更加重要。因此，本文的重点是解决大规模 OSS 问题。为了实现这一目标，我们设计了一个前 $m$ 个贪婪选择机制，该机制不断用前 $m$ 个运行样本均值对当前前 $m$ 个替代方案进行采样，并提出了探索优先前 $m$ 个贪婪 (EFG-$m$) 程序。通过扩展的跨界框架，我们证明了 EFG-$m$ 程序在样本最优和良好选择概率方面是一致的，从而证实了它在解决大规模 OSS 问题中的有效性。令人惊讶的是，我们还证明了 EFG-$m$ 程序能够在不增加额外成本的情况下在所选的替代方案子集内实现基于无差异的排名。这非常有益，因为它为决策者提供了更深入的见解，从而能够做出更明智的决策。最后，数值实验验证了我们的结果并证明了我们程序的效率。]]></description>
      <guid>https://arxiv.org/abs/2408.09537</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>$\ell_2$ 预期校准误差的置信区间</title>
      <link>https://arxiv.org/abs/2408.08998</link>
      <description><![CDATA[arXiv:2408.08998v1 公告类型：新
摘要：机器学习的最新进展显著提高了各种应用中的预测精度。然而，确保概率预测的校准仍然是一个重大挑战。尽管努力加强模型校准，但模型校准的严格统计评估仍然没有得到充分探索。在这项工作中，我们开发了置信区间$\ell_2$预期校准误差（ECE）。我们考虑从前 1 到 $k$ 的校准，其中包括流行的置信校准概念以及完全校准。对于 ECE 的去偏估计量，我们显示了渐近正态性，但对于校准和错误校准的模型具有不同的收敛速度和渐近方差。我们开发了为 ECE 构建渐近有效置信区间的方法，考虑到这种行为以及非负性。我们的理论发现得到了大量实验的支持，表明与基于重采样的方法获得的置信区间相比，我们的方法产生的有效置信区间长度更短。]]></description>
      <guid>https://arxiv.org/abs/2408.08998</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:36 GMT</pubDate>
    </item>
    <item>
      <title>学习傅里叶线性算子的误差界限</title>
      <link>https://arxiv.org/abs/2408.09004</link>
      <description><![CDATA[arXiv:2408.09004v1 公告类型：新
摘要：我们研究函数空间之间的学习算子问题，重点关注傅立叶神经算子的线性层。首先，我们确定学习过程中发生的三个主要错误：由于样本量有限而导致的统计错误、算子的有限秩近似导致的截断错误以及在有限域点网格上处理函数数据的离散化错误。最后，我们分析了基于离散傅里叶变换 (DFT) 的最小二乘估计量，并确定了上述错误的上限和下限。]]></description>
      <guid>https://arxiv.org/abs/2408.09004</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:36 GMT</pubDate>
    </item>
    </channel>
</rss>