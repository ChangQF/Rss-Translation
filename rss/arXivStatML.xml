<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 16 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>朗之万蒙特卡罗超越 Lipschitz 梯度连续性</title>
      <link>https://arxiv.org/abs/2412.09698</link>
      <description><![CDATA[arXiv:2412.09698v1 公告类型：新
摘要：我们通过引入不精确近端朗之万算法 (IPLA)，在朗之万蒙特卡罗 (LMC) 方法领域取得了重大进展。这种新算法扩大了 LMC 可以有效解决的问题范围，同时保持可控的计算成本。IPLA 将 LMC 的适用性扩展到凸的、尾部强凸的、表现出多项式增长的势，超越了传统的 $L$ 平滑度假设。此外，我们将 LMC 的适用性扩展到超二次势，并提供比现有算法更快的收敛速度。此外，我们还为 IPLA 生成的马尔可夫链的所有矩提供了界限，从而增强了其分析稳健性。]]></description>
      <guid>https://arxiv.org/abs/2412.09698</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>研究平衡、过滤和复杂性对预测多重性的影响：以数据为中心的视角</title>
      <link>https://arxiv.org/abs/2412.09712</link>
      <description><![CDATA[arXiv:2412.09712v1 公告类型：新
摘要：罗生门效应给模型选择带来了重大挑战。当多个模型在数据集上实现相似的性能但产生不同的预测时，就会发生这种情况，从而导致预测多重性。这在高风险环境中尤其成问题，因为任意的模型结果都可能产生严重后果。传统的模型选择方法优先考虑准确性，无法解决这个问题。类别不平衡和不相关变量等因素进一步使情况复杂化，使模型更难提供可靠的预测。以数据为中心的人工智能方法可以通过优先考虑数据优化来缓解这些问题，尤其是通过预处理技术。然而，最近的研究表明，预处理方法可能会无意中增加预测多重性。本文研究了平衡和过滤方法等数据预处理技术如何影响预测多重性和模型稳定性，并考虑了数据的复杂性。我们对 21 个真实数据集进行了实验，应用了各种平衡和过滤技术，并利用罗生门效应评估了这些方法引入的预测多重性水平。此外，我们还研究了过滤技术如何减少冗余并增强模型泛化能力。研究结果深入了解了平衡方法、数据复杂性和预测多重性之间的关系，展示了以数据为中心的 AI 策略如何提高模型性能。]]></description>
      <guid>https://arxiv.org/abs/2412.09712</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有指数族的监督深度学习的统计分析，适用于本质上低维的数据</title>
      <link>https://arxiv.org/abs/2412.09779</link>
      <description><![CDATA[arXiv:2412.09779v1 公告类型：新
摘要：最近的进展表明，深度监督学习中预期测试误差的收敛速度随输入空间的固有维度而不是维度 $d$ 而衰减。现有文献将此固有维度定义为 Minkowski 维度或底层概率度量支持的流形维度，这通常会导致次优速率和不切实际的假设。在本文中，我们考虑监督深度学习，此时解释变量的响应按照具有 $\beta$-H\&quot;older 平滑均值函数的指数族分布。我们考虑了内在数据维度的熵概念，并证明对于 $n$ 个独立且相同分布的样本，测试误差的尺度为 $\tilde{\mathcal{O}}\left(n^{-\frac{2\beta}{2\beta + \bar{d}_{2\beta}(\lambda)}}\right)$，其中 $\bar{d}_{2\beta}(\lambda)$ 是 $\lambda$（解释变量的分布）的 $2\beta$-熵维度。这提高了最知名的速率。此外，在解释变量的上限密度假设下，我们将收敛速度描述为 $\tilde{\mathcal{O}}\left( d^{\frac{2\lfloor\beta\rfloor(\beta + d)}{2\beta + d}}n^{-\frac{2\beta}{2\beta + d}}\right)$，确定对 $d$ 的依赖性不是指数的，而最多是多项式的。我们还证明，当解释变量具有下限密度时，就数据样本数量而言，这个比率对于学习指数族的依赖结构几乎是最佳的。]]></description>
      <guid>https://arxiv.org/abs/2412.09779</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过残差谱匹配完成矩阵</title>
      <link>https://arxiv.org/abs/2412.10005</link>
      <description><![CDATA[arXiv:2412.10005v1 公告类型：新
摘要：噪声矩阵补全因其在推荐系统、信号处理和图像恢复中的应用而引起了广泛关注。大多数现有工作依赖于各种低秩约束下的（加权）最小二乘法。然而，最小化残差平方和并不总是有效的，因为它可能会忽略残差中的潜在结构信息。在本研究中，我们提出了一种新的残差谱匹配标准，它不仅结合了残差的数值信息，还结合了残差的位置信息。该标准是噪声矩阵补全中第一个采用随机矩阵低秩扰动的视角并利用稀疏随机矩阵的谱特性的标准。​​我们通过分析稀疏随机矩阵的谱特性并限制低秩扰动和部分观测的影响来推导出最佳统计特性。此外，我们提出了通过构建易于计算的伪梯度来有效近似解的算法。所提算法的迭代过程确保以与最佳统计误差界限一致的速率收敛。我们的方法和算法在模拟和真实数据示例中都表现出了更好的数值性能，尤其是在高噪声水平的环境中。]]></description>
      <guid>https://arxiv.org/abs/2412.10005</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DQA：深度神经网络激活的深度量化有效方法</title>
      <link>https://arxiv.org/abs/2412.09687</link>
      <description><![CDATA[arXiv:2412.09687v1 公告类型：交叉 
摘要：深度神经网络 (DNN) 激活的量化是一种常用的技术，可以减少 DNN 推理期间的计算和内存需求，这在资源受限的设备上尤其有益。为了实现高精度，现有的量化激活方法依赖于复杂的数学计算或对最佳超参数进行大量搜索。然而，这些昂贵的操作在计算能力、内存容量和能量预算有限的设备上是不切实际的。此外，许多现有方法并不关注 6 位以下（或深度）量化。
为了填补这些空白，我们在本文中提出了 DQA（DNN 激活的深度量化），这是一种专注于 6 位以下激活量化的新方法，并利用简单的基于移位的操作和霍夫曼编码来提高效率并实现高精度。我们对具有 3、4 和 5 位量化级别的 DQA 和三个不同的 DNN 模型进行了评估，以用于两个不同的数据集上的两个不同任务（图像分类和图像分割）。与直接量化方法和最先进的 NoisyQuant 相比，DQA 在 6 位以下量化方面表现出明显更高的准确率（高达 29.28%）。]]></description>
      <guid>https://arxiv.org/abs/2412.09687</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算深度前馈神经网络高阶导数的拟线性算法</title>
      <link>https://arxiv.org/abs/2412.09752</link>
      <description><![CDATA[arXiv:2412.09752v1 公告类型：交叉 
摘要：由于计算高阶导数时自动微分的运行时间呈指数增长，因此使用神经网络求解微分方程实际上很困难。我们提出了 $n$-TangentProp，这是 TangentProp 形式主义 \cite{simard1991tangent} 到任意多个导数的自然扩展。对于具有平滑、无参数激活函数的密集连接前馈神经网络 $f$，$n$-TangentProp 以准线性（而不是指数时间）计算精确导数 $d^n/dx^n f(x)$。我们在一系列深度、宽度和导数上通过经验验证了我们的算法。我们证明，我们的方法在物理信息神经网络的背景下特别有用，其中 \ntp 允许比以前的方法更快的训练时间，并且在模型大小和损失函数复杂度方面具有良好的扩展性（以所需导数的数量来衡量）。本文的代码可以在 https://github.com/kyrochi/n\_tangentprop 找到。]]></description>
      <guid>https://arxiv.org/abs/2412.09752</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从排序中学习结构因果模型：可识别的流模型</title>
      <link>https://arxiv.org/abs/2412.09843</link>
      <description><![CDATA[arXiv:2412.09843v1 公告类型：交叉 
摘要：在本研究中，我们解决了因果推断问题，当时只有观测数据和因果图中的有效因果排序可用。我们引入了一组流模型，可以恢复外生变量的逐个组件、可逆变换。我们的基于流的方法提供了灵活的模型设计，同时无论离散化步骤的数量如何都能保持因果一致性。我们提出了设计改进，可以同时学习所有因果机制，并将归纳和预测复杂度降低到相对于层数的线性 O(n)，与因果变量的数量无关。从经验上讲，我们证明我们的方法优于以前最先进的方法，并且在回答观察性、干预性和反事实问题时，在广泛的结构因果模型中提供了一致的性能。此外，与现有的基于扩散的技术相比，我们的方法显著减少了计算时间，使其适用于大型结构因果模型。]]></description>
      <guid>https://arxiv.org/abs/2412.09843</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过可预测性分解评估特征重要性的高阶效应</title>
      <link>https://arxiv.org/abs/2412.09964</link>
      <description><![CDATA[arXiv:2412.09964v1 公告类型：交叉 
摘要：利用近年来用于描述随机变量间多元相互作用的冗余和协同作用的大量工作，我们提出了一种量化特征重要性协同效应的新方法，这是可解释人工智能最常用的技术之一。特别是，我们提出了一个众所周知的特征重要性度量的自适应版本，称为留一协变量 (LOCO)，以解开回归问题中涉及给定输入特征的高阶效应。LOCO 是将所考虑的特征添加到用于回归的所有特征集时预测误差的减少。我们的方法不是像标准版本那样使用手头的所有特征来计算 LOCO，而是搜索最大化 LOCO 的多个特征和最小化 LOCO 的特征。这提供了 LOCO 的分解，即二体分量和高阶分量（冗余和协同）的总和，同时还突出了有助于构建这些高阶效应以及驱动特征的特征。我们报告了 GEANT 模拟探测器测量中质子/介子鉴别的应用。]]></description>
      <guid>https://arxiv.org/abs/2412.09964</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对不平衡 RCT 数据的提升建模和异质性治疗效果评估的类别翻转</title>
      <link>https://arxiv.org/abs/2412.10009</link>
      <description><![CDATA[arXiv:2412.10009v1 公告类型：交叉 
摘要：提升建模和异质治疗效果 (HTE) 估计旨在预测某个行为（例如医疗治疗或营销活动）对特定个体的因果影响。在本文中，我们重点关注随机对照实验的数据，这些数据保证了对结果的因果解释。类别和治疗不平衡是提升建模/HTE 中的重要问题，但经典的欠采样或过采样方法很难应用于这种情况，因为它们会扭曲预测效果。过去曾提出过校准方法，但它们并不能保证正确的预测。在这项工作中，我们提出了一种替代欠采样的方法，该方法基于翻转所选记录的类值。我们表明，所提出的方法不会扭曲预测效果，也不需要校准。该方法对于基于类变量转换（修改后的结果模型）的模型特别有用。我们分别处理这些模型，设计一个转换方案，保证正确的预测，并解决对这些模型尤其重要的治疗不平衡问题。实验充分证实了我们的理论结果。此外，我们证明我们的方法也是标准分类问题的可行替代方案。]]></description>
      <guid>https://arxiv.org/abs/2412.10009</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>你比随机猜测做得更好吗？呼吁在评估因果发现算法时使用负面控制</title>
      <link>https://arxiv.org/abs/2412.10039</link>
      <description><![CDATA[arXiv:2412.10039v1 公告类型：交叉 
摘要：因果发现算法的新提案通常使用模拟和一些具有已知数据生成机制的选定真实数据示例进行评估。然而，对于如何设计此类评估研究，目前尚无一般指导方针，因此，比较不同研究的结果可能很困难。在本文中，我们通过提出以下问题提出了一个共同的评估基线：我们做得比随机猜测更好吗？对于图骨架估计任务，我们在随机猜测下得出一系列典型因果发现评估指标（包括精确度和召回率）的预期行为的精确分布结果。我们表明，这些指标在某些情况下可以在随机猜测下实现非常大的值，因此警告不要在没有报告负面控制结果（即随机猜测下的性能）的情况下使用它们。我们还提出了一种精确的整体骨架拟合测试，并展示了它在实际数据应用中的使用。最后，我们提出了一种在骨架估计任务之外使用随机控制的通用流程，并将其应用于模拟示例和实际数据应用中。]]></description>
      <guid>https://arxiv.org/abs/2412.10039</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AMUSE：使用模拟环境进行自适应模型更新</title>
      <link>https://arxiv.org/abs/2412.10119</link>
      <description><![CDATA[arXiv:2412.10119v1 公告类型：交叉 
摘要：预测模型经常面临概念漂移的挑战，其中底层数据分布随时间而变化，从而削弱性能。示例可以包括预测贷款违约的模型，或用于医疗保健环境的模型。典型的管理策略涉及定期模型更新或由概念漂移检测触发的更新。然而，这些简单的策略不一定能平衡模型更新成本和改进的分类器性能。我们提出了 AMUSE（使用模拟环境的自适应模型更新），这是一种利用在模拟数据生成环境中训练的强化学习的新方法，用于确定分类器的更新时间。最佳更新策略取决于当前数据生成过程和正在进行的漂移过程。我们的关键思想是，我们可以通过创建一个训练环境来训练任意复杂的模型更新策略，在该环境中，可能的漂移事件由参数模型模拟，该模型代表对可能的漂移模式的期望。因此，AMUSE 会根据估计的性能改进主动推荐更新，学习一种在保持模型性能和最小化更新成本之间取得平衡的策略。实证结果证实了AMUSE在模拟数据中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.10119</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高维统计学在代谢组学批次效应中的应用</title>
      <link>https://arxiv.org/abs/2412.10196</link>
      <description><![CDATA[arXiv:2412.10196v1 公告类型：交叉 
摘要：在大规模代谢组学中，批次效应不可避免。在正式数据分析之前，需要进行批次效应校正（BEC）以防止掩盖生物变异，并使用批次效应评估（BEE）进行校正评估。然而，现有的BEE算法忽略了变量之间的协方差，而现有的BEC算法可能无法充分校正协方差。因此，我们借助高维统计学的最新进展，分别提出了“基于质量控制的同时测试（QC-ST）”和“协方差校正（CoCo）”。通过模拟数据验证，QC-ST可以同时检测不同批次间QC样本均值向量和协方差矩阵的统计显著性，并且在经验大小、经验功效和计算速度方面具有令人满意的统计性能。然后，我们将四种基于 QC 的 BEC 算法应用于两个大型队列数据集，发现极端梯度提升 (XGBoost) 在相对标准差 (RSD) 和离散度 (D-ratio) 方面表现最佳。在前置 BEC 之后，如果 QC-ST 仍然表明某些两个批次之间的批次效应显著，则应实施 CoCo。并且在 CoCo 之后（如有必要），四个指标（即 RSD、D-ratio、分类性能和 QC-ST）可能会进一步改善。总之，在 QC-ST 的指导下，我们可以制定一种匹配策略，以更合理、更灵活地集成多种 BEC 算法，并最小化批次效应以获得可靠的生物学结论。]]></description>
      <guid>https://arxiv.org/abs/2412.10196</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>支持医疗决策的预测性人工智能模型的性能评估：概述和指导</title>
      <link>https://arxiv.org/abs/2412.10288</link>
      <description><![CDATA[arXiv:2412.10288v1 公告类型：交叉 
摘要：文献中提出了大量指标来说明预测人工智能 (AI) 模型的性能。选择适当的性能指标对于开发用于医疗实践的预测 AI 模型至关重要，因为性能不佳的模型可能会伤害患者并导致成本增加。我们的目标是在验证用于医疗实践的预测 AI 模型时评估经典和当代性能指标的优点。我们专注于具有二元结果的模型。我们讨论了涵盖五个性能领域（区分、校准、总体、分类和临床效用）的 32 个性能指标以及随附的图形评估。前四个领域涵盖统计性能，第五个领域涵盖决策分析性能。我们解释了为什么在选择要评估的绩效指标时，两个关键特征很重要：（1）当使用正确的概率（即“适当”的指标）计算指标的预期值时，指标的预期值是否得到优化；（2）它们是否反映纯统计绩效或通过适当考虑误分类成本而反映决策分析绩效。十七项指标同时表现出两种特征，十四项指标表现出一种特征，一项指标既不具备任何特征（F1 指标）。除了 0.5 或患病率之外，所有分类指标（如分类准确度和 F1）对于临床相关决策阈值都不合适。我们建议报告以下指标和图表：AUROC、校准图、临床效用指标（如具有决策曲线分析的净收益）以及每个结果类别的概率分布图。]]></description>
      <guid>https://arxiv.org/abs/2412.10288</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稀疏异质性下的最佳多任务线性回归和上下文老虎机</title>
      <link>https://arxiv.org/abs/2306.06291</link>
      <description><![CDATA[arXiv:2306.06291v3 公告类型：替换 
摘要：大型复杂数据集通常从多个可能异构的来源收集。多任务学习方法通​​过利用数据集之间的共性同时考虑它们之间可能存在的差异来提高效率。在这里，我们研究稀疏异质性下的多任务线性回归和上下文强盗，其中源/任务相关参数等于全局参数加上稀疏任务特定项。我们提出了一种称为 MOLAR 的新型两阶段估计器，它利用这种结构，首先构建任务线性回归估计的协变量加权中值，然后将任务估计缩小到加权中值。与任务最小二乘估计相比，MOLAR 改进了估计误差对数据维度的依赖性。本文讨论了 MOLAR 对广义线性模型的扩展以及构建置信区间。然后，我们应用 MOLAR 开发稀疏异构多任务上下文老虎机方法，获得比单任务老虎机方法更好的遗憾保证。我们进一步通过提供多个下限来证明我们的方法是极小极大最优的。最后，我们通过对来自异构国家的学生教育成果的合成数据和 PISA 数据集进行实验来支持我们方法的效率。]]></description>
      <guid>https://arxiv.org/abs/2306.06291</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向经典降维的一个模型：UMAP 和 t-SNE 的概率视角</title>
      <link>https://arxiv.org/abs/2405.17412</link>
      <description><![CDATA[arXiv:2405.17412v2 公告类型：替换 
摘要：本文表明，降维方法（例如 UMAP 和 t-SNE）可以近似地重铸为 MAP 推理方法，对应于 ProbDR 中引入的模型，该模型使用 Wishart 分布描述图拉普拉斯（精度/逆协方差的估计）矩阵，其均值由对潜在变量进行评估的非线性协方差函数给出。这种解释通过显示与这些协方差相对应的方差很低（且指定错误），并通过显示众所周知的核可用于描述图拉普拉斯算子隐含的协方差来建立与高斯过程潜变量模型的联系，为此类算法提供了更深入的理论和语义见解。我们还介绍了可以研究类似降维方法的工具，并提出了由这些解释产生的两个研究领域。]]></description>
      <guid>https://arxiv.org/abs/2405.17412</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>