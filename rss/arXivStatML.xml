<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 16 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>利用粘性 Hamilton-Jacobi PDE 进行科学机器学习中的不确定性量化</title>
      <link>https://arxiv.org/abs/2404.08809</link>
      <description><![CDATA[arXiv:2404.08809v1 公告类型：交叉
摘要：科学机器学习 (SciML) 中的不确定性量化 (UQ) 将 SciML 强大的预测能力与量化学习模型可靠性的方法相结合。然而，仍然存在两个主要挑战：可解释性有限和昂贵的培训程序。我们通过在 SciML 中出现的一些贝叶斯推理问题和粘性 Hamilton-Jacobi 偏微分方程 (HJ PDE) 之间建立新的理论联系，为 UQ 问题提供了新的解释。也就是说，我们证明后验均值和协方差可以从粘性 HJ PDE 解的空间梯度和 Hessian 矩阵中恢复。作为对这种联系的首次探索，我们专门研究线性模型、高斯似然和高斯先验的贝叶斯推理问题。在这种情况下，相关的粘性 HJ 偏微分方程可以使用 Riccati ODE 求解，并且我们开发了一种新的基于 Riccati 的方法，该方法在持续更新模型预测时提供计算优势。具体来说，我们基于 Riccati 的方法可以有效地向训练集中添加或删除数据点，且与数据顺序无关，并持续调整超参数。此外，这两种更新都不需要重新训练或访问先前合并的数据。我们提供了来自 SciML 的几个涉及噪声数据和 \textit{认知不确定性} 的示例，以说明我们方法的潜在优势。特别是，这种方法对数据流应用程序的适用性证明了其实时推理的潜力，这反过来又允许使用预测的不确定性来动态改变学习过程的应用程序。]]></description>
      <guid>https://arxiv.org/abs/2404.08809</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>多重稳健因果变化归因</title>
      <link>https://arxiv.org/abs/2404.08839</link>
      <description><![CDATA[arXiv:2404.08839v1 公告类型：交叉
摘要：比较两个数据样本，我们观察到结果变量分布的变化。在存在多个解释变量的情况下，每个可能的原因可以解释多少变化？我们开发了一种新的估计策略，在给定因果模型的情况下，结合回归和重新加权方法来量化每个因果机制的贡献。我们提出的方法是多重稳健的，这意味着它仍然可以在部分错误指定的情况下恢复目标参数。我们证明我们的估计量是一致的且渐近正态的。此外，它可以合并到现有的因果归因框架中，例如 Shapley 值，它将继承一致性和大样本分布属性。我们的方法在蒙特卡罗模拟中展示了出色的性能，并且在实证应用中展示了其有用性。]]></description>
      <guid>https://arxiv.org/abs/2404.08839</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>您经过微调的大型语言模型已经是一个强大的分布外检测器</title>
      <link>https://arxiv.org/abs/2404.08679</link>
      <description><![CDATA[arXiv:2404.08679v1 公告类型：交叉
摘要：我们重新审视预训练大语言模型（LLM）及其微调变体之间的似然比，作为分布外（OOD）检测的标准。这一标准背后的直觉是，预训练的LLM由于其大量的训练数据而具有关于OOD数据的先验知识，并且一旦与分布内数据进行微调，LLM就有足够的知识来区分它们的差异。利用 LLM 的力量，我们首次证明似然比可以作为有效的 OOD 检测器。此外，我们应用所提出的基于 LLM 的似然比来检测问答（QA）系统中的 OOD 问题，这可用于提高专门 LLM 对一般问题的性能。鉴于可以通过当代神经网络框架内的损失函数轻松获得似然性，因此在实践中实现这种方法很简单。由于预训练的 LLM 及其各种微调模型均可用，因此我们提出的标准可以轻松地纳入 OOD 检测，而无需进一步训练。我们对多种设置进行了综合评估，包括远 OOD、近 OOD、垃圾邮件检测和 QA 场景，以证明该方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.08679</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>单纯复形上的随机游走</title>
      <link>https://arxiv.org/abs/2404.08803</link>
      <description><![CDATA[arXiv:2404.08803v1 公告类型：交叉
摘要：图的拉普拉斯概念可以推广到单纯复形和超图，并且包含这些结构的拓扑信息。即使对于图来说，考虑相关的单纯复形对于理解其形状也是很有趣的。尽管图的拉普拉斯算子具有简单的概率解释，作为图上连续时间马尔可夫链的生成器，但在考虑单纯复形时，事情并不那么直接。我们在这里定义单纯复形上的新马尔可夫链。对于给定的阶 ~$k$，状态空间是 $k$ 循环的集合，它们是具有零边界的 $k$ 单纯形链。这个新框架是图上规范马尔可夫链的自然推广。我们证明了马尔可夫链的生成元是在离散结构的代数拓扑背景下定义的上拉普拉斯算子。我们建立了这个新过程的几个关键属性：特别是，当顶点数量有限时，马尔可夫链是正循环的。这个结果并非微不足道，因为循环可以无限次地循环自身。当所审查的单纯复形是一系列不断细化的平面环面三角剖分时，我们研究扩散极限。利用奇异同调性和霍奇同调性之间的类比，我们将该极限表示为电流集中的值。紧密性证明和极限鞅问题的识别利用了平坦范数并仔细控制了生成器收敛中的误差项。鞅问题解的唯一性尚未确定。进行了孔检测的应用。]]></description>
      <guid>https://arxiv.org/abs/2404.08803</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>无限维模型中约束函数参数的统计学习及其在公平机器学习中的应用</title>
      <link>https://arxiv.org/abs/2404.09847</link>
      <description><![CDATA[arXiv:2404.09847v1 公告类型：新
摘要：约束学习变得越来越重要，特别是在算法公平性和机器学习领域。在这些环境中，预测模型是专门为了满足预先定义的公平概念而开发的。在这里，我们通过统计函数镜头研究约束统计机器学习的一般问题。我们考虑在一个或多个预先指定的实值函数参数等于零或以其他方式有界的约束下学习感兴趣的函数值参数。我们使用拉格朗日乘数公式将受约束的函数参数描述为惩罚风险准则的最小值。我们表明，最佳约束参数的封闭式解决方案通常是可用的，从而提供了对推动预测模型公平性的机制的深入了解。我们的结果还建议了约束参数的自然估计，可以通过组合数据生成分布的无约束参数的估计来构建。因此，我们构建公平机器学习算法的估计过程可以与任何统计学习方法和现成软件结合应用。我们通过明确考虑统计公平性约束的许多示例并使用几种流行的学习方法来实现该方法，从而证明了我们方法的通用性。]]></description>
      <guid>https://arxiv.org/abs/2404.09847</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>不变子空间分解</title>
      <link>https://arxiv.org/abs/2404.09962</link>
      <description><![CDATA[arXiv:2404.09962v1 公告类型：新
摘要：我们考虑在给定 X 的 Y 条件分布随时间变化的设置中根据一组协变量 X 预测响应 Y 的任务。为了使其可行，需要假设条件分布如何随时间变化。例如，现有方法假设变化随着时间的推移平稳发生，因此仅使用最近的历史进行短期预测变得可行。在这项工作中，我们提出了一种新颖的基于不变性的线性条件框架，称为不变子空间分解（ISD），它将条件分布分为时不变分量和剩余时间相关分量。正如我们所展示的，这种分解可用于零样本和时间自适应预测任务，即在我们想要预测 Y 的时间点分别没有或少量训练数据可用的设置。我们提出了一种实用的估计程序，它使用近似联合矩阵对角化的工具自动推断分解。此外，我们为所提出的估计器提供有限样本保证，并凭经验证明它确实改进了不使用额外不变结构的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.09962</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>用于估计 COVID-19 对餐饮业消费者行为影响的贝叶斯回归方法</title>
      <link>https://arxiv.org/abs/2404.08670</link>
      <description><![CDATA[arXiv:2404.08670v1 公告类型：交叉
摘要：COVID-19 大流行对全球各行各业产生了长期影响，酒店和食品行业面临重大挑战，导致许多餐馆永久关闭和失业。在这项研究中，我们开发了一种创新的分析框架，使用哈密顿蒙特卡罗进行贝叶斯回归预测建模，旨在估计由于 COVID-19 导致的不同类型餐厅的消费者行为变化点。我们的方法强调计算分析中的新颖方法，提供对大流行前后客户行为变化的见解。这项研究有助于了解 COVID-19 对餐饮业的影响，对餐厅老板和政策制定者很有价值。]]></description>
      <guid>https://arxiv.org/abs/2404.08670</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>局部私有线性上下文强盗的最优后悔</title>
      <link>https://arxiv.org/abs/2404.09413</link>
      <description><![CDATA[arXiv:2404.09413v1 公告类型：新
摘要：具有线性奖励函数的上下文老虎机是老虎机和在线学习研究中研究最广泛的模型之一。最近，人们对设计\emph{本地私有}线性上下文强盗算法越来越感兴趣，其中上下文和奖励中包含的敏感信息受到保护，以免泄露给公众。虽然经典的线性上下文强盗算法通过多种替代方法承认 $\tilde O(\sqrt{T})$ 的累积遗憾上限，但在存在本地隐私约束的情况下是否可以实现这种遗憾界限仍然是一个悬而未决的问题。最先进的结果是 $\tilde O(T^{3/4})$。在本文中，我们证明确实有可能实现局部私有线性上下文老虎机的 $\tilde O(\sqrt{T})$ 遗憾上限。我们的解决方案依赖于几种新的算法和分析思想，例如平均绝对偏差误差的分析和分层主成分回归，以实现较小的平均绝对偏差误差。]]></description>
      <guid>https://arxiv.org/abs/2404.09413</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>装袋不足的复制品分析</title>
      <link>https://arxiv.org/abs/2404.09779</link>
      <description><![CDATA[arXiv:2404.09779v1 公告类型：新
摘要：Under-bagging（UB）方法是一种流行的用于从不平衡数据中训练分类器的集成学习方法，它的尖锐渐近性被推导出来，并与其他几种从不平衡数据中学习的标准方法进行了比较。其中线性分类器是根据二进制混合数据进行训练的。比较的方法包括欠采样 (US) 方法和简单加权 (SW) 方法，前者使用子采样数据集的单一实现来训练模型，后者使用整个数据的加权损失来训练模型。结果表明，即使类不平衡可能很大，尤其是当少数类的规模较小时，通过增加多数类的规模可以提高 UB 的性能。这与美国形成鲜明对比，美国的表现不会随着多数阶级规模的增加而变化，而SW则随着不平衡的增加而表现下降。这些结果与训练广义线性模型时不考虑类不平衡结构的朴素装袋的情况不同，表明集成和参数直接正则化之间的本质区别。]]></description>
      <guid>https://arxiv.org/abs/2404.09779</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>通过最优传输实现对数凹测度的坐标上升变分推理的收敛</title>
      <link>https://arxiv.org/abs/2404.08792</link>
      <description><![CDATA[arXiv:2404.08792v1 公告类型：新
摘要：平均场变分推理 (VI) 是在相对熵意义上找到与给定的高维概率度量 $\rho$ 最接近的乘积（因式分解）度量的问题。众所周知的坐标上升变分推理 (CAVI) 算法旨在通过一次迭代优化一个坐标（因子）来近似该乘积测量，这可以明确地完成。尽管 CAVI 很受欢迎，但人们对它的融合仍然知之甚少。在本文中，我们证明了 CAVI 对于对数凹密度 $\rho$ 的收敛性。如果另外 $\log \rho$ 具有 Lipschitz 梯度，我们会发现线性收敛速度，并且如果 $\rho$ 也是强对数凹的，我们会发现指数收敛速度。我们的分析从观察开始，即平均场 VI 虽然在通常意义上是众所周知的非凸，但实际上当 $\rho$ 是对数凹时，在最佳传输意义上是位移凸。这使我们能够采用欧几里得空间中坐标下降算法优化文献中的技术。]]></description>
      <guid>https://arxiv.org/abs/2404.08792</guid>
      <pubDate>Tue, 16 Apr 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>1 位矩阵补全中分数后验的浓度特性</title>
      <link>https://arxiv.org/abs/2404.08969</link>
      <description><![CDATA[arXiv:2404.08969v1 公告类型：新
摘要：基于一组观察到的条目估计矩阵的问题通常称为矩阵完成问题。在这项工作中，我们专门解决了二进制观察的场景，通常称为 1 位矩阵完成。虽然许多研究探索了实值矩阵补全的贝叶斯和频率论方法，但缺乏关于 1 位矩阵补全的贝叶斯方法的理论探索。我们通过考虑通用的、非均匀的采样方案并为分数后验的有效性提供理论保证来解决这一差距。我们的贡献包括获得分数后验的浓度结果并证明其在恢复基础参数矩阵方面的有效性。我们使用两种不同类型的先验分布来实现这一点：低秩分解先验和谱缩放学生先验，后者需要较少的假设。重要的是，我们的结果通过不要求参数矩阵的秩的先验知识表现出自适应性质。我们的研究结果与频率论文献中发现的结果相当，但需要较少的限制性假设。]]></description>
      <guid>https://arxiv.org/abs/2404.08969</guid>
      <pubDate>Tue, 16 Apr 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>通过熵正则化扩展平均场变分推理：理论与计算</title>
      <link>https://arxiv.org/abs/2404.09113</link>
      <description><![CDATA[arXiv:2404.09113v1 公告类型：新
摘要：变分推理（VI）已成为高维贝叶斯模型近似推理的流行方法。在本文中，我们提出了一种新颖的 VI 方法，通过熵正则化扩展朴素平均场，称为 $\Xi$-变分推理 ($\Xi$-VI)。 $\Xi$-VI 与熵最优传输问题密切相关，并受益于计算高效的 Sinkhorn 算法。我们证明$\Xi$-变分后验有效地恢复了真实的后验依赖性，其中依赖性通过正则化参数被降低了权重。我们分析了参数空间的维数对 $\Xi$-变分近似的准确性的作用以及它如何影响计算考虑因素，提供了 $\Xi$-VI 中统计计算权衡的粗略表征。我们还研究了 $\Xi$-VI 的频率属性，并建立了一致性、渐近正态性、高维渐近性和算法稳定性的结果。我们提供了使用该方法实现多项式时间近似推理的充分标准。最后，我们证明了 $\Xi$-VI 相对于模拟和真实数据的平均场变分推理的实际优势。]]></description>
      <guid>https://arxiv.org/abs/2404.09113</guid>
      <pubDate>Tue, 16 Apr 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>作为动态生成模型的状态空间系统</title>
      <link>https://arxiv.org/abs/2404.08717</link>
      <description><![CDATA[arXiv:2404.08717v1 公告类型：新
摘要：介绍了一个概率框架来研究确定性离散时间状态空间系统在输入和输出过程之间引起的依赖结构。一旦输入过程被固定，输出过程就存在并且是唯一的，一般的充分条件被公式化，该属性在确定性状态空间文献中被称为回波状态属性。当满足这些条件时，给定的状态空间系统就成为两个序列空间之间概率依赖性的生成模型。此外，这些条件保证了使用 Wasserstein 度量时输出持续依赖于输入。其存在被证明的输出过程在特定意义上是因果关系的，并且概括了在纯粹确定性情况下研究的结果。本文的结果构成了确定性回波状态属性成立的充分条件的重要随机推广，即随机回波状态属性可以在严格弱于确定性情况的收缩性条件下得到满足。这意味着状态空间系统可以在输入和输出序列空间之间引入纯粹的概率依赖结构，即使这两个空间之间没有函数关系。]]></description>
      <guid>https://arxiv.org/abs/2404.08717</guid>
      <pubDate>Tue, 16 Apr 2024 06:16:58 GMT</pubDate>
    </item>
    <item>
      <title>通过离散数据近似进行特定于观测的解释</title>
      <link>https://arxiv.org/abs/2404.08747</link>
      <description><![CDATA[arXiv:2404.08747v1 公告类型：新
摘要：这项工作介绍了特定于观察的解释的定义，为每个数据点分配与其在预测过程定义中的重要性成比例的分数。这种解释涉及识别对感兴趣的黑盒模型最有影响力的观察结果。所提出的方法包括利用正交匹配追踪算法通过分散数据近似构建代理模型来估计这些解释。所提出的方法在模拟和现实数据集上得到了验证。]]></description>
      <guid>https://arxiv.org/abs/2404.08747</guid>
      <pubDate>Tue, 16 Apr 2024 06:16:58 GMT</pubDate>
    </item>
    <item>
      <title>使用函数机制的差分私有日志位置尺度回归</title>
      <link>https://arxiv.org/abs/2404.08715</link>
      <description><![CDATA[arXiv:2404.08715v1 公告类型：新
摘要：本文介绍了差分隐私对数位置尺度（DP-LLS）回归模型，该模型通过功能机制将差分隐私融入到 LLS 回归中。所提出的模型是通过将噪声注入 LLS 回归的对数似然函数中以进行扰动参数估计来建立的。我们将导出用于确定注入噪声大小的灵敏度，并证明所提出的 DP-LLS 模型满足$\epsilon$-差分隐私。此外，我们将进行模拟和案例研究来评估所提出模型的性能。研究结果表明，预测维度、训练样本大小和隐私预算是影响所提出的 DP-LLS 回归模型性能的三个关键因素。此外，结果表明需要足够大的训练数据集来同时确保所提出的模型具有良好的性能并达到令人满意的隐私保护水平。]]></description>
      <guid>https://arxiv.org/abs/2404.08715</guid>
      <pubDate>Tue, 16 Apr 2024 06:16:57 GMT</pubDate>
    </item>
    </channel>
</rss>