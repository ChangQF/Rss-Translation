<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 06 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>量化分布变化和不确定性以增强机器学习应用中的模型稳健性</title>
      <link>https://arxiv.org/abs/2405.01978</link>
      <description><![CDATA[arXiv:2405.01978v1 公告类型：交叉
摘要：分布变化（训练数据集和测试数据集之间的统计属性不同）在现实世界的机器学习应用中提出了重大挑战，直接影响模型的泛化和鲁棒性。在这项研究中，我们通过利用合成数据系统地解决分布差异来探索模型的适应性和泛化。我们的研究旨在确定跨不同数据分布成功进行模型适应的先决条件，同时量化相关的不确定性。具体来说，我们使用气体的范德华方程生成合成数据，并采用 Kullback-Leibler 散度、Jensen-Shannon 距离和 Mahalanobis 距离等定量度量来评估数据相似性。这些指标使我们能够评估模型的准确性并量化数据分布变化引起的预测中的相关不确定性。我们的研究结果表明，利用马哈拉诺比斯距离等统计方法来确定模型预测是否属于低误差“插值体系”或高误差“外推体系”，为评估分布变化和模型不确定性提供了补充方法。这些见解对于增强模型的稳健性和泛化性具有重要价值，这对于在现实场景中成功部署机器学习应用程序至关重要。]]></description>
      <guid>https://arxiv.org/abs/2405.01978</guid>
      <pubDate>Mon, 06 May 2024 21:12:53 GMT</pubDate>
    </item>
    <item>
      <title>具有条件风险价值的鲁棒风险敏感强化学习</title>
      <link>https://arxiv.org/abs/2405.01718</link>
      <description><![CDATA[arXiv:2405.01718v1 公告类型：交叉
摘要：鲁棒马尔可夫决策过程（RMDP）受到了广泛的研究兴趣，为通常假设固定转移概率的标准马尔可夫决策过程（MDP）提供了替代方案。 RMDP 通过优化歧义集中最坏的情况来解决这个问题。虽然早期关于 RMDP 的研究主要集中在风险中性强化学习（RL）上，目标是最小化预期总贴现成本，但在本文中，我们分析了 RMDP 下基于 CVaR 的风险敏感强化学习的稳健性。首先，我们考虑预定的歧义集。基于 CVaR 的一致性，我们在鲁棒性和风险敏感性之间建立了联系，因此，可以采用风险敏感的 RL 技术来解决所提出的问题。此外，由于现实世界问题中存在决策相关的不确定性，我们研究了状态动作相关的模糊集问题。为了解决这个问题，我们定义了一个名为 NCVaR 的新风险度量，并建立了 NCVaR 优化和鲁棒 CVaR 优化的等价关系。我们进一步提出了价值迭代算法，并在模拟实验中验证了我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2405.01718</guid>
      <pubDate>Mon, 06 May 2024 21:12:52 GMT</pubDate>
    </item>
    <item>
      <title>判别广义狄利克雷分类器的分层混合</title>
      <link>https://arxiv.org/abs/2405.01778</link>
      <description><![CDATA[arXiv:2405.01778v1 公告类型：交叉
摘要：本文提出了一种用于成分数据的判别分类器。该分类器基于广义狄利克雷的后验分布，广义狄利克雷是广义狄利克雷混合模型的判别对应物。此外，遵循专家混合范式，我们提出了该分类器的分层混合。为了学习模型参数，我们通过推导广义狄利克雷混合的上限来使用变分近似。据我们所知，这是文献中首次提出这个界限。给出了垃圾邮件检测和颜色空间识别的实验结果。]]></description>
      <guid>https://arxiv.org/abs/2405.01778</guid>
      <pubDate>Mon, 06 May 2024 21:12:52 GMT</pubDate>
    </item>
    <item>
      <title>具有 O(Nd) 运算的完整 Adagrad 算法</title>
      <link>https://arxiv.org/abs/2405.01908</link>
      <description><![CDATA[arXiv:2405.01908v1 公告类型：交叉
摘要：提出了一种新方法来克服随机优化中全矩阵自适应梯度算法（Full AdaGrad）的计算挑战。通过开发一种估计梯度协方差平方根的倒数的递归方法，以及用于参数更新的流式变体，该研究为大规模应用提供了高效实用的算法。这种创新策略显着降低了通常与全矩阵方法相关的复杂性和资源需求，从而实现更有效的优化过程。此外，还给出了所提出的估计器的收敛速度及其渐近效率。它们的有效性通过数值研究得到证明。]]></description>
      <guid>https://arxiv.org/abs/2405.01908</guid>
      <pubDate>Mon, 06 May 2024 21:12:52 GMT</pubDate>
    </item>
    <item>
      <title>公平风险控制：校准多群体公平风险的通用框架</title>
      <link>https://arxiv.org/abs/2405.02225</link>
      <description><![CDATA[arXiv:2405.02225v1 公告类型：新
摘要：本文介绍了一种后处理机器学习模型的框架，使其预测满足多组公平性保证。基于著名的多重校准概念，我们引入 $(\mathbf{s},\mathcal{G}, \alpha)-$GMC（广义多维多重校准）用于多维映射 $\mathbf{s}$，约束集$\mathcal{G}$，以及预先指定的阈值水平$\alpha$。我们提出了相关算法来在一般设置中实现这一概念。然后将该框架应用于涵盖不同公平性问题的不同场景，包括图像分割中的假阴性率控制、层次分类中的预测集条件不确定性量化以及语言模型中的去偏文本生成。我们对多个数据集和任务进行数值研究。]]></description>
      <guid>https://arxiv.org/abs/2405.02225</guid>
      <pubDate>Mon, 06 May 2024 21:12:51 GMT</pubDate>
    </item>
    <item>
      <title>统一和扩展用于评估生成模型的精确召回指标</title>
      <link>https://arxiv.org/abs/2405.01611</link>
      <description><![CDATA[arXiv:2405.01611v1 公告类型：交叉
摘要：随着近年来生成模型在图像和文本领域的成功，生成模​​型的评估受到了广泛的关注。虽然大多数生成模型都是根据标量值进行比较，例如 Frechet Inception Distance (FID) 或 Inception Score (IS)，但近年来（Sajjadi et al., 2018）提出了精确率-召回率曲线的定义来表征接近度的两个分布。从那时起，各种精确率和召回率方法开始崭露头角（Kynkaanniemi et al., 2019；Naeem et al., 2020；Park &amp; Kim, 2023）。他们将注意力集中在精确度和召回率的极端值上，但除此之外，它们之间的联系是难以捉摸的。在本文中，我们依靠（Simon 等人，2019）的工作，将大多数这些方法统一在同一框架下。这样做，我们不仅能够恢复整个曲线，而且还能暴露相关指标的陷阱来源。我们还提供了远远超出相应文献中提出的一致性结果。最后，我们研究了实验获得的曲线的不同行为。]]></description>
      <guid>https://arxiv.org/abs/2405.01611</guid>
      <pubDate>Mon, 06 May 2024 21:12:51 GMT</pubDate>
    </item>
    <item>
      <title>随机广义 Stiefel 流形的无回缩优化</title>
      <link>https://arxiv.org/abs/2405.01702</link>
      <description><![CDATA[arXiv:2405.01702v1 公告类型：交叉
摘要：对满足 $X^\top B X = I_p$ 的矩阵集进行优化，称为广义 Stiefel 流形，出现在许多涉及采样协方差矩阵的应用中，例如规范相关分析 (CCA)、独立分量分析 (ICA) ）和广义特征值问题（GEVP）。解决这些问题通常是通过迭代方法来完成的，例如黎曼方法，这需要计算成本高昂的特征值分解，涉及完全形成的 $B$。我们提出了一种廉价的随机迭代方法，该方法可以解决优化问题，同时只能访问可行集的随机估计。我们的方法并不在每次迭代中严格强制约束，而是产生收敛到期望中定义的广义 Stiefel 流形上的临界点的迭代。该方法具有较低的每次迭代成本，仅需要矩阵乘法，并且具有与涉及全矩阵 $B$ 的黎曼对应方法相同的收敛速度。实验证明了其在涉及广义正交约束的各种机器学习应用中的有效性，包括 CCA、ICA 和 GEVP。]]></description>
      <guid>https://arxiv.org/abs/2405.01702</guid>
      <pubDate>Mon, 06 May 2024 21:12:51 GMT</pubDate>
    </item>
    <item>
      <title>具有异构子组的数据的最小最大遗憾学习</title>
      <link>https://arxiv.org/abs/2405.01709</link>
      <description><![CDATA[arXiv:2405.01709v1 公告类型：交叉
摘要：现代复杂数据集通常由各种子群体组成。为了在存在子群体异质性的情况下开发稳健且可推广的方法，重要的是保证统一的学习性能而不是平均的学习性能。在许多应用中，通常可以获得关于数据点属于哪个子群体或组的先验信息。给定观察到的数据组，我们开发了一个用于一般监督学习的最小-最大-遗憾（MMR）学习框架，其目标是最小化最差组的遗憾。受基于后悔的决策理论框架的启发，所提出的 MMR 与现有文献中基于价值或基于风险的鲁棒学习方法不同。遗憾准则同时具有多种鲁棒性和不变性特性。在普遍性方面，我们为元数据的超级总体中最坏情况的遗憾提供了理论保证，其中包含观察到的子总体、它们的混合物，以及可以通过以下方式近似的其他未见过的子总体：观察到的。我们通过广泛的模拟研究以及对来自数百个移植中心的肾移植数据的应用来证明我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.01709</guid>
      <pubDate>Mon, 06 May 2024 21:12:51 GMT</pubDate>
    </item>
    <item>
      <title>统计序贯决策的数学：随机赌博机中的集中度、风险意识和建模及其在减肥手术中的应用</title>
      <link>https://arxiv.org/abs/2405.01994</link>
      <description><![CDATA[arXiv:2405.01994v1 公告类型：新
摘要：本论文旨在研究术后患者随访统计序贯决策算法分析中出现的一些数学挑战。随机老虎机（多臂、上下文）对代理在不确定环境中学习一系列动作（策略）进行建模，以最大化观察到的奖励。为了学习最优策略，强盗算法必须平衡对当前知识的利用和对不确定行为的探索。此类算法已在具有大型数据集、低风险决策和明确建模假设的工业应用中得到广泛研究和部署，例如在线广告中的点击率最大化。相比之下，数字健康建议需要一种全新的小样本范式、规避风险的代理和复杂的非参数建模。为此，我们开发了新的安全、随时有效的浓度界限（Bregman，经验 Chernoff），引入了风险意识上下文强盗的新框架（具有可引出的风险度量），并在弱假设下分析了一类新型非参数强盗算法（狄利克雷采样）。除了理论保证外，这些结果还得到深入的经验证据的支持。最后，作为个性化术后随访建议的第一步，我们与医生和外科医生一起开发了一种可解释的机器学习模型，以预测减肥手术后患者的长期体重轨迹。]]></description>
      <guid>https://arxiv.org/abs/2405.01994</guid>
      <pubDate>Mon, 06 May 2024 21:12:50 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中有效不确定性量化的共形预测方法的比较研究</title>
      <link>https://arxiv.org/abs/2405.02082</link>
      <description><![CDATA[arXiv:2405.02082v1 公告类型：新
摘要：在过去的几十年中，数据分析和机器学习领域的大多数工作都集中在优化预测模型并获得比现有模型更好的结果。衡量此类改进的指标在多大程度上准确地捕捉了预期目标，结果值的数值差异是否显着，或者不确定性是否在本研究中发挥了作用以及是否应该考虑到这一点，这些都是重要的。次要重要性。尽管概率论，无论是频率论还是贝叶斯论，在超级计算机出现之前曾经是科学的黄金标准，但它很快就被黑盒模型和纯粹的计算能力所取代，因为它们能够处理大型数据集。遗憾的是，这种演变是以牺牲可解释性和可信性为代价的。然而，虽然人们仍在努力提高模型的预测能力，但社区开始意识到，对于许多应用来说，重要的并不是准确的预测，而是可变性或不确定性。
  本论文的工作试图进一步探索一个每个人都意识到不确定性、不确定性的重要性以及如何拥抱它而不是害怕它的世界。挑选并分析了一个具体但通用的框架，该框架允许任何人获得准确的不确定性估计。该框架的某些方面和应用（称为“共形预测”）得到了详细研究。尽管许多不确定性量化方法都对数据做出了强有力的假设，但在撰写本文时，保形预测是唯一配得上“无分布”称号的框架。无需进行任何参数假设，并且非参数结果也成立，而无需诉诸渐近体系中的大数定律。]]></description>
      <guid>https://arxiv.org/abs/2405.02082</guid>
      <pubDate>Mon, 06 May 2024 21:12:50 GMT</pubDate>
    </item>
    <item>
      <title>对抗性马尔可夫决策过程中在线学习的乐观后悔界限</title>
      <link>https://arxiv.org/abs/2405.02188</link>
      <description><![CDATA[arXiv:2405.02188v1 公告类型：新
摘要：对抗性马尔可夫决策过程（AMDP）是一种学习框架，用于处理机器人和推荐系统等决策应用中未知和变化的任务。然而，AMDP 形式主义的一个主要限制是悲观的遗憾分析结果，即虽然成本函数可以从一个事件到下一个事件发生变化，但许多情况下的演变并不是对抗性的。为了解决这个问题，我们引入并研究了 AMDP 的一种新变体，其目的是在利用一组成本预测因子的同时最大限度地减少遗憾。对于这种设置，我们开发了一种新的策略搜索方法，该方法以高概率实现亚线性乐观遗憾，即遗憾界限，随着成本预测器的估计能力而优雅地降低。建立这种乐观的遗憾界限并非易事，因为 (i) 正如我们所证明的，现有的重要性加权成本估计器无法建立乐观的界限，并且 (ii) AMDP 的反馈模型与现有的乐观在线学习不同（并且更现实）作品。我们的结果尤其取决于开发一种新颖的乐观偏差成本估计器，该估计器利用成本预测器并在不施加限制性假设的情况下实现高概率后悔分析。我们进一步讨论了所提出方案的实际扩展，并以数字方式证明了其有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.02188</guid>
      <pubDate>Mon, 06 May 2024 21:12:50 GMT</pubDate>
    </item>
    <item>
      <title>ReLU 网络的三种量化机制</title>
      <link>https://arxiv.org/abs/2405.01952</link>
      <description><![CDATA[arXiv:2405.01952v1 公告类型：新
摘要：我们通过具有有限精度权重的深度 ReLU 神经网络建立了 Lipschitz 函数逼近的基本限制。具体来说，根据作为网络权重精度的函数的极小极大近似误差行为，识别出三种状态，即欠量化、过度量化和适当量化。这是通过推导极小极大近似误差的非渐近严格下限和上限来实现的。值得注意的是，在适当的量化机制中，神经网络在 Lipschitz 函数的近似中表现出记忆最优性。深层网络在实现内存优化方面比浅层网络具有固有的优势。我们还开发了深度精度权衡的概念，表明具有高精度权重的网络可以转换为功能等效的具有低精度权重的更深网络，同时保持内存最优性。这个想法让人想起 sigma-delta 模数转换，其中过采样率被用来换取信号样本量化分辨率。我们改进了 Lipschitz 函数的最著名的 ReLU 网络近似结果，并描述了位提取技术的改进，这可能具有独立的普遍兴趣。]]></description>
      <guid>https://arxiv.org/abs/2405.01952</guid>
      <pubDate>Mon, 06 May 2024 21:12:49 GMT</pubDate>
    </item>
    <item>
      <title>了解法学硕士需要的不仅仅是统计概括</title>
      <link>https://arxiv.org/abs/2405.01964</link>
      <description><![CDATA[arXiv:2405.01964v1 公告类型：新
摘要：过去十年，深度学习理论的研究蓬勃发展，试图回答“为什么深度学习具有泛化能力？”一个重大的视角转变促成了这一进展：插值机制中过参数化模型的研究。在本文中，我们认为需要进行另一种观点转变，因为法学硕士的一些理想品质并不是良好统计概括的结果，需要单独的理论解释。我们的核心论点依赖于这样的观察：AR 概率模型本质上是不可识别的：模型的 KL 散度为零或接近零——因此，等效的测试损失——可以表现出明显不同的行为。我们用数学例子和经验观察来支持我们的立场，并通过三个案例研究说明为什么不可识别性具有实际意义：（1）零样本规则外推的不可识别性； （2）情境学习的近似不可识别性； (3)微调的不可识别性。我们回顾了有前途的研究方向，重点是法学硕士相关的泛化措施、可转移性和归纳偏差。]]></description>
      <guid>https://arxiv.org/abs/2405.01964</guid>
      <pubDate>Mon, 06 May 2024 21:12:49 GMT</pubDate>
    </item>
    <item>
      <title>隐式 HMM 的样本高效神经似然性贝叶斯推理</title>
      <link>https://arxiv.org/abs/2405.01737</link>
      <description><![CDATA[arXiv:2405.01737v1 公告类型：新
摘要：与 ABC 等经典方法相比，基于神经条件密度估计的无似然推理方法被证明可以大大减少模拟负担。当应用于任何潜在变量模型（例如隐马尔可夫模型 (HMM)）时，这些方法旨在仅估计参数，而不是参数和隐藏状态的联合分布。将这些方法简单应用于 HMM，忽略这种联合后验分布的推断，将导致对后验预测分布的估计不准确，进而妨碍拟合优度的评估。为了解决这个问题，我们提出了一种新颖的、样本高效的无似然方法来估计隐式 HMM 的高维隐藏状态。我们的方法依赖于利用马尔可夫特性，使用自回归流直接学习隐藏状态的难处理后验分布。在对我们的一些隐式 HMM 的方法进行评估后，我们发现使用我们的方法检索到的估计值的质量与使用计算成本更高的 SMC 算法所能实现的质量相当。]]></description>
      <guid>https://arxiv.org/abs/2405.01737</guid>
      <pubDate>Mon, 06 May 2024 21:12:48 GMT</pubDate>
    </item>
    <item>
      <title>多元贝叶斯回归的最后一层：不确定性量化和解开</title>
      <link>https://arxiv.org/abs/2405.01761</link>
      <description><![CDATA[arXiv:2405.01761v1 公告类型：新
摘要：我们在异方差噪声下的多元回归设置中提出了新的贝叶斯最后一层模型，并提出了一种参数学习的优化算法。贝叶斯最后一层将预测分布的贝叶斯建模与用于先验参数化的神经网络相结合，并具有通过单次前向传递进行不确定性量化的有吸引力的特性。所提出的框架能够解开任意和认知的不确定性，并且可用于将经过规范训练的深度神经网络转移到具有不确定性感知能力的新数据域。]]></description>
      <guid>https://arxiv.org/abs/2405.01761</guid>
      <pubDate>Mon, 06 May 2024 21:12:48 GMT</pubDate>
    </item>
    </channel>
</rss>