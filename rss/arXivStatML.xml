<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 01 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>多视图数据中缺失值的插补</title>
      <link>https://arxiv.org/abs/2210.14484</link>
      <description><![CDATA[arXiv:2210.14484v3 公告类型：替换
摘要：由多个不同特征集（称为视图）描述一组对象的数据被称为多视图数据。当多视图数据中出现缺失值时，视图中的所有要素可能会同时缺失。这导致大量缺失数据，特别是与高维数据结合时，使得条件插补方法的应用在计算上不可行。我们基于现有的堆叠惩罚逻辑回归（StaPLR）算法引入了一种新的插补方法，用于多视图学习。它在降维空间中执行插补，以解决多视图上下文固有的计算挑战。我们在模拟数据集中比较了新插补方法与几种现有插补算法的性能。结果表明，新的插补方法可以以低得多的计算成本获得有竞争力的结果，并且可以在无法计算的情况下使用高级插补算法（例如 missForest 和预测均值匹配）。]]></description>
      <guid>https://arxiv.org/abs/2210.14484</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>用于噪声混合物中目标信号恢复的统计分量分离</title>
      <link>https://arxiv.org/abs/2306.15012</link>
      <description><![CDATA[arXiv:2306.15012v3 公告类型：替换
摘要：当人们只对给定信号的特定属性感兴趣时，从加性混合物中分离信号可能是一个不必要的难题。在这项工作中，我们解决了更简单的“统计成分分离”问题，重点是从噪声混合物中恢复目标信号的一组预定义统计描述符。假设访问噪声过程的样本，我们研究了一种方法，该方法旨在将被噪声样本破坏的候选解决方案的统计数据与观察到的混合物的统计数据相匹配。我们首先使用简单的示例和易于分析的计算来分析该方法的行为。然后，我们将其应用到图像去噪环境中，使用 1）基于小波的描述符，2）基于天体物理学和 ImageNet 数据的 ConvNet 描述符。在 1) 的情况下，我们表明在大多数情况下我们的方法比标准去噪方法更好地恢复了目标数据的描述符。此外，尽管不是为此目的而构建的，但它在全信号重建的峰值信噪比方面表现得令人惊讶。相比之下，表示 2) 似乎不太适合图像去噪。最后，我们通过引入扩散逐步算法来扩展该方法，该算法为初始方法提供了新的视角，并在特定情况下为图像去噪带来了有希望的结果。]]></description>
      <guid>https://arxiv.org/abs/2306.15012</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>用于上下文学习的多头 Softmax Attention 的训练动态：涌现、收敛和最优性</title>
      <link>https://arxiv.org/abs/2402.19442</link>
      <description><![CDATA[arXiv:2402.19442v1 公告类型：交叉
摘要：我们研究了梯度流的动力学，用于训练多头 softmax 注意力模型，用于多任务线性回归的上下文学习。我们在适当的初始化选择下建立了梯度流的全局收敛。此外，我们证明了在梯度流动力学过程中出现了一个有趣的“任务分配”现象，其中每个注意力头专注于解决多任务模型的单个任务。具体来说，我们证明梯度流动力学可以分为三个阶段：一个是热身阶段，其中损失下降相当缓慢，注意力头逐渐建立对单个任务的倾向；一个是出现阶段，其中每个头选择一个任务任务和损失迅速减少，以及注意力参数收敛到极限的收敛阶段。此外，我们证明了梯度流的最优性，即通过梯度流学习的限制模型与最佳可能的多头 Softmax 注意力模型在常数因子范围内相当。我们的分析还描绘了单头和多头注意力模型之间 ICL 预测准确性的严格区别。我们收敛分析的关键技术是将参数空间中的梯度流动力学映射到谱域中的一组常微分方程，其中注意力权重的半奇异值的相对大小决定任务分配。据我们所知，我们的工作为多头 Softmax 注意力模型提供了第一个收敛结果。]]></description>
      <guid>https://arxiv.org/abs/2402.19442</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>重尾类不平衡以及为什么 Adam 在语言模型上优于梯度下降</title>
      <link>https://arxiv.org/abs/2402.19449</link>
      <description><![CDATA[arXiv:2402.19449v1 公告类型：交叉
摘要：Adam 在优化大型语言转换器方面已被证明在经验上优于梯度下降，并且比其他任务有更大的优势，但尚不清楚为什么会发生这种情况。我们表明，语言建模任务中发现的重尾类不平衡会导致优化动态方面的困难。当使用梯度下降进行训练时，与不频繁单词相关的损失比与频繁单词相关的损失下降得慢。由于大多数样本来自相对不频繁的单词，平均损失随着梯度下降缓慢下降。另一方面，Adam 和基于符号的方法不会遇到这个问题，并且改进了所有类别的预测。为了确定这种行为确实是由类别不平衡引起的，我们凭经验证明它在语言转换器、视觉 CNN 和线性模型上的不同架构和数据类型中持续存在。我们在具有交叉熵损失的线性分类上进一步研究了这种现象，表明重尾类不平衡会导致病态，而 Adam 使用的归一化可以抵消它。]]></description>
      <guid>https://arxiv.org/abs/2402.19449</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>不确定性分解基准：专门任务的专门不确定性</title>
      <link>https://arxiv.org/abs/2402.19460</link>
      <description><![CDATA[arXiv:2402.19460v1 公告类型：交叉
摘要：不确定性量化曾经是一项单一任务，现已发展成为一系列任务，包括弃权预测、分布外检测和任意不确定性量化。最新的目标是解开：构建多个估算器，每个估算器都针对一项且仅一项任务进行定制。因此，最近出现了大量具有不同意图的进展，而这些进展往往完全偏离实际行为。本文对 ImageNet 上不同任务的众多不确定性估计器进行了全面评估。我们发现，尽管理论上的努力很有希望，但在实践中尚未实现解脱。此外，我们还揭示了哪些不确定性估计器擅长哪些特定任务，为从业者提供见解，并指导未来的研究转向以任务为中心和解开的不确定性估计方法。我们的代码可在 https://github.com/bmucsanyi/bud 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.19460</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>半监督 U 统计</title>
      <link>https://arxiv.org/abs/2402.18921</link>
      <description><![CDATA[arXiv:2402.18921v1 公告类型：交叉
摘要：半监督数据集在不同领域中普遍存在，其中获取完全标记的数据成本高昂或耗时。此类数据集的流行一直推动着对利用未标记数据潜力的新工具和方法的需求。为了满足这一需求，我们引入了通过大量未标记数据增强的半监督 U 统计，并研究了它们的统计特性。我们表明，所提出的方法是渐近正态的，并且通过有效地将各种强大的预测工具集成到框架中，比经典 U 统计显示出显着的效率增益。为了理解问题的根本困难，我们在半监督设置中推导了极小极大下界，并展示了我们的程序在正则条件下是半参数有效的。此外，针对双变量内核，我们提出了一种改进的方法，该方法在所有简并状态下都优于经典的 U 统计，并证明了其最优性属性。进行模拟研究是为了证实我们的发现并进一步证明我们的框架。]]></description>
      <guid>https://arxiv.org/abs/2402.18921</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>异质过分散计数时间序列的负二项式随机伽马马尔可夫过程</title>
      <link>https://arxiv.org/abs/2402.18995</link>
      <description><![CDATA[arXiv:2402.18995v1 公告类型：交叉
摘要：自从计数时间序列自然出现在物理和社会领域以来，对计数值时间序列进行建模已受到越来越多的关注。泊松伽马动力系统（PGDS）是新开发的方法，可以很好地捕获计数序列背后的表达性潜在跃迁结构和突发动态。特别是，与基于规范线性动力系统（LDS）的方法相比，PGDS 在数据插补和预测方面表现出优越的性能。尽管有这些优点，PGDS 仍无法捕获底层动态过程的异构过度分散行为。为了缓解这一缺陷，我们提出了一种负二项式随机伽马马尔可夫过程，它不仅显着提高了所提出的动态系统的预测性能，而且有利于推理算法的快速收敛。此外，我们开发了估计因子结构和图结构转换动态的方法，这使我们能够推断出与 PGDS 相比更可解释的潜在结构。最后，我们展示了所提出的方法学习到的可解释的潜在结构，并展示了与相关模型相比，其在估算缺失数据和预测未来观测方面的优越性能。]]></description>
      <guid>https://arxiv.org/abs/2402.18995</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>0-1神经网络在处方和预测中的应用</title>
      <link>https://arxiv.org/abs/2402.18851</link>
      <description><![CDATA[arXiv:2402.18851v1 公告类型：交叉
摘要：医疗决策中的一个关键挑战是通过有限的观察数据了解患者的治疗政策。这一挑战在个性化医疗决策中尤为明显，其中模型需要考虑患者特征、治疗选择和健康结果之间的复杂关系。为了解决这个问题，我们引入了规范网络（PNN），这是一种经过混合整数编程训练的浅层 0-1 神经网络，可以与反事实估计一起使用，以优化中等数据设置中的策略。这些模型比深度神经网络提供了更好的可解释性，并且可以编码比决策树等常见模型更复杂的策略。我们表明，PNN 在合成数据实验和分配产后高血压治疗的案例研究中都优于现有方法。特别是，PNN 被证明可以制定政策，与现有临床实践相比，可以将峰值血压降低 5.47 毫米汞柱 (p=0.02)，与下一个最佳处方建模技术相比，可以降低 2 毫米汞柱 (p=0.01)。此外，PNN 比所有其他模型更有可能正确识别临床重要特征，而现有模型依赖于潜在危险的特征，例如患者保险信息和种族，可能导致治疗偏差。]]></description>
      <guid>https://arxiv.org/abs/2402.18851</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>监督对比表示学习：具有不受约束特征的景观分析</title>
      <link>https://arxiv.org/abs/2402.18884</link>
      <description><![CDATA[arXiv:2402.18884v1 公告类型：交叉
摘要：最近的研究结果表明，经过零训练误差训练的过度参数化深度神经网络在最后一层表现出独特的结构模式，称为神经崩溃（NC）。这些结果表明，此类网络中的最终隐藏层输出在训练集上显示出最小的类内变化。虽然现有的研究广泛研究了交叉熵损失下的这种现象，但很少有研究关注其对比损失，即监督对比（SC）损失。本文通过 NC 的视角，采用分析方法来研究优化 SC 损耗的解决方案。我们采用无约束特征模型（UFM）作为代表性代理，用于揭示充分过度参数化的深度网络中与 NC 相关的现象。我们表明，尽管 SC 损失最小化具有非凸性，但所有局部最小值都是全局最小值。此外，最小化器是唯一的（最多旋转）。我们通过形式化 UFM 的紧凸松弛来证明我们的结果。最后，通过这个凸公式，我们更深入地研究了标签不平衡训练数据下全局解决方案的特性。]]></description>
      <guid>https://arxiv.org/abs/2402.18884</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>随机对照试验中逻辑回归的预后协变量调整</title>
      <link>https://arxiv.org/abs/2402.18900</link>
      <description><![CDATA[arXiv:2402.18900v1 公告类型：交叉
摘要：具有二元主要终点的随机对照试验（RCT）为推断治疗的因果效应带来了新的挑战。最重要的挑战是不可折叠性，其中协变量调整下的条件比值比估计值与 RCT 数据的逻辑回归分析中的无条件估计值不同。这个问题引起了明显的悖论，例如来自协变量调整模型的条件比值比的估计量的方差大于来自未调整模型的估计量的方差。我们在基于生成人工智能（AI）算法的控制结果预测（称为预后评分）的调整背景下解决了这一挑战。我们证明，与未调整的分析相比，逻辑回归中的预后评分调整增加了固定样本量下条件比值比的 Wald 检验的功效，或者减少了实现所需功效所需的样本量。我们推导出用于功率增益和样本量减少的前瞻性计算的公式，这些功率增益和样本量减少可能是由于预后评分的调整而导致的。此外，我们利用 g 计算将预后评分调整的范围扩大到边际风险差异、相对风险和优势比估计值的推断。我们通过涵盖不同类型逻辑回归模型规范的广泛模拟研究证明了我们公式的有效性。我们的模拟研究还表明，预后评分调整如何减少边际估计量的 g 计算估计量的方差，同时保持渐近无偏性和 I 类错误率控制等频率特性。我们的方法最终可以为具有二元主要终点的随机对照试验提供更明确和结论性的分析。]]></description>
      <guid>https://arxiv.org/abs/2402.18900</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>BlockEcho：保留长范围依赖性以估算逐块丢失数据</title>
      <link>https://arxiv.org/abs/2402.18800</link>
      <description><![CDATA[arXiv:2402.18800v1 公告类型：交叉
摘要：分块缺失数据给现实世界的数据插补任务带来了重大挑战。与分散的缺失数据相比，块级间隙加剧了对后续分析和机器学习任务的不利影响，因为局部相邻元素的缺乏显着降低了插值能力和预测能力。然而，这个问题并没有得到足够的重视。大多数 SOTA 矩阵补全方法似乎效率较低，这主要是由于过度依赖相邻元素进行预测。我们系统地分析了这个问题，并提出了一种新颖的矩阵补全方法“BlockEcho”，以提供更全面的解决方案。该方法创造性地将矩阵分解（MF）集成到生成对抗网络（GAN）中，以明确地保留网络中的长距离元素间关系。原始矩阵。此外，我们为 GAN 加入了一个额外的判别器，将生成器的中间进度与预训练的 MF 结果进行比较，以约束高阶特征分布。随后，我们在三个领域的公共数据集上评估 BlockEcho。结果表明，两者相比都具有优越的性能传统方法和 SOTA 方法在插补逐块缺失数据时，特别是在较高缺失率下。该优势也适用于高缺失率下的分散缺失数据。我们还为分析提供了融合 MF 和 MF 的最优性和收敛性的理论依据。 GAN 用于丢失块数据。]]></description>
      <guid>https://arxiv.org/abs/2402.18800</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:13 GMT</pubDate>
    </item>
    <item>
      <title>VEC-SBM：具有矢量边缘协变量的最优社区检测</title>
      <link>https://arxiv.org/abs/2402.18805</link>
      <description><![CDATA[arXiv:2402.18805v1 公告类型：交叉
摘要：社交网络通常与丰富的辅助信息相关，例如文本和图像。尽管已经开发了许多方法来从成对交互中识别社区，但它们通常忽略此类辅助信息。在这项工作中，我们研究了随机块模型（SBM）的扩展，这是一种广泛使用的社区检测统计框架，它集成了矢量边缘协变量：矢量边缘协变量随机块模型（VEC-SBM）。我们提出了一种基于迭代细化技术的新颖算法，并表明它可以最佳地恢复 VEC-SBM 下的潜在社区。此外，我们严格评估在社区检测过程中利用边缘辅助信息的附加值。我们通过合成和半合成数据的数值实验来补充我们的理论结果。]]></description>
      <guid>https://arxiv.org/abs/2402.18805</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:13 GMT</pubDate>
    </item>
    <item>
      <title>通过迭代比例拟合从边际推断动态网络</title>
      <link>https://arxiv.org/abs/2402.18697</link>
      <description><![CDATA[arXiv:2402.18697v1 公告类型：新
摘要：由现实世界的数据约束引起的一个常见的网络推理问题是如何从时间聚合的邻接矩阵和时变边际（即行和列之和）推断动态网络。解决此问题的先前方法已经重新利用了经典的迭代比例拟合 (IPF) 程序（也称为 Sinkhorn 算法），并取得了有希望的经验结果。然而，使用 IPF 的统计基础尚未得到很好的理解：在什么设置下，IPF 从其边缘提供动态网络的原则性估计，以及它对网络的估计效果如何？在这项工作中，我们通过识别生成网络模型来建立这样的设置，其最大似然估计由 IPF 恢复。我们的模型既揭示了在此类设置中使用 IPF 的隐含假设，又支持新的分析，例如 IPF 参数估计的结构相关误差范围。当IPF在稀疏网络数据上无法收敛时，我们引入了一种原理性算法，保证IPF在网络结构变化最小的情况下收敛。最后，我们使用合成数据和真实数据进行实验，证明了我们的理论和算法贡献的实用价值。]]></description>
      <guid>https://arxiv.org/abs/2402.18697</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>聆听噪音：使用吉布斯扩散进行盲降噪</title>
      <link>https://arxiv.org/abs/2402.19455</link>
      <description><![CDATA[arXiv:2402.19455v1 公告类型：新
摘要：近年来，去噪问题与深度生成模型的发展交织在一起。特别是，扩散模型像降噪器一样进行训练，并且它们建模的分布与贝叶斯图像中的降噪先验一致。然而，通过基于扩散的后验采样去噪需要已知噪声水平和协方差，从而防止盲目去噪。我们通过引入吉布斯扩散（GDiff）克服了这一限制，吉布斯扩散是一种解决信号和噪声参数后采样问题的通用方法。假设存在任意参数高斯噪声，我们开发了一种吉布斯算法，该算法从经过训练的条件扩散模型中交替采样步骤，以将信号映射到噪声分布族之前，并使用蒙特卡罗采样器来推断噪声参数。我们的理论分析强调了潜在的陷阱，指导诊断使用，并量化由扩散模型引起的吉布斯平稳分布中的误差。我们展示了我们的方法：1）涉及具有未知幅度和光谱指数的有色噪声的自然图像的盲去噪，以及2）宇宙学问题，即宇宙微波背景数据的分析，其中“噪声”参数的贝叶斯推断意味着约束模型宇宙的演化。]]></description>
      <guid>https://arxiv.org/abs/2402.19455</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>通过梯度下降学习联想记忆</title>
      <link>https://arxiv.org/abs/2402.18724</link>
      <description><![CDATA[arXiv:2402.18724v1 公告类型：交叉
摘要：这项工作的重点是存储令牌嵌入外积的一个关联记忆模块的训练动态。我们将这个问题简化为对粒子系统的研究，粒​​子系统根据数据分布的属性和嵌入之间的相关性进行交互。通过理论和实验，我们提供了一些见解。在过度参数化的情况下，我们获得了“分类裕度”的对数增长。然而，我们表明，由于相关嵌入导致的令牌频率和内存干扰的不平衡会导致振荡的瞬时状态。大步长时振荡更加明显，这可能会产生良性损失尖峰，尽管这些学习速率会加速动态并加速渐近收敛。在参数化不足的情况下，我们说明了交叉熵损失如何导致次优的记忆方案。最后，我们评估了小型 Transformer 模型研究结果的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.18724</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    </channel>
</rss>