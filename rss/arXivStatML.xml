<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 18 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>认知无知的双样本测试</title>
      <link>https://arxiv.org/abs/2410.12921</link>
      <description><![CDATA[arXiv:2410.12921v1 公告类型：新
摘要：我们引入了信条双样本测试，这是一种用于比较信条集（概率测度的凸集，其中每个元素都捕获了随机不确定性，而集合本身则代表了由于建模者的部分无知而产生的认知不确定性）的新假设检验框架。依赖于比较精确分布的经典双样本测试无法解决由于部分无知而导致的认知不确定性。为了弥补这一差距，我们将双样本测试推广到比较信条集，从而能够推理相等、包含、交集和互斥性，每种测试都为建模者的认知信念提供了独特的见解。我们将这些测试形式化为具有干扰参数的双样本测试，并引入了针对此类问题的第一个基于置换的解决方案，从而显着改进了现有方法。我们的方法将建模者的认知不确定性正确地纳入到假设检验中，从而得出更为稳健和可信的结论，并为实际应用提供基于内核的实现。]]></description>
      <guid>https://arxiv.org/abs/2410.12921</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有 Arm 请求成本和延迟的上下文老虎机</title>
      <link>https://arxiv.org/abs/2410.13109</link>
      <description><![CDATA[arXiv:2410.13109v1 公告类型：新
摘要：我们引入了上下文强盗问题的一个新扩展，其中可以请求具有随机时间延迟和相关成本的新武器集。在这种情况下，学习者可以从决策集中选择多个武器，每次选择需要一个时间单位。该问题被视为半马尔可夫决策过程 (SMDP) 的一个特例。假设武器上下文、请求时间和成本遵循未知分布。我们考虑在线学习算法对实现最大平均奖励的最优策略的遗憾。通过利用贝尔曼最优方程，我们设计了可以有效选择武器并确定请求新武器的适当时间的算法，从而最大限度地减少他们的遗憾。在可实现性假设下，我们分析了所提出的算法并证明它们的遗憾上限与上下文强盗文献中既定的结果一致。我们通过对模拟数据和电影推荐数据集的实验验证了算法，表明它们的性能与理论分析一致。]]></description>
      <guid>https://arxiv.org/abs/2410.13109</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 Wasserstein 空间中的最近邻实现分布矩阵补全</title>
      <link>https://arxiv.org/abs/2410.13112</link>
      <description><![CDATA[arXiv:2410.13112v1 公告类型：新
摘要：我们引入了分布矩阵补全问题：给定一个稀疏观测的经验分布矩阵，我们试图估算与观测和未观测矩阵条目相关的真实分布。这是传统矩阵补全的推广，其中每个矩阵条目的观测值都是标量值。为此，我们利用最优传输工具将最近邻方法推广到分布设置。在概率分布的合适潜在因子模型下，我们确定我们的方法恢复了 Wasserstein 范数中的分布。我们通过模拟证明，我们的方法能够 (i) 与仅使用观测样本相比，为条目提供更好的分布估计，(ii) 产生标准差和风险价值等分布量的准确估计，以及 (iii) 固有支持异方差噪声。我们还证明了一维分布上 Wasserstein 重心的新型渐近结果。]]></description>
      <guid>https://arxiv.org/abs/2410.13112</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>L1 正则化 ICA：一种分析任务相关 fMRI 数据的新方法</title>
      <link>https://arxiv.org/abs/2410.13171</link>
      <description><![CDATA[arXiv:2410.13171v1 公告类型：新
摘要：我们提出了一种新的独立成分分析 (ICA) 方法，以便从高维数据中提取适当的特征。一般来说，包括 ICA 在内的矩阵分解方法在提取特征的可解释性方面存在问题。为了提高可解释性，人们认为对分解矩阵进行稀疏约束是有帮助的。在此背景下，我们构建了一种具有稀疏性的新 ICA 方法。在我们的方法中，将 L1 正则化项添加到 ICA 的成本函数中，并通过凸函数差分算法来最小化成本函数。为了验证我们提出的方法的有效性，我们将其应用于合成数据和真实的功能磁共振成像数据。]]></description>
      <guid>https://arxiv.org/abs/2410.13171</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变分推理中模式崩溃的理论视角</title>
      <link>https://arxiv.org/abs/2410.13300</link>
      <description><![CDATA[arXiv:2410.13300v1 公告类型：新
摘要：虽然深度学习扩展了高度表达变分族的可能性，但这些工具对变分推理 (VI) 的实际好处通常受到传统 Kullback-Leibler 目标最小化的限制，这可能会产生次优解。在这种情况下，一个主要挑战是 \emph{模式崩溃}：一种现象，即模型在训练期间集中于目标分布的几个模式，尽管在统计上能够表达它们。在这项工作中，我们对高斯混合模型上梯度流的模式崩溃进行了理论研究。我们确定了表征流的关键低维统计数据，并推导出一组控制其演化的低维方程。利用这种紧凑的描述，我们表明即使在统计上有利的情况下也会存在模式崩溃，并确定了驱动它的两个关键机制：均值对齐和消失权重。我们的理论发现与使用规范化流（一类流行的生成模型）实现 VI 一致，从而提供了实用的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.13300</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过核最近邻学习反事实分布</title>
      <link>https://arxiv.org/abs/2410.13381</link>
      <description><![CDATA[arXiv:2410.13381v1 公告类型：新
摘要：考虑一个具有多个单位（例如，个人、群组、地理位置）和结果（例如，治疗、时间、项目）的设置，其中目标是学习每个单位结果条目的多元分布，例如特定移动应用程序版本下用户每周支出和参与度的分布。一个常见的挑战是缺失非随机数据的普遍性，其中仅对某些单位结果组合提供观察结果，并且观察结果的可用性可以与分布本身的属性相关联，即存在未观察到的混杂。另一个挑战是，对于任何观察到的单位结果条目，我们只有来自底层分布的有限数量的样本。我们通过将问题投入到新的分布矩阵完成框架中来解决这两个挑战，并引入基于核的最近邻分布泛化来估计底层分布。通过利用最大均值差异和底层分布的核均值嵌入上的合适因子模型，即使数据缺失不是随机的并且违反了正性约束，我们也能建立底层分布的一致恢复。此外，我们证明了我们的最近邻方法对异方差噪声具有鲁棒性，前提是我们可以访问观察到的单位结果条目的两个或更多个测量值，而这种鲁棒性在之前对单个测量值的最近邻的研究中所不具备。]]></description>
      <guid>https://arxiv.org/abs/2410.13381</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有大 $p$ 的可扩展符号回归的从头非参数变量选择</title>
      <link>https://arxiv.org/abs/2410.13681</link>
      <description><![CDATA[arXiv:2410.13681v1 公告类型：新
摘要：符号回归 (SR) 是一种强大的技术，用于发现表征数据中非线性关系的符号表达式，因其可解释性、紧凑性和鲁棒性而受到越来越多的关注。然而，现有的 SR 方法不能扩展到具有大量输入变量的数据集（称为极端规模 SR），这在现代科学应用中很常见。这种“大 $p$”设置通常伴随着测量误差，导致 SR 方法性能缓慢，表达式过于复杂，难以解释。为了解决这个可扩展性挑战，我们提出了一种称为 PAN+SR 的方法，它将从头算非参数变量选择的关键思想与 SR 相结合，以有效地预先筛选大输入空间并降低搜索复杂性，同时保持准确性。非参数方法的使用消除了模型错误指定，支持一种称为参数辅助非参数 (PAN) 的策略。我们还通过结合具有各种信噪比的高维回归问题来扩展开源基准测试平台 SRBench。我们的结果表明，PAN+SR 持续增强了 17 种当代 SR 方法的性能，使其中一些方法在这些具有挑战性的数据集上实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.13681</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提高扩散概率模型的收敛速度</title>
      <link>https://arxiv.org/abs/2410.13738</link>
      <description><![CDATA[arXiv:2410.13738v1 公告类型：新
摘要：基于分数的扩散模型因其能够从复杂分布中生成高质量的新数据实例而在机器学习和人工智能领域取得了显著的经验表现。提高我们对扩散模型的理解，包括主要对此类模型的收敛分析，引起了很多兴趣。尽管进行了大量理论尝试，但理论与实践之间仍然存在很大差距。为了缩小这一差距，我们建立了一个 $d^{1/3}\varepsilon^{-2/3}$ 级的迭代复杂度，这比我们工作之前实现的最佳复杂度 $d^{5/12}\varepsilon^{-1}$ 要好。该收敛分析基于随机中点方法，该方法首先提出用于对数凹采样（Shen and Lee，2019），然后由 Gupta 等人（2024）扩展到扩散模型。我们的理论适用于 $\varepsilon$ 精确的分数估计，并且不需要目标分布具有对数凹度。此外，该算法还可以并行化，仅以 $O(\log^2(d/\varepsilon))$ 并行轮次运行，与之前的工作类似。]]></description>
      <guid>https://arxiv.org/abs/2410.13738</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过扩散模型探索数据的潜在层次结构</title>
      <link>https://arxiv.org/abs/2410.13770</link>
      <description><![CDATA[arXiv:2410.13770v1 公告类型：新
摘要：高维数据必须高度结构化才能学习。尽管数据的组成和层次性通常被用来解释可学习性，但建立这些属性的定量测量却很少。同样，访问这种数据结构背后的潜在变量仍然是一个挑战。在这项工作中，我们表明，在基于扩散的模型中，前向后向实验（其中数据被噪声化然后去噪以生成新样本）是探测数据潜在结构的有前途的工具。我们在简单的分层模型中预测，在此过程中，数据的变化是由相关块发生的，其长度尺度在已知发生相变的噪声水平处发散。值得注意的是，我们使用最先进的扩散模型在文本和图像数据集中证实了这一预测。我们的结果显示了潜在变量变化如何在数据中体现，并确定了如何使用扩散模型在实际数据中测量这些影响。]]></description>
      <guid>https://arxiv.org/abs/2410.13770</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>离散分布可以从亚稳态样本中学习</title>
      <link>https://arxiv.org/abs/2410.13800</link>
      <description><![CDATA[arXiv:2410.13800v1 公告类型：新
摘要：设计用于从多变量分布中采样的马尔可夫链采样器通常会不合时宜地卡在其状态空间的特定区域。这导致此类采样器近似地从亚稳态分布中进行采样，而亚稳态分布通常与链的期望平稳分布大不相同。我们表明，满足强亚稳态条件的可逆马尔可夫链采样器的亚稳态分布的单变量条件平均非常接近真实分布的单变量条件。即使亚稳态分布在 Kullback-Leibler 散度或总变差距离等全局指标方面远离真实模型，这种情况仍然成立。此属性使我们能够使用基于条件似然的估计器来学习真实模型，即使样本来自集中在状态空间一小块区域的亚稳态分布。可以从有效阻碍概率流并导致马尔可夫链混合不良的区域构建此类亚稳态的明确示例。对于二元成对无向图模型的具体情况，我们扩展了结果，进一步严格地表明来自亚稳态的数据可用于学习能量函数的参数并恢复模型的结构。]]></description>
      <guid>https://arxiv.org/abs/2410.13800</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于情境学习的数据自适应差异隐私提示合成</title>
      <link>https://arxiv.org/abs/2410.12085</link>
      <description><![CDATA[arXiv:2410.12085v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 依赖于示例/演示中嵌入的上下文信息来执行上下文学习 (ICL)。为了降低 LLM 可能泄露提示中示例中包含的私人信息的风险，我们引入了一种名为 AdaDPSyn 的新型数据自适应差分隐私算法，从私有数据集生成合成示例，然后使用这些合成示例执行 ICL。AdaDPSyn 的目标是根据数据固有的统计特性自适应地调整数据合成机制中的噪声水平，从而在保持正式的差分隐私保证的同时保持较高的 ICL 精度。AdaDPSyn 的一项关键创新是精确聚焦迭代半径缩减技术，该技术根据数据聚类中观察到的模式动态细化聚合半径（用于添加噪声的数据分组范围），从而最大限度地减少加性噪声。我们在标准基准上进行了大量实验，并将 AdaDPSyn 与 DP 小样本生成算法 (Tang et al., 2023) 进行了比较。实验表明，AdaDPSyn 不仅优于 DP 小样本生成，而且还保持了接近非隐私基线的高精度水平，为具有隐私保护的 ICL 提供了有效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.12085</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过上下文注入消除文本嵌入的偏见</title>
      <link>https://arxiv.org/abs/2410.12874</link>
      <description><![CDATA[arXiv:2410.12874v1 公告类型：交叉 
摘要：NLP 的最新进展使得利用文本数据构建应用程序变得越来越可行。通常，这些应用程序的核心依赖于通过专门的嵌入模型将文本很好地表示为向量。然而，事实证明，这些嵌入会捕获并延续文本中已经存在的偏见。虽然已经提出了一些消除嵌入偏差的技术，但它们并没有利用现代嵌入模型在上下文理解方面的最新进展。在本文中，我们通过对 19 个嵌入模型进行审查来填补这一空白，量化它们的偏差以及它们对上下文注入作为消除偏差的手段的响应程度。我们表明，性能更高的嵌入模型更容易捕获常见偏差，但也能够更好地融入上下文。令人惊讶的是，我们发现虽然模型可以轻松嵌入肯定的上下文，但它们无法嵌入中性语义。最后，在检索任务中，我们表明嵌入中的偏差可能会导致不理想的结果。我们利用新发现的见解设计了一个简单的算法，用于前 $k$ 个检索，其中 $k$ 是动态选择的。]]></description>
      <guid>https://arxiv.org/abs/2410.12874</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高斯矩阵过程的线性成本和指数收敛近似</title>
      <link>https://arxiv.org/abs/2410.13000</link>
      <description><![CDATA[arXiv:2410.13000v1 公告类型：交叉 
摘要：基于具有 Mat\&#39;ern 协方差函数的高斯过程的统计模型的推断和预测的计算成本与观测值的数量成立方关系，限制了它们对大型数据集的适用性。在某些特殊情况下可以降低成本，但目前没有具有线性成本的普遍适用的精确方法。已经引入了几种近似方法来降低成本，但其中大多数缺乏对准确性的理论保证。我们考虑具有 Mat\&#39;ern 协方差函数的有界区间上的高斯过程，并首次开发了一种具有线性成本的普遍适用方法，其协方差误差在所提出的近似的 $m$ 阶中呈指数快速下降。该方法基于谱密度的最佳有理近似，其结果可以表示为 $m$ 个独立高斯马尔可夫过程的总和，这便于在通用统计推断软件中使用，从而能够在通用统计推断软件包中高效实现。除了理论依据外，我们还通过精心设计的模拟研究从经验上证明了该方法的准确性，结果表明，在高斯过程回归等统计任务中，该方法在固定计算成本的准确性方面优于所有最先进的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2410.13000</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>样本压缩方案减少</title>
      <link>https://arxiv.org/abs/2410.13012</link>
      <description><![CDATA[arXiv:2410.13012v1 公告类型：交叉 
摘要：我们提出了从多类分类、回归和对抗性鲁棒学习设置中的样本压缩方案到二进制样本压缩方案的新颖方法。假设我们有一个大小为 $f(d_\mathrm{VC})$ 的二进制类压缩方案，其中 $d_\mathrm{VC}$ 是 VC 维度，那么我们得到以下结果：（1）如果二进制压缩方案是多数投票或稳定压缩方案，则存在一个大小为 $O(f(d_\mathrm{G}))$ 的多类压缩方案，其中 $d_\mathrm{G}$ 是图维度。此外，对于一般的二进制压缩方案，我们获得大小为 $O(f(d_\mathrm{G})\log|Y|)$ 的压缩方案，其中 $Y$ 是标签空间。 (2) 如果二进制压缩方案是多数票或稳定压缩方案，则存在一个 $\epsilon$ 近似压缩方案，用于大小为 $O(f(d_\mathrm{P}))$ 的 $[0,1]$ 值函数的回归，其中 $d_\mathrm{P}$ 是伪维数。对于一般的二进制压缩方案，我们获得大小为 $O(f(d_\mathrm{P})\log(1/\epsilon))$ 的压缩方案。如果样本压缩猜想得到解决（Littlestone 和 Warmuth，1986 年；Floyd 和 Warmuth，1995 年；Warmuth，2003 年），这些结果将具有重要意义。我们的结果将立即将猜想的证明扩展到其他设置。我们为对抗性鲁棒学习建立了类似的结果，并且还提供了一个具有鲁棒性但没有有界大小压缩方案的概念类的示例，证明了可学习性并不等同于具有独立于样本大小的压缩方案，这与二元分类不同，其中可以实现大小为 $2^{O(d_\mathrm{VC})}$ 的压缩（Moran and Yehudayoff，2016）。]]></description>
      <guid>https://arxiv.org/abs/2410.13012</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士中的电路假设检验</title>
      <link>https://arxiv.org/abs/2410.13032</link>
      <description><![CDATA[arXiv:2410.13032v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 展示了令人惊讶的能力，但我们不了解它们是如何实现的。一种假设表明，这些能力主要由 LLM 内的小型子网络（称为电路）执行。但我们如何评估这个假设呢？在本文中，我们形式化了一组假设电路满足的标准，并开发了一套假设检验来评估电路满足这些标准的程度。这些标准侧重于 LLM 行为的保留程度、这种行为的局部化程度以及电路是否最小。我们将这些测试应用于研究文献中描述的六个电路。我们发现合成电路（模型中硬编码的电路）与理想化的属性一致。在 Transformer 模型中发现的电路在不同程度上满足标准。为了方便将来对电路进行实证研究，我们创建了 \textit{circuitry} 包，它是 \textit{TransformerLens} 库的包装器，它抽象了钩子和激活的低级操作。该软件可在 \url{https://github.com/blei-lab/circuitry} 上获取。]]></description>
      <guid>https://arxiv.org/abs/2410.13032</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>