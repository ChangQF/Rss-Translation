<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 03 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于种群的 SHM 的拓扑和几何学</title>
      <link>https://arxiv.org/abs/2410.00923</link>
      <description><![CDATA[arXiv:2410.00923v1 公告类型：新
摘要：基于种群的结构健康监测 (PBSHM) 旨在利用结构种群中的信息来增强对具有稀疏数据的结构的诊断。迁移学习学科提供了这种能力的机制。PBSHM 中的一篇最新论文提出了一种几何视图，其中结构被表示为度量“基空间”中的图形，其数据被捕获在图空间上方的向量束的“总空间”中。这种观点更具启发性，而不是数学上的严谨性，尽管它确实允许某些有用的论点。更严格分析的一个障碍是图空间上没有有意义的拓扑，因此没有有用的连续性概念。本文旨在通过转移到基空间中的参数结构族来解决这个问题，本质上将图空间中的点更改为开球。这允许在纤维空间中定义开集，从而允许纤维之间的连续变化。新的想法激发了一种新的几何机制，用于将数据从一条光纤传输到相邻的光纤；即从一个结构传输到另一个结构。]]></description>
      <guid>https://arxiv.org/abs/2410.00923</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>StreamEnsemble：时空流数据的预测查询</title>
      <link>https://arxiv.org/abs/2410.00933</link>
      <description><![CDATA[arXiv:2410.00933v1 公告类型：新
摘要：对时空 (ST) 流数据的预测查询带来了重大的数据处理和分析挑战。ST 数据流涉及一​​组时间序列，其数据分布可能在空间和时间上变化，表现出多种不同的模式。在这种情况下，假设单个机器学习模型能够充分处理这种变化可能会导致失败。为了应对这一挑战，我们提出了 StreamEnsemble，这是一种对 ST 数据进行预测查询的新方法，它根据底层时间序列分布和模型特征动态选择和分配机器学习模型。我们的实验评估表明，该方法在准确性和时间方面明显优于传统的集成方法和单一模型方法，与传统方法相比，预测误差显著降低了 10 倍以上。]]></description>
      <guid>https://arxiv.org/abs/2410.00933</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AR-Sieve Bootstrap 用于随机森林以及与 rangerts 时间序列预测的模拟比较</title>
      <link>https://arxiv.org/abs/2410.00942</link>
      <description><![CDATA[arXiv:2410.00942v1 公告类型：新
摘要：随机森林 (RF) 算法可应用于广泛的问题，包括时间序列预测。然而，无论是经典的 IID（独立且相同分布）引导还是块引导策略（如 rangerts 中实现的）都不能完全解释在重新采样观测值时数据生成过程 (DGP) 的性质。我们提出将 RF 与残差引导技术相结合，其中我们用 AR-Sieve Bootstrap (ARSB) 替换 IID 引导，后者假设 DGP 是一个自回归过程。为了评估新模型的预测性能，我们使用从不同类型的 DGP 生成的合成数据进行了模拟研究。事实证明，ARSB 在森林中的树木之间提供了更多的变化。此外，与使用其他引导策略的 RF 相比，使用 ARSB 的 RF 显示出更高的准确性。然而，这些改进是以一些效率为代价实现的。]]></description>
      <guid>https://arxiv.org/abs/2410.00942</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于预测事件发生时间结果的深度生存分析模型简介</title>
      <link>https://arxiv.org/abs/2410.01086</link>
      <description><![CDATA[arXiv:2410.01086v1 公告类型：新
摘要：许多应用涉及推理关键事件发生之前的时间长度——也称为事件发生时间结果。客户何时取消订阅、昏迷患者何时醒来或被定罪的罪犯何时再次犯罪？事件发生时间结果在生存分析领域得到了广泛研究，主要由统计、医学和可靠性工程界进行，教科书早在 20 世纪 70 年代和 80 年代就已经问世。本专著旨在为生存分析提供合理独立的现代介绍。我们专注于借助神经网络在单个数据点级别预测事件发生时间结果。我们的目标是让读者准确理解什么是基本事件发生时间预测问题，它与标准回归和分类有何不同，以及关键的“设计模式”如何一次又一次地被用来推导新的事件发生时间预测模型，从 Cox 比例风险模型等经典方法到深度核 Kaplan-Meier 估计量和神经常微分方程模型等现代深度学习方法。我们进一步深入研究了基本事件发生时间预测设置的两个扩展：预测几个关键事件中的哪一个将首先发生以及这个最早事件发生的时间（竞争风险设置），以及根据随时间增长的时间序列预测事件发生时间的结果（动态设置）。最后，我们讨论了公平性、因果推理、可解释性和统计保证等各种主题。我们的专著附带一个代码存储库，其中实现了我们详细介绍的每个模型和评估指标。]]></description>
      <guid>https://arxiv.org/abs/2410.01086</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于等变分数的生成模型可以有效地学习具有对称性的分布</title>
      <link>https://arxiv.org/abs/2410.01244</link>
      <description><![CDATA[arXiv:2410.01244v1 公告类型：新
摘要：对称性在许多现实世界的现象和任务中无处不在，例如物理、图像和分子模拟。实证研究表明，当底层数据分布具有群对称性时，将对称性纳入生成模型可以提供更好的泛化和采样效率。在这项工作中，我们首次对基于分数的生成模型 (SGM) 进行了理论分析和保证，用于学习相对于某些群对称性不变的分布，并首次对数据增强和添加等变归纳偏差进行了定量比较。首先，基于最近关于 SGM 的 Wasserstein-1 ($\mathbf{d}_1$) 保证和群对称下概率散度的经验估计的研究，我们提供了数据分布为群不变时改进的 $\mathbf{d}_1$ 泛化界限。其次，我们使用 Hamilton-Jacobi-Bellman 理论描述等变 SGM 的归纳偏差，并通过分析得分匹配目标的最优性和等价性，严格证明可以使用等变向量场学习对称分布的得分，而无需数据增强。这也提供了实用指导，即只要向量场或神经网络参数化是等变的，就不必增强数据集。此外，我们通过表明非等变向量场会产生更差的泛化界限，量化了不将等变结构纳入得分参数化的影响。这可以看作是一种模型形式错误，描述非等变向量场缺失的结构。数值模拟证实了我们的分析，并强调数据增强不能取代等变向量场的作用。]]></description>
      <guid>https://arxiv.org/abs/2410.01244</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在过度参数化的机器学习中重新审视乐观主义和模型复杂性</title>
      <link>https://arxiv.org/abs/2410.01259</link>
      <description><![CDATA[arXiv:2410.01259v1 公告类型：新
摘要：现代机器学习中的常见做法涉及根据观察次数拟合大量参数。这些过度参数化的模型可能会表现出令人惊讶的泛化行为，例如，在绘制与模型参数的原始数量或另一个简单的复杂性概念时，预测误差曲线中的“双下降”。在本文中，我们从第一原理重新审视模型复杂性，首先重新解释然后扩展经典的统计概念（有效）自由度。虽然经典定义与固定 X 预测误差有关（其中预测误差通过对与训练期间使用的相同的非随机协变量点进行平均来定义），但我们对自由度的扩展与随机 X 预测误差有关（其中预测误差对来自协变量分布的新随机样本进行平均）。随机 X 设置更自然地体现了现代机器学习问题，其中高度复杂的模型（甚至复杂到足以插入训练数据的模型）在适当条件下仍可产生理想的泛化性能。我们通过概念论证、理论和实验的结合展示了我们提出的复杂性度量的实用性，并说明了如何使用它们来解释和比较任意预测模型。]]></description>
      <guid>https://arxiv.org/abs/2410.01259</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Transformers 处理上下文线性回归中的内生性</title>
      <link>https://arxiv.org/abs/2410.01265</link>
      <description><![CDATA[arXiv:2410.01265v1 公告类型：新
摘要：我们探索了 Transformer 解决上下文线性回归中内生性的能力。我们的主要发现是，Transformer 本身具有一种使用工具变量 (IV) 有效处理内生性的机制。首先，我们证明 Transformer 架构可以模拟基于梯度的双层优化过程，该过程以指数速率收敛到广泛使用的两阶段最小二乘 $(\textsf{2SLS})$ 解。接下来，我们提出了一种上下文预训练方案，并提供理论保证，表明预训练损失的全局最小化器实现了较小的超额损失。我们进行了大量的实验，验证了这些理论发现，表明在存在内生性的情况下，经过训练的 Transformer 比 $\textsf{2SLS}$ 方法提供了更稳健、更可靠的上下文预测和系数估计。]]></description>
      <guid>https://arxiv.org/abs/2410.01265</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无限方差先验权重下的深度核后验学习</title>
      <link>https://arxiv.org/abs/2410.01284</link>
      <description><![CDATA[arXiv:2410.01284v1 公告类型：新
摘要：Neal (1996) 证明，当网络权重具有有界先验方差时，无限宽的浅贝叶斯神经网络 (BNN) 会收敛到高斯过程 (GP)。Cho &amp; Saul (2009) 为深度核过程提供了一个有用的递归公式，用于将每层的协方差核与紧接着的下一层联系起来。此外，他们以明确的方式为几种常见的激活函数计算出了逐层协方差核的形式。包括 Aitchison 等人 (2021) 在内的最新研究强调，以这种方式获得的协方差核是确定性的，因此排除了任何表示学习的可能性，这相当于在给定数据的情况下学习随机核的非退化后验。为了解决这个问题，他们建议在核中添加人工噪声以保持随机性，并开发深度核逆 Wishart 过程。尽管如此，这种人工噪声注入可能会受到批评，因为它不会在无限宽度限制下的经典 BNN 架构中自然出现。为了解决这个问题，我们展示了贝叶斯深度神经网络，其中每个层宽度接近无穷大，并且所有网络权重都呈椭圆分布且方差无限，收敛到一个具有条件高斯表示的每个层中具有 $\alpha$ 稳定边际的过程。这些条件随机协方差核可以以 Cho &amp; Saul (2009) 的方式递归链接，即使该过程在边际上表现出稳定的行为，因此协方差甚至不一定定义。我们还提供了 Lor\&#39;ia &amp; Bhadra (2024) 最近关于浅层网络到多层网络的结果的有用概括，并减轻了他们的方法的计算负担。与竞争方法相比，计算和统计优势在模拟和基准数据集上的演示中脱颖而出。]]></description>
      <guid>https://arxiv.org/abs/2410.01284</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>引入灵活的单调多项选择题反应理论模型和比特量表</title>
      <link>https://arxiv.org/abs/2410.01480</link>
      <description><![CDATA[arXiv:2410.01480v1 公告类型：新
摘要：项目反应理论 (IRT) 是一种强大的统计方法，用于通过反应分析评估测试项目并确定应试者的能力。更适合数据的 IRT 模型可以更准确地估计潜在特征。在本研究中，我们提出了一种用于多项选择数据的新模型，即单调多项选择 (MMC) 模型，我们使用自动编码器对其进行拟合。使用模拟场景和瑞典学术能力测试的真实数据，我们通过经验证明 MMC 模型在拟合度方面优于传统的名义反应 IRT 模型。此外，我们说明了如何将任何拟合的 IRT 模型中的潜在特征量表转换为比率量表，以帮助解释分数并使比较不同类型的 IRT 模型变得更加容易。我们将这些新量表称为位量表。位尺度对于对潜在特征尺度分布做出最少或没有假设的模型特别有用，例如本研究中的自动编码器拟合模型。]]></description>
      <guid>https://arxiv.org/abs/2410.01480</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一波浪潮解释一切：事后可解释性的统一视角</title>
      <link>https://arxiv.org/abs/2410.01482</link>
      <description><![CDATA[arXiv:2410.01482v1 公告类型：新
摘要：尽管深度神经网络在安全关键决策中的应用越来越广泛，但其固有的黑箱性质阻碍了透明度和可解释性。因此，可解释的人工智能 (XAI) 方法应运而生，用于理解模型的内部工作原理，尤其是归因方法，也称为显着图。传统的归因方法通常识别输入中重要区域的位置——哪里。然而，由于它们忽略了输入数据的固有结构，这些方法通常无法解释这些区域在结构成分方面所代表的内容（例如，图像中的纹理或声音中的瞬态）。此外，现有方法通常针对单一数据模态进行定制，限制了它们的通用性。在本文中，我们建议利用小波域作为归因的强大数学基础。我们的方法，小波归因方法 (WAM) 将现有的基于梯度的特征归因扩展到小波域，为解释图像、音频和 3D 形状中的分类器提供了一个统一的框架。实证评估表明，WAM 在图像、音频和 3D 可解释性方面，在忠实度指标和模型方面均与最先进的方法相媲美甚至超越了最先进的方法。最后，我们展示了我们的方法如何不仅解释输入的重要部分（位置），还解释结构组件方面的相关模式（内容）。]]></description>
      <guid>https://arxiv.org/abs/2410.01482</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注意力层可证明解决单位置回归问题</title>
      <link>https://arxiv.org/abs/2410.01537</link>
      <description><![CDATA[arXiv:2410.01537v1 公告类型：新
摘要：基于注意力的模型（例如 Transformer）在各种任务上都表现出色，但缺乏全面的理论理解，尤其是关于 token 稀疏性和内部线性表示。为了解决这一差距，我们引入了单位置回归任务，其中序列中只有一个 token 决定输出，并且其位置是一个潜在随机变量，可通过输入的线性投影检索。为了解决这个任务，我们提出了一个专用的预测器，它原来是一个非线性自注意力层的简化版本。我们通过展示其渐近贝叶斯最优性和分析其训练动态来研究其理论特性。特别是，尽管问题具有非凸性，但预测器可以有效地学习底层结构。这项工作强调了注意力机制处理稀疏 token 信息和内部线性结构的能力。]]></description>
      <guid>https://arxiv.org/abs/2410.01537</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>保险数据惩罚回归模型系数的区间估计</title>
      <link>https://arxiv.org/abs/2410.01008</link>
      <description><![CDATA[arXiv:2410.01008v1 公告类型：交叉 
摘要：Tweedie 指数散度系列是许多人对由零膨胀半连续数据组成的保险损失进行建模的流行选择。在这样的数据中，获得描述内生变量的最重要特征的可信度（推断）通常很重要。后选择推断是统计学中的标准程序，用于在执行特征提取程序后获得模型参数的置信区间。对于线性模型，套索估计对于对应于外生变量的大系数通常具有不可忽略的估计偏差。为了对这些系数进行有效的推断，有必要纠正套索估计的偏差。传统的统计方法，例如假设检验或标准置信区间构造，可能会在后选择期间导致错误的结论，因为它们通常过于乐观。在这里，我们讨论了一些在广义线性模型 (GLM) 系列中特征选择后构建系数置信区间的方法，并将其应用于保险数据。]]></description>
      <guid>https://arxiv.org/abs/2410.01008</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习非线性泛函的球面分析</title>
      <link>https://arxiv.org/abs/2410.01047</link>
      <description><![CDATA[arXiv:2410.01047v1 公告类型：交叉
摘要：近年来，人们对功能神经网络领域的兴趣日益浓厚。它们被提出并研究，目的是近似定义在欧几里得域上的函数集上的连续函数。在本文中，我们考虑在球面上的函数集上定义的函数。通过使用编码器-解码器框架的新型球面分析研究了深度 ReLU 神经网络的逼近能力。首先出现一个编码器来适应函数域的无限维性质。它利用球面谐波帮助我们提取函数的潜在有限维信息，这反过来又有助于下一步使用全连接神经网络进行近似分析。此外，现实世界中的物体经常被离散采样，并且经常被噪声破坏。因此，分别构造了具有离散输入的编码器和具有离散和随机噪声输入的编码器。其中提供了具有不同编码器结构的近似率。]]></description>
      <guid>https://arxiv.org/abs/2410.01047</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有缺失数据的高维逻辑回归：归因、正则化和普适性</title>
      <link>https://arxiv.org/abs/2410.01093</link>
      <description><![CDATA[arXiv:2410.01093v1 公告类型：交叉 
摘要：我们研究高维、岭正则化逻辑回归，其中协变量可能缺失或被附加噪声破坏。当协变量和附加损坏都是独立的且呈正态分布时，我们会提供预测误差和估计误差的精确特征。此外，我们表明这些特征是通用的：只要数据矩阵的条目满足一组独立性和矩条件，我们的保证就会继续成立。反过来，当协变量完全随机缺失时，通用性使得能够详细研究几种基于插补的策略。我们通过将这些策略的性能与贝叶斯最优程序的推测性能（源自统计物理学中的复制理论）进行比较来奠定我们的研究基础。我们的分析得出了几个见解，包括：(i) 单一插补和多重插补的简单变体之间的区别；(ii) 在单一插补逻辑回归中添加一个简单的岭正则化项可以产生一个估计量，其预测误差几乎与贝叶斯最优预测误差没有区别。我们通过大量的数值实验补充了我们的发现。]]></description>
      <guid>https://arxiv.org/abs/2410.01093</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于嵌入的生成模型统计推断</title>
      <link>https://arxiv.org/abs/2410.01106</link>
      <description><![CDATA[arXiv:2410.01106v1 公告类型：交叉 
摘要：最近一批公开的生成模型可以在各种主题和领域中生成人类专家级别的内容。给定该群体中的模型作为基础模型，诸如参数高效微调、上下文学习和约束解码之类的方法进一步提高了生成能力并提高了计算和数据效率。整个衍生模型集合作为这些方法的副产品而出现，并且这些模型中的每一个都有一组相关的协变量，例如基准上的分数、模型是否有权访问敏感信息的指标等，这些信息可能对用户可用或不可用。对于某些模型级协变量，可以使用“类似”模型来预测未知的协变量。在本文中，我们将与基于嵌入的生成模型表示（数据核透视空间）相关的最新结果扩展到经典的统计推断设置。我们证明，使用透视空间作为“相似”概念的基础对于多个模型级推理任务是有效的。]]></description>
      <guid>https://arxiv.org/abs/2410.01106</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>