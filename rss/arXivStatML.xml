<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 28 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>错误的准确性：噪声数据对分布外泛化的陷阱</title>
      <link>https://arxiv.org/abs/2406.19049</link>
      <description><![CDATA[arXiv:2406.19049v1 公告类型：交叉 
摘要：“准确率在线”是机器学习中广泛观察到的现象，其中模型在分布内 (ID) 和分布外 (OOD) 数据的准确率在不同的超参数和数据配置之间呈正相关。但是这种有用的关系何时会破裂？在这项工作中，我们探索了它的稳健性。关键的观察是，嘈杂的数据和干扰特征的存在足以破坏准确率在线现象。在这些情况下，ID 和 OOD 准确率可能会呈负相关，导致“准确率在线错误”。这种现象也可能发生在存在虚假（捷径）特征的情况下，这些特征往往会掩盖更复杂的信号（核心、非虚假）特征，从而导致较大的干扰特征空间。此外，扩展到更大的数据集并不能减轻这种不良行为，甚至可能加剧它。我们正式证明了线性分类模型中分布外 (OOD) 误差的下限，描述了噪声和干扰特征对较大 OOD 误差的影响。我们最终在具有噪声数据和干扰特征的合成数据集和真实数据集中证明了这种现象。]]></description>
      <guid>https://arxiv.org/abs/2406.19049</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:05 GMT</pubDate>
    </item>
    <item>
      <title>信用评分和承保中的强化学习</title>
      <link>https://arxiv.org/abs/2212.07632</link>
      <description><![CDATA[arXiv:2212.07632v2 公告类型：替换 
摘要：本文提出了一种用于信用承保的新型强化学习 (RL) 框架，以解决不可概括的上下文挑战。我们采用 RL 原则进行信用评分，结合行动空间更新和多选行动。我们的工作表明，传统的承保方法与 RL 贪婪策略一致。我们引入了两种新的基于 RL 的信用承保算法，以实现更明智的决策。模拟表明，在数据与模型一致的情况下，这些新方法优于传统方法。然而，复杂的情况凸显了模型的局限性，强调了强大的机器学习模型对最佳性能的重要性。未来的研究方向包括探索更复杂的模型以及有效的探索机制。]]></description>
      <guid>https://arxiv.org/abs/2212.07632</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:05 GMT</pubDate>
    </item>
    <item>
      <title>全信息链接 ICA：解决多模态融合中的缺失数据问题</title>
      <link>https://arxiv.org/abs/2406.18829</link>
      <description><![CDATA[arXiv:2406.18829v1 公告类型：交叉 
摘要：多模态成像采集技术的最新进展使我们能够测量大脑结构和功能的不同方面。多模态融合，例如链接独立成分分析 (LICA)，被广泛用于整合互补信息。然而，它受到缺失数据的困扰，这在神经影像数据中很常见。因此，在本文中，我们提出了一种全信息 LICA 算法 (FI-LICA) 来处理 LICA 框架下多模态融合过程中的缺失数据问题。我们的方法建立在完整案例的基础上，采用全信息原则，利用所有可用信息来恢复缺失的潜在信息。与当前实践相比，我们的模拟实验表明 FI-LICA 具有理想的性能。此外，我们将 FI-LICA 应用于阿尔茨海默病神经影像计划 (ADNI) 研究的多模态数据，在对当前诊断进行分类和预测轻度认知障碍 (MCI) 参与者的 AD 转变方面表现出更好的性能，从而突出了我们提出的方法的实用性。]]></description>
      <guid>https://arxiv.org/abs/2406.18829</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:04 GMT</pubDate>
    </item>
    <item>
      <title>从有偏见的选择性标签到伪标签：从有偏见的决策中学习的期望最大化框架</title>
      <link>https://arxiv.org/abs/2406.18865</link>
      <description><![CDATA[arXiv:2406.18865v1 公告类型：交叉 
摘要：当标签观察受到决策过程的影响时，就会出现选择性标签；例如，依赖于实验室测试管理的诊断。我们研究了一种受临床启发的选择性标签问题，称为差异审查，其中标签偏见在子组中有所不同，未标记的个体被归结为“阴性”（即，没有诊断测试 = 没有疾病）。在这种标签上进行简单训练的机器学习模型可能会放大标签偏见。受选择性标签因果模型的启发，我们提出了差异审查期望最大化 (DCEM)，这是一种在存在差异审查的情况下进行学习的算法。我们从理论上分析了 DCEM 如何减轻差异审查对模型性能的影响。我们在合成数据上验证了 DCEM，结果表明它改善了偏差缓解（ROC 曲线之间的面积），同时与基线相比没有牺牲判别性能 (AUC)。我们在使用临床数据的败血症分类任务中取得了类似的结果。]]></description>
      <guid>https://arxiv.org/abs/2406.18865</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:04 GMT</pubDate>
    </item>
    <item>
      <title>通过共形风险控制调整模型属性</title>
      <link>https://arxiv.org/abs/2406.18777</link>
      <description><![CDATA[arXiv:2406.18777v1 公告类型：交叉 
摘要：由于训练数据中的无意偏差和现代机器学习中未指定的管道，AI 模型对齐至关重要，其中可以生成具有出色测试集指标的大量模型，但它们可能无法满足最终用户的要求。最近的进展表明，通过人工反馈进行训练后模型对齐可以解决其中的一些挑战。然而，这些方法通常局限于人类可以解释模型输出并提供反馈的设置（例如生成 AI）。在传统的非生成设置中，模型输出是数值或类别，通过单样本输出检测错位非常具有挑战性。
在本文中，我们考虑了一种替代策略。我们建议通过属性测试来解释模型对齐，将对齐的模型 $f$ 定义为属于表现出特定期望行为的函数子集 $\mathcal{P}$ 的模型。我们专注于使用共形风险控制对预训练模型 $f$ 进行后处理，以更好地与 $\mathcal{P}$ 对齐。具体来说，我们开发了一种通用程序，用于将给定属性 $\mathcal{P}$ 的查询转换为适用于共形风险控制算法的损失函数集合。我们证明了一个概率保证，即围绕 $f$ 的共形区间包含一个近似满足 $\mathcal{P}$ 的函数。
鉴于具有大量参数和训练数据的现代 AI 模型的功能，人们可能会认为对齐问题会自然解决。然而，当预训练数据有偏差时，增加随机特征模型中的训练数据或参数并不能消除对齐技术的需求。我们在监督学习数据集上展示了我们的对齐方法，用于单调性和凹度等属性。我们的灵活程序可以应用于各种所需的属性。]]></description>
      <guid>https://arxiv.org/abs/2406.18777</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>统一不确定性：将输入、数据和模型不确定性结合成一个公式</title>
      <link>https://arxiv.org/abs/2406.18787</link>
      <description><![CDATA[arXiv:2406.18787v1 公告类型：交叉 
摘要：在机器学习模型中对不确定性进行建模对于实现安全可靠的预测至关重要。大多数关于不确定性的研究都集中在输出不确定性（预测）上，但对输入不确定性的关注却很少。我们提出了一种通过神经网络传播输入不确定性的方法，该方法能够同时估计输入、数据和模型不确定性。我们的结果表明，与相对简单的蒙特卡罗采样相比，这种输入不确定性的传播即使在大量输入噪声下也能产生更稳定的决策边界。此外，我们讨论并证明，当输入不确定性通过模型传播时，会导致输出的模型不确定性。在已知输入不确定性量的情况下，明确纳入输入不确定性可能会有所帮助，尽管仍然需要良好的数据集。]]></description>
      <guid>https://arxiv.org/abs/2406.18787</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>私有量子通道的收缩与私有量子假设检验</title>
      <link>https://arxiv.org/abs/2406.18651</link>
      <description><![CDATA[arXiv:2406.18651v1 公告类型：交叉 
摘要：量子广义散度根据定义满足数据处理不等式；因此，在量子信道的作用下，这种散度的相对减少最多为 1。这种相对减少正式称为信道和散度的收缩系数。有趣的是，存在信道和散度的组合，其收缩系数严格小于 1。此外，了解收缩系数对于隐私约束下的统计任务的研究至关重要。为此，我们在此建立了隐私约束下曲棍球棒散度的收缩系数上限，其中隐私是根据量子局部差分隐私 (QLDP) 框架量化的，并且我们完全描述了隐私约束下跟踪距离的收缩系数。随着机制的开发，我们还确定了在 QLDP 约束下 Bures 距离和量子相对熵相对于归一化迹距离的收缩的上限。接下来，我们应用我们的研究结果来建立隐私约束下量子假设检验的样本复杂度的界限。此外，我们研究了样本复杂度界限严格的各种场景，同时提供了实现这些界限的顺序最优量子通道。最后，我们展示了私有量子通道如何在量子学习环境中提供公平性和 Holevo 信息稳定性。]]></description>
      <guid>https://arxiv.org/abs/2406.18651</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>一种用于噪声、凸、零阶优化的简单改进算法</title>
      <link>https://arxiv.org/abs/2406.18672</link>
      <description><![CDATA[arXiv:2406.18672v1 公告类型：交叉 
摘要：本文研究了有界凸集 $\bar{\mathcal X}\subset \mathbb{R}^d$ 上函数 $f$ 的噪声、凸、零阶优化问题。给定对函数 $f$ 的噪声查询预算 $n$，这些查询可以按顺序和自适应地分配，我们的目标是构建一个算法，该算法返回一个点 $\h​​at x\in \bar{\mathcal X}$，使得 $f(\hat x)$ 尽可能小。我们提供了一种概念上简单的方法，该方法受到教科书重心法的启发，但适用于噪声和零阶设置。我们证明，这种方法使得 $f(\hat x) - \min_{x\in \bar{\mathcal X}} f(x)$ 的阶小于 $d^2/\sqrt{n}$ 的阶，直到多项对数项。我们对现有文献进行了轻微改进，据我们所知，[Lattimore, 2024] 中的最佳已知速率为 $d^{2.5}/\sqrt{n}$ 阶，尽管这是一个更具挑战性的问题。然而，我们的主要贡献是概念性的，因为我们相信我们的算法及其分析带来了新颖的想法，并且比现有方法简单得多。]]></description>
      <guid>https://arxiv.org/abs/2406.18672</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>随机梯度分段确定性蒙特卡罗采样器</title>
      <link>https://arxiv.org/abs/2406.19051</link>
      <description><![CDATA[arXiv:2406.19051v1 公告类型：新
摘要：最近的研究建议使用基于分段确定性马尔可夫过程 (PDMP) 的蒙特卡罗方法从感兴趣的目标分布中进行采样。PDMP 是具有动量的不可逆连续时间过程，因此可以比标准可逆 MCMC 采样器更好地混合。此外，它们可以结合精确的子采样方案，该方案只需要在每次迭代时访问单个（随机选择的）数据点，而不会给算法的平稳分布引入偏差。但是，可以使用 PDMP 的模型范围有限，尤其是子采样。我们提出了使用子采样对 PDMP 进行近似模拟，以便从后验分布中进行可扩展采样。近似采用欧拉近似的形式，近似真实 PDMP 动态，并涉及使用基于数据子样本的对数后验梯度的估计。因此，我们将这类算法称为随机梯度 PDMP。重要的是，随机梯度 PDMP 的轨迹是连续的，可以利用最近从具有连续和原子成分的测量中进行采样的想法。我们表明这些方法易于实现，展示了它们的近似误差结果，并通过数字证明这类算法具有与随机梯度朗之万动力学相似的效率，但比其更稳健。]]></description>
      <guid>https://arxiv.org/abs/2406.19051</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>使用检查点模型权重改进超参数优化</title>
      <link>https://arxiv.org/abs/2406.18630</link>
      <description><![CDATA[arXiv:2406.18630v1 公告类型：交叉 
摘要：在训练深度学习模型时，性能在很大程度上取决于所选的超参数。然而，超参数优化 (HPO) 通常是模型设计中最昂贵的部分之一。经典的 HPO 方法将其视为黑盒优化问题。然而，灰盒 HPO 方法包含了更多关于设置的信息，已成为更高效优化的一个有希望的方向。例如，使用中间损失评估来终止错误的选择。在这项工作中，我们提出了一种用于神经网络的 HPO 方法，使用训练权重的记录检查点来指导未来的超参数选择。我们的方法，预测模型搜索 (FMS)，将权重嵌入高斯过程深度核代理模型中，使用置换不变图元网络来实现记录网络权重的数据效率。为了促进可重复性和进一步研究，我们在 https://github.com/NVlabs/forecasting-model-search 开放源代码。]]></description>
      <guid>https://arxiv.org/abs/2406.18630</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>共形预测中的长度优化</title>
      <link>https://arxiv.org/abs/2406.18814</link>
      <description><![CDATA[arXiv:2406.18814v1 公告类型：新
摘要：条件有效性和长度效率是共形预测 (CP) 的两个关键方面。实现条件有效性可确保准确量化数据子群体的不确定性，而适当的长度效率可确保预测集保持信息丰富且非平凡。尽管为解决这些问题付出了巨大努力，但 CP 文献中一直缺少一个能协调这两个目标的原则框架。在本文中，我们开发了长度优化的共形预测 (CPL) - 一种新颖的框架，可构建具有 (接近) 最佳长度的预测集，同时确保在各种协变量偏移类别下的条件有效性，包括边际和组条件覆盖的关键情况。在无限样本制度下，我们提供了强大的对偶结果，表明 CPL 实现了条件有效性和长度最优性。在有限样本制度下，我们表明 CPL 构建了条件有效的预测集。我们广泛的实证评估表明，与分类、回归和文本相关设置中各种现实世界和合成数据集中的最先进方法相比，CPL 具有更优异的预测集大小性能。]]></description>
      <guid>https://arxiv.org/abs/2406.18814</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>通过选择性推理对数据分析流程进行统计测试</title>
      <link>https://arxiv.org/abs/2406.18902</link>
      <description><![CDATA[arXiv:2406.18902v1 公告类型：新
摘要：数据分析管道是一系列结构化的处理步骤，通过有效整合各种分析算法将原始数据转化为有意义的见解。在本文中，我们提出了一种新颖的统计测试，旨在评估数据分析管道的统计意义。我们的方法允许系统地开发适用于由一组数据分析组件组成的任何数据分析管道配置的有效统计测试。我们通过采用选择性推理开发了这个框架，选择性推理作为一种新的数据驱动假设统计推断技术最近引起了人们的关注。所提出的统计测试在理论上旨在将有限样本中的 I 类错误控制在所需的显着性水平。作为示例，我们考虑由三种缺失值插补算法、三种异常值检测算法和三种特征选择算法组成的管道类。我们通过对此类数据分析管道的合成数据和真实数据进行实验来确认我们的统计测试的有效性。此外，我们提出了一个实施框架，该框架有助于在无需额外实施成本的情况下跨此类数据分析管道的任何配置进行测试。]]></description>
      <guid>https://arxiv.org/abs/2406.18902</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>通过平均随机梯度下降实现无偏最小二乘回归</title>
      <link>https://arxiv.org/abs/2406.18623</link>
      <description><![CDATA[arXiv:2406.18623v1 公告类型：新
摘要：我们考虑一个具有最优解$\theta^*$和Hessian矩阵H的在线最小二乘回归问题，并研究$\theta^*$的时间平均随机梯度下降估计量。对于$k\ge2$，我们提供了一个无偏的$\theta^*$估计量，它是时间平均估计量的修改，以k阶的预期时间步长运行，具有O(1/k)的预期超额风险。O符号后面的常数取决于回归的参数，是H最小特征值的多对数函数。我们提供了时间平均估计量的预期超额风险的有偏和无偏估计量及其无偏对应物的有偏和无偏估计量，而无需了解H或$\theta^*$。我们描述了具有类似属性的估计器的“平均起始”版本。我们的方法基于随机多层蒙特卡罗。我们的数值实验证实了我们的理论发现。]]></description>
      <guid>https://arxiv.org/abs/2406.18623</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:59 GMT</pubDate>
    </item>
    <item>
      <title>通过沿统计流形上的广义测地线采样来估计密度比</title>
      <link>https://arxiv.org/abs/2406.18806</link>
      <description><![CDATA[arXiv:2406.18806v1 公告类型：新
摘要：两个概率分布的密度比是数学和计算统计学以及机器学习的基本工具之一，具有多种已知的应用。因此，从有限样本中估计密度比是一项非常重要的任务，但众所周知，当分布彼此相距甚远时，它是不稳定的。解决这个问题的一种方法是使用两个分布的增量混合来估计密度比。我们从几何上重新解释了现有的基于增量混合的密度比估计方法。我们表明，这些方法可以看作是沿着两个概率分布之间的特定曲线在黎曼流形上进行迭代。利用流形的几何形状，我们建议考虑沿该流形上的广义测地线进行增量密度比估计。要实现这种方法，需要通过两个分布的变换沿测地线进行蒙特卡洛采样。我们展示了如何实现迭代算法来沿这些测地线进行采样，并展示了沿测地线改变距离如何影响密度比估计的方差和准确性。我们的实验表明，所提出的方法优于使用不考虑几何形状的增量混合的现有方法]]></description>
      <guid>https://arxiv.org/abs/2406.18806</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:59 GMT</pubDate>
    </item>
    <item>
      <title>符号回归中的最佳生成树重建</title>
      <link>https://arxiv.org/abs/2406.18612</link>
      <description><![CDATA[arXiv:2406.18612v1 公告类型：新
摘要：本文研究了回归模型生成问题。模型是原始函数的叠加。模型结构由加权彩色图描述。每个图顶点对应一些原始函数。一条边分配两个函数的叠加。边的权重等于叠加的概率。要生成最佳模型，必须从其图邻接矩阵重建其结构。所提出的算法从加权彩色图中重建最小生成树。本文提出了一种基于奖品收集 Steiner 树算法的新解决方案。将该算法与其替代算法进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2406.18612</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:58 GMT</pubDate>
    </item>
    </channel>
</rss>