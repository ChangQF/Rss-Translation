<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Wed, 19 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>铰链功能的积极集</title>
      <link>https://arxiv.org/abs/2503.13512</link>
      <description><![CDATA[ARXIV：2503.13512V1公告类型：新 
摘要：在本文中，我们研究了实际平面的哪个子集可以实现，因为一层relu神经网络在其上具有正值的一组点。在锥体的情况下，我们给出了此类集合的完整表征。此外，我们为$ \ mathbb r^d $的任何子集提供必要的条件。我们给出了此类单层神经网络的各种例子。]]></description>
      <guid>https://arxiv.org/abs/2503.13512</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于平衡的积极标记学习的微观文本分类</title>
      <link>https://arxiv.org/abs/2503.13562</link>
      <description><![CDATA[ARXIV：2503.13562V1公告类型：新 
摘要：在现实世界的文本分类任务中，负面文本通常包含最小比例的负内容，这在文本质量控制，法律风险筛选和敏感信息拦截的领域尤为问题。这一挑战在两个层面上表现出来：在宏观层面上，由于粗粒正面和负样品之间的高相似性，很难区分负面文本。在微观层面，该问题源于极端的阶级失衡和缺乏细粒度的标签。为了应对这些挑战，我们提出将粗粒阳性（PN）分类任务转换为不平衡的细粒阳性（PU）分类问题，并由理论分析支持。我们介绍了一个新颖的框架，平衡的细粒阳性未标记（BFGPU）学习，该学习具有独特的PU学习损失函数，可在微观级别的严重失衡中优化宏观性能。重新平衡的伪标记和阈值调整，框架的性能进一步提高了。对公共和现实世界数据集进行的广泛实验证明了BFGPU的有效性，即使在宏观和微型级别都高度不平衡的极端情况下，它也超过了其他方法。]]></description>
      <guid>https://arxiv.org/abs/2503.13562</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>功能数据的贝叶斯内核回归</title>
      <link>https://arxiv.org/abs/2503.13676</link>
      <description><![CDATA[ARXIV：2503.13676V1公告类型：新 
摘要：在监督学习中，要预测的输出变量通常表示为函数，例如频谱或概率分布。尽管其重要性，功能输出回归仍然相对尚未探索。在这项研究中，我们提出了一个基于内核方法的新型功能输出回归模型。与传统的方法不同，对于输出功能的每个测量点，独立训练带标量输出的回归器，我们的方法利用功能值中的协方差结构，类似于多任务学习，从而提高了学习效率和提高的预测准确性。与统计功能数据分析中现有的非线性量函数模型相比，我们的模型有效地处理了高维非线性，同时保持简单的模型结构。此外，完全基于内核的公式允许在复制内核希尔伯特空间（RKHS）的框架内表达该模型，为参数估计提供了分析形式，并为进一步的理论分析提供了稳固的基础。所提出的模型从贝叶斯的角度传达了分析得出的功能输出预测分布，从而实现了预测函数中不确定性的量化。我们通过在材料科学中的人工数据集和状态预测任务的密度实验中展示了模型的增强预测性能。]]></description>
      <guid>https://arxiv.org/abs/2503.13676</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用元杂志下降优化ML培训</title>
      <link>https://arxiv.org/abs/2503.13751</link>
      <description><![CDATA[ARXIV：2503.13751V1公告类型：新 
摘要：培训大规模机器学习模型的一个主要挑战是配置培训过程，以最大程度地提高模型性能，即从庞大的设计空间找到最佳的训练设置。在这项工作中，我们将基于梯度的方法解锁了此问题。我们首先引入了一种算法，用于在大规模上有效地计算Metagradients（通过模型培训）。然后，我们引入了一个“平稳的模型训练”框架，该框架可以使用巨星进行有效的优化。随着Metagradient下降（MGD），我们在现有数据集选择方法上大大改进，超过准确性的数据中毒攻击的数量级，并自动找到竞争性的学习率时间表。]]></description>
      <guid>https://arxiv.org/abs/2503.13751</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>岩石：用于繁殖内核希尔伯特空间的职业内核方法的变异配方</title>
      <link>https://arxiv.org/abs/2503.13791</link>
      <description><![CDATA[ARXIV：2503.13791V1公告类型：新 
摘要：我们提出了大量弱制剂问题的代表定理结果。我们提供了在传统的机器学习和数值方法以及新的和新兴技术中的应用中应用的示例。最后，我们应用公式来概括多变量职业内核（模拟）方法，用于从数据中学习动态系统，提出了更通用的Riesz职业核（Rock）方法。我们的广义方法在我们测试的大多数基准上都具有更高的计算效率和性能。]]></description>
      <guid>https://arxiv.org/abs/2503.13791</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>S.D.E.多类分类的经验风险最小化算法路径</title>
      <link>https://arxiv.org/abs/2503.14045</link>
      <description><![CDATA[ARXIV：2503.14045V1公告类型：新 
摘要：我们解决了随机扩散路径的多类分类问题，假设这些类别以其漂移函数为特征，而扩散系数在所有类别中仍然很常见。在这种情况下，我们提出了一种依赖于L 2风险最小化的分类算法。我们为所得预测变量建立收敛速率。值得注意的是，我们引入了一个余量假设，根据该假设，我们表明我们的程序可以达到快速的收敛速率。最后，一项模拟研究突出了我们的分类算法的数值性能。]]></description>
      <guid>https://arxiv.org/abs/2503.14045</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>矩阵传感的基本限制：确切的渐近学，普遍性和应用</title>
      <link>https://arxiv.org/abs/2503.14121</link>
      <description><![CDATA[ARXIV：2503.14121V1公告类型：新 
摘要：在矩阵传感问题中，人们希望从（可能是嘈杂的）观察到其线性投影沿给定的方向重建一个矩阵。我们在高维限制中考虑了该模型：虽然以前的该模型的作品主要集中在低级矩阵的恢复上，但我们在这项工作中考虑了具有潜在级别的结构化信号矩阵的更一般类别，例如与尺寸成正比的两个尺寸矩阵的产物。我们提供了严格的渐近方程，这些方程表征了许多样本与矩阵中条目数量成正比的样本中最佳学习表现。 Our proof is composed of three key ingredients: $(i)$ we prove universality properties to handle structured sensing matrices, related to the &#39;&#39;Gaussian equivalence&#39;&#39; phenomenon in statistical learning, $(ii)$ we provide a sharp characterization of Bayes-optimal learning in generalized linear models with Gaussian data and structured matrix priors, generalizing previously studied settings, and $(iii)$ we leverage previous works on矩阵denoising的问题。我们的结果的一般性允许多种应用：值得注意的是，我们在数学上通过[ETB+24]中的统计物理学从[ETB+24]中的统计学方法获得了有关双线性序列回归的预测，这是一个从图表的序列中学习的基准测试模型，在bayes-optimal Learning in Neural网络中对使用Quadrats quadrats quadrrations quadrrations的基于[mtm+24]中的基准模型，并且]]></description>
      <guid>https://arxiv.org/abs/2503.14121</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化高维倾斜分裂</title>
      <link>https://arxiv.org/abs/2503.14381</link>
      <description><![CDATA[ARXIV：2503.14381V1公告类型：新 
摘要：正交树的表现良好，但有证据表明倾斜裂片可以增强其性能。本文探讨了优化高维$ s $ -s-sparse倾斜的斜率从$ \ {（\ vec {w}，\ vec {w}^{\ top} \ boldsymbol {x} _ {i} _ {i}） \ mathbb {r}^p，\ | \ vec {w} \ | _ {2} = 1，\ | \ vec {w} \ | _ {0} \ leq s \} $用于种植斜树，其中$ s $是用户定义的稀疏参数。我们建立了SID收敛与$ S_0 $ -SPARSE斜体之间的连接，并用$ S_0 \ ge 1 $划分，表明SID函数类随着$ S_0 $的增加而扩展，从而捕获了更复杂的数据生成功能，例如$ S_0 $ s_0 $ dimensional-dimensional xor xor Xor函数。因此，$ s_0 $表示基础数据生成功能的未知潜在复杂性。学习这些复杂的功能需要$ s -sparse斜树，具有$ s \ geq s_0 $和更大的计算资源。这突出了统计准确性之间的权衡，该统计准确性受SID功能类规模约束，具体取决于$ S_0 $和计算成本。相比之下，以前的研究使用$ s_0 = s = 1 $的正交拆分探索了SID收敛的问题，其中运行时不太关键。此外，我们为倾斜树引入了一个实用框架，该框架将优化的倾斜裂片与正交分裂的随机森林集成在一起。通过模拟和真实数据实验评估了所提出的方法，将其性能与各种倾斜树模型进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2503.14381</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过自适应边缘云卸载在线共形概率数字</title>
      <link>https://arxiv.org/abs/2503.14453</link>
      <description><![CDATA[ARXIV：2503.14453V1公告类型：新 
摘要：考虑一个边缘计算设置，其中用户向边缘处理器提交了线性系统解决方案的查询，该问题受时变计算的可用性。边缘处理器应用概率线性求解器（PLS），以便能够在分配的时间和计算预算中响应用户的查询。向用户的反馈是不确定性集的形式。由于模型错误指定，通过直接应用PLS获得的不确定性集与线性系统的真实解决方案相对于覆盖范围保证。这项工作引入了一种新方法来校准PLS产生的不确定性集，以保证长期覆盖要求。所提出的方法，称为在线保形预测-PLS（OCP-PLS），假设从云到边缘的零星反馈。这可以通过在线保形预测（OCP）对不确定性阈值进行在线校准，这是一种以前在预测模型背景下研究的在线优化方法。 OCP-PLS的有效性通过实验进行了验证，这些实验可以在覆盖范围，预测设置大小和云使用之间进行洞察力。]]></description>
      <guid>https://arxiv.org/abs/2503.14453</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多种环境中对治疗效果的双重稳健鉴定</title>
      <link>https://arxiv.org/abs/2503.14459</link>
      <description><![CDATA[ARXIV：2503.14459V1公告类型：新 
摘要：实用和道德约束通常需要使用观察数据来进行因果推断，尤其是在医学和社会科学领域。然而，观察数据集容易混淆，可能损害因果结论的有效性。虽然可以纠正偏见，如果已知基本因果图，但这在实际情况下很少是可行的。一个常见的策略是调整所有可用的协变量，但是这种方法可以产生偏见的治疗效果估计，尤其是在存在后处理或未观察到的变量时。我们提出了拉面，这是一种算法，通过利用多个数据源的异质性而无需了解或学习基本因果图，从而产生无偏的治疗效果估计。值得注意的是，拉面实现了双重稳健的识别：每当观察到治疗的因果父母或结果的因果父母时，它都可以识别治疗效果，并且观察到父母的节点可以满足不公平的假设。对合成和现实世界数据集的经验评估表明，我们的方法表现优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2503.14459</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有图形结构的可变选择先验的贝叶斯考克斯模型用于多摩尼斯生物标志物</title>
      <link>https://arxiv.org/abs/2503.13078</link>
      <description><![CDATA[ARXIV：2503.13078V1公告类型：交叉 
摘要：癌症研究的一个重要目标是基于最小的基因组和分子标记（例如基因或蛋白质）的患者的存活预后。纯粹的数据驱动模型没有任何生物知识可以产生不可解剖的结果。我们提出了一个受惩罚的半参数贝叶斯Cox模型，该模型具有图形结构的选择先验，以通过Markov Random Field（MRF）利用生物学上有意义的图形来稀疏地识别多摩斯特征，然后才能捕获多媒体特征之间的已知关系。由于MRF先验中的固定图是针对先前的概率分布，因此确定可变选择并不是一个困难的约束，因此所提出的模型可以验证已知信息，并有可能识别新的和新颖的生物标志物来绘制新的生物学知识。我们的仿真结果表明，与在没有任何先验知识的情况下独立建模协变量的方法相比，提出的具有基于图的先验知识的拟议的贝叶斯Cox模型会导致更具可信赖和稳定的变量选择和非内部生存预测预测。结果还表明，所提出的模型的性能对于MRF先验中的部分正确图是可靠的，这意味着在不知道协变量之间所有真实网络信息的真实环境中，该图仍然可以很有用。提出的模型应用于癌症基因组图集项目中的主要侵入性乳腺癌患者数据。]]></description>
      <guid>https://arxiv.org/abs/2503.13078</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超参数在预测多重性中的作用</title>
      <link>https://arxiv.org/abs/2503.13506</link>
      <description><![CDATA[ARXIV：2503.13506V1公告类型：交叉 
摘要：本文研究了超参数在预测多样性中的关键作用，其中在同一数据集上训练的不同机器学习模型对相同的输入产生了不同的预测。这些不一致会严重影响高风险决策，例如信用评估，招聘和医学诊断。专注于六个广泛使用的表格数据模型 - 弹性网，决策树，k -nearest邻居，支持向量机，随机森林和极端梯度的增强 - 我们探索了超参数调整如何影响预测性多样性，这是通过基准标准跨基准数据集的预测差异表达的。关键的超参数，例如弹性网中的lambda，支持向量机中的伽玛和极端梯度增强中的alpha在塑造预测多样性方面起着至关重要的作用，通常会损害特定算法中预测的稳定性。我们在21个基准数据集上进行的实验表明，调整这些超参数会导致显着改善，但也会增加预测差异，极端的梯度增强表现出最高的差异和实质性的预测不稳定。这突出了性能优化和预测一致性之间的权衡，从而引起了人们对任意预测风险的担忧。这些发现提供了有关超参数优化如何导致预测多重性的见解。尽管预测性多重性允许优先考虑特定于域的目标，例如公平性并降低对单个模型的依赖，但它也使决策复杂化，可能导致任意或不合理的结果。]]></description>
      <guid>https://arxiv.org/abs/2503.13506</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们需要多少个基于模拟的宇宙学推断？</title>
      <link>https://arxiv.org/abs/2503.13755</link>
      <description><![CDATA[ARXIV：2503.13755V1公告类型：交叉 
摘要：我们需要进行多少个模拟来训练机器学习方法，以从宇宙密度字段的摘要统计数据中提取可用的信息？神经方法表明有可能从宇宙数据中提取非线性信息。成功取决于拥有足够的模拟来培训网络和适当的网络体系结构。在对宇宙学推断的神经网络培训进行的首次详细融合研究中，我们表明，目前可用的模拟套件，例如具有2000个模拟的Quijote Latin HyperCube（LH），也没有为通用神经网络提供足够的培训数据，即使是为了达到最佳状态，即使是针对Dark Matter Powersmime的最佳策略，也没有提供理想的情况。我们发现了一种经验神经缩放定律，该定律可以预测神经网络可以从高度信息丰富的汇总统计量（暗物质功率谱）中提取多少信息，这是用于训练网络的模拟数量的函数，以供广泛的体系结构和超参数进行培训。我们将此结果与CRAMER-RAO信息结合在一起，以预测近距离信息提取所需的训练模拟数量。为了验证我们的方法，我们创建了宇宙学中最大的公开释放的模拟数据集，即大型SOBOL序列（BSQ），由32,768 $ \ lambda $ cdm n-n-body模拟均匀覆盖$ \ lambda $ cdm参数空间组成。我们的方法可以有效地计划宇宙学中机器学习应用程序的模拟活动，而BSQ数据集则提供了一种前所未有的资源，用于研究神经网络在宇宙学参数推断中的收敛行为。我们的结果表明，新的大型模拟套件或新的培训方法将是从非线性模拟中获得最佳参数推断的必要条件。]]></description>
      <guid>https://arxiv.org/abs/2503.13755</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>反事实经验增强了非政策的强化学习</title>
      <link>https://arxiv.org/abs/2503.13842</link>
      <description><![CDATA[ARXIV：2503.13842V1公告类型：交叉 
摘要：强化学习控制算法由于分布和效率低下的勘探问题而面临重大挑战。虽然基于模型的强化学习通过构建虚拟环境增强了代理商的推理和计划功能，但培训这种虚拟环境可能非常复杂。为了建立有效的推理模型并增强学习数据的代表性，我们提出了反事实体验增强（CEA）算法。 CEA利用变异自动编码器来建模状态过渡的动态模式，并将随机性引入模型非平稳性。这种方法着重于通过反事实推断扩展体验池中的学习数据，并在遵循双仿真假设的环境中表现出色。具有三拟合特性的环境通常由离散观察和动作空间表示，我们提出了一种基于最大核密度估计熵的采样方法，以将CEA扩展到各种环境。通过基于真实信息的反事实状态过渡提供奖励信号，CEA构建了完全反事实的经验，以减轻学习数据的分布外问题，并在具有差异属性的环境中优于SOTA算法。最后，我们讨论产生的反事实经验和真实经验的相似性，差异和特性。该代码可从https://github.com/aegis1863/cea获得。]]></description>
      <guid>https://arxiv.org/abs/2503.13842</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>径向轮廓分布的混合物的松弛瓦斯汀距离公式</title>
      <link>https://arxiv.org/abs/2503.13893</link>
      <description><![CDATA[ARXIV：2503.13893V1公告类型：交叉 
摘要：最近，已经提出了高斯混合模型的Wasserstein型距离。但是，该框架只能推广到可识别的椭圆形分布的可识别混合物，其组成部分来自同一家族并满足边缘一致性。在本文中，我们提出了一个简单的放松瓦斯汀距离，用于径向轮廓分布的可识别混合物，其组件可能来自不同的家庭。我们显示了此距离的某些属性，其定义不需要边缘一致性。我们在色彩传递任务中应用了此距离，并将其性能与实验中的高斯混合模型的Wasserstein型距离进行了比较。我们方法的错误更加稳定，并且我们的输出图像的颜色分布更加可取。]]></description>
      <guid>https://arxiv.org/abs/2503.13893</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>