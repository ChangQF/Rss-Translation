<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Fri, 15 Dec 2023 03:14:17 GMT</lastBuildDate>
    <item>
      <title>对称破缺和等变神经网络。 （arXiv：2312.09016v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09016</link>
      <description><![CDATA[在深度学习中使用对称性作为归纳偏差已被证明是一种
样本有效模型设计的原则方法。但是，那
对称性与神经网络中等方差的必要性之间的关系
网络并不总是显而易见的。在这里，我们分析出现的一个关键限制
在等变函数中：它们无法在以下水平上打破对称性
个人数据样本。作为回应，我们引入了“放松”的新颖概念
等方差”规避了这一限制。我们进一步演示如何
将这种松弛融入等变多层感知器（E-MLP）中，
提供噪声注入方法的替代方法。的相关性
然后在各个应用领域讨论对称破缺：物理学，
图表示学习、组合优化和等变
解码。
]]></description>
      <guid>http://arxiv.org/abs/2312.09016</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>使用惊喜指数进行自主决策能力评估。 （arXiv：2312.09033v1 [cs.RO]）</title>
      <link>http://arxiv.org/abs/2312.09033</link>
      <description><![CDATA[本文考虑了评估自治系统的问题
执行任务的能力，特别是在动态和动态环境中工作时
不确定的环境。机器学习模型固有的不透明性，来自
用户的视角，通常被描述为“黑匣子”，构成了
挑战。为了克服这个问题，我们建议使用一种称为惊喜的措施
指数，它利用可用的测量数据来量化是否
动态系统按预期运行。我们证明惊喜指数可以是
当观察到证据时，以封闭形式计算动态系统
概率模型，如果该证据的联合分布遵循
多元高斯边缘分布。然后我们将其应用到非线性
航天器机动问题，其中行动由强化选择
学习代理并表明它可以指示轨迹遵循的程度
所需轨道。
]]></description>
      <guid>http://arxiv.org/abs/2312.09033</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>具有注意力机制的神经网络的知识驱动调制，用于预测下一步活动。 （arXiv：2312.08847v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.08847</link>
      <description><![CDATA[预测流程监控 (PPM) 旨在利用历史流程
执行数据来预测正在进行的执行将如何继续到其
完成。近年来，PPM技术用于预测未来
活动已经显着成熟，主要归功于神经网络的使用
网络（NN）作为预测器。虽然他们的表现很难被击败
一般情况，也有特殊情况需要后台进程
知识会有帮助。这些知识可以用来改善
对异常流程执行或流程执行时的预测质量
由于概念漂移而发生变化。在本文中，我们提出了一个符号[神经]
利用以程序形式表达的背景知识的系统
处理模型以抵消训练数据中的欠采样。更多的
具体来说，我们使用具有注意机制的神经网络进行预测，
NN领域的新兴技术。该系统已经在多个平台上进行了测试
现实生活日志显示预测性能有所改善
任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.08847</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>具有统计质量保证的保形数据合成。 （arXiv：2312.08999v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.08999</link>
      <description><![CDATA[随着越来越复杂的深度学习架构的激增，
数据合成是一种非常有前途的技术，可以满足以下需求：
需要大量数据的模型。然而，可靠地评估“合成器”的质量
模型的输出是一个开放的研究问题，具有重大的相关风险
对于高风险领域。为了应对这一挑战，我们设计了一种独特的
引入统计置信度的置信数据合成算法
通过保形预测框架的新颖扩展来保证。我们
通过理论证明和广泛的支持我们提出的算法
五个基准数据集的实证评估。展示我们的方法
为了应对现实世界中普遍存在的挑战，数据集经过仔细处理
因其各种困难特征而被选中：样本数少，
类别不平衡和不可分离性以及隐私敏感数据。在所有
试验，训练集扩展了我们自信的合成数据，在
至少不如原始版本，并且经常显着改进 Deep
学习成绩 F1 分数提高高达 +65%。
]]></description>
      <guid>http://arxiv.org/abs/2312.08999</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>fMRI 数据矩阵分解的性能评估。 （arXiv：2312.08809v1 [q-bio.NC]）</title>
      <link>http://arxiv.org/abs/2312.08809</link>
      <description><![CDATA[在大脑的研究中，有一个假设：稀疏编码是
通过外部刺激的信息表示来实现，即
最近通过实验证实了视觉刺激。然而，与
大脑的特定功能区域，信息的稀疏编码
整个大脑的处理过程尚未得到充分阐明。在这个
研究中，我们通过以下方法研究了稀疏编码在整个人脑中的有效性
将各种矩阵分解方法应用于功能磁共振
整个人脑神经活动的成像数据。结果表明
整个人类信息表示中的稀疏编码假设
大脑，因为从稀疏MF方法、SparsePCA或MOD下提取特征
高稀疏度设置，或者近似稀疏MF方法，FastICA，可以分类
外部视觉刺激比非稀疏 MF 方法或稀疏 MF 更准确
低稀疏度设置下的方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.08809</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>使用 Metropolis 调整的镜像朗之万算法从受限空间快速采样。 （arXiv：2312.08823v1 [stat.CO]）</title>
      <link>http://arxiv.org/abs/2312.08823</link>
      <description><![CDATA[我们提出了一种新方法，称为 Metropolis-adjusted Mirror Langevin
从支持度为 a 的分布中进行近似采样的算法
紧凑凸集。该算法添加了一个接受-拒绝过滤器
镜像Langevin算法的单步诱导马尔可夫链（张
et al., 2020），这是镜像 Langevin 动力学的基本离散化。
由于包含此过滤器，我们的方法相对于
目标，而已知的镜像朗之万动力学的离散化包括
镜像朗之万算法具有渐进偏差。我们给出上限
当势相对较大时，所提出算法的混合时间
相对于自和谐镜子而言，光滑、凸面和 Lipschitz
功能。由于马尔可夫链的可逆性
通过该算法，我们获得了对误差的指数级更好的依赖性
近似采样的公差。我们还提出了数值实验
证实了我们的理论发现。
]]></description>
      <guid>http://arxiv.org/abs/2312.08823</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>ZeroQuant(4+2)：通过针对多样化生成任务的新的以 FP6 为中心的策略重新定义法学硕士量化。 （arXiv：2312.08583v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.08583</link>
      <description><![CDATA[这项研究探讨了大型语言中的 4 位量化方法，例如 GPTQ
模型（法学硕士），强调了 GPTQ 的过度拟合和有限的增强
零射击任务。虽然之前的工作仅仅关注零样本测量，但我们
将任务范围扩展到更具生成性的类别，例如代码生成和
抽象总结，其中我们发现INT4量化可以
表现明显不佳。然而，只需转向更高精度
像 FP6 这样的格式特别具有挑战性，因此被忽视，因为
由于缺乏复杂的集成和系统而导致性能不佳
当前人工智能硬件上的加速策略。我们的结果表明 FP6，甚至
采用粗粒度量化方案，在各种
算法和任务，展示了其在准确性和准确性方面的优越性
多功能性。值得注意的是，通过 FP6 量化，\codestar-15B 模型执行
与代码生成方面的 FP16 版本相当，并且适用于较小的模型
与 406M 一样，它在总结方面与他们的基线非常匹配。也不可以
通过INT4来实现。为了更好的适配各种AI硬件，实现
最佳系统性能，我们为 FP6 提出了一种新颖的 4+2 设计来实现
与最先进的 INT4 细粒度量化类似的延迟。跟我们
设计上，FP6可以成为当前4位量化的一个有前途的解决方案
法学硕士中使用的方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.08583</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>估计没有标签的标签偏移下的校准误差。 （arXiv：2312.08586v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.08586</link>
      <description><![CDATA[面对数据集变化，模型校准发挥着关键作用
确保机器学习系统的可靠性。校准误差 (CE) 为
预测概率与预测概率之间的一致性指标
分类器的准确率。虽然之前的作品已经深入研究了
数据集在校准时发生变化，现有的 CE 估计器假设可以访问标签
来自目标域，这在实践中通常是不可用的，即当
模型已部署并使用。这项工作解决了这种具有挑战性的场景，并且
提出了一种新的标签移位下的CE估计器，其特点是
边际标签分布 $p(Y)$ 的变化，同时保持
源分布和目标分布之间的条件 $p(X|Y)$ 常数。我们的
贡献是一种方法，通过利用重要性重新加权
标记源分布，提供一致且渐近的
关于移动目标分布的无偏 CE 估计。
在各种条件下跨不同现实世界数据集的实证结果
和标签转移强度，证明了有效性和可靠性
建议的估计器。
]]></description>
      <guid>http://arxiv.org/abs/2312.08586</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>正确校准误差的一致且渐近无偏估计。 （arXiv：2312.08589v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.08589</link>
      <description><![CDATA[正确的评分规则可以评估概率预测的质量，
在追求准确和校准良好的过程中发挥着至关重要的作用
楷模。每个真分数都分解为两个基本组成部分——真分数
校准误差和细化——利用布雷格曼散度。尽管
不确定性校准已引起广泛关注，当前文献
缺乏对这些具有已知统计量的通用估计器
特性。为了解决这个差距，我们提出了一种方法，允许一致的、
以及所有正确校准误差的渐近无偏估计和
细化条款。特别介绍Kullback--Leibler校准
由常用的交叉熵损失引起的误差。作为我们结果的一部分，
我们证明了精化和 f 散度之间的关系，这意味着
神经网络中的信息单调性，无论哪种正确评分
规则已优化。我们的实验根据经验验证了所声称的特性
的建议估计者，并建议选择一个事后估计者
校准方法应根据具体的校准误差来确定
兴趣。
]]></description>
      <guid>http://arxiv.org/abs/2312.08589</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>重新审视随机梯度方法的最后迭代收敛。 （arXiv：2312.08531v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.08531</link>
      <description><![CDATA[在过去的几年里，最后一次迭代的收敛
随机梯度下降（SGD）算法引发了人们的兴趣
其在实践中表现良好，但缺乏理论理解。为了
Lipschitz 和凸函数，不同的工作都建立了最优
$O(\log(1/\delta)\log T/\sqrt{T})$ 或 $O(\sqrt{\log(1/\delta)/T})$
最终迭代的高概率收敛率，其中 $T$ 是时间
Horizo​​n 和 $\delta$ 是失败概率。然而，为了证明这些
界限，所有现有的工作都仅限于紧凑的领域或几乎需要
肯定是有限的噪音。人们很自然地会问 SGD 的最后一次迭代是否可以
仍然保证最优收敛速度但没有这两个限制
假设。除了这个重要问题之外，还有很多问题
缺乏答案的理论问题。例如，与上次相比
对于非光滑问题，SGD 迭代收敛，对于光滑问题只有很少的结果
优化尚未开发。另外，现有的结果是
所有这些都仅限于非复合目标和标准欧几里得范数。它
仍不清楚最后迭代收敛是否可以被证明
扩展到更广泛的复合优化和非欧几里得规范。在这项工作中，
为了解决上述问题，我们重新审视最后迭代收敛
随机梯度方法，并提供第一个统一的方法来证明
预期收敛率和高概率收敛率都可以适应
一般领域、复合目标、非欧几里得规范、Lipschitz
同时满足条件、平滑度和（强）凸度。此外，我们
扩展我们的分析以获得重尾下​​的最后迭代收敛
噪音。
]]></description>
      <guid>http://arxiv.org/abs/2312.08531</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:13 GMT</pubDate>
    </item>
    <item>
      <title>低数据制度下的公平主动学习。 （arXiv：2312.08559v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.08559</link>
      <description><![CDATA[在关键的机器学习应用中，确保公平性至关重要
避免社会不平等长期存在。在这项工作中，我们应对挑战
减少数据稀缺环境中的偏差并提高准确性，其中
收集标记数据的成本禁止使用大型标记数据集。
在这种情况下，主动学习有望最大限度地提高边际准确率
少量标记数据。然而，现有的主动应用
公平学习无法实现这一点，通常需要大量的
标记的数据集，或未能确保满足所需的公平性容忍度
人口分布。

为了解决这些限制，我们引入了创新的主动学习
结合受后验采样启发的探索过程的框架
具有公平分类子程序。我们证明这个框架
在数据非常稀缺的情况下有效执行，最大限度地提高准确性
以高概率满足公平约束。我们评估我们的建议
使用完善的现实世界基准数据集的方法并进行比较
与最先进的方法相比，证明了其在生产方面的有效性
公平模型，以及对现有方法的改进。
]]></description>
      <guid>http://arxiv.org/abs/2312.08559</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:13 GMT</pubDate>
    </item>
    <item>
      <title>基于深度学习的马尔可夫模型中时间相关参数的估计，并应用于非线性回归和 SDE。 （arXiv：2312.08493v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.08493</link>
      <description><![CDATA[我们提出了一种新颖的深度学习方法来估计时间依赖性
通过离散采样马尔可夫过程中的参数。出发地
传统的机器学习，我们的方法将参数近似重新定义为
使用最大似然法的优化问题。实验性的
验证侧重于多元回归中的参数估计和
随机微分方程（SDE）。理论结果表明
真实解接近 SDE，其参数使用我们的神经网络近似
特定条件下的网络衍生。我们的工作有助于基于 SDE
模型参数估计，为不同领域提供通用工具。
]]></description>
      <guid>http://arxiv.org/abs/2312.08493</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:12 GMT</pubDate>
    </item>
    <item>
      <title>预测在算法决策中的相对价值。 （arXiv：2312.08511v1 [cs.CY]）</title>
      <link>http://arxiv.org/abs/2312.08511</link>
      <description><![CDATA[算法预测越来越多地用于通知分配
公共领域的商品和干预措施。在这些领域中，预测
作为达到目的的手段。他们为利益相关者提供了以下见解：
未来事件的可能性作为提高决策质量的一种手段，以及
增进社会福利。然而，如果福利最大化是最终目标，
预测只是这个难题的一小部分。还有其他各种政策
社会规划者可能为了改善底线结果而追求的杠杆，
例如扩大现有商品的获取范围，或增加商品的效应规模
干预措施。

考虑到如此广泛的设计决策，要问的一个基本问题是：什么
是算法决策中预测的相对价值吗？怎样做
与预测相比，更好的预测带来的福利改善
其他政策杠杆？我们工作的目标是启动对
这些问题。我们的主要结果本质上是理论上的。我们确定
简单、明确的条件决定了预测的相对价值
相对于扩大访问，在几个统计模型中
在定量社会科学家中很受欢迎。此外，我们还说明了如何
这些理论见解可用于指导算法的设计
实践中的决策系统。
]]></description>
      <guid>http://arxiv.org/abs/2312.08511</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:12 GMT</pubDate>
    </item>
    <item>
      <title>随机神经网络的通用逼近性质。 （arXiv：2312.08410v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.08410</link>
      <description><![CDATA[在本文中，我们研究单隐藏层的随机神经网络
权重和偏差随机初始化的前馈神经网络。
在这个随机初始化之后，只需要训练线性读出，
这可以例如通过最小二乘法有效地执行。经过
将随机神经网络视为 Banach 空间值随机变量，我们
在合适的博赫纳空间内证明它们的通用逼近性质。
由此，相应的Banach空间可以比以下空间更一般
欧几里得空间的紧子集上的连续函数，即，例如，
$L^p$-空间或 Sobolev 空间，其中后者包括近似值
的衍生物。此外，我们得出了一些近似率并开发了一个
通过随机神经网络学习确定性函数的显式算法
网络。此外，我们还提供了随机时的完整误差分析和研究
神经网络克服了维数灾难
培训成本在输入和输出维度上最多按多项式缩放。
此外，我们在两个数值示例中展示了以下经验优势
随机神经网络与经过充分训练的确定性神经网络相比。
]]></description>
      <guid>http://arxiv.org/abs/2312.08410</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:11 GMT</pubDate>
    </item>
    <item>
      <title>傅里叶勒贝格空间中浅层神经网络的时空逼近。 （arXiv：2312.08461v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.08461</link>
      <description><![CDATA[浅层神经网络 (SNN) 的逼近能力形成一个整体
部分了解深度神经网络 (DNN) 的特性。在里面
研究一些非常流行的目标类别的近似能力
函数就是所谓的谱巴伦空间。这个空间很特别
对偏微分方程的近似感兴趣
（偏微分方程）解。已经证明某些静态偏微分方程的解
将位于某个光谱巴伦空间中。为了缓解限制
静态偏微分方程并包括可能具有不同规律的时域
除了空间域之外，我们将谱巴伦空间的概念扩展到
各向异性加权傅立叶-勒贝格空间。在此过程中，我们考虑目标
具有两个变量块的函数，其中每个块都允许
具有不同的衰减和可积性质。对于这些目标
我们首先研究包含各向异性加权傅立叶-勒贝格函数
Bochner-Sobolev 空间中的空间。这样我们现在还可以测量
各向异性 Sobolev 范数的近似误差，即
博赫纳-索博列夫范数。我们在第二步中使用这一观察结果
建立各向异性函数近似率的界限
加权 Fourier-Lebesgue 空间和通过 SNN 的近似
博赫纳-索博列夫范数。
]]></description>
      <guid>http://arxiv.org/abs/2312.08461</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:11 GMT</pubDate>
    </item>
    </channel>
</rss>