<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Mon, 11 Dec 2023 03:14:31 GMT</lastBuildDate>
    <item>
      <title>具有共享先验的贝叶斯数据融合。 （arXiv：2212.07311v2 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2212.07311</link>
      <description><![CDATA[来自多个来源的数据和知识的整合称为数据
融合。当数据仅以分布式方式可用或不同时
传感器用于推断感兴趣的数量，数据融合变成
基本的。在贝叶斯设置中，未知量的先验信息
是可用的，并且可能存在于不同的分布式估计器中。
当融合局部估计时，用于构建的先验知识
除非融合节点考虑到，否则几个局部后验可能会被过度使用
并纠正它。在本文中，我们分析了共享先验的影响
贝叶斯数据融合上下文。根据不同的常见融合规则，我们的
分析有助于理解作为函数的性能行为
协作代理的数量以及不同类型的结果
先验。该分析是通过使用两个常见的分歧来进行的
贝叶斯推理和结果的普遍性允许分析非常
通用分布。这些理论结果通过
各种估计和分类问题的实验，包括
线性和非线性模型以及联邦学习方案。
]]></description>
      <guid>http://arxiv.org/abs/2212.07311</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:31 GMT</pubDate>
    </item>
    <item>
      <title>损失最小化产生大型神经网络的多重校准。 （arXiv：2304.09424v2 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2304.09424</link>
      <description><![CDATA[多重校准是预测变量的公平概念，要求预测变量
为大量受保护群体提供经过校准的预测。
众所周知，多重校准是一个与损失最小化不同的目标，甚至
对于简单的预测变量，例如线性函数。

在这项工作中，我们考虑了受保护组可以的设置
由大小为 $k$ 的神经网络表示，预测变量是神经网络
网络大小 $n &gt; k$。我们证明了最小化所有平方损失
大小为 $n$ 的神经网络意味着除有限数量之外的所有神经网络的多重校准
$n$ 的不幸值。我们还提供证据表明我们对数量的限制
考虑到我们的证明技术，不幸的值是严格的。此前，调查结果
损失最小化产生多重校准的风味仅以
接近真实情况的预测，因此在
适用性。与这些不同的是，我们的结果依赖于神经网络的表达能力
网并利用预测器的表示。
]]></description>
      <guid>http://arxiv.org/abs/2304.09424</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:31 GMT</pubDate>
    </item>
    <item>
      <title>使用简约相加模型和结构化交互来预测人口普查调查响应率。 （arXiv：2108.11328v4 [stat.ML] 已更新）</title>
      <link>http://arxiv.org/abs/2108.11328</link>
      <description><![CDATA[在本文中，我们考虑预测调查回复率的问题
使用一系列灵活且可解释的非参数模型。该研究是
受到美国人口普查局著名的 ROAM 应用程序的启发，该应用程序使用
根据美国人口普查规划数据库数据训练的线性回归模型
识别难以调查的区域。众包竞赛（Erdman 和 Bates，
2016）大约十年前组织的揭示了机器学习方法
基于回归树的集成带来了最佳性能
预测调查回复率；但相应型号无法
由于其黑盒性质，可用于预期应用。我们
考虑具有少量主模型和成对模型的非参数加性模型
使用基于 $\ell_0$ 的惩罚的交互效果。从方法论上
观点，我们研究我们的计算和统计方面
估计器；并讨论包含强层次结构的变体
互动。我们的算法（在 github 上开源）扩展了计算能力
稀疏加性模型现有算法的前沿，能够
处理与我们考虑的应用程序相关的数据集。我们讨论并
解释我们在美国人口普查规划数据库中的模型的结果。在
除了从可解释性的角度来看很有用之外，我们的模型还领先
似乎比流行的黑盒机器学习更好的预测
基于梯度提升和前馈神经网络的方法 - 建议
有可能拥有两全其美的模型：好
模型的准确性和可解释性。
]]></description>
      <guid>http://arxiv.org/abs/2108.11328</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:30 GMT</pubDate>
    </item>
    <item>
      <title>多频联合社区检测和相位同步。 （arXiv：2206.12276v3 [cs.SI] 已更新）</title>
      <link>http://arxiv.org/abs/2206.12276</link>
      <description><![CDATA[本文研究了联合社区检测和相位同步
\textit{具有相对相位的随机块模型}上的问题，其中每个
节点与未知的相位角相关。这个问题，有多种
现实世界的应用程序，旨在恢复集群结构和相关
同时相位角。我们证明这个问题表现出
\textit{``多频率&#39;&#39;} 结构通过仔细检查其最大值
似然估计（MLE）公式，而现有方法则不然
源于这个视角。为此，有两个简单而有效的方法
利用 MLE 公式并从信息中受益的算法
建议跨多个频率。前者是基于谱的方法
新颖的多频率列旋转 QR 分解。因式分解
应用于观察矩阵的顶部特征向量提供了关键
有关簇结构和相关相位角的信息。第二
方法是一种迭代多频广义幂方法，其中每个
迭代更新矩阵乘法然后投影中的估计
方式。数值实验表明我们提出的算法显着
提高准确恢复簇结构的能力
与最先进的技术相比，估计相位角的准确性
算法。
]]></description>
      <guid>http://arxiv.org/abs/2206.12276</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:30 GMT</pubDate>
    </item>
    <item>
      <title>基于上下文无关语法的分层神经架构搜索空间的构建。 （arXiv：2211.01842v3 [cs.LG] 已更新）</title>
      <link>http://arxiv.org/abs/2211.01842</link>
      <description><![CDATA[从简单的构建块中发现神经架构是一个
神经架构搜索（NAS）的长期目标。分层搜索
space 是朝着这一目标迈出的有希望的一步，但缺乏统一的搜索空间
设计框架，通常只搜索某些有限的方面
架构。在这项工作中，我们引入了统一的搜索空间设计
基于上下文无关语法的框架，可以自然而紧凑地
生成具有数百个阶数的富有表现力的分层搜索空间
数量级大于文献中的公共空间。通过增强和使用
它们的属性，我们有效地支持对整个架构的搜索
并可以培养规律性。此外，我们提出了一个高效的分层内核
设计贝叶斯优化搜索策略以有效搜索
如此巨大的空间。我们展示了搜索空间设计的多功能性
框架并表明我们的搜索策略可以优于现有的 NAS
接近。代码可在
https://github.com/automl/hierarchical_nas_construction。
]]></description>
      <guid>http://arxiv.org/abs/2211.01842</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:30 GMT</pubDate>
    </item>
    <item>
      <title>异方差对隆起建模的影响。 （arXiv：2312.05234v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.05234</link>
      <description><![CDATA[应用程序多种多样，公司需要决定采用哪些应用程序
他们应该最好分配治疗的个人。为了支持这样的决定，
提升模型用于预测个体水平的治疗效果。
根据预测的治疗效果，可以对个体进行排名和
可以根据此排名确定治疗分配的优先顺序。隐含的
假设，在之前的隆起模型中没有受到质疑
文献中，这种治疗优先顺序方法往往会带来
治疗效果高的个体和治疗效果低的个体
治疗效果排名垫底。在我们的研究中，我们表明
训练数据中的异方差可能会导致提升模型出现偏差
排名：治疗效果最高的个体可以累积
排名底部的大量数字。我们从理论上解释如何
异方差可以使提升模型的排名产生偏差并显示此过程
在模拟和现实世界的数据中。我们认为这个排名问题
在许多现实世界的应用中可能会出现由于异方差性而导致的偏差
需要修改治疗优先顺序以实现有效
治疗分配。
]]></description>
      <guid>http://arxiv.org/abs/2312.05234</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:29 GMT</pubDate>
    </item>
    <item>
      <title>TaskMet：用于模型学习的任务驱动的度量学习。 （arXiv：2312.05250v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.05250</link>
      <description><![CDATA[深度学习模型通常部署在训练的下游任务中
程序可能不知道。例如，仅训练模型以实现
准确的预测可能很难在下游任务上表现良好，因为
看似很小的预测错误可能会导致严重的任务错误。标准
端到端学习方法是使任务损失可微分或
引入一个可以训练模型的可微代理。在这些
设置时，需要仔细平衡任务损失与预测损失
因为他们的目标可能相互冲突。我们建议承担任务损失
发出比模型参数更深一层的信号并用它来学习
模型训练的损失函数的参数，可以这样做
通过学习预测空间中的度量。这种方法不会改变
最优预测模型本身，而是将模型学习改变为
强调对下游任务重要的信息。这使我们能够
实现两全其美：在原始模型中训练的预测模型
预测空间，同时对于所需的下游任务也很有价值。我们
通过在两个主要环境中进行的实验来验证我们的方法：1）
以决策为中心的模型学习场景，涉及投资组合优化和
预算分配，2）在嘈杂环境中的强化学习
分散注意力的状态。重现我们实验的源代码可用
在 https://github.com/facebookresearch/taskmet
]]></description>
      <guid>http://arxiv.org/abs/2312.05250</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:29 GMT</pubDate>
    </item>
    <item>
      <title>最优多分布学习。 （arXiv：2312.05134v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.05134</link>
      <description><![CDATA[多分布学习（MDL），旨在学习一个共享模型
最小化 $k$ 不同数据分布中最坏情况的风险，
作为一个统一的框架，以满足不断变化的需求
鲁棒性、公平性、多组协作等，实现数据高效
MDL 需要自适应采样，也称为按需采样
学习过程。然而，两者之间存在着巨大差距
最佳样本复杂性的最先进的上限和下限。
关注 Vapnik-Chervonenkis (VC) 维度 $d$ 的假设类，我们
提出一种新算法，产生 $varepsilon$ 最优随机
样本复杂度约为 $(d+k)/\varepsilon^2$ 的假设
（对某个对数因子取模），匹配最著名的下限。我们的
算法思想和理论得到了进一步扩展，以适应
拉德马赫课程。所提出的算法具有预言机效率，可以访问
假设类仅通过经验风险最小化预言。
此外，我们确定了随机化的必要性，揭示了大
仅允许确定性假设时的样本量障碍。这些
研究结果成功解决了 COLT 2023 中提出的三个未决问题（即
Awasthi 等人，（2023 年，问题 1、3 和 4））。
]]></description>
      <guid>http://arxiv.org/abs/2312.05134</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:28 GMT</pubDate>
    </item>
    <item>
      <title>基于代理的贝叶斯推理中的不确定性量化和传播。 （arXiv：2312.05153v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.05153</link>
      <description><![CDATA[替代模型是统计或概念上的近似值
复杂的模拟模型。在此背景下，宣传
有限的模拟预算和替代近似引起的不确定性
预测、推理和后续决策相关量的错误。
然而，量化并传播替代物的不确定性是
通常仅限于特殊的分析情况，或者在其他方面计算量很大
昂贵的。在本文中，我们提出了一个框架，可实现可扩展的贝叶斯
具有彻底的不确定性量化的替代建模方法，
传播和验证。具体来说，我们提出了三种方法
给定测量数据的代理模型的贝叶斯推理。这是一个任务
其中替代不确定性的传播尤其相关，因为
未能考虑到这一点可能会导致有偏见和/或过度自信的估计
感兴趣的参数。我们通过两个详细案例展示我们的方法
研究线性和非线性建模场景。不确定
代理模型中的传播可以更可靠、更安全地近似
昂贵的模拟器，因此可用于各个领域
应用程序。
]]></description>
      <guid>http://arxiv.org/abs/2312.05153</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:28 GMT</pubDate>
    </item>
    <item>
      <title>Onflow：一种在线投资组合分配算法。 (arXiv:2312.05169v1 [q-fin.PM])</title>
      <link>http://arxiv.org/abs/2312.05169</link>
      <description><![CDATA[我们介绍 Onflow，一种强化学习技术，可以实现在线
基于梯度流的投资组合配置策略优化。我们
设计投资组合的动态分配，以最大化其预期
记录回报，同时考虑交易费用。投资组合分配
通过 softmax 函数进行参数化，并且在每个时间步，
梯度流法得出一个常微分方程，其解
对应于更新的分配。该算法属于大
随机优化过程类；我们通过以下方式衡量其效率
将我们的结果与对数正态分布的数学理论值进行比较
框架和来自“旧纽约证券交易所”数据集的标准基准。为了
对数正态资产，Onflow 学习的策略，交易成本为
零，模仿马科维茨的最佳投资组合，从而模拟最佳资产
分配策略。 “旧纽约证券交易所”数据集的数值实验显示
Onflow 导致动态资产配置策略，其性能
a) 与 Cover 的通用投资组合等基准策略相当
或赫尔姆博尔德等人。当交易成本为“乘法更新”方法时
零，b) 当交易成本很高时，比以前的程序更好。
Onflow 甚至可以在其他动态分配的情况下保持高效
技术不再起作用了。因此，根据测试，Onflow 似乎
是基于观察价格的有前景的动态投资组合管理策略
仅且不假设基础资产的分布规律
资产的回报。特别是它可以在构建模型时避免模型风险
交易策略。
]]></description>
      <guid>http://arxiv.org/abs/2312.05169</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:28 GMT</pubDate>
    </item>
    <item>
      <title>学习归纳共形预测的 PAC-Bayes 泛化证书。 （arXiv：2312.04658v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.04658</link>
      <description><![CDATA[感应共形预测（ICP）提供了实用且有效的方法
为深度学习模型配备不确定性估计的方法
保证包含真实情况的集值预测的形式
有很高的概率。尽管这种保险保障很有吸引力，但这些
集可能效率不高：预测集的大小和内容不是有效的
直接控制，而是取决于底层模型和选择
评分函数。为了解决这个问题，最近的工作提出了学习模型和
使用数据对函数参数进行评分，直接优化效率
ICP 预测集。虽然很有吸引力，但这种泛化理论
缺乏方法：经验效率的直接优化可能会产生
预测集要么对测试数据不再有效，要么不再有效
获得所需的测试数据覆盖率。在这项工作中，我们使用 PAC-Bayes
理论以获得覆盖率和效率的泛化界限
可以直接优化以最大化效率的集值预测器
同时满足所需的测试覆盖率。与之前的工作相比，我们的
框架允许我们利用整个校准数据集来学习
模型和评分函数的参数，而不需要单独的
用于获得测试时间覆盖率保证的保留集。我们利用这些
理论结果为使用校准数据提供实用算法
同时微调模型和评分函数的参数，同时
保证测试时间覆盖率和结果预测的效率
套。我们评估回归和分类任务的方法，并且
优于使用 Hoeffding 基于界限的 PAC 保证校准的基线
ICP，尤其是在低数据情况下。
]]></description>
      <guid>http://arxiv.org/abs/2312.04658</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:27 GMT</pubDate>
    </item>
    <item>
      <title>离散裂缝网络模拟存在固有随机性的敏感性分析。 （arXiv：2312.04722v1 [stat.AP]）</title>
      <link>http://arxiv.org/abs/2312.04722</link>
      <description><![CDATA[大规模离散裂缝网络 (DFN) 模拟器是以下领域的标准配置：
自直接以来涉及粒子地下传输的研究
对现实世界地下裂缝网络的观察通常是
不可行的。虽然这些模拟器已经在多个领域取得了巨大的成功
工程应用，对感兴趣数量 (QoI) 的估计 - 例如
粒子到达系统边缘的突破时间 - 遭受
两种不同类型的不确定性。 DFN 模拟器的运行需要几个
要设置的参数值决定裂缝的位置和大小，
裂缝密度和系统的整体渗透率；
正确参数选择的不确定性将导致一定程度的
QoI 的不确定性，称为认知不确定性。此外，由于 DFN
模拟器依靠随机过程来放置裂缝并控制流动，
了解这种随机性如何影响 QoI 需要多次运行
模拟器在不同的随机种子。 QoI 的不确定性归因于
同一随机过程的不同实现（即不同的种子）导致
第二种类型的不确定性，称为任意不确定性。在本文中，
我们进行敏感性分析，直接归因于不确定性
在 QoI 中观察到每个输入参数的认知不确定性
到任意的不确定性。我们做出了多种设计选择来处理
在 DFN 模拟器中观察到异方差性，其中任意不确定性
不同输入的变化，因为质量制定了几个标准
统计方法不可接受。除了输入的具体要点之外
变量对 DFN 模拟器的不确定性影响最大，这是一个主要贡献
本文介绍了一个统计上严格的工作流程
描述 DFN 流动模拟中的不确定性
异方差性。
]]></description>
      <guid>http://arxiv.org/abs/2312.04722</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:27 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的非自然算法。 （arXiv：2312.04739v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.04739</link>
      <description><![CDATA[自然梯度下降有一个显着的特性，在小型学习中
速率限制，它显示出相对于网络的不变性
重新参数化，即使对于高度
协变网络参数化。我们证明了优化算法
该属性可以被视为自然的离散近似
函子的转换确定优化器的状态空间
微分同胚群（如果其配置流形）到函子
从该组中确定该状态空间的切丛。算法与
当用于训练参数化不良时，该属性具有更高的效率
网络，因为它们生成的网络演化近似不变
网络重新参数化。更具体地说，这些产生的流量
算法在学习率消失的极限下在平滑条件下是不变的
重新参数化，参数的相应流程由下式确定
等变图。通过将此属性转换为自然变换，我们允许
对于群体行为而言，超越等方差的概括；这
框架可以解释不可逆的地图，例如投影，创建一个
直接比较非同构训练行为的框架
网络架构，以及限制行为的正式检查
通过考虑这些投影的逆限制来增加网络规模，
它们是否应该存在。我们介绍一种引入这种自然性的简单方法
更广泛地研究一些流行的机器学习训练
算法，发现大多数都是不自然的。
]]></description>
      <guid>http://arxiv.org/abs/2312.04739</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:27 GMT</pubDate>
    </item>
    <item>
      <title>估计 Fr\'echet 边界以验证程序性弱监督。 （arXiv：2312.04601v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.04601</link>
      <description><![CDATA[我们开发了估计 Fr\&#39;echet 边界的方法（可能是
高维）分布类，其中一些变量是
连续值。我们确定计算的统计正确性
边际约束不确定性下的界限并证明
通过评估机器学习的性能来评估我们算法的有用性
(ML) 模型使用程序化弱监督 (PWS) 进行训练。 PWS 是一个
从弱监督输入中进行原则学习的框架（例如，
众包标签、知识库、相关任务的预训练模型、
等），并在许多科学领域取得了令人瞩目的成功
工程。不幸的是，通常很难验证
由于缺乏标记数据，使用 PWS 训练的 ML 模型的性能。
我们的算法通过估计尖锐的下限和上限来解决这个问题
用于性能指标，例如准确度/召回率/精确度/F1 分数。
]]></description>
      <guid>http://arxiv.org/abs/2312.04601</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:26 GMT</pubDate>
    </item>
    <item>
      <title>使用新颖的概率迁移学习策略增强基于多项式混沌展开的代理建模。 （arXiv：2312.04648v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.04648</link>
      <description><![CDATA[在代理建模领域，多项式混沌展开（PCE）允许
从业者构建廉价但准确的替代品用于
昂贵的正演模型模拟的地方。对于黑盒模拟，
非侵入式 PCE 允许使用一组
模拟响应评估。在这种情况下，PCE系数可以是
使用线性回归获得，也称为点搭配或
随机响应面。回归表现出更好的可扩展性，并且可以
与其他非侵入式相比，处理嘈杂的函数评估
方法，例如投影。然而，由于过采样通常
建议采用线性回归方法，模拟要求
昂贵的前瞻模型变得令人望而却步。我们建议利用杠杆
迁移学习，通过类似的 PCE 替代物获得知识
构建任务（源域）转移到新的
代理构建任务（目标域），其数量有限
正演模型模拟（训练数据）。拟议的迁移学习
策略决定使用新的信息传输多少信息（如果有的话）
受贝叶斯建模和数据同化启发的技术。策略是
使用数值研究进行仔细检查并应用于工程
石油和天然气行业的问题。
]]></description>
      <guid>http://arxiv.org/abs/2312.04648</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:26 GMT</pubDate>
    </item>
    </channel>
</rss>