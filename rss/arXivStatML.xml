<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 17 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>疾病轨迹的半监督生成模型：系统性硬化症案例研究</title>
      <link>https://arxiv.org/abs/2407.11427</link>
      <description><![CDATA[arXiv:2407.11427v1 公告类型：交叉 
摘要：我们提出了一种深度生成方法，使用潜在时间过程对复杂的疾病轨迹进行建模和整体分析，特别关注系统性硬化症 (SSc)。我们的目标是学习底层生成过程的时间潜在表示，以可解释和全面的方式解释观察到的患者疾病轨迹。为了增强这些潜在时间过程的可解释性，我们开发了一种半监督方法，使用已建立的医学知识来解开潜在空间。通过将生成方法与 SSc 不同特征的医学定义相结合，我们促进了对该疾病的新方面的发现。我们表明，学习到的时间潜在过程可用于进一步的数据分析和临床假设检验，包括寻找相似的患者并将 SSc 患者轨迹聚类为新的子类型。此外，我们的方法能够实现个性化的在线监控和多变量时间序列的预测，并量化不确定性。]]></description>
      <guid>https://arxiv.org/abs/2407.11427</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:47 GMT</pubDate>
    </item>
    <item>
      <title>时刻展开</title>
      <link>https://arxiv.org/abs/2407.11284</link>
      <description><![CDATA[arXiv:2407.11284v1 公告类型：交叉 
摘要：在粒子和核物理学中，对探测器失真进行反卷积（“展开”）是将截面测量与理论预测进行比较的关键步骤。然而，大多数现有方法都需要直方图分箱，而许多理论预测处于统计矩的水平。我们开发了一种新方法，可以直接将分布矩展开为另一个可观测量的函数，而无需先将数据离散化。我们的矩展开技术使用机器学习，并受到生成对抗网络 (GAN) 的启发。我们使用对撞机物理学中的喷射子结构测量来展示这种方法的性能。通过这个说明性示例，我们发现我们的矩展开协议比基于箱的方法更精确，并且与完全未分箱的方法一样精确或更精确。]]></description>
      <guid>https://arxiv.org/abs/2407.11284</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:46 GMT</pubDate>
    </item>
    <item>
      <title>亚威布尔分布的指数倾斜</title>
      <link>https://arxiv.org/abs/2407.11386</link>
      <description><![CDATA[arXiv:2407.11386v1 公告类型：交叉 
摘要：最近已证明亚威布尔分布类可以概括亚指数和亚高斯随机变量的重要特性。我们描述了亚威布尔分布的替代特征，并详细说明了在指数倾斜后其尾部行为得以保留的条件。]]></description>
      <guid>https://arxiv.org/abs/2407.11386</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:46 GMT</pubDate>
    </item>
    <item>
      <title>通过多任务学习解开 RNN 中的表征</title>
      <link>https://arxiv.org/abs/2407.11249</link>
      <description><![CDATA[arXiv:2407.11249v1 公告类型：交叉 
摘要：抽象或解缠结表示是一种有前途的数学框架，可用于在生物和人工系统中实现高效和有效的泛化。我们在噪声证据流的多任务分类背景下研究抽象表示——这是一种典型的决策神经科学范式。我们推导出理论界限，当任务数量超过状态空间的维数时，保证在任何最佳多任务分类器的潜在状态中出现解缠结表示。我们通过实验证实，在多任务分类上训练的 RNN 以连续吸引子的形式学习解缠结表示，从而实现零样本分布外 (OOD) 泛化。我们展示了抽象 RNN 表示在各种决策边界几何和需要分类置信度估计的任务中的灵活性。我们的框架提出了形成认知图的一般原则，该原则组织知识以实现在生物和人工系统中的灵活概括，并且与人类和动物在决策和空间推理任务中发现的表现密切相关。]]></description>
      <guid>https://arxiv.org/abs/2407.11249</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>异构隐私下的经验均值和频率估计：最坏情况分析</title>
      <link>https://arxiv.org/abs/2407.11274</link>
      <description><![CDATA[arXiv:2407.11274v1 公告类型：交叉 
摘要：差分隐私 (DP) 是当前衡量隐私的黄金标准。文献中出现的 DP 约束下的估计问题主要集中在为所有用户提供平等的隐私。我们考虑单变量数据的经验均值估计和分类数据的频率估计问题，这是行业数据分析的两个支柱，受制于异构隐私约束。每个为数据集贡献样本的用户都可以有不同的隐私需求。数据集本身被假设为最坏情况，我们在两种不同的公式中研究这两个问题——相关和不相关的设置。在前一种设置中，隐私需求和用户数据可以任意相关，而在后一种设置中，数据集和隐私需求之间没有相关性。我们证明了我们提出的算法在 PAC 误差和均方误差下的一些最优结果，并通过实验证明了优于其他基线技术的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.11274</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>联邦学习与控制的结合：一项调查</title>
      <link>https://arxiv.org/abs/2407.11069</link>
      <description><![CDATA[arXiv:2407.11069v1 公告类型：交叉 
摘要：本调查概述了将联邦学习 (FL) 与控制相结合以增强 (非线性) 控制应用中的适应性、可扩展性、泛化和隐私。传统的控制方法依赖于控制器设计模型，但现实世界场景通常需要在线模型重新调整或学习。FL 提供了一种分布式模型训练方法，可以在分布式设备之间实现协作学习，同时保护数据隐私。通过保持数据本地化，FL 可以减轻对隐私和安全的担忧，同时降低通信的网络带宽要求。本调查总结了将 FL 与控制相结合的最新概念和思想。进一步讨论了方法上的好处，最终详细概述了预期的应用，从动态系统建模到控制器设计，重点关注自适应控制，再到多智能体决策系统中的知识转移。]]></description>
      <guid>https://arxiv.org/abs/2407.11069</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>基于稳健分数的最快变化检测</title>
      <link>https://arxiv.org/abs/2407.11094</link>
      <description><![CDATA[arXiv:2407.11094v1 公告类型：交叉
摘要：最快变化检测领域的方法可以快速实时检测在线数据流的数据生成分布的变化。现有方法能够在已知变化前后分布密度的情况下检测到这个变化点。最近的研究将这些结果扩展到仅通过其得分函数知道变化前后分布的情况。这项工作考虑了已知变化前后得分函数仅对应于两个不相交集合中的分布的情况。这项工作采用了一对“最不利”分布来增强现有的基于得分的最快变化检测算法的鲁棒性，并研究了该算法的性质。本文计算了特定模型类的最不利分布，并提供了估计常见构造的最不利分布的方法。模拟结果证明了我们鲁棒变化检测算法的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.11094</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中对抗性弱点的几何框架</title>
      <link>https://arxiv.org/abs/2407.11029</link>
      <description><![CDATA[arXiv:2407.11029v1 公告类型：交叉 
摘要：这项工作始于使用数学来理解 ~\citet{szegedy2013} 在人工神经网络中观察到的有趣漏洞。在此过程中，我们将开发一些新颖的工具，其应用范围远远超出对抗领域。我们将在开发一个严格的数学框架来研究这个问题的同时做到这一点。我们的目标是建立一种理论，可以支持越来越复杂的对抗攻击猜想，特别关注 ~\citet{shamir2021dimpled} 所谓的“酒窝流形假设”。第一章将介绍神经网络架构的历史和架构。第二章重点介绍对抗性漏洞的背景。从 ~\citet{szegedy2013} 的开创性论文开始，我们将发展对抗性扰动和攻击的理论。
第三章将构建一个与里奇曲率相关的持久性理论，该理论可用于测量决策边界的性质。我们将利用这个基础做出与对抗性攻击有关的猜想。第四章和第五章代表了一个突然而精彩的题外话，它考察了神经网络空间分析的一个有趣的相关理论体系，将其作为核机器的近似，并成为一种用双线性映射表示神经网络的新理论。这些数学含量很高的章节将建立一个框架，并开始探索可能成为使用空间和几何信息分析神经网络学习的非常重要的理论基础的应用。最后，我们将在继续研究中建立新的方法来解答第三章中的猜想。]]></description>
      <guid>https://arxiv.org/abs/2407.11029</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>函数交叉偏导数和替代项的最优估计</title>
      <link>https://arxiv.org/abs/2407.11035</link>
      <description><![CDATA[arXiv:2407.11035v1 公告类型：交叉 
摘要：使用较少的模型运行计算交叉偏导数与建模相关，例如随机近似、基于导数的方差分析、探索复杂模型和活动子空间。本文通过在 $N$ 个随机点处评估此类函数并使用一组 $L$ 约束来引入所有函数交叉偏导数的替代项。随机点依赖于独立、中心和对称变量。基于 $NL$ 模型运行的相关估计量达到最佳收敛速度（即 $\mathcal{O}(N^{-1})$），并且我们的近似偏差不会受到广泛函数类的维数灾难的影响。这些结果用于 i) 计算敏感度指标的主要和上限，以及 ii) 利用基于导数的方差分析得出模拟器的模拟器或函数的替代。模拟结果显示了我们的模拟器和敏感度指标估计器的准确性。使用一个样本的 U 统计量的指标插件估计在数值上非常稳定。]]></description>
      <guid>https://arxiv.org/abs/2407.11035</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>纵向数据的贝叶斯因果森林：评估兼职工作对高中数学成绩增长的影响</title>
      <link>https://arxiv.org/abs/2407.11927</link>
      <description><![CDATA[arXiv:2407.11927v1 公告类型：新
摘要：对学生成绩增长进行建模是教育领域的一项重大挑战。了解干预措施或兼职工作等经历如何影响这种增长也很重要。传统方法（如差异-差异法）对于从纵向数据估计因果效应非常有效。同时，贝叶斯非参数方法最近已成为从单时间点观察研究中估计因果效应的流行方法。然而，仍然缺乏能够结合这两种方法的优势来灵活地从纵向数据估计异质因果效应的方法。受高中纵向研究（NCES 的最新纵向研究，追踪了美国超过 20,000 名学生的代表性样本）的两波数据的启发，我们的研究引入了贝叶斯因果森林的纵向扩展。该模型可以灵活地识别个人数学能力的增长和参与兼职工作的影响。模拟研究证明了所提模型的预测性能和可靠的不确定性量化。结果显示兼职工作对大多数学生都有负面影响，但对那些最初对学校归属感较低的学生来说，兼职工作可能带来好处。研究还发现，高学业成绩和低学业成绩学生之间的成就差距正在扩大。本文讨论了潜在的政策影响，以及未来研究的有希望的领域。]]></description>
      <guid>https://arxiv.org/abs/2407.11927</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:42 GMT</pubDate>
    </item>
    <item>
      <title>核化异常检测的方差范数</title>
      <link>https://arxiv.org/abs/2407.11873</link>
      <description><![CDATA[arXiv:2407.11873v1 公告类型：新
摘要：我们提出了一种统一的 Banach 空间马哈拉诺比斯型异常检测理论，该理论使用 Cameron-Martin 理论的思想应用于非高斯测度。这种方法通过所谓的概率测度方差范数，得出了一种无基础、数据驱动的异常距离概念，可以使用经验测度进行一致估计。我们的框架概括了经典的 $\mathbb{R}^d$、函数 $(L^2[0,1])^d$ 和核化设置，包括非注入协方差算子的一般情况。我们证明方差范数仅取决于给定希尔伯特空间中的内积，因此可以通过对再生核希尔伯特空间进行工作自然地恢复核化马哈拉诺比斯距离。
使用方差范数，我们引入了用于半监督异常检测的核化最近邻马哈拉诺比斯距离的概念。在对 12 个真实世界数据集的实证研究中，我们证明了核化最近邻马哈拉诺比斯距离在多变量时间序列异常检测中优于传统的核化马哈拉诺比斯距离，使用最先进的时间序列核，例如签名、全局对齐和沃尔特拉储层核。此外，我们通过在有限维高斯情况下开发浓度不等式，为最近邻马哈拉诺比斯距离提供了初步的理论依据。]]></description>
      <guid>https://arxiv.org/abs/2407.11873</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:41 GMT</pubDate>
    </item>
    <item>
      <title>结合 Wasserstein-1 和 Wasserstein-2 近端：通过适定生成流进行稳健的流形学习</title>
      <link>https://arxiv.org/abs/2407.11901</link>
      <description><![CDATA[arXiv:2407.11901v1 公告类型：新
摘要：我们通过 Wasserstein 近端正则化 $f$ 散度，为低维流形上支持的学习分布制定了适定的连续时间生成流。Wasserstein-1 近端算子对 $f$ 散度进行正则化，以便可以比较奇异分布。同时，Wasserstein-2 近端算子通过添加最佳传输成本（即动能惩罚）来规范生成流的路径。通过平均场博弈论，我们表明两个近端的组合对于制定适定的生成流至关重要。可以通过平均场博弈 (MFG) 的最优性条件、后向汉密尔顿-雅可比 (HJ) 系统和前向连续性偏微分方程 (PDE) 来分析生成流，其解表征了最佳生成流。对于学习低维流形上支持的分布，MFG 理论表明，解决 HJ 终端条件的 Wasserstein-1 近端和解决 HJ 动力学的 Wasserstein-2 近端都是相应的后向-前向 PDE 系统定义明确并具有可证明的线性流轨迹的唯一解所必需的。这意味着相应的生成流也是唯一的，因此即使在学习低维流形上支持的高维分布时也可以以稳健的方式进行学习。生成流是通过连续时间流的对抗性训练来学习的，从而无需进行反向模拟。我们证明了我们的方法在生成高维图像方面的有效性，而无需借助自动编码器或专门的架构。]]></description>
      <guid>https://arxiv.org/abs/2407.11901</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:41 GMT</pubDate>
    </item>
    <item>
      <title>预条件梯度下降法可发现过度参数化的神经网络，对非参数回归具有敏锐的泛化能力</title>
      <link>https://arxiv.org/abs/2407.11353</link>
      <description><![CDATA[arXiv:2407.11353v1 公告类型：新
摘要：本文考虑通过梯度下降 (GD) 或其变体训练的过度参数化的两层神经网络进行非参数回归。我们表明，如果神经网络使用具有早期停止的新型预条件梯度下降 (PGD) 进行训练，并且目标函数具有深度学习文献中广泛研究的谱偏差，则训练后的网络会呈现特别尖锐的泛化界限，极小极大最优速率为 $\cO({1}/{n^{4\alpha/(4\alpha+1)}})$，当数据在 $\RR^d$ 中的单位球面上均匀分布且 $n$ 是训练数据的大小时，该速率比当前标准速率 $\cO({1}/{n^{2\alpha/(2\alpha+1)}})$ 更尖锐，其中 $2\alpha = d/(d-1)$。当目标函数没有谱偏差时，我们证明了使用常规 GD 和提前停止训练的神经网络仍然具有极小极大最优速率，并且在这种情况下，与目前已知的结果相比，我们的结果不需要分布假设。我们的结果建立在两个重要的技术贡献之上。首先，在训练过程中，PGD 或 GD 建立了向 NTK 的均匀收敛，因此我们可以在 GD 或 PGD 的任何步骤中将神经网络函数很好地分解为 RKHS 中的函数和具有较小 $L^{\infty}$ 范数的误差函数。其次，使用局部 Rademacher 复杂度来严格限制由 GD 或 PGD 获得的所有可能的神经网络函数组成的函数类的 Rademacher 复杂度。我们的结果还表明，PGD 可以是避免 NTK 通常的线性状态并获得更清晰的泛化界限的另一种方法，因为 PGD 在训练期间会诱导与常规 GD 训练的网络架构诱导的常规 NTK 不同的具有较低核复杂度的核。]]></description>
      <guid>https://arxiv.org/abs/2407.11353</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:40 GMT</pubDate>
    </item>
    <item>
      <title>通过优化最大平均差异实现的集合传输滤波器</title>
      <link>https://arxiv.org/abs/2407.11518</link>
      <description><![CDATA[arXiv:2407.11518v1 公告类型：新
摘要：本文提出了一种新的基于集合的滤波方法，通过传输图重构粒子滤波器的分析步骤，将先验粒子直接传输到后验粒子。传输图是通过最大均值差异损失函数描述的优化问题构建的，该函数与近似后验和参考后验的期望信息相匹配。所提出的方法继承了粒子滤波对后验分布的准确估计。为了提高最大均值差异的稳健性，使用方差惩罚项来指导优化。它优先最小化近似和参考后验的高度信息统计数据的期望之间的差异。惩罚项显著增强了所提方法的稳健性，并导致对后验的更好近似。给出了一些数值例子来说明所提方法相对于集合卡尔曼滤波器的优势。]]></description>
      <guid>https://arxiv.org/abs/2407.11518</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:40 GMT</pubDate>
    </item>
    <item>
      <title>通过输入映射和隐变量高斯过程实现异构多源数据融合</title>
      <link>https://arxiv.org/abs/2407.11268</link>
      <description><![CDATA[arXiv:2407.11268v1 公告类型：新
摘要：人工智能和机器学习框架已成为工程问题输入和输出之间计算效率高的映射。这些映射使优化和分析程序成为可能，从而保证了卓越的设计、巧妙的材料系统和优化的制造工艺。在此类建模工作中，一个常见的情况是存在多个数据源，每个数据源都因保真度、操作条件、实验条件等而有所区别。数据融合框架开启了将这些差异化来源组合成单一统一模型的可能性，从而提高了准确性和知识传递能力。然而，当不同来源本质上是异构的，即不共享相同的输入参数空间时，这些框架会遇到限制。当按复杂性、规模和保真度区分的域需要不同的参数化时，可能会出现这些异构输入场景。为了解决这一空白，提出了一种基于输入映射校准 (IMC) 和潜变量高斯过程 (LVGP) 的异构多源数据融合框架。在第一阶段，利用 IMC 算法将异构输入参数空间转换为统一的参考参数空间。在第二阶段，利用 LVGP 实现的多源数据融合模型在转换后的参考空间上构建单源感知代理模型。在三个工程案例研究（悬臂梁设计、椭圆空隙设计和 Ti6Al4V 合金建模特性）上演示和分析了所提出的框架。结果表明，所提出的框架比单源模型和转换但源不感知的模型提供了更高的预测精度。]]></description>
      <guid>https://arxiv.org/abs/2407.11268</guid>
      <pubDate>Wed, 17 Jul 2024 06:20:39 GMT</pubDate>
    </item>
    </channel>
</rss>