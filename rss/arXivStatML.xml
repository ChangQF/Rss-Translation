<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 29 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>Koopman 算子的非参数稀疏在线学习</title>
      <link>https://arxiv.org/abs/2501.16489</link>
      <description><![CDATA[arXiv:2501.16489v1 公告类型：新
摘要：Koopman 算子为表示一般非线性动态系统的动力学提供了一个强大的框架。用于学习 Koopman 算子的数据驱动技术通常假设所选函数空间在系统动力学下是封闭的。在本文中，我们通过 Koopman 算子对再生核希尔伯特空间 (RKHS) 的作用来研究它，并探索动态可能逃离所选函数空间的错误指定场景。我们将 Koopman 算子与条件均值嵌入 (CME) 算子联系起来，然后提出一种算子随机近似算法来迭代学习 Koopman 算子，并控制表示的复杂性。我们为基于轨迹的采样在线稀疏学习算法提供了渐近和有限时间的最后迭代保证，其分析比有限维随机近似的分析要复杂得多。数值算例验证了所提算法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.16489</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变分薛定谔动量扩散</title>
      <link>https://arxiv.org/abs/2501.16675</link>
      <description><![CDATA[arXiv:2501.16675v1 公告类型：新
摘要：动量薛定谔桥 (mSB) 已成为加速生成扩散过程和降低传输成本的主要方法。然而，缺乏无模拟属性不可避免地会导致高训练成本并影响可扩展性。为了在传输属性和可扩展性之间取得平衡，我们引入了变分薛定谔动量扩散 (VSMD)，它采用线性化前向得分函数（变分得分）来消除对模拟前向轨迹的依赖。我们的方法利用具有自适应传输优化变分得分的多元扩散过程。此外，我们应用临界阻尼变换来稳定训练，消除了对速度和样本得分估计的需要。从理论上讲，我们证明了使用最佳变分得分和动量扩散生成的样本的收敛性。实证结果表明，VSMD 能够有效生成各向异性形状，同时保持传输效率，优于过度阻尼替代方案，并避免复杂的去噪过程。我们的方法还可以有效地扩展到现实世界的数据，在时间序列和图像生成方面取得了有竞争力的结果。]]></description>
      <guid>https://arxiv.org/abs/2501.16675</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向多视角学习的泛化：信息论分析</title>
      <link>https://arxiv.org/abs/2501.16768</link>
      <description><![CDATA[arXiv:2501.16768v1 公告类型：新
摘要：多视图学习因其在利用跨视图共识和互补信息实现数据全面表示方面的有效性而受到广泛关注。虽然多视图学习经历了蓬勃发展并取得了显著的成功，但对其泛化行为的理论理解仍然难以捉摸。本文旨在通过开发多视图学习的信息理论泛化界限来弥合这一差距，特别关注多视图重建和分类任务。我们的界限强调了从多个不同视角捕获共识和互补信息以实现最大程度解开表示的重要性。这些结果还表明，应用多视图信息瓶颈正则化器有利于获得令人满意的泛化性能。此外，我们在留一法和超采样设置下推导出新的数据相关界限，从而产生计算可处理且更严格的界限。在插值机制中，我们进一步建立了多视图学习的快速率边界，与传统的平方根边界相比，其收敛速度更快。数值结果表明，在各种学习场景中，真正的泛化差距与导出的边界之间存在很强的相关性。]]></description>
      <guid>https://arxiv.org/abs/2501.16768</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>指数级的家庭关注</title>
      <link>https://arxiv.org/abs/2501.16790</link>
      <description><![CDATA[arXiv:2501.16790v1 公告类型：新
摘要：自注意力机制是大多数大型语言模型底层 Transformer 神经网络的支柱。它可以捕捉自然语言中复杂的词模式和长距离依赖关系。本文介绍了指数族注意力 (EFA)，这是一种概率生成模型，它扩展了自注意力以处理混合数据类型的高维序列、空间或时空数据，包括离散和连续观测。EFA 的关键思想是根据所有其他现有观测（称为上下文）对每个观测进行建模，其相关性是通过基于注意力的潜在因子模型以数据驱动的方式学习的。特别是，与静态潜在嵌入不同，EFA 使用自注意力机制来捕捉上下文中的动态交互，其中每个上下文观测的相关性取决于其他观测。我们建立了可识别性结果并为 EFA 提供了超额损失的泛化保证。在现实世界和合成数据集中（包括美国城市温度、Instacart 购物篮和 MovieLens 评级），我们发现 EFA 在捕捉复杂潜在结构和重建保留数据方面始终优于现有模型。]]></description>
      <guid>https://arxiv.org/abs/2501.16790</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型中的边际和条件重要性度量及其与条件平均治疗效果的关系</title>
      <link>https://arxiv.org/abs/2501.16988</link>
      <description><![CDATA[arXiv:2501.16988v1 公告类型：新
摘要：由于黑盒机器学习模型对数据的依赖性强且本质上是非参数性的，因此解释黑盒机器学习模型具有挑战性。本文通过“边际变量重要性度量”（MVIM）重新引入了重要性的概念，这是一种基于真实条件期望函数的预测因子重要性的模型无关度量。MVIM 评估预测因子对连续或离散结果的影响。受 \citet{breiman2001random} 和 \citet{fisher2019all} 的启发，提出了一种基于置换的估计方法来估计 MVIM。当预测因子高度相关时，MVIM 估计量是有偏差的，因为黑盒模型很难在低概率区域进行推断。为了解决这个问题，我们研究了 MVIM 的偏差方差分解，以了解高相关性下偏差的来源和模式。引入了改编自 \citet{strobl2008conditional} 的条件变量重要性度量 (CVIM) 来减少这种偏差。MVIM 和 CVIM 都与条件平均治疗效果 (CATE) 呈现二次关系。]]></description>
      <guid>https://arxiv.org/abs/2501.16988</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>版权与竞争：利用非结构化数据估计供需</title>
      <link>https://arxiv.org/abs/2501.16120</link>
      <description><![CDATA[arXiv:2501.16120v1 公告类型：交叉 
摘要：版权政策在保护创意产业创作者和公司的知识产权方面发挥着关键作用。这些行业中生成式人工智能等降低成本的技术的出现要求人们重新关注这些政策的作用。本文研究了创意差异化产品市场中的产品定位和竞争以及版权保护的竞争和福利效应。具有创意元素的产品的一个共同特征是它们的关键属性（例如图像和文本）是非结构化的，因此是高维的。我们专注于风格化的设计产品字体，并使用来自世界上最大的字体在线市场的数据。我们使用神经网络嵌入来量化非结构化属性并测量视觉相似性。我们表明，这种测量与实际的人类感知非常吻合。基于这一衡量标准，我们通过经验发现竞争发生在视觉特征空间的局部。然后，我们开发了一个集成嵌入的供需结构模型。通过反事实分析，我们发现，当产品转移时，本地版权保护可以提高消费者福利，而版权和降低成本技术之间的相互作用对于确定最佳社会福利政策至关重要。我们认为，本文介绍的嵌入分析和实证模型可以适用于非结构化数据捕捉产品和市场基本特征的一系列行业。]]></description>
      <guid>https://arxiv.org/abs/2501.16120</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过知识图谱、大型语言模型和不平衡学习改进网络威胁检测</title>
      <link>https://arxiv.org/abs/2501.16393</link>
      <description><![CDATA[arXiv:2501.16393v1 公告类型：交叉 
摘要：由于攻击活动的复杂性和可供学习的历史威胁数据的局限性，网络威胁检测一直具有挑战性。为了帮助增强使用分析、机器学习和人工智能方法检测网络威胁的现有实践，我们提出了一个集成建模框架，其中知识图谱用于分析用户的活动模式，不平衡学习技术用于修剪和权衡知识图谱，LLM 用于从知识图谱中检索和解释用户的活动。所提出的框架通过在线顺序学习应用于敏捷威胁检测。初步结果显示威胁捕获率提高了 3%-4%，并且基于用户活动的风险预测的可解释性得到了提高。]]></description>
      <guid>https://arxiv.org/abs/2501.16393</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有前向投影的封闭式无反馈学习</title>
      <link>https://arxiv.org/abs/2501.16476</link>
      <description><![CDATA[arXiv:2501.16476v1 公告类型：交叉 
摘要：用于无反向传播学习的最先进的方法采用局部误差反馈通过梯度下降来指导迭代优化。在这项研究中，我们研究了更严格的设置，其中神经元输出的逆向通信对于突触前权重优化是不可用的。为了应对这一挑战，我们提出了前向投影 (FP)。这种新颖的随机闭式训练方法只需要对整个数据集进行一次前向传递即可进行模型拟合，而无需逆向通信。通过对突触前输入和标签的非线性投影逐层生成激活前膜电位的目标值。使用闭式回归对突触前输入进行局部损失函数优化，而无需来自神经元输出或下游层的反馈。可解释性是 FP 训练的一个关键优势；FP 训练网络中隐藏神经元的膜电位编码的信息可逐层解释为标签预测。我们在四个生物医学数据集上证明了 FP 的有效性。在少量学习任务中，FP 产生的模型比通过反向传播优化的模型更具通用性。在大样本任务中，基于 FP 的模型实现了与基于梯度下降的局部学习方法相当的泛化，同时只需要一个前向传播步骤，从而显著加快了训练速度。基于 FP 的模型中在局部神经元活动上定义的解释函数成功地在两个生物医学数据集中识别出临床上显着的诊断特征。前向投影是一种计算效率高的机器学习方法，它可以产生可解释的神经网络模型，而无需在训练期间进行神经元活动的逆向通信。]]></description>
      <guid>https://arxiv.org/abs/2501.16476</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稳健语言模型的平滑嵌入</title>
      <link>https://arxiv.org/abs/2501.16497</link>
      <description><![CDATA[arXiv:2501.16497v1 公告类型：交叉 
摘要：提高大型语言模型 (LLM) 的安全性和可靠性是实现可信赖的 AI 系统的关键方面。尽管对齐方法旨在抑制有害内容的生成，但 LLM 通常仍然容易受到越狱攻击，这些攻击采用对抗性输入来破坏对齐并诱导有害输出。我们提出了随机嵌入平滑和标记聚合 (RESTA) 防御，它在嵌入向量中添加随机噪声并在生成每个输出标记期间执行聚合，目的是更好地保留语义信息。我们的实验表明，与基线防御相比，我们的方法实现了卓越的稳健性与效用权衡。]]></description>
      <guid>https://arxiv.org/abs/2501.16497</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于一类学习问题中最优学习轨迹的表征</title>
      <link>https://arxiv.org/abs/2501.16521</link>
      <description><![CDATA[arXiv:2501.16521v1 公告类型：交叉 
摘要：在这篇简短的论文中，我们提供了一个数学框架，利用最大原理和动态规划之间的关系来表征一类学习问题中的最佳学习轨迹，这与高维非线性函数建模的点估计有关。在这里，这种对最佳学习轨迹的表征与具有小参数的弱控制梯度系统的最优控制问题的解决有关，其时间演化由模型训练数据集及其扰动版本引导，而优化问题由成本函数组成，该函数总结了如何衡量相对于模型验证数据集在某个固定最终时间估计的模型参数的质量/性能。此外，使用连续 Galerkin 近似法，我们提供了一种算法方案，如何构建相应的最佳学习轨迹，从而为这类学习问题获得最佳估计的模型参数。]]></description>
      <guid>https://arxiv.org/abs/2501.16521</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>随机环境中分支过程的祖先推理和学习</title>
      <link>https://arxiv.org/abs/2501.16526</link>
      <description><![CDATA[arXiv:2501.16526v1 公告类型：交叉 
摘要：随机环境中分支过程的祖先推断涉及使用后代的种群大小确定祖先分布参数。在本文中，我们介绍了一种利用广义矩法进行祖先推断的新方法。我们证明估计量的行为受到环境序列变异系数的严重影响。此外，尽管该过程的演变在很大程度上取决于各代后代的均值，但我们表明，在适当的中心化和缩放下，祖先和后代均值的估计量的联合限制分布在代数与重复次数对数的比率收敛到零时解耦并收敛到独立的高斯随机变量。此外，我们提供了极限方差的估计量，并通过数值实验和来自聚合酶链反应实验和 COVID-19 数据的数据说明了我们的发现。]]></description>
      <guid>https://arxiv.org/abs/2501.16526</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有制度转换市场动态的探索性均值-方差投资组合优化</title>
      <link>https://arxiv.org/abs/2501.16659</link>
      <description><![CDATA[arXiv:2501.16659v1 公告类型：交叉 
摘要：考虑到连续时间均值-方差 (MV) 投资组合优化问题，我们研究了制度转换市场环境并应用强化学习 (RL) 技术来协助在控制空间内进行明智的探索。我们引入并解决了带有制度转换的探索性均值方差 (EMVRS) 问题。我们还提出了一个策略改进定理。此外，我们认识到广泛应用的时间差分 (TD) 学习不适合 EMVRS 环境，因此我们考虑正交条件 (OC) 学习，利用从解析解到 EMVRS 诱导的最优值函数的鞅性质。我们设计了一种使用市场参数进行更有意义的参数化的 RL 算法，并为每个参数提出了一个更新方案。我们的实证结果表明，OC 学习优于 TD 学习，在模拟市场场景中，市场参数明显收敛到其相应的“基本真实”值。在一项真实的市场数据研究中，采用 OC 学习的 EMVRS 表现优于其他同类产品，年化投资组合回报率平均值最高，波动性也相当低。]]></description>
      <guid>https://arxiv.org/abs/2501.16659</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高维扩散的一致支持恢复</title>
      <link>https://arxiv.org/abs/2501.16703</link>
      <description><![CDATA[arXiv:2501.16703v1 公告类型：交叉 
摘要：由于在不同领域的应用，随机过程的统计推断取得了显着进展，但在高维设置中仍然存在挑战，其中参数允许随样本大小增长。本文分析了稀疏性约束下的 d 维遍历扩散过程，重点研究了自适应 Lasso 估计量，它比标准 Lasso 改进了变量选择和偏差。我们推导了自适应 Lasso 实现支持恢复属性和漂移参数渐近正态性的条件，重点是线性模型。显式参数关系指导调整以获得最佳性能，并在部分正交性假设下为 p&gt;&gt;d 场景提出了边际估计量。数值研究证实了自适应 Lasso 在准确性和支持恢复方面优于标准 Lasso 和 MLE，为高维随机过程提供了稳健的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2501.16703</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提高板材树的有效前沿</title>
      <link>https://arxiv.org/abs/2501.16730</link>
      <description><![CDATA[arXiv:2501.16730v1 公告类型：交叉 
摘要：我们引入了一类新的基于树的模型，P-Trees，用于分析（不平衡）单个资产收益面板，通过经济指导和可解释性来推广高维排序。在均值方差有效框架下，P-Trees 构建的测试资产与常用测试资产相比，显著提高了有效前沿，基准定价模型无法解释 alpha。P-Tree 切线投资组合还构成交易因子，恢复定价核，并在投资和横截面定价方面优于流行的可观察和潜在因子模型。最后，P-Trees 以稀疏性捕获资产收益的复杂性，实现样本外夏普比率，接近仅由过度参数化的大型模型实现的比率。]]></description>
      <guid>https://arxiv.org/abs/2501.16730</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于估计异方差随机变量共同均值的经验中位数</title>
      <link>https://arxiv.org/abs/2501.16956</link>
      <description><![CDATA[arXiv:2501.16956v1 公告类型：交叉 
摘要：我们研究异方差设置中的均值估计问题。特别是，我们考虑具有相同位置参数和不同且未知尺度参数的对称随机变量。我们的目标是估计它们未知的共同位置参数。这是一个基本主题，但研究得还不够深入，因为我们总是假设随机变量是独立且同分布的。在本文中，我们研究了中位数估计量，并建立了其估计误差的上限和下限，这些上限和下限是同阶的，并且推广和改进了 Devroye 等人和 Xia 的最新结果。]]></description>
      <guid>https://arxiv.org/abs/2501.16956</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>