<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 12 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>得分最优扩散计划</title>
      <link>https://arxiv.org/abs/2412.07877</link>
      <description><![CDATA[arXiv:2412.07877v1 公告类型：新
摘要：去噪扩散模型 (DDM) 为从高维数据分布中采样提供了一个灵活的框架。DDM 通过逐步向数据中注入噪声来生成在参考高斯分布和数据分布之间插值的概率分布路径。为了对采样过程进行数值模拟，必须选择从参考数据返回到干净数据的离散化计划。合适的离散化计划对于获得高质量样本至关重要。然而，除了手工制作的启发式方法之外，选择此计划的通用方法仍然难以捉摸。本文提出了一种新算法，用于根据我们得出的成本自适应地选择最佳离散化计划。我们的成本衡量模拟过程将样本从扩散路径中的一个点传输到下一个点所做的​​工作。我们的方法不需要超参数调整，并且可以适应扩散路径的动态和几何形状。我们的算法仅涉及估计的 Stein 分数的评估，使其在推理时可扩展到现有的预训练模型，并在训练期间在线使用。我们发现，我们学习到的时间表恢复了以前只能通过手动搜索发现的高性能时间表，并在图像数据集上获得了有竞争力的 FID 分数。]]></description>
      <guid>https://arxiv.org/abs/2412.07877</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量化 LLM 的低秩校正</title>
      <link>https://arxiv.org/abs/2412.07902</link>
      <description><![CDATA[arXiv:2412.07902v1 公告类型：新
摘要：我们考虑了大型语言模型 (LLM) 在训练后阶段的模型压缩问题，其任务是仅使用一小组校准输入数据来压缩训练良好的模型。在这项工作中，我们引入了一种新的低秩方法来纠正 LLM 中 \emph{激活} 的量化误差：我们建议以全精度添加作用于 \emph{未量化} 激活的低秩权重矩阵。然后，我们针对权重的量化表示和额外的低秩权重矩阵解决联合优化问题，以量化权重和激活。我们专注于 4 位权重和激活量化 (W4A4) 的情况。使用相当于原始权重矩阵大小 10\% 的秩，我们的方法将与原始模型的准确度差距缩小了 50\% 以上。使用相当于原始权重矩阵 30% 的等级，准确率差距完全消失。我们在四个最近的 LLM 上展示了我们的结果，即 Llama-2、Llama-3、Phi-3 和 Mixtral 模型。]]></description>
      <guid>https://arxiv.org/abs/2412.07902</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有对抗性约束的在线凸优化的乐观算法</title>
      <link>https://arxiv.org/abs/2412.08060</link>
      <description><![CDATA[arXiv:2412.08060v1 公告类型：新
摘要：我们研究具有对抗性约束的在线凸优化 (OCO)，其中在线算法必须做出重复决策以最小化凸损失函数和累积约束违规。我们专注于算法可以访问损失和约束函数的预测的设置。我们的结果表明，我们可以将当前最佳界限 $ O(\sqrt{T}) $ 遗憾和 $ \tilde{O}(\sqrt{T}) $ 累积约束违规分别改进为 $ O(\sqrt{E_T(f)}) $ 和 $ \tilde{O}(\sqrt{E_T(g)}) $，其中 $ E_T(f) $ 和 $ E_T(g) $ 表示损失和约束函数的累积预测误差。在最坏的情况下，$ E_T(f) = O(T) $ 和 $ E_T(g) = O(T) $（假设损失和约束函数有界），我们的比率与之前的 $ O(\sqrt{T}) $ 结果相匹配。但是，当损失和约束预测准确时，我们的方法会产生明显较小的遗憾和累积约束违规。值得注意的是，如果约束函数随时间保持不变，我们将实现 $ \tilde{O}(1) $ 累积约束违规，与之前的结果一致。]]></description>
      <guid>https://arxiv.org/abs/2412.08060</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高维时间序列的谱差分网络分析</title>
      <link>https://arxiv.org/abs/2412.07905</link>
      <description><![CDATA[arXiv:2412.07905v1 公告类型：交叉 
摘要：从多变量时间序列数据得出的频谱网络出现在从脑科学到地球科学的许多领域。通常，研究这些网络在不同条件下如何变化是很有趣的。例如，为了更好地了解癫痫，使用脑电图数据捕捉患者癫痫发作时大脑连接网络的变化会很有趣。一种常见的方法依赖于估计每种情况下的网络并计算它们的差异。这种估计在高维度下可能表现不佳，因为网络本身的结构可能不稀疏，而它们的差异可能稀疏。我们基于这一观察结果开发了两种条件下逆谱密度差异的估计量。对差异使用 L1 惩罚，仅要求差异稀疏即可建立一致性。我们在合成数据实验、脑电图数据实验以及光致刺激和微皮层电图数据实验中说明了该方法。]]></description>
      <guid>https://arxiv.org/abs/2412.07905</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>相位感知训练计划简化了基于流的生成模型的学习</title>
      <link>https://arxiv.org/abs/2412.07972</link>
      <description><![CDATA[arXiv:2412.07972v1 公告类型：交叉 
摘要：我们分析了用于参数化基于流的生成模型的两层自动编码器的训练，该模型用于从高维高斯混合中进行采样。先前的研究表明，在没有适当的时间安排的情况下，随着维度趋于无穷大，学习模式之间的相对概率的阶段会消失。我们引入了解决这个问题的时间膨胀。这使我们能够表征学习到的速度场，找到学习每种模式的概率的第一阶段和学习每种模式的方差的第二阶段。我们发现，表示速度场的自动编码器通过仅估计与每个阶段相关的参数来学习简化。转向真实数据，我们提出了一种方法，对于给定的特征，找到训练可以最大程度地提高该特征的准确性的时间间隔。由于从业者在训练时间上采取均匀分布，因此我们的方法可以提高训练效率。我们提供了验证这种方法的初步实验。]]></description>
      <guid>https://arxiv.org/abs/2412.07972</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高维矩阵值数据的假设检验</title>
      <link>https://arxiv.org/abs/2412.07987</link>
      <description><![CDATA[arXiv:2412.07987v1 公告类型：交叉 
摘要：本文讨论了高维设置中矩阵值数据均值的假设检验。我们研究了 Cragg (1997) 最初提出的最小差异检验，它可作为低维矩阵的秩检验。我们评估了矩阵维数与样本大小成比例增加时此检验的性能，并确定了矩阵维数显著超过样本大小时的局限性。为了应对这些挑战，我们提出了一种针对高维矩阵秩检验量身定制的新检验统计量。分析了此统计量的 oracle 版本以突出其理论特性。此外，我们开发了一种用于构建奇异向量稀疏奇异值分解 (SVD) 估计量的新方法，全面检查了其理论方面。使用稀疏 SVD 估计量，我们探索了我们提出的统计量的样本版本的属性。本文最后进行了模拟研究和两个涉及监控视频数据的案例研究，证明了我们提出的方法的实用性。]]></description>
      <guid>https://arxiv.org/abs/2412.07987</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数据增强算法的快速混合：贝叶斯概率模型、Logit 模型和套索回归</title>
      <link>https://arxiv.org/abs/2412.07999</link>
      <description><![CDATA[arXiv:2412.07999v1 公告类型：交叉 
摘要：尽管数据增强 (DA) 算法被广泛使用，但对其收敛行为的理论理解仍然不完整。我们证明了三种重要 DA 算法的混合时间的第一个非渐近多项式上界：贝叶斯 Probit 回归的 DA 算法（Albert and Chib，1993，ProbitDA）、贝叶斯 Logit 回归（Polson、Scott 和 Windle，2013，LogitDA）和贝叶斯 Lasso 回归（Park and Casella，2008，Rajaratnam 等，2015，LassoDA）。具体来说，我们证明，在 $\eta$-热启动、参数维度 $d$ 和样本大小 $n$ 的情况下，ProbitDA 和 LogitDA 需要 $\mathcal{O}\left(nd\log \left(\frac{\log \eta}{\epsilon}\right)\right)$ 步才能获得最多具有 $\epsilon$ TV 误差的样本，而 LassoDA 需要 $\mathcal{O}\left(d^2(d\log d +n \log n)^2 \log \left(\frac{\eta}{\epsilon}\right)\right)$ 步。结果通常适用于具有较大 $n$ 和较大 $d$ 的设置，包括 Probit 和 Logit 回归中响应数据高度不平衡的设置。证明基于马尔可夫链电导和等周不等式。假设数据独立地从有界、亚高斯或对数凹分布生成，我们将 ProbitDA 和 LogitDA 的保证以高概率提高到 $\tilde{\mathcal{O}}(n+d)$，并将其与朗之万蒙特卡罗和 Metropolis 调整朗之万算法的最佳已知保证进行比较。我们还讨论了可行初始化下这三种算法的混合时间。]]></description>
      <guid>https://arxiv.org/abs/2412.07999</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>骰子与游戏：广义增强理论</title>
      <link>https://arxiv.org/abs/2412.08012</link>
      <description><![CDATA[arXiv:2412.08012v1 公告类型：交叉 
摘要：成本敏感损失函数在许多现实世界的预测问题中至关重要，其中不同类型的错误受到不同的惩罚；例如，在医学诊断中，假阴性预测可能导致比假阳性预测更糟糕的后果。然而，传统的 PAC 学习理论主要集中在对称 0-1 损失上，而成本敏感损失基本上没有得到解决。在这项工作中，我们扩展了著名的提升理论，以结合成本敏感和多目标损失。成本敏感损失将成本分配给混淆矩阵的条目，并用于控制考虑每种错误类型成本的预测误差总和。另一方面，多目标损失同时跟踪多个成本敏感损失，并且在目标是同时满足多个标准时很有用（例如，最小化假阳性，同时将假阴性保持在临界阈值以下）。我们开发了成本敏感和多目标增强的综合理论，提供了弱学习保证的分类，以区分哪些保证是微不足道的（即总能实现），哪些保证是可增强的（即意味着强学习），哪些保证是中等的，意味着非微不足道但不是任意准确的学习。对于二元分类，我们建立了二分法：弱学习保证要么是微不足道的，要么是可增强的。在多类设置中，我们描述了中间弱学习保证的更复杂格局。我们的表征依赖于增强的几何解释，揭示了成本敏感损失和多目标损失之间令人惊讶的等价性。]]></description>
      <guid>https://arxiv.org/abs/2412.08012</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GLL：神经网络的可微分图学习层</title>
      <link>https://arxiv.org/abs/2412.08016</link>
      <description><![CDATA[arXiv:2412.08016v1 公告类型：交叉 
摘要：用于分类的标准深度学习架构使用投影头和 softmax 激活函数生成标签预测。尽管这些方法很成功，但它们未能利用批次中样本之间的关系信息来生成标签预测。在最近的研究中，基于图的学​​习技术（即拉普拉斯学习）已启发式地与神经网络相结合，用于监督和半监督学习 (SSL) 任务。然而，先前的研究近似了损失函数相对于图学习算法的梯度或将过程解耦；无法实现与神经网络的端到端集成。在这项工作中，我们通过伴随方法推导出反向传播方程，以将一般的图学习层系列纳入神经网络。这使我们能够将基于图拉普拉斯算子的标签传播精确地集成到神经网络层中，从而取代分类任务中的投影头和 softmax 激活函数。使用这个新框架，与基于 softmax 的标准方法相比，我们的实验结果表明，跨数据的标签转换更加平滑，对对抗攻击的鲁棒性得到提高，泛化能力得到提高，训练动态得到改善。]]></description>
      <guid>https://arxiv.org/abs/2412.08016</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稳定边缘条件下参数化线性回归的准则与偏差</title>
      <link>https://arxiv.org/abs/2412.08025</link>
      <description><![CDATA[arXiv:2412.08025v1 公告类型：交叉 
摘要：经典优化理论要求基于梯度的方法使用较小的步长才能收敛。然而，最近的研究结果挑战了传统思想，通过经验证明即使步长 $\eta$ 超过阈值 $2/L$，梯度下降 (GD) 也会收敛，其中 $L$ 是全局平滑常数。这通常被称为稳定边缘 (EoS) 现象。人们普遍认为，具有次二次增长的目标函数在产生 EoS 方面起着重要作用。在本文中，我们通过考虑为损失函数为 $l(\cdot)$ 的回归寻找线性插值器 $\beta \in R^{d}$ 的任务来提供更全面的答案，其中 $\beta$ 允许参数化为 $\beta = w^2_{+} - w^2_{-}$。与之前的研究相反，该研究认为次二次 $l$ 是 EoS 的必要条件，而我们的新发现表明，在适当条件下，即使 $l$ 是二次函数，EoS 也会出现。经验和理论证据都证明了这一论证的严谨性，表明 GD 轨迹以非渐近方式收敛到线性插值器。此外，在 EoS 机制下，二次 $l$ 下的模型（也称为深度 2 对角线性网络）仍未得到充分探索。我们的分析为采用较大步长时对角线性网络的隐性偏差提供了一些新的见解，丰富了对更实际模型上 EoS 的理解。]]></description>
      <guid>https://arxiv.org/abs/2412.08025</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有向网络和二分网络的双向节点流行度模型</title>
      <link>https://arxiv.org/abs/2412.08051</link>
      <description><![CDATA[arXiv:2412.08051v1 公告类型：交叉 
摘要：在有向和二分网络中，社区检测已经得到了广泛的研究。然而，这些研究往往没有考虑到不同社区中节点的流行度，这是现实世界网络中的常见现象。为了解决这个问题，我们提出了一个新的概率框架，称为双向节点流行度模型 (TNPM)。TNPM 还可以容纳一般亚高斯家族中不同分布的边。我们引入了删除一方法 (DOM) 用于模型拟合和社区结构识别，并提供了全面的理论分析和处理亚高斯泛化的新技术技能。此外，我们提出了两阶段分割余弦算法 (TSDC) 来更有效地处理大规模网络。我们提出的方法在估计精度和计算效率方面具有多重优势，这通过广泛的数值研究得到了证明。我们将我们的方法应用于两个现实世界的应用，发现了有趣的发现。]]></description>
      <guid>https://arxiv.org/abs/2412.08051</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CANDOR：反事实注释双重稳健离策略评估</title>
      <link>https://arxiv.org/abs/2412.08052</link>
      <description><![CDATA[arXiv:2412.08052v1 公告类型：交叉 
摘要：离策略评估 (OPE) 通过在部署之前估计策略的性能来提供安全保障。最近的研究引入了 IS+，这是一种重要性抽样 (IS) 估计器，它使用专家注释的反事实样本来提高行为数据集覆盖率。然而，众所周知，IS 估计器具有高方差；此外，当注释不完善时，IS+ 的性能会下降。在这项工作中，我们提出了一组受双重稳健 (DR) 原理启发的 OPE 估计器。DR 估计器将 IS 与奖励模型估计（称为直接方法 (DM)）相结合，并提供有利的统计保证。我们提出了三种将反事实注释纳入 DR 启发式估计器的策略，并在各种现实设置下分析了它们的属性。我们证明，在估计器的 DM 部分使用不完善的注释可以最好地利用注释，而不是在 IS 部分使用它们。为了支持我们的理论发现，我们在三个情境老虎机环境中评估了所提出的估计器。我们的实证结果表明，当奖励模型指定错误且注释不完善时，仅在 DR 估计器的 DM 部分中使用注释是最有利的。基于这些理论和实证见解，我们提供了在不同的现实环境中使用反事实注释的实用指南。]]></description>
      <guid>https://arxiv.org/abs/2412.08052</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一般分布间最优传输图估计的统计收敛速度</title>
      <link>https://arxiv.org/abs/2412.08064</link>
      <description><![CDATA[arXiv:2412.08064v1 公告类型：交叉 
摘要：本文研究了最优传输 (OT) 映射估计量的收敛速度，这是统计学、机器学习和各个科学领域越来越受关注的一个主题。尽管最近取得了进展，但现有的结果依赖于在实践中非常严格的规律性假设，并且比 Brenier 定理中的假设严格得多，包括概率支持的紧性和凸性以及 OT 映射的双 Lipschitz 属性。我们的目标是拓宽 OT 映射估计的范围并填补理论与实践之间的这一空白。鉴于对 Brenier 势的强凸性假设，我们首先建立原始插件估计量的非渐近收敛速度，而无需对概率测度做出限制性假设。此外，我们引入了一个筛插入估计量，并建立了它的收敛速度，而无需对 Brenier 势进行强凸性假设，从而可以实现正态或 t 分布的秩函数等广泛使用的情况。我们还建立了新的庞加莱型不等式，这些不等式是在概率密度局部有界性和支撑的温和拓扑条件的充分条件下证明的，这些新的不等式使我们能够实现 Donsker 函数类的更快收敛速度​​。此外，我们开发了可扩展算法，使用神经网络有效地解决 OT 映射估计问题，并进行了数值实验以证明其有效性和鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2412.08064</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用辅助替代标签对潜在疾病进展进行动态分类</title>
      <link>https://arxiv.org/abs/2412.08088</link>
      <description><![CDATA[arXiv:2412.08088v1 公告类型：交叉 
摘要：当由于诊断能力或高成本而无法知道真实疾病状态时，基于患者不断变化的健康信息进行疾病进展预测具有挑战性。例如，缺乏黄金标准的神经诊断阻碍了区分阿尔茨海默病 (AD) 与相关疾病，如 AD 相关痴呆症 (ADRD)，包括路易体痴呆症 (LBD)。结合时间依赖的替代标签和健康标记可能会改善疾病预测。然而，现有文献使用纯生成方法对反映基础状态的信息替代标签和观察变量进行建模，限制了预测未来状态的能力。我们建议将传统的隐马尔可夫模型作为生成模型与时变判别分类模型相结合，以同时处理可能错误指定的替代标签并纳入疾病进展的重要标记。我们开发了一种自适应前向后向算法，使用主观标签进行估计，并利用改进的后验和维特比算法仅基于客观标记来预测未来状态或新患者的进展。重要的是，这种调整消除了对纵向标记的边际分布进行建模的需要，这是传统算法中的一项要求。建立了渐近性质，并通过模拟研究证明了有限样本的显著改进。对国家阿尔茨海默病协调中心 (NACC) 的神经病理学数据集的分析表明，区分 LBD 和 AD 的准确性大大提高。]]></description>
      <guid>https://arxiv.org/abs/2412.08088</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>时间序列中潜在非线性动力系统的建模</title>
      <link>https://arxiv.org/abs/2412.08114</link>
      <description><![CDATA[arXiv:2412.08114v2 公告类型：交叉 
摘要：我们研究了给定时间序列时通过直接从数据中推导出方程来建模非线性动力系统的问题。尽管时间序列数据是作为输入给出的，但现有研究中基本上没有包含长期时间依赖性的动态模型和估计算法。在本文中，我们引入了一个潜在状态以允许时间相关建模，并将该问题表述为潜在状态下的动态估计问题。我们面临多项技术挑战，包括 (1) 建模潜在非线性动态和 (2) 解决由潜在状态的存在引起的循环依赖关系。为了解决这些具有挑战性的问题，我们提出了一种新方法，即潜在非线性方程建模 (LaNoLem)，它可以建模潜在非线性动力系统和一种新颖的交替最小化算法，用于有效估计潜在状态和模型参数。此外，我们引入了无需人工干预即可控制模型复杂性的标准。与最先进的模型相比，LaNoLem 在估计动态方面取得了具有竞争力的性能，同时在预测方面优于其他方法。]]></description>
      <guid>https://arxiv.org/abs/2412.08114</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>