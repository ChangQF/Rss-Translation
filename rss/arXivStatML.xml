<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 15 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>MVG-CRPS：多元概率预测的稳健损失函数</title>
      <link>https://arxiv.org/abs/2410.09133</link>
      <description><![CDATA[arXiv:2410.09133v1 公告类型：新
摘要：在概率时间序列预测中，多元高斯 (MVG) 分布被广泛用作相关连续随机变量的预测分布。当前的深度概率模型通常采用神经网络来参数化分布的均值向量和协方差矩阵，以对数得分（即负对数似然）作为默认损失函数。然而，对数得分对异常值高度敏感，当数据中存在异常时会导致严重错误。受连续排序概率得分 (CRPS) 在学习单变量分布中的使用启发，我们提出了一种专为高维 MVG 输出设计的稳健损失函数。所提出的 MVG-CRPS 损失函数具有基于神经网络输出的闭式表达式，使其易于集成到深度学习模型中。我们在两个概率预测任务（多元自回归和单变量序列到序列 (Seq2Seq) 预测）上评估了 MVG-CRPS，这两项任务都涉及遵循 MVG 分布的观测值。在真实数据集上的实验结果表明，MVG-CRPS 兼具稳健性和效率，在概率预测中提供了更高的准确性和不确定性量化。]]></description>
      <guid>https://arxiv.org/abs/2410.09133</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>带噪声 SGD 的线性回归数据删除</title>
      <link>https://arxiv.org/abs/2410.09311</link>
      <description><![CDATA[arXiv:2410.09311v1 公告类型：新
摘要：在当今大数据和机器学习时代，找到缩小训练数据集大小的方法，同时保持训练性能以提高效率至关重要。然而，这背后的挑战包括提供实用的方法来找到可以删除的点，而不会显著损害训练结果并遭受诸如欠拟合之类的问题。因此，我们提出了经典线性回归任务中 1 步噪声 SGD 的完美删除点问题，旨在找到训练数据集中的完美删除点，使得从删除的数据集得到的模型与未删除数据集训练的模型相同。我们应用所谓的信噪比，并表明其值与完美删除点的选择密切相关。我们还基于此实现了一种算法，并通过经验证明了它在合成数据集中的有效性。最后，我们分析了完美删除点的后果，特别是它如何影响训练性能和隐私预算，从而突出了它的潜力。这项研究强调了数据删除的重要性，并呼吁迫切需要在该领域开展更多研究。]]></description>
      <guid>https://arxiv.org/abs/2410.09311</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>判定系数的组合优化</title>
      <link>https://arxiv.org/abs/2410.09316</link>
      <description><![CDATA[arXiv:2410.09316v1 公告类型：新
摘要：稳健相关性分析是统计学中最关键的挑战之一。在此，我们开发了一种有效的算法，用于选择平面中具有最高判定系数 $\left( R^2 \right)$ 的 $n$ 个点的 $k$ 个子集。借鉴组合几何，我们提出了一种称为 \textit{二次扫描} 的方法，该方法包括两个步骤：(i) 将数据点投影提升到 $\mathbb R^5$，然后 (ii) 迭代每个线性可分的 $k$ 个子集。其基础是最优异常值集可通过圆锥曲线与其在 $\mathbb R^2$ 中的补集分离，在 $\mathbb R^5$ 中，可通过拓扑扫描在 $\Theta \left( n^5 \log n \right)$ 时间内找到。尽管二次可分性的关键证明仍在进行中，但我们为我们的猜想开发了强大的数学直觉，然后通过实验证明了我们的方法在数百万次试验（最高 n=30）中的最优性，并且没有错误。Julia 中的实现和完全种子化的可重复实验可在 https://github.com/marc-harary/QuadraticSweep 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.09316</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非因果图模型的识别</title>
      <link>https://arxiv.org/abs/2410.09480</link>
      <description><![CDATA[arXiv:2410.09480v1 公告类型：新
摘要：本文考虑估计非因果图模型的问题，该模型的边缘编码了变量之间的平滑关系。我们提出了一个新的协方差扩展问题，并表明最小化白噪声过程的传输距离的解是一个双面自回归非因果图模型。然后，我们将该范式推广到一类图形自回归移动平均模型。最后，我们通过一些数值实验测试了所提出方法的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.09480</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>古德哈特定律及其在价值一致性中的应用</title>
      <link>https://arxiv.org/abs/2410.09638</link>
      <description><![CDATA[arXiv:2410.09638v1 公告类型：新
摘要：“当一个指标成为目标时，它就不再是一个好的指标”，这句格言被称为{\it 古德哈特定律}。在本文中，我们正式研究了这一定律，并证明它主要取决于真实目标与优化指标之间差异的尾部分布。具有长尾分布的差异有利于古德哈特定律，即指标的优化会对目标产生反作用。
我们通过研究指标优化时目标与指标之间相关性的渐近行为，提供了一个评估古德哈特定律的正式环境。此外，我们引入了{\it 弱}古德哈特定律和{\it 强}古德哈特定律之间的区别，前者指过度优化指标对真实目标无用，后者指过度优化指标对真实目标有害。我们证明这种区别取决于尾部分布。
我们强调这一结果对大规模决策和基于（并且必须基于）指标的政策的影响，并提出了许多研究方向，以更好地评估此类政策的安全性，以及这些政策通过算法自动化的特别令人担忧的情况。]]></description>
      <guid>https://arxiv.org/abs/2410.09638</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>朗之万动力学的几何调和的可证明收敛性和局限性</title>
      <link>https://arxiv.org/abs/2410.09697</link>
      <description><![CDATA[arXiv:2410.09697v1 公告类型：新
摘要：几何调和是一种从具有挑战性的多模态概率分布中抽样的流行方法，它通过从一系列分布中抽样，这些分布使用几何平均值在更简单的提议分布和目标分布之间进行插值。在本文中，我们从理论上研究了当采样算法是朗之万动力学时这种方法的合理性，证明了上限和下限。我们的上限是文献中在函数不等式下的首次分析。它们断言了调和朗之万在连续和离散时间内的收敛，并且它们的最小化导致某些提议和目标分布对的闭式最优调和计划。我们的下限展示了一个几何调和需要指数时间的简单情况，并进一步揭示了几何调和可能会受到函数不等式较差和收敛缓慢的影响，即使目标分布条件良好。总的来说，我们的结果表明几何调和可能没有帮助，甚至可能对收敛有害。]]></description>
      <guid>https://arxiv.org/abs/2410.09697</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 作为游戏玩家：预训练模型可证明的情境游戏能力</title>
      <link>https://arxiv.org/abs/2410.09701</link>
      <description><![CDATA[arXiv:2410.09701v1 公告类型：新
摘要：近年来，基于 Transformer 架构的预训练模型的上下文学习 (ICL) 能力受到越来越多的关注。虽然已经获得了对强化学习 (RL) 中 ICL 的理论理解，但之前的结果主要局限于单智能体设置。这项工作提出进一步探索预训练 Transformer 模型在竞争性多智能体游戏即上下文游戏 (ICGP) 中的上下文学习能力。专注于经典的双人零和游戏，提供理论保证以证明预训练的 Transformer 可以证明以上下文方式学习近似纳什均衡，适用于分散和集中学习设置。作为证明的关键部分，建立了构造结果以证明 Transformer 架构足够丰富，可以实现著名的多智能体游戏算法，特别是分散 V 学习和集中 VI-ULCB。]]></description>
      <guid>https://arxiv.org/abs/2410.09701</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>带中点引导的变分扩散后验采样</title>
      <link>https://arxiv.org/abs/2410.09945</link>
      <description><![CDATA[arXiv:2410.09945v1 公告类型：新
摘要：扩散模型最近在用作先验时显示出解决贝叶斯逆问题的巨大潜力。然而，从由此产生的去噪后验分布中进行采样仍然是一个挑战，因为它涉及难以处理的项。为了解决这个问题，最先进的方法将问题表述为从针对后验的替代扩散模型中采样并将其分数分解为两个项：先验分数和难以处理的指导项。虽然前者被考虑的扩散模型的预训练分数取代，但指导项必须估计。在本文中，我们提出了一种利用转换分解的新方法，与以前的方法相比，它允许在难以处理的指导项的复杂性和先验转换的复杂性之间进行权衡。我们通过对线性和非线性逆问题进行大量实验来验证所提出的方法，包括以潜在扩散模型为先验的具有挑战性的情况，并证明了其在从部分测量重建心电图（ECG）以进行准确心脏诊断的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.09945</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>梯度跨度算法在高维中取得可预测的进展</title>
      <link>https://arxiv.org/abs/2410.09973</link>
      <description><![CDATA[arXiv:2410.09973v1 公告类型：新
摘要：我们证明，当维度趋于无穷大时，所有“梯度跨度算法”在缩放的高斯随机函数上都具有渐近确定性行为。特别是，这个结果解释了一个违反直觉的现象，即尽管在复杂的非凸景观上进行了随机初始化，但许多大型机器学习模型的不同训练运行仍会导致大致相等的成本曲线。
我们使用的（非平稳）各向同性高斯随机函数的分布假设足够通用，可以作为机器学习训练的现实模型，但也包括自旋玻璃和随机二次函数。]]></description>
      <guid>https://arxiv.org/abs/2410.09973</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于因果效应估计的 DAG 感知 Transformer</title>
      <link>https://arxiv.org/abs/2410.10044</link>
      <description><![CDATA[arXiv:2410.10044v1 公告类型：新
摘要：因果推理是医疗保健、经济学和社会科学等领域的一项关键任务。虽然机器学习的最新进展，尤其是基于深度学习架构的进展，在估计因果关系方面显示出潜力，但现有方法往往无法处理复杂的因果结构，并且缺乏对各种因果场景的适应性。在本文中，我们提出了一种基于变压器的新型因果推理方法来克服这些挑战。我们模型的核心创新在于将因果有向无环图 (DAG) 直接集成到注意力机制中，使其能够准确地模拟底层因果结构。这允许灵活地估计平均治疗效果 (ATE) 和条件平均治疗效果 (CATE)。在合成和真实世界数据集上进行的大量实验表明，我们的方法在估计各种场景中的因果关系方面超越了现有方法。我们模型的灵活性和稳健性使其成为解决复杂因果推理问题的研究人员和从业人员的宝贵工具。]]></description>
      <guid>https://arxiv.org/abs/2410.10044</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>fastHDMI：高维数据的快速互信息估计</title>
      <link>https://arxiv.org/abs/2410.10082</link>
      <description><![CDATA[arXiv:2410.10082v1 公告类型：新
摘要：在本文中，我们介绍了 fastHDMI，这是一个 Python 包，旨在在高维数据集（尤其是神经影像数据）中进行有效的变量筛选。这项工作开创了三种互信息估计方法在神经影像变量选择中的应用，这是一种通过 fastHDMI 实现的新方法。这些进步增强了我们分析神经影像数据集复杂结构的能力，为高维空间中的变量选择提供了改进的工具。
使用预处理的 ABIDE 数据集，我们通过大量模拟评估这些方法的性能。测试涵盖了一系列条件，包括线性和非线性关联，以及连续和二元结果。我们的结果突出了基于 FFTKDE 的互信息估计在连续非线性结果中的特征筛选方面的优越性，而基于分箱的方法在具有非线性概率原像的二元结果方面优于其他方法。对于线性模拟，Pearson 相关性和基于 FFTKDE 的方法在连续结果方面都表现出了相当的性能，而 Pearson 在具有线性概率原像的二元结果方面表现出色。
使用 ABIDE 数据集的综合案例研究进一步证明了 fastHDMI 的实用性，展示了使用我们的筛选技术选择的变量构建的模型的预测能力。这项研究肯定了 fastHDMI 的计算效率和方法论优势，大大丰富了可用于神经影像分析的工具包。]]></description>
      <guid>https://arxiv.org/abs/2410.10082</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有偏好反馈的排队匹配老虎机</title>
      <link>https://arxiv.org/abs/2410.10098</link>
      <description><![CDATA[arXiv:2410.10098v1 公告类型：新
摘要：在本研究中，我们考虑多类多服务器非对称排队系统，该系统由一侧的 $N$ 个队列和另一侧的 $K$ 个服务器组成，其中作业每次随机到达队列。每个作业服务器分配的服务率未知，由基于特征的多项 Logit (MNL) 函数建模。每次，调度程序都会将作业分配给服务器，并且每个服务器根据其对分配作业的偏好随机地最多为一个作业提供服务。该算法的主要目标是在学习服务器的服务率的同时稳定系统中的队列。为了实现这一目标，我们提出了基于 UCB 和 Thompson 抽样的算法，该算法在较长的时间范围 $T$ 内实现系统稳定性，平均队列长度界限为 $O(\min\{N,K\}/\epsilon)$，其中 $\epsilon$ 是系统的流量松弛度。此外，该算法实现了次线性遗憾界限 $\tilde{O}(\min\{\sqrt{T} Q_{\max},T^{3/4}\})$，其中 $Q_{\max}$ 表示代理和时间的最大队列长度。最后，我们提供实验结果来证明我们算法的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.10098</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有负加权数据的神经准概率似然比估计</title>
      <link>https://arxiv.org/abs/2410.10216</link>
      <description><![CDATA[arXiv:2410.10216v1 公告类型：新
摘要：受高能粒子物理学中发现的现实情况的启发，我们考虑将似然比估计任务推广到概率密度可以为负的准概率设置。通过扩展，此框架也适用于重要性权重可以为负的环境中的重要性抽样。负密度和负权重的存在对传统的神经似然比估计方法提出了一系列挑战。我们通过引入一种新颖的损失函数来解决这些挑战。此外，我们引入了一种基于使用有符号混合模型分解似然比的新模型架构，提供了克服这些挑战的第二种策略。最后，我们通过一个教学示例和一个来自粒子物理学的真实示例展示了我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.10216</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过代理 PAC-Bayes 进行学习</title>
      <link>https://arxiv.org/abs/2410.10230</link>
      <description><![CDATA[arXiv:2410.10230v1 公告类型：新
摘要：PAC-Bayes 学习是一个全面的设置，用于 (i) 研究学习算法的泛化能力和 (ii) 通过优化泛化界限来推导新的学习算法。然而，优化泛化界限可能并不总是可行的，原因可能是易处理或计算，或两者兼而有之。例如，迭代查询经验风险可能会花费大量的计算资源。作为回应，我们引入了一种新颖的原则性策略，通过优化一系列替代训练目标来构建迭代学习算法，这些目标继承自 PAC-Bayes 泛化界限。关键论点是用泛化界限中的经验风险（被视为假设的函数）替换其在可构造的低维函数空间上的投影：这些投影的查询效率远高于初始风险。除了提供通过替代 PAC-Bayes 界限进行学习的通用方法之外，我们还 (i) 贡献理论结果，证明迭代优化替代意味着优化原始泛化界限，(ii) 将此策略实例化到元学习框架，引入元目标，为元梯度提供封闭形式表达式，(iii) 通过受工业生化问题启发的数值实验说明我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.10230</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>逻辑对数似然的最佳下限</title>
      <link>https://arxiv.org/abs/2410.10309</link>
      <description><![CDATA[arXiv:2410.10309v1 公告类型：新
摘要：逻辑变换可以说是除线性设置之外使用最广泛的链接函数。这种变换经常出现在二进制数据的回归模型中，并且以显式或隐式的方式为分类和回归的最先进方法提供了核心构建块。它的广泛使用，加上缺乏用于优化涉及逻辑变换的一般损失的分析解决方案，仍然激发了计算统计学的积极研究。在探索的方向中，一个中心方向集中在设计易于优化的逻辑对数似然的切线下限，同时提供这些对数似然的严格近似。尽管这些方面的进展已导致开发出有效的最小化-最大化 (MM) 算法用于点估计和坐标上升变分推理方案用于在几个逻辑模型下进行近似贝叶斯推理，但文献中的重点一直是切二次最小化器。事实上，目前尚不清楚是否可以在不破坏所得最小化器的可处理性的情况下推导出比二次最小化器更尖锐的切线下界。本文通过设计和研究一种新的分段二次下界来解决这样一个具有挑战性的问题，该下界可以均匀地改进任何切二次最小化器，包括最尖锐的切线二次最小化器，同时可以直接解释为经典的广义套索问题。如岭逻辑回归所示，这种独特的联系比现有的分段界限提供的实现更有效，同时提高了二次界限的收敛速度。]]></description>
      <guid>https://arxiv.org/abs/2410.10309</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>