<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 27 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于薛定谔桥的深度条件生成学习</title>
      <link>https://arxiv.org/abs/2409.17294</link>
      <description><![CDATA[arXiv:2409.17294v1 公告类型：新 
摘要：条件生成模型代表了机器学习领域的重大进步，通过将附加信息纳入生成过程，可以实现数据的受控合成。在本文中，我们介绍了一种基于薛定谔桥的新型深度生成方法，用于学习条件分布。我们从由随机微分方程 (SDE) 控制的单位时间扩散过程开始，该过程将时间 $0$ 的固定点转换为时间 $1$ 的期望目标条件分布。为了有效实施，我们使用欧拉-丸山方法离散化 SDE，其中我们使用深度神经网络非参数化地估计漂移项。我们将我们的方法应用于低维和高维条件生成问题。数值研究表明，虽然我们的方法不能直接提供条件密度估计，但与现有几种方法获得的样本相比，该方法生成的样本表现出更高的质量。此外，生成的样本可以有效地用于估计条件密度和相关统计量，例如条件均值和条件标准差。]]></description>
      <guid>https://arxiv.org/abs/2409.17294</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调整回归模型以进行条件不确定性校准</title>
      <link>https://arxiv.org/abs/2409.17466</link>
      <description><![CDATA[arXiv:2409.17466v1 公告类型：新
摘要：共形预测方法具有有限样本分布自由的边际覆盖保证。然而，它们通常不提供条件覆盖保证，这对于高风险决策来说可能很重要。在本文中，我们提出了一种新算法来训练回归函数，以在应用分割共形预测程序后改善条件覆盖率。我们为条件覆盖率和标称覆盖率之间的错误覆盖差距建立了一个上限，并提出了一种端到端算法来控制这个上限。我们在合成和真实世界的数据集上通过经验证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.17466</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>顺序核化 Stein 差异</title>
      <link>https://arxiv.org/abs/2409.17505</link>
      <description><![CDATA[arXiv:2409.17505v1 公告类型：新
摘要：我们提出了核化 Stein 差异的顺序版本，它允许对连续监控和自适应停止的非标准化密度进行拟合优度检验。也就是说，样本量不需要在数据收集之前固定；从业者可以选择是否停止测试或随时继续收集证据，同时控制错误发现率。与相关文献形成鲜明对比的是，我们没有对 Stein 核施加统一的有界性。相反，我们利用 Stein 核在任意点评估处的潜在有界性来定义测试鞅，这让位于后续的新型顺序测试。我们证明了测试的有效性，以及备选方案下财富过程对数增长的渐近下限。我们进一步说明了测试对各种分布（包括受限玻尔兹曼机）的经验性能。]]></description>
      <guid>https://arxiv.org/abs/2409.17505</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化综合联合图嵌入中的诱导相关性</title>
      <link>https://arxiv.org/abs/2409.17544</link>
      <description><![CDATA[arXiv:2409.17544v1 公告类型：新
摘要：理论和经验证据表明，联合图嵌入算法会在嵌入空间的网络间引起相关性。在 Omnibus 联合图嵌入框架中，先前的结果明确描述了算法引起的相关性和模型固有相关性对嵌入网络间相关性的双重影响。考虑和减轻算法引起的相关性是后续推理的关键，因为次优的 Omnibus 矩阵构造已被证明会导致推理保真度下降。这项工作首次尝试自动化 Omnibus 构造，以解决此联合嵌入框架中的两个关键问题：相关性到 OMNI 问题和平坦相关性问题。在平坦相关性问题中，我们试图了解广义 Omnibus 嵌入产生的最小算法引起的平坦相关性（即，在所有图对中相同）。在完全通用 Omnibus 矩阵的子空间中，我们证明了这种平坦相关性的下限，并且经典的 Omnibus 构造会产生最大平坦相关性。在相关性到 OMNI 问题中，我们提出了一种算法 - 名为 corr2Omni - 该算法从给定的估计成对图相关性矩阵中估计出在嵌入空间中产生最佳相关性的广义 Omnibus 权重矩阵。此外，在模拟和真实数据设置中，我们都证明了我们的 corr2Omni 算法比经典的 Omnibus 构造更有效。]]></description>
      <guid>https://arxiv.org/abs/2409.17544</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>霍克斯过程的共轭贝叶斯两步变点检测</title>
      <link>https://arxiv.org/abs/2409.17591</link>
      <description><![CDATA[arXiv:2409.17591v1 公告类型：新
摘要：贝叶斯两步变点检测方法因其简单直观而广泛应用于霍克斯过程。然而，点过程似然与先验之间的非共轭性要求大多数现有的贝叶斯两步变点检测方法依赖于非共轭推理方法。这些方法缺乏解析表达式，导致计算效率低下，妨碍及时检测变点。为了解决这个问题，这项工作采用数据增强技术，提出了一种针对霍克斯过程的共轭贝叶斯两步变点检测方法，该方法被证明更准确、更高效。在合成数据和真实数据上进行的大量实验表明，与基线方法相比，我们的方法具有更优越的有效性和效率。此外，我们进行了消融研究，以探索我们的方法对各种超参数的稳健性。我们的代码在 https://github.com/Aurora2050/CoBay-CPD 上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2409.17591</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高效的公平性能帕累托前沿计算</title>
      <link>https://arxiv.org/abs/2409.17643</link>
      <description><![CDATA[arXiv:2409.17643v1 公告类型：新
摘要：众所周知，表示的公平性和从表示派生的分类器的性能之间存在内在的权衡。由于大多数现代表示学习方法中优化算法的复杂性，对于给定的方法，确定该方法获得的公平性-性能曲线是否最佳可能并非易事，即它是否接近底层数据分布的这些数量的真实帕累托前沿。
在本文中，我们提出了一种计算最佳帕累托前沿的新方法，该方法不需要训练复杂的表示模型。我们表明，最佳公平表示具有几个有用的结构特性，这些特性可以将帕累托前沿的计算简化为紧凑的离散问题。然后，我们还表明，这些紧凑的近似问题可以通过现成的凹凸规划方法有效地解决。
由于我们的方法独立于特定的表示模型，因此可以将其用作表示学习算法的比较基准。我们在许多现实世界的基准数据集上对该方法进行了实验评估。]]></description>
      <guid>https://arxiv.org/abs/2409.17643</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>$\ell_1$ 正则化回归中的迁移学习：基于尖锐渐近分析的超参数选择策略</title>
      <link>https://arxiv.org/abs/2409.17704</link>
      <description><![CDATA[arXiv:2409.17704v1 公告类型：新
摘要：迁移学习技术旨在利用来自多个相关数据集的信息来提高针对目标数据集的预测质量。此类方法已在高维稀疏回归的背景下被采用，并且已经发明了一些基于 Lasso 的算法：Trans-Lasso 和 Pretraining Lasso 就是这样的例子。这些算法要求统计人员选择超参数来控制来自相关数据集的信息传输的程度和类型。然而，这些超参数的选择策略以及这些选择对算法性能的影响在很大程度上尚未被探索。为了解决这个问题，我们通过使用副本方法的渐近分析在高维设置中对算法进行了彻底、精确的研究。我们的方法揭示了算法的一个令人惊讶的简单行为：忽略传输到微调阶段的两种信息中的一种对泛化性能几乎没有影响，这意味着可以显著减少超参数选择的努力。我们的理论发现也得到了 IMDb 数据集上实际应用的经验支持。]]></description>
      <guid>https://arxiv.org/abs/2409.17704</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于丰富功能树的分类器：一种利用导数和几何特征的新方法</title>
      <link>https://arxiv.org/abs/2409.17804</link>
      <description><![CDATA[arXiv:2409.17804v1 公告类型：新
摘要：本研究的定位属于标量函数分类文献，这是一个跨多个领域（尤其是统计学、数学和计算机科学）引起广泛关注的领域。本研究通过将函数数据分析 (FDA) 与基于树的集成技术相结合来对高维时间序列进行分类，引入了一种用于监督分类的高级方法。所提出的框架，即丰富的基于函数树的分类器 (EFTC)，利用导数和几何特征，受益于集成方法固有的多样性，进一步提高预测性能并减少方差。虽然我们的方法已经在丰富的函数分类树 (FCT)、函数 K-NN (FKNN)、函数随机森林 (FRF)、函数 XGBoost (FXGB) 和函数 LightGBM (FLGBM) 上进行了测试，但它可以扩展到其他基于树和非基于树的分类器，并从本研究中得出适当的考虑。通过对七个真实数据集和六个模拟场景进行大量的实验评估，该提案展示了比传统方法更令人着迷的改进，为 FDA 在复杂、高维学习问题中的应用提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2409.17804</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>特征学习如何改善神经缩放定律</title>
      <link>https://arxiv.org/abs/2409.17858</link>
      <description><![CDATA[arXiv:2409.17858v1 公告类型：新
摘要：我们开发了一个超越核极限的神经缩放定律的可解模型。该模型的理论分析表明，性能如何随模型大小、训练时间和可用数据总量而变化。我们确定了三种对应于不同任务难度的缩放机制：困难、简单和超级简单任务。对于简单和超级简单目标函数，它们位于由初始无限宽度神经切线核 (NTK) 定义的再生核希尔伯特空间 (RKHS) 中，特征学习和核机制模型之间的缩放指数保持不变。对于困难任务（定义为初始 NTK 的 RKHS 之外的任务），我们通过分析和经验证明，特征学习可以通过训练时间和计算来改善缩放，几乎使困难任务的指数翻倍。这导致了在特征学习机制中缩放参数和训练时间的不同计算最优策略。通过对圆上的非线性 MLP 用幂律傅里叶谱拟合函数和 CNN 学习视觉任务的实验，我们支持了我们的发现，即特征学习可以改善困难任务的缩放规律，但不能改善简单和超简单任务的缩放规律。]]></description>
      <guid>https://arxiv.org/abs/2409.17858</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连续时间强化学习的随机测量方法</title>
      <link>https://arxiv.org/abs/2409.17200</link>
      <description><![CDATA[arXiv:2409.17200v1 公告类型：交叉 
摘要：我们提出了一种随机测量方法，用于建模探索，即在具有受控扩散和跳跃的连续时间强化学习 (RL) 中执行测量值控制。首先，我们考虑在离散时间网格上对连续时间中的随机控制进行采样的情况，并将得到的随机微分方程 (SDE) 重新表述为由合适的随机测度驱动的方程。这些随机测度的构造利用了布朗运动和泊松随机测度（它们是原始模型动力学中的噪声源）以及在网格上采样以执行控制的附加随机变量。然后，我们证明了当采样网格的网格大小变为零时这些随机测度的极限定理，这导致了由白噪声随机测度和泊松随机测度共同驱动的网格采样极限 SDE。我们还认为，网格采样极限 SDE 可以替代最近的连续时间 RL 文献中的探索性 SDE 和样本 SDE，即它可以应用于探索性控制问题的理论分析和学习算法的推导。]]></description>
      <guid>https://arxiv.org/abs/2409.17200</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模型聚合：最小化经验方差优于最小化经验误差</title>
      <link>https://arxiv.org/abs/2409.17267</link>
      <description><![CDATA[arXiv:2409.17267v1 公告类型：交叉 
摘要：无论是确定性还是随机性，模型都可以被视为旨在近似特定感兴趣量的函数。我们提出了一个数据驱动的框架，将来自不同模型的预测聚合成一个更准确的输出。这种聚合方法利用每个模型的优势来提高整体准确性。它是非侵入式的 - 将模型视为黑盒函数 - 与模型无关，需要最少的假设，并且可以组合来自各种模型的输出，包括来自机器学习和数值求解器的输出。我们认为聚合过程应该是逐点线性的，并提出了两种方法来找到最佳聚合：最小误差聚合（MEA），它最小化聚合的预测误差，以及最小方差聚合（MVA），它最小化其方差。当模型与目标量之间的相关性完全已知时，MEA 本质上会更准确，但当必须根据数据估计这些相关性时，最小经验方差聚合 (MEVA)（MVA 的经验版本）的表现始终优于最小经验误差聚合 (MEEA)（MEA 的经验对应物）。关键区别在于，MEVA 通过估计模型误差来构建聚合，而 MEEA 将模型视为直接插值感兴趣量的特征。这使得 MEEA 更容易出现过度拟合和泛化不良，在测试期间，聚合的表现可能不如单个模型。我们展示了我们的框架在数据科学和偏微分方程等各种应用领域的多功能性和有效性，展示了它如何成功地将传统求解器与机器学习模型相结合，以提高稳健性和准确性。]]></description>
      <guid>https://arxiv.org/abs/2409.17267</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>农业产量的稀疏性、正则化和因果关系：以秘鲁水稻为例</title>
      <link>https://arxiv.org/abs/2409.17298</link>
      <description><![CDATA[arXiv:2409.17298v1 公告类型：交叉 
摘要：本研究介绍了一种新方法，该方法将农业普查数据与遥感时间序列相结合，以开发秘鲁各地区水稻产量的精确预测模型。通过利用稀疏回归和弹性网络正则化技术，该研究确定了关键遥感变量（如 NDVI、降水量和温度）与农业产量之间的因果关系。为了进一步提高预测精度，应用了这些变量的一阶和二阶动态变换（速度和加速度），捕捉非线性模式和对产量的延迟影响。研究结果强调了将正则化技术与气候和地理空间变量相结合时预测性能的提高，从而能够更精确地预测产量变化。结果证实了格兰杰意义上的因果关系的存在，强调了这种方法对战略农业管理的价值。这有助于提高水稻种植的效率和可持续性。]]></description>
      <guid>https://arxiv.org/abs/2409.17298</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>维度的毒害</title>
      <link>https://arxiv.org/abs/2409.17328</link>
      <description><![CDATA[arXiv:2409.17328v1 公告类型：交叉 
摘要：本文推进了对机器学习模型的大小如何影响其易受毒害性的理解，尽管有最先进的防御措施。给定各向同性的随机诚实特征向量和几何中值（或截断均值）作为稳健梯度聚合规则，我们基本上证明了，也许令人惊讶的是，具有 $D \geq 169 H^2/P^2$ 参数的线性和逻辑回归容易受到毒害者的任意模型操纵，其中 $H$ 和 $P$ 是用于训练的诚实标记和毒害数据点的数量。我们的实验继续揭示在合成数据以及具有随机特征的线性分类器的 MNIST 和 FashionMNIST 数据上增强模型表达能力和增加毒害者攻击面之间的基本权衡。我们还讨论了对基于源的学习和神经网络的潜在影响。]]></description>
      <guid>https://arxiv.org/abs/2409.17328</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>训练 Transformer 进行下一个 token 预测的非渐近收敛</title>
      <link>https://arxiv.org/abs/2409.17335</link>
      <description><![CDATA[arXiv:2409.17335v1 公告类型：交叉 
摘要：Transformer 因其出色的处理顺序数据的能力而在现代机器学习中取得了非凡的成功，尤其是在下一个标记预测 (NTP) 任务中。然而，对其在 NTP 中性能的理论理解有限，现有研究主要集中于渐近性能。本文对由自注意模块和前馈层组成的单层 Transformer 的训练动态进行了细粒度的非渐近分析。我们首先使用基于偏序的数学框架来描述 NTP 训练数据集的基本结构特性。然后，我们设计了一个两阶段训练算法，其中训练前馈层的预处理阶段和训练注意层的主要阶段表现出快速收敛性能。具体而言，这两个层都以亚线性方式收敛到其相应最大边际解的方向。我们还表明交叉熵损失具有线性收敛速度。此外，我们表明经过训练的 Transformer 在数据集移位时表现出非平凡的预测能力，这揭示了 Transformer 出色的泛化性能。我们的分析技术涉及开发注意力梯度的新属性，并进一步深入分析这些属性如何有助于训练过程的收敛。我们的实验进一步验证了我们的理论发现。]]></description>
      <guid>https://arxiv.org/abs/2409.17335</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TDA Mapper 对点云数据的双过滤及稳定性</title>
      <link>https://arxiv.org/abs/2409.17360</link>
      <description><![CDATA[arXiv:2409.17360v1 公告类型：交叉 
摘要：Carlsson、Singh 和 Memoli 的 TDA 映射器采用点云数据集并输出取决于多个参数选择的图形。Dey、Memoli 和 Wang 为抽象拓扑空间开发了多尺度映射器，以便可以通过持久同源性分析参数选择。但是，当应用于实际数据时，并不总是能获得映射器图的过滤。DBSCAN 是 TDA 映射器软件中最常用的聚类算法之一，有两个参数，\textbf{$\epsilon$} 和 \textbf{MinPts}。如果 \textbf{MinPts = 1}，则 DBSCAN 相当于切割高度为 \textbf{$\epsilon$} 的单链接聚类。我们表明，如果使用 \textbf{MinPts $&gt;$ 2} 的 DBSCAN 聚类，则除非没有自由边界点，否则可能不存在映射器图的过滤；但如果使用 \textbf{MinPts = 1} 或 \textbf{2} 的 DBSCAN 聚类，则当覆盖大小增加、\textbf{$\epsilon$} 增加和/或 \textbf{MinPts} 减少时，就会存在此类过滤。但是，一维过滤是不稳定的。如果向数据集添加噪声，使得每个数据点的扰动距离最多为 \textbf{$\delta$}，则扰动数据集的映射器图的持久同源性可能与原始数据集的持久同源性有显著不同。我们表明，我们可以通过同时增加覆盖大小和 \textbf{$\epsilon$} 来获得稳定性。具体来说，我们表明这两个数据集之间同源群关于覆盖大小和 $\epsilon$ 的双过滤是 \textbf{2$\delta$} 交错的。]]></description>
      <guid>https://arxiv.org/abs/2409.17360</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>