<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 07 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用与图卷积神经网络相结合的种群 SIR 模型对美国的 COVID-19 传播进行建模</title>
      <link>https://arxiv.org/abs/2501.02043</link>
      <description><![CDATA[arXiv:2501.02043v1 公告类型：新
摘要：近年来，图卷积神经网络 (GCN) 在解决数据密集型挑战方面显示出巨大的潜力。特别是，人们已经尝试通过结合种群之间的人类流动性并使用图方法来估计相应的超参数来改进易感-感染-恢复 (SIR) 模型的预测。最近，研究人员发现，当用于日本区域级别收集的数据时，混合 GCN-SIR 方法优于现有方法。在我们的工作中，我们将这种方法扩展到从美国大陆收集的数据，并根据不同的流动模式和不同的政策响应进行调整。我们还开发了实时连续估计再生数的策略，并研究了模型对总体人口和各个州的预测准确性。讨论了 GCN-SIR 方法作为疾病动态建模的潜在候选方法的优势和局限性。]]></description>
      <guid>https://arxiv.org/abs/2501.02043</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>广义 Lasso 的优化-最小化双阶段算法</title>
      <link>https://arxiv.org/abs/2501.02197</link>
      <description><![CDATA[arXiv:2501.02197v1 公告类型：新
摘要：广义套索是著名套索方法的自然推广，用于处理结构正则化问题。许多重要的方法和应用都属于这一框架，包括融合套索、聚类套索和约束套索。为了提高其在大规模问题中的有效性，人们对广义套索的计算策略进行了广泛的研究。然而，据我们所知，大多数研究都是在线性设置下进行的，在非高斯和非线性模型方面的进展有限。我们提出了一种主要化-最小化双阶段 (MM-DUST) 算法，以有效地追踪广义套索问题的完整解路径。主要化技术被纳入其中，通过它们的二次主要化器来处理不同的凸损失函数。利用原始问题和对偶问题之间的联系以及分阶段学习的“慢酿造”思想，最小化步骤在对偶空间中通过对对偶系数进行一系列简单的坐标更新和较小的步长来实现。因此，选择合适的步长可以在统计准确性和计算效率之间取得平衡。我们分析了 MM-DUST 的计算复杂度，并建立了近似解路径的统一收敛性。广泛的模拟研究和正则化逻辑回归和 Cox 模型的应用证明了所提方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.02197</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过加速交替投影实现稳健的多维缩放</title>
      <link>https://arxiv.org/abs/2501.02208</link>
      <description><![CDATA[arXiv:2501.02208v1 公告类型：新
摘要：本文考虑了稳健多维缩放 (RMDS) 问题。目标是从可能被异常值破坏的成对距离中定位点位置。受经典 MDS 理论和针对稳健主成分分析 (RPCA) 问题的非凸工作的启发，我们提出了一种基于交替投影的算法，该算法通过切线空间投影技术进一步加速。对于所提出的算法，如果异常值足够稀疏，我们可以在居中和旋转对齐后建立重建点到原始点的线性收敛。数值实验验证了所提算法的最优性能。]]></description>
      <guid>https://arxiv.org/abs/2501.02208</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越对数凹度和得分规律：改进 W2 距离中基于得分的生成模型的收敛界限</title>
      <link>https://arxiv.org/abs/2501.02298</link>
      <description><![CDATA[arXiv:2501.02298v1 公告类型：新
摘要：基于分数的生成模型 (SGM) 旨在通过使用受高斯噪声干扰的样本学习分数函数来从目标分布中进行采样。$\mathcal{W}_2$ 距离中 SGM 的现有收敛界限依赖于对数据分布的严格假设。在这项工作中，我们提出了一个用于分析 SGM 中 $\mathcal{W}_2$ 收敛的新框架，大大放宽了对数凹度和分数规律性等传统假设。利用 Ornstein-Uhlenbeck (OU) 过程的正则化特性，我们表明数据分布的弱对数凹度会随着时间的推移演变为对数凹度。通过基于 PDE 的 Hamilton-Jacobi-Bellman 方程分析严格量化了这种转变，该方程控制前向过程的对数密度。此外，我们确定时间反转 OU 过程的漂移在收缩和非收缩状态之间交替，反映了凹度的动态。我们的方法绕过了对得分函数及其估计量严格的规律性条件的需求，而是依赖于更温和、更实际的假设。我们通过对高斯混合模型的显式计算证明了该框架的广泛适用性，说明了其多功能性和对更广泛数据分布类别的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.02298</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>谁写的？使用有限样本浓度不等式进行 LLM 生成文本检测的零样本统计测试</title>
      <link>https://arxiv.org/abs/2501.02406</link>
      <description><![CDATA[arXiv:2501.02406v1 公告类型：新
摘要：验证内容的出处对于许多组织（例如教育机构、社交媒体平台、公司等）的运作至关重要。随着大型语言模型 (LLM) 生成的文本与人类生成的内容几乎无法区分，这个问题变得越来越困难。此外，许多机构使用内部 LLM，并希望确保外部、未经批准的 LLM 不会在机构内生成内容。在本文中，我们回答了以下问题：给定一段文本，我们能否识别它是由 LLM $A$ 还是 $B$ 生成的（其中 $B$ 可以是人类）？我们将 LLM 生成的文本建模为完全依赖于历史的顺序随机过程，并设计零样本统计测试来区分 (i) 由两组不同的 LLM $A$（内部）和 $B$（未经批准）生成的文本以及 (ii) LLM 生成的文本和人工生成的文本。我们证明，我们的测试的 I 类和 II 类错误随着文本长度的增加而呈指数下降。在设计我们的测试时，我们推导出对数困惑度和 $A$ 下字符串的平均熵之间差异的集中不等式。具体而言，对于给定的字符串，我们证明如果该字符串由 $A$ 生成，则该字符串在 $A$ 下的对数困惑度会收敛到该字符串在 $A$ 下的平均熵，但字符串长度出现这种情况的概率会呈指数级小。我们还表明，如果 $B$ 生成文本，除了字符串长度呈指数级小的概率外，$A$ 下字符串的对数困惑度会收敛到 $B$ 和 $A$ 的平均交叉熵。最后，我们给出了初步的实验结果来支持我们的理论结果。通过确保（高概率）找到任意大小的有害 LLM 生成文本的来源，我们可以帮助打击虚假信息。]]></description>
      <guid>https://arxiv.org/abs/2501.02406</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过正则化线性判别分析进行迁移学习</title>
      <link>https://arxiv.org/abs/2501.02411</link>
      <description><![CDATA[arXiv:2501.02411v1 公告类型：新
摘要：线性判别分析是一种广泛使用的分类方法。然而，预测因子的高维数与小样本量相结合往往会导致较大的分类误差。为了应对这一挑战，利用相关源模型的数据来增强目标模型的分类性能至关重要。我们建议在迁移学习的框架内解决这个问题。
在本文中，我们通过正则化随机效应线性判别分析提出了一种新的迁移学习方法，其中判别方向被估计为从目标和源模型获得的岭估计的加权组合。介绍并评估了确定这些权重的多种策略，包括一种最小化判别向量估计风险的策略和另一种最小化分类误差的策略。利用随机矩阵理论的结果，我们明确推导出这些权重的渐近值以及高维设置中的相关分类错误率，其中 $p/n \rightarrow \infty$，其中 $p$ 表示预测变量维度，$n$ 表示样本大小。我们还提供了各种权重的几何解释以及选择权重的指导。广泛的数值研究（包括基于蛋白质组学的 10 年心血管疾病风险分类的模拟和分析）证明了所提出方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.02411</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中数据盗用检测的统计假设检验框架</title>
      <link>https://arxiv.org/abs/2501.02441</link>
      <description><![CDATA[arXiv:2501.02441v1 公告类型：新
摘要：近年来，大型语言模型 (LLM) 迅速流行起来。然而，LLM 的训练引发了重大的隐私和法律问题，特别是关于在未经适当归属或许可的情况下将受版权保护的材料纳入其训练数据中，这属于更广泛的数据盗用问题。在本文中，我们重点关注数据盗用检测的一个特定问题，即确定给定的 LLM 是否合并了另一个 LLM 生成的数据。为了解决这个问题，我们建议将水印嵌入受版权保护的训练数据中，并将数据盗用的检测制定为假设检验问题。我们开发了一个通用的统计测试框架，构建了一个关键统计数据，确定了最佳拒绝阈值，并明确控制 I 型和 II 型错误。此外，我们建立了所提测试的渐近最优性，并通过密集的数值实验证明了其经验有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.02441</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Transformers 模拟 MLE 以在贝叶斯网络中生成序列</title>
      <link>https://arxiv.org/abs/2501.02547</link>
      <description><![CDATA[arXiv:2501.02547v1 公告类型：新 
摘要：Transformer 在各个领域都取得了显著的成功，尤其是在自然语言处理等涉及序列数据的任务中表现出色。尽管取得了这些成就，但对 Transformer 能力的理论理解仍然有限。在本文中，我们研究了基于上下文最大似然估计 (MLE) 的 Transformer 在贝叶斯网络中自回归生成序列的理论能力。具体而言，我们考虑一种设置，其中上下文由一组根据贝叶斯网络生成的独立序列形成。我们证明存在一个简单的 Transformer 模型，它可以 (i) 根据上下文估计贝叶斯网络的条件概率，以及 (ii) 根据具有估计条件概率的贝叶斯网络自回归生成新样本。我们进一步在大量实验中证明，这样的 Transformer 不仅在理论上存在，而且可以通过训练有效地获得。我们的分析强调了变换器学习复杂概率模型的潜力，并有助于更好地理解大型语言模型作为一类强大的序列生成器。]]></description>
      <guid>https://arxiv.org/abs/2501.02547</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从因果贝叶斯网络视角重新审视格兰杰因果关系</title>
      <link>https://arxiv.org/abs/2501.02672</link>
      <description><![CDATA[arXiv:2501.02672v1 公告类型：新
摘要：描述复杂系统中的因果关系对于理解这些系统至关重要。对于许多人来说，格兰杰因果关系 (GC) 仍然是识别时间序列数据中因果关系的首选计算工具。与其他因果发现工具一样，GC 也有局限性，并被批评为非因果框架。在这里，我们通过赋予 GC 适当的因果解释来解决对 GC 的反复批评之一。这是通过从 Reichenbach 的共同因果原则 (RCCP) 和因果贝叶斯网络 (CBN) 视角分析 GC 实现的。我们从理论和图形上表明，这种重新表述在某些假设下赋予了 GC 适当的因果解释，并在模拟中取得了令人满意的结果。]]></description>
      <guid>https://arxiv.org/abs/2501.02672</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越 $\mathcal{O}(\sqrt{T})$ 遗憾：在线线性规划中的学习与决策解耦</title>
      <link>https://arxiv.org/abs/2501.02761</link>
      <description><![CDATA[arXiv:2501.02761v1 公告类型：新
摘要：在线线性规划在收益管理和资源分配中都发挥着重要作用，最近的研究主要集中在开发高效的一阶在线学习算法上。尽管一阶方法在经验上取得了成功，但它们通常得到的遗憾不比 $\mathcal{O} ( \sqrt{T} )$ 好，与最先进的基于线性规划 (LP) 的在线算法保证的 $\mathcal{O} (\log T)$ 界限相比，这是次优的。本文建立了一个通用框架，当 LP 对偶问题表现出某些误差界限条件时，该框架可以改进 $\mathcal{O} ( \sqrt{T} )$ 结果。我们首次证明，一阶学习算法在连续支持设置中实现了 $o( \sqrt{T} )$ 遗憾，在有限支持设置中实现了 $\mathcal{O} (\log T)$ 遗憾，这超出了非退化假设。我们的结果显著改善了最先进的遗憾结果，并为顺序决策提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2501.02761</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从数据中发现时滞微分方程的贝叶斯方法</title>
      <link>https://arxiv.org/abs/2501.02934</link>
      <description><![CDATA[arXiv:2501.02934v1 公告类型：新
摘要：时滞微分方程 (TDDE) 被广泛用于对复杂动态系统进行建模，其中未来状态依赖于具有延迟的过去状态。然而，由于现实系统中固有的非线性、不确定性和噪声，从观察到的数据推断底层 TDDE 仍然是一个具有挑战性的问题。传统的方程发现方法在处理较大的时间延迟时通常会表现出局限性，依赖于确定性技术或基于优化的方法，这些方法可能难以实现可扩展性和鲁棒性。在本文中，我们提出了 BayTiDe - 用于从数据中发现时滞微分方程的贝叶斯方法，该方法能够识别任意大的时间延迟值，其精度与输入数据的分辨率成正比。BayTiDe 利用贝叶斯推理结合稀疏性促进不连续尖峰和板状先验来准确识别时滞微分方程。该方法可以适应任意大的时间延迟，精度与输入数据分辨率成正比，同时有效地缩小搜索空间，从而节省大量计算资源。我们通过一系列数值示例展示了 BayTiDe 的效率和稳健性，验证了其从噪声数据中恢复延迟微分方程的能力。]]></description>
      <guid>https://arxiv.org/abs/2501.02934</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于优化向用户提供重复个性化行为的点过程模型</title>
      <link>https://arxiv.org/abs/2501.02961</link>
      <description><![CDATA[arXiv:2501.02961v1 公告类型：新
摘要：本文为受在线广告商用户与广告商互动启发的一类重要因果推理问题提供了一种形式化方法。然后，该形式化方法被专门用于时间标记点过程的扩展，并且神经点过程被建议作为一些有趣的特殊情况的实际解决方案。]]></description>
      <guid>https://arxiv.org/abs/2501.02961</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分类器加权混合模型</title>
      <link>https://arxiv.org/abs/2501.02989</link>
      <description><![CDATA[arXiv:2501.02989v1 公告类型：新
摘要：本文提出了标准混合随机模型的扩展，即用使用分类器定义的函数权重代替恒定混合权重。分类器加权混合模型可以直接进行密度评估、显式采样，并增强变分估计问题的表达能力，而不会增加组件数量或混合组件的复杂性。]]></description>
      <guid>https://arxiv.org/abs/2501.02989</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NeuroPMD：用于产品流形上密度估计的神经场</title>
      <link>https://arxiv.org/abs/2501.02994</link>
      <description><![CDATA[arXiv:2501.02994v1 公告类型：新
摘要：我们提出了一种用于乘积黎曼流形域密度估计的新型深度神经网络方法。在我们的方法中，网络直接参数化未知密度函数，并使用惩罚最大似然框架进行训练，其中惩罚项使用流形微分算子形成。网络架构和估计算法经过精心设计，可应对高维乘积流形域的挑战，有效缓解限制传统核和基础扩展估计量的维数灾难，并克服非专业神经网络方法遇到的收敛问题。广泛的模拟和对大脑结构连接数据的实际应用凸显了我们的方法相对于竞争替代方案的明显优势。]]></description>
      <guid>https://arxiv.org/abs/2501.02994</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稳健显著性检验的 Shapley 分组及其在债券回收率预测中的应用</title>
      <link>https://arxiv.org/abs/2501.03041</link>
      <description><![CDATA[arXiv:2501.03041v1 公告类型：新
摘要：我们提出了 Group Shapley，这是一种扩展经典的个体级 Shapley 值框架的度量标准，用于评估特征组的重要性，解决了商业和经济数据中常见的预测因子的结构化性质。更重要的是，我们开发了一种基于三累积量卡方近似的显着性检验程序，并建立了 Group Shapley 值的检验统计量的渐近性质。我们的方法可以有效地处理具有挑战性的场景，包括稀疏或倾斜的分布和小样本量，优于 Wald 检验等替代检验。模拟证实，所提出的测试保持了稳健的经验规模，并在各种条件下表现出增强的功效。为了说明该方法在推进可解释人工智能方面的实际意义，我们将我们的框架应用于债券回收率预测，使用一个全球数据集（1996-2023 年），该数据集包含 2,094 个观测值和 98 个特征，分为 16 个子组和五个更广泛的类别：债券特征、公司基本面、行业特定因素、市场相关变量和宏观经济指标。我们的结果表明，市场相关变量组最具影响力。此外，洛伦兹曲线和基尼指数表明，与单个 Shapley 值相比，Shapley 组对特征重要性的分配更为公平。]]></description>
      <guid>https://arxiv.org/abs/2501.03041</guid>
      <pubDate>Tue, 07 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>