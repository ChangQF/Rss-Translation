<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 19 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>机器学习与时间可逆数据桥梁</title>
      <link>https://arxiv.org/abs/2412.13665</link>
      <description><![CDATA[arXiv:2412.13665v1 公告类型：新
摘要：动态系统分析是自然科学和工程学的基本工具。它用于理解大到整个星系、小到单个分子的系统的演化。在动态系统演化的预定义条件下，底层微分方程必须满足时间和空间的特定约束。这类问题称为边界值问题。本论文提出了一种学习受初始和最终条件约束的时间可逆确定性和随机动力学的新方法。动态是由机器学习算法从观察到的数据推断出来的，这与传统的通过数值积分求解微分方程的方法不同。本论文的研究研究了一组难度不断增加的问题，每个问题都与学习动态的不同方面有关。首先，我们考虑从受确定性边界条件约束的地面真实解中学习确定性动力学。其次，我们研究离散状态空间中的边界值问题，其中正向动力学遵循随机跳跃过程，边界条件是离散概率分布。具体来说，我们考虑了特定跳跃过程（Ehrenfest 过程）的随机动力学，并使用机器学习推断逆时间动力学。最后，我们研究了在没有任何参考信息的情况下推断两个概率分布之间的连续时间随机过程的动力学的问题。在这里，我们提出了一种新颖的标准来学习两个随机过程的时间可逆动力学，以解决薛定谔桥问题。]]></description>
      <guid>https://arxiv.org/abs/2412.13665</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预条件子空间朗之万蒙特卡罗</title>
      <link>https://arxiv.org/abs/2412.13928</link>
      <description><![CDATA[arXiv:2412.13928v1 公告类型：新
摘要：我们开发了一种新的高维采样有效方法，称为子空间朗之万蒙特卡罗。这些方法的主要应用是有效地实现预条件朗之万蒙特卡罗。为了证明这种新方法的实用性，我们将欧几里得空间中的子空间下降方法的思想扩展到解决 Wasserstein 空间上的特定优化问题。我们的理论分析证明了所提出方法的有利收敛机制，这取决于镜像下降方法常见的相对条件假设。我们用从病态高斯分布中采样的实验证据支持我们的理论。]]></description>
      <guid>https://arxiv.org/abs/2412.13928</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>jinns：一个用于物理信息神经网络的 JAX 库</title>
      <link>https://arxiv.org/abs/2412.14132</link>
      <description><![CDATA[arXiv:2412.14132v1 公告类型：新
摘要：jinns 是一个用于物理信息神经网络的开源 Python 库，旨在解决正向和逆向问题以及元模型学习。它植根于 JAX 生态系统，提供了一个多功能框架，可以有效地对实际问题进行原型设计，同时轻松扩展以满足特定需求。此外，该实现利用现有的流行 JAX 库（如 equinox 和 optax）进行模型定义和优化，为用户带来熟悉感。许多模型可作为基线，文档提供了不同用例的参考实现以及针对特定需求扩展的分步教程。代码可在 Gitlab https://gitlab.com/mia_jinns/jinns 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.14132</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>参数贝叶斯模型的自适应非参数扰动</title>
      <link>https://arxiv.org/abs/2412.10683</link>
      <description><![CDATA[arXiv:2412.10683v2 公告类型：交叉 
摘要：参数贝叶斯建模为科学数据分析提供了一个强大而灵活的工具箱。然而，无论模型多么详细，它仍然可能是错误的，这可能会使推断不可信。在本文中，我们研究了非参数扰动参数 (NPP) 贝叶斯模型，其中参数贝叶斯模型通过其可能性的扭曲而放松。当推断的目标是真实数据分布或其某些功能（例如因果推断）时，我们分析了 NPP 模型的属性。我们表明，NPP 模型可以提供非参数模型的稳健性，同时保留参数模型的数据效率，并在参数模型接近真实时实现快速收敛。为了使用 NPP 模型有效地分析数据，我们开发了一个广义贝叶斯程序来近似其后验。我们通过从单细胞 RNA 测序数据中估计基因表达的因果效应来展示我们的方法。 NPP 建模为稳健贝叶斯推理提供了一种有效的方法，并且可用于稳健化任何参数贝叶斯模型。]]></description>
      <guid>https://arxiv.org/abs/2412.10683</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度学习在水力发电优化中的应用：利用全球环流模型的集合预报生成长期河流流量情景</title>
      <link>https://arxiv.org/abs/2412.12234</link>
      <description><![CDATA[arXiv:2412.12234v1 公告类型：交叉 
摘要：水力发电是全球能源矩阵的重要组成部分，特别是在巴西等国家，水力发电占能源供应的大部分。然而，它对河流流量的强烈依赖带来了重大挑战，而河流流量由于气候变化而具有内在的不确定性。河流流量与降水模式有关，因此开发准确的概率预测模型对于改善严重依赖这种资源的系统的运营规划至关重要。传统上，统计模型已用于表示能源优化中的河流流量。然而，由于气候行为的结构性变化，这些模型越来越无法产生现实的情景。降水模式的变化改变了流量动态，传统方法难以捕捉到这一动态。机器学习方法虽然可以作为时间序列的通用预测器，但通常只关注历史数据，而忽略了气象和气候条件等关键的外部因素。此外，这些方法通常缺乏概率框架，而概率框架对于表示水文过程的固有变化至关重要。历史流量数据的有限可用性进一步使大规模深度学习模型在此领域的应用变得复杂。为了应对这些挑战，我们提出了一个基于改进的循环神经网络架构的框架。该模型根据全球环流模型的预测生成参数化的概率分布，有效地解释了河流流量的随机性。此外，该架构还采用了增强功能以​​提高其泛化能力。我们在巴西互联系统中验证了该框架，使用来自 SEAS5-ECMWF 系统的预测作为条件变量。]]></description>
      <guid>https://arxiv.org/abs/2412.12234</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>后验均值匹配：通过在线贝叶斯推理进行生成建模</title>
      <link>https://arxiv.org/abs/2412.13286</link>
      <description><![CDATA[arXiv:2412.13286v1 公告类型：交叉 
摘要：本文介绍了后验均值匹配 (PMM)，这是一种基于贝叶斯推理的生成建模新方法。PMM 使用共轭分布对来对各种模态（如图像和文本）的复杂数据进行建模，为现有方法（如扩散模型）提供了一种灵活的替代方案。PMM 模型使用在线贝叶斯推理的更新迭代地细化目标分布的噪声近似。PMM 之所以灵活，是因为它的机制基于一般的贝叶斯模型。我们通过开发专门的示例来展示这种灵活性：使用正态-正态模型的实值数据生成 PMM 模型、使用 Gamma-Poisson 模型的计数数据生成 PMM 模型以及使用 Dirichlet-Categorical 模型的离散数据生成 PMM 模型。对于正态-正态 PMM 模型，我们通过展示其连续时间公式收敛到随机微分方程 (SDE) 建立了与扩散模型的直接联系。此外，对于 Gamma-Poisson PMM，我们推导出一种由 Cox 过程驱动的新型 SDE，这与传统的基于布朗运动的生成模型有很大不同。PMM 实现的性能可与语言建模和图像生成的生成模型相媲美。]]></description>
      <guid>https://arxiv.org/abs/2412.13286</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭秘秘方：监督微调小型法学硕士 (LLM) 指南</title>
      <link>https://arxiv.org/abs/2412.13337</link>
      <description><![CDATA[arXiv:2412.13337v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的兴起造成了巨大的差距：拥有计算资源、专家团队和先进基础设施的工业研究实验室可以有效地微调 LLM，而个人开发人员和小型组织则因资源有限而面临障碍。在本文中，我们旨在通过使用涵盖不同知识领域和技能的指令调整数据集对 LLM 进行监督微调的全面研究来弥合这一差距。我们专注于小型 LLM（3B 到 7B 参数），因为它们具有成本效益和可访问性。我们探索了四个开源预训练模型的各种训练配置和策略。我们提供了这些配置的详细文档，揭示了挑战几种常见训练实践的发现，包括 TULU 的超参数建议和 Orca 推荐的分阶段训练。我们工作的关键见解包括：（i）较大的批次大小与较低的学习率相结合可提高模型在 MMLU、MTBench 和 Open LLM Leaderboard 等基准上的性能；（ii）早期训练动态，例如较低的梯度范数和较高的损失值，是更好的最终模型性能的有力指标，可以提前终止次优运行并节省大量计算资源；（iii）通过彻底探索预热步骤和学习率计划等超参数，我们为从业者提供指导，并发现某些简化不会影响性能；（iv）我们观察到分阶段和堆叠训练策略之间的性能没有显着差异，但堆叠训练更简单，样本效率更高。由于这些发现在数据集和模型中都得到了稳健的证实，我们希望这项研究可以为从业者微调小型 LLM 提供指导，并为 LLM 研究促进更具包容性的环境。]]></description>
      <guid>https://arxiv.org/abs/2412.13337</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>单调前向-后向加速算法的 Lyapunov 分析</title>
      <link>https://arxiv.org/abs/2412.13527</link>
      <description><![CDATA[arXiv:2412.13527v1 公告类型：交叉 
摘要：在基于梯度的优化领域，Nesterov 的加速梯度法 (NAG) 是一项里程碑式的进步，其加速收敛速度优于凸函数的普通梯度下降法。然而，对于强凸函数，NAG 是否线性收敛仍是一个悬而未决的问题，正如 Chambolle 和 Pock [2016] 在综合评论中指出的那样。除了临界步长之外，Li 等人 [2024a] 使用高分辨率微分方程框架解决了这个问题。此外，Beck [2017，第 10.7.4 节] 引入了 NAG 的单调收敛变体，称为 M-NAG。尽管取得了这些进展，但 [Li et al., 2024a] 中提出的 Lyapunov 分析不能直接扩展到 M-NAG。在本文中，我们提出通过引入梯度项来修改迭代关系，从而得到一种新的基于梯度的迭代关系。这种调整允许构造一种排除动能的新型 Lyapunov 函数。从该 Lyapunov 函数导出的线性收敛与强凸函数的参数和步长无关，从而产生更通用和更稳健的结果。值得注意的是，我们观察到当应用位置-速度关系时，从 M-NAG 导出的梯度迭代关系与从 NAG 导出的梯度迭代关系等同。然而，Lyapunov 分析不依赖于位置-速度关系，这使我们能够将线性收敛扩展到 M-NAG。最后，通过利用两个近端不等式（作为强凸不等式的近端对应项），我们将线性收敛扩展到快速迭代收缩阈值算法 (FISTA) 及其单调对应项 (M-FISTA)。]]></description>
      <guid>https://arxiv.org/abs/2412.13527</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>哪种归因适合哪种特征选择方法？基于调查的模拟研究</title>
      <link>https://arxiv.org/abs/2412.13570</link>
      <description><![CDATA[arXiv:2412.13570v1 公告类型：交叉 
摘要：基于树的学习方法（例如随机森林和 XGBoost）仍然是表格数据的黄金标准预测方法。特征重要性度量通常用于特征选择以及评估特征对模型中结果变量的影响。这也适用于社会科学和官方统计中经常遇到的调查数据。这些类型的数据集通常存在缺失值的挑战。典型的解决方案是在应用学习方法之前对缺失数据进行插补。然而，鉴于可用的插补方法数量众多，因此出现了一个问题，即应该选择哪一种方法才能在后续分析中实现特征重要性和特征选择的“最佳”反映。在本文中，我们在一项基于调查的模拟研究中针对八种最先进的插补方法和三个学习者调查了这个问题。插补方法包括列表删除、三个 MICE 选项、四个 \texttt{missRanger} 选项以及最近提出的 mixGBoost 插补方法。作为学习者，我们考虑两种最常见的基于树的方法，即随机森林和 XGBoost，以及具有正则化的可解释线性模型。]]></description>
      <guid>https://arxiv.org/abs/2412.13570</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PASCO（并行结构化聚类）：一种加速图形聚类算法的覆盖层</title>
      <link>https://arxiv.org/abs/2412.13592</link>
      <description><![CDATA[arXiv:2412.13592v1 公告类型：交叉 
摘要：对图的节点进行聚类是图分析的基石，已经得到了广泛的研究。然而，一些流行的方法不适用于非常大的图：例如，谱聚类需要计算拉普拉斯矩阵的谱分解，这不适用于具有大量社区的大图。这项工作引入了 PASCO，这是一种加速聚类算法的覆盖。我们的方法包括三个步骤：1-我们通过应用高效且保持结构的粗化算法来计算表示输入图的几个独立的小图。2-聚类算法在每个小图上并行运行并提供初始图的几个分区。3-这些分区与最佳传输方法对齐并组合以输出最终分区。PASCO 框架基于两个关键贡献：一种旨在实现并行化的新型全局算法结构和一种快速、经过经验验证的保留结构属性的图粗化算法。我们在合成和真实世界图形数据集上进行了评估，证明了 1 PASCO 在计算效率、结构保存和输出分区质量方面的强劲性能。]]></description>
      <guid>https://arxiv.org/abs/2412.13592</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用随机模拟器进行非确定性极限状态的可靠性分析</title>
      <link>https://arxiv.org/abs/2412.13731</link>
      <description><![CDATA[arXiv:2412.13731v1 公告类型：交叉 
摘要：可靠性分析是不确定性量化的一个子领域，它评估系统在各种不确定性下按预期执行的概率。传统上，这种分析依赖于确定性模型，其中实验是可重复的，即它们为给定的一组输入产生一致的输出。然而，现实世界的系统往往表现出随机行为，导致不可重复的结果。这些所谓的随机模拟器每次运行模型时都会产生不同的输出，即使是固定的输入。本文正式介绍了随机模型的可靠性分析，并通过使用合适的替代模型来解决它，以降低其通常较高的计算成本。具体来说，我们专注于最近引入的广义 lambda 模型和随机多项式混沌展开。这些模拟器旨在学习模拟器响应的固有随机性，并以比传统蒙特卡洛模拟低得多的成本实现有效的不确定性量化。我们通过三个案例研究验证了我们的方法。首先，使用具有闭式解的解析函数，我们证明模拟器收敛到正确的解。其次，我们使用一个简单支撑梁的玩具示例展示从替代物获得的结果。最后，我们应用模拟器对现实的风力涡轮机案例研究进行可靠性分析，其中只有一组模拟结果可用。]]></description>
      <guid>https://arxiv.org/abs/2412.13731</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>半监督学习中的最佳精确恢复：谱方法和图卷积网络的研究</title>
      <link>https://arxiv.org/abs/2412.13754</link>
      <description><![CDATA[arXiv:2412.13754v1 公告类型：交叉 
摘要：我们深入研究了上下文随机块模型 (CSBM) 数据集上的半监督节点分类挑战。在这里，来自双集群随机块模型 (SBM) 的节点与特征向量相结合，这些特征向量来自与它们各自的节点标签相对应的高斯混合模型 (GMM)。由于只有一部分 CSBM 节点标签可用于训练，我们的主要目标就是对剩余节点进行准确分类。进入传导学习领域，我们首次确定了精确恢复 CSBM 中所有测试节点的信息理论阈值。同时，我们设计了一个受主成分分析 (PCA) 启发的最佳谱估计器，其中包含来自邻接矩阵和特征向量的训练标签和基本数据。我们还评估了图岭回归和图卷积网络 (GCN) 在这个合成数据集上的有效性。我们的研究结果强调，图岭回归和 GCN 在使用最优加权自循环时能够以类似于最优估计器的方式实现精确恢复的信息阈值。这凸显了特征学习在增强 GCN 能力方面的潜在作用，尤其是在半监督学习领域。]]></description>
      <guid>https://arxiv.org/abs/2412.13754</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于维度值的一致性估计</title>
      <link>https://arxiv.org/abs/2412.13898</link>
      <description><![CDATA[arXiv:2412.13898v1 公告类型：交叉 
摘要：考虑从随机点样本中估计欧几里得空间紧凑子集 S 的维数的问题。重点放在统计意义上的一致性结果上。也就是说，当样本大小增长到无穷大时，会收敛到真实维数值的陈述。在众多可用的维数定义中，我们（基于其统计可处理性）关注三个概念：闵可夫斯基维数、相关维数和可能不太流行的逐点维数概念。我们证明了这些数量的一些自然估计量的统计一致性。我们的证明部分依赖于使用以经验体积函数 Vn (r) 表示的工具估计量，该函数定义为到样本的距离最多为 r 的点集的勒贝格测度。具体来说，我们探讨了目标集 S 的真实体积函数 V (r) 是从零开始的某个区间上的多项式的情况。还包括一项实证研究。我们的研究旨在为确定集合 S 的维度是否小于周围空间的维度的问题提供一些理论支持和一些实践见解。这是维度研究的主要统计动机，与所谓的流形假设有关。]]></description>
      <guid>https://arxiv.org/abs/2412.13898</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的高斯-牛顿动力学：黎曼优化视角</title>
      <link>https://arxiv.org/abs/2412.14031</link>
      <description><![CDATA[arXiv:2412.14031v1 公告类型：交叉 
摘要：我们分析了高斯-牛顿动力学对具有平滑激活函数的神经网络训练的收敛性。在参数不足的情况下，高斯-牛顿梯度流在欧几里得输出空间的低维、平滑、嵌入子流形上诱导黎曼梯度流。使用黎曼优化工具，我们证明了黎曼梯度流以与 Gram 矩阵的条件无关的指数速率 \emph{last-iterate} 收敛到最佳类内预测器，\emph{无需}显式正则化。我们进一步描述了神经网络缩放因子和初始化对收敛行为的关键影响。在过度参数化的情况下，我们表明，具有适当选择的阻尼因子的 Levenberg-Marquardt 动力学对病态核具有鲁棒性，类似于参数不足的情况。这些发现证明了高斯-牛顿方法在有效优化神经网络方面的潜力，特别是在核和 Gram 矩阵具有较小奇异值的病态问题中。]]></description>
      <guid>https://arxiv.org/abs/2412.14031</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>带有 Tucker 分解的张量回归的噪声增强 $\ell_0$ 正则化</title>
      <link>https://arxiv.org/abs/2302.10775</link>
      <description><![CDATA[arXiv:2302.10775v2 公告类型：替换 
摘要：张量数据是多维数组。基于低秩分解的具有张量预测器的回归方法利用张量预测器中的结构信息，同时显著减少张量回归中的参数数量。我们提出了一种名为 NA$_0$CT$^2$（Tucker 分解中核心张量的 $\ell_0$ 正则化的噪声增强）的方法，用于正则化张量回归（TR）中的参数，并与 Tucker 分解相结合。我们从理论上确定 NA$_0$CT$^2$ 在线性 TR 和广义线性 TR 中的 Tucker 分解中实现了核心张量的精确 $\ell_0$ 正则化。据我们所知，NA$_0$CT$^2$ 是 TR 中第一个基于 Tucker 分解的正则化方法，可在核心张量中实现 $\ell_0$。 NA$_0$CT$^2$ 通过迭代过程实现，每次迭代涉及两个简单的步骤 - 根据更新的参数估计的 Tucker 分解的核心张量生成噪声数据，并对矢量化预测因子上的噪声增强数据运行常规 GLM。我们在模拟研究和实际数据应用中展示了 NA$_0$CT$^2$ 的实现及其 $\ell_0$ 正则化效果。结果表明，与其他基于分解的 TR 方法相比，NA$_0$CT$^2$ 可以改善预测，无论是否进行正则化，并且它可以识别重要的预测因子，尽管它不是为此目的而设计的。]]></description>
      <guid>https://arxiv.org/abs/2302.10775</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>