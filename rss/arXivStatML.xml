<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 17 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>扩散生成模型</title>
      <link>https://arxiv.org/abs/2412.10948</link>
      <description><![CDATA[arXiv:2412.10948v1 公告类型：新
摘要：我们引入了扩散模型作为生成新样本的一种方法。生成模型最近已被用于艺术生成（稳定扩散、Dall-E）和文本生成（ChatGPT）等任务。扩散模型特别将噪声应用于样本数据，然后“逆转”此噪声过程以生成新样本。我们将正式定义噪声和去噪过程，然后介绍使用扩散模型进行训练和生成的算法。最后，我们将探索扩散模型在提高不平衡数据分类器性能方面的潜在应用。]]></description>
      <guid>https://arxiv.org/abs/2412.10948</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动态网络的表征学习</title>
      <link>https://arxiv.org/abs/2412.11065</link>
      <description><![CDATA[arXiv:2412.11065v1 公告类型：新
摘要：本研究提出了一种针对动态网络量身定制的新型表示学习模型，该模型描述了群体中个体之间不断发展的关系。该问题包含在功能数据分析的降维主题中。由于动态网络表示为矩阵值函数，我们的目标是将此功能数据映射到低维学习空间中的一组矢量值函数中。该空间定义为度量函数空间，允许计算范数和内积。通过构建这个学习空间，我们解决了（i）属性学习、（ii）社区检测和（iii）动态网络中各个节点的链接预测和恢复。我们的模型还适应不对称的低维表示，从而可以单独研究节点的调节和接收角色。至关重要的是，学习方法考虑了网络的时间依赖性，确保表示随时间连续。我们定义的功能学习空间自然跨越了动态网络的时间范围，既有助于推断特定时间点的网络链接，也有助于重建整个网络结构，而无需直接观察。我们通过模拟研究和实际应用验证了我们的方法。在模拟中，我们将我们的方法在各种数据损坏情况下的链接预测性能与现有方法进行了比较。对于实际应用，我们研究了一个在六个蚂蚁种群中复制的动态社交网络，表明我们的低维学习空间有效地捕捉了相互作用、单个蚂蚁的角色以及网络的社会进化。我们的发现与现有的蚁群行为知识相一致。]]></description>
      <guid>https://arxiv.org/abs/2412.11065</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于深度学习的状态空间模型方法：精选综述</title>
      <link>https://arxiv.org/abs/2412.11211</link>
      <description><![CDATA[arXiv:2412.11211v1 公告类型：新
摘要：状态空间模型 (SSM) 为动态系统分析提供了一个强大的框架，其中系统的时间动态被认为是通过潜在状态的演变来捕获的，而潜在状态决定了观测值。本文选择性地回顾了基于深度神经网络的 SSM 方法的最新进展，并提出了离散时间深度状态空间模型和连续时间模型（如潜在神经常微分和随机微分方程）的统一视角。它首先概述了用于学习 SSM 的经典最大似然方法，回顾了变分自动编码器作为存在潜在变量的情况下基于神经网络的方法的通用学习管道，并详细讨论了属于 SSM 框架的代表性深度学习模型。还研究了最近的发展，其中 SSM 被用作独立的架构模块来提高序列建模的效率。最后，给出了涉及混合频率和不规则间隔时间序列数据的示例，以证明 SSM 在这些设置中的优势。]]></description>
      <guid>https://arxiv.org/abs/2412.11211</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测增强蒙特卡罗：控制变量的机器学习视角</title>
      <link>https://arxiv.org/abs/2412.11257</link>
      <description><![CDATA[arXiv:2412.11257v1 公告类型：新
摘要：尽管蒙特卡罗模拟是工程和金融领域必不可少的工具，但它的计算量却非常大，尤其是在大规模、路径相关问题中，这些问题阻碍了直接并行化。一种自然的替代方法是用机器学习或替代预测代替模拟，尽管这给理解由此产生的错误带来了挑战。我们引入了一个预测增强蒙特卡罗 (PEMC) 框架，其中我们利用机器学习预测作为控制变量，从而保持无偏评估，而不是直接使用 ML 预测器。传统的控制变量方法需要了解均值并专注于每个样本的方差减少。相比之下，PEMC 旨在降低总体成本，消除对均值知识的需求。PEMC 利用预先训练的神经架构来构建有效的控制变量，并用高效的神经网络评估取代计算成本高昂的样本路径生成。这使得 PEMC 能够解决没有良好控制变量的情况。我们通过两个生产级奇异期权定价问题展示了 PEMC 的有效性：HJM 模型中的掉期期权定价和随机局部波动率模型中的方差掉期定价。]]></description>
      <guid>https://arxiv.org/abs/2412.11257</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>datadriftR：用于预测模型中概念漂移检测的 R 包</title>
      <link>https://arxiv.org/abs/2412.11308</link>
      <description><![CDATA[arXiv:2412.11308v1 公告类型：新
摘要：预测模型通常会因数据分布的变化而面临性能下降的问题，这种现象称为数据漂移。在概念漂移的形式中，解释变量和响应变量之间的关系发生变化，这种现象尤其难以检测和适应。传统的漂移检测方法通常依赖于准确度或变量分布等指标，这些指标可能无法捕捉到细微但重要的概念变化。本文介绍了用于检测概念漂移的 R 包 Drifter，并提出了一种称为配置文件漂移检测 (PDD) 的新方法，该方法通过利用可解释的 AI 工具——部分依赖配置文件 (PDP)，既可以检测漂移，又可以增强对漂移背后原因的理解。该包的核心 PDD 方法通过新指标量化 PDP 的变化，确保对数据流变化的敏感性，而无需过多的计算成本。这种方法与 MLOps 实践相一致，强调在动态环境中进行模型监控和自适应再训练。在合成数据集和真实数据集上进行的实验表明，PDD 在保持高精度的同时有效平衡了灵敏度和稳定性，优于现有方法。结果突出了它在动态环境中自适应地重新训练模型的能力，使其成为实时应用的强大工具。本文最后讨论了该软件包的优势、局限性以及未来在更广泛用例中的扩展。]]></description>
      <guid>https://arxiv.org/abs/2412.11308</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 HP-ACCORD 学习临床多组学研究中的大规模偏相关网络</title>
      <link>https://arxiv.org/abs/2412.11554</link>
      <description><![CDATA[arXiv:2412.11554v1 公告类型：新
摘要：从现代多组学数据进行图形模型估计需要在统计估计性能和计算可扩展性之间取得平衡。我们引入了一种新的基于伪似然的图形模型框架，该框架在保留稀疏模式的同时重新参数化目标精度矩阵，并通过基于新损失函数最小化 $\ell_1$ 惩罚经验风险来估计它。所提出的估计量在高维假设下保持各种指标的估计和选择一致性。相关的优化问题允许使用新颖的运算符分割方法和避免通信的分布式矩阵乘法来实现可证明的快速计算算法。我们的框架的高性能计算实现在模拟数据中进行了测试，其中多达一百万个变量展示了类似于生物网络的复杂依赖结构。利用这种可扩展性，我们从双组学肝癌数据集中估计了偏相关网络。从超高维数据估计的共表达网络通过排除表观基因组调控的影响，在优先考虑关键转录因子和辅激活因子方面表现出卓越的特异性，证明了计算可扩展性在多组学数据分析中的价值。%源自基因表达数据。]]></description>
      <guid>https://arxiv.org/abs/2412.11554</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>广义贝叶斯深度强化学习</title>
      <link>https://arxiv.org/abs/2412.11743</link>
      <description><![CDATA[arXiv:2412.11743v1 公告类型：新
摘要：贝叶斯强化学习 (BRL) 是一种将贝叶斯统计和强化学习的原理相结合以在不确定的环境中做出最佳决策的方法。与其他基于模型的 RL 方法类似，它涉及两个关键部分：(1) 推断对真实环境进行建模的数据生成过程 (DGP) 的后验分布和 (2) 使用学习到的后验进行策略学习。我们建议通过假设马尔可夫依赖性的深度生成模型来模拟未知环境的动态。由于这些模型没有似然函数，我们通过学习广义预测序列 (或前序) 评分规则 (SR) 后验来训练它们。我们使用顺序蒙特卡罗 (SMC) 采样器从这个广义贝叶斯后验分布中抽取样本。同时，为了在神经网络的高维参数空间中实现可扩展性，我们在 SMC 中使用基于梯度的马尔可夫链蒙特卡罗 (MCMC) 核。为了证明使用先验评分规则后验的合理性，我们证明了 Bernstein-von Misses 型定理。对于策略学习，我们提出了预期汤普森抽样 (ETS)，通过最大化后验分布的预期值函数来学习最佳策略。这改进了传统的汤普森抽样 (TS) 及其扩展，后者仅使用从后验分布中抽取的一个样本。从理论上和使用假设离散动作和状态空间的模拟研究来研究这种改进。最后，我们成功地将我们的设置扩展到具有连续动作空间的具有挑战性的问题，而没有理论保证。]]></description>
      <guid>https://arxiv.org/abs/2412.11743</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于条件独立性检验的条件扩散模型</title>
      <link>https://arxiv.org/abs/2412.11744</link>
      <description><![CDATA[arXiv:2412.11744v1 公告类型：新
摘要：条件独立性 (CI) 测试是现代统计学和机器学习中的一项基本任务。条件随机化测试 (CRT) 最近被引入，用于测试给定一组潜在的高维随机变量 $Z$，两个随机变量 $X$ 和 $Y$ 是否条件独立。在条件分布 $X|Z$ 已知的假设下，CRT 运行得非常好。然而，由于这种分布在实践中通常是未知的，因此准确近似它变得至关重要。在本文中，我们建议使用条件扩散模型 (CDM) 来学习 $X|Z$ 的分布。从理论上和经验上看，CDM 非常接近真实的条件分布。此外，与 GAN 相比，CDM 提供了更准确的 $X|Z$ 近似值，可能导致 CRT 的性能优于基于 GAN 的 CRT。为了适应复杂的依赖结构，我们使用计算效率高的基于分类器的条件互信息 (CMI) 估计器作为我们的检验统计量。所提出的测试程序无需假设特定的分布形式或特征依赖性即可有效执行，并且能够处理包含连续和离散变量的混合类型条件集。理论分析表明，我们提出的测试实现了对 I 类错误的有效控制。对合成数据进行的一系列实验表明，即使在高维场景中，我们的新测试也能有效控制 I 类和 II 类错误。]]></description>
      <guid>https://arxiv.org/abs/2412.11744</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多数据源贝叶斯替代训练：一种混合建模策略</title>
      <link>https://arxiv.org/abs/2412.11875</link>
      <description><![CDATA[arXiv:2412.11875v1 公告类型：新
摘要：替代模型通常用作复杂模拟模型的计算效率近似值，使解决逆问题、敏感性分析和概率前向预测等任务成为可能，否则这些任务在计算上是不可行的。在训练期间，替代参数被拟合，使得替代尽可能接近地再现模拟模型的输出。然而，模拟模型本身只是现实世界系统的简化，通常缺少相关过程或存在错误指定，例如在输入或边界条件中。关于这些的提示可能会在现实世界的测量数据中捕获，然而，我们通常会在替代构建过程中忽略这些提示。在本文中，我们提出了两种新颖的概率方法来在替代训练期间整合模拟数据和现实世界的测量数据。第一种方法为每个数据源训练单独的替代模型并结合它们的预测分布，而第二种方法通过训练单个替代模型来整合两个数据源。我们通过综合和真实案例研究展示了这两种方法的概念差异和优势。结果证明了这些方法在提高预测准确性、预测覆盖率和诊断底层模拟模型中的问题方面的潜力。这些见解可以提高系统理解和未来的模型开发。]]></description>
      <guid>https://arxiv.org/abs/2412.11875</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BetaExplainer：一种解释图神经网络的概率方法</title>
      <link>https://arxiv.org/abs/2412.11964</link>
      <description><![CDATA[arXiv:2412.11964v1 公告类型：新
摘要：图神经网络 (GNN) 是进行图数据推理的强大工具，但由于难以提取有意义的子网络来推动预测性能，因此通常被视为“黑匣子”。存在许多可解释的 GNN 方法，但它们无法量化边缘权重的不确定性，并且在应用于具有挑战性的图结构时会降低预测准确性。在这项工作中，我们提出了 BetaExplainer，它通过在模型训练期间使用稀疏诱导先验来掩盖不重要的边缘来解决这些问题。为了评估我们的方法，我们检查了具有各种现实特征的各种模拟数据集。与最先进的解释器方法相比，这种实现不仅提供了边缘重要性不确定性的概念，而且还改进了具有挑战性的数据集的评估指标。]]></description>
      <guid>https://arxiv.org/abs/2412.11964</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度对比表征学习的泛化分析</title>
      <link>https://arxiv.org/abs/2412.12014</link>
      <description><![CDATA[arXiv:2412.12014v1 公告类型：新
摘要：在本文中，我们提出了深度对比表示学习框架中无监督风险的泛化界限，该框架使用深度神经网络作为表示函数。我们从两个角度来解决这个问题。一方面，我们推导出一个参数计数界限，该界限随神经网络的整体大小而变化。另一方面，我们提供了一个基于范数的界限，该界限随神经网络权重矩阵的范数而变化。忽略对数因子，界限与 $k$（对比学习提供的元组的大小）无关。据我们所知，只有另一项工作具有这一特性，该工作采用了不同的证明策略，并且由于使用了剥离技术，网络深度具有非常强的指数依赖性。我们的结果通过利用覆盖样本上均匀范数的强大结果来规避这个问题。此外，我们利用损失增强技术进一步减少对矩阵范数的依赖以及对网络深度的隐性依赖。事实上，我们的技术使我们能够为对比学习设置产生许多界限，其架构依赖性与研究普通损失函数的样本复杂性时类似，从而弥合对比学习和 DNN 的学习理论之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2412.12014</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>米高梅：通过全球视角理解受众重叠图，预测新闻媒体的真实性和偏见</title>
      <link>https://arxiv.org/abs/2412.10467</link>
      <description><![CDATA[arXiv:2412.10467v1 公告类型：交叉 
摘要：在当今数字数据快速增长的时代，评估新闻媒体的政治偏见和真实性对于在线寻找可靠信息变得更加重要。在这项工作中，我们从政治偏见和真实性的角度研究了新闻媒体的分类问题。传统的分析方法，如预训练语言模型 (PLM) 和图神经网络 (GNN) 已经显示出有希望的结果，但它们面临着显著的挑战。PLM 仅关注文本特征，导致它们忽略了实体之间的复杂关系，而 GNN 通常会处理包含断开连接的组件和标签不足的媒体图。为了解决这些限制，我们提出了 MediaGraphMind (MGM)，这是变分期望最大化 (EM) 框架内的有效解决方案。MGM 不依赖有限的相邻节点，而是利用来自全局相似节点的特征、结构模式和标签信息。这样的框架不仅使 GNN 能够捕获长距离依赖关系以学习富有表现力的节点表示，而且还通过整合结构信息增强了 PLM，从而提高了两种模型的性能。大量实验证明了所提框架的有效性，并取得了新的最先进成果。此外，我们共享了包含数据集、代码和文档的存储库 1]]></description>
      <guid>https://arxiv.org/abs/2412.10467</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>阿斯彭开放喷流：为粒子物理的基础模型解锁 LHC 数据</title>
      <link>https://arxiv.org/abs/2412.10504</link>
      <description><![CDATA[arXiv:2412.10504v1 公告类型：交叉 
摘要：基础模型是在大量数据上进行预训练的深度学习模型，能够推广到多个数据集和/或下游任务。这项工作展示了大型强子对撞机 CMS 实验收集的数据如何用于预训练 HEP 基础模型。具体来说，我们介绍了 AspenOpenJets 数据集，该数据集由来自 CMS 2016 开放数据的约 1.8 亿个高 $p_T$ 喷流组成。我们展示了如何在 AspenOpenJets 上预训练 OmniJet-$\alpha$ 基础模型来提高具有显着领域转移的生成任务的性能：从模拟的 JetClass 数据集生成增强的顶部和 QCD 喷流。除了展示在实际质子-质子碰撞数据上预训练基于喷流的基础模型的强大功能外，我们还提供了 ML 就绪的派生 AspenOpenJets 数据集供进一步公开使用。]]></description>
      <guid>https://arxiv.org/abs/2412.10504</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从分布中进行差异化隐私多重采样</title>
      <link>https://arxiv.org/abs/2412.10512</link>
      <description><![CDATA[arXiv:2412.10512v1 公告类型：交叉 
摘要：已经开发了许多算法来估计受差分隐私 (DP) 约束的概率分布：这种算法将来自分布的独立样本作为输入，并以对任何一个样本不敏感的方式估计密度函数。最近由 Raskhodnikova 等人 (Neurips &#39;21) 发起的一项工作探索了一个较弱的目标：一种近似分布中单个样本的差分隐私算法。Raskhodnikova 等人研究了 DP \emph{单次采样} 的样本复杂度，即执行此任务所需的最小样本数。他们表明，对于某些分布类，DP 单次采样的样本复杂度小于 DP 学习的样本复杂度。我们定义了 \emph{多次采样} 的两种变体，其目标是私下近似 $m&gt;1$ 个样本。这更好地模拟了需要合成数据进行探索性数据分析的现实场景。
\emph{多重采样} 的基本解决方案是在独立绘制的样本数据集上调用单次采样算法 $m$ 次。当数据来自有限域时，我们将样本复杂度提高到基线的 $m$ 倍。当数据来自高斯时，Ghazi 等人 (Neurips &#39;23) 表明，\emph{单次采样} 可以在近似差分隐私下执行；我们表明，可以 \emph{对已知协方差的高斯进行单次和多次采样，但要服从纯差分隐私}。我们的解决方案使用了拉普拉斯机制的变体，这是独立感兴趣的。
我们还给出了样本复杂度下限，一个用于有限分布的强多重采样，另一个用于有界协方差高斯的弱多重采样。]]></description>
      <guid>https://arxiv.org/abs/2412.10512</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>识别影响未来的预测：检测数据流中的表现概念漂移</title>
      <link>https://arxiv.org/abs/2412.10545</link>
      <description><![CDATA[arXiv:2412.10545v1 公告类型：交叉 
摘要：概念漂移已在流学习的背景下得到广泛研究。然而，人们通常认为部署模型的预测在系统经历的概念漂移中不起作用。仔细检查发现情况并非总是如此。自动交易可能容易出现自我实现的反馈循环。同样，恶意实体可能会适应在对抗环境中逃避检测器，从而导致自我否定的反馈循环，这需要部署的模型不断地重新训练。模型可能引起概念漂移的这种设置称为执行性的。在这项工作中，我们调查了这种现象。我们的贡献如下：首先，我们在流学习环境中定义了执行性漂移，并将其与其他漂移原因区分开来。我们引入了一种新型的漂移检测任务，旨在识别数据流中潜在的执行性概念漂移。我们提出了第一种这样的执行性漂移检测方法，称为 CheckerBoard 执行性漂移检测 (CB-PDD)。我们将 CB-PDD 应用于表现出不同程度的自我实现反馈循环的合成和半合成数据集。结果是积极的，CB-PDD 表现出高效率、低误检率、对内在漂移的弹性、与其他漂移检测技术的可比性以及有效检测半合成数据集中性能漂移的能力。其次，我们强调了内在（传统）漂移在混淆性能漂移方面的作用，并讨论了这些发现的含义以及 CB-PDD 的局限性。]]></description>
      <guid>https://arxiv.org/abs/2412.10545</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>