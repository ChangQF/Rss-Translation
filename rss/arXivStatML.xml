<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 23 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>方差无穷大随机梯度下降的极限定理</title>
      <link>https://arxiv.org/abs/2410.16340</link>
      <description><![CDATA[arXiv:2410.16340v1 公告类型：新
摘要：随机梯度下降是一种经典算法，在过去几十年中，它作为机器学习中训练模型的最常见方法而广受欢迎。虽然在假设随机梯度具有有限方差的情况下，该算法已经得到充分研究，但在无限方差梯度的情况下，关于其理论性质的研究却少得多。在本文中，我们在无限方差随机梯度的背景下建立了随机梯度下降的渐近行为，假设随机梯度是随指标 $\alpha\in(1,2)$ 规则变化的。在这种情况下，最接近的结果是在 1969 年建立的，在一维情况下，假设随机梯度属于更严格的分布类。我们将其扩展到多维情况，涵盖更广泛的无限方差分布类。正如我们所展示的，随机梯度下降算法的渐近分布可以表征为由适当的稳定 L\&#39;evy 过程驱动的适当定义的 Ornstein-Uhlenbeck 过程的平稳分布。此外，我们还探索了这些结果在线性回归和逻辑回归模型中的应用。]]></description>
      <guid>https://arxiv.org/abs/2410.16340</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推理缩放定律的简单模型</title>
      <link>https://arxiv.org/abs/2410.16377</link>
      <description><![CDATA[arXiv:2410.16377v1 公告类型：新
摘要：神经缩放定律因其能够预测模型性能（随着参数、数据和计算的增加而变化）而引起了人们的极大兴趣。在这项工作中，我们提出了一种基于记忆的简单统计假设，以研究推理背景下的缩放定律，特别是通过多次推理尝试如何提高性能。我们探索覆盖率或 pass@k 指标，它衡量重复尝试的成功几率，并为大型语言模型 (LLM) 在推理任务中覆盖率的推理缩放行为的观察到的函数形式提供动机。然后，我们定义一个“推理损失”，它随着试验次数的增加而表现出幂律衰减，并将此结果与提示成本联系起来。我们通过在一个简单的生成模型上进行实验进一步测试我们的构造，并发现我们的预测与受控环境中的经验覆盖曲线一致。我们的简单框架为将推理缩放与其他已知缩放定律结合起来奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2410.16377</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用自回归模型进行多元传感器时间序列数据增强及其在故障预测中的应用</title>
      <link>https://arxiv.org/abs/2410.16419</link>
      <description><![CDATA[arXiv:2410.16419v1 公告类型：新
摘要：这项工作提出了一种用于非平稳多元时间序列的新型数据增强解决方案及其在故障预测中的应用。该方法扩展了作者之前基于时变自回归过程的工作。它可用于从有限数量的样本中提取关键信息并生成新的合成样本，从而可能提高 PHM 解决方案的性能。这在数据稀缺的情况下尤其有价值，这在 PHM 中非常常见，尤其是对于故障预测。所提出的方法基于 CMAPSS 数据集进行测试，该数据集通常用于预测实验和基准测试。来自 PHM 文献的 AutoML 方法用于自动化预测解决方案的设计。实证评估提供了证据，表明所提出的方法可以显着提高 PHM 解决方案的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.16419</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BI-EqNO：具有等变神经算子框架的广义近似贝叶斯推理</title>
      <link>https://arxiv.org/abs/2410.16420</link>
      <description><![CDATA[arXiv:2410.16420v1 公告类型：新
摘要：贝叶斯推理提供了一个强大的框架，可以使用贝叶斯定理根据新数据更新先验信念，但精确推理通常在计算上不可行，需要近似方法。虽然这些方法被广泛使用，但它们很难准确估计边际似然，特别是由于高斯过程等确定性模型的刚性函数结构以及集合卡尔曼方法等随机模型中样本量较小的限制。在这项工作中，我们引入了 BI-EqNO，这是一种用于广义近似贝叶斯推理的等变神经算子框架，旨在增强确定性和随机性方法。BI-EqNO 通过数据驱动的训练将先验转化为以观察数据为条件的后验。该框架非常灵活，支持具有任意离散化和不同数量观测值的多种先验和后验表示。至关重要的是，BI-EqNO 的架构确保 (1) 先验和后验表示之间的置换等方差，以及 (2) 相对于观测数据的置换不变性。我们通过两个示例展示了 BI-EqNO 的实用性：(1) 作为回归的广义高斯过程 (gGP)，以及 (2) 作为顺序数据同化的集合神经滤波器 (EnNF)。结果表明，gGP 通过提供更灵活的协方差函数表示而优于传统的高斯过程。此外，EnNF 不仅在小型集合设置中优于集合卡尔曼滤波器，而且还有可能充当“超级”集合滤波器，能够表示和集成多个集合滤波器以增强同化性能。这项研究强调了 BI-EqNO 的多功能性和有效性，通过数据驱动的训练改进了贝叶斯推理，同时降低了各种应用程序的计算成本。]]></description>
      <guid>https://arxiv.org/abs/2410.16420</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高维多指标模型的鲁棒特征学习</title>
      <link>https://arxiv.org/abs/2410.16449</link>
      <description><![CDATA[arXiv:2410.16449v1 公告类型：新
摘要：最近，有大量关于使用神经网络进行特征学习的研究，特别是学习单指标和多指标模型，其中目标是输入的低维投影的函数。先前的研究表明，在高维度中，大部分计算和数据资源都用于恢复低维投影；一旦恢复了这个子空间，就可以独立于环境维度学习目标的其余部分。然而，特征学习在对抗环境中的含义仍未得到探索。在这项工作中，我们迈出了理解使用神经网络进行对抗性鲁棒特征学习的第一步。具体来说，我们证明，假设多指标坐标在统计上独立于其余坐标，多指标模型的隐藏方向提供了贝叶斯最优低维投影，以在平方损失下对 $\ell_2$ 有界对抗性扰动具有鲁棒性。因此，稳健学习可以通过首先执行标准特征学习，然后在标准表示之上稳健地调整线性读出层来实现。具体来说，我们表明对抗稳健学习与标准学习一样简单，因为与标准学习相比，稳健学习多指标模型所需的额外样本数量并不依赖于维数。]]></description>
      <guid>https://arxiv.org/abs/2410.16449</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用近似消息传递构建共形预测区间</title>
      <link>https://arxiv.org/abs/2410.16493</link>
      <description><![CDATA[arXiv:2410.16493v1 公告类型：新
摘要：共形预测已成为一种强大的工具，可用于以无分布的方式构建有效的预测区间。然而，它的评估可能在计算上很昂贵，特别是在高维设置中，其中维数和样本大小都很大且数量级相当。为了在广义线性回归的背景下解决这一挑战，我们提出了一种基于近似消息传递 (AMP) 的新算法，通过近似计算一致性分数来加速使用完全共形预测计算预测区间。我们的工作弥补了现代不确定性量化技术与涉及 AMP 算法的高维问题工具之间的差距。我们在合成数据和真实数据上评估了我们的方法，并表明它产生的预测区间接近基线方法，同时速度提高了几个数量级。此外，在高维极限和对数据分布的假设下，AMP 计算的一致性分数收敛到精确计算的分数，这允许对高维中的共形方法进行理论研究和基准测试。]]></description>
      <guid>https://arxiv.org/abs/2410.16493</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>条件双样本检验的一般框架</title>
      <link>https://arxiv.org/abs/2410.16636</link>
      <description><![CDATA[arXiv:2410.16636v1 公告类型：新
摘要：我们研究条件双样本测试的问题，该问题旨在确定在考虑混杂因素后两个总体是否具有相同的分布。这个问题通常出现在各种应用中，例如领域适应和算法公平性，在这些应用中，比较两个组在控制混杂变量的同时是必不可少的。我们首先建立条件双样本测试的硬度结果，证明没有适当的假设，任何有效的测试都不可能对任何单一替代方案具有显着的效力。然后，我们介绍两个通用框架，它们隐式或显式地针对特定类别的分布的有效性和效力。我们的第一个框架允许我们以黑盒方式将任何条件独立性测试转换为条件双样本测试，同时保留原始条件独立性测试的渐近性质。第二个框架将问题转化为比较边际分布与估计的密度比，这使我们能够利用现有的边际双样本测试方法。我们用分类和基于核的方法以具体的方式证明了这个想法。最后，进行模拟研究以说明有限样本场景中提出的框架。]]></description>
      <guid>https://arxiv.org/abs/2410.16636</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>时变核化赌博机的下限</title>
      <link>https://arxiv.org/abs/2410.16692</link>
      <description><![CDATA[arXiv:2410.16692v1 公告类型：新
摘要：具有噪声观测的黑盒函数的优化是一个具有广泛应用的基本问题，并且在假设函数位于再生核希尔伯特空间 (RKHS) 下得到了广泛的研究。这个问题已经在平稳环境中得到了广泛的研究，并且通过上界和下界的发展可以知道近似最优的遗憾界限。在本文中，我们考虑非平稳场景，这对于某些应用至关重要，但目前不太为人所知。具体而言，我们提供了第一个与算法无关的下界，其中时间变化取决于根据某些函数范数满足总变化预算。在 $\ell_{\infty}$ 范数变化下，我们的界限被发现接近最先进的上限 (Hong \emph{et al.}, 2023)。在 RKHS 规范变化下，上限和下限仍然相当接近，但差距较大，这引发了一个有趣的悬而未决的问题，即上限是否有可能进行非微小的改进。]]></description>
      <guid>https://arxiv.org/abs/2410.16692</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变分自动编码器的理论收敛保证</title>
      <link>https://arxiv.org/abs/2410.16750</link>
      <description><![CDATA[arXiv:2410.16750v1 公告类型：新
摘要：变分自动编码器 (VAE) 是一种流行的生成模型，用于从复杂数据分布中进行采样。尽管它们在各种机器学习任务中取得了经验上的成功，但在理解它们的理论特性方面仍然存在重大差距，特别是在收敛保证方面。本文旨在通过为使用随机梯度下降和 Adam 算法训练的 VAE 提供非渐近收敛保证来弥合这一差距。我们得出了收敛率为 $\mathcal{O}(\log n / \sqrt{n})$，其中 $n$ 是优化算法的迭代次数，明确依赖于批量大小、变分样本数量和其他关键超参数。我们的理论分析适用于线性 VAE 和深度高斯 VAE，以及几种 VAE 变体，包括 $\beta$-VAE 和 IWAE。此外，我们通过实证研究说明了超参数对收敛的影响，为 VAE 训练的理论理解提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.16750</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生存模型：适当的评分规则和具有竞争风险的随机优化</title>
      <link>https://arxiv.org/abs/2410.16765</link>
      <description><![CDATA[arXiv:2410.16765v1 公告类型：新
摘要：在处理右删失数据时，由于观察期有限，某些结果会缺失，生存分析（称为事件发生时间分析）侧重于预测感兴趣事件发生的时间。多种结果类别会导致分类变体：预测最有可能发生的事件，即较少探索的领域，称为竞争风险。经典的竞争风险模型将架构和损失结合在一起，限制了可扩展性。为了解决这些问题，我们设计了一个严格适当的审查调整可分离评分规则，允许在独立评估每个观察结果时对数据子集进行优化。损失估计结果概率并实现竞争风险的随机优化，我们将其用于高效的梯度提升树。 SurvivalBoost 不仅在 4 个真实数据集的多个指标上超越了 12 个最先进的模型（无论是在竞争风险还是生存环境中），而且还提供了出色的校准能力、在任何时间范围内进行预测的能力以及比现有方法更快的计算时间。]]></description>
      <guid>https://arxiv.org/abs/2410.16765</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联邦因果推理：超越元分析的多中心 ATE 估计</title>
      <link>https://arxiv.org/abs/2410.16870</link>
      <description><![CDATA[arXiv:2410.16870v1 公告类型：新
摘要：我们研究联邦因果推理，这是一种从跨中心分散数据估计治疗效果的方法。我们比较了从插件 G 公式中得出的三类平均治疗效果 (ATE) 估计量，从简单的元分析到一次性和多次联邦学习，后者利用完整数据来学习结果模型（尽管需要更多通信）。专注于随机对照试验 (RCT)，我们推导出这些估计量的线性模型渐近方差。我们的结果为选择适合各种场景的合适估计量提供了实用指导，包括样本大小的异质性、协变量分布、治疗分配方案和中心效应。我们通过模拟研究验证了这些发现。]]></description>
      <guid>https://arxiv.org/abs/2410.16870</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过平均场分析理解迁移学习</title>
      <link>https://arxiv.org/abs/2410.17128</link>
      <description><![CDATA[arXiv:2410.17128v1 公告类型：新
摘要：我们提出了一种新颖的框架，通过概率测度空间上的微积分来探索迁移学习的泛化误差。特别是，我们考虑了两种主要的迁移学习场景，即$\alpha$-ERM 和使用 KL 正则化经验风险最小化进行微调，并建立了通​​用条件，在这些条件下研究了这些场景的泛化误差和总体风险收敛率。基于我们的理论结果，我们展示了在损失和激活函数的一些合适的可积性和规律性假设下，在均值场范围内使用单隐层神经网络进行迁移学习的好处。]]></description>
      <guid>https://arxiv.org/abs/2410.17128</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 识别平均场动力学</title>
      <link>https://arxiv.org/abs/2410.16295</link>
      <description><![CDATA[arXiv:2410.16295v1 公告类型：交叉 
摘要：本文研究了使用变压器架构来近似表现出集体行为的相互作用粒子系统的平均场动力学。此类系统是建模物理学、生物学和工程学现象的基础，包括气体动力学、意见形成、生物网络和群体机器人。这些系统的主要特征是粒子是不可区分的，从而导致置换等变动力学。我们证明，变压器本身具有置换等变性，非常适合近似这些动力学。具体而言，我们证明，如果有限维变压器可以有效地近似控制粒子系统的有限维矢量场，那么该变压器的预期输出可以为无限维平均场矢量场提供良好的近似值。利用这一结果，我们建立了真实平均场动力学与使用变压器获得的平均场动力学之间距离的理论界限。我们通过对群集的 Cucker-Smale 模型和用于训练双层神经网络的平均场系统进行数值模拟来验证我们的理论发现。]]></description>
      <guid>https://arxiv.org/abs/2410.16295</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过锐度最小化的全局收敛解决简单性偏差</title>
      <link>https://arxiv.org/abs/2410.16401</link>
      <description><![CDATA[arXiv:2410.16401v1 公告类型：交叉 
摘要：神经网络卓越的泛化能力通常归因于 SGD 的隐性偏差，它通常使用更简单（例如线性）和低秩特征产生复杂度较低的模型。最近的研究为 SGD 的特定变体（例如标签噪声 SGD）偏向损失景观的较平坦区域提供了经验和理论证据。尽管民间直觉认为平坦的解决方案是“简单的”，但与最终训练模型（例如低秩）的简单性之间的联系尚不清楚。在这项工作中，我们通过研究一类两层神经网络的锐度最小化器产生的简单性结构，朝着弥合这一差距迈出了一步。我们表明，对于任何高维训练数据和某些激活，在步长足够小的情况下，标签噪声 SGD 总是收敛到一个在所有神经元上复制单个线性特征的网络；从而意味着一个简单的秩一特征矩阵。为了获得这个结果，我们的主要技术贡献是表明标签噪声 SGD 总是最小化零损失两层网络模型流形上的锐度。在此过程中，我们发现了零损失流形上近似驻点处 Hessian 损失迹的一个新特性——局部测地凸性，它将锐度与流形的几何形状联系起来。这个工具可能具有独立的兴趣。]]></description>
      <guid>https://arxiv.org/abs/2410.16401</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有限样本和无分布公平分类：过度风险与公平性之间的最优权衡以及群体失明的成本</title>
      <link>https://arxiv.org/abs/2410.16477</link>
      <description><![CDATA[arXiv:2410.16477v1 公告类型：交叉 
摘要：机器学习中的算法公平性最近引起了广泛关注。然而，仍然存在两个紧迫的挑战：（1）现有公平分类方法的公平性保证通常依赖于特定的数据分布假设和大样本量，这在样本量适中时可能导致公平性违规——这在实践中很常见。（2）出于法律和社会考虑，在决策过程中使用敏感的群体属性（称为群体盲目设置）可能并不总是可行的。
在这项工作中，我们量化了在群体公平约束下在二元分类中强制执行算法公平性和群体盲目的影响。具体而言，我们提出了一个统一的公平分类框架，该框架提供无分布和有限样本公平性保证，并控制超额风险。该框架适用于群体感知和群体盲目场景中的各种群体公平概念。此外，我们建立了超额风险的极小极大下界，表明我们提出的算法在对数因子范围内具有极小极大最优性。通过大量的模拟研究和真实数据分析，我们进一步证明了我们的算法与现有方法相比的优越性能，并为我们的理论发现提供了实证支持。]]></description>
      <guid>https://arxiv.org/abs/2410.16477</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>