<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 04 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用多个替代指标估计治疗效果：替代评分和替代指数的作用</title>
      <link>https://arxiv.org/abs/1603.09326</link>
      <description><![CDATA[arXiv:1603.09326v4 公告类型：replace-cross
摘要：估计治疗的长期效果引起了许多领域的兴趣。估计此类治疗效果的一个常见挑战是，在做出政策决策所需的时间范围内无法观察到长期结果。克服数据缺失问题的一种方法是分析治疗对中间结果（通常称为统计替代）的影响，如果它满足治疗和结果独立于统计替代的条件。代孕条件的有效性常常存在争议。在这里，我们利用了这样一个事实：在现代数据集中，研究人员经常观察到大量（可能是数百或数千）中间结果，这些中间结果被认为位于或接近治疗与感兴趣的长期结果之间的因果链。即使没有一个单独的代理本身满足统计替代标准，使用多个代理在因果推断中也很有用。我们主要关注具有两个样本的设置，一个实验样本包含有关治疗指标和替代指标的数据，一个观察样本包含有关替代指标和主要结果的信息。我们提出了这样的假设，即使用共同满足替代假设的高维代理向量来识别和估计平均治疗效果，并从违反替代假设的情况中得出偏差，并表明即使也观察到了主要结果在实验样本中，仍然可以通过使用替代物来获取信息。]]></description>
      <guid>https://arxiv.org/abs/1603.09326</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>Atari 基于模型的强化学习</title>
      <link>https://arxiv.org/abs/1903.00374</link>
      <description><![CDATA[arXiv:1903.00374v5 公告类型：replace-cross
摘要：无模型强化学习（RL）可用于学习复杂任务的有效策略，例如 Atari 游戏，甚至可以从图像观察中学习。然而，这通常需要大量的交互——事实上，比人类学习相同游戏所需的交互要多得多。人们怎么能学得这么快呢？部分答案可能是人们可以了解游戏的运作方式并预测哪些行动会带来理想的结果。在本文中，我们探讨了视频预测模型如何同样使代理能够以比无模型方法更少的交互来解决 Atari 游戏。我们描述了模拟策略学习 (SimPLe)，这是一种基于视频预测模型的完整的基于模型的深度 RL 算法，并比较了几种模型架构，包括在我们的设置中产生最佳结果的新颖架构。我们的实验在代理与环境之间进行 10 万次交互（相当于两个小时的实时游戏）的低数据状态下，在一系列 Atari 游戏上评估了 SimPLe。在大多数游戏中，SimPLe 的性能优于最先进的无模型算法，在某些游戏中超出一个数量级。]]></description>
      <guid>https://arxiv.org/abs/1903.00374</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>Shapley 曲线：平滑视角</title>
      <link>https://arxiv.org/abs/2211.13289</link>
      <description><![CDATA[arXiv:2211.13289v5 公告类型：替换
摘要：本文从非参数（或平滑）角度填补了对沙普利值作为变量重要性度量的有限统计理解。我们引入总体水平 \textit{Shapley 曲线} 来衡量真实变量的重要性，由条件期望函数和协变量的分布决定。定义了估计量后，我们得出了两种主要估计策略在一般条件下的极小极大收敛率和渐近正态性。对于有限样本推理，我们提出了一种新版本的狂野引导程序，专门用于捕获沙普利曲线估计中的低阶项。数值研究证实了我们的理论发现，并通过实证应用分析了汽车价格的决定因素。]]></description>
      <guid>https://arxiv.org/abs/2211.13289</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>相信你的$\nabla$：基于梯度的干预目标以发现因果关系</title>
      <link>https://arxiv.org/abs/2211.13715</link>
      <description><![CDATA[arXiv:2211.13715v5 公告类型：替换
摘要：从数据推断因果结构是科学中一项具有根本重要性的挑战性任务。观测数据通常不足以唯一地识别系统的因果结构。虽然进行干预（即实验）可以提高可识别性，但此类样本通常具有挑战性且获取成本昂贵。因此，因果发现的实验设计方法旨在通过估计信息最丰富的干预目标来最大限度地减少干预数量。在这项工作中，我们提出了一种新颖的基于梯度的干预目标方法，缩写为 GIT，该方法“信任”基于梯度的因果发现框架的梯度估计器，为干预获取功能提供信号。我们在模拟和真实数据集中提供了广泛的实验，并证明 GIT 的性能与竞争基线相当，在低数据情况下超越了它们。]]></description>
      <guid>https://arxiv.org/abs/2211.13715</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>分布式学习中稀疏通信的全局动量压缩</title>
      <link>https://arxiv.org/abs/1905.12948</link>
      <description><![CDATA[arXiv:1905.12948v3 公告类型：替换
摘要：随着数据的快速增长，分布式动量随机梯度下降~（DMSGD）已广泛应用于分布式学习，特别是用于训练大规模深度模型。由于网络的延迟和有限的带宽，通信成为分布式学习的瓶颈。稀疏梯度通信压缩，缩写为\emph{稀疏通信}，已被广泛采用来降低通信成本。所有关于 DMSGD 中稀疏通信的现有工作都采用局部动量，其中动量仅累积每个工作人员在本地计算的随机梯度。在本文中，我们提出了一种用于稀疏通信的新颖方法，称为 \emph{\underline{g}}lobal \emph{\underline{m}}omentum \emph{\underline{c}}ompression~(GMC)。与现有的利用本土动力的作品不同，GMC利用的是全球动力。此外，为了增强使用更激进的稀疏压缩器（例如 RBGS）时的收敛性能，我们将 GMC 扩展到 GMC+。我们从理论上证明了GMC和GMC+的收敛性。据我们所知，这是第一篇在分布式学习中引入稀疏通信全局动力的工作。实证结果表明，与局部动量对应物相比，我们的 GMC 和 GMC+ 可以实现更高的测试精度并表现出更快的收敛速度，特别是在非 IID 数据分布下。]]></description>
      <guid>https://arxiv.org/abs/1905.12948</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:38 GMT</pubDate>
    </item>
    <item>
      <title>海量医疗数据记录插补的多级随机优化</title>
      <link>https://arxiv.org/abs/2110.09680</link>
      <description><![CDATA[arXiv:2110.09680v3 公告类型：替换
摘要：长期以来，许多数据集都包含大量缺失的数值数据，这已成为一个公认的问题。将机器学习方法应用于数据集的一个潜在关键谓词涉及解决这个问题。然而，这是一项具有挑战性的任务。在本文中，我们应用最近开发的多级随机优化方法来解决海量医疗记录中的插补问题。该方法基于计算应用数学技术，并且非常准确。特别是，对于最佳线性无偏预测器 (BLUP)，这种多级公式是准确的，并且速度明显更快且数值更稳定。这使得克里格方法能够实际应用于大规模数据集的数据插补问题。我们使用来自国家住院样本 (NIS) 数据记录、医疗保健成本和利用项目 (HCUP)、医疗保健研究和质量机构的数据测试了这种方法。数值结果表明，多级方法明显优于当前方法并且在数值上具有鲁棒性。与 HCUP 最近报告中推荐的方法相比，它具有更高的准确性。基准测试显示错误率降低了 75%。此外，结果也优于最近最先进的方法，例如判别式深度学习。]]></description>
      <guid>https://arxiv.org/abs/2110.09680</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:38 GMT</pubDate>
    </item>
    <item>
      <title>通过 Hammersley-Chapman-Robbins 界限保证机密性</title>
      <link>https://arxiv.org/abs/2404.02866</link>
      <description><![CDATA[arXiv:2404.02866v1 公告类型：交叉
摘要：通过在最终分类器或其他特定任务层之前的最后一层的激活中添加噪声，可以在深度神经网络推理过程中保护隐私。这些层中的激活被称为“特征”（或者不太常见的是“嵌入”或“特征嵌入”）。添加的噪声有助于防止从噪声特征重建输入。输入的每个可能的无偏估计量的方差的下限量化了由这种添加的噪声引起的机密性。方便的、计算上易于处理的界限可以从 Hammersley 以及 Chapman 和 Robbins 的经典不等式中获得——HCR 界限。数值实验表明，HCR 界限即将对具有数据集“MNIST”和“CIFAR-10”的小型神经网络有效，其中每个数据集包含 10 个用于图像分类的类别。 HCR 界限本身似乎不足以保证使用标准深度神经网络“ResNet-18”和“Swin-T”（在数据集“ImageNet-1000”上进行预训练）的推理输入的机密性，其中包含 1000 个类。在 ImageNet 的情况下，可能需要使用其他方法来补充向特征添加噪声以提供机密性。在所有情况下，此处报告的结果限制了对添加噪声量的考虑，这些噪声量几乎不会降低噪声特征的分类准确性。因此，添加的噪声增强了机密性，而不会大幅降低图像分类任务的准确性。]]></description>
      <guid>https://arxiv.org/abs/2404.02866</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:37 GMT</pubDate>
    </item>
    <item>
      <title>从叙述到数字：使用来自口头尸检叙述的语言模型预测进行有效推理</title>
      <link>https://arxiv.org/abs/2404.02438</link>
      <description><![CDATA[arXiv:2404.02438v1 公告类型：交叉
摘要：在大多数死亡发生在医疗保健系统之外的环境中，口头尸检（VA）是监测死因（COD）趋势的常用工具。 VA 是对幸存的照顾者或亲属的访谈，用于预测死者的 COD。将 VA 转化为研究人员和政策制定者可操作的见解需要两个步骤（i）使用 VA 访谈来预测可能的 COD，以及（ii）对预测的 COD 进行推理（例如，使用死亡样本对按人口因素划分的原因进行建模）。在本文中，我们开发了一种使用最先进的 NLP 技术从自由格式文本预测的结果（在我们的例子中为 COD）进行有效推理的方法。这种方法，我们称之为 multiPPI++，将“预测驱动的推理”领域的最新工作扩展到了多项分类。我们利用一套 NLP 技术进行 COD 预测，并通过 VA 数据的实证分析，证明我们的方法在处理可运输性问题方面的有效性。无论哪个 NLP 模型生成预测，也无论它们是由更准确的预测器（如 GPT-4-32k）还是由不太准确的预测器（如 KNN）生成，multiPPI++ 都会恢复真实估计。我们的研究结果证明了推理校正对公共卫生决策的实际重要性，并表明如果推理任务是最终目标，那么无论 NLP 算法如何，拥有少量上下文相关的高质量标记数据都是必不可少的。]]></description>
      <guid>https://arxiv.org/abs/2404.02438</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:36 GMT</pubDate>
    </item>
    <item>
      <title>通过使用白盒变压器的结构化扩散进行掩蔽完成</title>
      <link>https://arxiv.org/abs/2404.02446</link>
      <description><![CDATA[arXiv:2404.02446v1 公告类型：交叉
摘要：现代学习框架通常使用大量未标记数据来训练深度神经网络，通过解决简单的借口任务来学习表示，然后使用这些表示作为下游任务的基础。这些网络是根据经验设计的；因此，它们通常是不可解释的，它们的表示没有结构化，并且它们的设计可能是多余的。白盒深度网络中的每一层都明确地识别和转换数据中的结构，提供了一种有前途的替代方案。然而，现有的白盒架构仅被证明可以在带有标记数据（例如分类）的监督环境中大规模工作。在这项工作中，我们提供了可应用于大规模无监督表示学习的白盒设计范例的第一个实例。我们通过利用扩散、压缩和（屏蔽）完成之间的基本联系来实现这一点，派生出一种类似于深度变压器的屏蔽自动编码器架构，称为 CRATE-MAE，其中每一层的作用在数学上都是完全可解释的：它们转换数据与结构化表示之间的分配。广泛的实证评估证实了我们的分析见解。与具有相同模型配置的标准屏蔽自动编码器相比，CRATE-MAE 在大规模图像数据集上展示了非常有前景的性能，同时仅使用约 30% 的参数。 CRATE-MAE 学习到的表示具有明确的结构，也包含语义。代码可在 https://github.com/Ma-Lab-Berkeley/CRATE 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.02446</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:36 GMT</pubDate>
    </item>
    <item>
      <title>自适应抽样策略意味着有偏见的信念：热风炉效应的概括</title>
      <link>https://arxiv.org/abs/2404.02591</link>
      <description><![CDATA[arXiv:2404.02591v1 公告类型：交叉
摘要：热炉效应是由于学习的适应性特征而产生的一种消极偏差。其机制是，追求具有正估计值的替代方案，但避免具有负估计值的替代方案的学习算法将纠正高估错误，但无法纠正低估错误。在这里，我们将“热炉效应”背后的理论推广到这样的环境：负估计不一定会导致回避，而是会导致较小的样本量（即，如果 B 被认为较差但又不完全有效，则学习者会选择较少的替代 B）避免 B）。我们正式证明了这种设置中仍然存在消极偏见。我们还表明，贝叶斯学习者存在消极偏见，因为大多数此类学习者低估了替代方案的预期价值。]]></description>
      <guid>https://arxiv.org/abs/2404.02591</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:36 GMT</pubDate>
    </item>
    <item>
      <title>分布式和速率自适应特征压缩</title>
      <link>https://arxiv.org/abs/2404.02179</link>
      <description><![CDATA[arXiv:2404.02179v1 公告类型：交叉
摘要：我们研究线性回归的分布式和速率自适应特征压缩问题。一组分布式传感器收集回归数据的不相交特征。假设融合中心包含预训练的线性回归模型，在整个未压缩数据的数据集上进行训练。在推理时，传感器压缩其观测结果，并通过通信受限的通道将其发送到融合中心，其速率可能随时间变化。我们的目标是设计一种特征压缩{方案}，能够适应不同的通信约束，同时最大限度地提高融合中心的推理性能。我们首先假设了解底层回归数据分布，获得最佳量化器的形式。在实际合理的近似下，我们提出了一种分布式压缩方案，该方案通过量化传感器数据的一维投影来工作。我们还提出了一种简单的自适应方案来处理通信约束的变化。我们通过模拟实验证明了分布式自适应压缩方案的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.02179</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:35 GMT</pubDate>
    </item>
    <item>
      <title>使用期权隐含信息和深度学习改进多资产期权的无模型边界</title>
      <link>https://arxiv.org/abs/2404.02343</link>
      <description><![CDATA[arXiv:2404.02343v1 公告类型：交叉
摘要：我们考虑在将依赖不确定性与依赖结构的附加信息相结合的设置中计算多资产期权的无模型边界。更具体地说，我们考虑边际分布已知的情况，并且市场上也可以获得多资产期权已知价格形式的部分信息。我们在这种情况下提供了资产定价的基本定理，以及超级对冲二元性，允许将概率度量的最大化问题转化为更容易处理的交易策略的最小化问题。后者是通过结合使用人工神经网络的深度学习近似的惩罚方法来解决的。数值方法速度快，计算时间与交易资产数量呈线性关系。我们最后检查了各种附加信息的重要性。经验证据表明，“相关”信息，即与目标收益具有相同收益结构的衍生品价格，比其他信息更有用，并且应考虑到准确性和计算效率之间的权衡而优先考虑。]]></description>
      <guid>https://arxiv.org/abs/2404.02343</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:35 GMT</pubDate>
    </item>
    <item>
      <title>具有软不等式和单调性约束的高斯过程回归</title>
      <link>https://arxiv.org/abs/2404.02873</link>
      <description><![CDATA[arXiv:2404.02873v1 公告类型：新
摘要：高斯过程（GP）回归是一种非参数贝叶斯框架，用于逼近复杂模型。标准 GP 回归可能会导致无界模型，其中某些点可能取不可行的值。我们引入了一种新的 GP 方法，该方法以概率方式强制实施物理约束。该 GP 模型由受量子启发的哈密顿蒙特卡罗 (QHMC) 进行训练。 QHMC 是从广泛的分布类别中进行采样的有效方法。与粒子具有固定质量的标准哈密顿蒙特卡罗算法不同，QHMC 允许粒子具有具有概率分布的随机质量矩阵。将 QHMC 方法引入到概率意义上的不等式和单调性约束 GP 回归中，我们的方法提高了所得 GP 模型的准确性并减少了方差。根据我们对多个数据集的实验，所提出的方法是一种有效的方法，因为它在保持精度的同时加速了采样过程，并且适用于高维问题。]]></description>
      <guid>https://arxiv.org/abs/2404.02873</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>关于多模态和单模态机器学习之间更强的计算分离</title>
      <link>https://arxiv.org/abs/2404.02254</link>
      <description><![CDATA[arXiv:2404.02254v1 公告类型：新
摘要：在多模态机器学习中，多种数据模态（例如文本和图像）被组合起来，以促进更好的机器学习模型的学习，该模型仍然适用于相应的单模态任务（例如文本生成）。最近，多模态机器学习取得了巨大的实证成功（例如 GPT-4）。 Lu (NeurIPS &#39;23, ALT &#39;24) 致力于为这一实证成功发展理论依据，引入了多模态学习理论，并考虑了多模态学习和单模态学习理论模型之间可能的分离。特别是，Lu (ALT &#39;24) 显示了计算分离，这与学习任务的最坏情况实例相关。
  在本文中，我们给出了更强的平均情况计算分离，其中对于学习任务的“典型”实例，单模态学习在计算上很困难，但多模态学习很容易。然后我们质疑平均情况分离的“有机”程度。实际中会遇到吗？为此，我们证明在自然条件下，平均情况单模态和多模态学习任务之间的任何给定计算分离都意味着相应的加密密钥协商协议。我们建议将此解释为证据，表明多模态学习的非常强的计算优势在实践中可能很少出现，因为它们仅存在于固有密码分布的“病态”情况下。然而，这不适用于可能的（超多项式）统计优势。]]></description>
      <guid>https://arxiv.org/abs/2404.02254</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>潜在空间中变压器流匹配的收敛性分析</title>
      <link>https://arxiv.org/abs/2404.02538</link>
      <description><![CDATA[arXiv:2404.02538v1 公告类型：新
摘要：我们提出了基于 ODE 的生成模型（特别是流匹配）的理论收敛保证。我们使用预先训练的自动编码器网络将高维原始输入映射到低维潜在空间，其中训练变压器网络来预测从标准正态分布到目标潜在分布的变换的速度场。我们的误差分析证明了这种方法的有效性，表明在温和且实用的假设下，通过估计 ODE 流生成的样本分布收敛到 Wasserstein-2 距离中的目标分布。此外，我们表明任意平滑函数可以通过具有 Lipschitz 连续性的变压器网络有效地近似，这可能是独立的兴趣。]]></description>
      <guid>https://arxiv.org/abs/2404.02538</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:33 GMT</pubDate>
    </item>
    </channel>
</rss>