<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 20 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过评分规则构建概率预测树</title>
      <link>https://arxiv.org/abs/2402.11052</link>
      <description><![CDATA[arXiv:2402.11052v1 公告类型：交叉
摘要：用数据构建的决策树仍然广泛用于非参数预测。当不确定性在分析和决策中发挥重要作用时，预测概率分布优于点预测。我们研究修改树以产生非参数预测分布。我们发现构建树的标准方法可能不会产生良好的预测分布，并建议将树的分割标准更改为基于适当的评分规则的标准。对模拟数据和几个真实数据集的分析表明，考虑到整个预测分布，使用这些新的分割标准会产生具有改进的预测属性的树。]]></description>
      <guid>https://arxiv.org/abs/2402.11052</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>使用稀疏子空间变分推理训练贝叶斯神经网络</title>
      <link>https://arxiv.org/abs/2402.11025</link>
      <description><![CDATA[arXiv:2402.11025v1 公告类型：交叉
摘要：贝叶斯神经网络（BNN）提供不确定性量化，但缺点是训练和推理成本大幅增加。稀疏 BNN 已被研究用于高效推理，通常通过在整个训练过程中缓慢引入稀疏性或通过密集 BNN 的训练后压缩来实现。如何削减大量培训成本的困境仍然存在，特别是考虑到需要了解不确定性。为了解决这一挑战，我们引入了稀疏子空间变分推理（SSVI），这是第一个完全稀疏的 BNN 框架，它在整个训练和推理阶段保持一致的高度稀疏贝叶斯模型。从随机初始化的低维稀疏子空间开始，我们的方法交替优化稀疏子空间基础选择及其相关参数。虽然基选择的特点是不可微的问题，但我们在基于权重分布统计的新标准的指导下，通过移除和添加策略来近似最佳解决方案。我们的大量实验表明，SSVI 在构建稀疏 BNN 方面树立了新的基准，例如，与密集 VI 训练相比，模型大小压缩了 10-20 倍，性能下降不到 3%，并且训练期间的 FLOPs 减少了高达 20 倍。值得注意的是，SSVI 还表现出对超参数的鲁棒性增强，减少了对 VI 进行复杂调整的需要，有时甚至在准确性和不确定性指标上超过了经过 VI 训练的密集 BNN。]]></description>
      <guid>https://arxiv.org/abs/2402.11025</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>通过域的正则化注释对带有域标签噪声的子群转移的鲁棒性</title>
      <link>https://arxiv.org/abs/2402.11039</link>
      <description><![CDATA[arXiv:2402.11039v1 公告类型：交叉
摘要：现有的最后一层再训练方法旨在优化最差组精度（WGA），这在很大程度上依赖于训练数据中注释良好的组。我们在理论和实践中都表明，使用下采样或上加权进行 WGA 的基于注释的数据增强很容易受到域注释噪声的影响，并且在高噪声情况下接近使用普通经验风险最小化训练的模型的 WGA。我们引入了域的正则化注释（RAD），以便在不需要显式域注释的情况下训练鲁棒的最后一层分类器。我们的结果表明，RAD 与其他最近提出的免域注释技术相比具有竞争力。最重要的是，即使几个公开可用数据集的训练数据中只有 5% 的噪声，RAD 的性能也优于最先进的依赖注释的方法。]]></description>
      <guid>https://arxiv.org/abs/2402.11039</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>用于端到端无监督决策树的内核 KMeans 聚类分裂</title>
      <link>https://arxiv.org/abs/2402.12232</link>
      <description><![CDATA[arXiv:2402.12232v1 公告类型：新
摘要：树是在相对较小的数据集上获得可解释预测的便捷模型。尽管有许多关于在监督学习中端到端构建此类树的建议，但端到端学习树以进行无标签聚类仍然是一个开放的挑战。由于大多数工作都集中在用树解释另一种聚类算法的结果，因此我们在这里提出一种新颖的端到端训练的无监督二叉树用于聚类：Kauri。该方法执行内核 KMeans 目标的贪婪最大化，而不需要定义质心。我们在多个数据集上将此模型与最近的无监督树进行比较，结果表明贝壳杉在使用线性内核时表现相同。对于其他内核，Kauri 通常优于内核 KMeans 和 CART 决策树的串联。]]></description>
      <guid>https://arxiv.org/abs/2402.12232</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>通过去噪进行正则化：贝叶斯模型和 Langevin-within-split Gibbs 采样</title>
      <link>https://arxiv.org/abs/2402.12292</link>
      <description><![CDATA[arXiv:2402.12292v1 公告类型：新
摘要：本文通过推导去噪正则化（RED）范式的概率对应项，介绍了图像反演的贝叶斯框架。它还实现了专门针对基于渐近精确数据增强 (AXDA) 从所得后验分布进行采样而定制的蒙特卡罗算法。所提出的算法是分割吉布斯采样 (SGS) 的近似实例，其中嵌入了一个 Langevin Monte Carlo 步骤。该方法适用于去模糊、修复和超分辨率等常见成像任务，并通过大量数值实验证明了其有效性。这些贡献通过在概率框架内利用数据驱动的正则化策略推进了成像中的贝叶斯推理。]]></description>
      <guid>https://arxiv.org/abs/2402.12292</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>谱聚类中特征向量的渐近高斯涨落</title>
      <link>https://arxiv.org/abs/2402.12302</link>
      <description><![CDATA[arXiv:2402.12302v1 公告类型：新
摘要：谱聚类的性能依赖于相似矩阵特征向量条目的波动，但迄今为止尚未对其进行表征。在这封信中，表明一般尖峰随机矩阵模型的信号$+$噪声结构被转移到相应的格拉姆核矩阵的特征向量，并且它们的条目的波动在大维范围内呈高斯分布。这种类似 CLT 的结果是精确预测谱聚类分类性能的最后一个缺失部分。所提出的证明非常笼统，仅依赖于噪声的旋转不变性。对合成数据和真实数据的数值实验说明了这种现象的普遍性。]]></description>
      <guid>https://arxiv.org/abs/2402.12302</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>离策略和在策略策略梯度方法何时一致？</title>
      <link>https://arxiv.org/abs/2402.12034</link>
      <description><![CDATA[arXiv:2402.12034v1 公告类型：新
摘要：策略梯度方法被广泛采用的强化学习算法用于具有连续动作空间的任务。这些方法在许多应用领域取得了成功，但是，由于它们臭名昭著的样本效率低下，它们的使用仍然仅限于可以进行快速和准确模拟的问题。提高样本效率的常见方法是将其目标函数修改为可从非策略样本计算而无需重要性采样。一个完善的离策略目标是偏移目标。这项工作研究了偏移目标与传统政策目标之间的差异，我们将其称为开关间隙。我们提供了第一个理论分析，显示了减少开关间隙的条件，同时建立了当这些条件不满足时出现短缺的经验证据。]]></description>
      <guid>https://arxiv.org/abs/2402.12034</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>迈向基于人工智能的精准肿瘤学：基于多组学数据的个性化反事实治疗建议的机器学习框架</title>
      <link>https://arxiv.org/abs/2402.12190</link>
      <description><![CDATA[arXiv:2402.12190v1 公告类型：新
摘要：人工智能驱动的精准肿瘤学具有通过利用人工智能模型的力量来分析复杂患者特征与其相应治疗结果之间的相互作用来重塑癌症治疗的变革潜力。新技术平台促进了以前所未有的分辨率及时获取肿瘤生物学多模态数据，例如单细胞多组学数据，使数据的质量和数量可用于数据驱动的改进临床决策。在这项工作中，我们提出了一个模块化的机器学习框架，该框架旨在基于受过不同多组学技术培训的机器学习专家团队，为个性化的反事实癌症治疗建议而设计。这些针对每种技术的专业反事实专家始终聚合成具有卓越性能的更强大的专家，可以提供对其决策的信心和解释。该框架旨在解决数据驱动的癌症研究中固有的关键挑战，包括数据的高维性质以及回顾性观察数据中存在的治疗分配偏差。该框架通过使用一组卵巢癌患者的体外和体内治疗反应数据进行综合演示来展示。我们的方法旨在为临床医生提供以现实为中心的决策支持工具，包括具有校准置信度的概率治疗建议和个性化解释，以便根据个体癌症患者的多组学特征定制治疗策略。]]></description>
      <guid>https://arxiv.org/abs/2402.12190</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>学习广义朗之万方程中的记忆核</title>
      <link>https://arxiv.org/abs/2402.11705</link>
      <description><![CDATA[arXiv:2402.11705v1 公告类型：新
摘要：我们介绍了一种在广义朗之万方程中学习记忆核的新方法。该方法最初利用正则化 Prony 方法根据轨迹数据估计相关函数，然后通过 RKHS 正则化对基于 Sobolev 范数的损失函数进行回归。我们的方法保证了指数加权 $L^2$ 空间内性能的提高，核估计误差由估计相关函数的误差控制。与依赖 $L^2$ 损失函数的其他回归估计器以及从拉普拉斯逆变换导出的估计器相比，我们证明了我们的估计器的优越性，并使用数值示例突出了其在各种权重参数选择中的一致优势。此外，我们还提供了包括在方程中应用力和漂移项的示例。]]></description>
      <guid>https://arxiv.org/abs/2402.11705</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>通过扩散模型生成的假设的统计检验</title>
      <link>https://arxiv.org/abs/2402.11789</link>
      <description><![CDATA[arXiv:2402.11789v1 公告类型：新
摘要：人工智能性能的增强加速了其与科学研究的融合。特别是，使用生成式人工智能来创建科学假设是有前景的，并且越来越多地应用于各个领域。然而，当使用人工智能生成的假设进行关键决策（例如医疗诊断）时，验证其可靠性至关重要。在本研究中，我们考虑使用扩散模型生成的图像进行医学诊断任务，并提出一种统计测试来量化其可靠性。所提出的统计测试背后的基本思想是采用选择性推理框架，其中我们考虑统计测试的条件是生成的图像是由经过训练的扩散模型生成的。使用所提出的方法，可以以 p 值的形式量化医学图像诊断结果的统计可靠性，从而可以在错误率受控的情况下做出决策。我们通过对合成数据集和大脑图像数据集的数值实验展示了所提出的统计测试的理论有效性及其有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.11789</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>李群上的随机 Hessian 拟合</title>
      <link>https://arxiv.org/abs/2402.11858</link>
      <description><![CDATA[arXiv:2402.11858v1 公告类型：新
摘要：本文研究了 Hessian 矩阵或其逆矩阵与随机 Hessian 向量积的拟合。分析采用 Hessian 拟合准则，可用于推导大多数常用方法，例如 BFGS、Gaussian-Newton、AdaGrad 等。我们的研究揭示了不同 Hessian 拟合方法的不同收敛速率，例如欧几里德空间中梯度下降的次线性速率和常用的封闭形式解、对称正定 (SPL) 矩阵流形上梯度下降的线性速率以及某些谎言团体。 Hessian 拟合问题进一步被证明在温和条件下在特定但足够普遍的李群上是强凸的。为了证实我们的分析，这些方法在不同的设置下进行了测试，例如噪声 Hessian 向量积、时变 Hessian 矩阵和低精度算术。这些发现对于依赖于快速、稳健和准确的 Hessian 估计的随机二阶优化非常有用。]]></description>
      <guid>https://arxiv.org/abs/2402.11858</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>用于调整预期改进的变分熵搜索</title>
      <link>https://arxiv.org/abs/2402.11345</link>
      <description><![CDATA[arXiv:2402.11345v1 公告类型：新
摘要：贝叶斯优化是一种广泛使用的优化黑盒函数的技术，其中预期改进（EI）是该领域最常用的采集函数。虽然 EI 通常被视为与其他信息论获取函数（例如熵搜索 (ES) 和最大值熵搜索 (MES)）不同，但我们的工作表明，当通过变分推理处理时，EI 可以被视为 MES 的特例（六）。在此背景下，我们开发了变分熵搜索 (VES) 方法和 VES-Gamma 算法，该算法通过结合信息论概念的原理来适应 EI。 VES-Gamma 的功效在各种测试函数和读取数据集中得到了证明，突出了其在贝叶斯优化场景中的理论和实践实用性。]]></description>
      <guid>https://arxiv.org/abs/2402.11345</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>基于样条拟插值的经验密度估计及其在Copulas聚类建模中的应用</title>
      <link>https://arxiv.org/abs/2402.11552</link>
      <description><![CDATA[arXiv:2402.11552v1 公告类型：新
摘要：密度估计是各个领域中使用的一项基本技术，用于建模和理解数据的基本分布。密度估计的主要目标是估计随机变量的概率密度函数。此过程在处理单变量或多变量数据时特别有价值，并且对于聚类、异常检测和生成建模等任务至关重要。在本文中，我们提出使用样条准插值的密度的单变量近似，并将其应用于聚类建模的背景下。所使用的聚类技术基于合适的多元分布的构造，该多元分布依赖于单变量经验密度（边际）的估计。这种近似是通过使用所提出的样条准插值来实现的，而对所寻求的聚类分区进行建模的联合分布是使用 copula 函数构建的。特别是，由于 copula 可以独立于边缘分布捕获数据特征之间的依赖性，因此提出了有限混合 copula 模型。所提出的算法在人工和真实数据集上进行了验证。]]></description>
      <guid>https://arxiv.org/abs/2402.11552</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>高效的低阶矩阵估计、实验设计和与臂组相关的低阶老虎机</title>
      <link>https://arxiv.org/abs/2402.11156</link>
      <description><![CDATA[arXiv:2402.11156v1 公告类型：新
摘要：我们研究了低秩矩阵迹回归和低秩矩阵老虎机的相关问题。假设可以访问协变量的分布，我们提出了一种称为 LowPopArt 的新颖的低秩矩阵估计方法，并提供其恢复保证，该保证取决于由 B(Q) 表示的新量，该量表示问题的难度，其中 Q 是测量分布的协方差矩阵。我们证明，在几个问题中，我们的方法可以提供比经典核范数惩罚最小二乘法（Koltchinskii et al., 2011）更严格的恢复保证。为了对任意给定测量集 A 中的有限数量的测量进行有效估计，我们还提出了一种新颖的实验设计标准，可以通过计算效率最小化 B(Q)。我们利用新颖的估计器和实验设计，为通用臂集推导出两种低秩线性老虎机算法，这些算法享有改进的遗憾上限。这比以前针对低阶老虎机的工作有所改进，这些工作做出了一些限制性假设，即手臂组是单位球或给出了有效的探索分布。据我们所知，我们的实验设计标准是第一个针对低秩矩阵估计量身定制的标准，超出了线性回归的简单简化，这可能是独立的兴趣。]]></description>
      <guid>https://arxiv.org/abs/2402.11156</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>最优随机森林的自适应分割平衡</title>
      <link>https://arxiv.org/abs/2402.11228</link>
      <description><![CDATA[arXiv:2402.11228v1 公告类型：新
摘要：虽然随机森林通常用于回归问题，但现有方法往往缺乏复杂情况的适应性，或者在简单、平滑的情况下失去最优性。在本研究中，我们引入了自适应分割平衡森林（ASBF），它能够从数据中学习树表示，同时在 Lipschitz 类下实现极小极大最优。为了利用高阶平滑度水平，我们进一步提出了一个局部版本，该版本可以在 H\&quot;旧类 $\mathcal{H}^{q,\beta}$ 下对于任何 $q\in\mathbb{N 获得极小极大速率}$ 和 $\beta\in(0,1]$。我们考虑对现有方法进行平衡修改，而不是依赖于广泛使用的随机特征选择。我们的结果表明，过度依赖辅助随机性可能会损害树模型的逼近能力，导致次优结果。相反，随机性较低、更平衡的方法表现出最优性。此外，我们建立统一的上限并探索随机森林在平均治疗效果估计问题中的应用。通过模拟研究和实际数据应用中，我们证明了所提出的方法比现有随机森林具有优越的经验性能。]]></description>
      <guid>https://arxiv.org/abs/2402.11228</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    </channel>
</rss>