<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 12 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>单变量 ReLU 网络中的稳定最小值无法过拟合：通过大步长进行泛化</title>
      <link>https://arxiv.org/abs/2406.06838</link>
      <description><![CDATA[arXiv:2406.06838v1 公告类型：交叉 
摘要：我们研究了两层 ReLU 神经网络在带有噪声标签的单变量非参数回归问题中的泛化。这是一个核（\emph{例如} NTK）可证明为次优且不会发生良性过度拟合的问题，因此现有的插值（0 损失、全局最优）解决方案理论不合格。我们提出了一种新的局部最小值泛化理论，具有恒定学习率的梯度下降可以 \emph{稳定} 收敛到该局部最小值。我们表明，具有固定学习率 $\eta$ 的梯度下降只能找到表示具有特定加权 \emph{一阶总变分} 的平滑函数的局部最小值，该函数受 $1/\eta - 1/2 + \widetilde{O}(\sigma + \sqrt{\mathrm{MSE}})$ 约束，其中 $\sigma$ 是标签噪声水平，$\mathrm{MSE}$ 是相对于基本事实的均方误差的缩写，$\widetilde{O}(\cdot)$ 隐藏对数因子。在温和的假设下，我们还证明了在 $n$ 个数据点的支持的严格内部存在近乎最优的 MSE 界限 $\widetilde{O}(n^{-4/5})$。我们的理论结果通过大量模拟得到验证，表明大学习率训练会引起稀疏线性样条拟合。据我们所知，我们是第一个在非插值情况下通过最小稳定性获得泛化界限的人，也是第一个证明没有正则化的 ReLU NN 可以在非参数回归中实现接近最优速率的人。]]></description>
      <guid>https://arxiv.org/abs/2406.06838</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:41 GMT</pubDate>
    </item>
    <item>
      <title>具有网络结构协变量的个性化二项式 DAG 学习</title>
      <link>https://arxiv.org/abs/2406.06829</link>
      <description><![CDATA[arXiv:2406.06829v1 公告类型：交叉 
摘要：数据中的因果依赖关系通常以有向无环图 (DAG) 模型为特征，该模型广泛应用于许多领域。因果发现旨在使用观察数据恢复 DAG 结构。本文重点研究多变量计数数据的因果发现。我们受到现实世界网络访问数据的启发，记录了单个用户对多个网站的访问。构建因果图有助于理解用户在网站之间转换的行为，从而启发运营策略。建模的一个挑战是用户异质性，因为不同背景的用户表现出不同的行为。此外，社交网络连接可能导致朋友之间出现相似的行为。我们引入了个性化的二项式 DAG 模型来解决观察之间的异质性和网络依赖性，这在现实世界的应用中很常见。为了学习所提出的 DAG 模型，我们开发了一种算法，将网络结构嵌入到降维协变量中，学习每个节点的邻域以减少 DAG 搜索空间，并探索方差-均值关系以确定排序。模拟表明，我们的算法在异构数据中的表现优于最先进的竞争对手。我们在现实世界的网络访问数据集上展示了它的实际用途。]]></description>
      <guid>https://arxiv.org/abs/2406.06829</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:40 GMT</pubDate>
    </item>
    <item>
      <title>具有差异隐私约束的联邦非参数假设检验：最优速率和自适应检验</title>
      <link>https://arxiv.org/abs/2406.06749</link>
      <description><![CDATA[arXiv:2406.06749v1 公告类型：交叉 
摘要：联邦学习最近引起了广泛关注，因为它适用于广泛的环境，在这些环境中，数据是在不同位置收集和分析的。在本文中，我们研究了在分布式差分隐私 (DP) 约束下，白噪声与漂移模型中的联邦非参数拟合优度检验。
我们首先建立匹配的下限和上限，最高为对数因子，以极小极大分离率为基础。这个最佳速率作为测试问题难度的基准，考虑到模型特征，例如观察次数、噪声水平和信号类的规律性，以及 $(\epsilon,\delta)$-DP 要求的严格性。结果展示了有趣而新颖的相变现象。此外，结果揭示了一个有趣的现象，即具有共享随机性的分布式一次性协议优于无法访问共享随机性的协议。我们还构建了一个数据驱动的测试程序，该程序能够以最小的额外成本适应大量函数类中的未知规律参数，同时保持遵守同一组 DP 约束。]]></description>
      <guid>https://arxiv.org/abs/2406.06749</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:39 GMT</pubDate>
    </item>
    <item>
      <title>具有异构分布式差分隐私约束的非参数回归最优联邦学习</title>
      <link>https://arxiv.org/abs/2406.06755</link>
      <description><![CDATA[arXiv:2406.06755v1 公告类型：交叉 
摘要：本文研究了在不同服务器之间分布式样本背景下的非参数回归联合学习，每个服务器都遵循不同的差分隐私约束。我们考虑的设置是异构的，既包括不同的样本大小，也包括跨服务器的差分隐私约束。在这个框架内，考虑了全局和逐点估计，并建立了 Besov 空间上的最佳收敛速度。
提出了分布式隐私保护估计器并研究了它们的风险特性。为全局和逐点估计建立了匹配的极小极大下界，最高可达对数因子。总之，这些发现揭示了统计准确性和隐私保护之间的权衡。特别是，我们不仅从隐私预算的角度来描述这种妥协，而且还从整个隐私框架内分发数据所产生的损失的角度来描述这种妥协。这一见解抓住了民间智慧，即在较大的样本中更容易保留隐私，并探讨了在分布式隐私约束下逐点估计和全局估计之间的差异。]]></description>
      <guid>https://arxiv.org/abs/2406.06755</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:39 GMT</pubDate>
    </item>
    <item>
      <title>频谱：针对信噪比进行有针对性的训练</title>
      <link>https://arxiv.org/abs/2406.06623</link>
      <description><![CDATA[arXiv:2406.06623v1 公告类型：交叉 
摘要：由于需要大量的计算资源，高效地对大型语言模型进行后期训练仍然是一项艰巨的任务。我们提出了 Spectrum，这是一种通过根据信噪比 (SNR) 选择性地定位层模块并冻结其余模块来加速 LLM 训练的方法。我们的方法利用一种算法在训练之前计算模块 SNR，事实证明它可以有效匹配完全微调的性能，同时减少 GPU 内存使用量。将 Spectrum 与 QLoRA 等现有方法进行比较的实验证明了它在分布式环境中的模型质量和 VRAM 效率方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.06623</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:38 GMT</pubDate>
    </item>
    <item>
      <title>Hinge-FM2I：一种使用图像修复来插入单变量时间序列中缺失数据的方法</title>
      <link>https://arxiv.org/abs/2406.06631</link>
      <description><![CDATA[arXiv:2406.06631v1 公告类型：交叉 
摘要：准确的时间序列预测对于各种应用都至关重要，例如交通管理、电力消耗和医疗保健。然而，模型和数据质量的局限性会严重影响预测的准确性。数据质量的一个常见问题是缺少数据点，称为缺失数据。这通常是由传感器故障、设备故障或人为错误造成的。本文提出了 Hinge-FM2I，一种处理单变量时间序列数据中缺失数据值的新方法。Hinge-FM2I 建立在图像修复预测方法 (FM2I) 的优势之上。FM2I 已被证明是有效的，但选择最准确的预测仍然是一个挑战。为了解决这个问题，我们提出了一种选择算法。受门铰链的启发，Hinge-FM2I 在间隙（左/右铰链）之前或之后放置一个数据点，然后使用 FM2I 进行插补，然后根据放置数据点的最低误差选择插补间隙。 Hinge-FM2I 的评估基于从 M3 竞赛基准数据集中提取的 1356 个时间序列的综合样本，缺失值率从 3.57% 到 28.57% 不等。实验结果表明，Hinge-FM2I 明显优于线性/样条插值、K-最近邻 (K-NN) 和 ARIMA 等既定方法。值得注意的是，Hinge-FM2I 在小间隙中实现了 5.6% 的平均对称平均绝对百分比误差 (sMAPE) 得分，在大间隙中实现了高达 10% 的得分。这些发现凸显了 Hinge-FM2I 作为一种有前途的新方法在解决单变量时间序列数据中的缺失值方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.06631</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:38 GMT</pubDate>
    </item>
    <item>
      <title>通过结构化牛顿下降法加速病态汉克尔矩阵恢复</title>
      <link>https://arxiv.org/abs/2406.07409</link>
      <description><![CDATA[arXiv:2406.07409v1 公告类型：新
摘要：本文研究了稳健 Hankel 恢复问题，该问题同时消除稀疏异常值并填补部分观察中的缺失条目。我们提出了一种新的非凸算法，称为 Hankel 结构化牛顿下降 (HSNLD)，以解决稳健 Hankel 恢复问题。HSNLD 具有线性收敛的高效性，其收敛速度与底层 Hankel 矩阵的条件数无关。恢复保证已在一些温和的条件下建立。在合成和真实数据集上的数值实验表明 HSNLD 相对于最先进的算法具有优越的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.07409</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:37 GMT</pubDate>
    </item>
    <item>
      <title>使用主动学习量化局部模型有效性</title>
      <link>https://arxiv.org/abs/2406.07474</link>
      <description><![CDATA[arXiv:2406.07474v1 公告类型：新
摘要：机器学习模型的实际应用通常受法律或基于政策的法规约束。其中一些法规要求确保模型的有效性，即近似误差小于阈值。全局度量通常太不敏感，无法确定特定预测的有效性，而评估局部有效性则成本高昂，因为它需要收集额外的数据。我们建议学习模型误差以获得局部有效性估计，同时通过主动学习减少所需的数据量。使用模型验证基准，我们提供经验证据表明，所提出的方法可以使用相对较少的数据量产生具有足够判别特性的误差模型。此外，与其他方法相比，该方法对有效性界限的局部变化的敏感性有所提高。]]></description>
      <guid>https://arxiv.org/abs/2406.07474</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:37 GMT</pubDate>
    </item>
    <item>
      <title>论核依赖最大化对特征选择的局限性</title>
      <link>https://arxiv.org/abs/2406.06903</link>
      <description><![CDATA[arXiv:2406.06903v1 公告类型：新
摘要：一种简单直观的特征选择方法包括选择最大化响应和特征之间非参数依赖性度量的特征子集。文献中一个流行的提议使用希尔伯特-施密特独立性标准 (HSIC) 作为非参数依赖性度量。这种特征选择方法背后的原理是，重要特征将表现出对响应的高度依赖性，并且将它们包含在选定特征集中将增加 HSIC。通过反例，我们证明了这种原理是有缺陷的，并且通过 HSIC 最大化进行的特征选择可能会遗漏关键特征。]]></description>
      <guid>https://arxiv.org/abs/2406.06903</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:36 GMT</pubDate>
    </item>
    <item>
      <title>DecoR：利用稳健回归分析时间序列</title>
      <link>https://arxiv.org/abs/2406.07005</link>
      <description><![CDATA[arXiv:2406.07005v1 公告类型：新
摘要：时间序列数据的因果推断是一个具有挑战性的问题，尤其是在存在未观察到的混杂因素的情况下。这项工作侧重于估计两个时间序列之间的因果关系，这两个时间序列被第三个未观察到的时间序列所混淆。假设混杂因素的频谱稀疏性，我们展示了如何在频域中将此问题构建为对抗性异常值问题。我们引入了稳健回归去混淆 (DecoR)，这是一种使用频域中的稳健线性回归估计因果关系的新方法。考虑两种不同的稳健回归技术，我们首先改进了此类技术估计误差的现有界限。至关重要的是，我们的结果不需要对协变量进行分布假设。因此，我们可以在时间序列设置中使用它们。将这些结果应用于 DecoR，我们在适当的假设下证明了 DecoR 估计误差的上限意味着一致性。我们通过对合成数据的实验展示了 DecoR 的有效性。我们的实验进一步表明，我们的方法对于模型错误指定具有很强的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2406.07005</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:36 GMT</pubDate>
    </item>
    <item>
      <title>对数凹度下的随机扫描坐标上升变分推断的收敛速度</title>
      <link>https://arxiv.org/abs/2406.07292</link>
      <description><![CDATA[arXiv:2406.07292v1 公告类型：新
摘要：坐标上升变分推理方案是一种流行的算法，用于计算感兴趣的概率分布的平均场近似值。我们在目标密度的对数凹度假设下分析了它的随机扫描版本。我们的方法建立在 M. Arnese 和 D. Lacker 最近的一项工作的基础上，\emph{通过最优传输对对数凹度测量进行坐标上升变分推理的收敛} [arXiv:2404.08792]，该工作研究了该算法的确定性扫描版本，将其表述为具有最优传输几何的概率分布空间中的块坐标下降算法。我们获得了随机扫描版本的严格速率，这意味着收敛所需的因子更新总数与条件数和目标分布的块数成线性比例。相比之下，确定性扫描案例的可用界限以相同的数量呈二次方增长，这类似于欧几里得空间中凸函数优化的情况。]]></description>
      <guid>https://arxiv.org/abs/2406.07292</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:36 GMT</pubDate>
    </item>
    <item>
      <title>时空霍克斯过程的灵活参数推断</title>
      <link>https://arxiv.org/abs/2406.06849</link>
      <description><![CDATA[arXiv:2406.06849v1 公告类型：新
摘要：许多现代时空数据集，例如社会学、流行病学或地震学，都表现出自激特性，同时触发和聚类行为，合适的霍克斯时空过程可以准确捕捉到这些特性。本文旨在开发一种快速灵活的参数推理技术，以基于此类数据恢复时空霍克斯过程强度函数中涉及的核函数的参数。我们的统计方法结合了三个关键因素：1)考虑具有有限支撑的核，2)适当离散化时空域，3)使用（近似）预计算。我们提出的推理技术由一个基于$\ell_2$梯度的求解器组成，该求解器快速且统计准确。除了描述算法方面之外，还对合成和真实的时空数据进行了数值实验，为所提出的方法的相关性提供了坚实的经验证据。]]></description>
      <guid>https://arxiv.org/abs/2406.06849</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:35 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 可以学习稀疏 token 选择，而全连接网络则不能</title>
      <link>https://arxiv.org/abs/2406.06893</link>
      <description><![CDATA[arXiv:2406.06893v1 公告类型：新
摘要：Transformer 架构因其出色的选择和组合结构信息的能力而在各种深度学习环境中盛行。受这些能力的启发，Sanford 等人提出了稀疏标记选择任务，其中 Transformer 表现出色，而全连接网络 (FCN) 在最坏情况下会失败。在此基础上，我们将 FCN 下限加强到平均情况设置，并建立 Transformer 在 FCN 上的算法分离。具体而言，经过梯度下降训练的单层 Transformer 可以证明学习稀疏标记选择任务，并且令人惊讶的是，表现出强大的分布外长度泛化。我们提供实证模拟来证明我们的理论发现。]]></description>
      <guid>https://arxiv.org/abs/2406.06893</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:35 GMT</pubDate>
    </item>
    <item>
      <title>老虎机优化中的满意探索</title>
      <link>https://arxiv.org/abs/2406.06802</link>
      <description><![CDATA[arXiv:2406.06802v1 公告类型：新
摘要：受决策中满意度概念的启发，我们考虑了老虎机优化中的满意度探索问题。在这种情况下，学习者的目标是尽可能频繁地选择满意度臂（平均奖励超过某个阈值的臂）。绩效通过满意度遗憾来衡量，满意度遗憾是所选臂的平均奖励与阈值相比的累积赤字。我们提出了 SELECT，这是一种通过低置信度边界测试进行满意度探索的通用算法模板，在可实现的情况下（即存在满意度臂），它可以为各种老虎机优化问题实现恒定的满意度遗憾。具体而言，给定一类老虎机优化问题和具有亚线性（标准）遗憾上限的相应学习预言机，SELECT 迭代地利用预言机来识别具有低遗憾的潜在满意度臂。然后，它从该分支收集数据样本，并不断将识别的分支的平均奖励的 LCB 与阈值进行比较，以确定它是否是令人满意的分支。作为补充，SELECT 还享有与不可实现情况下的预言机相同的（标准）遗憾保证。最后，我们进行数值实验来验证 SELECT 在几种流行的 bandit 优化设置下的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.06802</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:34 GMT</pubDate>
    </item>
    <item>
      <title>局部平方 Wasserstein-2 方法用于高效重构不确定模型</title>
      <link>https://arxiv.org/abs/2406.06825</link>
      <description><![CDATA[arXiv:2406.06825v1 公告类型：新
摘要：在本文中，我们提出了一种局部平方 Wasserstein-2 (W_2) 方法来解决具有不确定潜在变量或参数的模型重建的逆问题。我们的方法的一个关键优势是它不需要有关底层模型中潜在变量或参数分布的先验信息。相反，我们的方法可以根据观测数据的经验分布有效地重建与不同输入相关的输出的分布。我们在几个不确定性量化 (UQ) 任务中证明了我们提出的方法的有效性，包括具有系数不确定性的线性回归、具有权重不确定性的神经网络训练以及使用潜在随机变量重建常微分方程 (ODE)。]]></description>
      <guid>https://arxiv.org/abs/2406.06825</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:34 GMT</pubDate>
    </item>
    </channel>
</rss>