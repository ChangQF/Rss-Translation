<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 15 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>高维贝叶斯模型的吉布斯内都市方案的可扩展性</title>
      <link>https://arxiv.org/abs/2403.09416</link>
      <description><![CDATA[arXiv:2403.09416v1 公告类型：交叉
摘要：我们研究了通用的坐标式 MCMC 方案（例如 Metropolis-within-Gibbs 采样器），这些方案通常用于拟合贝叶斯非共轭分层模型。我们通过条件电导的概念将它们的收敛特性与相应的（可能无法实现的）吉布斯采样器的收敛特性联系起来。这使我们能够研究非共轭分层模型中流行的吉布斯内都市方案在数据点和参数数量都增加的高维体系中的性能。给定随机数据生成假设，我们建立了无量纲收敛结果，该结果与数值证据非常一致。还讨论了具有未知超参数和离散观察扩散的二元回归贝叶斯模型的应用。在此类统计应用的推动下，提供了对马尔可夫算子的近似电导和扰动独立感兴趣的辅助结果。]]></description>
      <guid>https://arxiv.org/abs/2403.09416</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>具有潜在变量的极值图形建模</title>
      <link>https://arxiv.org/abs/2403.09604</link>
      <description><![CDATA[arXiv:2403.09604v1 公告类型：交叉
摘要：极值图模型编码多元极值的条件独立结构，并为量化罕见事件的风险提供了强大的工具。之前从数据中学习这些图表的工作主要集中在观察所有相关变量的设置上。对于流行的 H\&quot;usler-Reiss 模型，我们提出了 \texttt{eglatent} 方法，这是一种易于处理的凸程序，用于在存在潜在变量的情况下学习极值图模型。我们的方法分解了 H\&quot;usler-Reiss 精度将矩阵转换为稀疏组件，在对潜在变量进行调节后编码观察变量之间的图形结构，以及低秩组件编码一些潜在变量对观察变量的影响。我们提供 \texttt{eglatent} 的有限样本保证，并表明它一致地恢复条件图以及潜在变量的数量。我们强调我们的方法在合成数据和真实数据上的性能改进。]]></description>
      <guid>https://arxiv.org/abs/2403.09604</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>随机扰动下的奇异子空间分析</title>
      <link>https://arxiv.org/abs/2403.09170</link>
      <description><![CDATA[arXiv:2403.09170v1 公告类型：交叉
摘要：我们在信号加随机高斯噪声矩阵模型的背景下对奇异向量和奇异子空间扰动进行了综合分析。假设一个低秩信号矩阵，我们以完全广义的方式扩展了 Wedin-Davis-Kahan 定理，适用于任何酉不变矩阵范数，扩展了 O&#39;Rourke、Vu 和作者之前的结果。我们还获得了细粒度的结果，其中包括奇异向量的 $\ell_\infty$ 分析、奇异子空间的 $\ell_{2, \infty}$ 分析，以及相关线性和双线性函数的探索到奇异向量。此外，我们在高斯混合模型和子矩阵定位问题的背景下探讨了这些发现的实际意义。]]></description>
      <guid>https://arxiv.org/abs/2403.09170</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>递归因果发现</title>
      <link>https://arxiv.org/abs/2403.09300</link>
      <description><![CDATA[arXiv:2403.09300v1 公告类型：交叉
摘要：因果发现，即从数据中学习因果图，通常是识别和估计因果效应的第一步，这是许多科学领域的关键要求。因果发现受到两个主要挑战的阻碍：有限的数据会导致统计测试中的错误，并且学习任务的计算复杂性令人望而生畏。本文以我们之前的四篇出版物为基础并对其进行了扩展（Mokhtarian 等人，2021 年；Akbari 等人，2021 年；Mokhtarian 等人，2022 年、2023a）。这些工作引入了可移除变量的概念，它们是唯一可以为了发现因果关系而递归移除的变量。可移除变量的存在和识别允许采用递归方法进行因果发现，这是一种有前途的解决方案，有助于通过连续减小问题规模来解决上述挑战。这种减少不仅最大限度地减少了每个条件独立性 (CI) 测试中的条件集，从而减少了错误，而且还显着减少了所需 CI 测试的数量。这些方法的最坏情况性能几乎与下限相符。在本文中，我们为所提出的算法提出了一个统一的框架，并通过附加细节和增强功能进行了改进，以实现连贯的呈现。还包括全面的文献综述，将我们的方法与现有方法的计算复杂性进行比较，展示其最先进的效率。本文的另一个贡献是发布了 RCD，这是一个有效实现这些算法的 Python 包。该软件包专为有兴趣在实际场景中应用这些方法的从业者和研究人员而设计。该软件包可在 github.com/ban-epfl/rcd 上获取，并在 rcdpackage.com 上提供全面的文档。]]></description>
      <guid>https://arxiv.org/abs/2403.09300</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>清晰时刻：使用矩池简化机器学习中的潜在空间</title>
      <link>https://arxiv.org/abs/2403.08854</link>
      <description><![CDATA[arXiv:2403.08854v1 公告类型：交叉
摘要：许多机器学习应用涉及学习数据的潜在表示，这些数据通常是高维的并且难以直接解释。在这项工作中，我们提出了“矩池”，这是深度集网络的自然扩展，它大大降低了这些网络的潜在空间维度，同时保持甚至提高了性能。矩池将深度集中的求和概括为任意多元矩，这使得模型能够针对固定的潜在维度实现更高的有效潜在维度。我们通过将能量流网络 (EFN) 扩展到矩 EFN，在夸克/胶子射流分类的对撞机物理任务中演示矩池。我们发现，潜在维度小至 1 的 Moment EFN 的表现与具有更高潜在维度的普通 EFN 类似。这个小的潜在维度允许直接可视化和解释内部表示，这反过来又使得学习到的内部射流表示能够以封闭形式提取。]]></description>
      <guid>https://arxiv.org/abs/2403.08854</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>用于最佳手臂识别和流体分析的最佳前二法</title>
      <link>https://arxiv.org/abs/2403.09123</link>
      <description><![CDATA[arXiv:2403.09123v1 公告类型：交叉
摘要：Top-$2$ 方法在解决最佳手臂识别（BAI）问题中已经变得很流行。最佳臂，或有限多个中具有最大平均值的臂，是通过一种算法来识别的，该算法在任何顺序步骤中以固定概率 $\beta$ 独立地拉动经验最佳臂，否则拉动最佳挑战者臂。错误选择的概率保证低于指定的 $\delta &gt;0$。样本复杂度的信息论下界对于 BAI 问题是众所周知的，并且通过计算要求较高的插件方法渐近匹配为 $\delta \rightarrow 0$。对于任何 $\beta \in (0,1)$ 的上述前 2 个算法的样本复杂度在下界常数内。然而，事实证明，确定与下限相匹配的最佳 $\beta$ 很困难。在本文中，我们解决了这个问题并提出了一种最佳的 top-2 类型算法。我们考虑以阈值为基础的分配函数。如果超过阈值，则算法对经验最佳臂进行采样。否则，它会对挑战者臂进行采样。我们证明所提出的算法是最优的 $\delta \rightarrow 0$。我们的分析依赖于识别分配的限制流体动力学，该分配满足一系列粘贴在一起的常微分方程，并描述我们的算法遵循的渐近路径。我们依靠隐函数定理来证明这些流体颂的存在性和唯一性，并证明所提出的算法仍然接近于颂的解。]]></description>
      <guid>https://arxiv.org/abs/2403.09123</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>非自适应汇总测试中的病毒载量推断</title>
      <link>https://arxiv.org/abs/2403.09130</link>
      <description><![CDATA[arXiv:2403.09130v1 公告类型：交叉
摘要：使用合并测试协议可以显着提高医学诊断测试的效率。这些通常需要稀疏感染信号并使用 O(1) 的二进制或实值条目。然而，现有方法不允许推断跨越多个数量级的病毒载量。我们开发了一种消息传递算法，结合 PCR（聚合酶链式反应）特定噪声函数，可以准确推断真实的病毒载量信号。这项工作是在非适应性环境下进行的，可以开启有效筛选的可能性，其中病毒载量测定在临床上很重要。]]></description>
      <guid>https://arxiv.org/abs/2403.09130</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>使用序列样本平均近似值的变分推理</title>
      <link>https://arxiv.org/abs/2403.09429</link>
      <description><![CDATA[arXiv:2403.09429v1 公告类型：新
摘要：我们提出了使用顺序样本平均近似（VISA）的变分推理，这是一种在计算密集型模型（例如基于数值模拟的模型）中进行近似推理的方法。 VISA 通过采用一系列样本平均近似值来扩展重要性加权的前向 KL 变分推理，这些近似值在信任区域内被认为是有效的。这使得可以在多个梯度步骤中重用模型评估，从而降低计算成本。我们对高维高斯、Lotka-Volterra 动力学和 Pickover 吸引子进行了实验，结果表明 VISA 可以实现与标准重要性加权前向 KL 变分推理相当的近似精度，并且对于保守选择，计算量可节省两倍或更多学习率。]]></description>
      <guid>https://arxiv.org/abs/2403.09429</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>温度计：迈向大型语言模型的通用校准</title>
      <link>https://arxiv.org/abs/2403.08819</link>
      <description><![CDATA[arXiv:2403.08819v1 公告类型：交叉
摘要：我们考虑大型语言模型（LLM）中的校准问题。最近的研究发现，指令调整等常见干预措施通常会导致法学硕士校准不佳。尽管校准在传统应用中已得到充分探索，但校准法学硕士却具有独特的挑战性。这些挑战既源于法学硕士严格的计算要求，也源于其多功能性，这使得它们能够应用于不同的任务。为了应对这些挑战，我们提出了 THERMOMETER，这是一种专为法学硕士量身定制的校准方法。 THERMOMETER 根据多个任务的给定数据学习辅助模型，用于校准法学硕士。它计算效率高，保留了法学硕士的准确性，并为新任务提供了更好的校准响应。各种基准的广泛实证评估证明了所提出方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.08819</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>用于深度神经网络高效并行的循环数据并行</title>
      <link>https://arxiv.org/abs/2403.08837</link>
      <description><![CDATA[arXiv:2403.08837v1 公告类型：交叉
摘要：训练大型深度学习模型需要并行化技术来扩展。在 Data Parallelism 或 ZeRO-DP 等现有方法中，微批量数据是并行处理的，这会产生两个缺点：在前向传递结束时存储模型激活峰值所需的总内存，并且梯度必须同时进行在反向传播步骤结束时取平均值。我们提出了循环数据并行，这是一种新颖的范例，将微批次的执行从同时执行转变为顺序执行，并具有统一的延迟。以轻微的梯度延迟为代价，激活所占用的总内存是恒定的，并且梯度通信在训练步骤期间是平衡的。借助模型并行性，我们的技术通过跨微批次共享 GPU 来减少所需的 GPU 数量。在 ZeRO-DP 框架内，我们的技术允许通过点对点操作而不是集体广播操作来进行模型状态的通信。我们在 CIFAR-10 和 ImageNet 数据集上展示了我们方法的优势。]]></description>
      <guid>https://arxiv.org/abs/2403.08837</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>面向快速准确的变分自动编码器的模型无关后验近似</title>
      <link>https://arxiv.org/abs/2403.08941</link>
      <description><![CDATA[arXiv:2403.08941v1 公告类型：新
摘要：变分自编码器 (VAE) 的推理包括学习两个模型：(1) 生成模型，将潜在空间上的简单分布转换为观测数据的分布；(2) 推理模型，近似后验概率给定数据的潜在代码。这两个组件是通过生成模型的对数边际似然的下限共同学习的。在联合训练的早期阶段，推理模型很难近似潜在的代码后验。最近的工作表明，这会导致优化陷入局部最优，从而对学习的生成模型产生负面影响。因此，最近的工作建议通过迭代训练确保高质量的推理模型：在每次更新生成模型之前最大化相对于推理模型的目标函数。不幸的是，迭代训练效率低下，需要启发式标准从迭代恢复到联合训练以提高速度。在这里，我们提出了一种独立训练生成模型和推理模型的推理方法。它先验地逼近真实模型的后验；固定这个后验近似，然后我们最大化相对于生成模型的下界。按照传统观点，这种方法应该依赖于真实模型的真实先验和可能性来近似其后验（这是未知的）。然而，我们证明我们可以计算真实模型后验的确定性、模型不可知的后验近似（MAPA）。然后，我们使用 MAPA 开发概念验证推理方法。我们提出了低维合成数据的初步结果：(1) MAPA 捕获了真实后验的趋势，(2) 我们基于 MAPA 的推理以比基线更少的计算执行了更好的密度估计。最后，我们提出了将基于 MAPA 的推理方法扩展到高维数据的路线图。]]></description>
      <guid>https://arxiv.org/abs/2403.08941</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>部分概念瓶颈模型 (CBM) 中贝叶斯泛化误差的上限：部分 CBM 优于朴素 CBM</title>
      <link>https://arxiv.org/abs/2403.09206</link>
      <description><![CDATA[arXiv:2403.09206v1 公告类型：新
摘要：概念瓶颈模型（CBM）是一种解释神经网络的方法。在 CBM 中，与输出原因相对应的概念作为观测值插入到最后的中间层中。期望我们能够像线性回归一样解释输出和概念之间的关系。然而，这种解释需要观察所有概念并降低神经网络的泛化性能。部分 CBM (PCBM) 使用部分观察到的概念，旨在解决这些困难。尽管一些数值实验表明PCBM的泛化性能几乎与原始神经网络一样高，但由于PCBM是奇异统计模型，其泛化误差的理论行为尚未阐明。在本文中，我们揭示了具有三层线性架构的 PCBM 中的贝叶斯泛化误差。结果表明，与 CBM（完全观察概念）相比，部分观察概念的结构降低了贝叶斯泛化误差。]]></description>
      <guid>https://arxiv.org/abs/2403.09206</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>Pantypes：可自我解释模型的多种代表</title>
      <link>https://arxiv.org/abs/2403.09383</link>
      <description><![CDATA[arXiv:2403.09383v1 公告类型：新
摘要：原型的可解释分类器的出现是为了满足对可解释人工智能系统不断增长的需求。这些分类器旨在通过基于与学习的原型对象的相似性进行推断，在决策中纳入高度透明度。虽然这些模型在设计时考虑到了多样性，但学习到的原型通常不足以代表输入分布的所有方面，特别是低密度区域的分布。这种缺乏足够的数据表示（称为表示偏差）与机器学习多样性和公平性相关的各种有害特性有关。有鉴于此，我们引入了 pantypes，这是一个新的原型对象系列，旨在通过一组稀疏对象捕获输入分布的全部多样性。我们表明，泛型可以通过占据潜在空间的不同区域来增强原型的可解释模型，从而促进高度多样性、可解释性和公平性。]]></description>
      <guid>https://arxiv.org/abs/2403.09383</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>三多数：最简单的最优学习器？</title>
      <link>https://arxiv.org/abs/2403.08831</link>
      <description><![CDATA[arXiv:2403.08831v1 公告类型：新
摘要：在经验风险最小化 (ERM) 不理想的可实现环境中开发最优 PAC 学习算法，是学习理论中数十年来的一个主要开放问题。几年前，这个问题终于被 Hanneke 解决了。不幸的是，Hanneke 的算法非常复杂，因为它返回许多 ERM 分类器的多数票，而这些分类器是在精心选择的数据子集上进行训练的。因此，确定最简单的最优算法是一个自然的目标。在这项工作中，我们研究了可以说是最简单的最优算法：返回三个 ERM 分类器的多数票。我们证明了该算法在其误差上实现了最佳的预期范围，这被证明是单个 ERM 分类器无法实现的。此外，我们证明了该算法错误的近乎最优的高概率界限。我们推测，更好的分析将证明该算法实际上在高概率情况下是最优的。]]></description>
      <guid>https://arxiv.org/abs/2403.08831</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:38 GMT</pubDate>
    </item>
    <item>
      <title>核岭回归的非渐近理论：确定性等价物、测试误差和 GCV 估计器</title>
      <link>https://arxiv.org/abs/2403.08938</link>
      <description><![CDATA[arXiv:2403.08938v1 公告类型：新
摘要：我们考虑使用给定 i.i.d. 的核岭回归 (KRR) 来学习未知目标函数 $f_*$。数据$(u_i,y_i)$，$i\leq n$，其中$u_i \in U$是协变量向量，$y_i = f_* (u_i) +\varepsilon_i \in \mathbb{R}$。最近的一系列工作凭经验表明，KRR 的测试误差可以通过从“等效”序列模型导出的封闭式估计来很好地近似，该模型仅取决于核算子的频谱。然而，迄今为止，这种等价性的理论论证要么依赖于限制性假设（例如亚高斯独立本征函数），要么依赖于高维特定核的渐近推导。
  在本文中，我们证明这种等价关系适用于满足核特征分解的某些光谱和浓度特性的一类一般问题。具体来说，我们在此设置中为 KRR 的测试误差建立了一个非渐近确定性近似（具有显式非渐近界限），该近似仅取决于特征值和目标函数与内核特征向量的对齐。我们的证明依赖于 Cheng 和 Montanari（2022）开创的无维体系中随机矩阵泛函的确定性等价物的仔细推导。
  我们将此设置应用于几个经典示例，并显示理论预测和数值模拟之间具有良好的一致性。这些结果依赖于对核运算符的特征分解的访问。或者，我们证明，在相同的设置下，广义交叉验证（GCV）估计器在包括零（插值解）的岭正则化参数范围内均匀地集中于测试误差。因此，GCV 估计器可用于根据数据估计 KRR 的测试误差和最佳正则化参数。]]></description>
      <guid>https://arxiv.org/abs/2403.08938</guid>
      <pubDate>Fri, 15 Mar 2024 06:16:38 GMT</pubDate>
    </item>
    </channel>
</rss>