<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 27 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>EFiGP：基于特征傅立叶物理的高斯过程，用于动态系统推理</title>
      <link>https://arxiv.org/abs/2501.14107</link>
      <description><![CDATA[arXiv:2501.14107v1 公告类型：新
摘要：由常微分方程 (ODE) 控制的数据驱动动态系统的参数估计和轨迹重建是生物、工程和物理等领域的基本任务。这些逆问题——从观测数据估计 ODE 参数——在数据嘈杂、稀疏且动态非线性时尤其具有挑战性。我们提出了特征傅里叶物理信息高斯过程 (EFiGP)，这是一种将傅里叶变换和特征分解集成到物理信息高斯过程框架中的算法。这种方法消除了对数值积分的需求，显著提高了计算效率和准确性。EFiGP 建立在原则性贝叶斯框架之上，通过概率条件整合 ODE 系统，在傅里叶域中执行控制方程，同时截断高频项以实现去噪和计算节省。特征分解的使用进一步简化了高斯过程协方差运算，即使在密集网格设置中也能高效恢复轨迹和参数。我们在三个基准示例上验证了 EFiGP 的实际效果，证明了其在复杂动态系统可靠且可解释建模方面的潜力，同时解决了轨迹恢复和计算成本方面的关键挑战。]]></description>
      <guid>https://arxiv.org/abs/2501.14107</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协变量偏移下的分布稳健核心集选择</title>
      <link>https://arxiv.org/abs/2501.14253</link>
      <description><![CDATA[arXiv:2501.14253v1 公告类型：新
摘要：核心集选择是一种减少训练数据的方法，它涉及从现有训练数据集中选择一个小子集，并且已经提出了各种方法来减少训练数据。在实际使用这些方法的情况下，通常情况下，数据分布在开发阶段和部署阶段之间有所不同，而后者是未知的。因此，选择一个在所有部署场景中表现良好的有效训练数据子集是一项挑战。因此，我们提出了分布稳健的核心集选择 (DRCS)。DRCS 理论上推导出最坏情况测试误差上限的估计值，假设未来的协变量分布可能在定义的范围内偏离训练分布。此外，通过以抑制最坏情况测试误差上限估计的方式选择实例，DRCS 实现了分布稳健的训练实例选择。这项研究主要适用于凸训练计算，但我们证明它也可以应用于适当近似下的深度学习。在本文中，我们重点研究了数据分布转移的一种——协变量转移，并通过实验证明了 DRCS 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.14253</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>线性分类器的统计验证</title>
      <link>https://arxiv.org/abs/2501.14430</link>
      <description><![CDATA[arXiv:2501.14430v1 公告类型：新
摘要：我们提出了一种与两个样本之间的线性可分性概念密切相关的同质性测试。使用该测试可以回答线性分类器是否仅仅是“随机的”还是有效地捕捉了两个类之间的差异。我们专注于为应用于二维样本的测试的 \emph{p} 值建立上限。具体而言，对于正态分布的样本，我们通过实验证明上限非常准确。使用此界限，我们评估了基于基因对表达检测 ER 阳性乳腺癌复发的分类器。我们的研究结果证实了 IGFBP6 和 ELOVL5 基因在此过程中的重要性。]]></description>
      <guid>https://arxiv.org/abs/2501.14430</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>coverforest：使用 Python 中的随机森林进行共形预测</title>
      <link>https://arxiv.org/abs/2501.14570</link>
      <description><![CDATA[arXiv:2501.14570v1 公告类型：新
摘要：共形预测为不确定性量化提供了一个框架，特别是以具有无分布保证覆盖范围的预测区间和集合的形式。虽然最近的交叉共形技术（如 CV+ 和 Jackknife+-after-bootstrap）比传统的分裂共形方法实现了更好的数据效率，但由于需要对训练和测试样本的袋外分数进行成对比较，因此会产生大量的计算成本。观察到这些方法自然地从集成模型（特别是随机森林）扩展而来，我们利用现有的优化随机森林实现来实现高效的交叉共形预测。
我们提出了 coverforest，这是一个 Python 包，它实现了专门针对随机森林优化的高效共形预测方法。coverforest 通过各种共形预测方法支持回归和分类任务，包括分裂共形、CV+、Jackknife+-after-bootstrap 和自适应预测集。我们的软件包利用并行计算和 Cython 优化来加速袋外计算。我们的实验表明，coverforest 的预测达到了所需的覆盖水平。此外，它的训练和预测时间比现有实现快 2-9 倍。coverforest 的源代码托管在 GitHub 上，网址为 https://github.com/donlapark/coverforest。]]></description>
      <guid>https://arxiv.org/abs/2501.14570</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过非凸凹极小极大优化实现最优运输重心</title>
      <link>https://arxiv.org/abs/2501.14635</link>
      <description><![CDATA[arXiv:2501.14635v1 公告类型：新
摘要：最优传输重心（又名 Wasserstein 重心）是平均的基本概念，从欧几里得空间延伸到概率分布的 Wasserstein 空间。当域维度 $d &gt; 1$ 时，计算点云上离散概率分布的非正则化重心是一项具有挑战性的任务。大多数用于近似重心问题的实用算法都是基于熵正则化的。在本文中，我们引入了一种近似线性时间 $O(m \log{m})$ 和线性空间复杂度 $O(m)$ 的原始对偶算法，即 Wasserstein-Descent $\dot{\mathbb{H}}^1$-Ascent (WDHA) 算法，用于在输入概率密度函数在 $m$ 点网格上离散化时计算精确的重心。 WDHA 算法成功的关键在于交替使用两种不同但密切相关的 Wasserstein 和 Sobolev 优化几何来解决原始重心和对偶 Kantorovich 势子问题。在合理的假设下，我们确定了当步长选择适当时 WDHA 到其驻点的收敛速度和迭代复杂度。在高分辨率（例如 $1024 \times 1024$ 图像）二维合成和真实数据上，与现有的 Sinkhorn 型算法相比，该算法具有更优越的计算效率、可扩展性和准确性。]]></description>
      <guid>https://arxiv.org/abs/2501.14635</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过预处理克服公平权衡：因果视角</title>
      <link>https://arxiv.org/abs/2501.14710</link>
      <description><![CDATA[arXiv:2501.14710v1 公告类型：新
摘要：训练机器学习模型以做出公平决策面临两个关键挑战：\emph{公平性-准确性权衡}源于强制公平性，与不受约束的模型相比，这会削弱其预测性能。不同公平性指标的不兼容性带来了另一种权衡——也称为\emph{不可能性定理}。最近的研究将观察到的数据中的偏差确定为可能的根本原因，并表明当在无偏数据上测量预测性能时，公平性和预测性能实际上是一致的。我们使用 FiND（虚构和规范期望）世界的框架对这些发现进行了因果解释，这是一个“公平”的世界，其中受保护的属性对目标变量没有因果影响。我们从理论上证明了：(i) 被认为不兼容的经典公平性指标在 FiND 世界中自然得到满足，而 (ii) 公平性与高预测性能相一致。我们通过提出如何在实践中受益于这些理论见解来扩展我们的分析，使用近似 FiND 世界的因果预处理方法。此外，我们提出了一种在我们无法访问 FiND 世界的实际用例中通过预处理评估 FiND 世界的近似值的方法。在模拟和实证研究中，我们证明这些预处理方法能够成功地近似 FiND 世界并解决这两种权衡。我们的结果为从业者提供了可行的解决方案，以同时实现公平性和高预测性能。]]></description>
      <guid>https://arxiv.org/abs/2501.14710</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过低秩矩阵感知学习量子信道和林德布拉迪斯的统一块测量设计</title>
      <link>https://arxiv.org/abs/2501.14080</link>
      <description><![CDATA[arXiv:2501.14080v1 公告类型：交叉 
摘要：量子超算子学习是量子信息科学中的一项关键任务，能够从测量数据中准确重建未知的量子操作。我们提出了一种基于矩阵感知技术的稳健方法，用于量子超算子学习，该方法超越了半正定的情况，涵盖了量子通道和林德布拉德。我们首先引入一种使用接近最佳测量次数的随机测量设计。通过利用受限等距特性 (RIP)，我们为存在噪声的情况下低秩超算子的可识别性和恢复提供了理论保证。此外，我们提出了一种分块测量设计，将断层扫描限制在子块中，在保持可比测量规模的同时显着提高性能。我们还为此设置提供了性能保证。我们的方法采用交替最小二乘 (ALS) 和加速来优化矩阵感知。数值实验验证了所提出方法的效率和可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2501.14080</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在长尾分类中做出可靠而灵活的决策</title>
      <link>https://arxiv.org/abs/2501.14090</link>
      <description><![CDATA[arXiv:2501.14090v1 公告类型：交叉 
摘要：长尾分类具有挑战性，因为其类别概率严重不平衡。虽然现有方法通常关注尾类的总体准确性或准确性，但它们忽略了一个关键方面：在现实世界的长尾问题中，某些类型的错误比其他错误的风险更大。例如，将患者（尾类）错误分类为健康个体（头类）比相反的情况会带来更严重的后果。为了解决这个关键问题，我们引入了在长尾分类中做出可靠和灵活的决策 (RF-DLC)，这是一个旨在对长尾问题进行可靠预测的新框架。利用贝叶斯决策理论，我们引入了一个集成增益，将长尾数据分布和决策程序无缝结合起来。我们进一步提出了一种有效的变分优化策略来应对决策风险目标。我们的方法很容易适应不同的效用矩阵，可以为特定任务设计，确保其在不同问题设置中的灵活性。在实证评估中，我们设计了一个新的指标“错误头部率”来量化尾部敏感风险，并对包括大规模图像分类和不确定性量化在内的多个现实任务进行了全面的实验，以证明我们方法的可靠性和灵活性。]]></description>
      <guid>https://arxiv.org/abs/2501.14090</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用贝叶斯优化选择配电网中采用 DER 的关键场景</title>
      <link>https://arxiv.org/abs/2501.14118</link>
      <description><![CDATA[arXiv:2501.14118v1 公告类型：交叉 
摘要：我们开发了一种新方法来选择对配电网最关键的 DER 采用场景。预测由于额外的 PV 采用者而导致的未来电压和线路流量违规风险对于公用事业投资规划至关重要，但仍然依赖于确定性或临时场景选择。我们提出了一种基于多目标贝叶斯优化的高效搜索框架。我们将底层电网压力指标视为计算成本高昂的黑盒函数，通过高斯过程代理进行近似，并设计一个基于场景在一系列基于线路和总线的违规目标中达到帕累托临界的概率的获取函数。我们的方法提供了统计保证，并且相对于保守的穷举搜索提供了数量级的加速。对具有 200-400 辆公交车的实际馈线的案例研究证明了我们方法的有效性和准确性。]]></description>
      <guid>https://arxiv.org/abs/2501.14118</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态规范深度学习</title>
      <link>https://arxiv.org/abs/2501.14152</link>
      <description><![CDATA[arXiv:2501.14152v1 公告类型：交叉 
摘要：我们引入了一个多模态深度学习框架，即规范神经网络 (PNN)，它结合了优化和机器学习的思想，据我们所知，这是处理多模态数据的第一个规范方法。PNN 是一个在嵌入上训练的前馈神经网络，用于输出结果优化处方。在两个现实世界的多模态数据集中，我们证明 PNN 规定的治疗方法能够显着改善经导管主动脉瓣置换术 (TAVR) 的估计结果，将估计术后并发症发生率降低 32%，并将肝脏创伤的估计死亡率降低 40% 以上。在四个现实世界的单模态表格数据集中，我们证明 PNN 的表现优于或可与其他众所周知的、最先进的规范模型相媲美；重要的是，在表格数据集上，我们还通过知识提炼恢复了可解释性，将可解释的最佳分类树模型拟合到 PNN 处方上作为分类目标，这对于许多实际应用至关重要。最后，我们证明我们的多模态 PNN 模型在随机数据分割中实现了与其他规范方法相当的稳定性，并在不同的数据集中产生了现实的处方。]]></description>
      <guid>https://arxiv.org/abs/2501.14152</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于图异常检测的双向课程学习：双重关注同质性和异质性</title>
      <link>https://arxiv.org/abs/2501.14197</link>
      <description><![CDATA[arXiv:2501.14197v1 公告类型：交叉
摘要：图异常检测（GAD）旨在从图中识别出与正常模式有显著差异的节点。以前的大多数研究都是模型驱动的，侧重于通过改进模型结构来增强检测效果。然而，这些方法往往平等对待所有节点，忽略了各个节点对训练的不同贡献。因此，我们引入了图课程学习作为一个简单有效的即插即用模块来优化GAD方法。现有的图课程学习主要关注图的同质性，将同质性高的节点视为简单节点。事实上，GAD模型不仅可以处理图的同质性，还可以处理异质性，这导致这些现有方法不适用。为了解决这个问题，我们提出了一种创新的双向课程学习策略（BCL），该策略将与邻居节点相似度较高和较低的节点分别视为关注同质性和关注异质性的简单节点，并优先进行训练。大量实验表明，BCL 可以快速融入现有的检测流程，并显著提升十个 GAD 异常检测模型在七个常用数据集上的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.14197</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>时间点过程的进展：贝叶斯方法、深度方法和 LLM 方法</title>
      <link>https://arxiv.org/abs/2501.14291</link>
      <description><![CDATA[arXiv:2501.14291v1 公告类型：交叉 
摘要：时间点过程 (TPP) 是用于表征连续时间中发生的事件序列的随机过程模型。传统的统计 TPP 有着悠久的历史，提出了许多模型并成功应用于各个领域。近年来，深度学习的进步推动了神经 TPP 的发展，使其在捕捉复杂的时间动态方面具有更大的灵活性和表现力。大型语言模型 (LLM) 的出现进一步激发了人们的兴趣，通过利用其丰富的上下文理解为事件序列的建模和分析提供了新的可能性。本调查从三个角度全面回顾了 TPP 的最新研究：贝叶斯、深度学习和 LLM 方法。我们首先回顾 TPP 的基本概念，然后深入讨论这三个框架中的模型设计和参数估计技术。我们还重新审视了 TPP 的经典应用领域，以强调它们的实际相关性。最后，我们概述了未来研究的挑战和有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2501.14291</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过消息传递进行分布式共形预测</title>
      <link>https://arxiv.org/abs/2501.14544</link>
      <description><![CDATA[arXiv:2501.14544v1 公告类型：交叉 
摘要：事后校准预训练模型对于确保可靠的推理至关重要，尤其是在医疗保健等安全关键领域。共形预测 (CP) 提供了一个强大的事后校准框架，通过利用保留的数据集为预测集提供无分布的统计覆盖保证。在这项工作中，我们解决了一个分散的环境，其中每个设备都有有限的校准数据，并且只能通过任意图拓扑与其邻居通信。我们提出了两种基于消息传递的方法，通过 CP 实现可靠的推理：基于分位数的分布式共形预测 (Q-DCP) 和基于直方图的分布式共形预测 (H-DCP)。Q-DCP 采用分布式分位数回归，并通过定制的平滑和正则化项增强以加速收敛，而 H-DCP 使用基于共识的直方图估计方法。通过大量实验，我们研究了不同网络拓扑中超参数调整要求、通信开销、覆盖保证和预测集大小之间的权衡。]]></description>
      <guid>https://arxiv.org/abs/2501.14544</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分层计数回声状态网络模型及其在研究生招生中的应用</title>
      <link>https://arxiv.org/abs/2501.14698</link>
      <description><![CDATA[arXiv:2501.14698v1 公告类型：交叉 
摘要：泊松自回归计数模型已发展成为相关计数数据的时间序列主要内容。本文提出了一种泊松自回归的替代方案：计数回声状态网络。回声状态网络可以通过优化惩罚似然以频率主义的方式进行统计分析，也可以通过 MCMC 抽样以贝叶斯方式进行统计分析。本文开发了用于计数数据的泊松回声状态技术，并将其应用于包含 1972-2021 年期间来自 1,758 所美国大学的研究生人数的海量计数数据集。还实施了负二项式模型以更好地处理计数中的过度分散。通过几种方法判断的预测性能比较了所提出的模型的性能。最后，基于分层负二项式的回声状态网络被判断为优越模型。]]></description>
      <guid>https://arxiv.org/abs/2501.14698</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EOC 的 MLP：NTK 的集中</title>
      <link>https://arxiv.org/abs/2501.14724</link>
      <description><![CDATA[arXiv:2501.14724v1 公告类型：交叉 
摘要：我们研究了神经切线核 (NTK) $K_\theta : \mathbb{R}^{m_0} \times \mathbb{R}^{m_0} \to \mathbb{R}^{m_l \times m_l}$ 的浓度，其中 $l$ 层多层感知器 (MLP) $N : \mathbb{R}^{m_0} \times \Theta \to \mathbb{R}^{m_l}$ 配备激活函数 $\phi(s) = a s + b \vert s \vert$，其中 $a,b \in \mathbb{R}$ 参数 $\theta \in \Theta$ 在混沌边缘 (EOC) 初始化。我们不依赖于仅在无限宽极限下渐近成立的梯度独立性假设，而是证明了梯度独立性的近似版本在有限宽度下成立。通过证明 NTK 项 $K_\theta(x_{i_1},x_{i_2})$（其中 $i_1,i_2 \in [1:n]$）在数据集 $\{x_1,\cdots,x_n\} \subset \mathbb{R}^{m_0}$ 上同时通过最大不等式集中，我们证明 NTK 矩阵 $K(\theta) = [\frac{1}{n} K_\theta(x_{i_1},x_{i_2}) : i_1,i_2 \in [1:n]] \in \mathbb{R}^{nm_l \times nm_l}$ 集中在其无限宽极限 $\overset{\scriptscriptstyle\infty}{K} \in \mathbb{R}^{nm_l \times nm_l}$ 附近，而无需线性过度参数化。我们的结果表明，为了准确地近似极限，隐藏层宽度必须随着 $m_k = k^2 m$ 二次增长，其中 $m \in \mathbb{N}+1$ 达到足够的浓度。对于这样的 MLP，我们获得浓度边界 $\mathbb{P}( \Vert K(\theta) - \overset{\scriptscriptstyle\infty}{K} \Vert \leq O((\Delta_\phi^{-2} + m_l^{\frac{1}{2}} l) \kappa_\phi^2 m^{-\frac{1}{2}})) \geq 1-O(m^{-1})$ 模对数项，其中我们表示为 $\Delta_\phi = \frac{b^2}{a^2+b^2}$ 和 $\kappa_\phi = \frac{\vert a \vert + \vert b \vert}{\sqrt{a^2 + b^2}}$。这特别表明，就 NTK 的浓度而言，绝对值（$\Delta_\phi=1$、$\kappa_\phi=1$）优于 ReLU（$\Delta_\phi=\frac{1}{2}$、$\kappa_\phi=\sqrt{2}$）。]]></description>
      <guid>https://arxiv.org/abs/2501.14724</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>