<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 30 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>具有一般阈值函数的非凸稳健矩阵补全的留一法分析</title>
      <link>https://arxiv.org/abs/2407.19446</link>
      <description><![CDATA[arXiv:2407.19446v1 公告类型：交叉 
摘要：我们研究了鲁棒矩阵补全 (RMC) 问题，其中底层低秩矩阵的部分观测条目被稀疏噪声破坏。针对此问题的现有非凸方法分析要么需要在算法中进行显式但经验上冗余的正则化，要么需要在分析中进行样本分割。在本文中，我们考虑了一种简单而有效的非凸方法，该方法在低秩部分的投影梯度步骤和稀疏噪声部分的阈值步骤之间交替。受低秩矩阵补全的留一法分析的启发，该方法可以实现一类阈值函数的线性收敛，例如软阈值和 SCAD。据我们所知，这是第一次对 RMC 非凸方法进行留一法分析。此外，当将我们的结果应用于低秩矩阵完成时，它提高了奇异值投影方法现有结果的采样复杂度。]]></description>
      <guid>https://arxiv.org/abs/2407.19446</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:47 GMT</pubDate>
    </item>
    <item>
      <title>深度神经网络中特征学习的弹簧块理论</title>
      <link>https://arxiv.org/abs/2407.19353</link>
      <description><![CDATA[arXiv:2407.19353v1 公告类型：交叉
摘要：深度学习的一个核心问题是深度神经网络 (DNN) 如何学习特征。DNN 层逐渐将数据折叠成规则的低维几何图形。非线性、噪声、学习率、宽度、深度和许多其他参数的这种集体效应，已经逃避了从微观神经元动力学构建的第一性原理理论。在这里，我们展示了一个噪声非线性相图，突出显示了浅层或深层在哪里更有效地学习特征。然后，我们提出了一种特征学习的宏观机械理论，该理论准确地再现了该相图，为为什么以及如何一些 DNN 是“懒惰的”，而一些是“主动的”提供了清晰的直觉，并将特征学习在层上的分布与测试准确度联系起来。]]></description>
      <guid>https://arxiv.org/abs/2407.19353</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:46 GMT</pubDate>
    </item>
    <item>
      <title>通过深度学习增强 Black-Scholes Delta 对冲</title>
      <link>https://arxiv.org/abs/2407.19367</link>
      <description><![CDATA[arXiv:2407.19367v1 公告类型：交叉 
摘要：本文提出了一种期权深度 delta 对冲框架，利用神经网络学习对冲函数与隐含的 Black-Scholes delta 之间的残差。这种方法利用这些残差的平滑特性，提高了深度学习的性能。利用十年的每日标准普尔 500 指数期权数据，我们的实证分析表明，使用均方一步对冲误差作为损失函数来学习残差，比直接学习对冲函数可以显著提高对冲性能，通常可以提高 100% 以上。在学习残差时添加输入特征可以提高看跌期权的对冲性能，而不是看涨期权，而市场情绪则不那么重要。此外，使用三年数据学习残差的结果与使用十年数据直接学习的结果相当，证明了我们的方法需要的数据更少。]]></description>
      <guid>https://arxiv.org/abs/2407.19367</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:46 GMT</pubDate>
    </item>
    <item>
      <title>具有未观测变量和测量误差的线性模型中的因果发现</title>
      <link>https://arxiv.org/abs/2407.19426</link>
      <description><![CDATA[arXiv:2407.19426v1 公告类型：交叉 
摘要：未观察到的共同原因的存在和测量误差的存在是因果结构学习任务中最具限制性的两个挑战。忽略这两个挑战中的任何一个都可能导致在感兴趣的变量之间检测到虚假的因果关系。在本文中，我们研究了在这两个挑战可能同时存在的系统中的因果发现问题。我们考虑包括四种类型变量的线性模型：直接观察到的变量、未直接观察到但有误差测量的变量、相应的测量值以及既未观察到也未测量的变量。我们描述了这种模型在可分离性条件下的可识别程度（即，表示与观察变量有关的独立外生噪声项的矩阵是可识别的）以及两个版本的忠诚度假设，并提出了观察等价的概念。我们提供等效模型的图形特征，并提出可以返回与基本事实等效的模型的恢复算法。]]></description>
      <guid>https://arxiv.org/abs/2407.19426</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:46 GMT</pubDate>
    </item>
    <item>
      <title>高斯混合模型数据集中聚类搜索算法的仿真研究</title>
      <link>https://arxiv.org/abs/2407.19199</link>
      <description><![CDATA[arXiv:2407.19199v1 公告类型：交叉 
摘要：确定聚类数是数据聚类中的一个基本问题。已经提出了几种算法，包括使用欧几里得距离的基于质心的算法和使用混合概率分布的基于模型的算法。其中，通过反复拆分或合并聚类来搜索聚类数量的贪婪算法在计算时间方面对于大样本量的问题具有优势。然而，仍然需要在系统评估实验中比较这些方法的研究。本研究在高斯混合模型 (GMM) 可以生成的各种情况下检验基于质心和基于模型的聚类搜索算法。这些案例是通过结合五个因素生成的：维数、样本大小、聚类数、聚类重叠和协方差类型。结果表明，一些基于欧几里得距离的聚类拆分标准在聚类重叠时会做出不合理的决策。结果还表明，如果样本量足够，基于模型的算法与基于质心的方法相比，对协方差类型和聚类重叠不敏感。我们的聚类搜索实现代码可在 https://github.com/lipryou/searchClustK 获得。]]></description>
      <guid>https://arxiv.org/abs/2407.19199</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>简约贝叶斯上下文树的近似学习</title>
      <link>https://arxiv.org/abs/2407.19236</link>
      <description><![CDATA[arXiv:2407.19236v1 公告类型：交叉 
摘要：分类序列模型通常假设可交换或一阶依赖序列元素。这些是常见的假设，例如，在计算机恶意软件痕迹和蛋白质序列模型中。尽管这种简化假设导致计算可处理性，但这些模型无法捕获可能被利用来提高预测能力的长距离复杂依赖结构。为此，提出了一种贝叶斯建模框架，以简约的方式捕获分类序列中丰富的依赖结构，内存效率适合实时处理数据流。简约贝叶斯上下文树被引入为具有共轭先验分布的变阶马尔可夫模型的一种形式。通过删除冗余依赖项和聚类顺序上下文，新框架需要的参数比固定阶马尔可夫模型少。通过计算效率高的基于模型的聚集聚类过程对上下文树结构进行近似推断。所提出的框架在合成和真实世界数据示例上进行了测试，当适用于真实蛋白质序列和蜜罐计算机终端会话时，其表现优于现有的序列模型。]]></description>
      <guid>https://arxiv.org/abs/2407.19236</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>增强广义正态分布：将机器学习与运维知识相结合</title>
      <link>https://arxiv.org/abs/2407.19092</link>
      <description><![CDATA[arXiv:2407.19092v1 公告类型：交叉 
摘要：机器学习 (ML) 技术在操作环境中的应用通常面临两个挑战：i) ML 方法主要提供点预测，而许多操作问题需要分布信息；ii) 它们通常不包含操作文献中的大量知识，特别是表征特定分布的理论和经验发现。我们引入了一种新颖而严格的方法，即增强广义正态分布 ($b$GND)，以应对这些挑战。广义正态分布 (GND) 涵盖了操作中常见的各种参数分布，$b$GND 利用树学习器的梯度提升来灵活地估计 GND 的参数作为协变量的函数。我们建立了 $b$GND 的统计一致性，从而将这一关键属性扩展到 ML 文献中研究的缺乏此类保证的特殊情况。我们使用来自美国一家大型学术急诊科的数据，表明通过利用医疗保健运营文献中的发现，可以显著改善患者等待和服务时间的分布预测。具体而言，$b$GND 的表现分别比用于预测等待和服务时间的分布无关 ML 基准高出 6% 和 9%。进一步的分析表明，这些改进意味着患者满意度提高 9%，心肌梗死患者死亡率降低 4%。我们的工作强调了将 ML 与运营知识相结合以增强分布预测的重要性。]]></description>
      <guid>https://arxiv.org/abs/2407.19092</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>非神经模型中的出现：通过平均梯度外积理解模块化算法</title>
      <link>https://arxiv.org/abs/2407.20199</link>
      <description><![CDATA[arXiv:2407.20199v1 公告类型：新
摘要：经过训练以解决模块化算术任务的神经网络表现出 grokking，这是一种在模型在训练过程中达到 100% 训练准确率之后很长时间测试准确率才开始提高的现象。它通常被视为“涌现”的一个例子，其中模型能力通过相变急剧体现出来。在这项工作中，我们表明 grokking 现象并非神经网络或基于梯度下降的优化所特有的。具体而言，我们表明这种现象发生在使用递归特征机 (RFM) 学习模块化算术时，RFM 是一种使用平均梯度外积 (AGOP) 实现通用机器学习模型的任务特定特征学习的迭代算法。当与内核机器结合使用时，迭代 RFM 会导致从随机、接近零的测试准确率快速过渡到完美的测试准确率。这种转变无法从训练损失（完全为零）或测试损失（在初始迭代中保持不变）中预测出来。相反，正如我们所展示的，转变完全由特征学习决定：RFM 逐渐学习块循环特征来解决模块化算法。与 RFM 的结果相似，我们表明解决模块化算法的神经网络也会学习块循环特征。此外，我们提供了理论证据，表明 RFM 使用此类块循环特征来实现傅里叶乘法算法，先前的研究认为这是神经网络在这些任务上学习的泛化解决方案。我们的结果表明，涌现可以纯粹来自学习与任务相关的特征，并且并不特定于神经架构或基于梯度下降的优化方法。此外，我们的工作为 AGOP 作为神经网络中特征学习的关键机制提供了更多证据。]]></description>
      <guid>https://arxiv.org/abs/2407.20199</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>Uber 使用因果机器学习进行实际市场优化</title>
      <link>https://arxiv.org/abs/2407.19078</link>
      <description><![CDATA[arXiv:2407.19078v1 公告类型：交叉 
摘要：市场杠杆的预算分配，例如对司机的激励和对乘客的促销，长期以来一直是 Uber 的技术和业务挑战；了解杠杆预算变化的影响并估计成本效率以实现预定义预算至关重要，目标是实现最大化商业价值的最佳分配；我们引入了一种端到端机器学习和优化程序，依靠特征存储、模型训练和服务、优化器和回测来自动化城市的预算决策；提出基于 S-Learner 和新型张量 B 样条回归模型的最先进的深度学习 (DL) 估计器，我们使用 ADMM 和原始对偶内点凸优化解决高维优化问题，大大提高了 Uber 的资源配置效率。]]></description>
      <guid>https://arxiv.org/abs/2407.19078</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>分段确定性生成模型</title>
      <link>https://arxiv.org/abs/2407.19448</link>
      <description><![CDATA[arXiv:2407.19448v1 公告类型：新
摘要：我们引入了一类基于分段确定性马尔可夫过程 (PDMP) 的新型生成模型，这是一类非扩散随机过程，由确定性运动和随机时间的随机跳跃组成。与扩散类似，这种马尔可夫过程允许时间反转，而时间反转最终也会成为 PDMP。我们将这一观察结果应用于文献中考虑的三个 PDMP：之字形过程、弹性粒子采样器和随机汉密尔顿蒙特卡罗。对于这三个特定实例，我们表明，相应时间反转的跳跃率和内核允许显式表达式，具体取决于跳跃前后所考虑的 PDMP 的一些条件密度。基于这些结果，我们提出了有效的训练程序来学习这些特征，并考虑了近似模拟逆过程的方法。最后，在基础分布为标准 $d$ 维高斯分布的情况下，我们给出了数据分布与模型所得分布之间的总变异距离的界限。有希望的数值模拟支持对此类模型的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2407.19448</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:42 GMT</pubDate>
    </item>
    <item>
      <title>自适应覆盖输入域上的回归和分类的泛化界限</title>
      <link>https://arxiv.org/abs/2407.19715</link>
      <description><![CDATA[arXiv:2407.19715v1 公告类型：新
摘要：我们主要关注的是泛化界限，它是泛化误差的上限。我们的分析分别深入研究了回归和分类任务，以确保进行彻底的检查。我们假设目标函数是实值的，并且对于回归任务是 Lipschitz 连续的。我们使用 2 范数和均方根误差 (RMSE) 变量来测量预测值和实际值之间的差异。在分类任务的情况下，我们将目标函数视为一个独热分类器，表示分段常数函数，并使用 0/1 损失进行误差测量。我们的分析强调了实现泛化界限集中不等式所需的不同样本复杂度，突出了回归和分类任务的学习效率的变化。此外，我们证明回归和分类函数的泛化界限与网络中参数数量的多项式成反比，其程度取决于假设类和网络架构。这些发现强调了过度参数化网络的优势，并阐明了此类系统中良性过度拟合的条件。]]></description>
      <guid>https://arxiv.org/abs/2407.19715</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:42 GMT</pubDate>
    </item>
    <item>
      <title>使多轴高斯图模型可扩展至数百万个样本和特征</title>
      <link>https://arxiv.org/abs/2407.19892</link>
      <description><![CDATA[arXiv:2407.19892v1 公告类型：新
摘要：高斯图模型可用于提取数据集特征之间的条件依赖关系。这通常是通过对样本做出独立性假设来实现的，但现实中很少满足这一假设。然而，避免这种假设的最先进的方法不可扩展，运行时间为 $O(n^3)$，空间复杂度为 $O(n^2)$。在本文中，我们介绍了一种运行时间为 $O(n^2)$，空间复杂度为 $O(n)$，且不假设独立性的方法。
我们在合成数据集和真实数据集上验证了我们的模型，结果表明我们的方法的准确性与以前的工作相当。我们证明我们的方法可以用于前所未有的大数据集，例如现实世界的 1,000,000 个细胞 scRNA-seq 数据集；这在以前的方法中是不可能的。我们的方法保留了先前研究的灵活性，例如能够处理多模态张量变量数据集，并且能够处理任意边际分布的数据。与先前研究不同，我们方法的另一个优点是，我们的超参数易于解释。]]></description>
      <guid>https://arxiv.org/abs/2407.19892</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:42 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯元学习，实现可信的不确定性量化</title>
      <link>https://arxiv.org/abs/2407.19287</link>
      <description><![CDATA[arXiv:2407.19287v1 公告类型：新
摘要：我们考虑具有可信不确定性量化的贝叶斯回归问题。我们定义，如果可以通过依赖于具有预先指定概率的预测分布的区间捕获基本事实，则不确定性量化是可信的。此外，我们提出了 Trust-Bayes，这是一种用于贝叶斯元学习的新型优化框架，它认识到可信的不确定性量化，而无需对函数的先验模型/分布做出明确的假设。我们描述了通过指定间隔捕获基本事实的概率的下限，并分析了可信不确定性量化的可行概率的样本复杂性。使用高斯过程回归对案例研究进行了蒙特卡罗模拟，以验证并与 Meta-prior 算法进行比较。]]></description>
      <guid>https://arxiv.org/abs/2407.19287</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:41 GMT</pubDate>
    </item>
    <item>
      <title>通过统计推断对数据进行 Shapley 不确定性量化</title>
      <link>https://arxiv.org/abs/2407.19373</link>
      <description><![CDATA[arXiv:2407.19373v1 公告类型：新
摘要：随着数据在决策中发挥越来越重要的作用，数据市场的出现凸显了数据估值日益增长的重要性。在机器学习领域，Data Shapley 是一种广受欢迎的数据估值方法。然而，Data Shapley 的一个局限性是它假设数据集是固定的，这与数据不断发展和扩展的现实应用的动态性质形成鲜明对比。本文建立了 Data Shapley 与无限阶 U 统计量之间的关系，并通过从 U 统计量的角度量化 Data Shapley 随数据分布变化的不确定性来解决这一限制。我们对数据估值进行统计推断，以获得估计的置信区间。我们构建了两种不同的算法来估计这种不确定性，并为它们的适用情况提供建议。我们还对各种数据集进行了一系列实验以验证渐近正态性，并提出了通过该方法实现的实际交易场景。]]></description>
      <guid>https://arxiv.org/abs/2407.19373</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:41 GMT</pubDate>
    </item>
    <item>
      <title>Flusion：整合多种数据源，实现精准流感预测</title>
      <link>https://arxiv.org/abs/2407.19054</link>
      <description><![CDATA[arXiv:2407.19054v1 公告类型：新 
摘要：在过去十年中，美国疾病控制和预防中心 (CDC) 组织了一年一度的流感预测挑战赛，其动机是准确的概率预测可以提高态势感知并产生更有效的公共卫生行动。从 2021/22 流感季节开始，该挑战赛的预测目标基于 CDC 的国家医疗保健安全网络 (NHSN) 监测系统中报告的住院情况。通过 NHSN 报告流感住院情况始于过去几年，因此该信号只有有限量的历史数据可用。为了在目标监测系统数据有限的情况下生成预测，我们在这些数据中增加了两个具有较长历史记录的信号：1) ILI+，估计患者患有流感的门诊就诊比例；以及 2) 选定一组医疗机构中实验室确诊的流感住院率。我们的模型 Flusion 是一个将梯度提升分位数回归模型与贝叶斯自回归模型相结合的集成模型。梯度提升模型在所有三个数据信号上进行训练，而自回归模型仅在目标信号上进行训练；所有模型都针对多个位置的数据进行联合训练。Flusion 是美国疾控中心 2023/24 季节流感预测挑战赛中表现最好的模型。在本文中，我们探讨了 Flusion 成功的因素，我们发现其强劲的表现主要得益于使用梯度提升模型，该模型针对来自多个监测信号和位置的数据进行联合训练。这些结果表明跨地点和监测信号共享信息的价值，尤其是当这样做可以增加可用的训练数据池时。]]></description>
      <guid>https://arxiv.org/abs/2407.19054</guid>
      <pubDate>Tue, 30 Jul 2024 06:20:40 GMT</pubDate>
    </item>
    </channel>
</rss>