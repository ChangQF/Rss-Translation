<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 22 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>图结构多边际 Schr\"odinger 桥计算资源使用的随机学习</title>
      <link>https://arxiv.org/abs/2405.12463</link>
      <description><![CDATA[arXiv:2405.12463v1 公告类型：交叉
摘要：我们建议将软件的时变随机计算资源使用情况作为图结构 Schr\&quot;odinger 桥问题来学习。一般来说，从数据中学习计算资源使用情况具有挑战性，因为诸如 CPU 指令数量和最后一级缓存请求的数量既是时变的，又是统计相关的。我们提出的方法能够以非参数方式从测量的配置文件快照中学习计算资源使用的联合时变随机性。我们提供了单核和多核情况下的随机学习的详细算法，讨论了收敛保证、计算复杂性，并在两个案例研究中展示了它们的实际用途：一个。 -核心非线性模型预测控制器，以及综合多核软件。]]></description>
      <guid>https://arxiv.org/abs/2405.12463</guid>
      <pubDate>Wed, 22 May 2024 06:19:06 GMT</pubDate>
    </item>
    <item>
      <title>关于离散概率神经网络的测量校准</title>
      <link>https://arxiv.org/abs/2405.12412</link>
      <description><![CDATA[arXiv:2405.12412v1 公告类型：交叉
摘要：随着机器学习系统越来越多地集成到现实世界的应用中，准确表示不确定性对于提高其安全性、鲁棒性和可靠性至关重要。通过最大似然训练神经网络来拟合高维概率分布已成为不确定性量化的有效方法。然而，此类模型通常表现出较差的校准，导致过度自信的预测。预期校准误差 (ECE) 和负对数似然 (NLL) 等传统指标存在局限性，包括偏差和参数假设。本文提出了一种使用条件核均值嵌入来测量校准差异的新方法，而无需这些偏差和假设。对合成数据的初步实验证明了该方法的潜力，未来的工作计划用于更复杂的应用。]]></description>
      <guid>https://arxiv.org/abs/2405.12412</guid>
      <pubDate>Wed, 22 May 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>用于从人类演示和反馈中进行离线奖励学习的统一线性编程框架</title>
      <link>https://arxiv.org/abs/2405.12421</link>
      <description><![CDATA[arXiv:2405.12421v1 公告类型：交叉
摘要：逆强化学习（IRL）和人类反馈强化学习（RLHF）是奖励学习的关键方法，涉及基于观察到的人类演示和反馈来推断和塑造顺序决策问题的潜在奖励函数。奖励学习方面的大多数先前工作都依赖于有关决策或偏好模型的先验知识或假设，这可能会导致鲁棒性问题。为此，本文介绍了一种专为离线奖励学习量身定制的新型线性规划（LP）框架。该框架利用预先收集的轨迹而无需在线探索，根据适当设计的 LP 的原始对偶最优性条件估计可行的奖励集，并提供具有可证明的样本效率的最优性保证。我们的 LP 框架还能够将奖励函数与人类反馈（例如成对轨迹比较数据）结合起来，同时保持计算的易处理性和样本效率。我们通过分析示例和数值实验证明，与传统的最大似然估计（MLE）方法相比，我们的框架有可能实现更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.12421</guid>
      <pubDate>Wed, 22 May 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>EKM：$K$-medoids 问题的精确多项式时间算法</title>
      <link>https://arxiv.org/abs/2405.12237</link>
      <description><![CDATA[arXiv:2405.12237v1 公告类型：交叉
摘要：$K$-medoids 问题是一项具有挑战性的组合聚类任务，广泛应用于数据分析应用中。虽然已经提出了许多算法来解决这个问题，但这些算法都无法在多项式时间内获得该问题的精确（全局最优）解决方案。在本文中，我们提出了 EKM：一种以最坏情况 $O\left(N^{K+1}\right)$ 时间复杂度精确解决该问题的新颖算法。 EKM 是根据转换编程和组合生成的最新进展，使用正式的程序推导步骤而开发的。推导的算法通过构造证明是正确的。我们通过将算法与大量现实世界数据集上的各种近似方法进行比较来证明算法的有效性。我们表明，我们算法的挂钟运行时间与合成数据集的最坏情况时间复杂度分析相匹配，明显优于基于分支定界的基准 MIP 求解器的指数时间复杂度。据我们所知，这是针对这个普遍存在的问题的第一个经过严格证明的多项式时间实用算法。]]></description>
      <guid>https://arxiv.org/abs/2405.12237</guid>
      <pubDate>Wed, 22 May 2024 06:19:04 GMT</pubDate>
    </item>
    <item>
      <title>随机储层计算机</title>
      <link>https://arxiv.org/abs/2405.12382</link>
      <description><![CDATA[arXiv:2405.12382v1 公告类型：交叉
摘要：与典型的神经网络相比，油藏计算是机器学习的一种形式，它利用非线性动力系统以经济有效的方式执行复杂的任务。储层计算（特别是量子储层计算）的许多最新进展都利用了本质上随机的储层。然而，使用这些系统的理论依据尚未得到充分证实。在本文中，我们研究了随机储层计算机的普适性，其中我们使用随机系统进行储层计算，使用每个储层状态的概率而不是状态本身作为读数。在随机油藏计算中，整个油藏计算机的不同状态的数量可能随着油藏硬件的大小呈指数级扩展，从而提供紧凑的设备尺寸的优势。我们证明随机回波状态网络的类，以及所有随机储层计算机的类，是通用逼近类。我们还研究了随机油藏计算机在分类和混沌时间序列预测方面的两个实际例子的性能。虽然散粒噪声是随机油藏计算性能的限制因素，但在噪声影响很小的情况下，与具有类似硬件的确定性油藏计算机相比，我们的性能显着提高。]]></description>
      <guid>https://arxiv.org/abs/2405.12382</guid>
      <pubDate>Wed, 22 May 2024 06:19:04 GMT</pubDate>
    </item>
    <item>
      <title>学习随机扩散过程的无穷小生成器</title>
      <link>https://arxiv.org/abs/2405.12940</link>
      <description><![CDATA[arXiv:2405.12940v1 公告类型：新
摘要：我们研究随机扩散过程的无穷小生成器的数据驱动学习，这对于理解自然和物理系统的数值模拟至关重要。生成器的无界性质提出了重大挑战，使得希尔伯特-施密特算子的传统分析技术无效。为了克服这个问题，我们引入了一种基于这些随机过程的能量泛函的新颖框架。我们的方法通过在完整和部分知识环境中基于能量的风险度量来整合物理先验。我们评估了在部分知识设置中再现核希尔伯特空间（RKHS）的降秩估计器的统计性能。值得注意的是，我们的方法提供了独立于状态空间维度的学习界限，并确保非虚假谱估计。此外，我们还阐明了随机扩散的内在能量引起的度量与用于生成器估计的 RKHS 度量之间的失真如何影响谱学习界限。]]></description>
      <guid>https://arxiv.org/abs/2405.12940</guid>
      <pubDate>Wed, 22 May 2024 06:19:03 GMT</pubDate>
    </item>
    <item>
      <title>使用单一无条件扩散模型进行分布外检测</title>
      <link>https://arxiv.org/abs/2405.11881</link>
      <description><![CDATA[arXiv:2405.11881v1 公告类型：交叉
摘要：分布外（OOD）检测是机器学习中的一项关键任务，旨在识别异常样本。传统上，无监督方法利用深度生成模型进行 OOD 检测。然而，在根据新分布评估异常时，此类方法需要不同的模型。随着基础生成模型的出现，本文探讨了单个通用模型是否也可以跨不同任务执行 OOD 检测。为此，我们在这项工作中引入了我们的方法，扩散路径（DiffPath）。 DiffPath 建议利用最初训练的单一扩散模型来执行 OOD 检测的无条件生成。具体来说，我们引入了一种测量连接样本与标准法线的扩散路径的变化率和曲率的新技术。大量实验表明，使用单一模型，DiffPath 在涉及不同分布的各种 OOD 任务上的性能优于先前的工作。我们的代码可在 https://github.com/clear-nus/diffpath 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2405.11881</guid>
      <pubDate>Wed, 22 May 2024 06:19:03 GMT</pubDate>
    </item>
    <item>
      <title>Epanechnikov 变分自动编码器</title>
      <link>https://arxiv.org/abs/2405.12783</link>
      <description><![CDATA[arXiv:2405.12783v1 公告类型：新
摘要：在本文中，我们通过 KDE 逼近后验并推导 Kullback-Leibler (KL) 散度的上限，将变分自编码器 (VAE) [17] 和核密度估计 (KDE) [25]、[23] 连接起来。在证据下限（ELBO）中。 KDE 的灵活性使得 VAE 中后验的优化成为可能，这不仅解决了普通 VAE 中高斯潜在空间的局限性，而且还为估计 ELBO 中的 KL 散度提供了新的视角。在适当的条件下[9]、[3]，我们证明Epanechnikov核是渐近最小化KL散度导出上限的最佳选择。与高斯核相比，Epanechnikov 核具有紧凑的支持，这应该使生成的样本噪声更少且模糊。 Epanechnikov 核在 ELBO 中的实现非常简单，因为它位于可以直接使用重参数化技巧的“位置尺度”分布族中。在 MNIST、Fashion-MNIST、CIFAR-10 和 CelebA 等基准数据集上进行的一系列实验进一步证明了 Epanechnikov 变分自动编码器 (EVAE) 在重建图像质量方面优于普通 VAE（通过 FID 分数和清晰度来衡量）[ 27]。]]></description>
      <guid>https://arxiv.org/abs/2405.12783</guid>
      <pubDate>Wed, 22 May 2024 06:19:02 GMT</pubDate>
    </item>
    <item>
      <title>LLM 流程：以自然语言为条件的数值预测分布</title>
      <link>https://arxiv.org/abs/2405.12856</link>
      <description><![CDATA[arXiv:2405.12856v1 公告类型：新
摘要：机器学习从业者在将其先验知识和信念正式整合到预测模型中时经常面临重大挑战，从而限制了细致入微和上下文感知分析的潜力。此外，将先验知识整合到概率建模中所需的专业知识通常限制了这些模型对专家的应用。我们的目标是建立一个回归模型，可以在描述用户先验知识的自然语言文本的指导下处理数值数据并在任意位置进行概率预测。大型语言模型 (LLM) 为设计此类工具提供了一个有用的起点，因为它们 1) 提供了一个界面，用户可以在其中将专家见解融入自然语言中；2) 为利用用户在 LLM 中编码的潜在问题相关知识提供了机会。自己可能没有。我们首先探索从法学硕士中得出明确、连贯的数值预测分布的策略。我们在预测、多维回归、黑盒优化和图像建模等设置中检查任意多个数量上的联合预测分布（我们称之为 LLM 过程）。我们研究了提示得出一致预测分布的实际细节，并证明了它们在回归中的有效性。最后，我们展示了将文本有效地合并到数值预测中的能力，提高了预测性能并提供了反映定性描述的定量结构。这让我们开始探索法学硕士隐式编码的丰富、有根据的假设空间。]]></description>
      <guid>https://arxiv.org/abs/2405.12856</guid>
      <pubDate>Wed, 22 May 2024 06:19:02 GMT</pubDate>
    </item>
    <item>
      <title>通过块引导程序对差分私有随机梯度下降进行不确定性量化</title>
      <link>https://arxiv.org/abs/2405.12553</link>
      <description><![CDATA[arXiv:2405.12553v1 公告类型：新
摘要：随机梯度下降（SGD）是机器学习中广泛使用的工具。在差分隐私（DP）的背景下，SGD 在过去几年中得到了很好的研究，其中重点主要集中在收敛速度和隐私保证上。虽然在非私有情况下，一些作者已经解决了通过 bootstrap 对 SGD 进行不确定性量化（UQ）的问题，但由于对私有数据的多次查询，这些过程无法转移到差分隐私。在本文中，我们提出了一种本地差分隐私下 SGD 的新型块引导程序，该引导程序在计算上易于处理，并且不需要调整隐私预算。该方法易于实现，适用于广泛的估计问题。我们证明了我们方法的有效性，并通过模拟研究说明了其有限样本特性。作为副产品，新方法还为非私有 SGD 的 UQ 提供了一个简单的替代数值工具。]]></description>
      <guid>https://arxiv.org/abs/2405.12553</guid>
      <pubDate>Wed, 22 May 2024 06:19:01 GMT</pubDate>
    </item>
    <item>
      <title>具有不确定性评估的无模型预测</title>
      <link>https://arxiv.org/abs/2405.12684</link>
      <description><![CDATA[arXiv:2405.12684v1 公告类型：新
摘要：深度非参数回归以利用深度神经网络学习目标函数为特征，近年来已成为研究关注的焦点。尽管在理解收敛率方面取得了相当大的进展，但渐近性质的缺乏阻碍了严格的统计推断。为了解决这一差距，我们提出了一种新颖的框架，利用条件扩散模型，将深度估计范式转变为有利于条件均值估计的平台。理论上，我们为条件扩散模型开发了端到端收敛率，并建立了生成样本的渐近正态性。因此，我们有能力构建置信区域，促进稳健的统计推断。此外，通过数值实验，我们凭经验验证了我们提出的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.12684</guid>
      <pubDate>Wed, 22 May 2024 06:19:01 GMT</pubDate>
    </item>
    <item>
      <title>粒子群优化及其在最大似然估计和惩罚负二项式回归中的应用</title>
      <link>https://arxiv.org/abs/2405.12386</link>
      <description><![CDATA[arXiv:2405.12386v1 公告类型：新
摘要：nlminb、optim (R) 或 nlmixed (SAS) 等通用优化例程经常用于估计非标准分布中的模型参数。本文介绍了粒子群优化 (PSO)，作为当前统计中使用的许多算法的替代方案。我们发现 PSO 不仅可以重现与上述例程相同的结果，还可以在其他例程无法收敛时产生更优化的结果。在后一种情况下，它还可以识别问题的根源。我们通过四个示例强调使用 PSO 的优点，其中：(1) 当广义分布中的某些参数不明显或使用 R 或 SAS 中的例程计算不明显时，使用 PSO 无法识别这些参数； (2) PSO 可以产生对数二项式回归的估计结果，而当前例程无法产生； (3) PSO 为带有 LASSO 罚分的二项式回归提供了灵活性，而 Stata 和 SAS 中的 GLM 和 GENMOD 等标准软件包分别不支持这种功能，并且 (4) PSO 为 EE-IW 分布提供了与与依赖矩的传统统计方法的方法。]]></description>
      <guid>https://arxiv.org/abs/2405.12386</guid>
      <pubDate>Wed, 22 May 2024 06:19:00 GMT</pubDate>
    </item>
    <item>
      <title>一种基于度量的一维流形学习主曲线方法</title>
      <link>https://arxiv.org/abs/2405.12390</link>
      <description><![CDATA[arXiv:2405.12390v1 公告类型：新
摘要：主曲线是一种著名的统计方法，面向流形学习，使用微分几何的概念。在本文中，我们提出了一种新颖的基于度量的主曲线（MPC）方法，该方法可以学习空间数据的一维流形。合成数据集使用 MNIST 数据集的实际应用表明，我们的方法可以很好地学习一维流形的形状。]]></description>
      <guid>https://arxiv.org/abs/2405.12390</guid>
      <pubDate>Wed, 22 May 2024 06:19:00 GMT</pubDate>
    </item>
    <item>
      <title>使用双地标积分算子对高维噪声数据集进行核谱联合嵌入</title>
      <link>https://arxiv.org/abs/2405.12317</link>
      <description><![CDATA[arXiv:2405.12317v1 公告类型：新
摘要：多个异构数据集的综合分析已成为许多研究领域的标准实践，特别是在单细胞基因组学和医学信息学领域。现有的方法常常受到捕获非线性结构的能力有限、对噪声和高维影响的考虑不足、缺乏对信号和样本大小不平衡的适应性的影响，并且它们的结果有时难以解释。为了解决这些限制，我们提出了一种新颖的核谱方法，可以实现两个独立观察的高维噪声数据集的联合嵌入。所提出的方法自动捕获并利用跨数据集可能共享的低维结构来提高嵌入质量。获得的低维嵌入可用于许多下游任务，例如同时聚类、数据可视化和去噪。所提出的方法通过严格的理论分析得到证明。具体来说，我们展示了我们的方法在恢复低维无噪声信号方面的一致性，并表征了信噪比对收敛速度的影响。在联合流形模型框架下，我们建立了最终嵌入与一些新引入的积分算子的本征函数的收敛。这些算子称为双地标积分算子，由一些再生核希尔伯特空间 (RKHS) 的卷积核映射定义。这些 RKHS 捕获两个数据集部分或完​​全共享的底层低维非线性信号结构。我们对两个单细胞组学数据集的数值实验和分析证明了所提出的方法在嵌入和几个下游任务中相对于现有方法的经验优势。]]></description>
      <guid>https://arxiv.org/abs/2405.12317</guid>
      <pubDate>Wed, 22 May 2024 06:18:59 GMT</pubDate>
    </item>
    <item>
      <title>时间序列模型的联合预测区域</title>
      <link>https://arxiv.org/abs/2405.12234</link>
      <description><![CDATA[arXiv:2405.12234v1 公告类型：新
摘要：机器学习算法因提供点预测而不是预测区间而臭名昭著。在许多应用中，人们需要对预测和预测区间有信心。这些间隔串在一起，产生具有所需显着性水平的联合预测区域。当数据是 IID 时，计算联合预测区域 (JPR) 是一项简单的任务。然而，当时间序列需要 JPR 时，由于观测值之间的依赖性，任务变得过于困难。该项目旨在实现 Wolf 和 Wunderli 构建 JPR 的方法，并将其与其他方法（例如 NP 启发式、联合边际）进行比较。正在研究的方法基于引导，并使用不同的预测变量（例如 ARIMA 和 LSTM）应用于不同的数据集（最低温度、太阳黑子）。应用所研究方法的一项挑战是推导模型的预测标准误差，它无法通过分析获得。还设计了一种估计不同预测变量的预测标准误差的新方法。最后，将该方法应用于合成数据集以查找经验平均值和经验宽度，并对 Wolf 和 Wunderli 论文的结果进行整合。实验结果表明，使用神经网络等强预测器会缩小宽度，随着预测范围 H 的增加和显着性水平 alpha 的降低而扩大宽度，使用 K-FWE 中的参数 k 控制宽度，以及使用联合边际会丢失信息。]]></description>
      <guid>https://arxiv.org/abs/2405.12234</guid>
      <pubDate>Wed, 22 May 2024 06:18:58 GMT</pubDate>
    </item>
    </channel>
</rss>