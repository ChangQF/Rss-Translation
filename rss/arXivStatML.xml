<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>stat.ml arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>arxiv.org e-print存档上的stat.ml更新。</description>
    <lastBuildDate>Tue, 18 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>预测时间序列和约束</title>
      <link>https://arxiv.org/abs/2502.10485</link>
      <description><![CDATA[ARXIV：2502.10485V1公告类型：新 
摘要：时间序列预测提出了限制传统机器学习算法有效性的独特挑战。为了解决这些局限性，各种方法都将线性约束纳入学习算法，例如广义添加剂模型和分层预测。在本文中，我们提出了一个统一的框架，用于在时间序列预测中整合和组合线性约束。在此框架内，我们表明，仅使用线性代数可以有效地计算约束经验风险的确切最小化器。这种方法允许对GPU进行高度可扩展的实现。我们通过对现实世界任务进行广泛的基准测试来验证拟议的方法，包括电力需求预测和旅游预测，实现最先进的绩效。]]></description>
      <guid>https://arxiv.org/abs/2502.10485</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用MMD加权量化：从平均场到平均偏移通过梯度流动</title>
      <link>https://arxiv.org/abs/2502.10600</link>
      <description><![CDATA[ARXIV：2502.10600V1公告类型：新 
摘要：使用一组粒子近似概率分布是机器学习和统计数据中的一个基本问题，其应用包括聚类和量化。正式地，我们寻求有限的加权混合物的狄拉克度量，以最能近似目标分布。尽管许多现有的工作依赖于瓦斯汀距离来量化近似误差，但最大平均差异（MMD）的关注较少，尤其是在允许可变粒子重量的情况下。我们从Wasserstein-Fisher-Rao（WFR）几何形状中通过梯度流量最小化MMD的角度研究了量化问题。该梯度流得出一个ode系统，我们从中进一步得出了一种称为平均移位相互作用粒子（MSIP）的定点算法。我们表明，MSIP扩展了（非相互作用）平均移位算法，该算法广泛用于识别内核密度估计中的模式。此外，我们表明MSIP可以解释为预处理的梯度下降，并且它可以放松劳埃德的聚类算法。我们的数值实验表明，MSIP和WFR ODE的表现优于量化多模式和高维靶标的其他算法。]]></description>
      <guid>https://arxiv.org/abs/2502.10600</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>批处理自适应注释，用于与复杂结局的因果推断</title>
      <link>https://arxiv.org/abs/2502.10605</link>
      <description><![CDATA[ARXIV：2502.10605V1公告类型：新 
摘要：估计干预对结局的因果影响至关重要。但是通常在医疗保健和社会服务等领域，这些有关结果的关键信息由非结构化文本（例如医疗保健或社会服务病例笔记中的临床注释。例如，对无家可归者人口的街头宣传是一种普遍的社会服务干预措施，含糊不清。外联工人编译了案件记录，这些记录详尽地涉及结果。尽管专家可以从此类非结构化的案例说明中简洁地提取相关信息，但对于整个语料库来说，这是昂贵或不可行的，这可能涵盖数百万个笔记。大型语言模型（LLMS）的最新进展使非结构化文本数据的注释可扩展但可能不准确。我们利用哪些数据点应在预算限制下获得专家注释与嘈杂的插入的决定，以“基于设计的”估算仪结合有限的专家和丰富的嘈杂插入数据，这是通过\ textit {因果{因果推断与失踪结果}结合的。我们开发了一种两阶段的自适应算法，该算法优化了专家注释概率，以最佳的渐近方差估算ATE。我们证明了如何在因果估计量中以战略性，有效和负责任地结合专家标签和LLM注释。我们对模拟数据和两个现实世界数据集进行了实验，其中包括一个在街头外展上，以显示我们提出的方法的多功能性。]]></description>
      <guid>https://arxiv.org/abs/2502.10605</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于高维项目因素分析的生成对抗网络：深层对抗性学习算法</title>
      <link>https://arxiv.org/abs/2502.10650</link>
      <description><![CDATA[ARXIV：2502.10650V1公告类型：新 
摘要：深度学习和表示学习的进步通过启用更有效和准确的参数估计来改变项目响应理论（IRT）文献中的项目因素分析（IFA）。在这种情况下，变异自动编码器（VAE）一直是对高维潜在变量进行建模的最有影响力的技术之一。但是，基于传统VAE的推论模型的表现力有限仍然会阻碍估计性能。这项研究介绍了对抗性变异贝叶斯（AVB）算法，以改善IFA的VAE，具有提高的灵活性和准确性。通过桥接VAE和生成对抗网络（GAN）的优势，AVB结合了辅助歧视者网络，以将估计过程重新构架为两人对抗游戏，并消除推理模型中标准正常分布的限制性假设。从理论上讲，与VAE相比，AVB可以实现相似或更高的可能性。提出了进一步增强的算法，重要性加权的对抗性贝叶斯（IWAVB），并将其与重要性加权自动编码器（IWAE）进行了比较。在对实际经验数据的探索性分析中，IWAVB通过与IWAE相比具有更高的可能性，证明了较高的表现力。在使用模拟数据的验证性研究中，IWAVB获得了与IWAE相似的均方误差结果，同时始终达到更高的可能性。此外，在潜在变量遵循多模式分布的模拟中，IWAVB通过提供更准确的参数估计来优于IWAE。凭借其创新的gans使用，IWAVB被证明具有扩展IFA来处理大规模数据的潜力，从而促进了心理图和多模式数据分析的潜在整合。]]></description>
      <guid>https://arxiv.org/abs/2502.10650</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动态影响跟踪器：测量训练期间的时变样品影响</title>
      <link>https://arxiv.org/abs/2502.10793</link>
      <description><![CDATA[ARXIV：2502.10793V1公告类型：新 
摘要：现有的测量训练样本影响模型的方法仅提供静态的总体测量，从而忽略了样本在训练过程中的影响如何变化。我们提出了动态影响跟踪器（DIT），该跟踪器捕获了训练期间任意时间窗口中随时间变化的样本影响。
  DIT提供了三个关键见解：1）样本显示出不同的时间变化的影响模式，有些样本在早期训练阶段很重要，而另一些样本则在以后变得重要。 2）样本影响显示早期和晚期之间的相关性较弱，这表明该模型以变化的优先级经历了不同的学习阶段。 3）分析影响期间的影响比全面训练分析更有效，更准确地检测损坏的样本。在理论保证的情况下，DIT在没有假设损失凸度或模型收敛的情况下支持了现有方法，在检测复杂建筑中检测损坏的样本时，达到了高达0.99的相关性，高于98 \％的准确性。]]></description>
      <guid>https://arxiv.org/abs/2502.10793</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高维回归的广义因子神经网络模型</title>
      <link>https://arxiv.org/abs/2502.11310</link>
      <description><![CDATA[ARXIV：2502.11310V1公告类型：新 
摘要：我们应对建模高维数据集的挑战，尤其是那些隐藏在复杂，非线性和嘈杂关系中的潜在低维结构的挑战。我们的方法可以从非参数回归，因子模型和神经网络中无缝整合以进行高维回归。我们的方法引入了PCA和软PCA层，它们可以嵌入在神经网络体系结构的任何阶段，从而使模型可以在因子建模和非线性转换之间进行交替。这种灵活性使我们的方法特别有效地处理分层组成数据。我们探索我们和其他技术，以在神经网络上施加低级结构，并研究建筑设计如何影响模型性能。通过仿真研究以及用于预测股票ETF指数的未来价格变动并使用宏观经济数据的应用程序的应用来证明我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.11310</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>强大的高维平均估计，数据大小低，这是一项经验研究</title>
      <link>https://arxiv.org/abs/2502.11324</link>
      <description><![CDATA[ARXIV：2502.11324V1公告类型：新 
摘要：强大的统计数据旨在计算数量以表示可能被任意损坏的数据。最重要的统计数据是平均值，近年来，有一系列理论发展是为了有效地估算损坏数据的高维度的平均值。虽然已经提出了几种算法，它们达到了几乎最佳的错误，但它们都依赖于大数据尺寸要求作为维度的函数。在本文中，我们对各种平均估计技术进行了广泛的实验，在各种平均值估计技术中，由于高维设置，数据大小可能无法满足此要求。]]></description>
      <guid>https://arxiv.org/abs/2502.11324</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>所有模型均被错误校准，但较少的是：将校准与条件平均操作员进行比较</title>
      <link>https://arxiv.org/abs/2502.11465</link>
      <description><![CDATA[ARXIV：2502.11465V1公告类型：新 
摘要：在高危环境中工作时，具有良好的概率预测模型是至关重要的要求。但是，校准误差的估计器并不总是能够正确区分哪种模型更好地校准。我们提出了\ emph {条件内核校准误差}（CKCE），该（CKCE）基于条件平均运算符之间差异的Hilbert-Schmidt Norm。通过直接将强校准的定义作为条件分布之间的距离进行定义，我们通过它们在再现核希尔伯特空间中的嵌入中表示，CKCE对预测模型的边际分布不太敏感。这使其比以前提出的校准指标更有效。我们使用合成数据和实际数据的实验表明，CKCE通过其校准误差提供了更一致的模型排名，并且在分配变化方面更强大。]]></description>
      <guid>https://arxiv.org/abs/2502.11465</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分销自动编码器知道分数</title>
      <link>https://arxiv.org/abs/2502.11583</link>
      <description><![CDATA[ARXIV：2502.11583V1公告类型：新 
摘要：这项工作介绍了最近引入的一类自动编码器类别（DPA）的新颖和理想的属性，该类型将分布在分布上正确的重建与主组件的解释性结合在一起。
  首先，我们证明编码器Orient的水平集与数据分布的分数有关。这两者都解释了该方法在解散数据变化因素方面经常出色的性能，并打开了仅访问样品的可能性的可能性。在分数本身具有物理含义的设置（例如数据遵守玻尔兹曼分布时），我们证明该方法可以恢复科学重要的数量，例如\ textit {最小自由能路径}。
  其次，我们表明，如果数据位于歧管上，可以由编码器近似，则最佳编码器的组件超出了歧管的尺寸，将绝对没有有关数据分布的其他信息。这有望确定超出常见启发式方法（例如Scree图）的数据相关维度的数量。
  最后，该方法正在学习分数这一事实意味着它可以作为生成模型具有承诺，例如扩散诸如扩散之类的方法，该方法类似地试​​图近似数据分布的得分。]]></description>
      <guid>https://arxiv.org/abs/2502.11583</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于内核学习问题</title>
      <link>https://arxiv.org/abs/2502.11665</link>
      <description><![CDATA[ARXIV：2502.11665V1公告类型：新 
摘要：经典的内核脊回归问题旨在找到最适合输出$ y $作为输入数据$ x \ in \ mathbb {r}^d $的函数的函数，并固定了由a强加的正则化项的选择。考虑到繁殖的内核希尔伯特空间，例如Sobolev空间。在这里，我们通过引入额外的矩阵参数$ u $来考虑内核脊回归问题的概括，该矩阵参数$ u $旨在检测数据中的比例参数和特征变量，从而提高了内核脊回归的效率。这自然会导致非线性变分问题，以优化$ u $的选择。我们研究了这个变异问题的各种基础数学方面，尤其是在数据中存在多尺度结构的情况下的表现。]]></description>
      <guid>https://arxiv.org/abs/2502.11665</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于3D点云数据的表面异常分类的深度子空间学习</title>
      <link>https://arxiv.org/abs/2502.11669</link>
      <description><![CDATA[ARXIV：2502.11669V1公告类型：新 
摘要：表面异常分类对于制造系统故障诊断和质量控制至关重要。但是，以下挑战始终阻碍实际上准确的异常分类：（i）异常模式表现出类别的变化和类间相似性，在每个样本的准确分类中都提出了挑战。 （ii）尽管有预定义的类别，但在生产过程中仍可能发生新的异常类型，需要准确检测到需要准确检测到。 （iii）在制造过程中很少使用异常数据，从而导致模型学习数据有限。为了同时应对上述挑战，本文提出了一种新型的基于深层学习的3D分类模型。具体而言，从轻巧的编码器开始提取潜在表示形式，我们将每个类作为子空间建模，以说明阶层内变化，同时促进不同类别的不同子空间以应对类间的相似性。此外，子空间的显式建模提供了检测分布外样品的能力，即新型异常类型的异常和正则化效应，而我们所提出的子空间分类器的可学习参数却少得多，与流行的多层观念相比（ MLP）。广泛的数值实验证明我们的方法比基准方法获得了更好的异常分类结果，并且可以有效地识别新型异常类型。]]></description>
      <guid>https://arxiv.org/abs/2502.11669</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>私人合成图生成和融合的Gromov-Wasserstein距离</title>
      <link>https://arxiv.org/abs/2502.11778</link>
      <description><![CDATA[ARXIV：2502.11778V1公告类型：新 
摘要：网络对于表示复杂数据很受欢迎。特别是，私人合成网络对方法和算法开发的需求很大。网络生成器应易于实现，并应具有理论保证。在这里，我们从复杂的数据开始，并共同提供网络表示以及合成网络生成器。使用随机连接模型，我们设计了一种有效的算法方法，用于生成归因的合成图，该方法是$ \ epsilon $ -digrient-diffitiality在顶点级别上私有的，同时在我们开发的适当距离概念下保留了实用性。我们使用融合的Gromov-Wasserstein距离为私人合成图的准确性提供了理论保证，该距离将Wasserstein度量扩展到结构化数据。我们的方法从\ citet {He2023}的PSMM方法中汲取灵感。]]></description>
      <guid>https://arxiv.org/abs/2502.11778</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>JOLT：使用LLMS对表格数据的联合概率预测</title>
      <link>https://arxiv.org/abs/2502.11877</link>
      <description><![CDATA[ARXIV：2502.11877V1公告类型：新 
摘要：我们介绍了一种基于大语言模型（LLMS）的表格数据的概率预测的简单方法（jolt）（表格数据的关节LLM过程）。 JOLT使用LLMS的文本学习能力来定义与用户指定的有关该问题的侧面信息的表格数据，从而利用了在LLMS中编码的潜在问题相关知识的广泛存储库。 JOLT定义了具有潜在异质数据类型的多个目标变量的联合分布，而无需任何数据转换，数据预处理，对丢失的数据的特殊处理或模型培训，从而使从业人员易于访问且有效。我们的实验表明，在低射击单目标和多目标表格分类和回归任务上，震动优于竞争方法。此外，我们表明，JOLT可以自动处理丢失的数据并通过利用文本侧面信息来执行数据插补。我们认为，由于其简单性和一般性，JOLT是解决各种真实预测问题的有效方法。]]></description>
      <guid>https://arxiv.org/abs/2502.11877</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经引导扩散桥</title>
      <link>https://arxiv.org/abs/2502.11909</link>
      <description><![CDATA[ARXIV：2502.11909V1公告类型：新 
摘要：我们提出了一种新的方法，用于模拟欧几里得空间中的条件扩散过程（扩散桥）。通过训练神经网络以近似桥梁的动力学，我们的方法消除了对计算密集的马尔可夫链蒙特卡洛（MCMC）方法或反处理建模的需求。与现有方法相比，它在各种扩散规格和条件方案中提供了更大的鲁棒性。这特别适用于罕见事件和多模式分布，这对基于得分学习和基于MCMC的方法构成了挑战。我们提出了一个灵活的变分家族，用于近似于神经网络部分指定的扩散桥路径。训练后，它可以以可与无条件（正向）过程相当的成本进行有效的独立采样。]]></description>
      <guid>https://arxiv.org/abs/2502.11909</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>离线土匪的精制豆湾边界</title>
      <link>https://arxiv.org/abs/2502.11953</link>
      <description><![CDATA[ARXIV：2502.11953V1公告类型：新 
摘要：在本文中，我们介绍了针对匪徒问题的差异学习的经验奖励估计的精致概率界限。我们建立在Seldin等人的Pac-Bayesian界限上。 （2010年），并使用Rodr \&#39;Iguez等人介绍的新参数优化方法改善了结果。 （2024）。该技术基于可能事件的空间的离散化，以优化“概率”参数。我们提供两个无参数的Pac-Bayes界限，一个基于Hoeffding-Azuma的不平等，另一个基于Bernstein的不平等。我们证明我们的边界几乎是最佳的，因为它们通过在实现数据后设置“概率”参数所获得的速率与获得的速率相同。]]></description>
      <guid>https://arxiv.org/abs/2502.11953</guid>
      <pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>