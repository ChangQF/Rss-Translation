<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 12 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>众包环境下基于偏好的在线学习主观评价自动设计优化</title>
      <link>https://arxiv.org/abs/2403.06100</link>
      <description><![CDATA[arXiv:2403.06100v1 公告类型：交叉
摘要：基于偏好的主观评估是可靠评估生成媒体的关键方法。然而，其庞大的对组合使其无法应用于众包的大规模评估。为了解决这个问题，我们提出了一种基于偏好的主观评估的自动优化方法，该方法涉及众包环境中在线学习的配对组合选择和评估量分配。我们采用基于排序算法的基于偏好的在线学习方法，以最小的样本量来识别评估目标的总顺序。我们的在线学习算法支持众包所需的固定预算条件下的并行和异步执行。我们对合成语音进行基于偏好的主观评估的实验表明，我们的方法成功地优化了测试，将对组合从 351 个减少到 83 个，并为每对分配从 30 到 663 个范围内的最佳评估量，而不会影响评估准确性和浪费预算分配。]]></description>
      <guid>https://arxiv.org/abs/2403.06100</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>非对数凹采样先验扩散 Langevin 算法的改进分析</title>
      <link>https://arxiv.org/abs/2403.06183</link>
      <description><![CDATA[arXiv:2403.06183v1 公告类型：交叉
摘要：无论从实践还是理论角度来看，理解高维采样问题中计算复杂度的维度依赖性都是一个基本问题。与具有无偏平稳分布的采样器（例如 Metropolis-adjusted Langevin 算法（MALA））相比，有偏采样器（例如 Underdamped Langevin Dynamics（ULD））在低精度情况下表现更好，因为其复杂性的维度依赖性较低。沿着这条线，弗罗因德等人。 (2022) 表明，具有先验扩散的改进 Langevin 算法能够独立地收敛强对数凹目标分布的维度。尽管如此，此类财产是否适用于更一般的情况仍然悬而未决。在本文中，我们研究了满足对数索博列夫不等式（LSI）的目标分布的先验扩散技术，与强对数凹分布相比，它涵盖了更广泛的分布类别。特别地，我们证明了改进的 Langevin 算法也可以在不同步长的情况下获得 KL 散度的与维度无关的收敛。我们证明技术的核心是插值 SDE 的新颖结构，它极大地有助于对过阻尼朗之万动力学的离散更新进行更准确的表征。我们的理论分析证明了先验扩散对于更广泛的目标分布类别的好处，并为开发更快的采样算法提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.06183</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>密度回归：用于分布变化下不确定性估计的高效且距离感知的深度回归器</title>
      <link>https://arxiv.org/abs/2403.05600</link>
      <description><![CDATA[arXiv:2403.05600v1 公告类型：交叉
摘要：现代深度集成技术通过使用不同模型进行多次前向传递，实现了强大的不确定性估计性能。这是以较高的存储空间和较慢的推理（测试）时间速度为代价的。为了解决这个问题，我们提出了密度回归，这是一种在不确定性估计中利用密度函数并通过单次前向传递实现快速推理的方法。我们证明它在特征空间上具有距离感知能力，这是神经网络在分布变化下产生高质量不确定性估计的必要条件。根据经验，我们使用立方玩具数据集、基准 UCI、时间序列天气预报以及现实世界转移应用下的深度估计进行回归任务实验。我们证明，密度回归在现代深度回归器的分布变化下具有竞争性的不确定性估计性能，同时使用较小的模型大小和更快的推理速度。]]></description>
      <guid>https://arxiv.org/abs/2403.05600</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>通过独立查询预言机进行马尔可夫等价类的成员资格测试</title>
      <link>https://arxiv.org/abs/2403.05759</link>
      <description><![CDATA[arXiv:2403.05759v1 公告类型：交叉
摘要：理解变量之间的因果关系是在许多科学领域具有广泛影响的基本问题。虽然广泛的研究致力于从数据中学习因果图，但其测试因果关系的补充概念在很大程度上仍未得到探索。虽然学习涉及从观察数据恢复底层因果图的马尔可夫等价类（MEC）的任务，但测试对应物解决了以下关键问题：给定特定的 MEC 和来自某些因果图的观察数据，我们能否确定数据是否-生成属于给定 MEC 的因果图？
  我们通过建立所需数量的条件独立性测试的界限来探索基于约束的测试方法。我们的界限是给定 MEC 的最大无向集团 ($s$) 的大小。在最坏的情况下，我们显示 $\exp(\Omega(s))$ 独立性测试的下限。然后，我们给出一个算法，通过 $\exp(O(s))$ 测试来解决任务，与我们的下限相匹配。与学习问题相比，算法经常使用大量最大入度呈指数的独立性测试，这表明测试相对容易。特别是，它需要在具有高入度和小团尺寸的图中进行指数级更少的独立性测试。此外，使用 DAG 关联面体，我们提供了测试与学习的几何解释，并讨论了我们的测试结果如何帮助学习。]]></description>
      <guid>https://arxiv.org/abs/2403.05759</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>关于核函数的逼近</title>
      <link>https://arxiv.org/abs/2403.06731</link>
      <description><![CDATA[arXiv:2403.06731v1 公告类型：新
摘要：统计学习中的各种方法都建立在再现核希尔伯特空间时考虑的核之上。在应用中，通常根据问题和数据的特征来选择内核。然后使用该内核来推断未观察到解释数据的点处的响应变量。这里考虑的数据位于更高维度的紧凑集合中，并且本文讨论了内核本身的近似值。新方法考虑径向核函数的泰勒级数近似。对于单位立方体上的高斯核，论文建立了相关特征函数的上限，该特征函数仅相对于索引呈多项式增长。这种新颖的方法证实了比文献中考虑的更小的正则化参数，总体上导致了更好的近似。这一改进证实了低秩近似方法，例如 Nystr\&quot;om 方法。]]></description>
      <guid>https://arxiv.org/abs/2403.06731</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>适用于野火科学的大规模非平滑最大熵模型的高效一阶算法</title>
      <link>https://arxiv.org/abs/2403.06816</link>
      <description><![CDATA[arXiv:2403.06816v1 公告类型：新
摘要：最大熵（Maxent）模型是一类利用最大熵原理估计数据概率分布的统计模型。由于现代数据集的规模，Maxent 模型需要高效的优化算法才能很好地适应大数据应用程序。然而，Maxent 模型的最先进算法最初并不是为处理大数据集而设计的。这些算法要么依赖于可能产生不可靠数值结果、扩展性差的技术设备，要么需要许多实际 Maxent 模型所缺乏的平滑假设。在本文中，我们提出了新颖的优化算法，克服了用于训练大规模非平滑 Maxent 模型的最先进算法的缺点。我们提出的一阶算法利用 Kullback-Leibler 散度来有效地训练大规模和非平滑 Maxent 模型。对于由样本构建的具有 $n$ 个元素的离散概率分布的 Maxent 模型，每个元素包含 $m$ 个特征，我们算法中的步长参数估计和迭代按 $O(mn)$ 操作的顺序缩放，并且可以简单地并行化。此外，Kullback-Leibler 散度的强 $\ell_{1}$ 凸性允许更大的步长参数，从而加快算法的收敛速度。为了说明我们的新颖算法的效率，我们考虑将火灾发生概率估计为美国西部 MTBS 跨机构野火数据集中生态特征的函数。我们的数值结果表明，我们的算法比现有技术高出一个数量级，并且产生的结果与野火发生的物理模型和之前对野火驱动因素的统计分析一致。]]></description>
      <guid>https://arxiv.org/abs/2403.06816</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>基于 NML 代码检测离散、混合和连续变量中未观察到的常见原因</title>
      <link>https://arxiv.org/abs/2403.06499</link>
      <description><![CDATA[arXiv:2403.06499v1 公告类型：新
摘要：仅从观测数据中发现未观察到的常见原因时的因果发现是一个至关重要但具有挑战性的问题。我们将两个随机变量之间所有可能的因果关系分为以下四类，并旨在从观察到的数据中识别出一类：存在直接因果关系的两种情况，变量独立的情况，以及变量被混杂的情况。潜在的混杂因素。尽管已经提出了现有的方法来解决这个问题，但它们需要未观察到的变量来满足对其方程模型形式的假设。在我们之前的研究中（Kobayashi et al., 2022），针对离散数据提出了第一个没有这种假设的因果发现方法，并将其命名为 CLOUD。使用归一化最大似然 (NML) 代码，CLOUD 从一组候选模型中选择一个模型，该模型可生成观测数据的最小代码长度。本文扩展了云以适用于离散、混合和连续的各种数据类型。我们不仅进行了理论分析以证明 CLOUD 在模型选择方面的一致性，而且通过对合成数据和真实世界数据的大量实验证明了 CLOUD 在推断因果关系方面比现有方法更有效。]]></description>
      <guid>https://arxiv.org/abs/2403.06499</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>隐私敏感领域中联邦学习可证明的互惠互利</title>
      <link>https://arxiv.org/abs/2403.06672</link>
      <description><![CDATA[arXiv:2403.06672v1 公告类型：新
摘要：跨孤岛联邦学习（FL）允许数据所有者通过受益于彼此的私有数据集来训练准确的机器学习模型。不幸的是，协作带来的模型准确性优势常常因隐私保护而受到损害。因此，为了激励客户参与隐私敏感领域，FL 协议应该在隐私保证和最终模型准确性之间取得微妙的平衡。在本文中，我们研究了服务器何时以及如何设计可证明对所有参与者都有利的 FL 协议的问题。首先，我们在均值估计和凸随机优化的背景下为互利协议的存在提供了充分必要条件。考虑到对称的隐私偏好，我们还得出了最大化客户总效用的协议。最后，我们设计了最大化最终模型准确性的协议，并在合成实验中证明了它们的好处。]]></description>
      <guid>https://arxiv.org/abs/2403.06672</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>解开多模态变分自编码器中的共享和私有潜在因素</title>
      <link>https://arxiv.org/abs/2403.06338</link>
      <description><![CDATA[arXiv:2403.06338v1 公告类型：新
摘要：多模态数据的生成模型可以识别可能与观察到的数据异质性的重要决定因素相关的潜在因素。共同或共享的因素对于解释跨模态的变化可能很重要，而其他因素可能是私有的并且仅对于解释单一模态很重要。多模态变分自动编码器（例如 MVAE 和 MMVAE）是推断这些潜在潜在因素并将共享变化与私有变化分离的自然选择。在这项工作中，我们研究了他们可靠地执行这种解开的能力。特别是，我们强调了一个具有挑战性的问题设置，其中模态特定的变化在共享信号中占主导地位。从跨模态预测的角度来看，我们证明了现有模型的局限性，并提出了一种修改方法，使它们对特定模态的变化更加鲁棒。我们的研究结果得到了合成实验以及各种现实世界多组学数据集的实验的支持。]]></description>
      <guid>https://arxiv.org/abs/2403.06338</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>桥接具有近似共享功能的域</title>
      <link>https://arxiv.org/abs/2403.06424</link>
      <description><![CDATA[arXiv:2403.06424v1 公告类型：新
摘要：多源领域适应旨在减少将机器学习模型应用于未知领域时的性能下降。一个基本的挑战是设计特征选择的最佳策略。现有的文献有些自相矛盾：一些文献主张从源域学习不变的特征，而另一些文献则倾向于更多样化的特征。为了应对这一挑战，我们提出了一个统计框架，该框架根据特征与跨域标签 $y$ 的相关性方差来区分特征的效用。在我们的框架下，我们设计和分析了一个学习过程，包括从源任务中学习大约共享的特征表示并在目标任务上对其进行微调。我们的理论分析需要学习近似共享特征而不仅仅是严格不变的特征，并且与之前的源任务和目标任务结果相比，可以提高总体风险，从而部分解决上述悖论。受我们理论的启发，我们提出了一种更实用的方法，将内容（不变+近似共享）与环境特征隔离，并进一步巩固我们的理论发现。]]></description>
      <guid>https://arxiv.org/abs/2403.06424</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>稀疏计数数据的 ALL0CORE 张量分解</title>
      <link>https://arxiv.org/abs/2403.06153</link>
      <description><![CDATA[arXiv:2403.06153v1 公告类型：新
摘要：本文介绍了 ALL0CORE，一种新形式的概率非负张量分解。 ALL0CORE 是一种 Tucker 分解，其中核心张量的非零元素（即 L0 范数）的数量被限制为远小于核心大小的预设值 Q。当用户指定总预算 Q 时，非零元素的位置和值是潜在变量，并在推理过程中分配到核心张量上。 ALL0CORE——即分配的 L0 约束核心——因此享有 CP 分解的计算易处理性和 Tucker 的定性吸引人的潜在结构。在一系列真实数据实验中，我们证明 ALL0CORE 通常只需要完整核心的一小部分（例如~1%），即可以相对较小的成本实现与完整 Tucker 分解相同的结果。]]></description>
      <guid>https://arxiv.org/abs/2403.06153</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>使用样条逼近的非参数自动微分变分推理</title>
      <link>https://arxiv.org/abs/2403.06302</link>
      <description><![CDATA[arXiv:2403.06302v1 公告类型：新
摘要：自动微分变分推理（ADVI）在学习概率模型方面非常有效。经典 ADVI 依靠参数方法来近似后验。在本文中，我们开发了一种基于样条的非参数逼近方法，该方法能够对具有复杂结构（例如偏度、多模态和有界支持）的分布进行灵活的后验逼近。与广泛使用的非参数变分推理方法相比，该方法易于实现且适应各种数据结构。通过采用样条近似，我们得出了重要性加权自动编码器的下界并建立了渐近一致性。实验证明了该方法在逼近复杂后验分布和提高不完整数据生成模型性能方面的效率。]]></description>
      <guid>https://arxiv.org/abs/2403.06302</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>分布时间差异的统计效率</title>
      <link>https://arxiv.org/abs/2403.05811</link>
      <description><![CDATA[arXiv:2403.05811v1 公告类型：新
摘要：分布式强化学习（DRL）关心回报的完整分布而不仅仅是平均值，在各个领域都取得了经验上的成功。 DRL 领域的核心任务之一是分配策略评估，其中涉及估计给定策略 $\pi$ 的收益分布 $\eta^\pi$。据此提出了分布式时间差分（TD）算法，它是经典强化学习文献中时间差分算法的扩展。在表格情况下，\citet{rowland2018analysis}和\citet{rowland2023analysis}分别证明了分布TD的两个实例的渐近收敛性，即分类时间差分算法（CTD）和分位数时间差分算法（QTD）。在本文中，我们更进一步分析了分布式 TD 的有限样本性能。为了便于理论分析，我们提出了非参数分布TD算法（NTD）。对于具有状态空间 $S$ 和动作空间 $A$ 的 $\gamma$ 贴现无限水平表格马尔可夫决策过程，我们表明，在 NTD 的情况下，我们需要 $\wtilde O\prn{\frac{1}当估计误差由 $p$-Wasserstein 测量时，{\varepsilon^{2p}(1-\gamma)^{2p+2}}}$ 迭代以高概率实现 $\varepsilon$-最优估计器距离。在一些温和的假设下，$\wtilde O\prn{\frac{1}{\varepsilon^{2}(1-\gamma)^{4}}}$ 迭代足以确保 NTD 估计器之间的 Kolmogorov-Smirnov 距离$\hat\eta^\pi$ 和 $\eta^\pi$ 小于 $\varepsilon$ 的概率很高。我们重新审视 CTD，表明在 $p$-Wasserstein 距离的情况下，相同的非渐近收敛界限也适用于 CTD。]]></description>
      <guid>https://arxiv.org/abs/2403.05811</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>嫁接：使随机​​森林保持一致</title>
      <link>https://arxiv.org/abs/2403.06015</link>
      <description><![CDATA[arXiv:2403.06015v1 公告类型：新
摘要：尽管随机森林具有出色的性能和广泛的应用，但人们对它的理论知之甚少。一个尚未解答的主要问题是随机森林算法是否或何时一致。文献探讨了经典随机森林算法的各种变体来解决这个问题和该方法的已知缺点。本文是对该文献的贡献。具体来说，探讨了将一致估计器移植到浅层 CART 上的适用性。结果表明，该方法具有一致性保证，并且在经验设置中表现良好。]]></description>
      <guid>https://arxiv.org/abs/2403.06015</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>通过额外图节点对分类和混合类型数据进行谱聚类</title>
      <link>https://arxiv.org/abs/2403.05669</link>
      <description><![CDATA[arXiv:2403.05669v1 公告类型：新
摘要：将数据对象聚类成同质组是数据挖掘中最重要的任务之一。谱聚类可以说是最重要的聚类算法之一，因为它的理论可靠性很有吸引力，并且适用于许多现实世界的数据设置。例如，混合数据（数据由数值和分类特征组成）通常通过数值离散、虚拟编码或考虑两种数据类型的相似性计算来处理。本文探索了一种更自然的方法，将数值和分类信息合并到谱聚类算法中，避免了数据预处理或使用复杂的相似性函数的需要。我们建议添加与数据可能所属的不同类别相对应的额外节点，并表明它会产生可解释的聚类目标函数。此外，我们证明这个简单的框架可以为仅分类数据提供线性时间谱聚类算法。最后，我们将我们的算法的性能与其他相关方法进行比较，并表明它在性能和运行时间方面为它们提供了有竞争力的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2403.05669</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:39 GMT</pubDate>
    </item>
    </channel>
</rss>