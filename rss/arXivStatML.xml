<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的统计 — 机器学习 (stat.ML) 更新</description>
    <lastBuildDate>Mon, 04 Dec 2023 03:14:13 GMT</lastBuildDate>
    <item>
      <title>用于回归任务的目标不可知的无源域适应。 （arXiv：2312.00540v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00540</link>
      <description><![CDATA[无监督领域适应 (UDA) 旨在弥合领域之间的差距
使用未标记的目标数据的目标和源。无源 UDA 删除了
要求目标处标记源数据以保护数据隐私和
贮存。然而，无源 UDA 的工作需要了解领域差距
分布，因此仅限于目标感知或分类
任务。为了克服这个问题，我们提出了 TASFAR，一种新颖的目标不可知的无源
用于回归任务的域适应方法。使用预测置信度，
TASFAR估计一个标签密度图作为目标标签分布，即
然后用于在目标域上校准源模型。我们进行了
对具有不同领域差距的四个回归任务进行了广泛的实验，
即针对不同用户、基于图像的人的行人航位推算
不同场景计数，不同地区房价预测，
以及不同出发点的出租车行程持续时间预测。塔斯法尔是
表现明显优于最先进的无源 UDA
通过平均减少 22% 的四项任务错误来实现
值得注意的是，在不使用源数据的情况下，其准确性与基于源的 UDA 相当。
]]></description>
      <guid>http://arxiv.org/abs/2312.00540</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:12 GMT</pubDate>
    </item>
    <item>
      <title>完全数据驱动的岩土工程之路：材料信息学的经验教训。 （arXiv：2312.00581v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00581</link>
      <description><![CDATA[本文阐明了固有的挑战和机遇
将数据驱动的方法融入岩土工程中，汲取灵感
材料信息学的成功。突出土壤的复杂性
复杂性、异质性和缺乏全面的数据，讨论
强调迫切需要社区驱动的数据库举措和
开放科学运动。通过利用深度的变革力量
学习，特别是从高维数据中提取特征以及
转移学习的潜力，我们设想范式转变为更多
协作和创新的岩土工程领域。该论文的结论是
前瞻性立场，强调所带来的革命潜力
通过先进的计算工具（例如大型语言模型）进行重塑
岩土工程信息学。
]]></description>
      <guid>http://arxiv.org/abs/2312.00581</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:12 GMT</pubDate>
    </item>
    <item>
      <title>物理系统的可解释元学习。 （arXiv：2312.00477v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00477</link>
      <description><![CDATA[机器学习方法可以为科学过程提供宝贵的帮助，但是
他们需要面对具有挑战性的环境，其中数据来自不均匀的环境
实验条件。最近的元学习方法取得了重大进展
多任务学习方面取得了进展，但它们依赖于黑盒神经网络，
导致高计算成本和有限的可解释性。杠杆作用
对于学习问题的结构，我们认为多环境
泛化可以使用更简单的学习模型来实现，具有仿射
学习任务的结构。至关重要的是，我们证明了这一点
架构可以识别系统的物理参数，从而使
可解释的学习。我们展示了竞争性泛化
通过与我们的方法进行比较，我们的方法的性能和计算成本较低
物理系统上最先进的算法，范围从玩具模型到
复杂的非分析系统。我们的方法的可解释性是
说明了物理参数引起的适应的原始应用
以及自适应控制。
]]></description>
      <guid>http://arxiv.org/abs/2312.00477</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:11 GMT</pubDate>
    </item>
    <item>
      <title>从未知的一般干预中发现贝叶斯因果关系。 （arXiv：2312.00509v1 [stat.ME]）</title>
      <link>http://arxiv.org/abs/2312.00509</link>
      <description><![CDATA[我们考虑学习因果有向无环图（DAG）的问题
使用观察和干预实验数据的组合。
目前针对这种情况量身定制的方法假设干预措施
破坏干预（目标）节点的父子关系或仅改变
即使在干预的情况下，这种关系也无需修改父集
目标未知。我们通过提出贝叶斯方法来放宽这一假设
从一般干预中发现因果关系，允许进行修改
未知目标的父集。即使在这个框架中，DAG 和
一般干预措施可能只能识别到某些等价类别。
我们提供这种介入马尔可夫的图形特征
等价性并为贝叶斯推理设计兼容的先验，保证
不可区分结构的得分等价性。然后我们开发一个马尔可夫
链蒙特卡罗 (MCMC) 方案来近似后验分布
DAG、干预目标和诱导父集。最后，我们评估
提出了模拟和真实蛋白质表达数据的方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.00509</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:11 GMT</pubDate>
    </item>
    <item>
      <title>GFN-SR：生成流网络的符号回归。 （arXiv：2312.00396v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00396</link>
      <description><![CDATA[符号回归 (SR) 是可解释机器学习的一个领域，
旨在识别通常由简单函数组成的数学表达式，
最适合一组给定的协变量 $X$ 和响应 $y$。在最近
近年来，深度符号回归（DSR）已成为该领域的流行方法。
利用深度强化学习来解决复杂的领域
组合搜索问题。在这项工作中，我们提出了一个替代框架
(GFN-SR) 通过深度学习来实现 SR。我们建模了一个
表达式树遍历有向无环图 (DAG)，以便
GFlowNet 可以学习随机策略来顺序生成此类树。
通过自适应奖励基线增强，我们的方法能够生成
一组多样化的最合适的表达方式。值得注意的是，我们观察到 GFN-SR
在噪声数据环境中优于其他 SR 算法，因为它能够
了解候选解决方案空间中的奖励分配。
]]></description>
      <guid>http://arxiv.org/abs/2312.00396</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:10 GMT</pubDate>
    </item>
    <item>
      <title>从互信息到预期动态：重尾 SGD 的新泛化界限。 （arXiv：2312.00427v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.00427</link>
      <description><![CDATA[了解现代机器学习的泛化能力
过去几十年来，算法一直是一个主要的研究课题。在最近
多年来，随机梯度下降（SGD）的学习动态已经
与重尾动力学有关。该方法已成功应用于
通过利用这些动力学的分形特性的泛化理论。
然而，导出的界限取决于互信息（解耦）项
超出了可计算性的范围。在这项工作中，我们证明
一类重尾动力学轨迹的泛化界限，
没有那些相互信息条款。相反，我们引入几何
通过比较学习动态（取决于经验
风险）与预期风险（取决于人群风险）。我们进一步
通过使用重尾和
分形文献，使其完全可计算。此外，作为一种尝试
收紧界限，我们提出了基于扰动的 PAC-贝叶斯设置
动力学，其中相同的几何项起着至关重要的作用，并且仍然可以
使用上述技术来限制。
]]></description>
      <guid>http://arxiv.org/abs/2312.00427</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:10 GMT</pubDate>
    </item>
    <item>
      <title>噪声矩阵完成的线性形式的多重测试。 （arXiv：2312.00305v1 [stat.ME]）</title>
      <link>http://arxiv.org/abs/2312.00305</link>
      <description><![CDATA[大规模推荐系统的许多重要任务都可以自然地投射出来
作为测试噪声矩阵完成的多个线性形式。这些问题，
然而，由于微妙的偏差和方差，提出了独特的挑战
估计条目之间的权衡和复杂的依赖性
低级结构。在本文中，我们开发了一种通用方法
通过为个别测试引入新的统计数据来克服这些困难
具有边际和联合的锐渐近性，并利用它们
通过数据分割和对称控制错误发现率（FDR）
聚合方案。我们证明了有效的 FDR 控制可以通过以下方式实现
使用以下方法在接近最佳样本量要求下保证功效
提议的方法。广泛的数值模拟和真实数据示例
还提出了进一步说明其实际优点。
]]></description>
      <guid>http://arxiv.org/abs/2312.00305</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:09 GMT</pubDate>
    </item>
    <item>
      <title>温度平衡、分层权重分析和神经网络训练。 （arXiv：2312.00359v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00359</link>
      <description><![CDATA[现代机器学习中的正则化至关重要，它可以采取多种措施
算法设计中的形式：训练集、模型族、误差函数、
正则化项和优化。特别是学习率，
可以将其解释为统计中类似温度的参数
学习机制在神经网络训练中起着至关重要的作用。的确，
许多广泛采用的培训策略基本上只是定义了
随着时间的推移学习率。这个过程可以解释为减少
温度，使用全局学习率（对于整个模型）或
每个参数不同的学习率。本文提出TempBalance，
一种简单而有效的分层学习率方法。温度平衡是
基于重尾自调节（HT-SR）理论，一种方法
表征训练中不同层的隐式自调节
楷模。我们证明了使用 HT-SR 驱动的指标来指导的有效性
整个网络层的温度调度和平衡
模型训练，从而提高测试期间的性能。我们实施
使用 CIFAR10、CIFAR100、SVHN 和 TinyImageNet 数据集上的 TempBalance
具有各种深度和宽度的 ResNet、VGG 和 WideResNet。我们的结果显示
TempBalance 的性能明显优于普通 SGD，并且经过精心调整
谱范数正则化。我们还表明 TempBalance 的性能优于
许多最先进的优化器和学习率调度器。
]]></description>
      <guid>http://arxiv.org/abs/2312.00359</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:09 GMT</pubDate>
    </item>
    <item>
      <title>对比学习的最佳样本复杂性。 （arXiv：2312.00379v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00379</link>
      <description><![CDATA[对比学习是一种非常成功的学习技术
来自标记元组的数据表示，指定距离关系
元组内。我们研究对比学习的样本复杂性，即
足以获得高度泛化的标记元组的最小数量
准确性。我们对各种样本的复杂性给出了严格的限制
设置，重点关注任意距离函数，都是通用的
$\ell_p$-距离和树度量。我们的主要结果是（几乎）最优的
受学习 $\ell_p$ 整数 $p$ 距离的样本复杂性限制。
对于任何 $p \ge 1$ 我们表明 $\tilde \Theta(\min(nd,n^2))$ 标记的元组是
学习 $d$ 维表示的必要和充分条件
$n$ 点数据集。我们的结果适用于输入的任意分布
样本并基于给出相应的界限
相关问题的 Vapnik-Chervonenkis/Natarajan 维度。我们进一步
显示通过 VC/Natarajan 获得的样本复杂性的理论界限
维度对实验结果具有很强的预测能力，
与民间传说中认为两者之间存在巨大差距的看法相反
统计学习理论和深度学习实践。
]]></description>
      <guid>http://arxiv.org/abs/2312.00379</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:09 GMT</pubDate>
    </item>
    <item>
      <title>通过主动探索从人类反馈中进行有效的强化学习示例。 （arXiv：2312.00267v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00267</link>
      <description><![CDATA[基于偏好的反馈对于强化中的许多应用都很重要
直接评估奖励函数不可行的学习。 A
最近值得注意的例子来自人类反馈的强化学习
（RLHF）在大型语言模型上。对于 RLHF 的许多应用来说，成本
获取人类反馈可能会很重要。在这项工作中，我们采取
优点是人们通常可以选择获取信息的上下文
人类反馈，以便最有效地确定良好的政策，以及
将其形式化为离线上下文决斗强盗问题。我们给出一个
该问题的上置信界算法并证明多项式
最坏的情况是后悔。然后，我们在合成中提供经验证实
设置我们的方法优于现有方法。之后，我们延长
大语言 RLHF 训练的实际应用设置和方法
楷模。在这里，我们的方法能够用更少的样本达到更好的性能
与三个现实世界数据集的多个基线相比，人类偏好的程度更高。
]]></description>
      <guid>http://arxiv.org/abs/2312.00267</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:08 GMT</pubDate>
    </item>
    <item>
      <title>走向一致的典型相关分析：初步表述和概念验证结果。 （arXiv：2312.00296v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00296</link>
      <description><![CDATA[典型相关分析（CCA）已被广泛应用于联合嵌入
最大相关潜在空间中数据的多个视图。但是，那
各种数据视角之间的一致性，这是传统的要求
方法，在许多实际案例中并不明确。在这项工作中，我们提出了一个新的
框架对齐典型相关分析（ACCA），来解决这个问题
通过迭代解决对齐和多视图嵌入的挑战。
]]></description>
      <guid>http://arxiv.org/abs/2312.00296</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:08 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯神经网络图对比学习的不确定性。 （arXiv：2312.00232v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00232</link>
      <description><![CDATA[当标记数据被标记时，图对比学习显示出巨大的前景
稀缺，但可以获得大量未标记的数据集。然而，它往往不
考虑不确定性估计。我们证明了变分贝叶斯
神经网络方法不仅可以用来改善不确定性
估计以及半监督的下游表现
节点分类任务。此外，我们提出了一种新的不确定性衡量方法
对于对比学习，这是基于可能性的分歧
对于不同的阳性样本。
]]></description>
      <guid>http://arxiv.org/abs/2312.00232</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:07 GMT</pubDate>
    </item>
    <item>
      <title>基于深度平衡的稳态偏微分方程神经算子。 （arXiv：2312.00234v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00234</link>
      <description><![CDATA[数据驱动的机器学习方法越来越多地用于解决
偏微分方程（PDE）。他们表现出了特别引人注目的
在训练操作员时取得成功，该操作员将某些族中的偏微分方程作为输入，
并输出其解。然而，建筑设计空间，尤其是
考虑到感兴趣的 PDE 系列的结构知识，仍然很差
明白了。我们试图通过研究负重的好处来弥补这一差距
稳态偏微分方程的神经网络架构。为了实现这一目标，我们首先
证明大多数稳态偏微分方程的解可以表示为
非线性算子的不动点。受这一观察的启发，我们建议
FNO-DEQ，FNO 架构的深度平衡变体，直接
将稳态 PDE 的解求解为无限深度不动点
使用黑盒根求解器的隐式算子层并微分
分析通过这个固定点导致 $\mathcal{O}(1)$ 训练
记忆。我们的实验表明基于 FNO-DEQ 的架构性能优于
基于 FNO 的基线，预测参数数量为 $4\times$
稳态偏微分方程的解，例如达西流和稳态
不可压缩纳维-斯托克斯。最后，我们证明 FNO-DEQ 在以下情况下更加稳健：
使用比基于 FNO 的噪声观测结果更多的数据集进行训练
基线，展示了在中使用适当的归纳偏差的好处
基于不同神经网络的 PDE 求解器的架构设计。更远，
我们展示了通用近似结果，表明 FNO-DEQ 可以
近似任何可写为固定偏微分方程的稳态偏微分方程的解
点方程。
]]></description>
      <guid>http://arxiv.org/abs/2312.00234</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:07 GMT</pubDate>
    </item>
    <item>
      <title>逆强化学习比标准强化学习更难吗？ （arXiv：2312.00054v1 [stat.ML]）</title>
      <link>http://arxiv.org/abs/2312.00054</link>
      <description><![CDATA[逆强化学习（IRL）——学习奖励问题
\emph{专家政策}演示中的功能——起着至关重要的作用
在开发智能系统中的作用，例如那些理解和
模仿人类行为。虽然在应用中广泛使用，但理论上
对现实生活的理解承认独特的挑战并且仍然不发达
与标准强化学习理论相比。例如，如何进行 IRL 仍然是开放的
使用预先收集的数据在标准 \emph{offline} 设置中高效地工作，其中
状态是从\emph{行为政策}（可以是专家
策略本身），并且操作是从专家策略中采样的。

本文提供了原生高效 IRL 的第一行结果
使用多项式样本和运行时的离线和在线设置。我们首先
为离线设置设计一种新的 IRL 算法，Reward Learning with
悲观主义（RLP），并表明它实现了多项式样本复杂度
就 MDP 的大小而言，集中系数介于
行为策略和专家策略，以及所需的准确性。建立在
RLP，我们进一步设计了一种算法Reward Learning with Exploration（RLE），
它在自然的在线环境中运行，学习者可以主动地
探索环境、查询专家政策，获得更强的
来自多项式样本的 IRL 保证的概念。我们建立样本复杂度
两种设置的下限表明 RLP 和 RLE 几乎是最佳的。
最后，作为一个应用，我们证明了学习到的奖励函数可以
\emph{transfer} 到另一个目标 MDP，当目标
MDP 满足与原始（源）MDP 的某些相似性假设。
]]></description>
      <guid>http://arxiv.org/abs/2312.00054</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:06 GMT</pubDate>
    </item>
    <item>
      <title>通过完全提升随机二元理论的二元感知器能力。 （arXiv：2312.00073v1 [数学.PR]）</title>
      <link>http://arxiv.org/abs/2312.00073</link>
      <description><![CDATA[我们研究经典二元感知器的统计能力
一般阈值$\kappa$。认识到两者之间的联系后
容量和双线性索引（bli）随机过程，我们利用最近的
研究此类过程以表征能力的进展。在
特别是，我们依赖 \emph{完全提升} 随机对偶理论 (fl RDT)
\cite{Stojnicflrdt23} 中建立的用于创建学习的通用框架
感知器的能力。成功的基础数值评估是
框架（以及最终整个 fl RDT 机制）所需的
全面投入实际运行。我们呈现在这方面获得的结果
方向并发现容量特征是在
第二个（第一个重要的）\emph{stationarized} 完全提升水平。这
获得的结果 \emph{完全} 匹配副本对称性破缺预测
通过\cite{KraMez89}中的统计物理复制方法获得。最多
值得注意的是，对于著名的零阈值场景 $\kappa=0$，我们发现
众所周知的 $\alpha\approx0.8330786$ 缩放容量。
]]></description>
      <guid>http://arxiv.org/abs/2312.00073</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:06 GMT</pubDate>
    </item>
    </channel>
</rss>