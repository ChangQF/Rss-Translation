<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 09 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>度量空间中的不确定性量化</title>
      <link>https://arxiv.org/abs/2405.05110</link>
      <description><![CDATA[arXiv:2405.05110v1 公告类型：交叉
摘要：本文介绍了一种新颖的回归模型不确定性量化框架，其中响应在可分离的度量空间中取值，预测变量在欧几里得空间中。所提出的算法可以有效地处理大型数据集，并且与所使用的预测基础模型无关。此外，该算法具有渐近一致性保证，并且在一些特殊的同方差情况下，我们提供非渐近保证。为了说明所提出的不确定性量化框架的有效性，我们在与精准和数字医学相关的各种临床应用中使用了度量响应的线性回归模型（称为全局 Fr&#39;echet 模型）。分析的不同临床结果表示为复杂的统计对象，包括多元欧几里德数据、拉普拉斯图和概率分布。]]></description>
      <guid>https://arxiv.org/abs/2405.05110</guid>
      <pubDate>Thu, 09 May 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>多保真哈密顿蒙特卡罗</title>
      <link>https://arxiv.org/abs/2405.05033</link>
      <description><![CDATA[arXiv:2405.05033v1 公告类型：交叉
摘要：生物学、统计学、科学和工程领域的许多应用都需要从高维概率分布生成样本。近年来，哈密顿蒙特卡罗（HMC）方法作为最先进的马尔可夫链蒙特卡罗技术出现，利用这种高维目标分布的形状来有效地生成样本。尽管其在实证上取得了令人印象深刻的成功并且越来越受欢迎，但由于梯度计算的计算成本较高，其广泛采用仍然受到限制。此外，当无法计算后验梯度时（例如，使用黑盒模拟器），应用此方法是不可能的。为了克服这些挑战，我们提出了一种带有代理模型的新型两阶段哈密顿蒙特卡罗算法。在这种多保真度算法中，接受概率是在第一阶段使用廉价的可微代理模型通过标准 HMC 提案计算的，如果提案被接受，则在第二阶段使用高保真度（HF）评估后验概率。 ) 数值求解器。将标准 HMC 算法分为这两个阶段可以有效地逼近后验梯度，同时在第二阶段使用 HF 数值求解器生成准确的后验样本。我们证明了该算法对于一系列问题的有效性，包括使用计算机数据和实验数据的线性和非线性贝叶斯逆问题。所提出的算法被证明可以与各种低保真和高频模型、先验和数据集无缝集成。值得注意的是，我们提出的方法在计算和统计效率方面都优于传统的 HMC 算法几个数量级，同时保留或提高了计算后验统计的准确性。]]></description>
      <guid>https://arxiv.org/abs/2405.05033</guid>
      <pubDate>Thu, 09 May 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>基于层次相关重建的生物启发式联合分布神经元，允许多向神经网络</title>
      <link>https://arxiv.org/abs/2405.05097</link>
      <description><![CDATA[arXiv:2405.05097v1 公告类型：交叉 
摘要：流行的人工神经网络 (ANN) 优化单向值传播的参数，假设某些猜测的参数化类型，如多层感知器 (MLP) 或 Kolmogorov-Arnold 网络 (KAN)。相比之下，对于生物神经元，例如“动作电位的轴突传播在两个方向上发生并不罕见”\cite{axon} - 表明它们经过优化以连续以多向方式运行。此外，单个神经元可以建模的统计依赖关系不仅仅是（预期的）值依赖性，还包括整个联合分布，包括高阶矩。这种不可知的联合分布神经元将允许多向传播（分布或值），例如 $\rho(x|y,z)$ 或 $\rho(y,z|x)$，通过替换为 $\rho(x,y,z)$ 并进行规范化。我们将讨论这种神经元模型的层次相关重建 (HCR)：假设 $\rho(x,y,z)=\sum_{ijk} a_{ijk} f_i(x) f_j(y) f_k(z)$ 型联合分布参数化，多项式基 $f_i$，这允许灵活、廉价的处理，包括非线性、直接模型估计和更新，通过标准反向传播或新颖的方式对这种结构进行训练，直至张量分解。仅使用成对（输入-输出）依赖关系，其预期值预测变得类似于 KAN，其中训练的激活函数为多项式，可以通过包含的产品添加更高阶的依赖关系进行扩展 - 以有意识的可解释方式，允许值和概率密度的多向传播。]]></description>
      <guid>https://arxiv.org/abs/2405.05097</guid>
      <pubDate>Thu, 09 May 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>时变需求下收益管理的后采样学习</title>
      <link>https://arxiv.org/abs/2405.04910</link>
      <description><![CDATA[arXiv:2405.04910v1 公告类型：交叉
摘要：本文讨论了收入管理（RM）问题，通过对商品或服务进行定价来最大化收入。该问题的一个挑战是需求分布是未知的，并且在航空和零售行业等实际应用中随时间变化。特别是，由于难以共同管理剩余库存和估计需求，因此在未知需求场景下的时变需求尚未得到很好的研究。为了应对这一挑战，我们首先引入由典型应用场景驱动的 RM 问题的情景概括。然后，我们提出了一种基于后验采样的计算高效算法，该算法通过求解线性规划有效地优化价格。我们为一般模型推导了该算法的贝叶斯遗憾上限，其中需求参数可以在时间段之间相关，同时还推导了通用算法的遗憾下限。我们的实证研究表明，所提出的算法比其他基准算法表现更好，并且事后看来与最优策略相当。我们还提出了对所提出算法的启发式修改，进一步有效地学习实验中的定价策略。]]></description>
      <guid>https://arxiv.org/abs/2405.04910</guid>
      <pubDate>Thu, 09 May 2024 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>通过协同数据指导自适应收缩，以改进基于回归的预测和特征选择</title>
      <link>https://arxiv.org/abs/2405.04917</link>
      <description><![CDATA[arXiv:2405.04917v1 公告类型：交叉
摘要：基因组学数据的高维性质使特征选择变得复杂，特别是在低样本量研究中 - 这在临床预测环境中并不罕见。人们广泛认识到，关于特征的补充数据“协同数据”可以改善结果。例如先前的特征组或相关研究中的 p 值。由于公共存储库的可用性，此类协同数据在基因组学环境中无处不在。然而，在结构上使用此类协同数据的学习方法的采用是有限的。我们回顾了引导自适应收缩方法：一类基于回归的学习器，使用协同数据来调整收缩参数，这对于这些学习器的表现至关重要。我们讨论技术方面，还讨论可处理的协同数据类型的适用性。此类方法与其他几种方法进行了对比。特别是，通过评估特征选择，将组自适应收缩与更知名的稀疏组套索进行比较。最后，我们通过展示如何“自己动手”来展示引导收缩方法的多功能性：我们集成了协同数据学习器和尖峰和平板先验的实现，以改进遗传学研究中的特征选择。]]></description>
      <guid>https://arxiv.org/abs/2405.04917</guid>
      <pubDate>Thu, 09 May 2024 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>通过神经对抗不变性学习从异构环境中寻找因果关系</title>
      <link>https://arxiv.org/abs/2405.04715</link>
      <description><![CDATA[arXiv:2405.04715v1 公告类型：交叉
摘要：统计学面临一个根本问题，“内生性诅咒”——回归函数，或者更广泛地说，无限数据的预测风险最小化器，可能不是我们希望追求的目标。这是因为，当从多个来源收集复杂数据时，偏离个体或亚群体遗传的感兴趣（因果）关联的偏差预计不会被消除。传统的补救措施是事后诸葛亮，并且在根据先验知识（例如不可测试的因果结构）进行定制方面受到限制，导致方法存在模型错误指定的风险并且缺乏可扩展的适用性。本文旨在提供一种纯粹的数据驱动且普遍适用的方法，该方法仅使用数据偏差的异质性，而不是遵循预先提供的戒律。这样的想法被表述为非参数不变性追求问题，其目标是揭示不变条件期望 $m^\star(x)\equiv \mathbb{E}[Y^{(e)}|X_{S^\ star}^{(e)}=x_{S^\star}]$，具有跨异构环境 $e\in \mathcal{E}$ 的未知重要变量集 $S^\star$。在结构因果模型框架下，$m^\star$ 一般可以解释为某种数据驱动的因果关系。该论文提出了一种称为聚焦对抗不变正则化（FAIR）的新颖框架，该框架被制定为可以解决一般不变性追求问题的单个极小极大优化程序。正如统一非渐近分析所示，我们的对抗性估计框架可以在各种任务和模型的最小识别条件下获得类似于标准回归的可证明的样本有效估计。作为一种应用，由两个神经网络类实现的 FAIR-NN 估计器被强调为在一般非参数不变性学习中实现统计有效估计的第一种方法。]]></description>
      <guid>https://arxiv.org/abs/2405.04715</guid>
      <pubDate>Thu, 09 May 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>随机低秩近似的一般误差分析及其在数据同化中的应用</title>
      <link>https://arxiv.org/abs/2405.04811</link>
      <description><![CDATA[arXiv:2405.04811v1 公告类型：交叉
摘要：事实证明，随机算法在解决一大类数值线性代数问题上表现良好。他们的理论分析对于为其行为提供保证至关重要，从这个意义上说，随机低秩近似误差的随机分析起着核心作用。事实上，用于近似主要特征模式或奇异模式的几种随机方法可以重写为低秩近似方法。然而，尽管算法多种多样，但现有的分析理论框架依赖于协方差矩阵的特定结构，该结构并不适合所有算法。我们提出了一个通用框架，用于对中心和非标准高斯矩阵的 Frobenius 范数中的低秩逼近误差进行随机分析。在协方差矩阵的最小假设下，我们得出期望和概率的准确界限。我们的界限有清晰的解释，使我们能够导出协方差矩阵的属性并激发实际选择，从而产生有效的低秩近似算法。文献中最常用的界限已被证明为此处提出的界限的具体实例，并具有更严格的额外贡献。与数据同化相关的数值实验进一步说明，利用问题结构来选择协方差矩阵可以提高性能，正如我们的界限所表明的那样。]]></description>
      <guid>https://arxiv.org/abs/2405.04811</guid>
      <pubDate>Thu, 09 May 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>快速分散梯度跟踪，用于具有本地更新的联合极小极大优化</title>
      <link>https://arxiv.org/abs/2405.04566</link>
      <description><![CDATA[arXiv:2405.04566v1 公告类型：交叉
摘要：用于极小极大优化的联邦学习（FL）已成为跨分布式节点/客户端训练模型的强大范例，同时保护数据隐私和模型对数据异构性的鲁棒性。在这项工作中，我们通过提出 \texttt{K-GT-Minimax} 来深入研究联邦极小极大优化的去中心化实现，这是一种结合了局部更新和梯度跟踪技术的新型去中心化极小极大优化算法。我们的分析展示了该算法的通信效率和非凸强凹 (NC-SC) 极小极大优化的收敛速度，与现有方法相比，展示了卓越的收敛速度。 \texttt{K-GT-Minimax} 处理数据异构性并确保稳健性的能力强调了其在推进联邦学习研究和应用方面的重要性。]]></description>
      <guid>https://arxiv.org/abs/2405.04566</guid>
      <pubDate>Thu, 09 May 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>数据驱动的误差估计：无技术负担的多重误差上限</title>
      <link>https://arxiv.org/abs/2405.04636</link>
      <description><![CDATA[arXiv:2405.04636v1 公告类型：交叉
摘要：我们将构建多个同时有效的置信区间（CI）的问题表述为估计一类/一组估计-估计-误差元组的最大误差的高概率上限，并将其称为误差估计问题。对于单个这样的元组，数据驱动的置信区间通常可用于限制我们估计中的误差。然而，对于一类估计-估计-误差元组，最大误差的非平凡高概率上限通常需要类复杂性作为输入——限制了此类方法的实用性，并且常常导致宽松的边界。我们提出了一种完全数据驱动的方法来估计最大误差的上限，而不是推导基于理论类复杂性的界限。我们针对这一基本挑战的解决方案的简单性和通用性使其适合多种应用，包括：多重 CI 构建、多重假设检验、估计任何训练/微调算法的超额风险界限（机器学习中不确定性的基本度量），并实现上下文老虎机管道的开发，该管道可以利用任何奖励模型估计程序作为输入（无需额外的数学分析）。]]></description>
      <guid>https://arxiv.org/abs/2405.04636</guid>
      <pubDate>Thu, 09 May 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>转导式学习是否等同于 PAC 学习？</title>
      <link>https://arxiv.org/abs/2405.05190</link>
      <description><![CDATA[arXiv:2405.05190v1 公告类型：新
摘要：学习理论领域的大多数工作都集中在设计有效的可能近似正确（PAC）学习器。最近，其他学习模型（例如传导误差）受到了更多的审查。我们通过向数据集中添加少量样本，将具有 PAC 保证的不可知学习减少到具有转导保证的不可知学习，从而证明这些问题是等效的。我们首先重新推导 Aden-Ali 等人的结果。 arXiv:2304.09167 使用更简单的技术和更普遍的方法，在可实现的环境中将 PAC 学习简化为转导式学习，作为我们主要积极结果的背景。我们的不可知转导到 PAC 转换技术将上述论点扩展到不可知情况，表明不可知转导学习器可以有效地转换为不可知 PAC 学习器。最后，我们描述了 Asilis 等人的不可知单一包含图算法的性能。 arXiv:2309.13692 用于二元分类，并表明将其插入我们的归约中会产生本质上最优的不可知 PAC 学习器。我们的结果表明，转导式学习和 PAC 学习对于可实现环境中具有伪计量损失的监督学习以及不可知环境中的二元分类本质上是等效的。我们推测对于不可知论环境来说这更普遍。]]></description>
      <guid>https://arxiv.org/abs/2405.05190</guid>
      <pubDate>Thu, 09 May 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>具有私有密度估计的差分私有合成数据</title>
      <link>https://arxiv.org/abs/2405.04554</link>
      <description><![CDATA[arXiv:2405.04554v1 公告类型：交叉 
摘要：近年来，分析敏感数据（例如医疗记录或财务数据）的需求已成为一项关键的研究挑战。在本文中，我们采用差异隐私框架，并探索生成整个数据集的机制，该数据集可准确捕捉原始数据的特征。我们以 Boedihardjo 等人的工作为基础，为基于优化的隐私合成数据生成新算法奠定了基础。重要的是，我们通过用隐私分布估计器替换均匀采样步骤来调整他们的算法；这使我们能够获得更好的离散分布计算保证，并开发出一种适用于连续分布的新算法。我们还探索了我们的工作在几个统计任务中的应用。]]></description>
      <guid>https://arxiv.org/abs/2405.04554</guid>
      <pubDate>Thu, 09 May 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>从弱相关数据中进行稳健的深度学习</title>
      <link>https://arxiv.org/abs/2405.05081</link>
      <description><![CDATA[arXiv:2405.05081v1 公告类型：新
摘要：深度学习的最新发展确立了深度神经网络估计器的一些理论特性。然而，关于该主题的大多数现有工作仅限于有界损失函数或（亚）高斯或有界输入。本文考虑了来自弱相关观察的鲁棒深度学习，具有无界损失函数和无界输入/输出。仅假设输出变量具有有限的 $r$ 阶矩，且 $r &gt;1$。深度神经网络估计器的预期超额风险的非渐近界限是在强混合和对观测值的弱依赖假设下建立的。我们推导了这些界限和$r$之间的关系，当数据具有任意阶矩（即$r=\infty$）时，收敛速度接近一些众所周知的结果。当目标预测器属于具有足够大平滑指数的 H\&quot;older 平滑函数时，指数强混合数据的预期超额风险率接近或与独立同分布样本获得的预期超额风险率接近或相同。在鲁棒性中的应用考虑了非参数回归和鲁棒非参数自回归对重尾误差模型的模拟研究表明，具有绝对损失和Huber损失函数的鲁棒估计量优于最小二乘法。]]></description>
      <guid>https://arxiv.org/abs/2405.05081</guid>
      <pubDate>Thu, 09 May 2024 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>$k$-NN 回归的留一交叉验证的快速计算</title>
      <link>https://arxiv.org/abs/2405.04919</link>
      <description><![CDATA[arXiv:2405.04919v1 公告类型：新
摘要：我们描述了一种用于$k$-最近邻（$k$-NN）回归的留一交叉验证（LOOCV）的快速计算方法。我们表明，在最近邻的平局决胜条件下，$k$-NN 回归的均方误差的 LOOCV 估计与在训练数据，乘以缩放因子 $(k+1)^2/k^2$。因此，为了计算LOOCV分数，只需拟合$(k+1)$-NN回归一次，并且不需要针对训练数据的数量重复$k$-NN回归的训练验证。数值实验验证了快速计算方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.04919</guid>
      <pubDate>Thu, 09 May 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>通过深度生成模型学习结构因果模型：方法、保证和挑战</title>
      <link>https://arxiv.org/abs/2405.05025</link>
      <description><![CDATA[arXiv:2405.05025v1 公告类型：新
摘要：本文对深层结构因果模型（DSCM）进行了全面的回顾，特别关注它们使用已知因果结构内的观察数据回答反事实查询的能力。它通过分析底层深度学习组件和结构因果模型固有的假设、保证和应用，深入研究 DSCM 的特征，从而更好地理解它们在解决不同反事实查询方面的能力和局限性。此外，它还强调了深层结构因果建模领域的挑战和悬而未决的问题。它为研究人员确定未来的工作方向和从业者获得概述奠定了基础，以便找到最适合他们需求的方法。]]></description>
      <guid>https://arxiv.org/abs/2405.05025</guid>
      <pubDate>Thu, 09 May 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>COBRA 在顺序学习设置中的一些变化</title>
      <link>https://arxiv.org/abs/2405.04539</link>
      <description><![CDATA[arXiv:2405.04539v1 公告类型：新
摘要：本文介绍了基于组合回归策略的不同变化的多元时间序列预测的创新方法。我们使用特定的数据预处理技术，这使得预测行为发生了根本性的变化。我们比较基于贝叶斯优化（BO）和常用网格搜索两种超参数调整的模型的性能。我们提出的方法优于所有最先进的比较模型。我们通过来自三个类别的八个时间序列数据集来说明这些方法：加密货币、股票指数和短期负载预测。]]></description>
      <guid>https://arxiv.org/abs/2405.04539</guid>
      <pubDate>Thu, 09 May 2024 06:18:14 GMT</pubDate>
    </item>
    </channel>
</rss>