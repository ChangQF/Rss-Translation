<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 stat.ML 更新</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 07 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用维纳混沌展开中的神经网络求解随机偏微分方程</title>
      <link>https://arxiv.org/abs/2411.03384</link>
      <description><![CDATA[arXiv:2411.03384v1 公告类型：新
摘要：在本文中，我们通过使用（可能是随机的）神经网络在其相应解的截断维纳混沌展开中对随机偏微分方程 (SPDE) 进行数值求解。此外，我们还提供了一些近似率来学习具有加性和/或乘性噪声的 SPDE 的解。最后，我们将结果应用于数值示例中，以近似三个 SPDE 的解：随机热方程、Heath-Jarrow-Morton 方程和 Zakai 方程。]]></description>
      <guid>https://arxiv.org/abs/2411.03384</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Csisz\'{a}r 型 Tsallis 熵设计神经网络优化中的线性化势函数</title>
      <link>https://arxiv.org/abs/2411.03611</link>
      <description><![CDATA[arXiv:2411.03611v1 公告类型：新
摘要：近年来，神经网络的学习可以看作是概率测度空间中的优化。为了获得优化器的指数收敛，基于香农熵的正则项起着重要作用。尽管熵函数对收敛结果有很大影响，但几乎没有关于其泛化的结果，因为以下两个技术困难：一是缺乏广义对数 Sobolev 不等式的充分条件，二是梯度流方程中势函数的分布依赖性。在本文中，我们建立了一个框架，该框架利用 Csisz\&#39;{a}r 类型的 Tsallis 熵（广义熵之一）的线性化势函数。我们还表明我们的新框架使我们能够得出指数收敛结果。]]></description>
      <guid>https://arxiv.org/abs/2411.03611</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于子采样的空间数据神经网络</title>
      <link>https://arxiv.org/abs/2411.03620</link>
      <description><![CDATA[arXiv:2411.03620v1 公告类型：新
摘要：深度神经网络在地理空间数据中的应用已成为当今的热门研究问题。已经引入了大量统计研究，例如通过合并空间方差-协方差矩阵的广义最小二乘优化、在神经网络的输入节点中考虑基函数等。然而，对于格点数据，没有关于在空间数据回归中使用神经网络渐近分析的文献。本文提出了一种基于局部两层深度神经网络的空间数据一致性回归。我们已经证明了这种深度神经网络在混合增加空间区域的固定采样设计下对有界和无界空间域的一致性。我们已证明其渐近收敛速度比 \cite{zhan2024neural} 神经网络和 \cite{shen2023asymptotic} 神经网络结构的改进泛化更快。我们通过经验观察了观测数据和预测数据的经验概率分布之间的差异度量的收敛速度，对于不太平滑的空间表面，收敛速度会变得更快。我们将深度神经网络的渐近分析应用于从美国卫星图像估计其主要城市的月平均气温。此应用是非线性空间回归的有效展示。我们在各种场景中使用模拟网格数据演示了我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2411.03620</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>线性集成采样的改进遗憾算法</title>
      <link>https://arxiv.org/abs/2411.03932</link>
      <description><![CDATA[arXiv:2411.03932v1 公告类型：新
摘要：在这项工作中，我们通过提供改进的线性集合抽样遗憾界限来缩小理论与实践之间的根本差距。我们证明，当集合大小对数为 $T$ 时，线性集合抽样可以实现频率论遗憾界限 $\tilde{\mathcal{O}}(d^{3/2}\sqrt{T})$，与随机线性强盗算法的最新结果相匹配，其中 $d$ 和 $T$ 分别是参数和时间范围的维度。我们的方法为线性强盗算法引入了一个通用的遗憾分析框架。此外，我们揭示了线性集合抽样和线性扰动历史探索 (LinPHE) 之间的重要关系，表明当集合大小等于 $T$ 时，LinPHE 是线性集合抽样的一个特例。这项洞察使我们能够为 LinPHE 推导出新的遗憾界限 $\tilde{\mathcal{O}}(d^{3/2}\sqrt{T})$，与臂的数量无关。我们的贡献推进了集合采样的理论基础，使其遗憾界限与其他随机探索算法的最佳已知界限保持一致。]]></description>
      <guid>https://arxiv.org/abs/2411.03932</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>部分结构发现足以实现因果赌博中的无遗憾学习</title>
      <link>https://arxiv.org/abs/2411.04054</link>
      <description><![CDATA[arXiv:2411.04054v1 公告类型：新
摘要：在老虎机环境中，关于决策变量和奖励变量之间关系的因果知识可以加速最佳决策的学习。当前的研究通常假设因果图是已知的，但这可能并不总是先验的。受这一挑战的启发，我们专注于因果老虎机问题，即底层因果图未知且可能包含潜在混杂因素的场景。虽然在没有潜在混杂因素的情况下，对奖励节点的父节点进行干预是最佳的，但一般情况下并非如此。相反，必须考虑一组可能的最佳武器/干预措施，每个武器/干预措施都是奖励节点祖先的一个特殊子集，这使得在奖励节点的父节点之外发现因果关系至关重要。对于遗憾最小化，我们发现发现完整的因果结构是不必要的；然而，现有的研究并没有提供因果图的必要和充分组成部分。我们正式描述了需要检测或学习的必要和充分的潜在混杂因素集，以确保正确识别所有可能的最佳臂。我们还提出了一种随机算法，用于使用有限数量的样本学习因果图，为任何所需的置信度提供样本复杂度保证。在因果老虎机设置中，我们提出了一种两阶段方法。在第一阶段，我们学习奖励祖先的诱导子图，以及必要和充分的潜在混杂因素子集，以构建可能的最佳臂集。在此阶段产生的遗憾与因果图中的节点数呈多项式关系。第二阶段涉及标准老虎机算法的应用，例如 UCB 算法。我们还为我们的两阶段方法建立了遗憾界限，该界限在轮数上是亚线性的。]]></description>
      <guid>https://arxiv.org/abs/2411.04054</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>平移不变性下的近似最优且易处理的估计</title>
      <link>https://arxiv.org/abs/2411.03383</link>
      <description><![CDATA[arXiv:2411.03383v1 公告类型：交叉 
摘要：估计离散时间信号 $(x_{1}, ..., x_{n}) \in \mathbb{C}^n$ 有多难，该信号满足未知的 $s$ 阶线性递归关系，并在 i.i.d. 复杂高斯噪声中观察到？所有此类信号的类别都是参数化的，但非常丰富：它包含 $\mathbb{C}$ 上所有总次数为 $s$ 的指数多项式，包括具有 $s$ 个任意频率的谐振动。从几何上讲，此类对应于维度为 $s$ 的 $\mathbb{C}^\mathbb{Z}$ 的所有平移不变子空间的并集在 $\mathbb{C}^{n}$ 上的投影。我们表明，此类的统计复杂度（以 $(1-\delta)$ 置信度 $\ell_2$ 球的平方极小极大半径衡量）与 $s$ 稀疏信号类的统计复杂度几乎相同，即 $O\left(s\log(en) + \log(\delta^{-1})\right) \cdot \log^2(es) \cdot \log(en/s)。此外，相应的近极小极大估计量是可处理的，可用于在相关检测问题中构建具有近极小极大检测阈值的检验统计量。这些统计结果基于近似理论：我们表明，有限维平移不变子空间允许紧支撑再生核，其傅里叶谱几乎具有最小的可能 $\ell_p$ 范数，对于所有 $p \in [1,+\infty]$。]]></description>
      <guid>https://arxiv.org/abs/2411.03383</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量化治疗效果的随机不确定性：一种新颖的正交学习器</title>
      <link>https://arxiv.org/abs/2411.03387</link>
      <description><![CDATA[arXiv:2411.03387v1 公告类型：交叉 
摘要：从观察数据中估计因果量对于理解医疗治疗的安全性和有效性至关重要。然而，为了做出可靠的推断，医疗从业者不仅需要估计平均因果量，例如条件平均治疗效果，还需要了解治疗效果作为随机变量的随机性。这种随机性被称为随机不确定性，对于理解治疗获益的概率或治疗效果的分位数是必要的。然而，治疗效果的随机不确定性在因果机器学习社区中却很少受到关注。为了填补这一空白，我们的目标是在协变量条件水平上量化治疗效果的随机不确定性，即治疗效果的条件分布 (CDTE)。与平均因果量不同，如果没有强有力的附加假设，CDTE 是无法点识别的。作为补救措施，我们采用部分识别来获得 CDTE 的明确界限，从而量化治疗效果的随机不确定性。然后，我们为 CDTE 的界限开发了一种新颖的正交学习器，我们称之为 AU-learner。我们进一步表明，我们的 AU-learner 具有几个优势，因为它满足 Neyman 正交性并且具有双重鲁棒性。最后，我们提出了一个完全参数化的 AU-learner 深度学习实例。]]></description>
      <guid>https://arxiv.org/abs/2411.03387</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过记忆感知降低 ML、视觉和语言模型训练流程中的超参数调整成本</title>
      <link>https://arxiv.org/abs/2411.03731</link>
      <description><![CDATA[arXiv:2411.03731v1 公告类型：交叉 
摘要：机器学习、视觉和语言模型的训练或微调通常以流水线的形式实现：一系列阶段，包括数据准备、模型训练和评估。在本文中，我们利用流水线结构来降低模型训练/微调的超参数调整成本，这对于语言模型尤其有价值，因为它们在 GPU 上的成本很高。我们提出了一种“记忆感知”贝叶斯优化 (BO) 算法 EEIPU，它与流水线缓存系统协同工作，使其能够比其他调整算法在每个 GPU 上评估更多的超参数候选。结果是在相同的搜索时间内获得更高质量的超参数，或者等效地，减少搜索时间以达到相同的超参数质量。在我们对机器学习（模型集成）、视觉（卷积架构）和语言（T5 架构）管道的基准测试中，我们将 EEIPU 与最近的 BO 算法进行了比较：EEIPU 平均多产生 $103\%$ 的超参数候选（在相同预算内），并且比其他算法将验证指标平均提高了 $108\%$（从预热迭代结束开始测量增量）。]]></description>
      <guid>https://arxiv.org/abs/2411.03731</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对梯度重构攻击的最佳防御</title>
      <link>https://arxiv.org/abs/2411.03746</link>
      <description><![CDATA[arXiv:2411.03746v1 公告类型：交叉 
摘要：联邦学习 (FL) 旨在通过协作模型训练来防止数据泄露，而无需集中数据存储。然而，它仍然容易受到梯度重建攻击，这种攻击会从共享梯度中恢复原始训练数据。为了优化数据泄露和效用损失之间的权衡，我们首先为两种标准方法（添加噪声和梯度剪枝）推导出重建误差的理论下限（在所有攻击者中）。然后，我们将这两种防御措施定制为参数和模型特定的，并在我们获得的重建下限和模型效用之间实现最佳权衡。实验结果验证了我们的方法优于梯度噪声和梯度剪枝，因为它可以更好地保护训练数据，同时实现更好的效用。]]></description>
      <guid>https://arxiv.org/abs/2411.03746</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用量子熵进行布尔超立方体的变分推理</title>
      <link>https://arxiv.org/abs/2411.03759</link>
      <description><![CDATA[arXiv:2411.03759v1 公告类型：交叉 
摘要：在本文中，我们基于 Kullback-Leibler 散度的量子松弛，推导出布尔超立方体上成对马尔可夫随机场对数分割函数的变分推理上限。然后，我们提出了一种基于原始对偶优化计算这些界限的有效算法。提出了一种通过使用类似于平方和 (SoS) 层次结构的“层次结构”来改进这些界限的方法，并提出了一种贪婪算法来在这些松弛中进行选择。我们对这个推理问题进行了广泛的数值实验，并与最先进的方法进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2411.03759</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多语言层次分类招聘广告，用于职位空缺统计</title>
      <link>https://arxiv.org/abs/2411.03779</link>
      <description><![CDATA[arXiv:2411.03779v1 公告类型：交叉 
摘要：本文的目标是根据国际标准职业分类 (ISCO) 开发在线招聘广告职业代码的多语言分类器和条件概率估计器，该分类器扩展了波兰职业和专业分类 (KZiS)，类似于欧洲职业分类。在本文中，我们利用了一系列数据源，包括一个新的数据源，即中央工作机会数据库，它是提交给公共就业办公室的所有职位空缺的登记册。他们的工作人员根据 ISCO 和 KZiS 对职位空缺进行编码。基于变压器架构开发了一个分层多类分类器。分类器首先将广告中的职位编码为最宽的 1 位职业组，然后将分配缩小到 6 位职业代码。我们表明，结合职业的层级结构可将预测准确度提高 1-2 个百分点，尤其是对于手工编码的在线招聘广告。最后，基于使用闭源和开源软件翻译的数据开发了双语（波兰语和英语）和多语（24 种语言）模型。开源软件是为了官方统计界的利益而提供的，特别注重国际可比性。]]></description>
      <guid>https://arxiv.org/abs/2411.03779</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合迁移强化学习：从移位动态数据中证明样本效率</title>
      <link>https://arxiv.org/abs/2411.03810</link>
      <description><![CDATA[arXiv:2411.03810v1 公告类型：交叉 
摘要：在线强化学习 (RL) 通常需要高风险的在线交互数据来学习目标任务的策略。这引起了人们对利用历史数据来提高样本效率的兴趣。历史数据可能来自具有不同动态的过时或相关源环境。目前仍不清楚如何在目标任务中有效地使用这些数据来可证明地提高学习和样本效率。为了解决这个问题，我们提出了一种混合转移 RL (HTRL) 设置，其中代理在目标环境中学习，同时从具有偏移动态的源环境中访问离线数据。我们表明 - 如果没有关于动态偏移的信息 - 一般的偏移动态数据，即使是细微的偏移，也不会降低目标环境中的样本复杂性。然而，有了关于动态偏移程度的先前信息，我们设计了 HySRL，这是一种实现问题相关样本复杂性并优于纯在线 RL 的转移算法。最后，我们的实验结果表明 HySRL 超越了最先进的在线 RL 基线。]]></description>
      <guid>https://arxiv.org/abs/2411.03810</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GUIDE-VAE：利用用户信息和模式词典推进数据生成</title>
      <link>https://arxiv.org/abs/2411.03936</link>
      <description><![CDATA[arXiv:2411.03936v1 公告类型：交叉 
摘要：多用户数据集的生成建模在科学和工程领域已变得十分重要。为给定用户生成数据点需要使用用户信息，而传统的生成模型（包括变分自动编码器 (VAE)）通常会忽略这一点。本文介绍了 GUIDE-VAE，这是一种利用用户嵌入来生成用户引导数据的新型条件生成模型。通过允许模型从用户之间的共享模式中受益，GUIDE-VAE 可提高多用户设置下的性能，即使在数据严重不平衡的情况下也是如此。除了集成用户信息外，GUIDE-VAE 还结合了基于模式词典的协方差组合 (PDCC)，通过捕获复杂的特征依赖关系来提高生成样本的真实性。虽然用户嵌入可以提高性能，但 PDCC 解决了 VAE 中常见的噪声和过度平滑等常见问题。
所提出的 GUIDE-VAE 是在多用户智能电表数据集上进行评估的，该数据集的特点是用户之间的数据严重不平衡。定量结果表明，GUIDE-VAE 在合成数据生成和缺失记录插补任务中均表现良好，而定性评估表明，GUIDE-VAE 生成的数据更合理、噪声更少。这些结果表明，GUIDE-VAE 是一种有前途的工具，可用于在多用户数据集中生成受控、真实的数据，并可能应用于需要用户知情建模的各个领域。]]></description>
      <guid>https://arxiv.org/abs/2411.03936</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无界域上神经网络的加权 Sobolev 近似率</title>
      <link>https://arxiv.org/abs/2411.04108</link>
      <description><![CDATA[arXiv:2411.04108v1 公告类型：交叉 
摘要：在这项工作中，我们考虑了浅层神经网络在加权 Sobolev 空间中对谱 Barron 空间中函数的逼近能力。现有文献已经涵盖了几种情况，其中浅层网络和几种不同类型的激活函数可以很好地近似谱 Barron 空间，即没有维数灾难。现有结果的局限性主要在于所考虑的误差度量，其中结果仅限于有界域上的 Sobolev 空间。我们将在这里处理两种扩展现有结果的情况。即，我们处理有界域和 Muckenhoupt 权重的情况以及允许域无界且权重需要衰减的情况。我们首先展示在加权 Sobolev 空间中更一般的加权 Fourier-Lebesgue 空间的嵌入结果，然后为没有维数灾难的浅层神经网络建立渐近近似率。]]></description>
      <guid>https://arxiv.org/abs/2411.04108</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注意尖峰：固定维度中内核和神经网络的良性过度拟合</title>
      <link>https://arxiv.org/abs/2305.14077</link>
      <description><![CDATA[arXiv:2305.14077v3 公告类型：替换 
摘要：过度参数化的神经网络训练到接近零的训练误差的成功引起了人们对良性过拟合现象的极大兴趣，在良性过拟合中，即使估计量插入了嘈杂的训练数据，它们在统计上也是一致的。虽然一些学习方法已经建立了固定维度的良性过拟合，但目前的文献表明，对于使用典型核方法和宽神经网络的回归，良性过拟合需要高维设置，其中维度随样本大小而增长。在本文中，我们表明估计量的平滑度，而不是维度，是关键：良性过拟合当且仅当估计量的导数足够大时才有可能。我们将现有的不一致结果推广到非插值模型和更多核，以表明在固定维度下不可能出现具有中等导数的良性过拟合。相反，我们表明，对于具有较大导数的尖峰平滑核序列的回归，速率最优良性过拟合是可能的。使用神经正切核，我们将结果转换为宽神经网络。我们证明，虽然无限宽度网络不会良性地与 ReLU 激活过度拟合，但可以通过向激活函数添加小的高频波动来解决这个问题。我们的实验验证了这种神经网络虽然过度拟合，但即使在低维数据集上也能很好地推广。]]></description>
      <guid>https://arxiv.org/abs/2305.14077</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>